- en: Chapter 7\. Clustering and Segmentation in R
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章 聚类与分割在R中
- en: 'Big Bonanza Warehouse is at the beginning of a big change: they’re going to
    upgrade their current SAP system to S/4HANA. Furthermore, they’ve decided they
    will not migrate all of their old data unless necessary. Each department has been
    tasked with identifying its own crucial data. Rod works as a national account
    rep and his responsibility is to identify which customers in their system should
    be migrated. They have decades of customer data, much of which is obsolete.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 大宝贝仓库正在进行一场重大变革：他们将升级当前的SAP系统为S/4HANA。此外，他们决定除非必要，否则不迁移他们的旧数据。每个部门都被要求确定其自己的关键数据。罗德作为国家客户代表，他的责任是确定系统中应该迁移哪些客户。他们有数十年的客户数据，其中许多已经过时。
- en: Rod has long wanted to understand his customers better so this process will
    be rewarding for him. Which customers are the highest value? Does this exercise
    entail a simple calculation of the top N sales by customer? Is it the frequency
    of a customer purchase? Maybe it is a combination of factors. He turns to Duane,
    his SAP Sales and Distribution Analyst, for suggestions on how to approach this.
    Duane, having read this book, thinks immediately, “This is a task for clustering
    and segmentation!”
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 罗德长期以来一直想更好地了解他的客户，因此这个过程对他来说是有益的。哪些客户是最有价值的？这项工作是否仅仅是计算客户按销售额排名前N名？或者是顾客购买的频率？也许是一些因素的结合。他向他的SAP销售与分销分析师杜安寻求建议如何解决这个问题。杜安读过这本书后立刻想到：“这是聚类和分割的任务！”
- en: Clustering is any one of several algorithmic approaches to dividing a dataset
    into smaller, meaningful groups. There’s no predetermined notion of what dimension
    (or dimensions) best allow that grouping. Practically speaking, you’ll almost
    always have some idea what dimension (or features) you want to analyze. For example,
    we have sales data and you want to know customer value. Well, clearly overall
    purchase history and dollar value is important. What about the frequency of a
    customer purchase? What about how recent they purchased? Perhaps they moved away?
    We will use all three of these features to demonstrate clustering in this chapter.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类是将数据集分成较小且有意义的组的几种算法之一。并没有预先确定什么维度（或多维度）最适合进行分组。从实际角度来看，你几乎总是会对你想分析的维度（或特征）有一些想法。例如，我们有销售数据，你想了解客户价值。显然，整体购买历史和金额很重要。那么顾客购买的频率呢？他们最近的购买情况呢？也许他们搬走了？在本章中，我们将使用这三个特征来演示聚类。
- en: Segmentation applies the clustering to business strategies. Its most common
    use comes in researching markets. If you can identify groups of customers (or
    potential customers, or opportunities), you can identify efficient ways to approach
    them based on their cluster position. For example, you could cluster customers
    based on what time of the week they are likely to respond to ads, then fine-tune
    your advertising from that information.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 分割将聚类应用于业务策略。它最常见的用途是研究市场。如果你能够识别出客户（或潜在客户或机会）的群体，你就可以根据他们的集群位置确定高效的接触方式。例如，你可以基于客户在一周中哪个时段更可能对广告做出响应来对客户进行聚类，然后根据这些信息微调你的广告策略。
- en: Note
  id: totrans-5
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Clustering and segmentation are often used interchangeably. However, there is
    a technical distinction. Clustering is considered the act of using machine learning
    to bunch the customers together. Segmentation is used to *apply the results of
    clustering*. It absolutely looks like nit-picky semantics, but it’s more than
    that. It also reminds us of a coworker who had a fit when someone used the term
    *on-premise* incorrectly...calm yourself.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类和分割经常被交替使用。然而，它们在技术上是有区别的。聚类被认为是使用机器学习将客户分组的行为。分割则用于*应用聚类的结果*。这看起来确实像是挑剔的语义，但它不仅仅如此。它还让我们想起一个同事，当有人错误地使用术语*on-premise*时发火了...冷静下来。
- en: In this chapter we will walk through the process of clustering and segmenting
    customer data using a variety of techniques. This is a one-time report to be delivered
    to Rod. We’ve decided to use R Markdown^([1](ch07.html#ch07fn1)) as it is an easy
    way to report our results. There is no need to build a dynamic dashboard such
    as PowerBI as we did in [Chapter 5](ch05.html#anomaly_detection_with_r_and_python)
    since the data is not going to change. R Markdown can become quite complex; however,
    in our example we’re going to use the basic features. [Figure 7-1](#process_flow_used_for_segmenting_custome)
    shows the process we will follow. We have seen this flow before, but this time
    we’ve added a “Report” as the final step. Remember, Rod is a national account
    representative; sales people don’t want to see code.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将通过多种技术步骤来详细说明聚类和分段客户数据的过程。这是一次性报告，要交给Rod。我们决定使用R Markdown^([1](ch07.html#ch07fn1))，因为这是报告结果的简便方式。不像在[第5章](ch05.html#anomaly_detection_with_r_and_python)中做的那样构建动态仪表板如PowerBI，因为数据不会发生变化。尽管R
    Markdown可能变得非常复杂；但在我们的示例中，我们将使用基本功能。[图7-1](#process_flow_used_for_segmenting_custome)展示了我们将遵循的流程。我们之前见过这个流程，但这次我们添加了“报告”作为最后一步。记住，Rod是一位国家客户代表；销售人员不希望看到代码。
- en: '![Process flow used for segmenting customer data](assets/pdss_0701.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![用于分段客户数据的流程图](assets/pdss_0701.png)'
- en: Figure 7-1\. Process flow used for segmenting customer data
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-1\. 用于分段客户数据的流程图
- en: Understanding Clustering and Segmentation
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解聚类和分段
- en: 'Before we can segment our customers, we need to understand a few different
    types of clustering and segmentation techniques. There are many different clustering
    techniques, but we will focus on:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们能够对客户进行分段之前，我们需要了解几种不同的聚类和分段技术。有许多不同的聚类技术，但我们将重点关注：
- en: The recency, frequency, and monetary value (RFM) approach
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最近性、频率和货币价值（RFM）方法
- en: '*k*-means clustering'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*k*-均值聚类'
- en: '*k*-medoid or partitioning around medoids (PAM) clustering'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*k*-中心或围绕中心（PAM）聚类'
- en: Hierarchical clustering
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分层聚类
- en: Time-series clustering
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间序列聚类
- en: RFM
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RFM
- en: 'RFM is a clustering method that evaluates customers based solely on their purchase
    history. The scenario is pretty straightforward. The customer is evaluated based
    on the following three factors:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: RFM是一种仅基于客户购买历史评估客户的聚类方法。情景非常直接。客户根据以下三个因素进行评估：
- en: Recency
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 最近性
- en: When was the last purchase?
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 上次购买是什么时候？
- en: Frequency
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 频率
- en: How many purchases did they make in a given time period?
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 他们在给定时间段内购买了多少次？
- en: Monetary value
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 货币价值
- en: What is the total dollar value of the purchases in this time period?
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个时间段内的购买总金额是多少？
- en: Once these questions are answered the customer is assigned a value for each
    factor, typically 5 for the top 20%, 4 for the next 20%, and so on. Once they
    are given values in each category, we can cluster the customers based on those
    values. These are individual RFM *values*. These values are combined (concatenated)
    into the RFM *score.* For instance, if a customer has a recency of 5, a frequency
    of 4, and a monetary value of 3, their RFM score would be 543.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦这些问题得到解答，客户就会为每个因素分配一个值，通常是前20%为5分，接下来的20%为4分，依此类推。一旦他们在每个类别中得到了值，我们可以根据这些值对客户进行聚类。这些是个体的RFM
    *值*。这些值被组合（连接）成RFM *分数*。例如，如果客户的最近性为5，频率为4，货币价值为3，他们的RFM分数将是543。
- en: These customers are then placed into a category from which actions can be taken
    (i.e., during segmentation), as shown in [Table 7-1](#RFM-customer-segment). This
    can be a very granular or more generic approach; there is a detailed list of options
    on the [Putler website](https://www.putler.com/rfm-analysis).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将这些客户放入一个类别中，可以采取行动（即在分段过程中），如[表7-1](#RFM-customer-segment)所示。这可以是非常细粒度或更一般化的方法；在[Putler网站](https://www.putler.com/rfm-analysis)上有详细的选项列表。
- en: Table 7-1\. RFM customer segment characteristics
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 表7-1\. RFM客户段特征
- en: '| Customer Segment | Factor | Characteristics |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 客户段 | 因素 | 特征 |'
- en: '| --- | --- | --- |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Champions | R - High | Bought recently |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 冠军 | R - 高 | 最近购买 |'
- en: '|  | F - High | Buy often |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '|  | F - 高 | 经常购买 |'
- en: '|  | M - High | Spend the most |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '|  | M - 高 | 花费最多 |'
- en: '| Potential Champions | R - High | Bought recently |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 潜在冠军 | R - 高 | 最近购买 |'
- en: '|  | F - Medium | Not often |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '|  | F - 中等 | 不经常 |'
- en: '|  | M - High | Spent a lot |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '|  | M - 高 | 花费很多 |'
- en: '| Middle of the Road | R - Medium to High | Bought fairly recently |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 中等路线 | R - 中至高 | 较近期购买 |'
- en: '|  | F - Medium to High | Have some frequency |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '|  | F - 中至高 | 有一定频率 |'
- en: '|  | M - Medium | Spend a medium amount |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '|  | M - Medium | Spend a medium amount |'
- en: '| Almost Inactive | R - Low to Medium | Haven’t bought in a while |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| Almost Inactive | R - Low to Medium | Haven’t bought in a while |'
- en: '|  | F - Medium | Had some frequency |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '|  | F - Medium | Had some frequency |'
- en: '|  | M - Low to Medium | Spent a medium to low amount |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '|  | M - Low to Medium | Spent a medium to low amount |'
- en: '| Inactive | R - Low | No recent activity |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| Inactive | R - Low | No recent activity |'
- en: '|  | F - Low | Not much if any frequency |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '|  | F - Low | Not much if any frequency |'
- en: '|  | M - Low | Not spending much |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '|  | M - Low | Not spending much |'
- en: '| One-Timers | R - Anything | Any time frame recently |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| One-Timers | R - Anything | Any time frame recently |'
- en: '|  | F - Low | Not much if any frequency |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '|  | F - Low | Not much if any frequency |'
- en: '|  | M - Anything | Any monetary value |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '|  | M - Anything | Any monetary value |'
- en: '| Penny Pinchers | R - Anything | Any time frame recently |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| Penny Pinchers | R - Anything | Any time frame recently |'
- en: '|  | F - Anything | Any type of frequency |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '|  | F - Anything | Any type of frequency |'
- en: '|  | M - Low | Low monetary value |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '|  | M - Low | Low monetary value |'
- en: Businesses will have different definitions of what they consider *High*, *Medium*,
    and *Low*. For our purposes, we will say High is 4 to 5, Medium is 2 to 3, and
    Low is 1.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 企业对于他们认为的*高*、*中*和*低*可能有不同的定义。对于我们的目的，我们将高定义为4到5，中定义为2到3，低定义为1。
- en: Pareto Principle
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 帕累托原则
- en: Many clustering and evaluation techniques that are ultimately used for customer
    segmentation are based on the *Pareto principle*, which is summed up in [Figure 7-2](#the_pareto_principle).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 许多最终用于客户分割的聚类和评估技术都基于*帕累托原则*，这在 [图 7-2](#the_pareto_principle) 中有所总结。
- en: '![The Pareto Principle](assets/pdss_0702.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![帕累托原则](assets/pdss_0702.png)'
- en: Figure 7-2\. The Pareto principle
  id: totrans-55
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-2\. 帕累托原则
- en: This principle indicates that 80% of the sales for Big Bonanza Warehouse is
    driven by only 20% of the customers. For our conversion task, that means we want
    to make sure that these key customers are converted into the new system.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 此原则表明，Big Bonanza Warehouse 的销售的80%来自于仅有的20%客户。对于我们的转换任务，这意味着我们要确保这些关键客户被转化为新系统。
- en: k-Means
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: k-Means
- en: '*k*-means is an algorithm that clusters values around a geometric center. When
    using *k*-means you need to define the number of clusters you’d like to use. The
    process of choosing the number of clusters is both intuitive (in the respect that
    you may know your data and have an idea of how many clusters or groups you will
    need) and experimental. We will also explore automatically finding the optimal
    clusters later in this chapter. For now, let’s choose three. The algorithm randomly
    initializes three points called centroids. Then it goes through each of the data
    points (our customers’ RFM score perhaps) and assigns them to the closest centroid.
    Then the algorithm focuses back on the centroids and moves them to the average
    distance from all points that were assigned to it. This process repeats until
    the centroids stop moving. If there are few centroids, *k*-means is computationally
    fast. An example process might look something like Figures [7-3](#step_one_in_kmeans_-_random_centroid_ini)
    through [7-6](#final_position_in_kmeans_-_centroid_aver).'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*k*-means 是一种聚类算法，它将数值聚集在几何中心周围。使用 *k*-means 时，您需要定义要使用的聚类数。选择聚类数的过程既直观（您可能了解您的数据，并且知道您需要多少个聚类或组），也是实验性的。我们还将在本章后面探讨自动找到最优聚类的方法。现在，让我们选择三个聚类。该算法随机初始化三个称为质心的点。然后，它遍历每个数据点（也许是我们客户的
    RFM 分数），并将它们分配给最近的质心。然后算法再次关注质心，并将它们移动到所有分配给它的点的平均距离处。这个过程重复进行，直到质心停止移动。如果质心较少，*k*-means
    的计算速度很快。一个示例过程可能看起来像图 [7-3](#step_one_in_kmeans_-_random_centroid_ini) 到图 [7-6](#final_position_in_kmeans_-_centroid_aver)。'
- en: '![Step One in k-means - random centroid initialization](assets/pdss_0703.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![k-means 中的第一步 - 随机质心初始化](assets/pdss_0703.png)'
- en: Figure 7-3\. Step 1 in k-means—random centroid initialization
  id: totrans-60
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-3\. k-means 第1步 — 随机质心初始化
- en: '![Step Two in k-means - moving centroids via average distance](assets/pdss_0704.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![k-means 中的第二步 - 通过平均距离移动质心](assets/pdss_0704.png)'
- en: Figure 7-4\. Step 2 in k-means—moving centroids via average distance
  id: totrans-62
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-4\. k-means 第2步 — 通过平均距离移动质心
- en: '![Step Three in k-means - continuing to move centroids via average distance](assets/pdss_0705.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![k-means 中的第三步 - 继续通过平均距离移动质心](assets/pdss_0705.png)'
- en: Figure 7-5\. Step 3 in k-means—continuing to move centroids via average distance
  id: totrans-64
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-5\. k-means 第3步 — 继续通过平均距离移动质心
- en: '![Final position in k-means - centroid average distance convergence](assets/pdss_0706.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![k-means 中的最终位置 - 质心平均距离收敛](assets/pdss_0706.png)'
- en: Figure 7-6\. Final position in k-means - centroid average distance convergence
  id: totrans-66
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-6\. k-means 的最终位置 - 质心平均距离收敛
- en: k-Medoid
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: k-Medoid
- en: '*k*-medoid is a data partitioning algorithm like *k*-means, except where *k*-means
    minimizes the total squared error of centroid distance *k*-medoid minimizes the
    sum of the dissimilarities. This can make it more robust to noise and outliers
    when compared to *k*-means. The most common implementation of *k*-m is the PAM
    algorithm. The steps would look similar to the ones shown above for *k*-means.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*k*-medoid 是一种数据分区算法，类似于 *k*-means，不同之处在于 *k*-means 最小化质心距离的总平方误差，而 *k*-medoid
    最小化不相似性的总和。这使得它在处理噪声和离群值时比 *k*-means 更为健壮。*k*-m 的最常见实现是 PAM 算法。其步骤与上述 *k*-means
    的步骤类似。'
- en: Tip
  id: totrans-69
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Simply put, *k*-means uses the mean and *k*-m uses the median.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 简单地说，*k*-means 使用平均值，而 *k*-medoid 使用中位数。
- en: Hierarchical Clustering
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分层聚类
- en: 'Hierarchical clustering uses a technique to build a hierarchy from the ground
    up. It does not require the number of clusters to be specified beforehand. There
    are two types of hierarchical clustering: agglomerative and divisive. We introduced
    these concepts in [Chapter 2](ch02.html#ch02). To quickly recap, agglomerative
    clustering works by first putting each point into its own cluster. For our example,
    every customer would be a cluster. Then it identifies the closest two clusters
    and combines them into one. It repeats this process until every data point is
    in one cluster. Divisive clustering works in reverse. All of our customers are
    put into a cluster. That cluster is split recursively until all the customers
    are in their own individual cluster.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 分层聚类使用一种从下至上构建层次结构的技术。它不需要预先指定簇的数量。分层聚类有两种类型：凝聚式和分裂式。我们在 [第2章](ch02.html#ch02)
    中介绍了这些概念。简要回顾一下，凝聚式聚类首先将每个点放入自己的簇中。在我们的示例中，每个客户将是一个簇。然后它标识最接近的两个簇并将它们合并成一个。它重复此过程直到每个数据点都在一个簇中。分裂式聚类则相反。我们所有的客户都放入一个簇中。该簇递归地分裂，直到所有客户都在各自的单独簇中。
- en: 'There are different linkage types that can be used to determine the pairing
    of the data points into clusters. The two most common are complete and mean:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 有不同的连接类型可用于确定数据点配对成簇的方式。最常见的两种是完全连接和平均连接：
- en: Complete linkage
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 完全连接
- en: Finds the maximum possible distance between two points belonging to two clusters.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 找到属于两个不同簇的两点之间的最大可能距离。
- en: Mean linkage
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 平均连接
- en: Finds all possible pairwise distances for points belonging to two different
    clusters and then takes the mean.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 找到属于两个不同簇的点的所有可能成对距离，然后取平均值。
- en: These cluster regions become wider and more discernible as the categories move
    upward as shown in [Figure 7-7](#cluster_dendrogramdot_the_colored_bars_o). Diagrams
    of hierarchical clustering are referred to as *dendrograms.*
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 随着类别向上移动，这些聚类区域变得更宽更可辨，如 [图 7-7](#cluster_dendrogramdot_the_colored_bars_o)
    所示。分层聚类的图称为 *树状图*。
- en: '![Cluster Dendrogram. The colored bars on the y-axis represent the levels of
    clustering.](assets/pdss_0707.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![聚类树状图。y 轴上的彩色条代表聚类的层级。](assets/pdss_0707.png)'
- en: Figure 7-7\. Cluster dendrogram (the colored bars on the y-axis represent the
    levels of clustering)
  id: totrans-80
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-7\. 聚类树状图（y 轴上的彩色条代表聚类的层级）
- en: Time-Series Clustering
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 时间序列聚类
- en: Time-series clustering is not something we are going to do with our customer
    segmentation, as it requires much more computational power and data than regular
    clustering. However, it is a fascinating type of clustering and something we want
    to mention. Time-series clustering creates clusters from the data based on their
    behavior over time. For instance, considering our scenario, we may have customers
    that exhibit a particular behavior right before going inactive. They had a high
    frequency of purchases in the past, slowed gradually, and the monetary value decreased.
    Perhaps we have additional data and we can see that these customers had an increased
    number of returns (and therefore frustration). By clustering this pattern over
    time we can see when a current customer, exhibiting the same pattern and belonging
    to the same cluster, has not yet gone inactive. Marketing, in particular, would
    be interested in knowing about these customers to prevent churn.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列聚类不是我们进行客户分割的方法之一，因为它需要比常规聚类更多的计算能力和数据。然而，它是一种引人入胜的聚类类型，我们想提一下。时间序列聚类根据数据随时间变化的行为创建聚类。例如，考虑我们的情景，我们可能有一些客户在不活跃之前表现出特定的行为。他们过去的购买频率高，逐渐减少，货币价值也减少。也许我们有额外的数据，我们可以看到这些客户退货增加（因此感到沮丧）。通过对时间上的这种模式进行聚类，我们可以看到当前的客户，表现出相同的模式并属于同一聚类，尚未变得不活跃。特别是市场营销部门对了解这些客户以防止流失非常感兴趣。
- en: Tip
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: There is a very robust and wonderful R package [*TSclust*](http://www.jstatsoft.org/v62/i01/paper)
    made specifically for time-series clustering. Time-series hierarchical clustering
    is not only useful—it’s also a lot of fun.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个非常强大和出色的R包[*TSclust*](http://www.jstatsoft.org/v62/i01/paper)专门用于时间序列聚类。时间序列的层次聚类不仅有用，而且非常有趣。
- en: 'Step 1: Collecting the Data'
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1步：收集数据
- en: We have explored a number of ways to extract data from SAP. This time we are
    going to use a Core Data Service (CDS) view. In [Chapter 3](ch03.html#ch03) we
    detail the process for defining a CDS view for sales data. That is the exact CDS
    view we will use here, so make sure to brush up on [Chapter 3](ch03.html#ch03)!
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经探索了多种从SAP中提取数据的方式。这次我们将使用核心数据服务（CDS）视图。在[第3章](ch03.html#ch03)中，我们详细介绍了为销售数据定义CDS视图的过程。这正是我们将在这里使用的确切CDS视图，所以确保熟悉[第3章](ch03.html#ch03)！
- en: 'Step 2: Cleaning the Data'
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2步：清理数据
- en: 'Once we have downloaded the data from SAP, we need to clean it. We have done
    this so far for every chapter, and you may recall in the introduction that SAP
    data is clean! Here’s some perspective: if you are a data scientist, you will
    agree that this data is as clean as it gets. Data scientists are often dealing
    with wildly unclean data. For instance, data we recently worked with from the
    [FDA’s Orange Book](http://bit.ly/2lSCKZm) has a particularly interesting “therapeutic
    class” column. These classes can be of multiple categories. If there is more than
    one class it is just added to the field. You never know how many classes of which
    group are going to be in that one field. There may be one class, there may be
    a dozen. To get the data out of this column you have to split it, stack it, shape
    it, do some regular expression (regex) work on it, and then it still isn’t quite
    there. We use this as an example of what a dirty column might look like, and this
    is not a very complex example of the daily toils of cleaning data. From that perspective,
    SAP’s data is sparkling clean.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们从SAP下载了数据，我们就需要清理它。到目前为止，我们已经为每一章节做到了这一点，你可能还记得在介绍中提到过SAP的数据是干净的！这里有一些看法：如果你是一名数据科学家，你会同意这份数据非常干净。数据科学家经常处理非常不干净的数据。例如，我们最近使用的来自[FDA的橙皮书](http://bit.ly/2lSCKZm)的数据有一个特别有趣的“治疗类别”栏目。这些类别可以有多个类别。如果有多个类别，它们会被添加到字段中。你永远不知道一个字段中会有多少类别，有时可能是一个类别，有时可能是十几个类别。要从这一列中获取数据，你需要拆分、堆叠、整理一些正则表达式（regex）工作，但还不够。我们用这个作为一个例子，展示一个脏列看起来会是什么样子，这并不是每天清理数据的复杂例子。从这个角度来看，SAP的数据确实是闪闪发光的。
- en: 'Nonetheless, our sparkling data still needs a little shine. First let’s load
    the libraries that we are going to need for our next steps:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，我们闪闪发光的数据仍然需要一些光泽。首先让我们加载我们接下来需要用到的库：
- en: '[PRE0]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The [`httr` library in R](http://bit.ly/2k0DsTW) makes it easy to extract data
    directly from our CDS view. The first step is to identify the URL (refer back
    to [“Core Data Services”](ch03.html#core_data_services) for a refresher on this).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[`R 中的 httr 库`](http://bit.ly/2k0DsTW) 使直接从我们的 CDS 视图中提取数据变得容易。第一步是识别 URL（请参考
    [“Core Data Services”](ch03.html#core_data_services) 进行复习）。'
- en: '[PRE1]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The next step is to simply call the service and authenticate with your SAP
    credentials:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步很简单，只需调用服务并使用您的 SAP 凭证进行身份验证：
- en: '[PRE2]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The `r` object is a *response* object. It contains details on the HTTP response
    including the content. Access the content with the following command:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '`r` 对象是一个 *response* 对象。它包含有关 HTTP 响应的详细信息，包括内容。使用以下命令访问内容：'
- en: '[PRE3]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The `customers` object is a large list. We need to get that into a friendlier
    format before we move on. First we will extract the results of the list in this
    way:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '`customers` 对象是一个大列表。在我们继续之前，我们需要将其转换为更友好的格式。首先，我们将以这种方式提取列表的结果：'
- en: '[PRE4]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We still have a list, but it is only a list of the results of our call and
    not the HTTP details. We can turn that list into a dataframe using a [`do.call`
    command](http://bit.ly/2lxahIr) and binding all the rows of the list together:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仍然有一个列表，但它只是我们调用的结果列表，不包括 HTTP 的详细信息。我们可以使用 [`do.call` 命令](http://bit.ly/2lxahIr)
    将该列表转换为数据框架，并将所有行绑定在一起：
- en: '[PRE5]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Tip
  id: totrans-101
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Take some time to get to know [`do.call`](https://www.rdocumentation.org/packages/base/versions/3.6.0/topics/do.call).
    This simple and unassuming command will become a well-used tool in your data scientist’s
    toolbox.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 花点时间了解 [`do.call`](https://www.rdocumentation.org/packages/base/versions/3.6.0/topics/do.call)。这个简单而不起眼的命令将成为您数据科学家工具箱中的一个常用工具。
- en: 'Finally, we convert our object into a dataframe:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将我们的对象转换为数据框架：
- en: '[PRE6]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let’s take a look at it. This time instead of using the messy `head` function
    by itself, we will leverage the [`DT` library](https://rstudio.github.io/DT/).
    Here’s the command we’ll need to run (the results are shown in [Figure 7-8](#datatables_viewdot_datatables_are_a_nice)):'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看它。这一次，我们不再单独使用混乱的 `head` 函数，而是利用 [`DT` 库](https://rstudio.github.io/DT/)。以下是我们需要运行的命令（结果显示在
    [图 7-8](#datatables_viewdot_datatables_are_a_nice) 中）：
- en: '[PRE7]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![Datatables view. Datatables are a nicely formatted and sortable dataframe
    from the DT library.](assets/pdss_0708.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![Datatables 视图。Datatables 是来自 DT 库的格式化良好且可排序的数据框架。](assets/pdss_0708.png)'
- en: Figure 7-8\. Datatables view (datatables are a nicely formatted and sortable
    dataframe from the DT library)
  id: totrans-108
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-8\. Datatables 视图（datatables 是来自 DT 库的格式化良好且可排序的数据框架）
- en: 'As we have done a few times already, there are some quick and easy cleanups
    to do—get rid of a couple extra columns, some whitespace, and a few columns that
    we don’t want. We also drop the __metadata, CreateTime, CustomerMaterial, ItemCategory,
    DocumentType, and DocumentCategory columns as they are not needed for our analysis:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们已经做过几次一样，还有一些快速简单的清理工作要做 —— 摆脱一些额外的列、一些空白和一些我们不需要的列。我们还会删除 __metadata、CreateTime、CustomerMaterial、ItemCategory、DocumentType
    和 DocumentCategory 列，因为它们对我们的分析没有必要：
- en: '[PRE8]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We notice that the date comes over in Unix format. We will fix this the same
    way we fixed it in [Chapter 6](ch06.html#predictive_analytics_in_r_and_python):'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到日期以 Unix 格式传输。我们将以与我们在 [第 6 章](ch06.html#predictive_analytics_in_r_and_python)
    中修复的方式修复它：
- en: '[PRE9]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We also noticed when previewing our data that some units of measure (UoM) were
    blank. Units of measure are an important and complex master data concept in SAP.
    If our transactional data is missing the UoM, this indicates we do not know the
    actual quantity. For example, if we have a quantity of 10 but no UoM do we have
    10 each or 10 boxes of 12 each? In the event the UoM is missing, we should exclude
    those entries:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在预览数据时还注意到一些计量单位（UoM）为空白。计量单位是 SAP 中重要且复杂的主数据概念。如果我们的交易数据缺少 UoM，这表明我们不知道实际数量。例如，如果我们有
    10 个数量但没有 UoM，那么我们是有 10 个每个还是 10 个箱子，每个箱子里有 12 个？如果缺少 UoM，则应排除这些条目：
- en: '[PRE10]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let’s also make sure that the fields are appropriately typed: dates are dates,
    integers are integers, and so on. We will also clear up whitespace that appears
    in some of the columns:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也确保字段类型适当：日期是日期，整数是整数，等等。我们还将清除出现在某些列中的空白：
- en: '[PRE11]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now we have a dataframe of customers and their sales. Let’s think for a moment
    about our mission. We want to identify characteristics per *customer*, so our
    dataframe should have unique rows per customer. Currently, we have all sales for
    each customer. Our key therefore is not *customer;* it is *order*. Let’s change
    that and create a dataframe of RFM values for each customer as the basis for all
    other analysis.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个客户及其销售数据的数据框。让我们思考一下我们的任务。我们想要识别每位*客户*的特征，因此我们的数据框应该对每位客户有唯一的行。目前，我们拥有每位客户的所有销售数据。因此，我们的关键不是*客户*；而是*订单*。让我们更改这一点，并创建一个以每位客户的RFM值为基础的数据框，作为所有其他分析的依据。
- en: 'First we will work on recency. To do this, create a new entry in the dataframe
    that indicates the number of days since the sale:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将处理最近性。为此，在数据框中创建一个新条目，表示自销售以来的天数：
- en: '[PRE12]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Remember that important statistical paper titled [“The Split-Apply-Combine
    Strategy for Data Analysis”](http://bit.ly/2lvfPTO) referenced in [Chapter 6](ch06.html#predictive_analytics_in_r_and_python)?
    We will use those same techniques here. We want a dataframe of the most recent
    purchase by customers. We do this using the aggregate function and taking the
    minimum value. We are *splitting* data off of our main dataframe by aggregating
    it and *applying* the minimum function to it:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 记得那篇重要的统计论文，题为[“数据分析的分割-应用-组合策略”](http://bit.ly/2lvfPTO)，在[第 6 章](ch06.html#predictive_analytics_in_r_and_python)中引用过吗？我们将在这里使用相同的技术。我们想要一个客户的最近购买数据框。我们使用聚合函数并取最小值来实现这一点。我们正在*分割*主数据框以聚合它，并*应用*最小函数：
- en: '[PRE13]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In true *combine* fashion we put them back together again, which will create
    a column of the most recent purchase by customer:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 以真正的*组合*方式将它们重新放在一起，这将创建一个按客户最近购买排序的列：
- en: '[PRE14]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Next we will work on frequency, following the same theory as we did for recency.
    Create a dataframe for the count of orders by customer by aggregating the data
    by sales document and customer. The way you count in R is by asking “what is the
    length?” Because we have multiple lines on an individual order and we want to
    count orders not lines we say, “what is the *unique* length?” or “how many lines
    are on the order?”
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将处理频率，按照与我们对最近性的处理相同的理论进行。创建一个通过按销售文档和客户聚合数据来计算订单数量的数据框。在R中进行计数是通过问“长度是多少？”来进行的。因为我们在单个订单上有多行，并且我们想要计算订单而不是行数，所以我们说“唯一长度是多少？”或者“订单上有多少行？”
- en: '[PRE15]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Again, add the newly split dataframe back into the original to leave a column
    of order count assigned to the customer:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 再次将新分割的数据框添加回原始数据，以留下分配给客户的订单计数列：
- en: '[PRE16]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Finally, we will deal with the monetary value of a customer. We have in our
    dataframe columns for price and quantity. Multiply these together to get the value
    per line:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将处理客户的货币价值。在我们的数据框中，有价格和数量的列。将它们相乘以获得每行的价值：
- en: '[PRE17]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Again, in true *Split-Apply-Combine* fashion, aggregate the values of all lines
    per customer:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 再次以真正的*分割-应用-组合*方式，对每位客户的所有行进行聚合：
- en: '[PRE18]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Repeat the process to merge the newly split dataframe back to the original.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 重复此过程，将新分割的数据框合并回原始数据。
- en: '[PRE19]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Tip
  id: totrans-134
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: 'All those split-off dataframes are no longer of use. To keep your workspace
    clean and free up some memory, remove them with this simple command:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些分割出来的数据框现在已经没有用了。为了保持工作区的整洁并释放一些内存，使用这个简单的命令将它们删除：
- en: '[PRE20]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'A little cleanup of our main dataframe is in order after all that splitting
    and combining. We want to make sure that each row is unique. There should be no
    duplicate rows when comparing all fields. After all, no order number and line
    number should be the same for multiple rows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些分割和组合之后，我们需要清理一下主数据框。我们要确保每一行都是唯一的。当比较所有字段时，不应该有重复的行。毕竟，没有订单号和行号应该是多行相同的：
- en: '[PRE21]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We also want to ensure that there are no customer values that are blank. We
    are identifying customers and their RFM values so obviously a blank customer is
    of no use. There should be none, but it is good practice to double-check this:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还要确保没有空白的客户值。我们正在识别客户及其RFM值，所以显然空白的客户没有用处。不应该有空白值，但是双重检查是个好习惯：
- en: '[PRE22]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'What we want is a dataframe of our four key values: `customer number`, `most_recent_order_days`,
    `count_total_orders`, and `total_purchase_value`. View the column names and position
    with the `colnames` function.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要的是一个包含四个关键值的数据框：`customer number`、`most_recent_order_days`、`count_total_orders`
    和 `total_purchase_value`。使用 `colnames` 函数查看列名和位置。
- en: '[PRE23]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We want only the columns 1, 15, 16, and 18\. All the other columns are no longer
    necessary, they were just needed to create the RFM values. We want a dataframe
    of these RFM values by customer only. This is simple, as we just slice off all
    other columns:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只想要第1、15、16和18列。其他列现在不再需要，它们只是用来创建RFM值。我们只需按客户切片得到这些RFM值的数据框即可：
- en: '[PRE24]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Now when we look at the dataframe we see just the columns we want. However,
    we also notice at this point that we have duplicate rows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 现在当我们查看数据框时，我们只看到了我们想要的列。但是，在这一点上我们也注意到我们有重复的行：
- en: '[PRE25]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Remove the duplicate rows with the `!duplicated` command:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`!duplicated`命令删除重复的行：
- en: '[PRE26]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: How in the world are we going to rank them the way we need them? This seems
    like a big task. Not with R! We simply create a new dataframe from `customer`.
    Make a column titled `R` that is a mutation of `most_recent_order_days`. The mutation
    is to create a percentage ranking based on 5\. That is, put the top 20% in 5,
    the next 20% in 4, and so on. Repeat this process for `count_total_orders` and
    `total_purchase_value`.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 如何才能按我们需要的方式对它们进行排名呢？这看起来像是一项艰巨的任务。不过，用R的话就简单了！我们只需从`customer`创建一个新的数据框。创建一个名为`R`的列，这是基于`most_recent_order_days`的变化值。该变化是基于5来创建百分比排名。也就是说，把前20%放在5中，接下来的20%放在4中，依此类推。对`count_total_orders`和`total_purchase_value`重复此过程。
- en: '[PRE27]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now that we have our R, F, and M values, we can turn the column for customer
    into an index and clean up our workspace:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了R、F和M值，我们可以把客户列转换为索引并清理我们的工作空间：
- en: '[PRE28]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Ever worked with someone who complained they lost all their work because their
    computer crashed? “I was working on that for four hours and now it’s lost!” Well,
    that can happen to us too, so let’s create a little output that can be read in
    easily if we want to pick up from this point:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 曾经有人抱怨他们因为电脑崩溃而丢失了所有工作吗？“我已经在那上面工作了四个小时，现在全都丢了！”嗯，我们也可能遇到这种情况，所以让我们创建一个可以轻松读取的小输出，如果需要从这一点继续工作：
- en: '[PRE29]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Step 3: Analyzing the Data'
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三步：分析数据
- en: 'After those simple steps the data is ready to analyze. We have six different
    techniques we are going to employ in analysis. It is redundant, but illustrative
    of the different ways you can analyze data. These methods are:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 经过这些简单的步骤，数据就准备好分析了。我们将使用六种不同的技术进行分析。这可能有些多余，但可以说明数据分析的不同方式。这些方法包括：
- en: Pareto principle
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 帕累托原理
- en: '*k*-means clustering'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*k*-means聚类'
- en: '*k*-medoid clustering'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*k*-medoid聚类'
- en: Hierarchical clustering
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分层聚类
- en: Manual clustering
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手动聚类
- en: Revisiting the Pareto Principle
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重新审视帕累托原理
- en: 'Remember the Pareto principle suggests that 80% of our sales is dictated by
    20% of our customers. How close is our data to that principle? For that matter,
    how would we tell which customers contribute to 80% of the sales? Let’s break
    the concept into small components:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 记住帕累托原理表明我们销售额的80%由我们客户的20%决定。我们的数据离这个原理有多接近？事实上，我们如何确定哪些客户贡献了80%的销售额？让我们把这个概念分解成小组件：
- en: Calculate what the cutoff is for 80% of the sales.
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算销售额80%的截止点是多少。
- en: Order our dataframe from largest monetary value to smallest.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按最大货币值到最小货币值对数据框进行排序。
- en: Create a column that has the cumulative sum of the monetary value. That is,
    it will add row by row.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个列，其值为货币价值的累计和。也就是说，它会逐行相加。
- en: Label each customer as “Top 20” if the cumulative sum is less than the cutoff
    and “Bottom 80” if it is greater than the cutoff.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果累计总和小于截止点，则将每个客户标记为“前20”，如果大于截止点，则标记为“后80”。
- en: Calculate the percentage of customers in each group.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算每个组中客户的百分比。
- en: Interpret the findings.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释研究结果。
- en: 'Calculating 80% of the sales is simple:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 计算销售额的80%非常简单：
- en: '[PRE30]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Then we sort the dataframe from largest to smallest monetary value:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将数据框按最大到最小的货币值排序：
- en: '[PRE31]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Add a column to the dataframe that is the rolling sum of the monetary values:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 添加一个列到数据框中，该列是货币值的滚动总和：
- en: '[PRE32]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Label the customers before and after the cutoff:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在截止点之前和之后标记客户：
- en: '[PRE33]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Calculate the percentages using [`prop.table`](http://bit.ly/2ksaXhY).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[`prop.table`](http://bit.ly/2ksaXhY)计算百分比。
- en: '[PRE34]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'By our calculations, roughly the top 6% of the customers contribute to 80%
    of the sales. This sounds quite far off of the Pareto principle until you consider
    that Big Bonanza Warehouse has a lot of customers. However, they also have distributors
    and resellers. It is the distributors and the resellers that are driving the vast
    majority of the sales. At first glance, this feature in the data may not seem
    very useful. Until you think about it. Big Bonanza Warehouse has stores and distribution
    centers all over the United States. Distributors and resellers get their product
    from distribution centers and not the stores. If it comes to making a decision
    whether to close a distribution center or a store, the choice is clear: close
    the store.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的计算，大约前 6% 的客户贡献了 80% 的销售额。这听起来与帕累托原理相差甚远，直到考虑到大宝狂购物广场有很多客户。然而，他们也有分销商和经销商。正是这些分销商和经销商驱动了绝大部分的销售。乍一看，数据中的这个特征似乎不是很有用。直到你仔细思考。大宝狂购物广场在美国各地都有商店和分销中心。分销商和经销商从分销中心而非商店获取产品。如果必须做出关闭分销中心或商店的决定，选择显而易见：关闭商店。
- en: Finding Optimal Clusters
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 寻找最佳聚类
- en: 'For *k*-means and *k*-medoid clustering we need to manually choose the optimal
    number of clusters. This process is as much an art as it is a science. However,
    there are some tools we can employ to choose the optimal number of clusters. The
    R library [`factoextra`](http://bit.ly/2lzUTuM) has a method `fviz_nbclust` that
    will help to find and visualize the optimal cluster number. We want to do this
    before we start our *k*-means and *k*-medoid clustering. There are three possible
    options in this method:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 *k*-means 和 *k*-medoid 聚类，我们需要手动选择最佳的聚类数。这个过程既是艺术也是科学。然而，有一些工具可以帮助我们选择最佳的聚类数。R
    库 [`factoextra`](http://bit.ly/2lzUTuM) 提供了一个名为 `fviz_nbclust` 的方法，可以帮助找到并可视化最佳的聚类数。在我们开始
    *k*-means 和 *k*-medoid 聚类之前，我们希望进行这个步骤。在这种方法中，有三个可能的选项：
- en: Elbow method
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 肘部法
- en: Minimizes the within-cluster sum of squares (wss). The total of the wss measures
    how compact a cluster is. Theoretically, this should be as small as possible.
    It is referred to as the Elbow method because the chart has an elbow in it where
    increasing the number of clusters no longer contributes much to minimizing the
    wss.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 最小化聚类内平方和（wss）。wss 的总和衡量了聚类的紧凑程度。理论上，这应该尽可能小。它被称为“肘部法”，因为图表中有一个肘部，在这里增加聚类数不再对最小化
    wss 有太大的贡献。
- en: Average Silhouette method
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 平均轮廓方法
- en: Measures how well each point falls within a cluster. A high value indicates
    good clustering. It performs this by measuring the average distance between the
    clusters.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 评估每个点落入聚类的情况。较高的值表示良好的聚类效果。它通过测量聚类之间的平均距离来实现这一点。
- en: Gap Statistic method
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 间隙统计方法
- en: Measures the total within intra-cluster variation. The gap statistic is optimal
    when it is maximized and further clusters do not contribute much if any to the
    value.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 评估总的聚类内变异。当间隙统计量被最大化时，进一步的聚类不会对值有太大的贡献。
- en: 'We will use each of these methods and then decide which one or combination
    to use. Our dataframe has over a quarter million rows, which is too much for these
    statistical methods. We can deal with this by taking a representative sample of
    the data with enough points to ensure a similar distribution. Because we want
    reproducibility in our sampling, we need to set a seed. Otherwise, every time
    this step is run the randomness could lead to slightly different results. We also
    only want the RFM values for which we are clustering:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用每一种方法，然后决定使用哪一种或哪些方法的组合。我们的数据框架有超过 25 万行数据，对于这些统计方法来说太多了。我们可以通过取足够数量的数据的代表性样本来处理这个问题，以确保分布类似。因为我们希望在采样中具有可重现性，所以我们需要设置一个种子。否则，每次运行此步骤时，随机性可能导致稍有不同的结果。我们也只希望对我们正在聚类的
    RFM 值进行分析：
- en: '[PRE35]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'These clustering algorithms run better when the data is normalized. We will
    log transform the data for each of our features:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这些聚类算法在数据被归一化后运行效果更好。我们将对每个特征进行对数转换：
- en: '[PRE36]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Now we use `fviz_nbclust` to optimize and visualize our different methods.
    The first will be the Elbow method shown in [Figure 7-9](#optimal_number_of_clusters_for_elbow_met):'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们使用 `fviz_nbclust` 来优化和可视化我们的不同方法。首先将展示肘部法的图示（显示在 [Figure 7-9](#optimal_number_of_clusters_for_elbow_met)
    中）。
- en: '[PRE37]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Second is the visualization of the optimal number of clusters using the Silhouette
    method (the results are shown in [Figure 7-10](#optimal_number_of_clusters_for_the_silho)):'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 其次是使用轮廓方法可视化最佳聚类数（结果显示在 [Figure 7-10](#optimal_number_of_clusters_for_the_silho)
    中）：
- en: '[PRE38]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '![Optimal Number of clusters for Elbow method.](assets/pdss_0709.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![Elbow方法的最佳聚类数。](assets/pdss_0709.png)'
- en: Figure 7-9\. Optimal number of clusters for Elbow method
  id: totrans-198
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-9\. Elbow方法的最佳聚类数
- en: '![Optimal Number of clusters for the Silhouette method.](assets/pdss_0710.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![Elbow方法的最佳聚类数。](assets/pdss_0710.png)'
- en: Figure 7-10\. Optimal number of clusters for the Silhouette method
  id: totrans-200
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-10\. Silhouette方法的最佳聚类数
- en: 'Finally, we will use the Gap Statistic method (the results are shown in [Figure 7-11](#optimal_number_of_clusters_using_the_gap)):'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将使用间隔统计法（结果显示在[图7-11](#optimal_number_of_clusters_using_the_gap)中）：
- en: '[PRE39]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '![Optimal Number of clusters using the Gap-Stat method.](assets/pdss_0711.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![使用间隔统计法确定的最佳聚类数。](assets/pdss_0711.png)'
- en: Figure 7-11\. Optimal number of clusters using the Gap Statistic method
  id: totrans-204
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-11\. 使用间隔统计法确定的最佳聚类数
- en: Each method had different results. The Elbow method left a chart that did not
    have a distinct “elbow” in it. When we look at it, it seems the elbow could be
    at point 5, 6, or 7\. The silhouette method distinctly shows the average distance
    between the clusters peaking at 3\. The Gap Statistic method also clearly shows
    the optimal number to be at 5\. We know our data and we feel comfortable with
    five clusters. Three we feel is too small. Five clusters would be in agreement
    with two of the three methods we have charted.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 每种方法都有不同的结果。Elbow方法的图表没有明显的“拐点”。当我们看它时，看起来拐点可能在5、6或7点。轮廓方法清楚地显示出聚类之间的平均距离在3点处达到峰值。间隔统计法也清楚地显示出最佳聚类数为5。我们了解我们的数据，我们对五个聚类感到满意。我们觉得三个聚类太小了。五个聚类将与我们绘制的三种方法中的两种达成一致。
- en: k-Means Clustering
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: K均值聚类
- en: 'Once the data is formatted and the number of clusters is identified, executing
    *k*-means is easy. The first step is to set the number of clusters:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据格式化并确定了聚类数，执行*k*-means就很容易。第一步是设置聚类数目：
- en: '[PRE40]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Then we create a dataframe of our original values (not the RFM values, but
    the actual values from the customer):'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们创建一个包含我们原始值的数据框（不是RFM值，而是来自客户的实际值）：
- en: '[PRE41]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Because we do not have a normal distribution we want to normalize these values.
    If we do not, the charting we do will be squashed and not be very legible. There
    are many different methods for normalizing data (previously we’ve used min-max
    scaling). In this example, we will use a [log transformation](http://bit.ly/2lxpPMj):'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们的数据不服从正态分布，所以我们希望对这些值进行标准化。如果不进行标准化，我们做的图表会被压缩，不够清晰。有许多不同的方法可以用来标准化数据（先前我们使用了最小-最大缩放）。在这个例子中，我们将使用[对数变换](http://bit.ly/2lxpPMj)：
- en: '[PRE42]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Now we simply use the [`k-means`](http://bit.ly/2lszdkl) method. We put in
    the dataframe we created, the number of clusters, and the number of times the
    process should run. By default, `k-means` initializes its starting point (or initial
    position) randomly. Because of this, there are occasions when it starts so poorly
    it fails to cluster well. There is a simple way to overcome this. Simply run `k-means`
    numerous times. It’s extremely unlikely to start poorly every time. The `nstart`
    parameter can be used to specify the number of run times:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们简单地使用[`k-means`](http://bit.ly/2lszdkl)方法。我们输入我们创建的数据框、聚类数以及应该运行该过程的次数。默认情况下，`k-means`随机初始化其起始点（或初始位置）。因此，有时它的开始可能不佳，无法很好地进行聚类。有一种简单的方法可以克服这一问题。只需多次运行`k-means`。每次都开始得很糟糕是极不可能的。可以使用`nstart`参数来指定运行次数：
- en: '[PRE43]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '`km` is a structure with clusters and other attributes related to clustering
    as is shown in [Figure 7-12](#large_kmeans_structure). For our purposes, we are
    only interested in the cluster attribute.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '`km`是一个带有聚类和其他与聚类相关的属性的结构，如[图7-12](#large_kmeans_structure)所示。对于我们的目的，我们只对聚类属性感兴趣。'
- en: '![Large KMeans structure.](assets/pdss_0712.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![大型K均值结构。](assets/pdss_0712.png)'
- en: Figure 7-12\. Large k-means structure
  id: totrans-217
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-12\. 大型K均值结构
- en: 'We want to create a new dataframe with our customer details and the clusters
    from `km`. The clusters need to be factors:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望创建一个包含客户详细信息和来自`km`的聚类的新数据框。这些聚类需要是因子：
- en: '[PRE44]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Now we are ready to chart. Our first chart will be a simple `ggplot` of the
    monetary value and recency (the result is shown in [Figure 7-13](#kmeans_clustering_of_customer_data_by_re)):'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备绘制图表。我们的第一张图将是货币价值和最近性的简单`ggplot`图（结果显示在[图7-13](#kmeans_clustering_of_customer_data_by_re)中）：
- en: '[PRE45]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '![KMeans clustering of customer data by recency and monetary value.](assets/pdss_0713.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![顾客数据按最近性和货币价值进行的K均值聚类。](assets/pdss_0713.png)'
- en: Figure 7-13\. k-means clustering of customer data by recency and monetary value
  id: totrans-223
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-13\. 按最近性和货币价值对客户数据进行的K均值聚类
- en: 'This is not a very satisfying representation of our clusters. While we can
    see the values of recency and monetary value clearly clustered by color, we do
    not see how they relate to frequency. What if we try a change to this and plot
    recency by frequency and then size the points by order value. We will apply an
    alpha to the points because there are so many of them and this allows us to see
    when they are blending together (the results are shown in [Figure 7-14](#kmeans_clustering_of_customer_data_by)):'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是对我们群集的一个很令人满意的表示。虽然我们可以看到按颜色清晰聚集的最近性和货币价值的值，但我们看不到它们与频率的关系。如果我们尝试更改此图表，绘制最近性和频率，然后按订单值大小调整点的大小，我们将对点应用
    alpha 值，因为它们太多了，这样可以让我们看到它们何时混合在一起（结果显示在 [图 7-14](#kmeans_clustering_of_customer_data_by)
    中）：
- en: '[PRE46]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '![KMeans clustering of customer data by recency, frequency and monetary value.](assets/pdss_0714.png)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![按最近性、频率和货币价值的客户数据 k-means 聚类](assets/pdss_0714.png)'
- en: Figure 7-14\. k-means clustering of customer data by recency, frequency, and
    monetary value
  id: totrans-227
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-14\. 客户数据的按最近性、频率和货币价值 k-means 聚类
- en: 'Again, not very satisfying. When we chart more than two variables on a two-dimensional
    plane the results can be rather disappointing. Fortunately in R there are ways
    to create three-dimensional plots. We will use the [`car`](http://bit.ly/2kg2ChA)
    and the `rgl` libraries to do this (the results are shown in [Figure 7-15](#kmeans_clustering_of_customer_data_in_th)):'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，这并不是非常令人满意。当我们在二维平面上绘制超过两个变量时，结果可能令人失望。幸运的是，在 R 中有方法创建三维图表。我们将使用 [`car`](http://bit.ly/2kg2ChA)
    和 `rgl` 库来实现这一点（结果显示在 [图 7-15](#kmeans_clustering_of_customer_data_in_th) 中）：
- en: '[PRE47]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Note
  id: totrans-230
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'You may need to change the recency values from a difftime attribute to numeric.
    To do this execute the following command:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能需要将 `difftime` 属性的最近值更改为数值。要执行此操作，请执行以下命令：
- en: '[PRE48]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '![KMeans clustering of customer data in three dimensions.](assets/pdss_0715.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![客户数据的三维 k-means 聚类](assets/pdss_0715.png)'
- en: Figure 7-15\. k-means clustering of customer data in three dimensions
  id: totrans-234
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-15\. 客户数据的三维 k-means 聚类
- en: This is a much more satisfying representation of our clusters in *k*-means and
    gives us a good idea of how our customers group into five clusters. You can see
    one group of clusters in the upper right that represents our most recent, most
    frequent, and highest monetary valued customers. Likewise, in the lower left of
    the chart we see the least frequent, least recent, and least monetary valued.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对我们在 *k*-means 中群集的一个更令人满意的表示，并且给我们一个关于我们的客户如何分成五个群集的好主意。您可以看到图表的右上角有一组群集，代表我们最近、最频繁和最高货币价值的客户。同样，在图表的左下角，我们看到最不频繁、最不新鲜和最低货币价值的群集。
- en: Next, we will use *k*-medoid to get a different view of these clusters.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用 *k*-medoid 来以不同视角查看这些群集。
- en: k-Medoid Clustering
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: k-Medoid 聚类
- en: '*k*-medoid is similar to *k*-means except that *k*-means uses the mean distance
    to create clusters, while *k*-medoid uses the median. This makes *k*-medoid less
    sensitive to noise and outliers. As we discussed earlier, the most common *k*-medoid
    clustering method is the PAM algorithm.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '*k*-medoid 与 *k*-means 类似，但 *k*-means 使用平均距离创建群集，而 *k*-medoid 使用中位数。这使得 *k*-medoid
    对噪声和异常值不太敏感。正如我们前面讨论的那样，最常见的 *k*-medoid 聚类方法是 PAM 算法。'
- en: 'From our work on *k*-means we have a dataframe titled `cust` with a scaled
    (log) value of `most_recent_order_days`, `count_total_orders`, and `total_purchase_value`.
    This is also the format needed for PAM. The `pam` function itself is limited to
    65,536 observations so sampling is needed first (we’ve already done this when
    estimating the number of clusters):'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们对 *k*-means 的工作中，我们有一个名为 `cust` 的数据框，其中包含 `most_recent_order_days`、`count_total_orders`
    和 `total_purchase_value` 的标度化（对数）值。这也是 PAM 所需的格式。`pam` 函数本身限制为 65,536 条观测值，因此首先需要进行抽样（在估算群集数量时我们已经完成了这一步）：
- en: '[PRE49]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Execute the PAM clustering algorithm with the following command:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令执行 PAM 聚类算法：
- en: '[PRE50]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The PAM object consists of the components `medoids` and `clustering.` To view
    these results use the following commands:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: PAM 对象由 `medoids` 和 `clustering` 组件组成。要查看这些结果，请使用以下命令：
- en: '[PRE51]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Visualizing the clusters is also easy using the `fviz_cluster` method (the
    results are shown in [Figure 7-16](#kmedoid_pam_clustering)):'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `fviz_cluster` 方法也很容易可视化群集（结果显示在 [图 7-16](#kmedoid_pam_clustering) 中）：
- en: '[PRE52]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '![KMedoid PAM clustering.](assets/pdss_0716.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![KMedoid PAM clustering.](assets/pdss_0716.png)'
- en: Figure 7-16\. k-medoid PAM clustering
  id: totrans-248
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-16\. k-medoid PAM 聚类
- en: Tip
  id: totrans-249
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: '`pamk()` in the `fpc` library is a wrapper for `pam`. It prints the suggested
    number of clusters based on the optimum average silhouette width.'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '`fpc`库中的`pamk()`是`pam`的一个包装器。它根据最优平均轮廓宽度打印建议的聚类数量。'
- en: The *k*-medoid visualization of the five clusters gives us a new view of our
    observations. There appears to be a lot of overlap in this type of clustering,
    leading us to believe the optimal number of clusters for using this technique
    is less than what we chose. As an investigation, we will try the `pamk` function,
    which determines the number of clusters for us:^([2](ch07.html#ch07fn16))
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 五个聚类的*k*-中心点可视化给我们带来了对我们观察结果的新视角。在这种类型的聚类中存在大量重叠，这使我们认为使用该技术的最优聚类数量比我们选择的要少。作为一项调查，我们将尝试`pamk`函数，该函数可以为我们确定聚类的数量：^([2](ch07.html#ch07fn16))
- en: '[PRE53]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Next we will again use the three-dimensional visualization to see how many
    clusters `pamk` thinks are optimal (the results are shown in [Figure 7-17](#visual_results_for_pamk_clustering)):'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们将再次使用三维可视化来查看 `pamk` 认为最优的聚类数（结果显示在 [图 7-17](#visual_results_for_pamk_clustering)
    中）：
- en: '[PRE54]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Note
  id: totrans-255
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Remember that the `pamk` function uses the Silhouette method for determining
    the optimal number of clusters.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，`pamk`函数使用轮廓方法确定最优的聚类数量。
- en: These results are interesting and should be cause for pause. Using the optimal
    Average Silhouette method yields two clusters. Why? Remember that there are distributors
    and resellers in our customer base. Earlier when we applied the Pareto principle
    we saw that a very small number of our customers contributed to the majority of
    sales. We surmised that these were our distributors and resellers. In the preceding
    chart, the upper cluster likely represents our distributors and resellers. The
    lower cluster likely represents regular customers. The SAP business analyst and
    data scientist should be questioning these results. What is this visualization
    telling us? We think this visualization is telling us that the distributors and
    resellers are skewing the clustering results. We may want to start this process
    over again but this time exclude the distributors and resellers.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果非常有趣，应该值得停下来思考。使用最优平均轮廓法得出两个聚类。为什么？记得我们的客户群体中有分销商和经销商。早些时候，当我们应用帕累托法则时，我们看到很少一部分客户贡献了大部分销售额。我们推测这些是我们的分销商和经销商。在前面的图表中，上方的聚类很可能代表我们的分销商和经销商。下方的聚类很可能代表普通客户。SAP业务分析师和数据科学家应该对这些结果提出质疑。这个可视化告诉了我们什么？我们认为这个可视化告诉我们，分销商和经销商正在扭曲聚类结果。我们可能希望重新开始这个过程，但这次排除分销商和经销商。
- en: '![Visual results for PAMK clustering.](assets/pdss_0717.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![PAMK聚类的可视化结果。](assets/pdss_0717.png)'
- en: Figure 7-17\. Visual results for pamk clustering
  id: totrans-259
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-17\. PAMK聚类的可视化结果
- en: Tip
  id: totrans-260
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: What if your SAP system does not discriminate between distributors and resellers
    and regular customers? How would we exclude distributors and resellers, then?
    The clustering process we’ve used with `pamk` seems to have done that pretty nicely.
    Save the customers from the lower cluster and restart the clustering process again
    on that subset.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的SAP系统不区分分销商、经销商和普通客户，我们该如何排除分销商和经销商？我们使用`pamk`进行的聚类过程似乎做得相当好。保存下来自下层聚类的客户，然后重新对这个子集进行聚类过程。
- en: Next, we will use hierarchical clustering to get another perspective.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用层次聚类来获得另一个视角。
- en: Hierarchical Clustering
  id: totrans-263
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 层次聚类
- en: Hierarchical clustering, as we’ve discussed, is another approach for identifying
    segments among observations. Unlike *k*-means and *k*-medoids, it does not require
    that the number of clusters be identified.^([3](ch07.html#ch07fn17))
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们讨论过的，层次聚类是识别观察结果中段的另一种方法。不像*k*-均值和*k*-中心点，它不要求确定聚类的数量。^([3](ch07.html#ch07fn17))
- en: 'We will perform one of each type of hierarchical clustering. Both of them have
    five fundamental steps:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将执行每种类型的层次聚类中的一种。它们都有五个基本步骤：
- en: The observations are put in a dataframe, where each column is a value by which
    to cluster.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将观察结果放入数据框中，其中每列是一个用于聚类的值。
- en: The data is scaled (we will use log).
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缩放数据（我们将使用对数）。
- en: A dissimilarity matrix is calculated (distance).
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算出一个不相似性矩阵（距离）。
- en: Clustering is performed.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进行聚类。
- en: Results are displayed.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示结果。
- en: 'Our first step is to create a new RFM dataframe. We have done this process
    a few times now:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一步是创建一个新的RFM数据框架。我们已经做过几次这个过程了：
- en: '[PRE55]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Now we’ll apply logarithm to our values:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将对我们的值应用对数：
- en: '[PRE56]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Like our other machine learning clustering techniques, we are limited to a
    particular maximum number of observations so we must again sample our data:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 像我们其他的机器学习聚类技术一样，我们限制了特定数量的观察结果，因此我们必须再次对我们的数据进行采样：
- en: '[PRE57]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Now we are ready to create a dissimilarity matrix. We will apply it with the
    standard default values. The `dist()` function returns the computed distances
    between the rows of a data matrix.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备创建一个不相似度矩阵。我们将使用标准默认值应用它。`dist()`函数返回数据矩阵行之间计算出的距离。
- en: '[PRE58]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Tip
  id: totrans-279
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: To view the parameters and details of the `dist` function put `?dist` into the
    console and press Enter. Documentation will appear in the right panel of RStudio.
    If this isn’t enough, try `??dist` for even more.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看`dist`函数的参数和详细信息，请在控制台中输入`?dist`并按Enter键。文档将出现在RStudio的右侧面板中。如果这还不够，请尝试`??dist`以获得更多信息。
- en: 'Agglomerative hierarchical clustering is performed with `hclust()`. Alternatively,
    divisive hierarchical clustering can be performed with `agnes()`. We will perform
    both of them here:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`hclust()`执行凝聚式分层聚类。或者，可以使用`agnes()`执行分裂式分层聚类。我们将在这里执行这两种方法：
- en: '[PRE59]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Visualizing our findings is easy with the `plot` command (the results of agglomerative
    hierarchical clustering are shown in [Figure 7-18](#agglomerative_hierarchical_clustering_pl)):'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`plot`命令可以轻松可视化我们的发现（凝聚式分层聚类的结果显示在[图 7-18](#agglomerative_hierarchical_clustering_pl)中）：
- en: '[PRE60]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '![Agglomerative Hierarchical Clustering plot.](assets/pdss_0718.png)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
  zh: '![凝聚式分层聚类图。](assets/pdss_0718.png)'
- en: Figure 7-18\. Agglomerative hierarchical clustering plot
  id: totrans-286
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-18\. 凝聚式分层聚类图
- en: 'We can do the same for divisive hierarchical clustering (the results are shown
    in [Figure 7-19](#divisive_hierarchical_clustering_plot)):'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分裂式分层聚类，我们也可以做同样的事情（结果显示在[图 7-19](#divisive_hierarchical_clustering_plot)中）：
- en: '[PRE61]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '![Divisive Hierarchical Clustering plot.](assets/pdss_0719.png)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![分裂式分层聚类图。](assets/pdss_0719.png)'
- en: Figure 7-19\. Divisive hierarchical clustering plot
  id: totrans-290
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-19\. 分裂式分层聚类图
- en: Both of these dendrograms are showing the same thing—the clustering of customers
    based on their recency, frequency, and monetary value. They come to slightly different
    clusters because their techniques differ.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个树状图显示的都是相同的内容——基于他们的最近性、频率和货币价值对客户进行聚类。由于他们的技术不同，它们会形成略微不同的聚类。
- en: Personally, we don’t think that our observations (customers) worked well as
    dendrograms. For one thing, to get accurate and readable visualizations we had
    to sample down quite a bit, probably too much actually to maintain integrity in
    our observations’ relationships. However, the purpose here was to demonstrate
    another type of clustering.^([4](ch07.html#ch07fn18))
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 就个人而言，我们认为我们的观察（客户）作为树状图的效果不佳。首先，为了获得准确和可读的可视化效果，我们不得不大幅度地进行采样，实际上可能太多，以至于无法维护我们的观察关系的完整性。然而，这里的目的是展示另一种类型的聚类。^([4](ch07.html#ch07fn18))
- en: Manual RFM
  id: totrans-293
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 手动RFM
- en: For our final technique, we will define manual buckets into which our RFM scores
    fall. It is a method of manual clustering of the customers. It may seem cheap,
    but it works and fulfills the requirements for many types of analyses.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的最终技术，我们将定义手动的桶，将我们的RFM分数划分到其中。这是一种手动对客户进行聚类的方法。这可能看起来很简单，但它确实有效，并且满足许多类型分析的要求。
- en: Tip
  id: totrans-295
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Sometimes the simplest tool is the best. The range of neural networks and machine
    learning algorithms is wide and robust. It is tempting to grab the shiniest one
    and try to make that fit your data. We are guilty of that, especially when it
    comes to nature-inspired algorithms. Read the fantastic book [*Clever Algorithms*](http://bit.ly/2kpe2Q8)
    and you’ll try to apply ant colony optimization to everything. We make this comment
    now because in this exercise we just use “if” statements...about the least flashy
    technique there is.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 有时最简单的工具是最好的。神经网络和机器学习算法的范围广泛且强大。诱人的是，我们会选择最耀眼的工具，试图让它适应我们的数据。特别是当涉及到受自然启发的算法时，我们会这样做。阅读出色的书籍[*Clever
    Algorithms*](http://bit.ly/2kpe2Q8)，你会尝试将蚁群优化应用于一切。我们现在发表这一评论，因为在这个练习中，我们只使用“if”语句……这可能是最不起眼的技术。
- en: 'The hardest part of performing manual RFM is defining the categories. What
    constitutes a *champion* customer as opposed to a *potential champion*? Big Bonanza
    Warehouse moves a large number of products to individual customers, but they also
    have distributors. The distributors are going to always look like champions compared
    to customers. Their definitions for the RFM model will vary drastically from the
    definitions for a company that does not have distributors. This business process
    requires you to work closely with marketing and sales teams to define the RFM
    categories. For our purposes, we will define them exactly as [Table 7-1](#RFM-customer-segment)
    above defines them. The code is a simple nest of `ifelse` statements:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 手动执行RFM的最困难部分是定义分类。什么构成*冠军*客户与*潜在冠军*客户的区别？Big Bonanza Warehouse向个别客户提供大量产品，但他们也有分销商。与客户相比，分销商总是看起来像冠军。他们对RFM模型的定义将与没有分销商的公司的定义截然不同。这个业务过程需要您与营销和销售团队密切合作，以定义RFM分类。为了我们的目的，我们将完全按照[表 7-1](#RFM-customer-segment)中的定义来定义它们。代码是一个简单的`ifelse`语句嵌套：
- en: '[PRE62]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Once the code is done we can see the results with a `table` statement:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 代码完成后，我们可以通过`table`语句查看结果：
- en: '[PRE63]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'The [`ggplot2` package](https://ggplot2.tidyverse.org/) can quickly show us
    a visual distribution of the classes (the results are shown in [Figure 7-20](#distribution_of_manually_segmented_custo)):'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '[`ggplot2`包](https://ggplot2.tidyverse.org/)可以快速显示我们类的视觉分布（结果显示在[图 7-20](#distribution_of_manually_segmented_custo)中）：'
- en: '[PRE64]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: This chart shows us some interesting findings. In particular, there is a high
    number of customers who did not get classified at all (unclassified). Most of
    the customers, not surprisingly, fall into the *Middle of the Road* category.
    Our initial goal was to identify customers who should be converted to the new
    system. Clearly *Champion* and *Potential Champion* should make the cut. However,
    it is up to the business to decide if *Middle of the Road* and *Unclassified*
    should make it. Our recommendation would be to err on the side of caution and
    keep them. However, even if we keep those large groups we’ve reduced our conversion
    task substantially by not including the *Almost Inactive, Inactive, One-Timers*,
    and *Penny Pinchers.*
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 该图显示了一些有趣的发现。特别是，有大量客户未被分类（未分类）。大多数客户，毫不奇怪，都属于*中庸*类别。我们最初的目标是识别应该转换为新系统的客户。显然，*冠军*和*潜在冠军*应该入选。然而，是否将*中庸*和*未分类*纳入其中则由业务决定。我们的建议是谨慎行事并保留它们。然而，即使我们保留了这些大型群体，我们通过不包括*几乎不活跃，不活跃，一次性购买*和*节省一分钱*大大减少了我们的转换任务。
- en: '![Distribution of manually segmented customers](assets/pdss_0720.png)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
  zh: '![手动分段客户的分布](assets/pdss_0720.png)'
- en: Figure 7-20\. Distribution of manually segmented customers
  id: totrans-305
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-20\. 手动分段客户的分布
- en: 'Step 4: Report the Findings'
  id: totrans-306
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4步：报告发现
- en: We’ve done the analysis and have some interesting findings. Now, however, we
    want to report these findings to others. Presenting lines of code will not go
    over well in meetings. We will use R Markdown to generate a unique report. First
    we will code the R Markdown document. Then we will [*knit*](http://bit.ly/2lScRcc)
    the document to make it presentable to end users. *Knitting* in R studio is similar
    to publishing.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了分析并获得了一些有趣的发现。然而，现在我们希望向其他人报告这些发现。在会议上展示代码行并不太合适。我们将使用R Markdown生成一个独特的报告。首先我们将编写R
    Markdown文档。然后我们将[*knit*](http://bit.ly/2lScRcc)文档，以使其适合最终用户查看。在R Studio中，*Knitting*类似于发布。
- en: To begin, start a new R Markdown document by following the menu path File →
    R Markdown in RStudio, as shown in [Figure 7-21](#menu_path_to_create_a_markdown_document).
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，请按照菜单路径文件 → R Markdown在RStudio中开始一个新的R Markdown文档，如[图 7-21](#menu_path_to_create_a_markdown_document)所示。
- en: '![Menu path to create a Markdown document in RStudio.](assets/pdss_0721.png)'
  id: totrans-309
  prefs: []
  type: TYPE_IMG
  zh: '![在RStudio中创建Markdown文档的菜单路径。](assets/pdss_0721.png)'
- en: Figure 7-21\. Menu path to create a Markdown document in RStudio
  id: totrans-310
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-21\. 在RStudio中创建Markdown文档的菜单路径
- en: Create a title for the presentation and add your name as the author ([Figure 7-22](#create_r_markdown_documen)).
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 创建演示文稿的标题，并将您的名字作为作者添加（[图 7-22](#create_r_markdown_documen)）。
- en: '![Create R Markdown Documen](assets/pdss_0722.png)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![创建R Markdown文档](assets/pdss_0722.png)'
- en: Figure 7-22\. Create R Markdown document
  id: totrans-313
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-22\. 创建R Markdown文档
- en: Let’s take a look at the basic structure of an R Markdown document, as shown
    in [Figure 7-23](#basic_structure_of_markdown_document).
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下R Markdown文档的基本结构，如[图 7-23](#basic_structure_of_markdown_document)所示。
- en: '![Basic Structure of Markdown Document](assets/pdss_0723.png)'
  id: totrans-315
  prefs: []
  type: TYPE_IMG
  zh: '![Markdown 文档的基本结构](assets/pdss_0723.png)'
- en: Figure 7-23\. Basic structure of Markdown document
  id: totrans-316
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-23\. Markdown 文档的基本结构
- en: 'The basic information of your document:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 您的文档的基本信息：
- en: The type of document you are creating. HTML is default but you could have PDFs,
    Word or RTF documents, GitHub files, and others.
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您正在创建的文档类型。HTML 是默认选项，但您可以选择 PDF、Word 或 RTF 文档、GitHub 文件等。
- en: Click the Knit button to create/render the report.
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单击 Knit 按钮创建/渲染报告。
- en: Write code between [PRE65] sections.
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在[PRE65]部分之间编写代码。
- en: Test code for specific sections using the run button.
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用运行按钮测试特定部分的代码。
- en: Use text to describe and document your code and findings.
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用文本描述和记录您的代码和发现。
- en: Put plots in your document and hide the code that runs them with the `echo=FALSE
    command`.
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图表放入文档中，并使用`echo=FALSE`命令隐藏运行它们的代码。
- en: There is much more to R Markdown than this! Refer to this cheat sheet—one of
    many—at [R Studio](http://bit.ly/2jXi8i1).
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: R Studio 提供了许多丰富的信息！请参考这张速查表之一：[R Studio](http://bit.ly/2jXi8i1)。
- en: R Markdown Code
  id: totrans-325
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: R Markdown 代码
- en: 'We have already done our analysis so to be concise we will create a very simple
    report in R Markdown for illustrative purposes. This is the code created in RStudio:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了分析，为了简洁起见，我们将使用 R Markdown 创建一个非常简单的报告作为示例。这是在 RStudio 中创建的代码：
- en: '[PRE66]{r setup, include=FALSE}'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE66]{r setup, include=FALSE}'
- en: knitr::opts_chunk$set(echo = TRUE)
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: knitr::opts_chunk$set(echo = TRUE)
- en: knitr::opts_chunk$set(message = FALSE)
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: knitr::opts_chunk$set(message = FALSE)
- en: library(tidyverse)
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: library(tidyverse)
- en: library(ggplot2)
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: library(ggplot2)
- en: library(knitr)
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: library(knitr)
- en: library(kableExtra)
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: library(kableExtra)
- en: customer_rfm <- read.csv('D:/DataScience/Oreily/customer_rfm.csv',
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: customer_rfm <- read.csv('D:/DataScience/Oreily/customer_rfm.csv',
- en: stringsAsFactors = FALSE)
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: stringsAsFactors = FALSE)
- en: row.names(customer_rfm) <- customer_rfm$X
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: row.names(customer_rfm) <- customer_rfm$X
- en: customer_rfm$X <- NULL
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: customer_rfm$X <- NULL
- en: '#RMarkedown is a rich and rewarding way to display your findings. Refer to'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '#RMarkedown 是显示发现的一种丰富而有益的方式。请参考'
- en: https://rmarkdown.rstudio.com/index.html for a wealth of information.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '[R Markdown](https://rmarkdown.rstudio.com/index.html) 提供了丰富的信息。'
- en: '[PRE67]{r range_of_order_dates, echo=FALSE}'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE67]{r range_of_order_dates, echo=FALSE}'
- en: count(customer_rfm)
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: count(customer_rfm)
- en: '[PRE68]{r median_recency, echo=FALSE, fig.height = 7, fig.width = 14}'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE68]{r median_recency, echo=FALSE, fig.height = 7, fig.width = 14}'
- en: '#use the mutate function to limit the number. Outliers will be binned in one
    value.'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '#使用 mutate 函数限制数量。异常值将被分组到一个值中。'
- en: In this case 100.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下为100。
- en: customer_rfm %>%
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: customer_rfm %>%
- en: mutate(mrod = ifelse(most_recent_order_days > 100, 100, most_recent_order_days))
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: mutate(mrod = ifelse(most_recent_order_days > 100, 100, most_recent_order_days))
- en: '%>% ggplot(aes(mrod)) +'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '%>% ggplot(aes(mrod)) +'
- en: geom_histogram(binwidth = .7,
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: geom_histogram(binwidth = .7,
- en: col = "black",
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: col = "black",
- en: fill = "blue") +
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: fill = "blue") +
- en: ylab('Count') +
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: ylab('Count') +
- en: xlab('Most Recent Order Days') +
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: xlab('最近订单天数') +
- en: ggtitle('Histogram of Most Recent Orders')
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: ggtitle('最近订单的直方图')
- en: '[PRE69]{r median_recency_number, echo=FALSE}'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE69]{r median_recency_number, echo=FALSE}'
- en: wd <- mean(customer_rfm$most_recent_order_days)
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: wd <- mean(customer_rfm$most_recent_order_days)
- en: 'print(paste0("Average Recenct Order: ", wd))'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: print(paste0("平均最近订单：", wd))
- en: '[PRE70]{r median_frequency, echo=FALSE, fig.height = 7, fig.width = 14}'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE70]{r median_frequency, echo=FALSE, fig.height = 7, fig.width = 14}'
- en: customer_rfm %>%
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: customer_rfm %>%
- en: mutate(cto = ifelse(count_total_orders > 20, 20, count_total_orders)) %>%
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: mutate(cto = ifelse(count_total_orders > 20, 20, count_total_orders)) %>%
- en: ggplot(aes(cto)) +
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: ggplot(aes(cto)) +
- en: geom_histogram(binwidth = .7,
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: geom_histogram(binwidth = .7,
- en: col = "black",
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: col = "black",
- en: fill = "green") +
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: fill = "green") +
- en: ylab('Count') +
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: ylab('Count') +
- en: xlab('Order Count or Frequency') +
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: xlab('订单数量或频率') +
- en: ggtitle('Histogram of Frequency of Orders')
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: ggtitle('订单频率的直方图')
- en: '[PRE71]{r median_frequency_number, echo=FALSE}'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE71]{r median_frequency_number, echo=FALSE}'
- en: wd <- mean(customer_rfm$count_total_orders)
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: wd <- mean(customer_rfm$count_total_orders)
- en: 'print(paste0("Average Order Frequency: ", wd))'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: print(paste0("平均订单频率：", wd))
- en: '[PRE72]{r median_monetary_large, echo=FALSE, fig.height = 7, fig.width = 14}'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE72]{r median_monetary_large, echo=FALSE, fig.height = 7, fig.width = 14}'
- en: '#We need to break the monetary value into two because of potential great'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: '#由于可能存在巨大的潜力，我们需要将货币价值分开。'
- en: '#differences between distributors and regular customers'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: '#分销商和常规客户之间的差异'
- en: customer_rfm_big_players <-
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: customer_rfm_big_players <-
- en: customer_rfm[customer_rfm$total_purchase_value >= 100000 &
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: customer_rfm[customer_rfm$total_purchase_value >= 100000 &
- en: customer_rfm$total_purchase_value < 1000000,]
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: customer_rfm$total_purchase_value < 1000000,]
- en: customer_rfm_big_players %>%
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: customer_rfm_big_players %>%
- en: mutate(tpv = ifelse(total_purchase_value > 1000000,
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: mutate(tpv = ifelse(total_purchase_value > 1000000,
- en: 1000000, total_purchase_value)) %>%
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 1000000, total_purchase_value)) %>%
- en: ggplot(aes(tpv)) +
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: ggplot(aes(tpv)) +
- en: geom_histogram(binwidth = .7,
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: geom_histogram(binwidth = .7,
- en: col = "black",
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: col = "black",
- en: fill = "orange") +
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: fill = "orange") +
- en: ylab('Count') +
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: ylab('Count') +
- en: xlab('Total Monetary Value') +
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: xlab('总货币价值') +
- en: ggtitle('Histogram of Customer Monetary Value ( > 100,000 )')
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: ggtitle('客户货币价值的直方图（> 100,000）')
- en: '[PRE73]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: This is just a very small example of reporting with R Markdown. This is just
    the tip of the iceberg and hopefully it inspires you to dive deeper into the world
    of R Markdown. We will end with this simple example because, quite frankly, we
    could write an entire book on this wonderful tool alone.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是用R Markdown进行报告的一个很小的例子。这只是冰山一角，希望它能激励你深入探索R Markdown的世界。我们将以这个简单的例子结束，因为坦率地说，我们可以单独为这个精彩的工具写一本完整的书。
- en: R Markdown Knit
  id: totrans-388
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: R Markdown Knit
- en: Obviously you will not report your data science findings using lines of code.
    R Markdown allows you to *knit* your findings into a report to be distributed
    to the business. Click on the Knit button in RStudio to display the report in
    Figures [7-24](#r_markdown_document_rendered) and [7-25](#r_markdown_document_rendered-id0020).
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，你不会用代码行来报告你的数据科学发现。R Markdown允许你*编织*你的发现成为一份向业务分发的报告。在RStudio中点击Knit按钮，可以显示图7-24和图7-25的报告。
- en: '![R Markdown Document rendered](assets/pdss_0724.png)'
  id: totrans-390
  prefs: []
  type: TYPE_IMG
  zh: '![渲染的R Markdown文档](assets/pdss_0724.png)'
- en: Figure 7-24\. R Markdown document rendered
  id: totrans-391
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-24\. R Markdown文档渲染
- en: '![R Markdown document rendered](assets/pdss_0725.png)'
  id: totrans-392
  prefs: []
  type: TYPE_IMG
  zh: '![渲染的R Markdown文档](assets/pdss_0725.png)'
- en: Figure 7-25\. R Markdown document rendered (continued)
  id: totrans-393
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-25\. R Markdown文档渲染（续）
- en: Summary
  id: totrans-394
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: We’ve completed quite a journey in clustering and segmentation, starting with
    the concepts and ending with a report to display to the business. Remember that
    our original requirement came from Rod at Big Bonanza Warehouse. He wanted to
    know which customers should be migrated to the new system and which should be
    left behind. We’ve gained insight into that question and much more in our data
    exploration. For the migration to the new system we will keep the *Champion, Potential
    Champion, Middle of the Road*, and *Unclassified* customers. This will reduce
    conversion time, validation, and cost by not converting tens of thousands of unnecessary
    customer records. Duane takes the findings to the Master Data team in preparation
    for their work in the S/4HANA conversion.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在聚类和分割方面已经完成了相当的旅程，从概念开始，以报告形式展示给业务。请记住，我们最初的需求来自Big Bonanza Warehouse的Rod。他想知道应该将哪些客户迁移到新系统，哪些客户应该留下。在数据探索中，我们对这个问题以及更多内容有了深入了解。对于新系统的迁移，我们将保留*冠军、潜在冠军、中庸*和*未分类*的客户。这将通过不转换成千上万个不必要的客户记录来减少转换时间、验证和成本。Duane将这些发现带给主数据团队，为他们在S/4HANA转换中的工作做准备。
- en: Furthermore, the results helped us understand the importance of distributors
    in our customer base as well as the key evaluation parameters of recency, frequency,
    and monetary value. In addition to Rod’s project, surely the marketing team would
    like to see this evaluation to guide or validate their efforts.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，结果帮助我们理解了我们客户基础中分销商的重要性，以及最近性、频率和货币价值的关键评估参数。除了Rod的项目，市场团队肯定也希望看到这些评估结果，以指导或验证他们的工作。
- en: Like all of our previous exploration, this is just the beginning. Knowing your
    customers is a valuable and often underappreciated aspect of business. Techniques
    we have touched upon in this chapter will help you gain insight into your SAP
    business data and raise questions the business may not have thought to ask.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们之前的所有探索一样，这只是个开始。了解你的客户是业务中一个有价值但经常被低估的方面。本章介绍的技术将帮助你深入了解你的SAP业务数据，并提出业务可能没有考虑到的问题。
- en: ^([1](ch07.html#ch07fn1-marker)) A nice introduction with a great cheat sheet
    can be found on the [R Studio website](http://bit.ly/2lSzWLO).
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch07.html#ch07fn1-marker)) 你可以在[R Studio网站](http://bit.ly/2lSzWLO)找到一个很棒的入门介绍和速查表。
- en: ^([2](ch07.html#ch07fn16-marker)) If you are wondering, “why not use `pamk`
    simply to determine the optimal number of clusters?” This process can be computationally
    expensive and run a long time.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch07.html#ch07fn16-marker)) 如果你想知道，“为什么不简单地使用`pamk`来确定最佳的聚类数量呢？”这个过程可能计算开销很大，并且运行时间很长。
- en: '^([3](ch07.html#ch07fn17-marker)) In [Chapter 2](ch02.html#ch02) we discussed
    the two types of hierarchical clustering: divisive and agglomerative. Take note
    that hierarchical clustering is sensitive to outliers.'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch07.html#ch07fn17-marker)) 在[第2章](ch02.html#ch02)中，我们讨论了层次聚类的两种类型：分裂型和凝聚型。请注意，层次聚类对异常值敏感。
- en: '^([4](ch07.html#ch07fn18-marker)) There are a number of ways to display dendrograms—do
    a simple internet search for “beautiful dendrograms” for some options. Some of
    our favorite techniques can be done using the `ape#` package. You can get pretty
    creative with colors and shapes in dendrograms. This is more than simply aesthetics.
    Visualizations bring out the data in ways that our minds more easily interpret.
    *The Functional Art: An Introduction* by Alberto Cairo is a wonderful, insightful
    must for anyone wanting to get more from their visualizations.'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch07.html#ch07fn18-marker)) 有许多方法可以显示树状图 — 搜索一下“美丽的树状图”来获取一些选项。我们喜欢的一些技术可以使用`ape#`包来实现。你可以在树状图中运用丰富的颜色和形状，创造出非常有创意的效果。这不仅仅是美学问题。可视化可以以更容易理解的方式展示数据。*《功能艺术：一种介绍》*
    由阿尔贝托·开罗撰写，对于希望从他们的可视化中获得更多收获的人来说，是一本了不起的、富有洞察力的必读之作。
