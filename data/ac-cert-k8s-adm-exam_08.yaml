- en: 8 Troubleshooting Kubernetes
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8 Kubernetes故障排除
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Monitoring and viewing logs
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控和查看日志
- en: Determining high CPU or RAM usage
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定高CPU或RAM使用情况
- en: Resolving common cluster problems
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决常见的集群问题
- en: Analyzing network traffic to identify communication concerns
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析网络流量以识别通信问题
- en: As this is the biggest topic (30%) on the CKA exam, we’re going to cover troubleshooting
    in detail in this chapter. Troubleshooting means fixing problems with applications,
    control plane components, worker nodes, and the underlying network. When running
    applications in Kubernetes, problems will arise, such as concerns with Pods, Services,
    and Deployments.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是CKA考试中最大的主题（30%），我们将在本章中详细讲解故障排除。故障排除意味着修复应用程序、控制平面组件、工作节点和底层网络中的问题。在Kubernetes中运行应用程序时，可能会出现诸如Pod、服务和工作部署等问题。
- en: The troubleshooting domain
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 故障排除领域
- en: This chapter covers the troubleshooting domain of the CKA curriculum, which
    consists of 30% of the questions on the exam. This domain covers the techniques
    we use to discover and fix problems inside our Kubernetes cluster, including viewing
    the logs, capturing cluster events, networking problems, and application monitoring.
    It encompasses the following competencies.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了CKA课程中的故障排除领域，该领域占考试题目的30%。这个领域包括我们用来发现和修复Kubernetes集群内部问题的技术，包括查看日志、捕获集群事件、网络问题和应用程序监控。它包括以下能力。
- en: '| Competency | Chapter section |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| 能力 | 章节部分 |'
- en: '| --- | --- |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Evaluate cluster and node logging. | 8.1, 8.2 |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| 评估集群和节点日志。 | 8.1, 8.2 |'
- en: '| Understand how to monitor applications. | 8.1 |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| 理解如何监控应用程序。 | 8.1 |'
- en: '| Manage container stdout and stderr logs. | 8.1 |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| 管理容器stdout和stderr日志。 | 8.1 |'
- en: '| Troubleshoot application failure. | 8.1, 8.3 |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| 故障排除应用程序故障。 | 8.1, 8.3 |'
- en: '| Troubleshoot cluster component failure. | 8.2 |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| 故障排除集群组件故障。 | 8.2 |'
- en: '| Troubleshoot networking. | 8.3 |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 故障排除网络问题。 | 8.3 |'
- en: This chapter will help you understand the logs that a container might output
    in the process of debugging and getting the application back to a healthy state.
    If the problem is not the application, it may be the underlying node, the underlying
    operating system, or a communication problem on the network. On the exam, you’ll
    be expected to know the differences between an application failure, a cluster-level
    problem, and a network problem and how to troubleshoot and determine a resolution
    in the shortest amount of time.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将帮助你理解容器在调试和将应用程序恢复到健康状态的过程中可能输出的日志。如果问题不是应用程序，可能是底层节点、底层操作系统或网络上的通信问题。在考试中，你将需要了解应用程序故障、集群级别问题和网络问题之间的区别，以及如何在最短的时间内进行故障排除和确定解决方案。
- en: NOTE The exercises in this chapter involve an action that you must take to “break”
    the cluster to provide something to troubleshoot. For the exam, the cluster or
    cluster object will already be broken so you shouldn’t be too concerned about
    the initial action as a prerequisite for the exam.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：本章中的练习涉及你必须采取的操作来“破坏”集群以提供故障排除的内容。对于考试，集群或集群对象已经损坏，因此你不需要太担心作为考试先决条件的初始操作。
- en: 8.1 Understanding application logs
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.1 理解应用程序日志
- en: One of the ways Kubernetes administrators find out why a problem is occurring
    in a cluster is by viewing the logs. Application logs help you to get more verbose
    information about what’s going on inside a containerized application running in
    a Pod. Container engines (e.g., containerd) are designed to support logging and
    usually write all their output to standard output (stdout) and standard error
    (stderr) streams to a file located in the directory `/var/log/containers` (figure
    8.1).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes管理员发现集群中问题发生原因的一种方式是通过查看日志。应用程序日志可以帮助你获取关于在Pod中运行的容器化应用程序内部发生情况的更详细的信息。容器引擎（例如，containerd）被设计为支持日志记录，通常将所有输出写入标准输出（stdout）和标准错误（stderr）流，并将这些流写入位于`/var/log/containers`目录中的文件（图8.1）。
- en: '![](../../OEBPS/Images/08-01.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/08-01.png)'
- en: Figure 8.1 The stdout and stderr container logs are sent to a log file managed
    by kubelet in `/var/log/containers``.`
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1 stdout和stderr容器日志被发送到由kubelet管理的日志文件，位于`/var/log/containers`。
- en: The CKA exam will test you on your ability to troubleshoot errors from within
    a Pod. Because Pod errors and container errors are synonymous, retrieving logs
    from any application in Kubernetes is simplified. An example of an exam question
    in this domain is as follows.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: CKA考试将测试你在Pod内部排查错误的能力。由于Pod错误和容器错误是同义的，从Kubernetes中的任何应用程序检索日志被简化了。该领域的一个考试问题示例如下。
- en: '| Exam Task In cluster `ik8s`, in a namespace called `db08328`, create a Deployment
    with the `kubectl` command line (imperatively) named `mysql`, with the image `mysql:8`.
    List the Pods in the `db08328` namespace to see if the Pod is running. If the
    Pod is not running, view the logs to determine why the Pod is not in a healthy
    state. Once you’ve collected the necessary log information, make changes to the
    Pod to fix it and get it back to a running, healthy state. |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 考试任务 在集群`ik8s`中，在名为`db08328`的命名空间中，使用`kubectl`命令行（强制）创建一个名为`mysql`的部署，其镜像为`mysql:8`。列出`db08328`命名空间中的Pods以查看Pod是否正在运行。如果Pod没有运行，查看日志以确定Pod为何不在健康状态。一旦收集到必要的日志信息，对Pod进行更改以修复它并使其恢复到运行和健康状态。
    |'
- en: 'If you don’t already have access to an existing Kubernetes cluster, you can
    create a Kubernetes cluster with kind as explained in appendix A. You will only
    need a single-node cluster, so follow the instructions in section A.1.1\. Once
    you have a shell to the control plane node using the command `docker exec -it
    kind-control-plane bash`, set your alias for `kubectl` as well as tab completion,
    as this will help you with typos and becoming used to using the tab completion
    for the exam. You can find the instructions to do this at the end of appendix
    B, but here again are the commands to run (in order):'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有访问现有的Kubernetes集群，你可以按照附录A中所述使用kind创建一个Kubernetes集群。你只需要一个单节点集群，所以遵循A.1.1节中的说明。一旦你通过命令`docker
    exec -it kind-control-plane bash`获得了控制平面节点的shell，设置你的`kubectl`别名以及Tab补全功能，这将有助于你在考试中纠正错误并习惯使用Tab补全。你可以在附录B的末尾找到执行这些操作的说明，但这里再次列出要运行的命令（按顺序）：
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: On exam day, these will already be configured, so don’t worry about having to
    memorize these commands. When you sit for the exam, you will already be able to
    use the `k` alias and tab completion as soon as you start the exam.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在考试当天，这些配置已经完成，所以无需担心需要记住这些命令。当你开始考试时，你将能够立即使用`k`别名和Tab补全功能。
- en: 'After these commands are run, create the namespace per the instructions with
    the command `k create ns db08328`. You can follow that up by listing all namespaces
    with the command `k get ns`. The output will look similar to this:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行这些命令之后，根据说明使用命令`k create ns db08328`创建命名空间。你可以使用命令`k get ns`继续列出所有命名空间。输出将类似于以下内容：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now that you have the correct namespace, you can change your context to the
    `db08328` namespace, so you don’t have to keep typing the namespace with every
    command. You can change your context with the command `k config set-context --current
    --namespace db08328`. The output will look like this:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经设置了正确的命名空间，你可以使用命令`k config set-context --current --namespace db08328`将上下文更改为`db08328`命名空间，这样你就不必在每次命令中输入命名空间。你可以使用命令更改上下文。输出将如下所示：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now that you’ve set the context to the namespace in which you’ll be creating
    the Deployment, create the Deployment named `mysql` with the command `k create
    deploy mysql --image mysql:8`. After this, you can list the Pods with the command
    `k get po`.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经将上下文设置为你将创建部署的命名空间，使用命令`k create deploy mysql --image mysql:8`创建名为`mysql`的部署。之后，你可以使用命令`k
    get po`列出Pods。
- en: EXAM TIP Notice that you don’t have to use the `-n` option to specify your namespace
    each time. I will warn you that this can become confusing on the exam, as with
    each task you are also setting the context. So just be mindful that you’ll be
    performing this command twice; therefore, it may be easier in some cases to type
    out the namespace each time, depending on how many namespaces you have to work
    in with each task.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 考试技巧：请注意，你不必每次都使用`-n`选项来指定你的命名空间。我要提醒你，在考试中这可能会变得令人困惑，因为随着每个任务的进行，你也在设置上下文。所以请记住，你将执行此命令两次；因此，在某些情况下，每次都输入命名空间可能更容易，具体取决于每个任务中你需要处理的命名空间数量。
- en: 'The output of the Deployment creation and the listing of the Pods should look
    as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 部署创建和Pod列表的输出应如下所示：
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The result, in this case, is that the status of the Pod is in a `CrashLoopBackOff`.
    There are many statuses that a Pod can have, including `OOMKilled`, `ErrImagePull`,
    `ImagePullBackoff`, `FailedScheduling`, `NonZeroExitCode`, and `CreateContainerConfigError`.
    You can view the failed statuses in table 8.1.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，Pod 的状态处于 `CrashLoopBackOff`。Pod 可以有多个状态，包括 `OOMKilled`、`ErrImagePull`、`ImagePullBackoff`、`FailedScheduling`、`NonZeroExitCode`
    和 `CreateContainerConfigError`。你可以在表 8.1 中查看失败的状态。
- en: Table 8.1 Access modes and their short form, used in the YAML for a persistent
    volume or persistent volume claim
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8.1 持久卷或持久卷声明的 YAML 中使用的访问模式和它们的简称
- en: '| Status | Meaning |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 状态 | 含义 |'
- en: '| --- | --- |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `CrashLoopBackOff` | The Pod is trying to start, crashing, then restarting
    in a loop. Kubernetes will wait an increasing back-off time between restarts to
    give you a chance to fix the error. |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| `CrashLoopBackOff` | Pod 正在尝试启动，崩溃，然后循环重启。Kubernetes 将在重启之间等待递增的回退时间，以给你机会修复错误。
    |'
- en: '| `ImagePullBackOff` | A Pod cannot start up because it can’t find the specified
    image locally or in the remote container registry. It will continue to try with
    an increasing back-off delay. |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| `ImagePullBackOff` | Pod 无法启动，因为它无法在本地或远程容器注册库中找到指定的镜像。它将继续尝试，并使用递增的回退延迟。
    |'
- en: '| `ErrImagePull` | A Pod fails to start up because the image cannot be found
    or pulled due to authorization. |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| `ErrImagePull` | Pod 由于授权问题无法找到或拉取镜像而无法启动。 |'
- en: '| `CreateContainerConfigError` | A container within the Pod will not start
    due to missing components that are required to run. |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| `CreateContainerConfigError` | Pod 内的容器由于缺少运行所需的组件而无法启动。 |'
- en: '| `RunContainerError` | Running the container within a Pod fails due to problems
    with the container runtime or entry point of the container. |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| `RunContainerError` | Pod 内的容器由于容器运行时或容器入口点的问题而无法运行。 |'
- en: '| `FailedScheduling` | A Pod is unable to be scheduled to a node, either because
    nodes are marked as unschedulable, a taint is applied, or the node can’t satisfy
    the requirements. |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| `FailedScheduling` | Pod 无法调度到节点，可能是因为节点被标记为不可调度，应用了污点，或者节点无法满足要求。 |'
- en: '| `NonZeroExitCode` | The container within a Pod exits unexpectedly due to
    an application error or missing file or directory. |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| `NonZeroExitCode` | Pod 内的容器由于应用程序错误或缺少文件或目录而意外退出。 |'
- en: '| `OOMKilled` | A Pod was scheduled, but the memory limit assigned to it has
    been exceeded. |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| `OOMKilled` | Pod 已被调度，但分配给它的内存限制已被超出。 |'
- en: 'A `CrashLoopBackoff` means that the Pod is continuing to start, crash, and
    restart again, and then crashing again, hence the term *crash loop*. We can see
    why this is happening by viewing the container logs with the command `k logs mysql-68f7776797-w92l6`.
    Tab completion comes in handy here because you can start typing `mysql` and then
    quickly press the Tab key on the keyboard, and it will complete the rest for you.
    Tab completion will be enabled on the exam, but if you’d like to set this up in
    your own cluster, see appendix B. The output of the command `k logs mysql-68f7776797-w92l6`
    will look like this:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: A `CrashLoopBackoff` 表示 Pod 正在持续启动、崩溃、重启，然后再次崩溃，因此称为 *崩溃循环*。我们可以通过使用命令 `k logs
    mysql-68f7776797-w92l6` 来查看容器日志来了解为什么会发生这种情况。在这里，Tab 完成功能很有用，因为你可以开始输入 `mysql`，然后快速按下键盘上的
    Tab 键，它将为你完成剩余的部分。Tab 完成功能将在考试中启用，但如果你想在你的集群中设置此功能，请参阅附录 B。命令 `k logs mysql-68f7776797-w92l6`
    的输出将如下所示：
- en: '[PRE4]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This tells us exactly what we wanted to know, which is that the database password
    needs to be set as an environment variable inside the container. The output even
    gives you the environment variable names from which to choose. If you recall in
    chapter 7, we created a `mysql` Deployment in which we set the password as an
    environment variable; let’s refer back to it and utilize those same techniques
    to solve the problem that we have here. Looking back at figure 7.12 specifically,
    we can see that the environment variable is set inline with the name of the container
    image; let’s apply this to our currently running Deployment with the command `k
    edit deploy mysql`. First, if you’ve started with a fresh kind cluster, you’ll
    need to run the command `apt update; apt install vim` to edit the Deployment using
    the Vim text editor. Once the Deployment is open, you can make the following additions
    to the YAML, as you’ll see depicted in figure 8.2.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉我们我们想要知道的确切信息，即数据库密码需要在容器内部设置为一个环境变量。输出甚至给出了您可以选择的环境变量名称。如果您还记得第 7 章，我们创建了一个
    `mysql` 部署，其中我们将密码设置为环境变量；让我们回顾一下并利用那些相同的技巧来解决我们这里的问题。回顾图 7.12，我们可以看到环境变量是与容器镜像的名称一起设置的；让我们使用命令
    `k edit deploy mysql` 将此应用于我们当前正在运行的部署。首先，如果您从一个全新的集群开始，您需要运行命令 `apt update; apt
    install vim` 来使用 Vim 文本编辑器编辑部署。一旦部署打开，您可以在 YAML 中进行以下添加，如图 8.2 所示。
- en: '![](../../OEBPS/Images/08-02.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/08-02.png)'
- en: Figure 8.2 Edit the `mysql` Deployment by adding the environment variable for
    a database password.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.2 通过添加数据库密码的环境变量来编辑 `mysql` 部署。
- en: 'Once you’ve done this, save and quit editing the `mysql` Deployment by pressing
    `:wq` on your keyboard. This will take you back to the command prompt, in which
    you can perform the command `k get po` to see if the Pod is now in a running state.
    The output should look like this:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成这些操作，通过按键盘上的 `:wq` 保存并退出编辑 `mysql` 部署。这将带您回到命令提示符，在那里您可以执行 `k get po` 命令来查看
    Pod 是否现在处于运行状态。输出应该看起来像这样：
- en: '[PRE5]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Sure enough, the Pod now has a status of `Running`, which is exactly what we
    need to get the Pod back to a running, healthy state and complete the exam task.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 果然，Pod 现在的状态是 `Running`，这正是我们需要让 Pod 回到运行、健康状态并完成考试任务的情况。
- en: 8.1.1 Container log detail
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1.1 容器日志详情
- en: 'The `k logs` command is a handy utility for viewing the stdout and stderr from
    a container within a Pod. If there are two containers inside of one Pod, you must
    add a `-c` and specify the container you’d like to access. For example, run the
    command `k run busybox -image busybox -command [''while true; do echo "$(date)":
    "I am a busybox container"; sleep 5; done''] -dry-run=client -o yaml > pod.yaml`
    to generate the YAML for a Pod. Open the `pod.yaml` file with the command `vim
    pod.yaml`. We’ll make a few minor changes to the YAML, first by placing the command
    all on one line, moving the single quotes to inside the square brackets, and then
    adding the following to the beginning of the line, just before the word `while`:
    `''sh'', ''-c'',`. The final result should look similar to the YAML file in figure
    8.3.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '`k logs` 命令是一个方便的实用工具，用于查看 Pod 内容器的 stdout 和 stderr。如果一个 Pod 内部有两个容器，您必须添加一个
    `-c` 并指定您想要访问的容器。例如，运行命令 `k run busybox -image busybox -command [''while true;
    do echo "$(date)": "I am a busybox container"; sleep 5; done''] -dry-run=client
    -o yaml > pod.yaml` 以生成 Pod 的 YAML。使用命令 `vim pod.yaml` 打开 `pod.yaml` 文件。我们将对 YAML
    进行一些小的修改，首先将命令全部放在一行上，将单引号移动到方括号内，然后在 `while` 单词之前添加以下内容：`''sh'', ''-c'',`。最终结果应该类似于图
    8.3 中的 YAML 文件。'
- en: '![](../../OEBPS/Images/08-03.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/08-03.png)'
- en: Figure 8.3 Specify in the YAML to run a command inside of a container in Kubernetes.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.3 在 Kubernetes 中在容器内运行命令的 YAML 指定。
- en: Now that you’ve made your YAML, matching the YAML line in figure 8.3, make just
    one more change. Copy the three lines beginning with `command`, `image`, and `name`,
    and paste them just below the existing three lines to specify the second container.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经创建了 YAML，与图 8.3 中的 YAML 行匹配，只需进行一个更改。复制以 `command`、`image` 和 `name` 开头的三行，并将它们粘贴到现有三行下方，以指定第二个容器。
- en: EXAM TIP Being able to copy and paste in Vim can save you time on the exam!
    Select lines by pressing Shift + V on your keyboard, followed by the up and down
    arrows to select. Once you’ve selected all the lines, press the Y key to copy
    and the P key to paste. This may take some practice, but it is well worth it to
    save time on the CKA exam!
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 考试技巧：在 Vim 中能够复制粘贴可以在考试中节省你时间！通过按键盘上的 Shift + V 选择行，然后使用上下箭头选择。一旦你选择了所有行，按 Y
    键复制，按 P 键粘贴。这可能需要一些练习，但为了在 CKA 考试中节省时间，这是值得的！
- en: Now that you’ve pasted these lines, change the name of the second container
    from `busybox` to `sidecar`. Also, change the sentence `I am a busybox container`
    to `I am a sidecar container`. Leave the rest the same. The result should look
    similar to the YAML in figure 8.4, which creates two different containers with
    different names and different commands running for each.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经粘贴了这些行，将第二个容器的名称从 `busybox` 更改为 `sidecar`。同时，将句子 `I am a busybox container`
    更改为 `I am a sidecar container`。其余部分保持不变。结果应该类似于图 8.4 中的 YAML，它创建了两个具有不同名称和不同命令的不同容器。
- en: '![](../../OEBPS/Images/08-04.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/08-04.png)'
- en: Figure 8.4 Adding a second container to a Pod YAML manifest
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.4 在 Pod YAML 清单中添加第二个容器
- en: 'Now that the YAML is complete, create the Pod with the command `k apply -f
    pod.yaml`. If you were not able to follow along or are having trouble creating
    the Pod, run the command `k apply -f https://raw.githubusercontent.com/chadmcrowell/
    acing-the-cka-exam/main/ch_08/multi-container-pod-for-logging.yaml`. To view the
    Pods in the default namespace within the cluster, run the command `k get po`.
    The output should look similar to this:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在YAML已经完成，使用命令 `k apply -f pod.yaml` 创建 Pod。如果你没有跟上或者创建 Pod 有困难，运行命令 `k apply
    -f https://raw.githubusercontent.com/chadmcrowell/ acing-the-cka-exam/main/ch_08/multi-container-pod-for-logging.yaml`。要查看集群中默认命名空间内的
    Pods，运行命令 `k get po`。输出应该类似于这样：
- en: '[PRE6]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'To view the container logs from the first container named `busybox` within
    the Pod `busybox`, you can run either the command `k logs busybox` or, to be explicit,
    you can specify the container name as `k logs busybox -c busybox`. The output
    should look like this:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看 Pod `busybox` 中名为 `busybox` 的第一个容器的日志，你可以运行命令 `k logs busybox`，或者为了更明确，你可以指定容器名称为
    `k logs busybox -c busybox`。输出应该看起来像这样：
- en: '[PRE7]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'To view the logs from the second container named `sidecar` within the same
    Pod, run the command `k logs busybox -c sidecar`. The output should look like
    this:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看同一 Pod 中名为 `sidecar` 的第二个容器的日志，运行命令 `k logs busybox -c sidecar`。输出应该看起来像这样：
- en: '[PRE8]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To view the logs from both containers all at once, you can type `k logs busybox
    -all-containers`. The output should look similar to this:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 要同时查看两个容器的日志，你可以输入 `k logs busybox -all-containers`。输出应该类似于这样：
- en: '[PRE9]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: If you wanted to continue to view the logs (streaming logs), you could run the
    command `k logs nginx -all-containers -f`. To get the prompt back, press Control-C
    on your keyboard.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要继续查看日志（流式日志），你可以运行命令 `k logs nginx -all-containers -f`。要返回提示符，请按键盘上的 Control-C。
- en: EXAM TIP The help menu can really save you during the exam. Instead of trying
    to memorize the commands, use the `kubectl` help menu (e.g., `k logs -help`).
    Best of all, the help menu contains example commands, which you can simply copy
    and paste!
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 考试技巧：帮助菜单在考试中真的能帮到你。与其试图记住命令，不如使用 `kubectl` 帮助菜单（例如，`k logs -help`）。最好的是，帮助菜单包含示例命令，你可以直接复制粘贴！
- en: When you run the `k logs` command, you’re getting the same output as you would
    see in the log directory. To see the log directory, look inside the `/var/log/containers`
    directory on the node (where the Pod is running). For example, you can look at
    the `var/log/containers` directory on our control plane node and see the contents.
    You will see an output similar to figure 8.5.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行 `k logs` 命令时，你将得到与在日志目录中看到相同的输出。要查看日志目录，请查看节点上的 `/var/log/containers` 目录（Pod
    运行的地方）。例如，你可以查看我们的控制平面节点上的 `var/log/containers` 目录并查看其内容。你将看到类似于图 8.5 的输出。
- en: '![](../../OEBPS/Images/08-05.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/08-05.png)'
- en: Figure 8.5 An abbreviated output of each log file correlating to each running
    container in the `/var/log/containers` directory
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.5 `/var/log/containers` 目录中每个运行容器对应的日志文件的简略输出
- en: You’ll notice that the name of each log file begins with the Pod name followed
    by a string of unique characters (e.g., `mysql-5dcb7797...`). You can view the
    contents of this file to get an output similar to the `k logs` command. To view
    the contents of the log file, type the command `cat /var/log/containers/mysql-5dcb7797f7-6spvc_db08328_
    mysql-f9f53dc7de949452d848211d5d74aab36c2f5ae24a9d8b0b45577890d8b26ea2.log` (you
    can press Tab to complete the file name, so you don’t have to type it all out)`.`
    The output will look similar to figure 8.6.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到每个日志文件的名字都是以Pod名称开头，后面跟着一串唯一字符（例如，`mysql-5dcb7797...`）。你可以查看这个文件的 内容以获取类似于
    `k logs` 命令的输出。要查看日志文件的内容，输入命令 `cat /var/log/containers/mysql-5dcb7797f7-6spvc_db08328_mysql-f9f53dc7de949452d848211d5d74aab36c2f5ae24a9d8b0b45577890d8b26ea2.log`（你可以按Tab键完成文件名，这样你就不必全部输入）`.`
    输出将类似于图8.6。
- en: '![](../../OEBPS/Images/08-06.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/08-06.png)'
- en: Figure 8.6 Looking into the log file associated with a specific Pod
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.6 查看与特定Pod关联的日志文件
- en: What if the `k logs` command doesn’t return any log output? Let’s look at the
    decision tree in figure 8.7 to help us through the troubleshooting decision-making
    process.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 `k logs` 命令没有返回任何日志输出怎么办？让我们看看图8.7中的决策树，以帮助我们通过故障排除决策过程。
- en: '![](../../OEBPS/Images/08-07.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/08-07.png)'
- en: Figure 8.7 Decision-making process for troubleshooting Pod errors
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.7 故障排除Pod错误的决策过程
- en: 'This can happen from the container not starting in the first place. In this
    case, the next step in your troubleshooting process should be to run the `k describe`
    command to look at the events of the container. As an example, run the command
    `k run brick --image busybox --command ''while true; do echo "$(date)"; sleep
    5; done''`. This will return an error. Run the command `k get po` to list the
    Pods. You should see the following output:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是因为容器一开始就没有启动。在这种情况下，你的故障排除过程中的下一步应该是运行 `k describe` 命令来查看容器的日志。例如，运行命令 `k
    run brick --image busybox --command 'while true; do echo "$(date)"; sleep 5; done'`。这将返回一个错误。运行命令
    `k get po` 来列出Pods。你应该看到以下输出：
- en: '[PRE10]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'When you run the command `k logs brick`, you don’t receive any output because
    the container hasn’t started up yet, so it hasn’t had the opportunity to generate
    any logs. If you run the command `k describe po brick`, you will see the reason
    why this container didn’t start. The output should look like this (abbreviated
    for context):'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行 `k logs brick` 命令时，你没有收到任何输出，因为容器还没有启动，所以它还没有机会生成任何日志。如果你运行 `k describe
    po brick` 命令，你会看到这个容器没有启动的原因。输出应该类似于以下内容（为了上下文而省略）：
- en: '[PRE11]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: As you see from the output of the `k describe po brick` command, the container
    failed to start because it couldn’t start the process within, which is shown in
    both the message and the events, all within the output of the `k describe` command.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如你从 `k describe po brick` 命令的输出中看到，容器未能启动，因为它无法启动内部进程，这在 `k describe` 命令的输出中的消息和事件中都有显示。
- en: 8.1.2 Troubleshooting from inside the container
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1.2 从容器内部进行故障排除
- en: 'Because the network namespace is different inside a container than on the node,
    you may need to troubleshoot from within the container itself. This is common
    in troubleshooting scenarios, as you may not be able to open a shell to a container
    that’s in an error state (as shown previously). Run the command `k run tool --image
    lansible/ dnstools:latest -it -sh` to create a new Pod named `tool` and get a
    shell to the container within that Pod at the same time. At this point, you will
    see your prompt change. The result will look like this:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 因为容器内部的网络命名空间与节点上的不同，你可能需要从容器内部本身进行故障排除。这在故障排除场景中很常见，因为你可能无法打开一个到处于错误状态的容器的shell（如前所述）。运行命令
    `k run tool --image lansible/dnstools:latest -it -sh` 来创建一个名为 `tool` 的新Pod，并同时在那个Pod内部获取到容器的shell。此时，你会看到你的提示符发生变化。结果将类似于以下内容：
- en: '[PRE12]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'You can now enter various commands to troubleshoot from inside the container,
    in the container’s network namespace. You can run the command `nslookup Kubernetes`
    to get back the DNS server for the Kubernetes Service. The output would look similar
    to this:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以在容器内部的网络命名空间中输入各种命令来进行故障排除。你可以运行命令 `nslookup Kubernetes` 来获取Kubernetes服务的DNS服务器。输出将类似于以下内容：
- en: '[PRE13]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Once you exit out of the container, you’ll notice that the container is still
    running.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你退出容器，你会注意到容器仍在运行。
- en: EXAM TIP For the exam, if you need to troubleshoot communication to a Pod, use
    the `busybox` image and get a shell to it upon creation. This will keep the container
    running without having to insert a verbose command. For example, run the command
    `k run busybox --image busybox -it --sh`.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 考试技巧：对于考试，如果你需要排除与Pod的通信问题，请使用 `busybox` 镜像并在创建时获取一个shell。这将使容器在没有插入冗长命令的情况下继续运行。例如，运行命令
    `k run busybox --image busybox -it --sh`。
- en: 'Because the container is still running, you can use the command `k exec -it
    tool --sh` to get back into a shell within the container. The output will look
    similar to this:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 因为容器仍在运行，你可以使用命令 `k exec -it tool --sh` 来重新进入容器内的shell。输出将类似于以下内容：
- en: '[PRE14]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now that you have a shell again, run the command `curl` -`k http://10.96.0.1:443`
    to send a request to the Kubernetes Service. The output will look like this:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你再次有了shell，运行命令 `curl -k http://10.96.0.1:443` 向Kubernetes服务发送请求。输出将类似于以下内容：
- en: '[PRE15]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Go ahead and exit out once again, and now you can run a command inside the
    container without getting a shell, using the command `k exec tool --cat /etc/
    resolv.conf`. The output should look similar to this:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 再次退出，现在你可以使用命令 `k exec tool --cat /etc/resolv.conf` 在容器内运行命令而不需要获取shell。输出应该类似于以下内容：
- en: '[PRE16]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Finally, you can also get a shell to a container within a Pod, while deleting
    the Pod at the same time, with the command `k run curlpod --image=nicolaka/netshoot
    --rm -it --sh`. This will give you the same result as before, but once you exit,
    the Pod will be deleted because of using the `--rm` option with `kubectl run`.
    The output will look like this:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你还可以使用命令 `k run curlpod --image=nicolaka/netshoot --rm -it --sh` 在删除Pod的同时进入Pod内的容器。这将给出与之前相同的结果，但一旦你退出，由于使用了
    `kubectl run` 中的 `--rm` 选项，Pod将被删除。输出将类似于以下内容：
- en: '[PRE17]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Practice exercises
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 练习题
- en: Run the command `k run testbox --image busybox --command 'sleep 3600'` to create
    a new Pod named `testbox`. See if the container is running or not. Go through
    the decision tree to find out why, and fix the Pod so that it’s running.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 运行命令 `k run testbox --image busybox --command 'sleep 3600'` 来创建一个名为 `testbox`
    的新Pod。检查容器是否正在运行。通过决策树找出原因，并修复Pod使其运行。
- en: Create a new container named `busybox2` that uses the image `busybox:1.35.0`.
    Check if the container is in a running state. Find out why the container is failing,
    and make the corrections to the Pod YAML to get it running.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个名为 `busybox2` 的新容器，使用镜像 `busybox:1.35.0`。检查容器是否处于运行状态。找出容器失败的原因，并对Pod的YAML文件进行修正以使其运行。
- en: Create a new container named `curlpod2` that uses the image `nicolaka/netshoot`,
    while opening a shell to it upon creation. While a shell is open to the container,
    run `nslookup` on the Kubernetes Service. Exit out of the shell and see why the
    container is not running. Fix the container so that it continues to run.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个名为 `curlpod2` 的新容器，使用镜像 `nicolaka/netshoot`，并在创建时打开一个shell。当shell打开到容器时，运行
    `nslookup` 命令来检查Kubernetes服务。退出shell并查看为什么容器没有运行。修复容器使其继续运行。
- en: 8.2 Cluster component failure
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.2 集群组件故障
- en: When you run the `k describe` command, you won’t always find that it’s a problem
    with the container itself; it very well could be a problem with the control plane
    components that control the Pods in a Kubernetes cluster. We previously reviewed
    the control plane components in chapter 2 to help you understand each component’s
    function, which helps when troubleshooting those components in the case of a failure.
    For example, if a Pod is in a pending state and isn’t being assigned to a node,
    you know to investigate the scheduler, as this component is responsible for scheduling
    Pods to nodes. Or if the Deployment is not being scaled properly, you know to
    look at the controller manager because the controller manager is responsible for
    matching the desired state to the current state.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行 `k describe` 命令时，并不总是会发现问题是容器本身；它也可能是控制平面组件的问题，这些组件控制着Kubernetes集群中的Pod。我们在第2章中回顾了控制平面组件，以帮助你理解每个组件的功能，这在故障排除时很有帮助。例如，如果一个Pod处于挂起状态并且没有被分配到节点，你知道要调查调度器，因为这个组件负责将Pod调度到节点。或者如果Deployment没有正确扩展，你知道要查看控制器管理器，因为控制器管理器负责将期望状态与当前状态匹配。
- en: We know that the control plane components, such as the scheduler, controller
    manager, etcd, and API server, all run as Pods on the control plane node in the
    `kube-system` namespace. Therefore, the process for investigating these Pods is
    very similar to the first section of this chapter, including running the `k logs`
    and `k describe` commands to find the container logs and events. We also know
    that the YAML manifests for these control plane components are located in the
    `/etc/Kubernetes/manifests` directory, and any valid YAML file will automatically
    run here. We call this a *static Pod* because the scheduler is not aware of these
    Pods, so it cannot schedule them accordingly. An example question for the exam
    follows.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道，控制平面组件，如调度器、控制器管理器、etcd 和 API 服务器，都在 `kube-system` 命名空间中的控制平面节点上作为 Pods
    运行。因此，调查这些 Pods 的过程与本章第一部分非常相似，包括运行 `k logs` 和 `k describe` 命令以查找容器日志和事件。我们还知道，这些控制平面组件的
    YAML 清单位于 `/etc/Kubernetes/manifests` 目录中，任何有效的 YAML 文件都会自动在此运行。我们称这为 *静态 Pod*，因为调度器不知道这些
    Pods，因此无法相应地调度它们。以下是一个考试示例问题。
- en: '| Exam Task In cluster `ik8s`, in a namespace called `ee8881`, create a Deployment
    with the kubectl command line (imperatively) named `prod-app`, with the image
    `nginx`. List the Pods in the `ee8881` namespace to see if the Pod is running.
    Run the command `curl` `https://raw.githubusercontent.com/chadmcrowell/acing-the-cka-exam/main/ch_08/kube-scheduler.yaml
    --silent --output /etc/ kubernetes/manifests/kube-scheduler.yaml` to make a change
    to the kube-scheduler, simulating a cluster component failure. Now scale the Deployment
    from one replica to three. List the Pods again and see if the additional two Pods
    in the Deployment are running. Find out why the two additional Pods are not running,
    and fix the scheduler so that the containers are in a running state again. |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 考试任务 在集群 `ik8s` 中，在名为 `ee8881` 的命名空间中，使用 kubectl 命令行（命令式）创建一个名为 `prod-app`
    的 Deployment，使用镜像 `nginx`。列出 `ee8881` 命名空间中的 Pods，以查看 Pod 是否正在运行。运行命令 `curl https://raw.githubusercontent.com/chadmcrowell/acing-the-cka-exam/main/ch_08/kube-scheduler.yaml
    --silent --output /etc/kubernetes/manifests/kube-scheduler.yaml` 以对 kube-scheduler
    进行更改，模拟集群组件故障。现在将 Deployment 从一个副本扩展到三个。再次列出 Pods，并查看 Deployment 中的额外两个 Pods 是否正在运行。找出为什么这两个额外的
    Pods 没有运行，并修复调度器，使容器再次处于运行状态。|'
- en: You can continue to use the same single-node cluster that we used for the previous
    exam task. There is no need to create a new kind Kubernetes cluster.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以继续使用我们之前用于考试任务的相同单节点集群。无需创建新的 kind Kubernetes 集群。
- en: 'First, create the `ee8881` namespace with the command `k create ns ee8881`.
    Then, change the context to this new namespace with the command `k config set-context
    --current --namespace ee8881` to prevent having to type the namespace multiple
    times. The output should look like this:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，使用命令 `k create ns ee8881` 创建 `ee8881` 命名空间。然后，使用命令 `k config set-context
    --current --namespace ee8881` 将上下文更改为这个新命名空间，以避免多次输入命名空间。输出应类似于以下内容：
- en: '[PRE18]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now that your context is in the `ee8881` namespace, you can create the Deployment
    named `prod-app` with the command `k create deploy prod-app --image nginx`. Immediately
    following, you can run `k get deploy,po` to see the Deployment running and the
    Pods within. The output should look like this:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你的上下文位于 `ee8881` 命名空间，你可以使用命令 `k create deploy prod-app --image nginx` 创建名为
    `prod-app` 的 Deployment。紧接着，你可以运行 `k get deploy,po` 以查看正在运行的 Deployment 和其内的 Pods。输出应类似于以下内容：
- en: '[PRE19]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now that the Deployment is created and the Pod within the Deployment is in
    a running state, run the command `curl https://raw.githubusercontent.com/chadmcrowell/
    acing-the-cka-exam/main/ch_08/kube-scheduler.yaml --silent --output /etc/ kubernetes/manifests/kube-scheduler.yaml`
    to simulate a control plane failure. Immediately following, scale the Deployment
    from one replica to three with the command `k scale deploy prod-app -replicas
    3`. When you look at the Pods within the Deployment with the `k get po` command,
    you see that the Pods are in a pending state. The output should look similar to
    this:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在 Deployment 已创建，并且 Deployment 内的 Pod 处于运行状态，运行命令 `curl https://raw.githubusercontent.com/chadmcrowell/acing-the-cka-exam/main/ch_08/kube-scheduler.yaml
    --silent --output /etc/kubernetes/manifests/kube-scheduler.yaml` 以模拟控制平面故障。紧接着，使用命令
    `k scale deploy prod-app -replicas 3` 将 Deployment 从一个副本扩展到三个。使用 `k get po` 命令查看
    Deployment 内的 Pods，你会看到 Pods 处于挂起状态。输出应类似于以下内容：
- en: '[PRE20]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'In this case, if you run `k logs prod prod-app-85c9dd4f9d-9clfl,` you will
    not get any output, because the container was never able to start and generate
    logs. But, if you run the command `k -n kube-system logs kube-scheduler-kind-control-plane`,
    you’ll receive useful information about why the containers aren’t able to start
    up. As mentioned previously, knowing what the scheduler does in Kubernetes helps
    you find the quickest path to resolution when troubleshooting. Running the command
    `k -n kube-system logs kube-scheduler-kind-control-plane | tail -2` will show
    the last two lines of the log, which is enough for what we need to know about
    the error. The output should look like this:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，如果您运行 `k logs prod prod-app-85c9dd4f9d-9clfl,` 您将不会得到任何输出，因为容器从未能够启动并生成日志。但是，如果您运行命令
    `k -n kube-system logs kube-scheduler-kind-control-plane`，您将收到有关容器为何无法启动的有用信息。如前所述，了解调度器在Kubernetes中的工作原理有助于您在故障排除时找到最快的解决方案路径。运行命令
    `k -n kube-system logs kube-scheduler-kind-control-plane | tail -2` 将显示日志的最后两行，这对于我们了解错误已经足够。输出应该看起来像这样：
- en: '[PRE21]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This is a clue to the solution. If you look at the scheduler manifest in the
    `/etc/ kubernetes/manifests/` directory with the command `vim /etc/kubernetes/manifests/
    kube-scheduler.yaml`, you will see—toward the top of the file, under the commands
    section of the container—the reason why the scheduler is failing (figure 8.8).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这是解决问题的线索。如果您使用命令 `vim /etc/kubernetes/manifests/kube-scheduler.yaml` 在 `/etc/kubernetes/manifests/`
    目录下查看调度器清单，您将看到——在文件顶部，在容器的命令部分——调度器失败的原因（图8.8）。
- en: '![](../../OEBPS/Images/08-08.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/08-08.png)'
- en: Figure 8.8 The command that was run inside the scheduler container contains
    an extra `k` when passing in the kubeconfig.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.8 在调度器容器内部运行的命令在传递kubeconfig时包含了一个额外的 `k`。
- en: 'To fix this, we can simply edit the file by entering insert mode (pressing
    I on the keyboard) and removing the additional `k`. Once we fix this, we can exit
    Vim by first pressing the Esc key on the keyboard and then typing `:wq`, which
    will get you back to the prompt where you can see the scheduler Pod automatically
    repairing itself. You can see this with the command `k get po -A` (or `k -n kube-system
    get po`). The output should look like this:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们可以简单地通过进入插入模式（按键盘上的I键）并删除额外的 `k` 来编辑文件。一旦我们修复了这个问题，我们可以通过首先按键盘上的Esc键，然后输入
    `:wq` 来退出Vim，这将带您回到可以看到调度器Pod自动修复自己的提示符。您可以使用命令 `k get po -A`（或 `k -n kube-system
    get po`）来查看这一点。输出应该看起来像这样：
- en: '[PRE22]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: By running the `k get po -A` command, you’ll notice that the Pods from the `prod-app`
    Deployment start up at the same time, which shows that the scaling problem we
    had before has been resolved, and all three replicas within the `prod-app` Deployment
    are now in a running state. This satisfies the requirement for our exam task.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行 `k get po -A` 命令，您会注意到 `prod-app` 部署的Pod同时启动，这表明我们之前遇到的扩展问题已经解决，`prod-app`
    部署中的所有三个副本现在都处于运行状态。这满足了我们的考试任务要求。
- en: 8.2.1 Troubleshooting cluster events
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.1 故障排除集群事件
- en: 'Now that we’ve reviewed individual Pod logs for both control plane components
    and other applications, we should consider an object in Kubernetes that generates
    events for all changes in the state of a Kubernetes resource. When a Pod goes
    from pending to running, or from running to failing, an event is triggered. These
    events—where the path to resolution isn’t as clear as what we just witnessed in
    the last exam task—are useful for debugging. The object is different than regular
    log events and can tell you valuable information about the root of the problem
    at hand. Take a look at these events with the command `k get events -A`. The `-A`
    signifies all namespaces, because this object is a namespaced resource in Kubernetes.
    The output should look like this:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经审查了控制平面组件和其他应用程序的各个Pod日志，我们应该考虑Kubernetes中一个为Kubernetes资源状态的所有更改生成事件的对象。当一个Pod从挂起变为运行，或从运行变为失败时，会触发一个事件。这些事件——解决路径不像我们在上一个考试任务中看到的那样清晰——对于调试很有用。这个对象与常规日志事件不同，可以告诉您关于当前问题根源的有价值信息。使用命令
    `k get events -A` 查看这些事件。`-A` 表示所有命名空间，因为在这个对象是Kubernetes中的命名空间资源。输出应该看起来像这样：
- en: '[PRE23]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: As you can see, some valuable information is returned about the “brick” Pod
    that we were working with earlier, including the reason and the message.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，关于我们之前正在处理的“砖块”Pod，返回了一些有价值的信息，包括原因和消息。
- en: EXAM TIP For the exam, the `k get events` command may output too many events,
    including events that are “normal” messages that may not be helpful for troubleshooting.
    Use the command `k get events --field-selector type!=Normal -A` to filter out
    the normal events and only give you warning- and information-type events.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 考试提示：对于考试，`k get events`命令可能会输出太多事件，包括可能对故障排除没有帮助的“正常”消息。使用以下命令来过滤掉正常事件，只显示警告和信息类型的事件：`k
    get events --field-selector type!=Normal -A`。
- en: Keep in mind that these events are held for only 1 hour by default, so they
    might be different from the start of the exam to the end. You can set the `--event-ttl`
    option on the API server to change this, but I don’t recommend it unless the exam
    task specifically tells you to do so.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这些事件默认情况下只保留1小时，所以它们可能从考试开始到结束会有所不同。您可以在API服务器上设置`--event-ttl`选项来更改此设置，但我不建议这样做，除非考试任务明确要求您这样做。
- en: 'The inverse of filtering certain types of logs is dumping the entire cluster
    information and logs of all the Pods in the cluster. To get a verbose look at
    the health of the cluster, you can run the command `k cluster-info dump`. The
    output will be quite large, so I have modified my command to only include the
    last 10 lines here:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 过滤特定类型日志的逆操作是输出整个集群的信息以及集群中所有Pod的日志。要获取集群健康状况的详细视图，您可以运行以下命令：`k cluster-info
    dump`。输出将非常大，因此我已经修改了命令，只包括这里最后10行：
- en: '[PRE24]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'You can also grep this command to look for the words *error* or *fail*, which
    is very effective for troubleshooting when you don’t know from where the problem
    is originating. For example, run the command `k cluster-info dump | grep error`
    to only get lines that include the word *error*. Again, I have modified my command
    to shorten the output, but the command output should look like this:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用grep这个命令来查找单词*error*或*fail*，这在您不知道问题来源时进行故障排除非常有效。例如，运行以下命令以仅获取包含单词*error*的行：`k
    cluster-info dump | grep error`。再次提醒，我已经修改了我的命令以缩短输出，但命令输出应该看起来像这样：
- en: '[PRE25]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 8.2.2 Worker node failure
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.2 工作节点故障
- en: Sometimes when you’re troubleshooting the nodes of a Kubernetes cluster, it
    can be useful to look at the status of the node to see if the kubelet service
    is running. Just as you would a Pod, you can run the command `k describe no kind-control-plane`
    to find the condition of the CPU and RAM, as well as the events at the very bottom
    of the output. You may find that there are no available resources or that the
    node is in a failed state. In addition, the metrics server will already be installed
    for the exam, so don’t focus too much on the details of installing it in this
    section.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，当您在故障排除Kubernetes集群的节点时，查看节点状态以查看kubelet服务是否正在运行可能会有所帮助。就像检查Pod一样，您可以运行以下命令来找到CPU和RAM的状态，以及输出底部的事件：`k
    describe no kind-control-plane`。您可能会发现没有可用资源或节点处于失败状态。此外，考试中已经安装了指标服务器，所以在这个部分不要过多关注安装的细节。
- en: 'The metrics server allows you to check the CPU and memory usage in real time,
    and the main focus of the exam will be what commands to run to view these metrics
    in the provided terminal. Install the metrics server with the command `kubectl
    apply -f https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.5.0/
    components.yaml`. If you are following along on your own kind cluster, you’ll
    have to apply one small patch, which you can do quite easily with the command
    `kubectl patch -n kube-system deployment metrics-server --type=json -p ''[{"op":"add",
    "path":"/spec/template/spec/containers/0/args/-","value":"--kubelet-insecure -tls"}]''`.
    Wait just a few seconds (up to 60 seconds), and you should have a working metrics
    server. Test this with the command `k top no`. The output should look like this:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 指标服务器允许您实时检查CPU和内存使用情况，考试的重点将是如何在提供的终端中运行命令来查看这些指标。使用以下命令安装指标服务器：`kubectl apply
    -f https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.5.0/components.yaml`。如果您在自己的集群中跟随操作，您需要应用一个小补丁，这可以通过以下命令轻松完成：`kubectl
    patch -n kube-system deployment metrics-server --type=json -p '[{"op":"add", "path":"/spec/template/spec/containers/0/args/-","value":"--kubelet-insecure
    -tls"}]'`。等待几秒钟（最多60秒），您应该会有一个正在工作的指标服务器。使用以下命令进行测试：`k top no`。输出应该看起来像这样：
- en: '[PRE26]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: As you can see from the output, this node is consuming 177m of CPU, which is
    4% of the total CPU, and 1820 MB of memory, which is 44% of the total memory.
    This is a way to check if your Pods are not able to be scheduled to a node, because
    if they are not, they will show closer to 100% utilized using this command.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如从输出中所示，此节点正在消耗 177m 的 CPU，占总 CPU 的 4%，以及 1820 MB 的内存，占总内存的 44%。这是一种检查你的 Pods
    是否无法调度到节点的方法，因为如果它们不能，它们将使用此命令显示接近 100% 的利用率。
- en: 'In terms of checking for available disk space, you can run the command `df
    -h`, which is a command to display the free disk space on a node, and the `-h`
    option makes the output more human readable. Here’s how the output should look:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在检查可用磁盘空间方面，你可以运行命令 `df -h`，这是一个显示节点上可用磁盘空间的命令，而 `-h` 选项使输出更易于阅读。以下是输出应看起来像这样：
- en: '[PRE27]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: You can also show the state of the node by simply running the command `k get
    no`, as we have done many times before in this book. Finally, to start the kubelet
    service on a node, run the command `systemctl start kubelet`. You can also use
    Journalctl to view the logs from the kubelet service. Run the command `journalctl
    -u kubelet` to troubleshoot any problems with the kubelet service. The output
    should look like figure 8.9 (abbreviated for readability).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以通过简单地运行命令 `k get no` 来显示节点的状态，就像我们在本书中多次做的那样。最后，要在节点上启动 kubelet 服务，请运行命令
    `systemctl start kubelet`。你还可以使用 Journalctl 来查看 kubelet 服务的日志。运行命令 `journalctl
    -u kubelet` 以排除 kubelet 服务的任何问题。输出应类似于图 8.9（为了可读性进行了缩写）。
- en: '![](../../OEBPS/Images/08-09.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/08-09.png)'
- en: Figure 8.9 Abbreviated output from `journalctl` utility of the kubelet logs
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.9 kubelet 日志的 `journalctl` 工具的缩写输出
- en: Another problem with the kubelet could be the kubelet configuration. In chapter
    6, we modified the kubelet configuration while changing the cluster DNS. Along
    with the cluster DNS, some certificates are passed to the kubelet when it starts
    up to authenticate to the Kubernetes API; the cluster domain and the health Endpoints
    are also set here. On the exam, if for some reason the kubelet is not starting
    with the `systemctl start kubelet` command, check the `/var/lib/kubelet/config.yaml`
    file for misconfigurations.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: kubelet 可能存在另一个问题是 kubelet 配置。在第 6 章中，我们在更改集群 DNS 的同时修改了 kubelet 配置。当 kubelet
    启动时，一些证书会传递给 kubelet 以验证 Kubernetes API；集群域名和健康端点也在这里设置。在考试中，如果由于某种原因 kubelet
    无法通过 `systemctl start kubelet` 命令启动，请检查 `/var/lib/kubelet/config.yaml` 文件以查找配置错误。
- en: Finally, in chapter 2 we talked about the kubeconfig for the kubelet, which
    is a file named `kubelet.conf` in the `/etc/kubernetes/` directory. This will
    sometimes cause problems with accessing the cluster. To properly think through
    this troubleshooting process, review the decision tree depicted in figure 8.10.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在第 2 章中我们讨论了 kubelet 的 kubeconfig，它位于 `/etc/kubernetes/` 目录下的名为 `kubelet.conf`
    的文件。这有时会导致访问集群的问题。为了正确思考这个故障排除过程，请回顾图 8.10 中所示的决策树。
- en: '![](../../OEBPS/Images/08-10.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/08-10.png)'
- en: Figure 8.10 The decision process of troubleshooting access to the cluster
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.10 故障排除集群访问的决策过程
- en: 'Sometimes the kubelet binary is missing entirely or located in a different
    directory. You can see where the kubelet binary is located with the command `which
    kubelet`. The output looks similar to this:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 有时 kubelet 二进制文件完全缺失或位于不同的目录中。你可以使用命令 `which kubelet` 来查看 kubelet 二进制文件的位置。输出看起来类似于这样：
- en: '[PRE28]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'If the directory `/usr/bin/kubelet` is different than what’s listed when you
    run `systemctl status kubelet`, then there is a problem. Check the `10-kubeadm.conf`
    file in the `/etc/systemd/system/kubelet.service.d/` directory to see if the `ExecStart`
    is set to `/usr/bin/kubelet`. When you change the kubelet configuration, keep
    in mind that you must reload the daemon and then start the Service. Do this with
    the command `systemctl daemon-reload``,` and then the command `systemctl restart
    kubelet`, like so:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 `/usr/bin/kubelet` 目录与运行 `systemctl status kubelet` 时列出的不同，则存在问题。检查 `/etc/systemd/system/kubelet.service.d/`
    目录中的 `10-kubeadm.conf` 文件，以查看 `ExecStart` 是否设置为 `/usr/bin/kubelet`。当你更改 kubelet
    配置时，请记住你必须重新加载守护进程然后启动服务。使用命令 `systemctl daemon-reload``,` 然后使用命令 `systemctl restart
    kubelet` 来这样做：
- en: '[PRE29]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 8.2.3 Did you specify the right host or port?
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.3 你指定了正确的主机或端口吗？
- en: 'A common message you might receive when typing any `kubectl` command (e.g.,
    `kubectl get po`) is “The connection to the server $SERVER:6443 was refused -
    did you specify the right host or port?” This message occurs either because the
    API is misconfigured or your kubeconfig is not set correctly. To see this message
    in your cluster, first run the command `curl https://raw.githubusercontent.com/chadmcrowell/acing-the-cka-exam/main/ch_08/kube-apiserver.yaml
    --silent --output /etc/kubernetes /manifests/kube-scheduler.yaml` to modify the
    API server configuration. Then run the command `k get po` immediately to try to
    list the Pods running in the cluster. You will see output similar to this:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 当你输入任何`kubectl`命令（例如，`kubectl get po`）时，你可能会收到的一条常见信息是：“服务器$SERVER:6443的连接被拒绝
    - 你指定了正确的主机或端口吗？”这条信息发生的原因要么是API配置错误，要么是你的kubeconfig设置不正确。为了在你的集群中看到这条信息，首先运行命令`curl
    https://raw.githubusercontent.com/chadmcrowell/acing-the-cka-exam/main/ch_08/kube-apiserver.yaml
    --silent --output /etc/kubernetes/manifests/kube-scheduler.yaml`来修改API服务器配置。然后立即运行命令`k
    get po`来尝试列出集群中运行的Pod。你会看到类似于以下内容的输出：
- en: '[PRE30]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: If you look at the `kube-apiserver.yaml` file in the /`etc/kubernetes/manifests/
    directory`, you’ll see the problem on line 44, where the `event-ttl` is missing
    an `=` sign.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看`/etc/kubernetes/manifests/`目录下的`kube-apiserver.yaml`文件，你会在第44行看到问题，那里的`event-ttl`缺少一个`=`符号。
- en: EXAM TIP Remember, the host from which you’ll be taking the exam is not the
    same as the control plane server. You’ll want to SSH to the control plane node
    before looking for the `/etc/kubernetes/manifests/` directory.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 考试提示：记住，你将参加考试的主机与控制平面服务器不同。在寻找`/etc/kubernetes/manifests/`目录之前，你将想要SSH到控制平面节点。
- en: When you put that equal sign back in, the output should look similar to figure
    8.11.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 当你把那个等号放回去时，输出应该看起来类似于图8.11。
- en: '![](../../OEBPS/Images/08-11.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/08-11.png)'
- en: Figure 8.11 Part of the `kube-apiserver.yaml` file that includes the correct
    formatting of `event-ttl`
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.11 包含正确格式化`event-ttl`的`kube-apiserver.yaml`文件的一部分
- en: When you save and quit this file (`:wq`), you’ll realize that the message doesn’t
    go away.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 当你保存并退出此文件（`:wq`）时，你会发现信息并没有消失。
- en: EXAM TIP Don’t panic! You may modify the API config in a way that is unrecoverable.
    Along with making a backup copy of the `kube-apiserver.yaml` file before making
    a change, you can check the status of the API server Pod with `crictl`.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 考试提示：不要慌张！你可能会以无法恢复的方式修改API配置。除了在更改之前备份`kube-apiserver.yaml`文件外，你还可以使用`crictl`检查API服务器Pod的状态。
- en: 'This is okay, because we can use the `crictl` tool to restart the container.
    The `crictl` tool is handy for when you can’t use the `kubectl` command and want
    to see the state of the underlying Pods. Use the command `crictl ps` to view the
    containers, and you will see the `kube-apiserver` container in the list. The output
    will look similar to the following (this output is abbreviated) and will include
    different container IDs:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这是可以的，因为我们可以使用`crictl`工具来重启容器。当不能使用`kubectl`命令而想查看底层Pod的状态时，`crictl`工具非常方便。使用命令`crictl
    ps`来查看容器，你将看到列表中的`kube-apiserver`容器。输出将类似于以下内容（此输出已缩略）并包括不同的容器ID：
- en: '[PRE31]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The first column in this output is the container ID. Run the command `crictl
    stop 842` to stop the `kube-apiserver` container. You can use the first three
    characters of the container ID, as long as it’s unique among all the other containers
    listed by `crictl ps`. Then immediately run the command `crictl rm 842` to kill
    the container. After a few seconds, you’ll see another container spun up in its
    place. You can tell that it’s a new container because after you run `crictl ps`
    again, it has a different container ID. Once you can view the container from `crictl`
    with a status of `Running`, you can run `kubectl get po` and see that it returns
    the list of Pods again. You will no longer see the message about the right host
    or port!
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这个输出的第一列是容器ID。运行命令`crictl stop 842`来停止`kube-apiserver`容器。你可以使用容器ID的前三个字符，只要它在`crictl
    ps`列出的所有其他容器中是唯一的。然后立即运行命令`crictl rm 842`来杀死容器。几秒钟后，你会看到一个新的容器在其位置启动。你可以通过再次运行`crictl
    ps`来知道它是一个新容器，因为它的容器ID与之前不同。一旦你可以从`crictl`中看到状态为`Running`的容器，你就可以运行`kubectl get
    po`并看到它再次返回Pod列表。你将不再看到关于正确主机或端口的提示信息！
- en: 8.2.4 Troubleshooting kubeconfig
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.4 调试kubeconfig
- en: The other possibility when receiving the “Do you have the right host or port?”
    message is to check your kubeconfig to see if it’s specifying the correct control
    plane node, if the certificate is valid, and if the `KUBECONFIG` environment variable
    is set correctly. When you installed `kubectl`, or within your kind cluster, a
    hidden directory named `.kube` was created in your home directory. This contains
    the server address, the certificates to authenticate to the cluster, and the user
    information. You can view this file just like you would any other file, with the
    command `cat ~/.kube/config`, but there’s also a `kubectl` command for viewing
    the kubeconfig, which is `k config view`. The output from this command will look
    similar to figure 8.12.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 当收到“你有正确的主机或端口吗？”的消息时，另一种可能性是检查你的 kubeconfig 文件，看看它是否指定了正确的控制平面节点，证书是否有效，以及
    `KUBECONFIG` 环境变量是否设置正确。当你安装 `kubectl` 或在你的 kind 集群中时，在你的主目录中创建了一个名为 `.kube` 的隐藏目录。这个目录包含服务器地址、用于验证集群的证书以及用户信息。你可以像查看其他文件一样查看这个文件，使用命令
    `cat ~/.kube/config`，但还有一个用于查看 kubeconfig 的 `kubectl` 命令，即 `k config view`。这个命令的输出将类似于图
    8.12。
- en: '![](../../OEBPS/Images/08-12.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/08-12.png)'
- en: Figure 8.12 Output from the command `k` `config` `view`, which lists the API
    server, context, and user info
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.12 命令 `k config view` 的输出，列出了 API 服务器、上下文和用户信息
- en: EXAM TIP The result of these two commands (`cat ~/.kube/config` and `k config
    view`) may not be the same on the exam. If you’re tasked with fixing the context
    of your cluster, perhaps because you can’t list the nodes, run the command `k
    config view --flatten > ~/.kube/config` to get them synced up. This will merge
    the config files and save the output to the file config in `~/.kube/config`.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '**考试技巧** 这两个命令（`cat ~/.kube/config` 和 `k config view`）在考试中的结果可能不同。如果你被要求修复你的集群上下文，可能是因为你无法列出节点，运行命令
    `k config view --flatten > ~/.kube/config` 以同步它们。这将合并配置文件并将输出保存到 `~/.kube/config`
    目录下的 config 文件中。'
- en: 'It may be that on the exam this kubeconfig file is not present. Or perhaps
    you accidentally deleted or misconfigured it. Don’t panic! There is a copy of
    this file stored in the `/etc/kubernetes/` directory and it’s named `admin.conf`.
    You can use this along with the `kubectl` command by running the command `k get
    no --kubeconfig /etc/kubernetes/admin.conf``,` for example, or you can set a special
    environment variable named `KUBECONFIG`. This environment variable is used with
    the `kubectl` command-line utility and will point your `kubectl` commands toward
    the config file stored in the value of this variable. Run the command `KUBECONFIG=/etc/kubernetes/
    admin.conf` to set the environment variable (creating a variable name in all caps
    is common for Linux systems), and you’ll be able to access your cluster again.
    Or you can simply copy the file from the `/etc/Kubernetes/` directory to the `~/.kube/`
    directory with the command `cp /etc/kubernetes/admin.conf ~/.kube/config`. The
    output of these commands will look like this:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在考试中，这个 kubeconfig 文件可能不存在。或者你可能不小心删除或误配置了它。不要慌张！这个文件的一个副本存储在 `/etc/kubernetes/`
    目录中，名为 `admin.conf`。你可以使用这个文件以及 `kubectl` 命令，例如，通过运行命令 `k get no --kubeconfig
    /etc/kubernetes/admin.conf`，或者你可以设置一个名为 `KUBECONFIG` 的特殊环境变量。这个环境变量与 `kubectl`
    命令行工具一起使用，并将你的 `kubectl` 命令指向这个变量值中存储的配置文件。运行命令 `KUBECONFIG=/etc/kubernetes/admin.conf`
    来设置环境变量（在 Linux 系统中，使用全部大写字母创建变量名是常见的），然后你将能够再次访问你的集群。或者，你可以简单地使用命令 `cp /etc/kubernetes/admin.conf
    ~/.kube/config` 将文件从 `/etc/Kubernetes/` 目录复制到 `~/.kube/` 目录。这些命令的输出将类似于以下内容：
- en: '[PRE32]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'You’ll notice when you run the `k config view` command, as in figure 8.7, certificate
    data is redacted from the output. You can see the certificate data with the command
    `k config view -raw`. The output will look like this:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行 `k config view` 命令，如图 8.7 所示，你将注意到证书数据从输出中被删除。你可以使用命令 `k config view -raw`
    来查看证书数据。输出将类似于以下内容：
- en: '[PRE33]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'You can do this to reveal the certificate data with which you can validate
    the authenticity of the certificate and match it with the `ca.crt` certificate
    file that’s in the `/etc/Kubernetes/pki/` directory. First, run the command `k
    config view --raw -o jsonpath=''{.clusters[0].cluster.certificate-authority-data}''
    | base64 -d > ca-compare.crt` to Base64 decode the certificate from the `k config
    view --raw` command, and store the output in a file named `ca-compare.crt`. Then,
    run the command `cat /etc/kubernetes/pki/ca.crt >> ca-compare.crt` to append the
    `ca.crt` certificate in `/etc/Kubernetes/pki/ca.crt` to the same file. Open the
    file and compare the two strings of text between the words `BEGIN CERTIFICATE`
    and `END CERTIFICATE`. The output of these commands should look as follows:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过以下操作来显示证书数据，这些数据可以用来验证证书的真实性，并将其与 `/etc/Kubernetes/pki/` 目录中的 `ca.crt`
    证书文件进行匹配。首先，运行命令 `k config view --raw -o jsonpath='{.clusters[0].cluster.certificate-authority-data}'
    | base64 -d > ca-compare.crt` 以 Base64 解码 `k config view --raw` 命令中的证书，并将输出存储在名为
    `ca-compare.crt` 的文件中。然后，运行命令 `cat /etc/kubernetes/pki/ca.crt >> ca-compare.crt`
    将 `/etc/Kubernetes/pki/ca.crt` 中的 `ca.crt` 证书追加到同一文件中。打开文件，并比较 `BEGIN CERTIFICATE`
    和 `END CERTIFICATE` 之间的两行文本。这些命令的输出应如下所示：
- en: '[PRE34]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Along with the certificates, check that the server address is correct in the
    kubeconfig file. You can check this by comparing the output of the `k config view`
    command with the output of the `k cluster-info` command. Usually, the exam will
    use an IP address instead of the DNS name. In that case, you can check the private
    IP address of the control plane server (remember to first SSH to the control plane
    server if attempting this on the exam) by running the command `ip addr | grep
    eth0`. The output should look like this:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 除了证书外，还要检查 kubeconfig 文件中的服务器地址是否正确。你可以通过比较 `k config view` 命令的输出与 `k cluster-info`
    命令的输出来进行检查。通常，考试会使用 IP 地址而不是 DNS 名称。在这种情况下，你可以通过运行命令 `ip addr | grep eth0` 来检查控制平面服务器的私有
    IP 地址（如果在考试中尝试此操作，请记住首先 SSH 到控制平面服务器）。输出应如下所示：
- en: '[PRE35]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: If you take off the grep for `eth0`, you’ll see the `veth` interfaces—the virtual
    Ethernet devices for the containers running on the control plane node—which we
    went over in greater detail in chapter 2 where we were investigating the virtual
    network interface within a container.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你移除了对 `eth0` 的 grep，你会看到 `veth` 接口——运行在控制平面节点上的容器的虚拟以太网设备，我们已经在第 2 章中详细讨论过，当时我们正在调查容器内的虚拟网络接口。
- en: Exam exercises
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 考试练习
- en: Move the file `kube-scheduler.yaml` to the `/tmp` directory with the command
    `mv /etc/Kubernetes/manifests/kube-scheduler.yaml /tmp/kube-scheduler.yaml`.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 使用命令 `mv /etc/Kubernetes/manifests/kube-scheduler.yaml /tmp/kube-scheduler.yaml`
    将文件 `kube-scheduler.yaml` 移动到 `/tmp` 目录。
- en: Create a Pod with the command `k run nginx -image nginx`. List the Pods and
    see if the Pod is in a running state.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 使用命令 `k run nginx -image nginx` 创建一个 Pod。列出 Pod，看看 Pod 是否处于运行状态。
- en: Determine why the Pod is not starting by looking at the events and the logs.
    Determine how to fix it and get the Pod back in a running state.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看事件和日志来确定 Pod 为什么没有启动。确定如何修复它，并将 Pod 恢复到运行状态。
- en: Run the command `curl https://raw.githubusercontent.com/chadmcrowell/ acing-the-cka-exam/main/ch_08/10-kubeadm.conf
    --silent --output /etc/ systemd/system/kubelet.service.d/10-kubeadm.conf; systemctl
    daemon-reload; systemctl restart kubelet.`
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 运行命令 `curl https://raw.githubusercontent.com/chadmcrowell/ acing-the-cka-exam/main/ch_08/10-kubeadm.conf
    --silent --output /etc/ systemd/system/kubelet.service.d/10-kubeadm.conf; systemctl
    daemon-reload; systemctl restart kubelet.`。
- en: Check the status of the kubelet, and go through the troubleshooting steps to
    resolve the problem with the kubelet service.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 检查 kubelet 的状态，并按照故障排除步骤解决 kubelet 服务的问题。
- en: 8.3 Network troubleshooting
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.3 网络故障排除
- en: As you already know, Pod-to-Pod communication happens via CNI. If the node is
    not in a ready state or the containers are unable to create IP addresses, you
    have a problem with the network within the cluster or the container network interface.
    You already know from the CKA exam handbook that one of your clusters will have
    a loopback CNI, which may or may not require troubleshooting or fixing the CNI
    in some way. Regardless of which CNI is used, the exam will always give you either
    a YAML file with which to install the CNI or a link for where to find it. This
    question comes up a lot, and I want to assure you that *you will not* have to
    memorize the steps to install a CNI on the exam.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所知，Pod 之间的通信是通过 CNI 进行的。如果节点不在就绪状态或容器无法创建 IP 地址，那么你就有集群内部或容器网络接口的网络问题。你已经从
    CKA 考试手册中知道，你的一个集群将有一个回环 CNI，这可能需要或不需要对 CNI 进行故障排除或以某种方式修复 CNI。无论使用哪种 CNI，考试都会始终提供用于安装
    CNI 的 YAML 文件或指向其位置的链接。这个问题经常出现，我想向你保证 *你不需要* 在考试中记住安装 CNI 的步骤。
- en: 8.3.1 Troubleshooting the config
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3.1 配置故障排除
- en: When trying to troubleshoot network problems, various concerns must be considered.
    After you’ve evaluated the decision tree, the resolution still might not be clear.
    You should pay special attention to common misspellings in the error message details.
    For example, a question on the exam might look like the following.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 当尝试排除网络问题时，必须考虑各种因素。在你评估了决策树之后，解决方案可能仍然不清楚。你应该特别注意错误消息细节中的常见拼写错误。例如，考试中的一个问题可能看起来如下。
- en: '| Exam TasK In cluster `ik8s`, run the command `k replace -f https://raw .githubusercontent.com/chadmcrowell/acing-the-cka-exam/main/ch_08/kube-proxy-configmap.yaml
    -force` to purposely insert a bug in the cluster. Immediately after that, delete
    the kube-proxy Pod in the `kube-system` namespace (it will automatically recreate).
    List the Pods in the namespace, and see that the kube-proxy Pod is in an error
    state. View the logs to determine why the kube-proxy Pod is not running. Once
    you’ve collected the necessary log information, make the changes to fix the Pod
    and get the Pod back up in a running, healthy state. |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| 考试任务 在集群 `ik8s` 中，运行命令 `k replace -f https://raw.githubusercontent.com/chadmcrowell/acing-the-cka-exam/main/ch_08/kube-proxy-configmap.yaml
    -force` 故意向集群中插入一个错误。立即之后，删除 `kube-system` 命名空间中的 kube-proxy Pod（它将自动重新创建）。列出命名空间中的
    Pods，并查看 kube-proxy Pod 处于错误状态。查看日志以确定 kube-proxy Pod 为什么没有运行。一旦你收集了必要的日志信息，对
    Pod 进行更改以修复它，并使其恢复到运行、健康的状态。|'
- en: You can continue to use the same single-node cluster that we used for the previous
    exam task. There is no need to create a new kind Kubernetes cluster.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以继续使用之前考试任务中使用的相同单节点集群。没有必要创建一个新的 kind Kubernetes 集群。
- en: 'First, run the command `k replace -f https://raw.githubusercontent.com/ chadmcrowell/acing-the-cka-exam/main/ch_08/kube-proxy-configmap.yaml
    -force` as instructed in the exam task. The output will look as follows:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，按照考试任务中的说明运行命令 `k replace -f https://raw.githubusercontent.com/chadmcrowell/acing-the-cka-exam/main/ch_08/kube-proxy-configmap.yaml
    -force`。输出将如下所示：
- en: '[PRE36]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Delete the kube-proxy Pod with the command `k -n kube-system delete po kube-proxy-k7dt6`
    (the Pod name will be different for each cluster).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 使用命令 `k -n kube-system delete po kube-proxy-k7dt6` 删除 kube-proxy Pod（每个集群的 Pod
    名称可能不同）。
- en: EXAM TIP To save time, type the `kubectl` command with the namespace first (e.g.,
    `k -n kube-system...`). This allows you to hit the Tab key on the keyboard to
    autocomplete the names of resources within that namespace (e.g., Pods). This is
    especially useful for Deployments, where the names are usually quite long. It
    also prevents typos, which are a waste of time and might cost you a few points
    on the exam.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 考试技巧 为了节省时间，先输入带有命名空间的 `kubectl` 命令（例如，`k -n kube-system...`）。这允许你在键盘上按 Tab
    键来自动补全该命名空间内资源的名称（例如，Pods）。这对于名称通常相当长的 Deployments 特别有用。它还可以防止输入错误，这会浪费你的时间，并在考试中可能让你失去一些分数。
- en: 'We can list the Pods in the `kube-system` namespace with the command `k -n
    kube-system get po` or `k get po -A`. The output will look similar to this:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用命令 `k -n kube-system get po` 或 `k get po -A` 列出 `kube-system` 命名空间中的 Pods。输出将类似于以下内容：
- en: '[PRE37]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'By running this command, the Pod `kube-proxy-chc4w` is in a `CrashLoopBackOff`.
    Note that the Pod name will be different for each cluster; therefore, the characters
    after `kube-proxy-` will be different for you. Let’s run the command `k -n kube-system
    logs kube-proxy-chc4w` to view the logs and find out why the Pod is failing. The
    output from this command will be similar to this:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行此命令，Pod `kube-proxy-chc4w`处于`CrashLoopBackOff`状态。请注意，Pod名称对于每个集群都是不同的；因此，`kube-proxy-`后面的字符对于你来说将是不同的。让我们运行命令`k
    -n kube-system logs kube-proxy-chc4w`来查看日志并找出Pod失败的原因。此命令的输出将类似于以下内容：
- en: '[PRE38]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'A lot of useful information comes from this output—in particular, the line
    `/var/lib/ kube-proxy/kubeconfigd.conf: no such file or directory`, which tells
    us that there’s a problem with the configuration of kube-proxy. We know this because
    files ending in `.conf` usually coincide with configuration files on Linux systems.
    Also, notice that the word `kubeconfig` has a `d` at the end. To double-check
    if this is correct, search in the Kubernetes docs ([https://kubernetes.io/docs](https://kubernetes.io/docs));
    it autocorrects to “Did you mean kubeconfig.conf?”'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '从这个输出中可以得到很多有用的信息——特别是`/var/lib/kube-proxy/kubeconfigd.conf: no such file or
    directory`这一行，它告诉我们kube-proxy的配置存在问题。我们知道这是因为以`.conf`结尾的文件通常与Linux系统上的配置文件相对应。此外，请注意`kubeconfig`这个词的末尾有一个`d`。为了双重检查这是否正确，请在Kubernetes文档([https://kubernetes.io/docs](https://kubernetes.io/docs))中搜索；它会自动更正为“你是指kubeconfig.conf吗？”'
- en: We know after having read chapter 6 that the configuration for kube-proxy is
    stored inside of a ConfigMap in the `kube-system` namespace. Open it in Vim and
    see if you can spot if there’s a line matching `/var/lib/kube-proxy/kubeconfigd.conf`.
    Most likely we’ll have to make edits in this file, so we can use the command `k
    -n kube-system edit cm kube-proxy` to open the ConfigMap in Vim and make the necessary
    changes. The partial contents of the file are shown in figure 8.13\. We see that,
    in fact, a line matches one of the lines from our logs; change the `kubeconfigd.conf`
    to `kubeconfig .conf` to see if that fixes it.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读了第6章之后，我们知道kube-proxy的配置存储在`kube-system`命名空间下的ConfigMap中。在Vim中打开它，看看是否能找到匹配`/var/lib/kube-proxy/kubeconfigd.conf`的行。很可能会在这个文件中需要做出修改，因此我们可以使用命令`k
    -n kube-system edit cm kube-proxy`在Vim中打开ConfigMap并做出必要的更改。文件的部分内容如图8.13所示。我们看到实际上有一行与我们的日志中的一行匹配；将`kubeconfigd.conf`改为`kubeconfig
    .conf`以查看是否可以修复问题。
- en: '![](../../OEBPS/Images/08-13.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![图8.13](../../OEBPS/Images/08-13.png)'
- en: Figure 8.13 Editing the ConfigMap for kube-proxy, we notice that a line should
    be changed in the client connection.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.13 编辑kube-proxy的ConfigMap，我们注意到客户端连接中应该修改一行。
- en: 'After we make that change and save the file (`:wq`), delete the kube-proxy
    Pod once again so the DaemonSet can recreate it and apply the configuration changes
    we just made in the ConfigMap. To do this, we’ll perform the command `k -n kube-system
    delete po kube-proxy-chc4w` and then immediately list the Pods in the `kube-system`
    namespace again with the command `k -n kube-system get po`. The output will look
    similar to this:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们做出更改并保存文件（`:wq`）之后，再次删除kube-proxy Pod，以便DaemonSet可以重新创建它并应用我们在ConfigMap中刚刚做出的配置更改。为此，我们将执行命令`k
    -n kube-system delete po kube-proxy-chc4w`，然后立即使用命令`k -n kube-system get po`再次列出`kube-system`命名空间中的Pod。输出将类似于以下内容：
- en: '[PRE39]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: We notice that the kube-proxy Pod is in a running state again. This completes
    our exam task, as the Pod is back in a running state once again and the function
    of kube-proxy is restored.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到kube-proxy Pod又处于运行状态。这完成了我们的考试任务，因为Pod再次回到运行状态，kube-proxy的功能也得以恢复。
- en: 'Kube-proxy is a component that may need troubleshooting on the exam, as it
    is responsible for creating iptables rules (firewall rules) for Pod network communication
    in the cluster. The kube-proxy Pod will make sure that requests to Services reach
    the underlying Pods associated with that Service. You can see the kube-proxy listening
    and monitoring the network activity with the `netstat` tool. The `netstat` tool
    will already be installed for the exam, but if you’d like to practice in your
    own cluster, run the command `netstat -plan | grep kube-proxy` to view the ports
    that kube-proxy is active on and listening to within the cluster. (To install
    `netstat`, run the command `apt update; apt install net-tools`). The output will
    look similar to this:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: Kube-proxy 是一个可能在考试中需要故障排除的组件，因为它负责在集群中为 Pod 网络通信创建 iptables 规则（防火墙规则）。kube-proxy
    Pod 将确保对服务的请求能够到达与该服务关联的底层 Pod。您可以使用 `netstat` 工具看到 kube-proxy 正在监听和监控网络活动。考试中
    `netstat` 工具已经安装好，但如果您想在您的集群中练习，请运行命令 `netstat -plan | grep kube-proxy` 以查看 kube-proxy
    在集群中活跃并监听的端口。要安装 `netstat`，请运行命令 `apt update; apt install net-tools`。输出将类似于以下内容：
- en: '[PRE40]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Kube-proxy runs on each node as a DaemonSet in the Kubernetes cluster. You
    can list the DaemonSets in all namespaces by running the command `k get ds -A`.
    The output will look similar to this:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: Kube-proxy 在 Kubernetes 集群中的每个节点上作为 DaemonSet 运行。您可以通过运行命令 `k get ds -A` 列出所有命名空间中的
    DaemonSet。输出将类似于以下内容：
- en: '[PRE41]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'This component is installed when you first initialize the cluster. There’s
    not a manifest for it like there is for the other cluster components, however,
    so some people get confused. Also, CoreDNS and kube-proxy can easily be reset
    (i.e., recreated) with the command `kubeadm init phase addon all`. So, if on the
    exam the kube-proxy Pod in the `kube-system` namespace is erroring or in a `CrashLoopBackOff`,
    then running the command `kubeadm init phase addon all` will be a quick way to
    solve your problem, as it recreates the Pod with the default configuration (as
    initially set when the cluster was first initialized). A Service Account and a
    ConfigMap are also created for kube-proxy, and they are located in the `kube-system`
    namespace. You can view them with the command `k -n kube-system get cm,sa | grep
    kube-proxy`. The output will look similar to this:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 此组件在您首次初始化集群时安装。与其他集群组件不同，它没有清单，因此有些人会感到困惑。此外，CoreDNS 和 kube-proxy 可以通过命令 `kubeadm
    init phase addon all` 轻易地重置（即重新创建）。因此，如果在考试中 `kube-system` 命名空间中的 kube-proxy Pod
    出错或处于 `CrashLoopBackOff` 状态，运行命令 `kubeadm init phase addon all` 将是一个快速解决问题的方法，因为它会使用默认配置（在集群首次初始化时设置）重新创建
    Pod。还会为 kube-proxy 创建一个服务账户和一个 ConfigMap，它们位于 `kube-system` 命名空间中。您可以使用命令 `k -n
    kube-system get cm,sa | grep kube-proxy` 查看它们。输出将类似于以下内容：
- en: '[PRE42]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 8.3.2 Troubleshooting Services
  id: totrans-215
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3.2 服务故障排除
- en: For the exam, you may be presented with a Service that cannot reach the underlying
    Pods. To properly troubleshoot, check the labels and the ports that the Pods are
    communicating over, both on the Service and the Deployment. For example, an exam
    task may be as follows.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 对于考试，您可能会遇到一个无法到达底层 Pod 的服务。为了正确地故障排除，请检查 Pod 在服务和部署中通信的标签和端口。例如，一个考试任务可能如下所示。
- en: '| Exam Task In cluster `ik8s`, in a namespace called `kb6656`, run the command
    `k apply -f https://raw.githubusercontent.com/chadmcrowell/acing-the-cka-exam/main/ch_08/deploy-and-svc.yaml`
    to create a Deployment and Service in the cluster. This is an NGINX application
    running on port 80, so try to reach the application by using curl to reach the
    IP address and port of the Service. Once you realize that you cannot communicate
    with the application via curl, try to determine why. Make the necessary changes
    to reach the application using curl and return to the NGINX welcome page. |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| 考试任务：在集群 `ik8s` 中，名为 `kb6656` 的命名空间中，运行命令 `k apply -f https://raw.githubusercontent.com/chadmcrowell/acing-the-cka-exam/main/ch_08/deploy-and-svc.yaml`
    以在集群中创建 Deployment 和 Service。这是一个运行在端口 80 上的 NGINX 应用程序，因此请尝试使用 curl 通过服务的 IP
    地址和端口来访问应用程序。一旦您意识到无法通过 curl 与应用程序通信，请尝试确定原因。进行必要的更改，使用 curl 访问应用程序并返回到 NGINX
    欢迎页面。 |'
- en: 'We can continue to use the same single-node cluster that we used for the previous
    exam task. There is no need to create a new kind Kubernetes cluster. First, we’ll
    create the namespace with the command `k create ns kb6656`. We can switch our
    context to that namespace with the command `k config set-context --current --namespace
    kb6656`. Then, we’ll run the command given to us in the exam task. That command
    again was `k apply -f https://raw.githubusercontent.com/chadmcrowell/acing-the-cka-exam/main/ch_08/deploy-and-svc.yaml``.`
    This will create the Deployment and Service, and we can view them with the command
    `k get deploy,svc`. The output should look similar to this:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以继续使用之前考试任务中使用的相同单节点集群。没有必要创建一个新的Kubernetes集群。首先，我们将使用命令 `k create ns kb6656`
    创建命名空间。我们可以使用命令 `k config set-context --current --namespace kb6656` 切换到该命名空间。然后，我们将运行考试任务中给出的命令。该命令再次是
    `k apply -f https://raw.githubusercontent.com/chadmcrowell/acing-the-cka-exam/main/ch_08/deploy-and-svc.yaml`。这将创建部署和服务，我们可以使用命令
    `k get deploy,svc` 查看它们。输出应该类似于以下内容：
- en: '[PRE43]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Once the Deployment and Service have been created, we can reach out to the
    NGINX application with curl using the command `curl -k http://10.96.119.24`. The
    output should look like this:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦创建了部署和服务，我们就可以使用curl命令通过 `curl -k http://10.96.119.24` 来访问NGINX应用程序。输出应该类似于以下内容：
- en: '[PRE44]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Notice that it failed to connect. You may have noticed already that when we
    listed the Service, the port was 3306, not 80\. Let’s change it to 80 and see
    if that fixes our problem. We can run the command `k edit svc nginx-svc` to edit
    the port on which our Service is exposed. This command will open the YAML in the
    Vim text editor and allow us to change the port from 3306 to 80\. We’ll save and
    quit (`:wq`) and then try our curl command again. The output of the command will
    look like this:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 注意它未能连接。你可能已经注意到，当我们列出服务时，端口是3306，而不是80。让我们将其更改为80，看看是否可以解决这个问题。我们可以运行命令 `k
    edit svc nginx-svc` 来编辑服务暴露的端口。此命令将在Vim文本编辑器中打开YAML文件，并允许我们将端口从3306更改为80。我们将保存并退出（`:wq`），然后再次尝试我们的curl命令。命令的输出将类似于以下内容：
- en: '[PRE45]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Changing the port for the Service fixed our problem. This is a frequent problem
    that you’ll be tasked with on the exam. Check that the ports of the Service match
    the ports of the Pod (e.g., running inside of a Deployment). Also, sometimes a
    label mismatch between Service and Deployment might occur. If we view the Service
    again with the command `k get svc -o yaml`, we’ll see that the selector is set
    to direct all traffic to Pods with the label `app=nginx`. The output looks similar
    to figure 8.14.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 更改服务的端口解决了我们的问题。这是考试中你可能会被要求解决的问题之一。检查服务的端口是否与Pod的端口匹配（例如，在部署内部运行）。有时，服务和部署之间可能会发生标签不匹配。如果我们再次使用命令
    `k get svc -o yaml` 查看服务，我们会看到选择器被设置为将所有流量导向带有标签 `app=nginx` 的Pod。输出看起来类似于图8.14。
- en: '![](../../OEBPS/Images/08-14.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/08-14.png)'
- en: Figure 8.14 The output of `k` `get` `svc` `-o` `yaml` shows us the selector,
    which tells the Service which Pods to direct traffic to.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.14 `k` `get` `svc` `-o` `yaml` 的输出显示了选择器，它告诉服务将流量导向哪些Pod。
- en: 'If we list the Pod labels with the command `k get po --show-labels`, we’ll
    see that the Pod in this NGINX Deployment does in fact have the label `app=nginx`.
    The output will look similar to this:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用命令 `k get po --show-labels` 列出Pod标签，我们会看到这个NGINX部署中的Pod确实有标签 `app=nginx`。输出将类似于以下内容：
- en: '[PRE46]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 8.3.3 Troubleshooting cluster-wide communications
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3.3 故障排除集群通信
- en: In addition to incorrect ports on the Service in Kubernetes, there are other
    concerns to watch for that would require you to know how resources communicate
    with each other in Kubernetes. In general, a Deployment is connected to a Service
    through a label selector on the Service itself. If the Service label selector
    is not correct, the application will become unreachable. Also, with every Service
    there is at least one Endpoint, which is the Pod IP address. If there are no Endpoints
    for a Service, check again to see if the label selector is correct, so the Service
    can direct traffic to the correct Deployment or Pod.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 除了Kubernetes中服务上的端口不正确之外，还有其他需要关注的问题，这需要你了解资源如何在Kubernetes中相互通信。一般来说，部署通过服务本身的标签选择器连接到服务。如果服务标签选择器不正确，应用程序将变得不可访问。此外，每个服务至少有一个端点，即Pod
    IP地址。如果没有服务端点，请再次检查标签选择器是否正确，以便服务可以将流量导向正确的部署或Pod。
- en: EXAM TIP To compare what the correct label selectors are, and whether your YAML
    syntax is correct, run the command `k create deploy nginx -image ngnix -dry-run=client
    -o yaml`, followed by `k expose deploy nginx`. This will save you time, as you
    can just copy and paste or easily compare the two files.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 考试技巧 要比较正确的标签选择器，以及你的 YAML 语法是否正确，请运行命令 `k create deploy nginx -image ngnix
    -dry-run=client -o yaml`，然后运行 `k expose deploy nginx`。这将节省你的时间，因为你可以直接复制粘贴或轻松比较这两个文件。
- en: Summary
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: To view the logs in a Pod, we can use the `kubectl` command-line utility or
    look in the `/var/logs/containers` directory.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要查看 Pod 中的日志，我们可以使用 `kubectl` 命令行工具或查看 `/var/logs/containers` 目录。
- en: There are many different Pod statuses, logs, and events to begin the troubleshooting
    decision-making process. A Pod can be in a running state but still not accessible
    through the frontend.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有许多不同的 Pod 状态、日志和事件，可以作为故障排除决策过程的起点。一个 Pod 可能处于运行状态，但仍然无法通过前端访问。
- en: We can view cluster-wide events that determine from where the error is coming
    and what correlates to that error within the cluster.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以查看集群范围内的事件，以确定错误来源以及集群内与该错误相关的内容。
- en: We can monitor the cluster metrics with the metrics server, which will already
    be installed within the exam environment.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以使用指标服务器监控集群指标，该服务器已经在考试环境中安装。
- en: We can identify problems with our control plane components by looking within
    the `kube-system` namespace. Knowing what each component does will help you get
    to the root of the problem.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以通过查看 `kube-system` 命名空间来识别我们的控制平面组件的问题。了解每个组件的功能将有助于你找到问题的根源。
- en: We can identify network problems by looking at the kube-proxy, as it is the
    facilitator of firewalled traffic from Pod to Pod within a cluster. We can also
    see if a CNI is installed in our cluster to determine network problems.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以通过查看 kube-proxy 来识别网络问题，因为它是集群内 Pod 到 Pod 之间防火墙流量的促进者。我们还可以查看我们的集群中是否安装了
    CNI，以确定网络问题。
- en: We can look for the correct ports and labels on a Service and Deployment on
    the exam, which will help to identify if that is at the root of why we can’t connect
    to the application.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以在考试中的 Service 和 Deployment 上查找正确的端口和标签，这有助于确定我们无法连接到应用程序的根本原因。
