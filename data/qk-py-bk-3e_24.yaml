- en: Chapter 21\. Processing data files
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 21 章：处理数据文件
- en: '*This chapter covers*'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章涵盖*'
- en: Using ETL (extract-transform-load)
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 ETL（提取-转换-加载）
- en: Reading text data files (plain text and CSV)
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 读取文本数据文件（纯文本和 CSV）
- en: Reading spreadsheet files
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 读取电子表格文件
- en: Normalizing, cleaning, and sorting data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准化、清洗和排序数据
- en: Writing data files
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写数据文件
- en: Much of the data available is contained in text files. This data can range from
    unstructured text, such as a corpus of tweets or literary texts, to more structured
    data in which each row is a record and the fields are delimited by a special character,
    such as a comma, a tab, or a pipe (|). Text files can be huge; a data set can
    be spread over tens or even hundreds of files, and the data in it can be incomplete
    or horribly dirty. With all the variations, it’s almost inevitable that you’ll
    need to read and use data from text files. This chapter gives you strategies for
    using Python to do exactly that.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 大部分可用的数据都包含在文本文件中。这些数据可以从无结构的文本，如推文或文学文本的语料库，到更结构化的数据，其中每一行是一个记录，字段由特殊字符分隔，如逗号、制表符或管道（|）。文本文件可能非常大；一个数据集可能分布在十个甚至数百个文件中，其中的数据可能不完整或非常脏。在所有这些变化中，几乎不可避免的是，你需要读取和使用文本文件中的数据。本章为你提供了使用
    Python 实现这一点的策略。
- en: 21.1\. Welcome to ETL
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 21.1\. 欢迎来到 ETL
- en: 'The need to get data out of files, parse it, turn it into a useful format,
    and then do something with it has been around for as long as there have been data
    files. In fact, there is a standard term for the process: extract-transform-load
    (ETL). The extraction refers to the process of reading a data source and parsing
    it, if necessary. The transformation can be cleaning and normalizing the data,
    as well as combining, breaking up, or reorganizing the records it contains. The
    loading refers to storing the transformed data in a new place, either a different
    file or a database. This chapter deals with the basics of ETL in Python, starting
    with text-based data files and storing the transformed data in other files. I
    look at more structured data files in [chapter 22](kindle_split_035.html#ch22)
    and storage in databases in [chapter 23](kindle_split_036.html#ch23).'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 从文件中获取数据、解析它、将其转换为有用的格式，然后对其进行操作的需求，与数据文件存在的时间一样长。事实上，这个过程有一个标准的术语：提取-转换-加载（ETL）。提取指的是读取数据源并解析它，如果需要的话。转换可以是清洗和标准化数据，以及合并、拆分或重新组织它所包含的记录。加载指的是将转换后的数据存储在新的位置，无论是不同的文件还是数据库。本章将介绍
    Python 中 ETL 的基础知识，从基于文本的数据文件开始，并将转换后的数据存储在其他文件中。我将在第 22 章（kindle_split_035.html#ch22）中查看更结构化的数据文件，在第
    23 章（kindle_split_036.html#ch23）中查看数据库存储。
- en: 21.2\. Reading text files
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 21.2\. 读取文本文件
- en: The first part of ETL—the “extract” portion—involves opening a file and reading
    its contents. This process seems like a simple one, but even at this point there
    can be issues, such as the file’s size. If a file is too large to fit into memory
    and be manipulated, you need to structure your code to handle smaller segments
    of the file, possibly operating one line at a time.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ETL 的第一部分——“提取”部分——涉及打开一个文件并读取其内容。这个过程看似简单，但即使在这个阶段也可能出现问题，例如文件的大小。如果一个文件太大，无法放入内存并操作，你需要对你的代码进行结构化以处理文件的小部分，可能是一行一行地操作。
- en: '21.2.1\. Text encoding: ASCII, Unicode, and others'
  id: totrans-12
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 21.2.1\. 文本编码：ASCII、Unicode 及其他
- en: Another possible pitfall is in the encoding. This chapter deals with text files,
    and in fact, much of the data exchanged in the real world is in text files. But
    the exact nature of *text* can vary from application to application, from person
    to person, and of course from country to country.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个可能的陷阱是在编码上。本章涉及文本文件，实际上，在现实世界中交换的大部分数据都在文本文件中。但“文本”的确切性质可能因应用程序而异，因人而异，当然也因国家而异。
- en: Sometimes, *text* means something in the ASCII encoding, which has 128 characters,
    only 95 of which are printable. The good news about ASCII encoding is that it’s
    the lowest common denominator of most data exchange. The bad news is that it doesn’t
    begin to handle the complexities of the many alphabets and writing systems of
    the world. Reading files using ASCII encoding is almost certain to cause trouble
    and throw errors on character values that it doesn’t understand, whether it’s
    a German ü, a Portuguese ç, or something from almost any language other than English.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，*文本*在 ASCII 编码中意味着某种含义，ASCII 编码有 128 个字符，其中只有 95 个是可打印的。关于 ASCII 编码的好消息是，它是大多数数据交换的最低共同分母。坏消息是，它根本无法处理世界上许多字母表和书写系统的复杂性。使用
    ASCII 编码读取文件几乎肯定会引起麻烦并抛出错误，无论是德语的 ü、葡萄牙语的 ç，还是除了英语之外几乎任何语言的字符值。
- en: These errors arise because ASCII is based on 7-bit values, whereas the bytes
    in a typical file are 8 bits, allowing 256 possible values as opposed to the 128
    of a 7-bit value. It’s routine to use those additional values to store additional
    characters—anything from extra punctuation (such as the printer’s en dash and
    em dash) to symbols (such as the trademark, copyright, and degree symbols) to
    accented versions of alphabetical characters. The problem has always been that
    if, in reading a text file, you encounter a character in the 128 outside the ASCII
    range, you have no way of knowing for sure how it was encoded. Is the character
    value of 214, say, a division symbol, an Ö, or something else? Short of having
    the code that created the file, you have no way to know.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这些错误产生的原因是，ASCII 基于的是 7 位值，而典型文件中的字节是 8 位，因此可以有 256 种可能的值，而 7 位值只有 128 种。使用这些额外的值来存储额外的字符是常规操作——从额外的标点符号（例如打印机的
    en 连字符和 em 连字符）到符号（例如商标、版权和度数符号）再到带音标的字母字符。问题始终在于，如果在读取文本文件时遇到 ASCII 范围之外的 128
    个字符，你无法确定它是如何编码的。比如说，字符值 214 是除号、Ö 还是其他什么符号？除非你有创建文件的代码，否则你无法知道。
- en: Unicode and UTF-8
  id: totrans-16
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Unicode 和 UTF-8
- en: One way to mitigate this confusion is Unicode. The Unicode encoding called UTF-8
    accepts the basic ASCII characters without any change but also allows an almost
    unlimited set of other characters and symbols according to the Unicode standard.
    Because of its flexibility, UTF-8 was used in more 85% of web pages served at
    the time I wrote this chapter, which means that your best bet for reading text
    files is to assume UTF-8 encoding. If the files contain only ASCII characters,
    they’ll still be read correctly, but you’ll also be covered if other characters
    are encoded in UTF-8\. The good news is that the Python 3 string data type was
    designed to handle Unicode by default.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 缓解这种混淆的一种方法就是 Unicode。UTF-8 编码的 Unicode 接受基本的 ASCII 字符而不做任何改变，但同时也允许根据 Unicode
    标准使用几乎无限多的其他字符和符号。由于其灵活性，UTF-8 在我写这一章的时候被用于超过 85% 的网页中，这意味着你阅读文本文件的最佳选择是假设 UTF-8
    编码。如果文件只包含 ASCII 字符，它们仍然会被正确读取，但如果你遇到其他以 UTF-8 编码的字符，你也会有所准备。好消息是，Python 3 的字符串数据类型默认设计为处理
    Unicode。
- en: Even with Unicode, there’ll be occasions when your text contains values that
    can’t be successfully encoded. Fortunately, the `open` function in Python accepts
    an optional errors parameter that tells it how to deal with encoding errors when
    reading or writing files. The default option is `'strict'`, which causes an error
    to be raised whenever an encoding error is encountered. Other useful options are
    `'ignore'`, which causes the character causing the error to be skipped; `'replace'`,
    which causes the character to be replaced by a marker character (often, ?); `'backslashreplace'`,
    which replaces the character with a backslash escape sequence; and `'surrogateescape'`,
    which translates the offending character to a private Unicode code point on reading
    and back to the original sequence of bytes on writing. Your particular use case
    will determine how strict you need to be in handling or resolving encoding issues.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 即使有了 Unicode，也可能会遇到你的文本包含无法成功编码的值的情况。幸运的是，Python 的 `open` 函数接受一个可选的 errors 参数，它告诉函数在读取或写入文件时如何处理编码错误。默认选项是
    `'strict'`，这意味着每当遇到编码错误时都会引发错误。其他有用的选项包括 `'ignore'`，它会导致引发错误的字符被跳过；`'replace'`，它会导致字符被替换为一个标记字符（通常是？）；`'backslashreplace'`，它将字符替换为反斜杠转义序列；以及
    `'surrogateescape'`，它在读取时将违规字符转换为私有的 Unicode 代码点，在写入时再转换回原始的字节序列。你的特定用例将决定你在处理或解决编码问题时需要多么严格。
- en: 'Look at a short example of a file containing an invalid UTF-8 character, and
    see how the different options handle that character. First, write the file, using
    bytes and binary mode:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 看一个包含无效UTF-8字符的文件的简短示例，并看看不同的选项如何处理该字符。首先，使用字节和二进制模式写入文件：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This code results in a file that contains “ABC” followed by three non-ASCII
    characters, which may be rendered differently depending on the encoding used.
    If you use vim to look at the file, you see
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码生成一个包含“ABC”后跟三个非ASCII字符的文件，这些字符的显示方式可能因所使用的编码而异。如果你用vim查看这个文件，你会看到
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now that you have the file, try reading it with the default `''strict''` errors
    option:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你有了这个文件，尝试使用默认的`'strict'`错误选项来读取它：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The fourth byte, which had a value of 255, isn’t a valid UTF-8 character in
    that position, so the `''strict''` errors setting raises an exception. Now see
    how the other error options handle the same file, keeping in mind that the last
    three characters raise an error:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 第四字节，其值为255，在那个位置不是有效的UTF-8字符，因此`'strict'`错误设置会引发异常。现在看看其他错误选项如何处理相同的文件，记住最后三个字符会引发错误：
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If you want any problem characters to disappear, `'ignore'` is the option to
    use. The `'replace'` option only marks the place occupied by the invalid character,
    and the other options in different ways attempt to preserve the invalid characters
    without interpretation.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望任何问题字符消失，请使用`'ignore'`选项。`'replace'`选项仅标记无效字符所占的位置，而其他选项则以不同的方式尝试在不解释的情况下保留无效字符。
- en: 21.2.2\. Unstructured text
  id: totrans-28
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 21.2.2. 无结构化文本
- en: Unstructured text files are the easiest sort of data to read but the hardest
    to extract information from. Processing unstructured text can vary enormously,
    depending on both the nature of the text and what you want to do with it, so any
    comprehensive discussion of text processing is beyond the scope of this book.
    A short example, however, can illustrate some of the basic issues and set the
    stage for a discussion of structured text data files.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 无结构化文本文件是最容易读取的数据类型，但也是从其中提取信息最困难的一种。处理无结构化文本的方式可能因文本的性质以及你想要用它做什么而大相径庭，因此，关于文本处理的全面讨论超出了本书的范围。然而，一个简短的例子可以说明一些基本问题，并为讨论结构化文本数据文件奠定基础。
- en: One of the simplest issues is deciding what forms a basic logical unit in the
    file. If you have a corpus of thousands of tweets, the text of *Moby Dick*, or
    a collection of news stories, you need to be able to break them up into cohesive
    units. In the case of tweets, each may fit onto a single line, and you can read
    and process each line of the file fairly simply.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个最简单的问题就是决定文件中的基本逻辑单元是什么形式。如果你有一份包含数千条推文、*《白鲸记》*的文本或一系列新闻报道的语料库，你需要能够将它们分解成连贯的单元。在推文的情况下，每条可能只占一行，你可以相对简单地读取和处理文件的每一行。
- en: In the case of *Moby Dick* or even a news story, the problem can be trickier.
    You may not want to treat all of a novel or news item as a single item in many
    cases. But if that’s the case, you need to decide what sort of unit you do want
    and then come up with a strategy to divide the file accordingly. Perhaps you want
    to consider the text paragraph by paragraph. In that case, you need to identify
    how paragraphs are separated in your file and create your code accordingly. If
    a paragraph is the same as a line in the text file, the job is easy. Often, however,
    the line breaks in a text file are shorter, and you need to do a bit more work.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 对于*《白鲸记》*或甚至是一篇新闻报道，问题可能更复杂。在许多情况下，你可能不希望将整部小说或新闻报道视为一个单独的项目。但如果是这样，你需要决定你想要的单元类型，然后想出一个相应地分割文件的战略。也许你希望按段落考虑文本。在这种情况下，你需要确定你的文件中段落是如何分隔的，并相应地编写你的代码。如果一个段落与文本文件中的一行相同，那么这项工作就很简单。然而，通常文本文件中的行中断符会更短，你需要做更多的工作。
- en: 'Now look at a couple of examples:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在看看几个例子：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In the sample, which is indeed the beginning of *Moby Dick*, the lines are
    broken more or less as they might be on the page, and paragraphs are indicated
    by a single blank line. If you want to deal with each paragraph as a unit, you
    need to break the text on the blank lines. Fortunately, this task is easy if you
    use the string `split()` method. Each newline character in a string can represented
    by `"\n"`. Naturally, the last line of a paragraph’s text ends with a newline,
    and if the next line is blank, it’s immediately followed by a second newline for
    the blank line:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在样本中，实际上这是《白鲸记》的开头，行与页上的行大致相同，段落由一个空行表示。如果你想将每个段落作为一个单元处理，你需要将文本在空行处断开。幸运的是，如果你使用字符串
    `split()` 方法，这项任务很容易完成。字符串中的每个换行符都可以表示为 `"\n"`。自然地，段落文本的最后一行以换行符结束，如果下一行是空行，则紧随其后的是第二个换行符，表示空行：
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '***1* Reads all of file as a single string**'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 读取整个文件作为一个单一字符串**'
- en: '***2* Splits on two newlines together**'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 在两个换行符处拆分**'
- en: 'Splitting the text into paragraphs is a very simple first step in handling
    unstructured text. You might also need to do more normalization of the text before
    processing. Suppose that you want to count the rate of occurrence of every word
    in a text file. If you just split the file on whitespace, you get a list of words
    in the file. Counting their occurrences accurately will be hard, however, because
    *This*, *this,* *this.*, and *this,* are not the same. The way to make this code
    work is to normalize the text by removing the punctuation and making everything
    the same case before processing. For the example text above, the code for a normalized
    list of words might look like this:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 将文本拆分为段落是处理非结构化文本的一个非常简单的第一步。在处理文本之前，你可能还需要进行更多的文本规范化。假设你想要计算文本文件中每个单词出现的频率。如果你只是根据空白字符拆分文件，你会得到文件中的单词列表。然而，准确计数将很困难，因为
    *This*、*this*、*this.* 和 *this,* 并不相同。使此代码正常工作的方法是通过对文本进行规范化，在处理之前删除标点符号并使所有内容都变为同一大小写。对于上面的示例文本，规范化单词列表的代码可能看起来像这样：
- en: '[PRE6]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '***1* Reads all of the file as a single string**'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 读取整个文件作为一个单一字符串**'
- en: '***2* Makes everything lowercase**'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 将所有内容转换为小写**'
- en: '***3* Removes periods**'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 删除句号**'
- en: '***4* Removes commas**'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 删除逗号**'
- en: '|  |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 'Quick Check: Normalization'
  id: totrans-45
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 快速检查：规范化
- en: Look closely at the list of words generated. Do you see any issues with the
    normalization so far? What other issues do you think you might encounter in a
    longer section of text? How do you think you might deal with those issues?
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细查看生成的单词列表。你看到规范化过程中有任何问题吗？你认为在较长的文本部分中可能会遇到哪些其他问题？你认为你将如何处理这些问题？
- en: '|  |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 21.2.3\. Delimited flat files
  id: totrans-48
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 21.2.3\. 分隔的平面文件
- en: 'Although reading unstructured text files is easy, the downside is their very
    lack of structure. It’s often much more useful to have some organization in the
    file to help with picking out individual values. The simplest way is to break
    the file into lines and have one element of information per line. You may have
    a list of the names of files to be processed, a list of people’s names that need
    to be printed (on name tags, say), or maybe a series of temperature readings from
    a remote monitor. In such cases, the data parsing is very simple: You read in
    the line and convert it to the right type, if necessary. Then the file is ready
    to use.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然读取非结构化文本文件很容易，但它们的缺点是结构非常缺乏。通常，在文件中有些组织结构会更有用，可以帮助挑选出单个值。最简单的方法是将文件拆分为行，每行有一个信息元素。你可能有一个要处理的文件名列表，一个需要打印的人名列表（比如在姓名标签上），或者可能是一系列来自远程监控器的温度读数。在这种情况下，数据处理非常简单：你读取行并将其转换为正确的类型（如果需要的话）。然后文件就准备好使用了。
- en: Most of the time, however, things aren’t not quite so simple. Usually, you need
    to group multiple related bits of information, and you need your code to read
    them in together. The common way to do this is to put the related pieces of information
    on the same line, separated by a special character. That way, as you read each
    line of the file, you can use the special characters to split the file into its
    different fields and put the values of those fields in variables for later processing.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，大多数时候事情并不那么简单。通常，你需要将多个相关的信息块分组，并且你需要你的代码一起读取它们。常见的做法是将相关的信息块放在同一行上，并用特殊字符分隔。这样，当你读取文件的每一行时，你可以使用特殊字符将文件拆分为不同的字段，并将这些字段的值放入变量中以便后续处理。
- en: 'This file is a simple example of temperature data in delimited format:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 此文件是分隔格式温度数据的简单示例：
- en: '[PRE7]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This data is pipe-delimited, meaning that each field in the line is separated
    by the pipe (|) character, in this case giving you four fields: the state of the
    observations, the date of the observations, the average high temperature, and
    the number of stations reporting. Other common delimiters are the tab character
    and the comma. The comma is perhaps the most common, but the delimiter could be
    any character you don’t expect to occur in the values. (More about that issue
    next.) Comma delimiters are so common that this format is often called CSV (comma-separated
    values), and files of this type often have a .csv extension as a hint of their
    format.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这份数据是管道分隔的，这意味着行中的每个字段都由管道（|）字符分隔，在这种情况下提供了四个字段：观测的状态、观测的日期、平均最高温度以及报告的站点数量。其他常见的分隔符是制表符和逗号。逗号可能是最常用的，但分隔符可以是任何你不会期望在值中出现的字符。（关于这个问题的更多内容将在下一节中介绍。）逗号分隔符如此常见，以至于这种格式通常被称为CSV（逗号分隔值），这种类型的文件通常具有.csv扩展名，作为其格式的提示。
- en: 'Whatever character is being used as the delimiter, if you know what character
    it is, you can write your own code in Python to break each line into its fields
    and return them as a list. In the previous case, you can use the string `split()`
    method to break a line into a list of values:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 无论使用什么字符作为分隔符，如果你知道它是哪个字符，你可以在Python中编写自己的代码来将每一行分割成字段并返回它们作为一个列表。在前一个例子中，你可以使用字符串的`split()`方法将一行分割成一个值列表：
- en: '[PRE8]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note that this technique is very easy to do but leaves all the values as strings,
    which might not be convenient for later processing.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这种技术非常容易做，但会将所有值都保留为字符串，这可能在后续处理中不太方便。
- en: '|  |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: 'Try this: Read A file'
  id: totrans-58
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 尝试这个：读取一个文件
- en: Write the code to read a text file (assume temp_data_pipes_00a.txt, as shown
    in the example), split each line of the file into a list of values, and add that
    list to a single list of records.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 编写代码以读取一个文本文件（假设为temp_data_pipes_00a.txt，如示例所示），将文件的每一行分割成值列表，并将该列表添加到单个记录列表中。
- en: What issues or problems did you encounter in implementing this code? How might
    you go about converting the last three fields to the correct date, real, and int
    types?
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在实现此代码时，你遇到了哪些问题或困难？你如何将最后三个字段转换为正确的日期、实数和整数类型？
- en: '|  |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: 21.2.4\. The csv module
  id: totrans-62
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 21.2.4\. `csv`模块
- en: If you need to do much processing of delimited data files, you should become
    familiar with the `csv` module and its options. When I’ve been asked to name my
    favorite module in the Python standard library, more than once I’ve cited the
    `csv` module—not because it’s glamorous (it isn’t), but because it has probably
    saved me more work and kept me from more self-inflicted bugs over my career than
    any other module.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要处理大量的分隔数据文件，你应该熟悉`csv`模块及其选项。当我被问到我最喜欢的Python标准库模块时，不止一次提到过`csv`模块——并不是因为它很炫酷（它并不炫酷），而是因为它可能为我节省了更多的工作，并让我在职业生涯中避免了更多的自我造成的错误，比其他任何模块都要多。
- en: The `csv` module is a perfect case of Python’s “batteries included” philosophy.
    Although it’s perfectly possible, and in many cases not even terribly hard, to
    roll your own code to read delimited files, it’s even easier and much more reliable
    to use the Python module. The `csv` module has been tested and optimized, and
    it has features that you probably wouldn’t bother to write if you had to do it
    yourself, but that are truly handy and time-saving when available.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`csv`模块是Python“内置电池”哲学的一个完美案例。虽然自己编写代码来读取分隔文件是完全可能的，而且在许多情况下甚至并不困难，但使用Python模块会更简单、更可靠。`csv`模块已经过测试和优化，它具有如果你自己编写可能不会费心去写的功能，但在可用时确实很方便且节省时间。'
- en: 'Look at the previous data, and decide how you’d read it by using the `csv`
    module. The code to parse the data has to do two things: read each line and strip
    off the trailing newline character, and then break up the line on the pipe character
    and append that list of values to a list of lines. Your solution to the exercise
    might look something like this:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 查看前面的数据，并决定如何使用`csv`模块来读取它。解析数据的代码需要做两件事：读取每一行并移除尾随的换行符，然后根据管道字符分割行，并将该值列表追加到行列表中。你的练习解决方案可能看起来像这样：
- en: '[PRE9]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'To do the same thing with the `csv` module, the code might be something like
    this:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用`csv`模块做同样的事情，代码可能如下所示：
- en: '[PRE10]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In this simple case, the gain over rolling your own code doesn’t seem so great.
    Still, the code is two lines shorter and a bit clearer, and there’s no need to
    worry about stripping off newline characters. The real advantages come when you
    want to deal with more challenging cases.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简单的情况下，自己编写代码的收益似乎并不那么大。尽管如此，代码行数减少了，而且更清晰，而且你不需要担心移除换行符。真正的优势在于当你想要处理更具挑战性的情况时。
- en: 'The data in the example is real, but it’s actually been simplified and cleaned.
    The real data from the source is more complex. The real data has more fields,
    some fields are in quotes while others are not, and the first field is empty.
    The original is tab-delimited, but for the sake of illustration, I present it
    as comma-delimited here:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 示例中的数据是真实的，但实际上已经被简化和清理。原始数据更复杂。原始数据有更多字段，一些字段在引号内，而另一些则不是，第一个字段是空的。原始数据是制表符分隔的，但为了说明，我在这里将其表示为逗号分隔的：
- en: '[PRE11]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Notice that some fields include commas. The convention in that case is to put
    quotes around a field to indicate that it’s not supposed to be parsed for delimiters.
    It’s quite common, as here, to quote only some fields, especially those in which
    a value might contain the delimiter character. It also happens, as here, that
    some fields are quoted even if they’re not likely to contain the delimiting character.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，一些字段包含逗号。在这种情况下，惯例是在字段周围放置引号，以表示它不应该被解析为分隔符。像这里这样只引用一些字段是很常见的，特别是那些可能包含分隔符字符的值。同样，像这里一样，即使字段不太可能包含分隔符字符，一些字段也可能被引用。
- en: 'In a case like this one, your home-grown code becomes cumbersome. Now you can
    no longer split the line on the delimiting character; you need to be sure that
    you look only at delimiters that aren’t inside quoted strings. Also, you need
    to remove the quotes around quoted strings, which might occur in any position
    or not at all. With the `csv` module, you don’t need to change your code at all.
    In fact, because the comma is the default delimiter, you don’t even need to specify
    it:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，你自编的代码会变得很繁琐。现在你不能再在分隔符上分割行；你需要确保你只查看不在引号字符串内部的分隔符。此外，你需要移除可能出现在任何位置或根本不出现的引号字符串。使用`csv`模块，你根本不需要更改你的代码。事实上，因为逗号是默认分隔符，你甚至不需要指定它：
- en: '[PRE12]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Notice that the extra quotes have been removed and that any field values with
    commas have the commas intact inside the fields—all without any more characters
    in the command.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，多余的引号已经被移除，并且任何包含逗号的字段值在字段内部保留了逗号——所有这些都不需要命令中更多的字符。
- en: '|  |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 'Quick Check: Handling Quoting'
  id: totrans-77
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 快速检查：处理引号
- en: 'Consider how you’d approach the problems of handling quoted fields and embedded
    delimiter characters if you didn’t have the `csv` library. Which would be easier
    to handle: the quoting or the embedded delimiters?'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一下，如果你没有`csv`库，你会如何处理引号字段和嵌入的分隔符字符的问题。处理引号还是嵌入的分隔符更容易？
- en: '|  |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 21.2.5\. Reading a csv file as a list of dictionaries
  id: totrans-80
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 21.2.5\. 将csv文件作为字典列表读取
- en: 'In the preceding examples, you got a row of data back as a list of fields.
    This result works fine in many cases, but sometimes it may be handy to get the
    rows back as dictionaries where the field name is the key. For this use case,
    the `csv` library has a `DictReader`, which can take a list of fields as a parameter
    or can read them from the first line of the data. If you want to open the data
    with a `DictReader`, the code would look like this:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，你得到了一个字段列表作为数据行。这种结果在许多情况下都很好用，但有时将行作为字典返回，其中字段名是键，可能更方便。为此用例，`csv`库有一个`DictReader`，它可以接受一个字段列表作为参数，也可以从数据的第一行读取它们。如果你想用`DictReader`打开数据，代码看起来会是这样：
- en: '[PRE13]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Note that the `csv.DictReader` returns `OrderedDicts`, so the fields stay in
    their original order. Although their representation is a little different, the
    fields still behave like dictionaries:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`csv.DictReader`返回`OrderedDicts`，因此字段保持其原始顺序。尽管它们的表示略有不同，但字段仍然像字典一样表现：
- en: '[PRE14]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: If the data is particularly complex, and specific fields need to be manipulated,
    a `DictReader` can make it much easier to be sure you’re getting the right field;
    it also makes your code somewhat easier to understand. Conversely, if your data
    set is quite large, you need to keep in mind that `DictReader` can take on the
    order of twice as long to read the same amount of data.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据特别复杂，并且需要操作特定字段，使用 `DictReader` 可以使确保获取正确字段变得容易得多；它也使你的代码更容易理解。相反，如果你的数据集相当大，你需要记住
    `DictReader` 读取相同数量的数据可能需要的时间是两倍。
- en: 21.3\. Excel files
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 21.3. Excel 文件
- en: The other common file format that I discuss in this chapter is the Excel file,
    which is the format that Microsoft Excel uses to store spreadsheets. I include
    Excel files here because the way you end up treating them is very similar to the
    way you treat delimited files. In fact, because Excel can both read and write
    CSV files, the quickest and easiest way to extract data from an Excel spreadsheet
    file often is to open it in Excel and then save it as a CSV file. This procedure
    doesn’t always make sense, however, particularly if you have a lot of files. In
    that case, even though you could theoretically automate the process of opening
    and saving each file in CSV format, it’s probably faster to deal with the Excel
    files directly.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中我讨论的另一种常见文件格式是 Excel 文件，这是 Microsoft Excel 用于存储电子表格的格式。我包括 Excel 文件在这里，因为处理它们的方式与处理分隔文件的方式非常相似。事实上，因为
    Excel 可以读取和写入 CSV 文件，所以从 Excel 电子表格文件中提取数据的最快和最简单的方法通常是将其在 Excel 中打开，然后保存为 CSV
    文件。然而，这种方法并不总是合理，尤其是如果你有很多文件。在这种情况下，即使你可以从理论上自动化打开和保存每个文件为 CSV 格式的过程，直接处理 Excel
    文件可能更快。
- en: It’s beyond the scope of this book to have an in-depth discussion of spreadsheet
    files, with their options for multiple sheets in the same file, macros, and various
    formatting options. Instead, in this section I look at an example of reading a
    simple one-sheet file simply to extract the data from it.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中深入讨论电子表格文件，包括同一文件中的多个工作表、宏和各种格式选项超出了范围。相反，在本节中，我查看了一个读取简单单工作表文件的示例，仅为了从中提取数据。
- en: 'As it happens, Python’s standard library doesn’t have a module to read or write
    Excel files. To read that format, you need to install an external module. Fortunately,
    several modules are available to do the job. For this example, you use one called
    OpenPyXL, which is available from the Python package repository. You can install
    it with the following command from a command line:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，Python 的标准库没有用于读取或写入 Excel 文件的模块。要读取该格式，你需要安装外部模块。幸运的是，有几个模块可以完成这项工作。在这个例子中，你使用一个名为
    OpenPyXL 的模块，它可以从 Python 软件包仓库中获取。你可以从命令行使用以下命令安装它：
- en: '[PRE15]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Here’s a view of the previous data, but in a spreadsheet:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是之前数据的视图，但以电子表格的形式：
- en: '![](images/0293fig01.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图片](images/0293fig01.jpg)'
- en: 'Reading the file is fairly simple, but it’s still more work than CSV files
    require. First, you need to load the workbook; next, you need to get the specific
    sheet; then you can iterate over the rows; and from there, you extract the values
    of the cells. Some sample code to read the spreadsheet looks like this:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 读取文件相对简单，但仍然比 CSV 文件需要更多的工作。首先，你需要加载工作簿；然后，你需要获取特定的工作表；然后你可以遍历行；然后从那里提取单元格的值。读取电子表格的一些示例代码如下：
- en: '[PRE16]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This code gets you the same results as the much simpler code did for a csv file.
    It’s not surprising that the code to read a spreadsheet is more complex, because
    spreadsheets are themselves much more complex objects. You should also be sure
    that you understand the way that data has been stored in the spreadsheet. If the
    spreadsheet contains formatting that has some significance, if labels need to
    be disregarded or handled differently, or if formulas and references need to be
    processed, you need to dig deeper into how those elements should be processed,
    and you need to write more-complex code.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码得到的结果与用于 csv 文件的简单代码相同。代码读取电子表格更复杂并不奇怪，因为电子表格本身就是一个更复杂的对象。你还应该确保你理解数据在电子表格中的存储方式。如果电子表格包含具有某些重要性的格式，如果需要忽略或以不同方式处理标签，或者如果需要处理公式和引用，你需要深入了解这些元素应该如何处理，并且你需要编写更复杂的代码。
- en: Spreadsheets also often have other possible issues. At this writing, it’s common
    for spreadsheets to be limited to around a million rows. Although that limit sounds
    large, more and more often you’ll need to handle data sets that are larger. Also,
    spreadsheets sometimes automatically apply inconvenient formatting. One company
    I worked for had part numbers that consisted of a digit and at least one letter
    followed by some combination of digits and letters. It was possible to get a part
    number such as 1E20\. Most spreadsheets automatically interpret 1E20 as scientific
    notation and save it as 1.00E+20 (1 times 10 to the 20^(th) power) while leaving
    1F20 as a string. For some reason, it’s rather difficult to keep this from happening,
    and particularly with a large data set, the problem won’t be detected until farther
    down the pipeline, if all. For these reasons, I recommend using CSV or delimited
    files when at all possible. Users usually can save a spreadsheet as CSV, so there’s
    usually no need put up with the extra complexity and formatting hassles that spreadsheets
    involve.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 电子表格也可能存在其他问题。在撰写本文时，电子表格通常限制在大约一百万行。虽然这个限制听起来很大，但越来越经常需要处理更大的数据集。此外，电子表格有时会自动应用不便利的格式。我之前工作的一家公司，其零件号由一个数字和至少一个字母组成，后面跟着一些数字和字母的组合。例如，可以得到一个零件号如1E20。大多数电子表格会自动将1E20解释为科学记数法，并保存为1.00E+20（1乘以10的20次方），而将1F20保留为字符串。由于某种原因，很难防止这种情况发生，尤其是在大型数据集中，问题可能直到管道的下游才会被发现。因此，我建议在可能的情况下使用CSV或定界文件。用户通常可以将电子表格保存为CSV格式，因此通常没有必要忍受电子表格带来的额外复杂性和格式化问题。
- en: 21.4\. Data cleaning
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 21.4\. 数据清洗
- en: One common problem you’ll encounter in processing text-based data files is dirty
    data. By *dirty*, I mean that there are all sorts of surprises in the data, such
    as null values, values that aren’t legal for your encoding, or extra whitespace.
    The data may also be unsorted or in an order that makes processing difficult.
    The process of dealing with situations like these is called *data cleaning*.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理基于文本的数据文件时，你可能会遇到的一个常见问题是数据不干净。我所说的“不干净”是指数据中存在各种意外情况，例如空值、不适用于你的编码的值或额外的空白字符。数据可能未排序或顺序难以处理。处理这些情况的过程称为“数据清洗”。
- en: 21.4.1\. Cleaning
  id: totrans-99
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 21.4.1\. 清洗
- en: 'In a very simple example data clean, you might need to process a file that
    was exported from a spreadsheet or other financial program, and the columns dealing
    with money may have percentage and currency symbols (such as %, $, £, and ?),
    as well as extra groupings that use a period or comma. Data from other sources
    may have other surprises that make processing tricky if they’re not caught in
    advance. Look again at the temperature data you saw previously. The first data
    line looks like this:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个非常简单的数据清洗示例中，你可能需要处理从电子表格或其他财务程序导出的文件，处理金钱相关的列可能包含百分比和货币符号（如%，$，£和?），以及使用句点或逗号进行额外分组的组合。来自其他来源的数据可能包含其他意外情况，如果事先没有发现，处理起来会很棘手。再次看看你之前看到的温度数据。第一行数据看起来像这样：
- en: '[PRE17]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Some columns, such as `'State'` (field 2) and `'Notes'` (field 1), are clearly
    text, and you wouldn’t be likely to do much with them. There are also two date
    fields in different formats, and you might well want to do calculations with the
    dates, possibly to change the order of the data and to group rows by month or
    day, or possibly to calculate how far apart in time two rows are.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 一些列，例如`'State'`（字段2）和`'Notes'`（字段1），显然是文本类型，你不太可能对它们做太多操作。此外，还有两个日期字段，格式不同，你可能很希望对这些日期进行计算，比如改变数据的顺序，按月或日分组，或者计算两行之间的时间差。
- en: 'The rest of the fields seem to be different types of numbers; the temperatures
    are decimals, and the record counts columns are integers. Notice, however, that
    the heat index temperatures have a variation: When the value for the `''Max Temp
    for Daily Max Air Temp (F)''` field is below 80, the values for the heat index
    fields aren’t reported, but instead are listed as `''Missing''`, and the record
    count is 0\. Also note that the `''Daily Max Heat Index (F) % Coverage''` field
    is expressed as a percentage of the number of temperature records that also qualify
    to have a heat index. Both of these issues will be problematic if you want to
    do any math calculations on the values in those fields, because both `''Missing''`
    and any number ending with % will be parsed as strings, not numbers.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 其余字段似乎都是不同类型的数字；温度是十进制数，而记录计数列是整数。然而，请注意，热指数温度有变化：当“每日最高空气温度（F）最大值”字段的值低于80时，热指数字段的值不报告，而是列示为“缺失”，记录计数为0。此外，请注意，“每日最大热指数（F）覆盖率”字段表示为具有热指数的温度记录数量的百分比。如果你想在那些字段中的值上进行任何数学计算，这两个问题都会变得有挑战性，因为“缺失”和任何以%结尾的数字都将被解析为字符串，而不是数字。
- en: Cleaning data like this can be done at different steps in the process. Quite
    often, I prefer to clean the data as it’s being read from the file, so I might
    well replace the `'Missing'` with a None value or an empty string as the lines
    are being processed. You could also leave the `'Missing'` strings in place and
    write your code so that no math operations are performed on a value if it is `'Missing'`.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理过程的各个步骤中都可以进行此类数据清理。通常，我更喜欢在从文件读取数据时清理数据，所以我可能会在处理行时将“缺失”替换为None值或空字符串。你也可以保留“缺失”字符串，并编写代码，以便在值是“缺失”的情况下不执行任何数学运算。
- en: '|  |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 'Try this: Cleaning Data'
  id: totrans-106
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 尝试这个：清理数据
- en: How would you handle the fields with `'Missing'` as possible values for math
    calculations? Can you write a snippet of code that averages one of those columns?
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 你会如何处理具有“缺失”作为可能值的字段进行数学计算？你能编写一个代码片段来计算这些列的平均值吗？
- en: What would you do with the average column at the end so that you could also
    report the average coverage? In your opinion, would the solution to this problem
    be at all linked to the way that the `'Missing'` entries were handled?
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 你会如何处理末尾的平均列，以便也能报告平均覆盖率？在你看来，这个问题的解决方案是否与处理“缺失”条目的方式有关？
- en: '|  |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 21.4.2\. Sorting
  id: totrans-110
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 21.4.2. 排序
- en: 'As I mentioned earlier, it’s often useful to have data in the text file sorted
    before processing. Sorting the data makes it easier to spot and handle duplicate
    values, and it can also help bring together related rows for quicker or easier
    processing. In one case, I received a 20 million–row file of attributes and values,
    in which arbitrary numbers of them needed to be matched with items from a master
    SKU list. Sorting the rows by the item ID made gathering each item’s attributes
    much faster. How you do the sorting depends on the size of the data file relative
    to your available memory and on the complexity of the sort. If all the lines of
    the file can fit comfortably into available memory, the easiest thing may be to
    read all of the lines into a list and use the list’s sort method:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如我之前提到的，在处理之前对数据进行排序通常很有用。排序数据可以更容易地发现和处理重复值，并且还可以帮助将相关行聚集在一起，以便更快或更容易地处理。在一个案例中，我收到了一个包含2000万行属性和值的文件，其中任意数量的它们需要与主SKU列表中的项目匹配。按项目ID对行进行排序可以使收集每个项目的属性变得更快。你如何进行排序取决于数据文件相对于可用内存的大小以及排序的复杂性。如果文件的所有行都可以舒适地放入可用内存中，最简单的事情可能是将所有行读取到一个列表中，并使用列表的排序方法：
- en: '[PRE18]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: You could also use the `sorted()` function, as in `sorted_lines = sorted(lines)`.
    This function preserves the order of the lines in your original list, which usually
    is unnecessary. The drawback to using the `sorted()` function is that it creates
    a new copy of the list. This process takes slightly longer and consumes twice
    as much memory, which might be a bigger concern.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用`sorted()`函数，例如`sorted_lines = sorted(lines)`。这个函数保留了原始列表中行的顺序，这通常是不必要的。使用`sorted()`函数的缺点是它会创建列表的新副本。这个过程会稍微慢一些，并且消耗两倍的内存，这可能会成为一个更大的问题。
- en: 'If the data set is larger than memory and the sort is very simple (just by
    an easily grabbed field), it may be easier to use an external utility, such as
    the UNIX `sort` command, to preprocess the data:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据集大于内存，并且排序非常简单（仅按易于获取的字段排序），则可能更容易使用外部实用程序，例如UNIX `sort`命令，来预处理数据：
- en: '[PRE19]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'In either case, sorting can be done in reverse order and can be keyed by values,
    not the beginning of the line. For such occasions, you need to study the documentation
    of the sorting tool you choose to use. A simple example in Python would be to
    make a sort of lines of text case-insensitive. To do this, you give the `sort`
    method a key function that makes the element lowercase before making a comparison:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何情况下，排序都可以按逆序进行，并且可以按值进行排序，而不是按行的开头。在这种情况下，你需要研究你选择的排序工具的文档。Python中的一个简单例子是使文本行的排序不区分大小写。为此，你给`sort`方法提供一个键函数，在比较之前将元素转换为小写：
- en: '[PRE20]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This example uses a `lambda` function to ignore the first five characters of
    each string:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子使用了一个`lambda`函数来忽略每个字符串的前五个字符：
- en: '[PRE21]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Using key functions to determine the behavior of sorts in Python is very handy,
    but be aware that the key function is called a lot in the process of sorting,
    so a complex key function could mean a real performance slowdown, particularly
    with a large data set.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 使用键函数来确定Python中排序的行为非常方便，但请注意，在排序过程中会多次调用键函数，因此复杂的键函数可能会导致真正的性能下降，尤其是在大数据集上。
- en: 21.4.3\. Data cleaning issues and pitfalls
  id: totrans-121
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 21.4.3\. 数据清理问题和陷阱
- en: It seems that there are as many types of dirty data as there are sources and
    use cases for that data. Your data will always have quirks that do everything
    from making processing less accurate to making it impossible to even load the
    data. As a result, I can’t provide an exhaustive list of the problems you might
    encounter and how to deal with them, but I can give you some general hints.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 似乎脏数据的类型和数据的来源以及使用案例一样多。你的数据总会有些怪癖，从使处理不准确到使数据甚至无法加载，什么都有可能。因此，我无法提供一个详尽的列表，列出你可能会遇到的问题以及如何处理它们，但我可以给你一些一般性的提示。
- en: '*Beware of whitespace and null characters.* The problem with whitespace characters
    is that you can’t see them, but that doesn’t mean that they can’t cause troubles.
    Extra whitespace at the beginning and end of data lines, extra whitespace around
    individual fields, and tabs instead of spaces (or vice versa) can all make your
    data loading and processing more troublesome, and these problems aren’t always
    easily apparent. Similarly, text files with null characters (ASCII 0) may seem
    okay on inspection but break on loading and processing.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*小心空白符和空字符。* 空白字符的问题是你看不到它们，但这并不意味着它们不能引起麻烦。数据行开头和结尾的额外空白，字段周围的额外空白，以及使用制表符而不是空格（或反之亦然）都可能使你的数据加载和处理更加麻烦，这些问题并不总是容易察觉。同样，包含空字符（ASCII
    0）的文本文件在检查时可能看起来没问题，但在加载和处理时可能会出错。'
- en: '*Beware punctuation.* Punctuation can also be a problem. Extra commas or periods
    can mess up CSV files and the processing of numeric fields, and unescaped or unmatched
    quote characters can also confuse things.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*小心标点符号。* 标点符号也可能成为问题。额外的逗号或句号可能会搞乱CSV文件和数值字段的处理，未转义或未匹配的引号字符也可能使事情变得混乱。'
- en: '*Break down and debug the steps.* It’s easier to debug a problem if each step
    is separate, which means putting each operation on a separate line, being more
    verbose, and using more variables. But the work is worth it. For one thing, it
    makes any exceptions that are raised easier to understand, and it also makes debugging
    easier, whether with print statements, logging, or the Python debugger. It may
    also be helpful to save the data after each step and to cut the file size to just
    a few lines that cause the error.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*分解并调试步骤。* 如果每个步骤都是独立的，那么调试问题会更容易，这意味着将每个操作放在单独的一行上，更加详细，并使用更多的变量。但这项工作值得去做。一方面，它使得抛出的任何异常都更容易理解，同时也使得调试更容易，无论是通过打印语句、日志记录还是Python调试器。在每一步之后保存数据，并将文件大小缩减到只有几行导致错误的程度，这也可能是有帮助的。'
- en: 21.5\. Writing data files
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 21.5\. 编写数据文件
- en: The last part of the ETL process may involve saving the transformed data to
    a database (which I discuss in [chapter 22](kindle_split_035.html#ch22)), but
    often it involves writing the data to files. These files may be used as input
    for other applications and analysis, either by people or by other applications.
    Usually, you have a particular file specification listing what fields of data
    should be included, what they should be named, what format and constraints there
    should be for each, and so on
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: ETL过程的最后部分可能涉及将转换后的数据保存到数据库中（我在第22章中讨论了这一点），但通常它涉及将数据写入文件。这些文件可能被用作其他应用程序和分析的输入，无论是人工还是由其他应用程序。通常，你有一个特定的文件规范，列出应包含哪些数据字段，它们应该被命名为什么，每个字段的格式和约束应该是什么，等等。
- en: 21.5.1\. CSV and other delimited files
  id: totrans-128
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 21.5.1. CSV和其他分隔文件
- en: Probably the easiest thing of all is to write your data to CSV files. Because
    you’ve already loaded, parsed, cleaned, and transformed the data, you’re unlikely
    to hit any unresolved issues with the data itself. And again, using the `csv`
    module from the Python standard library makes your work much easier.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 可能最容易的事情就是将你的数据写入CSV文件。因为你已经加载、解析、清洗和转换了数据，所以你不太可能遇到与数据本身相关的未解决的问题。再次强调，使用Python标准库中的`csv`模块可以使你的工作更加容易。
- en: 'Writing delimited files with the `csv` module is pretty much the reverse of
    the read process. Again, you need to specify the delimiter that you want to use,
    and again, the `csv` module takes care of any situations in which your delimiting
    character is included in a field:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`csv`模块写入分隔文件基本上是读取过程的逆过程。同样，你需要指定你想要使用的分隔符，同样，`csv`模块会处理任何你的分隔字符包含在字段中的情况：
- en: '[PRE22]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This code results in the following file:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码会产生以下文件：
- en: '[PRE23]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Just as when reading from a CSV file, it’s possible to write dictionaries instead
    of lists if you use a `DictWriter`. If you do use a `DictWriter`, be aware of
    a couple of points: You must specify the fields names in a list when you create
    the writer, and you can use the `DictWriter`’s `writeheader` method to write the
    header at the top of the file. So assume that you have the same data as previously,
    but in dictionary format:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 就像从CSV文件读取时一样，如果你使用`DictWriter`，你可以写入字典而不是列表。如果你确实使用`DictWriter`，请注意以下几点：在创建写入器时，你必须指定字段名称列表，并且你可以使用`DictWriter`的`writeheader`方法在文件顶部写入标题。所以假设你拥有与之前相同的数据，但以字典格式：
- en: '[PRE24]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'You can use a `DictWriter` object from the `csv` module to write each row,
    a dictionary, to the correct fields in the CSV file:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用`csv`模块的`DictWriter`对象将每一行，一个字典，写入CSV文件的正确字段：
- en: '[PRE25]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 21.5.2\. Writing Excel files
  id: totrans-138
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 21.5.2. 写入Excel文件
- en: 'Writing spreadsheet files is unsurprisingly similar to reading them. You need
    to create a workbook, or spreadsheet file; then you need to create a sheet or
    sheets; and finally, you write the data in the appropriate cells. You could create
    a new spreadsheet from your CSV data file like this:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 写入电子表格文件与读取它们非常相似。你需要创建一个工作簿，或者电子表格文件；然后你需要创建一个或多个工作表；最后，你需要在适当的单元格中写入数据。你可以像这样从CSV数据文件创建一个新的电子表格：
- en: '[PRE26]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: It’s also possible to add formatting to cells as you write them to the spreadsheet
    file. For more on how to add formatting, please refer to the `xlswriter` documentation.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在将数据写入电子表格文件时，也可以为单元格添加格式。有关如何添加格式的更多信息，请参阅`xlswriter`文档。
- en: 21.5.3\. Packaging data files
  id: totrans-142
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 21.5.3. 打包数据文件
- en: If you have several related data files, or if your files are large, it may make
    sense to package them in a compressed archive. Although various archive formats
    are in use, the zip file remains popular and almost universally accessible to
    users on almost every platform. For hints on how to create zip-file packages of
    your data files, please refer to [chapter 20](kindle_split_033.html#ch20).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有几个相关的数据文件，或者如果你的文件很大，将它们打包成压缩归档可能是有意义的。尽管使用各种归档格式，但zip文件仍然很受欢迎，并且几乎在几乎每个平台上都可以被用户访问。有关如何创建数据文件的zip文件包的提示，请参阅[第20章](kindle_split_033.html#ch20)。
- en: '|  |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: 'Lab 21: Weather observations'
  id: totrans-145
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 实验室21：天气观测
- en: The file of weather observations provided here is by month and then by county
    for the state of Illinois from 1979 to 2011. Write the code to process this file
    to extract the data for Chicago (Cook County) into a single CSV or spreadsheet
    file. This process includes replacing the `'Missing'` strings with empty strings
    and translating the percentage to a decimal. You may also consider what fields
    are repetitive (and therefore can be omitted or stored elsewhere). The proof that
    you’ve got it right occurs when you load the file into a spreadsheet. You can
    download a solution with the book’s source code.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这里提供的天气观测文件是根据月份和伊利诺伊州从1979年到2011年的县来划分的。编写代码处理此文件，将芝加哥（库克县）的数据提取到单个CSV或电子表格文件中。此过程包括将`'Missing'`字符串替换为空字符串，并将百分比转换为小数。你也可以考虑哪些字段是重复的（因此可以省略或存储在其他地方）。当你将文件加载到电子表格中时，你会得到正确的证明。你可以下载带有书籍源代码的解决方案。
- en: '|  |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Summary
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 摘要
- en: ETL (extract-transform-load) is the process of getting data from one format,
    making sure that it’s consistent, and then putting it in a format you can use.
    ETL is the basic step in most data processing.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ETL（提取-转换-加载）是从一种格式获取数据，确保其一致性，然后将其放入你可以使用的格式的过程。ETL是大多数数据处理的基本步骤。
- en: Encoding can be problematic with text files, but Python lets you deal with some
    encoding problems when you load files.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本文件的编码可能会出现问题，但Python允许你在加载文件时处理一些编码问题。
- en: Delimited or CSV files are common, and the best way to handle them is with the
    `csv` module.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分隔符或CSV文件很常见，处理它们最好的方式是使用`csv`模块。
- en: Spreadsheet files can be more complex than CSV files but can be handled much
    the same way.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电子表格文件可能比CSV文件更复杂，但处理方式几乎相同。
- en: Currency symbols, punctuation, and null characters are among the most common
    data cleaning issues; be on the watch for them.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 货币符号、标点符号和空字符是最常见的数据清理问题；请注意它们。
- en: Presorting your data file can make other processing steps faster.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对你的数据文件进行预排序可以使其他处理步骤更快。
