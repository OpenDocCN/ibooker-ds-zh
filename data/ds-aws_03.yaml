- en: Chapter 3\. Automated Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三章：自动化机器学习
- en: In this chapter, we will show how to use the fully managed Amazon AI and machine
    learning services to avoid the need to manage our own infrastructure for our AI
    and machine learning pipelines. We dive deep into two Amazon services for automated
    machine learning, Amazon SageMaker Autopilot and Amazon Comprehend, both designed
    for users who want to build powerful predictive models from their datasets with
    just a few clicks. We can use both SageMaker Autopilot and Comprehend to establish
    baseline model performance with very low effort and cost.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将展示如何使用完全托管的亚马逊 AI 和机器学习服务，避免为我们的 AI 和机器学习流水线管理自己的基础设施需求。我们深入探讨了两个亚马逊服务：Amazon
    SageMaker Autopilot 和 Amazon Comprehend。这两个服务都专为希望通过简单点击即可从其数据集构建强大预测模型的用户而设计。我们可以使用
    SageMaker Autopilot 和 Comprehend 来以非常低的工作量和成本建立基准模型性能。
- en: Machine learning practitioners typically spend weeks or months building, training,
    and tuning their models. They prepare the data and decide on the framework and
    algorithm to use. In an iterative process, ML practitioners try to find the best
    performing algorithm for their dataset and problem type. Unfortunately, there
    is no cheat sheet for this process. We still need experience, intuition, and patience
    to run many experiments and find the best hyper-parameters for our algorithm and
    dataset. Seasoned data scientists benefit from years of experience and intuition
    to choose the best algorithm for a given dataset and problem type, but they still
    need to validate their intuition with actual training runs and repeated model
    validations.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习从业者通常花费数周或数月来构建、训练和调整他们的模型。他们准备数据并决定使用的框架和算法。在迭代过程中，机器学习从业者试图找到适合其数据集和问题类型的最佳执行算法。不幸的是，对于这个过程，没有捷径。我们仍然需要经验、直觉和耐心来运行许多实验，找到我们算法和数据集的最佳超参数。经验丰富的数据科学家凭借多年的经验和直觉为给定数据集和问题类型选择最佳算法，但他们仍然需要通过实际训练运行和重复模型验证来验证他们的直觉。
- en: What if we could just use a service that, with just a single click, finds the
    best algorithm for our dataset, trains and tunes the model, and deploys a model
    to production? Amazon SageMaker Autopilot simplifies the model training and tuning
    process and speeds up the overall model development life cycle. By spending less
    time on boiler-plate life-cycle phases such as feature selection and hyper-parameter
    tuning (HPT), we can spend more time on domain-specific problems.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只需点击一次就能使用一个服务，该服务会找到适合我们数据集的最佳算法，训练和调整模型，并将模型部署到生产环境中，那该有多好？Amazon SageMaker
    Autopilot 简化了模型训练和调整过程，并加快了整体模型开发生命周期。通过在特征选择和超参数调整等样板生命周期阶段花费较少时间，我们可以花更多时间处理领域特定问题。
- en: By analyzing our data from S3, SageMaker Autopilot explores different algorithms
    and configurations based on many years of AI and machine learning experience at
    Amazon. SageMaker Autopilot compares various regression, classification, and deep
    learning algorithms to find the best one for our dataset and problem type.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 通过分析我们在 S3 中的数据，SageMaker Autopilot 基于亚马逊多年的 AI 和机器学习经验，探索不同的算法和配置。SageMaker
    Autopilot 比较各种回归、分类和深度学习算法，找出适合我们数据集和问题类型的最佳算法。
- en: The model candidates are summarized by SageMaker Autopilot through a set of
    automatically generated Jupyter notebooks and Python scripts. We have full control
    over these generated notebooks and scripts. We can modify them, automate them,
    and share them with colleagues. We can select the top model candidate based on
    our desired balance of model accuracy, model size, and prediction latency.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Autopilot 通过一组自动生成的 Jupyter 笔记本和 Python 脚本总结了模型候选人。我们完全控制这些生成的笔记本和脚本。我们可以修改它们，自动化它们，并与同事分享。我们可以根据我们期望的模型准确性、模型大小和预测延迟选择顶级模型候选人。
- en: Automated Machine Learning with SageMaker Autopilot
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 SageMaker Autopilot 的自动化机器学习
- en: We configure the SageMaker Autopilot job by providing our raw data in an S3
    bucket in the form of a tabular CSV file. We also need to tell SageMaker Autopilot
    which column is the target. Then SageMaker Autopilot applies automated machine
    learning techniques to analyze the data, identify the best algorithm for our dataset,
    and generate the best model candidates.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过将原始数据以表格形式的 CSV 文件提供到 S3 存储桶中，配置 SageMaker Autopilot 作业。我们还需要告诉 SageMaker
    Autopilot 哪一列是目标列。然后，SageMaker Autopilot 应用自动化机器学习技术来分析数据，识别适合我们数据集的最佳算法，并生成最佳模型候选人。
- en: SageMaker Autopilot analyzes and balances the dataset and splits the dataset
    into train/validation sets. Based on the target attribute we are trying to predict,
    SageMaker Autopilot automatically identifies the machine learning problem type,
    such as regression, binary classification, or multiclass classification. SageMaker
    Autopilot then compares a set of algorithms depending on the problem type. The
    algorithm choices include logistic regression, linear regression, XGBoost, neural
    networks, and others.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Autopilot 分析并平衡数据集，并将数据集分为训练/验证集。根据我们试图预测的目标属性，SageMaker Autopilot
    自动识别机器学习问题类型，如回归、二元分类或多类分类。然后，SageMaker Autopilot 根据问题类型比较一组算法。算法选择包括逻辑回归、线性回归、XGBoost、神经网络等。
- en: SageMaker Autopilot generates code to execute a set of model pipelines specific
    to each algorithm. The generated code includes data transformations, model training,
    and model tuning. Since SageMaker Autopilot is transparent, we have full access
    to this generated code to reproduce on our own. We can even modify the code and
    rerun the pipeline anytime.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Autopilot 生成执行每种算法特定模型流水线的代码。生成的代码包括数据转换、模型训练和模型调优。由于 SageMaker Autopilot
    具有透明性，我们可以完全访问这些生成的代码以便自行重现。我们甚至可以修改代码并随时重新运行流水线。
- en: After training and tuning the generated pipelines in parallel, SageMaker Autopilot
    ranks the trained models by an objective metric such as accuracy, AUC, and F1-score,
    among others.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在并行训练和调整生成的流水线之后，SageMaker Autopilot 根据准确率、AUC 和 F1 分数等客观指标对训练好的模型进行排名。
- en: SageMaker Autopilot uses a transparent approach to AutoML. In nontransparent
    approaches, as shown in [Figure 3-1](#with_many_automl_servicescomma_we_donap),
    we don’t have control or visibility into the chosen algorithms, applied data transformations,
    or hyper-parameter choices. We point the automated machine learning (AutoML) service
    to our data and receive a trained model.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Autopilot 使用透明的自动机器学习方法。在不透明的方法中，如图 3-1 所示，我们无法控制或看到所选算法、应用的数据转换或超参数选择。我们将自动化机器学习服务指向我们的数据，并接收一个训练好的模型。
- en: '![](assets/dsaw_0301.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0301.png)'
- en: Figure 3-1\. With many AutoML services, we don’t have visibility into the chosen
    algorithms, applied data transformations, or hyper-parameter choices.
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-1。在许多自动机器学习服务中，我们无法看到所选算法、应用的数据转换或超参数选择。
- en: This makes it hard to understand, explain, and reproduce the model. Many AutoML
    solutions implement this kind of nontransparent approach. In contrast, SageMaker
    Autopilot documents and shares its findings throughout the data analysis, feature
    engineering, and model tuning steps.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得理解、解释和重现模型变得困难。许多自动机器学习解决方案采用这种不透明的方法。相比之下，SageMaker Autopilot 在数据分析、特征工程和模型调优步骤中文档并分享其发现。
- en: SageMaker Autopilot doesn’t just share the models; it also logs all observed
    metrics and generates Jupyter notebooks, which contain the code to reproduce the
    model pipelines, as visualized in [Figure 3-2](#autopilot_generates_jupyter_notebooksco).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Autopilot 不仅分享模型；它还记录所有观察到的指标，并生成包含用于重现模型流水线的代码的 Jupyter 笔记本，如图 3-2
    所示。
- en: '![](assets/dsaw_0302.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0302.png)'
- en: Figure 3-2\. SageMaker Autopilot generates Jupyter notebooks, feature engineering
    scripts, and model code.
  id: totrans-17
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-2。SageMaker Autopilot 生成 Jupyter 笔记本、特征工程脚本和模型代码。
- en: The data-analysis step identifies potential data-quality issues, such as missing
    values that might impact model performance if not addressed. The Data Exploration
    notebook contains the results from the data-analysis step. SageMaker Autopilot
    also generates another Jupyter notebook that contains all pipeline definitions
    to provide transparency and reproducibility. The Candidate Definition notebook
    highlights the best algorithms to learn our given dataset, as well as the code
    and configuration needed to use our dataset with each algorithm.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析步骤识别可能影响模型性能的数据质量问题，如缺失值。数据探索笔记本包含来自数据分析步骤的结果。SageMaker Autopilot 还生成另一个
    Jupyter 笔记本，其中包含所有流水线定义，以提供透明性和可重现性。候选定义笔记本突出显示了学习给定数据集的最佳算法，以及使用每种算法需要的代码和配置。
- en: Tip
  id: totrans-19
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Both Jupyter notebooks are available after the first data-analysis step. We
    can configure Autopilot to just do a “dry run” and stop after this step.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个数据分析步骤之后，两个 Jupyter 笔记本都可用。我们可以配置 Autopilot 只进行“干跑”并在此步骤后停止。
- en: Track Experiments with SageMaker Autopilot
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 SageMaker Autopilot 跟踪实验
- en: SageMaker Autopilot uses SageMaker Experiments to keep track of all data analysis,
    feature engineering, and model training/tuning jobs. This feature of the broader
    Amazon SageMaker family of ML services helps us organize, track, compare and evaluate
    machine learning experiments. SageMaker Experiments enables model versioning and
    lineage tracking across all phases of the ML life cycle.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 自动驾驶使用 SageMaker 实验来跟踪所有数据分析、特征工程和模型训练/调优作业。 Amazon SageMaker 家族的这一更广泛的
    ML 服务功能帮助我们组织、跟踪、比较和评估机器学习实验。 SageMaker 实验使模型版本控制和谱系跟踪在 ML 生命周期的所有阶段均可实现。
- en: A SageMaker Experiment consists of trials. A trial is a collection of steps
    that includes data preprocessing, model training, and model tuning. SageMaker
    Experiments also offers lineage tracking across S3 locations, algorithms, hyper-parameters,
    trained models, and model-performance metrics.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 实验由试验组成。 试验是一系列步骤的集合，包括数据预处理、模型训练和模型调优。 SageMaker 实验还提供了跨 S3 位置、算法、超参数、训练模型和模型性能指标的谱系跟踪。
- en: We can explore and manage SageMaker Autopilot experiments and trials either
    through the UI or using SDKs, such as the [Amazon SageMaker Python SDK](https://oreil.ly/nUN9I)
    or the [AWS SDK for Python (Boto3)](https://oreil.ly/eiN8j).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过 UI 或使用 SDK（如 [Amazon SageMaker Python SDK](https://oreil.ly/nUN9I) 或
    [AWS SDK for Python (Boto3)](https://oreil.ly/eiN8j)）来探索和管理 SageMaker 自动驾驶实验和试验。
- en: Note
  id: totrans-25
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The SageMaker SDK is a high-level, SageMaker-specific abstraction on top of
    Boto3 and is the preferred choice for SageMaker model development and management.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker SDK 是建立在 Boto3 之上的高级 SageMaker 特定抽象，是 SageMaker 模型开发和管理的首选选择。
- en: Train and Deploy a Text Classifier with SageMaker Autopilot
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 SageMaker 自动驾驶训练和部署文本分类器
- en: Let’s create a SageMaker Autopilot experiment to build a custom text classifier
    to classify social feedback on products that we are selling. The product feedback
    comes from various online channels, such as our website, partner websites, social
    media, customer support emails, etc. We capture the product feedback and want
    our model to classify the feedback into star rating classes, with 5 being the
    best feedback and 1 being the worst.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个 SageMaker 自动驾驶实验，构建一个定制的文本分类器，用于分类我们销售产品的社交反馈。 产品反馈来自各种在线渠道，如我们的网站、合作伙伴网站、社交媒体、客户支持电子邮件等。
    我们捕获产品反馈，并希望我们的模型将反馈分类为星级评价类别，5 表示最佳反馈，1 表示最差反馈。
- en: As input data, we leverage samples from the [Amazon Customer Reviews Dataset](https://oreil.ly/LjXva).
    This dataset is a collection of over 150 million product reviews on Amazon.com
    from 1995 to 2015\. Those product reviews and star ratings are a popular customer
    feature of Amazon.com. We will describe and explore this dataset in much more
    detail in Chapters [4](ch04.html#ingest_data_into_the_cloud) and [5](ch05.html#explore_the_dataset).
    For now, we focus on the `review_body` (feature) and `star_rating` (predicted
    label).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 作为输入数据，我们利用来自 [亚马逊客户评论数据集](https://oreil.ly/LjXva) 的样本。 该数据集是从 1995 年到 2015
    年在 Amazon.com 上收集的超过 1.5 亿产品评论的集合。 这些产品评论和星级评分是 Amazon.com 的热门客户功能。 我们将在第 [4](ch04.html#ingest_data_into_the_cloud)
    章和第 [5](ch05.html#explore_the_dataset) 章详细描述和探索此数据集。 现在，我们关注 `review_body`（特征）和
    `star_rating`（预测标签）。
- en: Train and Deploy with SageMaker Autopilot UI
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 SageMaker 自动驾驶 UI 进行训练和部署
- en: The SageMaker Autopilot UI is integrated into SageMaker Studio, an IDE that
    provides a single, web-based visual interface where we can perform our machine
    learning development. Simply navigate to Amazon SageMaker in our AWS Console and
    click SageMaker Studio. Then follow the instructions to set up SageMaker Studio
    and click Open Studio.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 自动驾驶 UI 集成在 SageMaker Studio 中，这是一个提供单一、基于 Web 的可视界面的 IDE，我们可以在其中进行机器学习开发。
    只需导航到 AWS 控制台中的 Amazon SageMaker，并单击 SageMaker Studio。 然后按照说明设置 SageMaker Studio
    并单击 Open Studio。
- en: This will take us to the SageMaker Studio UI, where we can access the SageMaker
    Autopilot UI through the Experiments and trials menu. There, we can click Create
    Experiment to create and configure our first SageMaker Autopilot experiment.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这将带我们进入 SageMaker Studio UI，在那里我们可以通过实验和试验菜单访问 SageMaker 自动驾驶 UI。 在那里，我们可以单击
    Create Experiment 来创建和配置我们的第一个 SageMaker 自动驾驶实验。
- en: 'In preparation for our SageMaker Autopilot experiment, we use a subset of the
    Amazon Customer Reviews Dataset to train our model. We want to train a classifier
    model to predict the `star_rating` for a given `review_body`. We created our input
    CSV file to contain the `star_rating` as our label/target column and the `review_body`
    column, which contains the product feedback:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备我们的 SageMaker Autopilot 实验时，我们使用亚马逊客户评论数据集的子集来训练我们的模型。我们希望训练一个分类器模型，以预测给定
    `review_body` 的 `star_rating`。我们创建了输入 CSV 文件，包含 `star_rating` 作为我们的标签/目标列和包含产品反馈的
    `review_body` 列：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In other scenarios, we will likely want to use more columns from our dataset
    and let SageMaker Autopilot choose the most important ones through automated feature
    selection. In our example, however, we keep things simple and use the `star_rating`
    and `review_body` columns to focus on the steps to create the Autopilot experiment.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他情况下，我们可能希望从数据集中使用更多列，并让 SageMaker Autopilot 通过自动特征选择选择最重要的列。然而，在我们的示例中，我们保持简单，并使用
    `star_rating` 和 `review_body` 列来专注于创建 Autopilot 实验的步骤。
- en: 'Next, we configure the SageMaker Autopilot experiment with a few input parameters
    that define the dataset, the target column to predict, and, optionally, the problem
    type, such as binary classification, multiclass classification, or regression.
    If we don’t specify the problem type, SageMaker Autopilot can automatically determine
    the problem type based on the values it finds in the target column:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用几个输入参数配置 SageMaker Autopilot 实验，这些参数定义数据集、要预测的目标列，以及可选的问题类型，如二元分类、多类分类或回归。如果我们没有指定问题类型，SageMaker
    Autopilot 可以根据目标列中的值自动确定问题类型。
- en: Experiment name
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 实验名称
- en: A name to identify the experiment, e.g., *amazon-customer-reviews*.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 用于标识实验的名称，例如 *amazon-customer-reviews*。
- en: Input data location
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 输入数据位置
- en: The S3 path to our training data, e.g., *s3://<MY-S3-BUCKET>/data/amazon_reviews_us_Digital_Software_v1_00_header.csv*.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们训练数据的 S3 路径，例如 *s3://<MY-S3-BUCKET>/data/amazon_reviews_us_Digital_Software_v1_00_header.csv*。
- en: Target
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 目标
- en: The target column we want to predict, e.g., `star_rating`.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要预测的目标列，例如 `star_rating`。
- en: Output data location
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 输出数据位置
- en: The S3 path for storing the generated output, such as models and other artifacts,
    e.g., *s3://<MY-S3-BUCKET>/autopilot/output*.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 存储生成输出的 S3 路径，例如模型和其他工件的 *s3://<MY-S3-BUCKET>/autopilot/output*。
- en: Problem type
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 问题类型
- en: The machine learning problem type, such as binary classification, multiclass
    classification, and regression. The default, “Auto,” allows SageMaker Autopilot
    to choose for itself based on the given input data, including categorical data.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习问题类型，如二元分类、多类分类和回归。默认情况下，“自动”允许 SageMaker Autopilot 根据给定的输入数据（包括分类数据）自行选择。
- en: Run complete experiment
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 运行完整实验
- en: We can choose to run a complete experiment or just generate the Data Exploration
    and Candidate Definition notebooks as part of the data analysis phase. In this
    case, SageMaker Autopilot stops after the data analysis phase and would not run
    the feature engineering, model training, and tuning steps.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以选择运行完整实验，或者仅生成数据探索和候选定义笔记本作为数据分析阶段的一部分。在这种情况下，SageMaker Autopilot 在数据分析阶段结束后停止，并且不会运行特征工程、模型训练和调优步骤。
- en: 'Let’s click Create Experiment and start our first SageMaker Autopilot job.
    We can observe the progress of the job in SageMaker Studio’s Autopilot UI through
    preprocessing, candidate generation, feature engineering, and model tuning. Once
    SageMaker Autopilot completes the candidate generation phase, we can see the links
    to the two generated notebooks appearing in the UI: Candidate Generation and Data
    Exploration.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们点击“创建实验”并启动我们的第一个 SageMaker Autopilot 作业。我们可以通过 SageMaker Studio 的 Autopilot
    UI 观察作业的进展，包括预处理、候选生成、特征工程和模型调优。一旦 SageMaker Autopilot 完成候选生成阶段，我们可以在 UI 中看到两个生成笔记本的链接：候选生成和数据探索。
- en: 'We can either download these files directly from the UI or automate the download
    from S3 directly. We can find the generated notebooks, code, and transformed data
    in the following structure:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以直接从 UI 下载这些文件，或者直接从 S3 自动化下载。我们可以在以下结构中找到生成的笔记本、代码和转换后的数据：
- en: '[PRE1]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: When the feature engineering stage starts, we will see SageMaker Training Jobs
    appearing in the AWS Console or within SageMaker Studio directly. Each training
    job is a combination of a model candidate and the data preprocessor (dpp) code,
    named `dpp0` through `dpp9`. We can think of those training jobs as the 10 machine
    learning pipelines SageMaker Autopilot builds to find the best-performing model.
    We can select any of those training jobs to view the job status, configuration,
    parameters, and log files. We will dive deep into feature engineering in [Chapter 6](ch06.html#prepare_the_dataset_for_model_training)
    and SageMaker Training Jobs in [Chapter 7](ch07.html#train_your_first_model).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当特征工程阶段开始时，我们将看到 SageMaker 训练作业出现在 AWS 控制台或直接在 SageMaker Studio 中。每个训练作业都是一个模型候选者与数据预处理器（dpp）代码的组合，命名为
    `dpp0` 到 `dpp9`。我们可以将这些训练作业看作是 SageMaker Autopilot 构建的 10 个机器学习管道，以找到性能最佳的模型。我们可以选择任何一个训练作业来查看作业状态、配置、参数和日志文件。我们将在第
    6 章深入探讨特征工程（[Chapter 6](ch06.html#prepare_the_dataset_for_model_training)）和 SageMaker
    训练作业（[Chapter 7](ch07.html#train_your_first_model)）。
- en: 'Once the feature-engineering stage has completed, we can view the transformed
    data directly in S3 grouped by pipeline. The data has been divided into smaller
    chunks and split into separate train and validation datasets, as shown in the
    following:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成特征工程阶段，我们可以直接在 S3 中按管道分组查看转换后的数据。数据已经被分成更小的块，并分为独立的训练和验证数据集，如下所示：
- en: '[PRE2]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Finally, SageMaker Autopilot runs the model-tuning stage, and we start seeing
    the trials appear in SageMaker Studio’s Autopilot UI. The model-tuning stage creates
    a SageMaker Hyper-Parameter Tuning Job. HPT, or hyper-parameter optimization (HPO),
    as it is commonly called, is natively supported by Amazon SageMaker and is usable
    outside of SageMaker Autopilot for standalone HPT jobs on custom models, as we
    will see in [Chapter 8](ch08.html#train_and_optimize_models_at_scale).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，SageMaker Autopilot 运行模型调优阶段，我们开始在 SageMaker Studio 的 Autopilot UI 中看到试验出现。模型调优阶段创建了一个
    SageMaker 超参数调整作业。HPT 或超参数优化（HPO），作为 Amazon SageMaker 的本地支持功能，可以在 SageMaker Autopilot
    之外的自定义模型上进行独立的 HPT 作业，我们将在第 8 章中看到（[Chapter 8](ch08.html#train_and_optimize_models_at_scale)）。
- en: SageMaker Hyper-Parameter Tuning Jobs find the best version of a model by running
    many training jobs on our dataset using the algorithm and ranges of hyper-parameters
    that we specify. SageMaker supports multiple algorithms for HPT, including random
    search and Bayesian search. With random search, SageMaker chooses random combinations
    of hyper-parameters from the ranges we specify. With Bayesian search, SageMaker
    treats tuning as a regression problem. We will explore SageMaker’s automatic model
    tuning functionality in [Chapter 8](ch08.html#train_and_optimize_models_at_scale).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 超参数调整作业通过在我们指定的算法和超参数范围上运行多个训练作业来找到模型的最佳版本。SageMaker 支持多种 HPT 算法，包括随机搜索和贝叶斯搜索。随机搜索时，SageMaker
    从我们指定的范围内随机选择超参数的组合。贝叶斯搜索时，SageMaker 将调整视为回归问题。我们将在第 8 章中探索 SageMaker 的自动模型调优功能（[Chapter 8](ch08.html#train_and_optimize_models_at_scale)）。
- en: We can find the corresponding training jobs listed in the SageMaker Training
    Jobs UI or within SageMaker Studio directly. Again, we can click and inspect any
    of these jobs to view the job status, configuration, parameters, and log files.
    Back in the SageMaker Autopilot UI, we can inspect the trials.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在 SageMaker 训练作业 UI 或直接在 SageMaker Studio 中找到相应的训练作业列表。同样，我们可以点击并检查这些作业以查看作业状态、配置、参数和日志文件。回到
    SageMaker Autopilot UI，我们可以检查试验。
- en: 'The four SageMaker Autopilot trial components make up a pipeline of the following
    jobs:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Autopilot 的四个试验组件构成以下作业的管道：
- en: Processing Job
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 处理作业
- en: Splits the data into train and validation data and separates the header data
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据分割为训练和验证数据，并分离头数据
- en: Training Job
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 训练作业
- en: Trains a batch transform model using the previously split training and validation
    data with the data preprocessor code (*dpp[0-9].py*) for each model candidate
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 使用先前分割的训练和验证数据以及数据预处理器代码（*dpp[0-9].py*）训练批量转换模型的每个模型候选者
- en: Batch Transform Job
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 批量转换作业
- en: Transforms the raw data into features
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 将原始数据转换为特征
- en: Tuning Job
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 调优作业
- en: Finds the best-performing model candidates using the previously transformed
    algorithm-specific features by optimizing the algorithm configuration and parameters
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 使用先前转换的特定算法特征来优化算法配置和参数，找到性能最佳的模型候选者
- en: 'Those four components preserve the model’s lineage by tracking all hyper-parameters,
    input datasets, and output artifacts. After the model-tuning step is completed,
    we can find the final outputs and model candidates in the S3 bucket organized
    per model-candidate pipeline:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这四个组件通过跟踪所有超参数、输入数据集和输出物件保留模型的血统。完成模型调整步骤后，我们可以在S3存储桶中找到按模型候选管线组织的最终输出和模型候选项：
- en: '[PRE3]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note that the pipeline name (i.e., `amazon-cus-dpp0-xgb`) conveniently contains
    information on the settings used (`dpp0` = data preprocessor pipeline dpp0, `xgb`
    = chosen algorithm XGBoost). In addition to programmatically retrieving the best-performing
    model, we can use SageMaker Studio’s Autopilot UI to visually highlight the best
    model.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，管线名称（即`amazon-cus-dpp0-xgb`）方便地包含所使用的设置信息（`dpp0` = 数据预处理管线dpp0，`xgb` = 选择的算法XGBoost）。除了以编程方式检索最佳模型外，我们还可以使用SageMaker
    Studio的Autopilot UI直观地突出显示最佳模型。
- en: Deploying this model into production is now as easy as right-clicking on the
    name and selecting the Deploy model action. We just need to give our endpoint
    a name, select the AWS instance type we want to deploy the model on, e.g., `ml.m5.xlarge`,
    and define the number of instances to serve our model.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将此模型部署到生产环境就像右键单击名称并选择“部署模型”操作一样简单。我们只需为我们的端点命名，选择要在其上部署模型的AWS实例类型，例如`ml.m5.xlarge`，并定义服务模型的实例数。
- en: Tip
  id: totrans-71
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: There is an overview of all AWS instance types supported by [Amazon SageMaker
    and their performance characteristics](https://oreil.ly/2AJ4c).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[Amazon SageMaker及其性能特征支持的所有AWS实例类型概述](https://oreil.ly/2AJ4c)'
- en: Note that those instances start with `ml.` in their name.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这些实例名称以`ml.`开头。
- en: Optionally, we can enable data capture of all prediction requests and responses
    for our deployed model. We can now click Deploy model and watch our model endpoint
    being created. Once the endpoint shows up as *In Service*, we can invoke the endpoint
    to serve predictions.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 可选地，我们可以启用对部署模型的所有预测请求和响应的数据捕获。现在，我们可以点击“部署模型”并观察我们的模型端点正在创建。一旦端点显示为*已启动*，我们就可以调用端点来提供预测。
- en: 'Here is a simple Python code snippet that shows how to invoke the model deployed
    to the SageMaker endpoint. We pass a sample review (“I loved it!”) and see which
    star rating our model chooses. Remember, star rating 1 is the worst, and star
    rating 5 is the best:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的Python代码片段，展示了如何调用部署到SageMaker端点的模型。我们传递一个样本评论（“我喜欢它！”），看看我们的模型选择了哪个星级评分。请记住，1星是最差的，5星是最好的：
- en: '[PRE4]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Here is the star rating that our model predicts:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我们的模型预测的星级评分：
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Our model successfully classified the review as a 5-star rating.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型成功将评论分类为5星评级。
- en: Train and Deploy a Model with the SageMaker Autopilot Python SDK
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用SageMaker Autopilot Python SDK训练和部署模型
- en: 'In addition to using the preceding SageMaker Autopilot UI, we can also launch
    a SageMaker Autopilot job using the Python SDK to train and deploy a text classifier
    in just a few lines of code, as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 除了使用前面的SageMaker Autopilot UI外，我们还可以使用Python SDK启动SageMaker Autopilot作业，仅需几行代码即可训练和部署文本分类器，具体如下：
- en: '[PRE6]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can specify the number of model candidates to explore and set a maximum
    runtime in seconds for each training job and the overall SageMaker Autopilot job:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以指定要探索的模型候选数目，并为每个训练作业和整体SageMaker Autopilot作业设置最长运行时间（以秒为单位）：
- en: '[PRE7]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Similar to the SageMaker Autopilot UI configuration, we provide an S3 input
    and output location and define the target attribute for predictions:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 与SageMaker Autopilot UI配置类似，我们提供了S3输入和输出位置，并定义了预测的目标属性：
- en: '[PRE8]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Next, we create our SageMaker Autopilot job. Note that we add a timestamp to
    the SageMaker Autopilot job name, which helps to keep the jobs unique and easy
    to track. We pass the job name, input/output configuration, job configuration,
    and execution role. The execution role is part of the AWS Identity and Access
    Management (IAM) service and manages service access permissions:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建我们的SageMaker Autopilot作业。请注意，我们向SageMaker Autopilot作业名称添加了时间戳，这有助于保持作业的唯一性和易于跟踪。我们传递作业名称、输入/输出配置、作业配置和执行角色。执行角色是AWS身份和访问管理（IAM）服务的一部分，管理服务访问权限：
- en: '[PRE9]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The SageMaker Autopilot job has been created with a unique identifier, described
    as `AutoMLJobArn` previously. ARN (Amazon Resource Name) is often encoded in the
    form of `arn:partition:service:region:account-id:resource-id`. ARNs are used across
    all AWS services to specify resources unambiguously.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Autopilot 作业已经创建，并且有一个唯一标识符，先前被描述为`AutoMLJobArn`。ARN（Amazon 资源名称）通常以`arn:partition:service:region:account-id:resource-id`的形式编码。ARN
    在所有 AWS 服务中用于明确指定资源。
- en: 'We can poll the SageMaker Autopilot job status and check if the data analysis
    step has completed:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以轮询 SageMaker Autopilot 作业状态，并检查数据分析步骤是否已完成：
- en: '[PRE10]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The code will return the following output (shortened):'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 代码将返回以下输出（已缩短）：
- en: '[PRE11]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Similarly, we can query for `job_sec_status in ('FeatureEngineering')` and `job_sec_status
    in ('ModelTuning')` for the two following SageMaker Autopilot steps.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们可以查询`job_sec_status in ('FeatureEngineering')`和`job_sec_status in ('ModelTuning')`，来进行
    SageMaker Autopilot 的另外两个步骤。
- en: 'Once the SageMaker Autopilot job has finished, we can list all model candidates:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦 SageMaker Autopilot 作业完成，我们可以列出所有模型候选者：
- en: '[PRE12]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This will generate output similar to this:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成类似于这样的输出：
- en: '[PRE13]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We can also retrieve the best candidate:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以检索最佳候选者：
- en: '[PRE14]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This will generate output similar to this:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成类似于这样的输出：
- en: '[PRE15]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now, let’s deploy the best model as a REST endpoint. First, we need to create
    a model object:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将最佳模型部署为 REST 端点。首先，我们需要创建一个模型对象：
- en: '[PRE16]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output should look similar to this:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应该类似于这样：
- en: '[PRE17]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The preceding code reveals another detail that has been hidden in the UI. When
    we deploy our model as a REST endpoint, we actually deploy a whole inference pipeline.
    The inference pipeline consists of three containers.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码揭示了 UI 中隐藏的另一个细节。当我们将模型部署为 REST 端点时，实际上部署了整个推理流水线。推理流水线由三个容器组成。
- en: Data transformation container
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 数据转换容器
- en: This is essentially the “request handler” that converts the application inputs
    (e.g., `review_body`) into a format recognized by the model (i.e., NumPy arrays
    or tensors). The container hosts the model that SageMaker Autopilot trained for
    the feature engineering step.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这本质上是“请求处理程序”，将应用程序输入（例如`review_body`）转换为模型认可的格式（即 NumPy 数组或张量）。该容器托管了 SageMaker
    Autopilot 为特征工程步骤训练的模型。
- en: Algorithm container
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 算法容器
- en: This container hosts the actual model that serves the predictions.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 此容器托管实际用于提供预测的模型。
- en: Inverse label transformer container
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 逆标签转换器容器
- en: This is the “response handler” that converts the algorithm-specific output (i.e.,
    NumPy arrays or tensors) back into a format recognized by the invoker (e.g., `star_rating`).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这是“响应处理程序”，将算法特定的输出（例如 NumPy 数组或张量）转换为调用者认可的格式（例如`star_rating`）。
- en: '[Figure 3-3](#autopilot_deploys_a_model_as_an_inferen) shows an example of
    the inference pipeline.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[Figure 3-3](#autopilot_deploys_a_model_as_an_inferen) 展示了推理流水线的示例。'
- en: '![](assets/dsaw_0303.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0303.png)'
- en: Figure 3-3\. SageMaker Autopilot deploys a model as an inference pipeline.
  id: totrans-116
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-3\. SageMaker Autopilot 将模型部署为推理流水线。
- en: We pass our reviews as raw text, and the data transformation container converts
    the text into TF/IDF vectors. TF/IDF stands for *term frequency–inverse document
    frequency* and causes more common terms to be downweighted and more unique terms
    to be upweighted. TF/IDF encodes the relevance of a word to a document in a collection
    of documents.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将我们的评论作为原始文本传递，数据转换容器将文本转换为 TF/IDF 向量。TF/IDF 代表*词频-逆文档频率*，导致常见词项被降权，而独特词项被加权。TF/IDF
    编码了一个词对于文档集合中文档的相关性。
- en: The algorithm container processes the input and predicts the star rating. Note
    that the algorithm in our example returns the prediction results as a 0-based
    index value. The task of the inverse label transformer container is to map the
    index (0,1,2,3,4) to the correct star rating label (1,2,3,4,5).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 算法容器处理输入并预测星级评分。请注意，我们示例中的算法将预测结果作为基于0的索引值返回。逆标签转换器容器的任务是将索引（0,1,2,3,4）映射到正确的星级评分标签（1,2,3,4,5）。
- en: 'To deploy the inference pipeline, we need to create an endpoint configuration:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署推理流水线，我们需要创建一个端点配置：
- en: '[PRE18]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'SageMaker Autopilot is now deploying the inference pipeline. Let’s query for
    the endpoint status to see when the pipeline is successfully in service:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Autopilot 现在正在部署推理流水线。让我们查询端点状态，查看何时流水线成功投入服务：
- en: '[PRE19]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'After a couple of minutes, the output should look similar to this:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 几分钟后，输出应该类似于这样：
- en: '[PRE20]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We can now invoke the endpoint and run a sample prediction. We pass the review
    “It’s OK.” to see which star-rating class the model predicts:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以调用端点并运行一个样本预测。我们传递评论 “还行。” 来查看模型预测的星级分类：
- en: '[PRE21]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let’s print the response:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们打印响应：
- en: '[PRE22]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Our endpoint has successfully classified this sample review as a 3-star rating.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的端点已成功将此样本评论分类为 3 星评级。
- en: Note
  id: totrans-130
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: We can check the S3 output location again for all generated models, code, and
    other artifacts, including the Data Exploration notebook and Candidate Definition
    notebook.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以再次检查 S3 输出位置，查看所有生成的模型、代码和其他工件，包括数据探索笔记本和候选定义笔记本。
- en: Invoking our models using the SageMaker SDK is just one option. There are many
    more service integrations available in AWS. In the next section, we describe how
    we can run real-time predictions from within a SQL query using Amazon Athena.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 SageMaker SDK 调用我们的模型只是其中一种选项。在 AWS 中还有许多其他服务集成可用。在下一节中，我们将描述如何通过 Amazon
    Athena 在 SQL 查询中运行实时预测。
- en: Predict with Amazon Athena and SageMaker Autopilot
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Amazon Athena 和 SageMaker Autopilot 进行预测
- en: Amazon Athena is an interactive query service that lets us analyze data stored
    in S3 using standard SQL. Since Athena is serverless, we don’t need to manage
    any infrastructure, and we only pay for the queries we run. With Athena, we can
    query large amounts of data (TB+) without needing to move the data to a relational
    database. We can now enrich our SQL queries with calls to a SageMaker model endpoint
    and receive model predictions.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Athena 是一个交互式查询服务，允许我们使用标准 SQL 分析存储在 S3 中的数据。由于 Athena 是无服务器的，我们无需管理任何基础设施，只需为我们运行的查询付费。通过
    Athena，我们可以查询大量数据（TB+），而无需将数据移动到关系数据库。现在，我们可以通过调用 SageMaker 模型端点丰富我们的 SQL 查询，并接收模型预测。
- en: To call SageMaker from Athena, we need to define a function with the `USING
    FUNCTION` clause, as shown in [Figure 3-4](#we_can_invoke_a_sagemaker_model_from_am).
    Any subsequent `SELECT` statement can then reference the function to invoke a
    model prediction.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 要从 Athena 调用 SageMaker，我们需要使用 `USING FUNCTION` 子句定义一个函数，如 [Figure 3-4](#we_can_invoke_a_sagemaker_model_from_am)
    中所示。随后的任何 `SELECT` 语句都可以引用该函数来调用模型预测。
- en: '![](assets/dsaw_0304.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0304.png)'
- en: Figure 3-4\. We can invoke a SageMaker model from Amazon Athena ML using a user-defined
    function.
  id: totrans-137
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-4\. 我们可以通过用户定义函数从 Amazon Athena ML 调用 SageMaker 模型。
- en: 'Here’s a simple SQL query that selects product reviews stored in an Athena
    table called `dsaws.product_reviews`. The function `predict_star_rating` then
    calls a SageMaker endpoint with the name `reviews` to serve the prediction:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的 SQL 查询，选择存储在名为 `dsaws.product_reviews` 的 Athena 表中的产品评论。函数 `predict_star_rating`
    然后使用名称为 `reviews` 的 SageMaker 端点进行预测：
- en: '[PRE23]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The result should look similar to this (shortened):'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应该类似于以下内容（已缩短）：
- en: '| review_id | review_body | predicted_star_rating |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| review_id | review_body | predicted_star_rating |'
- en: '| --- | --- | --- |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| R23CFDQ6SLMET | The photographs of this book is a let down. I ... | 1 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| R23CFDQ6SLMET | 本书的照片令人失望。我 ... | 1 |'
- en: '| R1301KYAYKX8FU | This is my go-to commentary for all of my semi... | 5 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| R1301KYAYKX8FU | 这是我为所有我半 ... 的评论的评论 ... | 5 |'
- en: '| R1CKM3AKI920D7 | I can’t believe I get to be the first to tell ... | 5 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| R1CKM3AKI920D7 | 我简直不敢相信我能成为第一个告诉 ... | 5 |'
- en: '| RA6CYWHAHSR9H | There’s Something About Christmas / Debbie Mac... | 5 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| RA6CYWHAHSR9H | 圣诞节有点不同 / 黛比·麦克 ... | 5 |'
- en: '| R1T1CCMH2N9LBJ | This revised edition by Murray Straus is an ex... | 1 |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| R1T1CCMH2N9LBJ | Murray Straus 的这一修订版是一个 ... | 1 |'
- en: '| ... | ... | ... |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| ... | ... | ... |'
- en: This example shows how easy it is to enrich our S3 data with machine learning
    prediction results using a simple SQL query.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例展示了如何使用简单的 SQL 查询丰富我们的 S3 数据，利用机器学习预测结果。
- en: Train and Predict with Amazon Redshift ML and SageMaker Autopilot
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Amazon Redshift ML 和 SageMaker Autopilot 进行训练和预测
- en: 'Amazon Redshift is a fully managed data warehouse that allows us to run complex
    analytic queries against petabytes of structured data. With Amazon Redshift ML,
    we can use our data in Amazon Redshift to create and train models with SageMaker
    Autopilot as new data arrives. Following is the code to train a text classifier
    model with training data retrieved from an Amazon Redshift query. The `SELECT`
    statement points to the data in Amazon Redshift we want to use as training data
    for our model. The `TARGET` keyword defines the column to predict. The `FUNCTION`
    keyword defines the function name used to invoke the model in a prediction Amazon
    Redshift query:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift是一款完全托管的数据仓库，允许我们针对以PB计的结构化数据运行复杂的分析查询。借助Amazon Redshift ML，我们可以利用Amazon
    Redshift中的数据使用SageMaker Autopilot来创建和训练模型，随着新数据的到来。以下是使用从Amazon Redshift查询检索到的训练数据来训练文本分类器模型的代码。`SELECT`语句指向Amazon
    Redshift中我们要用作模型训练数据的数据。`TARGET`关键字定义了要预测的列。`FUNCTION`关键字定义了在预测Amazon Redshift查询中调用模型时使用的函数名称。
- en: '[PRE24]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The preceding statement executes an Amazon Redshift query, exports the selected
    data to S3, and triggers a SageMaker Autopilot job to generate and deploy the
    model. Amazon Redshift ML then deploys the trained model and function in our Amazon
    Redshift cluster called `predict_star_rating`.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 上述语句执行了一个Amazon Redshift查询，将选择的数据导出到S3，并触发了一个SageMaker Autopilot作业来生成和部署模型。然后，Amazon
    Redshift ML在我们称为`predict_star_rating`的Amazon Redshift集群中部署训练好的模型和函数。
- en: 'To make predictions with our trained Amazon Customer Reviews text classifier
    model, we query the `review_body` column in Amazon Redshift and predict the `star_rating`
    as follows:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用我们训练过的Amazon Customer Reviews文本分类器模型进行预测，我们在Amazon Redshift中查询`review_body`列，并预测`star_rating`如下：
- en: '[PRE25]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Here are sample query results that demonstrate Amazon Redshift ML:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是演示Amazon Redshift ML的示例查询结果：
- en: '| review_body | predicted_star_rating |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| review_body | predicted_star_rating |'
- en: '| --- | --- |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| I love this product! | 5 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| I love this product! | 5 |'
- en: '| It’s ok. | 3 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 没问题。 | 3 |'
- en: '| This product is terrible. | 1 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| This product is terrible. | 1 |'
- en: Automated Machine Learning with Amazon Comprehend
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Amazon Comprehend进行自动化机器学习
- en: Amazon Comprehend is a fully managed AI service for natural language processing
    (NLP) tasks using AutoML to find the best model for our dataset. Amazon Comprehend
    takes text documents as input and recognizes entities, key phrases, language,
    and sentiment. Amazon Comprehend continues to improve as new language models are
    discovered and incorporated into the managed service.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Comprehend是一款完全托管的AI服务，用于自然语言处理（NLP）任务，使用AutoML来为我们的数据集找到最佳模型。Amazon
    Comprehend将文本文档作为输入，并识别实体、关键短语、语言和情感。随着新的语言模型被发现并纳入托管服务中，Amazon Comprehend继续改进。
- en: Predict with Amazon Comprehend’s Built-in Model
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Amazon Comprehend内置模型进行预测
- en: Sentiment analysis is a text classification task that predicts positive, negative,
    or neutral sentiment of a given input text. This is extremely helpful if we want
    to analyze product reviews and identify product-quality issues from social streams,
    for example.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 情感分析是一个文本分类任务，用于预测给定输入文本的正面、负面或中性情感。例如，如果我们想要分析产品评价并从社交流中识别产品质量问题，这将非常有帮助。
- en: Let’s implement this text classifier with Amazon Comprehend. As input data,
    we leverage a subset of the Amazon Customer Reviews Dataset. We want Amazon Comprehend
    to classify the sentiment of a provided review. The Comprehend UI is the easiest
    way to get started. We can paste in any text and Amazon Comprehend will analyze
    the input in real time using the built-in model. Let’s test this with a sample
    product review such as “I loved it! I will recommend this to everyone.” After
    clicking Analyze, we see the positive-sentiment prediction and prediction confidence
    score under the Insights tab. The score tells us that Amazon Comprehend is 99%
    confident that our sample review has a positive sentiment. Now let’s implement
    a custom model that classifies our product reviews into star ratings again.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用Amazon Comprehend实现这个文本分类器。作为输入数据，我们利用亚马逊客户评价数据集的一个子集。我们希望Amazon Comprehend对提供的评价分类情感。Comprehend
    UI是开始的最简单方式。我们可以粘贴任何文本，Amazon Comprehend将实时使用内置模型分析输入。我们可以点击“分析”，在“洞察”标签下看到正面情感预测和预测置信度分数。该分数告诉我们，Amazon
    Comprehend对我们的示例评价有99%的置信度认为是正面情感。现在让我们实现一个自定义模型，再次将我们的产品评价分类为星级评分。
- en: Train and Deploy a Custom Model with the Amazon Comprehend UI
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Amazon Comprehend UI训练和部署自定义模型
- en: 'Comprehend Custom is an example of automated machine learning that enables
    the practitioner to fine-tune Amazon Comprehend’s built-in model to a specific
    dataset. Let’s reuse the Amazon Customer Reviews Dataset file from the previous
    SageMaker Autopilot example as our training data:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: Comprehend自定义是自动化机器学习的一个例子，它使从业者能够微调Amazon Comprehend的内置模型以适应特定数据集。让我们从之前的SageMaker
    Autopilot示例中重新使用Amazon客户评价数据集文件作为我们的训练数据：
- en: '[PRE26]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We can use the Comprehend UI to train a custom multiclass text classifier by
    providing a name for the custom classifier, selecting multiclass mode, and putting
    in the path to the training data. Next, we define the S3 location to store the
    trained model outputs and select an IAM role with permissions to access that S3
    location. Then, we click Train classifier to start the training process. We now
    see the custom classifier show up in the UI with the status `Submitted` and shortly
    after with the status `Training`.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用Comprehend UI通过为自定义分类器提供一个名称、选择多类模式并输入训练数据的路径来训练自定义多类文本分类器。接下来，我们定义一个S3位置来存储训练模型输出，并选择一个具有访问该S3位置权限的IAM角色。然后，我们点击“训练分类器”来开始训练过程。现在我们在UI中看到自定义分类器显示为“已提交”，不久后变为“训练中”状态。
- en: Once the classifier shows up as `Trained`, we can deploy it as a Comprehend
    Endpoint to serve predictions. Simply select the trained model and click Actions.
    Give the endpoint a name and click Create Endpoint.In the Comprehend UI, navigate
    to Real-time analysis and select the analysis type Custom. Select the custom endpoint
    from the endpoint drop-down list. Amazon Comprehend can now analyze input text
    using the custom text classifier model. Let’s paste in the review “Really bad.
    I hope they don’t make this anymore.” and click Analyze.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦分类器显示为`已训练`，我们就可以将其部署为Comprehend端点以提供预测。只需选择已训练的模型并点击操作。给端点取一个名字然后点击创建端点。在Comprehend
    UI中，导航到实时分析并选择自定义分析类型。从端点下拉列表中选择自定义端点。Amazon Comprehend现在可以使用自定义文本分类器模型分析输入文本。让我们粘贴评论“真的很糟糕。我希望他们不再制造这个了。”然后点击分析。
- en: We can see in the results that our custom model now classifies input text into
    the star ratings from 1 to 5 (with 5 being the best rating). In this example,
    the model is 76% confident that the review classifies as star-rating 2.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 从结果中我们可以看到，我们的自定义模型现在将输入文本分类为星级评分从1到5（5为最佳评级）。在这个例子中，模型有76%的置信度认为该评论属于星级评分2。
- en: In just a few clicks, we trained a Comprehend Custom model on the Amazon Customer
    Reviews Dataset to predict a star rating from review text. That is the power of
    Amazon AI services.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 只需点击几下，我们就在Amazon客户评价数据集上训练了一个Comprehend自定义模型，以预测评论文本的星级评分。这就是Amazon AI服务的威力。
- en: Train and Deploy a Custom Model with the Amazon Comprehend Python SDK
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Amazon Comprehend Python SDK训练和部署自定义模型
- en: 'We can also interact programmatically with Amazon Comprehend. Let’s use the
    Amazon Comprehend Python SDK to train and deploy the custom classifier:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过Amazon Comprehend进行程序化交互。让我们使用Amazon Comprehend Python SDK来训练和部署自定义分类器：
- en: '[PRE27]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The input parameters are as follows:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 输入参数如下：
- en: '`DocumentClassifierName`'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '`DocumentClassifierName`'
- en: The name of the custom model
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义模型的名称
- en: '`DataAccessRoleArn`'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '`DataAccessRoleArn`'
- en: The ARN of the IAM role that grants Amazon Comprehend read access to our input
    data
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 授予Amazon Comprehend读取输入数据权限的IAM角色的ARN。
- en: '`InputDataConfig`'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '`InputDataConfig`'
- en: 'Specifies the format and location of the training data (`S3Uri`: S3 path to
    the training data)'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '指定训练数据的格式和位置（`S3Uri`: 训练数据的S3路径）'
- en: '`OutputDataConfig`'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '`OutputDataConfig`'
- en: Specifies the location of the model outputs (`S3Uri:` S3 path for model outputs)
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 指定模型输出的位置（`S3Uri:` 模型输出的S3路径）
- en: '`LanguageCode`'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '`LanguageCode`'
- en: The language of the training data
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据的语言
- en: The training job will now run for some time depending on the amount of training
    data to process. Once it is finished, we can deploy an endpoint with our custom
    classifier to serve predictions.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 训练作业将根据需要处理的训练数据量运行一段时间。一旦完成，我们可以部署一个端点，使用我们的自定义分类器进行预测。
- en: 'To deploy the custom model, let’s first find out the ARN of the model that
    we need to reference:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署自定义模型，让我们首先找出需要引用的模型的ARN：
- en: '[PRE28]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'With the `model_arn`, we can now create a model endpoint:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`model_arn`，我们现在可以创建一个模型端点：
- en: '[PRE29]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The input parameters are as follows:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 输入参数如下：
- en: '`EndpointName`'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '`EndpointName`'
- en: A name for our endpoint.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们端点的名称。
- en: '`ModelArn`'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '`ModelArn`'
- en: The ARN of the model to which the endpoint will be attached.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 将端点附加到模型的ARN。
- en: '`DesiredInferenceUnits`'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '`DesiredInferenceUnits`'
- en: The desired number of inference units to be used by the model attached to this
    endpoint. Each inference unit represents a throughput of one hundred characters
    per second.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 模型附加到此端点上所需的推理单元数。每个推理单元表示每秒一百个字符的吞吐量。
- en: 'Once the model endpoint is successfully created and `In Service`, we can invoke
    it for a sample prediction. To invoke the custom model, let’s find out the ARN
    of our endpoint:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型端点成功创建并处于`In Service`状态，我们可以为样本预测调用它。要调用定制模型，让我们找出端点的ARN：
- en: '[PRE30]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We can now run a prediction using `comprehend.classify_document()` along with
    text we want to classify and the ARN of our endpoint:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用`comprehend.classify_document()`来运行预测，以及我们想要分类的文本和端点的ARN：
- en: '[PRE31]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The JSON-formatted response will look similar to this:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: JSON格式的响应将类似于这样：
- en: '[PRE32]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Our custom classifier is 97% confident that our sample review deserves a 3-star
    rating. And with just a few lines of Python code, we trained an Amazon Comprehend
    Custom model on the Amazon Customer Reviews Dataset to predict a star rating from
    review text.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的定制分类器有97%的置信度认为我们的样本评论应该得到3星评分。只需几行Python代码，我们就能在亚马逊顾客评论数据集上训练一个Amazon Comprehend定制模型，以预测评论文本的星级评分。
- en: Summary
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we discussed the concept of AutoML. We introduced SageMaker
    Autopilot’s transparent approach to AutoML. SageMaker Autopilot offloads the heavy
    lifting of building ML pipelines while providing full visibility into the automated
    process. We demonstrated how to invoke machine learning models from SQL queries
    using Amazon Athena. We also showed how Amazon Comprehend uses AutoML to train
    and deploy a custom text classification model based on the public Amazon Customer
    Reviews Dataset in just a few clicks or lines of Python code.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了AutoML的概念。我们介绍了SageMaker Autopilot对AutoML的透明化方法。SageMaker Autopilot可以在提供完整自动化过程可见性的同时，卸下构建ML管道的重担。我们展示了如何通过Amazon
    Athena从SQL查询中调用机器学习模型。我们还展示了Amazon Comprehend如何利用AutoML在几次点击或几行Python代码中，基于公共Amazon顾客评论数据集训练和部署定制文本分类模型。
- en: In the following chapters, we will dive deep into building a custom BERT-based
    text classifier with Amazon SageMaker and TensorFlow to classify product reviews
    from different sources, including social channels and partner websites.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将深入探讨如何使用Amazon SageMaker和TensorFlow构建基于BERT的定制文本分类器，用于分类来自不同来源（包括社交渠道和合作伙伴网站）的产品评论。
