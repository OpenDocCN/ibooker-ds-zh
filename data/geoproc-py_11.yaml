- en: Chapter 12\. Map classification
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第12章 地图分类
- en: '*This chapter covers*'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章涵盖*'
- en: Using the `spectral` module for unsupervised map classification
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `spectral` 模块进行无监督地图分类
- en: Using the `scikit-learn` module for supervised map classification
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `scikit-learn` 模块进行监督式地图分类
- en: One common use for raster data is map classification, which involves categorizing
    the pixels into groups. For example, say you wanted to create a vegetation landcover
    dataset. You might use satellite imagery, elevation, slope, geology, precipitation,
    or other input data in order to create your classifications. The techniques we’ve
    looked at so far will help you prepare your datasets, but you need something else
    in order to classify pixels. Many different classification techniques exist, and
    which one you use will probably depend on your use case and available resources.
    This section is by no means a comprehensive introduction to map classification,
    and you should consult a remote sensing book if you want to learn more, but at
    least you’ll get an idea of what’s possible.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 栅格数据的一个常见用途是地图分类，这涉及到将像素分类到不同的组中。例如，假设您想创建一个植被土地覆盖数据集。您可能会使用卫星图像、海拔、坡度、地质、降水或其他输入数据来创建您的分类。我们迄今为止探讨的技术将帮助您准备数据集，但您还需要其他东西来对像素进行分类。存在许多不同的分类技术，您使用哪种技术可能取决于您的用例和可用资源。本节绝对不是地图分类的全面介绍，如果您想了解更多信息，请查阅遥感书籍，但至少您会了解可能实现的内容。
- en: You’ll use four bands from a Landsat 8 image to see how well you can replicate
    the landcover classification from the SWReGAP project that you saw earlier. These
    classifications include groupings such as “Great Basin Pinyon-Juniper Woodland”
    and “Inter-Mountain Basins Playa.” Although this project covered five states in
    the southwestern United States, you’ll only look at the area covered by one Landsat
    scene ([figure 12.1](#ch12fig01)). Landsat scenes contain more than four bands,
    but you’ll only use the three visible bands (red, green, and blue, which make
    up the natural color image) and a thermal band. You’ll also use versions of these
    bands that have been resampled from 30-meter to 60-meter pixels so that the examples
    run faster and your computer is less likely to run into memory issues.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 您将使用 Landsat 8 图像中的四个波段来查看您能多好地复制您之前看到的 SWReGAP 项目的土地覆盖分类。这些分类包括“大盆地松树-刺柏林地”和“山地盆地盐沼”等分组。尽管这个项目覆盖了美国西南部的五个州，但您将只查看一个
    Landsat 场景覆盖的区域（[图12.1](#ch12fig01)）。Landsat 场景包含超过四个波段，但您将只使用三个可见波段（红、绿、蓝，这些组成了自然色图像）和一个热波段。您还将使用这些波段从30米像素重新采样到60米像素的版本，这样示例运行得更快，您的计算机不太可能遇到内存问题。
- en: Figure 12.1\. The SWReGAP landcover dataset for Utah with the Landsat scene
    footprint drawn on top. The red, green, and blue bands of the Landsat dataset
    make up the natural color image, and the thermal band is shown alone.
  id: totrans-6
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图12.1. 犹他州的 SWReGAP 土地覆盖数据集，上面绘制了 Landsat 场景足迹。Landsat 数据集的红、绿、蓝波段组成了自然色图像，而热波段单独显示。
- en: '![](12fig01.jpg)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![图片](12fig01.jpg)'
- en: You’ll use the SWReGAP field data when necessary. Don’t expect your results
    to rival theirs, though, because that project involved many years of work, with
    thousands of locations visited in person to collect data, a much more comprehensive
    set of predictor variables at 30-meter resolution, and more-sophisticated modeling
    methods. In addition, the SWReGAP dataset consists of more than 100 distinct landcover
    classifications, but these examples won’t produce nearly so many classes. You’ll
    see that your simpler models can replicate several of the same general patterns,
    however.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 当需要时，您将使用 SWReGAP 场地数据。但不要期望您的结果能与他们相媲美，因为那个项目涉及多年的工作，亲自访问了成千上万个地点来收集数据，拥有30米分辨率的更全面的预测变量集，以及更复杂的建模方法。此外，SWReGAP
    数据集包含超过100种不同的土地覆盖分类，但这些示例不会产生如此多的类别。然而，您会发现您更简单的模型可以复制几个相同的一般模式。
- en: 'The examples in this section use a few new Python modules: Spectral Python,
    SciKit-Learn, and SciKit-Learn Laboratory. Please see [appendix A](kindle_split_022.html#app01)
    for installation instructions.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中的示例使用了几个新的 Python 模块：Spectral Python、SciKit-Learn 和 SciKit-Learn Laboratory。请参阅[附录A](kindle_split_022.html#app01)以获取安装说明。
- en: 12.1\. Unsupervised classification
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1. 无监督分类
- en: Unsupervised classification methods group pixels together based on their similarities,
    with no information from the user about which ones belong together. The user selects
    the independent, or predictor, variables of interest, and the chosen algorithm
    does the rest. This doesn’t mean that you don’t need to know what you’re classifying,
    however. Once a classification is produced, it’s up to the user to interpret it
    and decide which types of features correspond to which generated classes, or if
    they even do correspond nicely.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督分类方法根据像素的相似性将像素分组，没有任何用户关于哪些像素属于一起的信息。用户选择感兴趣的独立或预测变量，然后选定的算法完成剩余的工作。但这并不意味着你不需要知道你在分类什么。一旦产生了分类，用户就必须解释它，并决定哪些类型的特征对应于哪些生成的类别，或者它们是否甚至很好地对应。
- en: The Spectral Python module is designed for working with hyperspectral image
    data, of which Landsat data is an example. You’ll use a k-means clustering algorithm
    to group the pixels into clusters and then visually compare your results to the
    SWReGAP classification. But first, let’s write a function that takes a list of
    filenames as a parameter, reads in all bands from all files, and returns the data
    as a three-dimensional NumPy array. We’ll use this function in the next few listings,
    and to make things easier, it’s in the `ospybook` module.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Spectral Python 模块旨在处理高光谱图像数据，其中 Landsat 数据是一个例子。你将使用 k-means 聚类算法将像素分组到聚类中，然后直观地将你的结果与
    SWReGAP 分类进行比较。但首先，让我们编写一个函数，该函数接受一个文件名列表作为参数，从所有文件中读取所有波段，并将数据作为三维 NumPy 数组返回。我们将在接下来的几个列表中使用这个函数，为了方便起见，它位于
    `ospybook` 模块中。
- en: Listing 12.1\. Function to stack raster bands
  id: totrans-13
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 12.1\. 堆叠栅格波段的功能
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now back to the classification problem. A k-means algorithm begins with an initial
    set of cluster centers and then assigns each pixel to a cluster based on distance.
    This distance is computed as if the pixel values were coordinates. For example,
    if two pixel values were 25 and 42, the distance would be 17, no matter where
    the pixels were in relation to each other spatially.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 现在回到分类问题。k-means 算法从一组初始聚类中心开始，然后根据距离将每个像素分配到聚类中。这个距离是假设像素值是坐标来计算的。例如，如果两个像素值是
    25 和 42，那么距离将是 17，无论这些像素在空间上的相对位置如何。
- en: After this process has completed, the centroids of the clusters are then used
    as starting points, and the process repeats until the maximum number of iterations
    or a user-defined stopping condition is reached.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在此过程完成后，聚类中心被用作起点，然后重复此过程，直到达到最大迭代次数或用户定义的停止条件。
- en: Running the default classification is quite easy, as you’ll see in the following
    listing. In fact, it’s only one line of code, and the bulk of the example consists
    of setting things up and saving the output. That code has been shortened, also,
    by using custom functions in the `ospybook` module.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 运行默认分类非常简单，你将在下面的列表中看到。事实上，这只是一行代码，而示例的大部分内容都是设置和保存输出。此外，通过使用 `ospybook` 模块中的自定义函数，这段代码也被缩短了。
- en: Listing 12.2\. K-means clustering with Spectral Python
  id: totrans-18
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 12.2\. 使用 Spectral Python 进行 K-means 聚类
- en: '![](278fig01_alt.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图片](278fig01_alt.jpg)'
- en: The only required parameter to the `kmeans` function is an array containing
    the predictor variables, which is in the three-dimensional array returned by `stack_bands`.
    You could also specify the number of output clusters desired, maximum number of
    iterations, several initial clusters, or a few other things. The default 10 clusters
    and 20 iterations are sufficient for the example, however. Feel free to consult
    the Spectral Python online documentation for more information.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '`kmeans` 函数的唯一必需参数是一个包含预测变量的数组，该数组是 `stack_bands` 返回的三维数组。你也可以指定所需的输出聚类数、最大迭代次数、几个初始聚类或其他一些东西。然而，对于这个例子，默认的
    10 个聚类和 20 次迭代是足够的。如果你需要更多信息，请随时查阅 Spectral Python 在线文档。'
- en: Assuming you got the same results I did, the algorithm only created nine classes
    instead of ten, but it would have created ten if it could resolve them with the
    given data. I went to the trouble to try to match the resulting classes with SWReGAP
    classes so that you can see a visual comparison, although admittedly, this works
    best if you’re looking at a color version of [figure 12.2](#ch12fig02). The classification
    is definitely different, but at least the mountains in the east are clearly separated
    from the flats and playas to the west. It’s possible that the match would be better
    if more clusters had been requested, because the SWReGAP data contains a much
    larger number of classes. If you were to run a classification like this, you’d
    have to determine what each cluster represented, as I tried to match up clusters
    with existing classifications.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你得到了与我相同的结果，算法只创建了九个类别而不是十个，但如果它能用给定数据解决它们，它本可以创建十个。我费尽周折试图将结果类别与SWReGAP类别相匹配，以便你可以看到视觉比较，尽管诚然，如果你查看的是[图12.2](#ch12fig02)的颜色版本，这会更好。分类确实不同，但至少东部的山脉与西部的平原和盆地明显分开。如果请求了更多的聚类，匹配可能会更好，因为SWReGAP数据包含许多更多的类别。如果你要运行这样的分类，你必须确定每个聚类代表什么，就像我试图将聚类与现有分类相匹配一样。
- en: Figure 12.2\. The SWReGAP landcover dataset and one created using unsupervised
    classification
  id: totrans-22
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '![图12.2](12fig02_alt.jpg) SWReGAP土地覆盖数据集和通过无监督分类创建的一个数据集'
- en: '![](12fig02_alt.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图片](12fig02_alt.jpg)'
- en: 12.2\. Supervised classification
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2. 监督分类
- en: Supervised classification, unlike unsupervised techniques, requires input from
    the user in the form of training data. A training dataset contains all of the
    independent variables that correspond to a known value for the dependent variable.
    For example, if you knew for a fact that a particular pixel was an agricultural
    field, then you could sample your input datasets, such as satellite imagery, at
    that location and include those pixel values as the independent variables. The
    model is fitted using these input data and then it can be applied to your full
    datasets to get a spatial representation of the model results.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 与无监督技术不同，监督分类需要用户以训练数据的形式提供输入。训练数据集包含所有与因变量已知值相对应的独立变量。例如，如果你确实知道某个特定像素是农业用地，那么你可以在该位置采样你的输入数据集，如卫星图像，并将这些像素值作为独立变量包括在内。模型使用这些输入数据进行拟合，然后它可以应用于你的完整数据集以获得模型结果的空问表示。
- en: It used to be that training data had to be collected by visiting locations in
    person and documenting first-hand what the actual classification should be. In
    this age of high-resolution online imagery, however, in certain cases researchers
    can determine these values from imagery without leaving their desks. This is definitely
    a more cost-effective solution, although it certainly isn’t appropriate or possible
    for every situation. Because accurate training datasets are essential for supervised
    classification, consider collecting data in the field if possible. Even if the
    truth can be determined by looking at imagery, the modeling process is still necessary,
    unless you want to manually classify every pixel.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 以前，训练数据必须通过亲自访问地点并记录实际分类应该是什么来收集。然而，在这个高分辨率在线图像的时代，在某些情况下，研究人员可以在不出办公室的情况下从图像中确定这些值。这绝对是一个更经济有效的解决方案，尽管它当然不适用于或不可能适用于每种情况。由于准确的训练数据集对于监督分类至关重要，如果可能的话，考虑在野外收集数据。即使可以通过查看图像确定真相，建模过程仍然是必要的，除非你想要手动对每个像素进行分类。
- en: We’ll take a look at one example of supervised classification using a decision
    tree. This type of model consists of a hierarchical set of conditions based on
    the model’s independent variables, and has at least one pathway that leads to
    each possible outcome. [Figure 12.3](#ch12fig03) shows a simple, if not accurate,
    example of a decision tree.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将查看使用决策树进行监督分类的一个示例。此类模型由基于模型独立变量的分层条件集组成，并且至少有一条路径通向每个可能的输出。![图12.3](#ch12fig03)展示了决策树的一个简单（尽管不一定准确）示例。
- en: Figure 12.3\. A simple example of a decision tree
  id: totrans-28
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '![图12.3](12fig03_alt.jpg) 决策树的一个简单示例'
- en: '![](12fig03_alt.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图片](12fig03_alt.jpg)'
- en: '[Listing 12.3](#ch12ex03) uses the `scikit-learn` module to create a decision
    tree that predicts landcover type based on four bands from a Landsat 8 image and
    actual field data from the SWReGAP project. The locations of these ground-truthed
    points are shown in [figure 12.4](#ch12fig04).'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表12.3](#ch12ex03)使用`scikit-learn`模块创建一个决策树，该决策树基于Landsat 8图像的四个波段和SWReGAP项目的实际现场数据预测土地覆盖类型。这些地面真实点的位置在[图12.4](#ch12fig04)中显示。'
- en: Figure 12.4\. The locations of the ground-truthed data points used in [listing
    12.3](#ch12ex03)
  id: totrans-31
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图12.4\. 用于[列表12.3](#ch12ex03)的地面真实数据点的位置
- en: '![](12fig04.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![12fig04.jpg](12fig04.jpg)'
- en: 'You have a text file that contains coordinates for the points in [figure 12.4](#ch12fig04)
    and an integer value signifying the landcover class, which looks something like
    this:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 你有一个包含[图12.4](#ch12fig04)中点坐标和表示土地覆盖类别的整数值的文本文件，其内容大致如下：
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'That’s a good start, but you still need the independent variables. You’ll sample
    the Landsat bands at the coordinates in the text file to get a dataset that looks
    more like this:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这是个不错的开始，但你仍然需要独立变量。你将在文本文件中的坐标处采样Landsat波段，以获得类似以下的数据集：
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: These data will be used to build a model that you’ll then apply to the entire
    extent of the Landsat bands to get a spatial dataset containing predictions. This
    process is shown in the following listing.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据将被用来构建一个模型，然后将其应用于Landsat波段的整个范围，以获得包含预测的空间数据集。这个过程在下面的列表中展示。
- en: Listing 12.3\. Map classification using CART
  id: totrans-38
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表12.3\. 使用CART进行地图分类
- en: '![](ch12ex03-0.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![ch12ex03-0.jpg](ch12ex03-0.jpg)'
- en: '![](ch12ex03-1.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![ch12ex03-1.jpg](ch12ex03-1.jpg)'
- en: This is a little more complicated than the unsupervised example, but it’s still
    not that bad. The first task is to read in the coordinates and landcover class
    from the text file. You skip the header line, and then convert the first two values
    to floating-point (because they’re read in as strings) and put them in a list.
    When finished, this list contains a list of lists, with each inner list containing
    the x and y coordinates. You need the coordinates in this format later. You also
    put the landcover class integer in another list for later use.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程比无监督示例稍微复杂一些，但仍然不是那么糟糕。第一个任务是读取文本文件中的坐标和土地覆盖类别。你跳过标题行，然后将前两个值转换为浮点数（因为它们是以字符串形式读取的）并将它们放入一个列表中。完成时，这个列表包含一个列表的列表，其中每个内部列表包含x和y坐标。你稍后需要这种格式的坐标。你还将土地覆盖类别的整数放入另一个列表中，以供以后使用。
- en: Then you open one of the raster datasets so you can create a transformer object
    to convert between map coordinates and pixel offsets. You use this with your list
    of coordinates to get pixel offsets in two lists called `cols` and `rows`.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你打开一个栅格数据集，以便创建一个转换对象，用于在地图坐标和像素偏移之间进行转换。你使用这个对象和你的坐标列表来获取两个名为`cols`和`rows`的列表中的像素偏移。
- en: 'After reading the four satellite bands into a three-dimensional array, you
    take advantage of the fact that you can pass lists of coordinates as indices to
    pull data out of an array, and sample all of the points in one line of code:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在将四个卫星波段读入三维数组后，你利用了这样一个事实：你可以将坐标列表作为索引传递，从数组中提取数据，并在一行代码中采样所有点：
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This samples the 3D array at each of the provided row and column offsets, and
    returns every value in the third dimension, which is the four different satellite
    bands. The result is a two-dimensional array, where each row contains the four
    pixel values from the four bands.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这在每个提供的行和列偏移处采样3D数组，并返回第三维度的每个值，即四个不同的卫星波段。结果是二维数组，其中每行包含四个波段的像素值。
- en: Now you have all of the data required in order to fit the model, so you create
    a new decision tree classifier using default parameters (see the `scikit-learn`
    documentation to read the nitty-gritty details of the optional parameters) and
    then pass the `fit` method your independent variables and known landcover classifications
    at those same points. Make sure you don’t change the order of any of the lists;
    otherwise, the satellite pixel values won’t match up with the appropriate landcover
    value and your model won’t be fitted correctly.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经拥有了拟合模型所需的所有数据，因此你创建一个新的决策树分类器，使用默认参数（参见`scikit-learn`文档以了解可选参数的详细信息），然后传递`fit`方法你的独立变量和已知土地覆盖分类。确保不要更改任何列表的顺序；否则，卫星像素值将不会与相应的土地覆盖值匹配，你的模型将无法正确拟合。
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'All that’s left is to apply your fitted model to the full set of pixel values.
    Unfortunately, the predictor variables need to be in a two-dimensional array for
    this to work, so you reshape the array so that it has a large number of rows (`rows
    * cols`) and four columns, one for each band. You pass this to the `predict` function,
    and then reshape the resulting one-dimensional array back into two dimensions:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的就是将你的拟合模型应用到像素值的完整集合上。不幸的是，预测变量需要是一个二维数组才能工作，所以你需要重新塑形数组，使其具有大量的行（`rows *
    cols`）和四列，每列对应一个波段。你将这个数组传递给`predict`函数，然后将结果的一维数组重新塑形回二维：
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Another way to handle the prediction is to loop through the rows and process
    one at a time. An added advantage to this method is that it uses less memory.
    For example, my laptop crashed when I tried to run the prediction on the entire
    30-meter dataset at once, but it did it row by row without a problem. You’d do
    it something like this:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 处理预测的另一种方法是逐行循环并通过逐个处理。这种方法的一个额外优点是它使用的内存更少。例如，当我尝试一次性在30米数据集上运行预测时，我的笔记本电脑崩溃了，但它逐行处理时没有问题。你会这样做：
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Landsat bands have 0 values around the edges of the image, but those pixels
    are still assigned a value with the model. If all four Landsat bands contain 0
    at a location, then you know that there’s no data for that cell, so you change
    those to 0 in the prediction data as well. You could have used any number that
    wasn’t a valid landcover classification, as long as you set it as the `NoData`
    value. After saving the prediction as a GeoTIFF, you copy the color table from
    the real SWReGAP landcover classification so you can visually compare the results.
    Again, you can see in [figure 12.5](#ch12fig05) that this model predicts some
    of the same general patterns, but the results are still different. If you’re viewing
    this in color, you’ll see that it even failed to predict water correctly! This
    is a strong indication that the model needs more work. A better set of training
    data or independent variables would probably help.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Landsat波段在图像边缘有0值，但那些像素仍然会被模型赋予一个值。如果所有四个Landsat波段在某个位置都包含0，那么你就知道该单元格没有数据，因此你将预测数据中的这些值也改为0。你可以使用任何不是有效土地覆盖分类的数字，只要将其设置为`NoData`值。将预测保存为GeoTIFF后，你将颜色表从真实的SWReGAP土地覆盖分类复制过来，以便可以直观地比较结果。再次强调，你可以在[图12.5](#ch12fig05)中看到，这个模型预测了一些相同的一般模式，但结果仍然不同。如果你以彩色查看，你会发现它甚至未能正确预测水！这是一个强烈的迹象，表明模型需要更多的改进。更好的训练数据集或独立变量可能有所帮助。
- en: Figure 12.5\. The SWReGAP landcover dataset and one created using a decision
    tree
  id: totrans-53
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图12.5. SWReGAP土地覆盖数据集和用决策树创建的一个数据集
- en: '![](12fig05_alt.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![12fig05_alt.jpg](12fig05_alt.jpg)'
- en: 12.2.1\. Accuracy assessments
  id: totrans-55
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 12.2.1. 准确性评估
- en: Accuracy assessments are usually performed on models such as this to get an
    idea of how good they are. Because the model should do a good job of predicting
    the values that were used to build it, accuracy assessments are usually performed
    using a separate set of data to test the model on different values. I’ve provided
    a separate dataset for this, but if you need to split your data into training
    and assessment groups, you may want to look into the cross-validation tools in
    `scikit-learn`. One easy accuracy assessment method is to use a confusion matrix,
    which breaks out the results by predicted and observed values so you can see how
    well each classification was predicted. Although you can figure out the total
    percentage of correct classifications from the confusion matrix, better measures
    of accuracy exist. One of these is Cohen’s kappa coefficient, which ranges from
    -1 to 1, where the higher the number, the better the predictions. The following
    listing shows you how to use the `scikit-learn` module to construct a confusion
    matrix and SciKit-Learn Laboratory to compute the kappa statistic.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 准确性评估通常是在此类模型上进行的，以了解它们的好坏程度。因为模型应该能够很好地预测用于构建它的值，所以准确性评估通常使用一组独立的数据来测试模型在不同值上的表现。我已经为此提供了一个单独的数据集，但如果你需要将你的数据分成训练组和评估组，你可能需要查看`scikit-learn`中的交叉验证工具。一种简单的准确性评估方法是使用混淆矩阵，它根据预测值和观察值来分解结果，这样你可以看到每个分类预测得有多好。虽然你可以从混淆矩阵中计算出正确分类的总百分比，但存在更好的准确性度量方法。其中之一是Cohen的kappa系数，其范围从-1到1，数值越高，预测越好。以下列表展示了如何使用`scikit-learn`模块构建混淆矩阵和计算kappa统计量。
- en: Listing 12.4\. Confusion matrix and kappa statistic
  id: totrans-57
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表12.4. 混淆矩阵和kappa统计量
- en: '![](ch12ex04-0.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![ch12ex04-0.jpg](ch12ex04-0.jpg)'
- en: '![](ch12ex04-1.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图片](ch12ex04-1.jpg)'
- en: Most of this code should look familiar because obtaining the data points needed
    for the accuracy assessment is similar to collecting the model training data.
    The difference is that instead of sampling the satellite imagery, you sample the
    prediction output and compare those results to the known classifications.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 大部分代码应该看起来很熟悉，因为获取用于准确度评估的数据点与收集模型训练数据相似。区别在于，你不再对卫星图像进行采样，而是对预测输出进行采样，并将这些结果与已知分类进行比较。
- en: Once you have the known and predicted values for each location, computing kappa
    is easy. All you need to do is pass an array containing the true values and one
    containing the predicted values to the `kappa` function. Again, the order of the
    values is important, because your results will be extremely inaccurate if the
    known values are compared to predicted values from other locations. The kappa
    statistic for this model is 0.24, so the classification is slightly better than
    random, but it’s certainly nothing to brag about, either. In fact, a number that
    low indicates a poor classification.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了每个位置的已知和预测值，计算卡方就很容易了。你只需要将包含真实值的数组和包含预测值的数组传递给`kappa`函数。同样，值的顺序很重要，因为如果已知值与来自其他位置的预测值进行比较，你的结果将极其不准确。此模型的卡方统计值为0.24，因此分类略好于随机分类，但绝对没有什么值得炫耀的。事实上，这么低的数字表明分类质量较差。
- en: Technically, you only need the same inputs that you use for the kappa statistic
    to create the confusion matrix, but you also create a list of unique classification
    values to use as labels. The classes will be listed in this order in the resulting
    matrix. After creating the matrix, you add the labels in much the same way as
    you added labels to your two-way histogram earlier. The matrix looks something
    like [figure 12.6](#ch12fig06), where the rows correspond to predicted values
    and columns to known values. For example, 16 pixels that were predicted as class
    22 were predicted correctly, but two were really class 5 and one was actually
    class 28.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 技术上，你只需要与用于卡方统计的相同输入来创建混淆矩阵，但你还需要创建一个包含唯一分类值的列表，用作标签。类别将按此顺序列在结果矩阵中。创建矩阵后，你将以与之前添加到双向直方图标签相同的方式添加标签。矩阵看起来类似于[图12.6](#ch12fig06)，其中行对应预测值，列对应已知值。例如，预测为类别22的16个像素被正确预测，但其中两个实际上是类别5，一个实际上是类别28。
- en: Figure 12.6\. The first few rows and columns of the confusion matrix for the
    classification tree model. Rows are predictions, and columns are actual values,
    so two pixels were predicted as class 22 but were class 5.
  id: totrans-63
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图12.6。分类树模型的混淆矩阵的前几行和列。行是预测值，列是实际值，因此有两个像素被预测为类别22，但实际上是类别5。
- en: '![](12fig06.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图片](12fig06.jpg)'
- en: 12.3\. Summary
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3. 概述
- en: Unsupervised classification algorithms group pixels based on how alike they
    are.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无监督分类算法根据像素之间的相似性对像素进行分组。
- en: Supervised classification algorithms use ground-truthed data to predict which
    set of conditions results in each class.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监督分类算法使用已标记的真实数据来预测哪些条件组合导致每个类别。
