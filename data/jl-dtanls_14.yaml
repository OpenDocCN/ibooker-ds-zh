- en: 12 Mutating and transforming data frames
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 12 变异和转换数据帧
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了
- en: Extracting data from ZIP archives
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从ZIP存档中提取数据
- en: Adding and mutating columns of a data frame
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加和变异数据帧的列
- en: Performing split-apply-combine transformations of data frames
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对数据帧执行split-apply-combine转换
- en: Working with graphs and analyzing their properties
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用图并分析其属性
- en: Creating complex plots
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建复杂图表
- en: 'In chapters 8-11, you learned to create data frames and extract data from them.
    It is time to discuss ways in which data frames can be mutated. By *data frame
    mutation**,* I mean creating new columns by using data from existing columns.
    For example, you might have a date column in a data frame and want to create a
    new column that stores the year extracted from this date. In DataFrames.jl, you
    can achieve this objective in two ways:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在第8-11章中，您学习了如何创建数据帧并从中提取数据。现在是时候讨论数据帧可以变异的方式了。通过*数据帧变异*，我的意思是使用现有列的数据创建新列。例如，您可能有一个日期列在数据帧中，并希望创建一个新列来存储从该日期提取的年份。在DataFrames.jl中，您可以通过两种方式实现这一目标：
- en: Update the source data frame in place by adding a new column to it.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过向其中添加新列来就地更新源数据帧。
- en: Create a new data frame storing only the columns that you will later need in
    your data analysis pipeline.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个新的数据帧，只存储您将在数据分析管道中稍后需要的列。
- en: This chapter covers both approaches. Data frame mutation is a fundamental step
    in all data science projects. As discussed in chapter 1, after ingesting the source
    data, you need to prepare it before it can be analyzed for insights. This data
    preparation process typically involves such tasks as data cleaning and transforming,
    which are usually achieved by mutating existing columns of a data frame.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了两种方法。数据帧变异是所有数据科学项目的基本步骤。正如第1章所讨论的，在摄取源数据之后，您需要对其进行准备，以便可以分析以获得见解。此数据准备过程通常涉及数据清洗和转换等任务，这些任务通常通过变异数据帧的现有列来完成。
- en: The problem we solve in this chapter is a classification of GitHub developers.
    The data we will use is taken from the work of Benedek Rozemberczki et al. presented
    in “Multi-Scale Attributed Node Embedding” ([https://github.com/benedekrozemberczki/MUSAE](https://github.com/benedekrozemberczki/MUSAE)).
    The shared data set is licensed under GPL-3.0.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章解决的问题是对GitHub开发者的分类。我们将使用的数据来自Benedek Rozemberczki等人发表在“多尺度属性节点嵌入”（[https://github.com/benedekrozemberczki/MUSAE](https://github.com/benedekrozemberczki/MUSAE)）中的工作。共享数据集许可协议为GPL-3.0。
- en: The task of classifying GitHub developers is a typical data science project
    from the field of mining complex networks. A practical business application of
    these techniques is predicting types of products that your customers might be
    interested in buying by investigating what their friends purchase.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 将GitHub开发者进行分类的任务是来自复杂网络挖掘领域的典型数据科学项目。这些技术的实际商业应用是通过调查他们的朋友购买的产品来预测客户可能感兴趣购买的产品类型。
- en: In our source data, each developer is classified as either a web or a machine
    learning expert. Additionally, we have information on which developers are connected.
    Two developers are defined as *connected* if they mutually follow each other on
    GitHub.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的源数据中，每个开发者被分类为网络或机器学习专家。此外，我们还拥有有关哪些开发者之间有联系的信息。如果两个开发者相互在GitHub上关注对方，则称这两个开发者是*连接的*。
- en: It is natural to assume that web developers are mostly connected to other web
    developers; similarly, machine learning developers are probably working with other
    machine learning developers. Our goal in this chapter is to check whether our
    source data confirms these hypotheses.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 很自然地假设网络开发者主要与其他网络开发者连接；同样，机器学习开发者可能与其他机器学习开发者一起工作。本章的目标是检查我们的源数据是否证实了这些假设。
- en: 'As usual in this book, I present a full example of a data science project.
    Therefore, apart from this chapter’s core topic of data frame mutation, you will
    learn new things in all areas of data analysis: getting, transforming, and analyzing
    the data. We will discuss how to integrate DataFrames.jl, which makes it possible
    for you to work with tabular data, with the Graphs.jl package, which provides
    functionalities you can use to analyze graph data. The point of such integration
    is that some data transformations, as you will see in this chapter, are expressed
    more naturally when data is in tabular form, while others are easier to do when
    you represent data using a graph structure.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如本书惯例，我提供了一个数据科学项目的完整示例。因此，除了本章的核心主题数据帧变异之外，你将在数据分析的所有领域学习新事物：获取、转换和分析数据。我们将讨论如何集成
    DataFrames.jl，它使你能够处理表格数据，以及 Graphs.jl 包，它提供了你可以用来分析图数据的函数。这种集成的目的是，正如你将在本章中看到的，某些数据转换在数据以表格形式表示时表达得更为自然，而其他转换在用图结构表示数据时更容易进行。
- en: 12.1 Getting and loading the GitHub developers data set
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.1 获取和加载 GitHub 开发者数据集
- en: In this section, you will download and extract from the ZIP archive the GitHub
    developers data set. You will store the information about developers in two data
    frames and additionally learn how to update the columns in a data frame. All these
    tasks are commonly performed when doing virtually any data analysis project.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将下载并从 ZIP 文件中提取 GitHub 开发者数据集。你将把开发者的信息存储在两个数据帧中，并学习如何更新数据帧的列。所有这些任务在几乎任何数据分析项目中都是常见的任务。
- en: The GitHub developers data set is available for download on Stanford University’s
    Large Network Dataset Collection website ([https://snap.stanford.edu/data/github-social.html](https://snap.stanford.edu/data/github-social.html)).
    This data set contains information about GitHub developers’ social networks. The
    observational unit in this data is a GitHub developer. For each developer, we
    have information about their specialization, which is either machine learning
    or web development. Additionally, for each pair of developers, we know whether
    they mutually follow each other. In data science, this kind of data structure
    is called a *graph*.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub 开发者数据集可在斯坦福大学大型网络数据集收藏网站下载（[https://snap.stanford.edu/data/github-social.html](https://snap.stanford.edu/data/github-social.html)）。此数据集包含有关
    GitHub 开发者社交网络的信息。在此数据中，观测单位是一个 GitHub 开发者。对于每个开发者，我们都有关于他们专业化的信息，这可能是机器学习或网页开发。此外，对于每对开发者，我们知道他们是否相互关注。在数据科学中，这种数据结构被称为
    *图*。
- en: 12.1.1 Understanding graphs
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1.1 理解图
- en: In this section, you’ll learn what a graph is and how to represent GitHub developer
    data by using a graph. A *graph* is a collection of *nodes*, and some pairs of
    nodes may be connected by *undirected edges*. In our data, a single GitHub developer
    is a node, and a connection between two developers is an edge. When visualized,
    nodes are typically represented as points, and edges as lines connecting these
    points. Figure 12.1 shows an example of a small graph representing five developers,
    taken from the GitHub developers’ social network.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习什么是图以及如何使用图来表示 GitHub 开发者数据。一个 *图* 是由 *节点* 组成的集合，并且一些节点对可能通过 *无向边*
    连接。在我们的数据中，单个 GitHub 开发者是一个节点，两个开发者之间的连接是一个边。当可视化时，节点通常表示为点，边表示为连接这些点的线。图 12.1
    展示了一个表示五个开发者的示例小图，该图来自 GitHub 开发者的社交网络。
- en: '![CH12_F01_Kaminski2](../Images/CH12_F01_Kaminski2.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F01_Kaminski2](../Images/CH12_F01_Kaminski2.png)'
- en: Figure 12.1 In this graph of five GitHub developers, each developer is a numbered
    node (point), and each connection between developers is an edge (line).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.1 在这个包含五个 GitHub 开发者的图中，每个开发者是一个编号的节点（点），开发者之间的每个连接是一个边（线）。
- en: This graph consists of five nodes. For each node, I present the GitHub name
    of the developer. In the Graphs.jl package, nodes are assigned numbers. In Julia,
    we use 1-based indexing (see chapter 4 for details), so nodes are numbered from
    1 to 5.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 此图由五个节点组成。对于每个节点，我展示了开发者的 GitHub 名称。在 Graphs.jl 包中，节点被分配了数字。在 Julia 中，我们使用基于
    1 的索引（详细信息请参阅第 4 章），因此节点从 1 到 5 编号。
- en: 'Nodes in a graph are connected by edges. In this example, edges are drawn as
    lines connecting nodes. Typically, an edge is described by a pair of numbers indicating
    the nodes they’re connected to; for example, edge (1, 2) means that nodes 1 and
    2 are connected by an edge. We have six edges in our graph: (1, 2), (1, 4), (2,
    3), (3, 4), (3, 5), and (4, 5).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图中的节点通过边连接。在这个例子中，边是通过连接节点的线条表示的。通常，边由表示它们连接的节点的数字对描述；例如，边 (1, 2) 表示节点 1 和 2
    通过边连接。在我们的图中，我们有六个边：(1, 2)、(1, 4)、(2, 3)、(3, 4)、(3, 5) 和 (4, 5)。
- en: When analyzing a graph, we often talk about a set of neighbors of a particular
    node. *Neighbors* of a node are defined as nodes that are connected by an edge
    to the analyzed node. For example, in figure 12.1, node 4 is connected by an edge
    to nodes 1, 3, and 5, so the set {1, 3, 5} is the neighborhood of node 4\. Additionally,
    for each node, we define its *degree* as the number of edges connected to it.
    In the case of node 4, its degree is 3.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析图时，我们经常谈论一个特定节点的邻居集合。*邻居*定义为与被分析节点通过边连接的节点。例如，在图 12.1 中，节点 4 通过边与节点 1、3 和
    5 连接，因此集合 {1, 3, 5} 是节点 4 的邻域。此外，对于每个节点，我们定义其 *度* 为连接到它的边的数量。在节点 4 的例子中，其度数为 3。
- en: Going back to our problem involving the GitHub developer graph, we want to see
    if, by inspecting the neighborhood of a node (GitHub developer), we will be able
    to predict whether this developer is a machine learning or web specialist. For
    example, in figure 12.1, node 4 (dead-horse GitHub user) is connected to nodes
    1, 3, and 5 (Teachat8, Jasondu, and Shawflying GitHub users), which are its neighborhood.
    We want to check if, by learning whether nodes 1, 3, and 5 represent web or machine
    learning developers, we can predict the type of node 4.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们涉及 GitHub 开发者图的问题，我们想看看通过检查一个节点（GitHub 开发者）的邻域，我们是否能够预测这位开发者是机器学习或网络专家。例如，在图
    12.1 中，节点 4（dead-horse GitHub 用户）与节点 1、3 和 5（Teachat8、Jasondu 和 Shawflying GitHub
    用户）连接，这些是它的邻域。我们想检查通过学习节点 1、3 和 5 是否代表网络或机器学习开发者，我们是否可以预测节点 4 的类型。
- en: The problem I just described is a standard task in the graph-mining domain called
    *node classification*. In this chapter, I will show you how to do a simple analysis
    of this problem, focusing mostly on processing data by using DataFrames.jl. If
    you would like to explore analyzing graph data in more detail, you can check out
    *Mining Complex Networks* (CBC Press, 2021), which I coauthored with Paweł Prałat
    and François Théberge ([www.ryerson.ca/mining-complex-networks/](https://www.torontomu.ca/mining-complex-networks/)).
    The book is accompanied by source code for all examples in both Julia and Python.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我刚才描述的问题在图挖掘领域是一个标准任务，称为 *节点分类*。在本章中，我将向你展示如何对这个问题进行简单分析，主要关注使用 DataFrames.jl
    处理数据。如果你想更深入地探索分析图数据，你可以查看我与 Paweł Prałat 和 François Théberge 合著的 *Mining Complex
    Networks*（CBC Press，2021），[www.ryerson.ca/mining-complex-networks/](https://www.torontomu.ca/mining-complex-networks/)。这本书附有所有示例的源代码，包括
    Julia 和 Python。
- en: 12.1.2 Fetching GitHub developer data from the web
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1.2 从网络获取 GitHub 开发者数据
- en: In this section, we will download the GitHub developer data and check that the
    downloaded file is correct. This time, the source file ([https://snap.stanford.edu/data/git_web_ml.zip](https://snap.stanford.edu/data/git_web_ml.zip))
    is a ZIP archive, so you will also learn how to work with this file type. Since
    ZIP archives are binary, for security reasons, we will validate the SHA-256 hash
    (explained later in this section) of the file to make sure it is fetched correctly.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将下载 GitHub 开发者数据并检查下载的文件是否正确。这次，源文件 ([https://snap.stanford.edu/data/git_web_ml.zip](https://snap.stanford.edu/data/git_web_ml.zip))
    是一个 ZIP 归档，因此你还将学习如何处理此类文件。由于 ZIP 归档是二进制文件，出于安全考虑，我们将验证文件的 SHA-256 哈希（本节后面将解释），以确保正确获取。
- en: In the following listing, we download the data by using the functions described
    in more detail in chapter 6.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的列表中，我们使用第 6 章中更详细描述的函数下载数据。
- en: Listing 12.1 Downloading and checking the git_web_ml.zip file
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.1 下载并检查 git_web_ml.zip 文件
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Downloads the file only if it is not present in the current working directory
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 仅在当前工作目录中不存在该文件时下载文件
- en: ❷ Makes sure the file has been successfully downloaded
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 确保文件已成功下载
- en: ❸ Applies the sha256 function to the downloaded file to compute its SHA-256
    hash and compare it to a reference vector that I have computed on my machine
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将 sha256 函数应用于下载的文件以计算其 SHA-256 哈希，并将其与我在我的机器上计算的一个参考向量进行比较
- en: Let’s focus on the open(sha256, git_zip) operation. It is a short piece of code
    but does a lot underneath. In this pattern, we pass two arguments to the open
    function. The first is the function that we want to apply to the file, and the
    second is the filename we want to work with. Figure 12.2 lists the steps that
    Julia performs when executing this operation.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们关注 open(sha256, git_zip) 操作。这是一段简短的代码，但下面做了很多事情。在这个模式中，我们向 open 函数传递两个参数。第一个是我们想要应用于文件的函数，第二个是我们想要处理的文件名。图
    12.2 列出了 Julia 执行此操作时执行的步骤。
- en: '![CH12_F02_Kaminski2](../Images/CH12_F02_Kaminski2.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F02_Kaminski2](../Images/CH12_F02_Kaminski2.png)'
- en: Figure 12.2 Steps performed by the open(sha256, git_zip) operation. The open
    function, when passed the sha256 function as a first argument, guarantees to close
    the opened stream when the operation finishes and to return the value produced
    by the sha256 function.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.2 open(sha256, git_zip) 操作执行的步骤。当 open 函数以 sha256 函数作为第一个参数传递时，保证在操作完成后关闭打开的流，并返回
    sha256 函数产生的值。
- en: The function that is passed as a first argument to the open function must accept
    the handle to the newly opened file as its only argument. This is the case with
    the
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 将作为 open 函数的第一个参数传递的函数必须接受新打开文件的句柄作为其唯一参数。这种情况适用于
- en: sha256 function, which can accept this file handle and compute the SHA-256 hash
    value for data read in from it. Notably, this calculation is done without having
    to read the whole file into RAM, which allows processing of very large files.
    Additionally, it is important to know that if the open function gets a function
    as its first argument, then open returns the value returned by that function and
    automatically closes the stream that it opened. This behavior is useful because
    the programmer does not have to remember to manually close the stream.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: sha256 函数，它可以接受这个文件句柄并计算从其中读取的数据的 SHA-256 哈希值。值得注意的是，这个计算不需要将整个文件读入 RAM，这允许处理非常大的文件。此外，重要的是要知道，如果
    open 函数将其第一个参数作为函数，那么 open 将返回该函数返回的值并自动关闭它打开的流。这种行为很有用，因为程序员不需要记住手动关闭流。
- en: SHA-256 hash
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: SHA-256 哈希
- en: '*SHA-256* is a cryptographic hash function designed by the US National Security
    Agency. The SHA-256 algorithm takes a stream of bytes and returns its 256-bit
    representation. The idea is that if you have two different source streams, it
    is highly unlikely that they will have the same SHA-256 representation. Additionally,
    the algorithm is called *one-way*, which means that if you have 256-bit representation
    of data, it is hard to come up with input data whose SHA-256 hash matches the
    one you have. If you would like to learn more about this topic, check out *Real-World
    Cryptography* by David Wong (Manning, 2021, [www.manning.com/books/real-world-cryptography](http://www.manning.com/books/real-world-cryptography)).'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '*SHA-256* 是由美国国家安全局设计的加密哈希函数。SHA-256 算法接收一个字节流并返回其 256 位的表示。其理念是，如果你有两个不同的源流，它们具有相同的
    SHA-256 表示的可能性非常低。此外，该算法被称为 *单向*，这意味着如果你有数据的 256 位表示，很难找到输入数据，其 SHA-256 哈希与你的匹配。如果你想了解更多关于这个主题的信息，请查看
    David Wong 的《Real-World Cryptography》（Manning，2021，[www.manning.com/books/real-world-cryptography](http://www.manning.com/books/real-world-cryptography)）。'
- en: One common use of SHA-256 hashing is verifying that data fetched from the web
    is correctly downloaded. If you have the data’s expected SHA-256 hash and it matches
    the hash you compute on the fetched data, the data is likely not corrupted.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: SHA-256 哈希的一个常见用途是验证从网络获取的数据是否正确下载。如果你有数据的预期 SHA-256 哈希，并且它与你在获取的数据上计算出的哈希匹配，那么数据很可能没有被损坏。
- en: In Julia, the sha256 function from the SHA module returns a 32-element Vector
    {UInt8} that contains the result of applying the SHA-256 algorithm to the passed
    data.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Julia 中，SHA 模块中的 sha256 函数返回一个包含应用 SHA-256 算法到传递数据的结果的 32 元素 Vector {UInt8}。
- en: 12.1.3 Implementing a function that extracts data from a ZIP file
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1.3 实现从 ZIP 文件中提取数据的函数
- en: Now that we have downloaded the git_web_ml.zip archive, we can read the data
    we want to later work with into a data frame. In this section, we will create
    a function that performs this operation.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经下载了 git_web_ml.zip 归档，我们可以将我们稍后要处理的数据读入一个数据框中。在本节中，我们将创建一个执行此操作的函数。
- en: 'As a first step, we open the ZIP archive by using the ZipFile.jl package:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一步，我们使用 ZipFile.jl 包打开 ZIP 归档：
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The git_archive variable is bound to an object that allows us to read data from
    the archive. We can see five files in the archive. We are interested in musae_git_edges.csv
    and musae_git_target.csv. These are CSV files, so we will read them in by using
    the CSV.jl package.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`git_archive`变量绑定到一个对象，允许我们从存档中读取数据。我们可以看到存档中有五个文件。我们感兴趣的是`musae_git_edges.csv`和`musae_git_target.csv`。这些是CSV文件，因此我们将使用CSV.jl包来读取它们。'
- en: 'Before we continue, let’s look at the structure of ZipFile.Reader. Every ZipFile.Reader
    object has a files property that is a Vector of files stored in it. Let’s investigate
    this property for our git_archive variable:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，让我们看看`ZipFile.Reader`的结构。每个`ZipFile.Reader`对象都有一个`files`属性，它是一个包含其中存储的文件的Vector。让我们调查`git_archive`变量中的这个属性：
- en: '[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In this case, we have elements: one directory and five files. Each stored file
    has several properties. We are interested in the name property that stores the
    name of the file. Let’s check for the second file stored in git_archive:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们有元素：一个目录和五个文件。每个存储的文件都有几个属性。我们感兴趣的是存储文件名的`name`属性。让我们检查`git_archive`中存储的第二个文件：
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: First, we write a helper function that creates a DataFrame from a CSV file stored
    in an archive. In listing 12.2, the ingest_to_df function takes two arguments.
    The first is archive, which should be an open ZipFile.Reader object, just like
    the one bound to the git_archive variable. The second argument is filename, which
    is the name of the file that we want to extract from the archive. This name includes
    a full path to the file so all files in the archive are uniquely identified.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们编写一个辅助函数，该函数从存档中存储的CSV文件创建一个DataFrame。在列表12.2中，`ingest_to_df`函数接受两个参数。第一个是存档，它应该是一个打开的ZipFile.Reader对象，就像绑定到`git_archive`变量上的那样。第二个参数是`filename`，这是我们想要从存档中提取的文件名。这个名称包括文件的完整路径，因此存档中的所有文件都是唯一标识的。
- en: Listing 12.2 Function extracting a CSV file from the ZIP archive to a data frame
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.2 从ZIP存档中提取CSV文件到数据框的函数
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Let’s look at what this function does step by step. The findall(x -> x.name
    == filename, archive.files) call finds all files whose name matches the filename
    variable and returns them as a vector. The findall function takes two arguments.
    The first is a function specifying a condition we want to check (in this case,
    whether the name of the file matches filename). The second argument is a collection;
    from this collection, we want to find elements for which the function passed as
    the first argument returns true.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐步查看这个函数的功能。`findall(x -> x.name == filename, archive.files)`调用查找所有名称与`filename`变量匹配的文件，并将它们作为向量返回。`findall`函数接受两个参数。第一个是一个函数，指定我们想要检查的条件（在这种情况下，文件名是否与`filename`匹配）。第二个参数是一个集合；从这个集合中，我们想要找到函数作为第一个参数传递时返回为真的元素。
- en: 'The findall function returns a vector of indices to the collection for which
    the checked condition is satisfied. Here are two examples of findall calls:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`findall`函数返回一个索引向量，指向满足检查条件的集合。以下有两个`findall`调用的示例：'
- en: '[PRE5]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In the first call to findall, we learn that at index 2, we have a file whose
    name is git_web_ml/musae_git_edges.csv. In the second call, we find that no files
    have a name matching "".
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一次调用`findall`时，我们了解到在索引2处有一个文件，其名称为`git_web_ml/musae_git_edges.csv`。在第二次调用中，我们发现没有文件名称匹配""。
- en: 'In the ingest_to_df function, we expect that the passed filename matches exactly
    one file in our archive. Therefore, we use the only function to get the index
    of this file as an integer. If we do not have exactly one match, an error is thrown:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在`ingest_to_df`函数中，我们期望传入的文件名与我们的存档中恰好一个文件完全匹配。因此，我们使用唯一函数来获取该文件索引作为整数。如果没有恰好一个匹配项，则会抛出错误：
- en: '[PRE6]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Using only in combination with findall is a common pattern that provides a safe
    way to check whether exactly one element in a collection meets a certain condition.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 将`only`与`findall`结合使用是一种常见的模式，它提供了一种安全的方式来检查集合中是否恰好有一个元素满足某种条件。
- en: In the ingest_to_df function, we store the index of the file found in the idx
    variable. Next, we call read(archive.files[idx]) to uncompress the file to a Vector{UInt8}
    object. It is important to remember that reading the data from the archive consumes
    it. If we were to call the read function on the same file object, we would get
    the empty vector UInt8[]. This is the same pattern as discussed in chapter 7,
    when we were converting the result of the HTTP.get query to String.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在ingest_to_df函数中，我们将找到的文件索引存储在idx变量中。接下来，我们调用read(archive.files[idx])将文件解压缩到Vector{UInt8}对象中。重要的是要记住，从存档中读取数据会消耗它。如果我们对同一个文件对象调用read函数，我们会得到空的UInt8向量数组。这与第7章中讨论的相同模式相同，当时我们将HTTP.get查询的结果转换为String。
- en: Next, this Vector{UInt8} object is passed to the CSV.read function that parses
    the passed data as a CSV and returns a data frame. Note that earlier we used the
    CSV.read function, passing it a string that contains the name of the file to be
    parsed. This time, we pass it a vector of bytes directly, and it gets correctly
    handled. This approach is useful because we do not have to save the unpacked CSV
    file to disk before reading it to a data frame.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，这个Vector{UInt8}对象被传递给CSV.read函数，该函数将传递的数据解析为CSV并返回一个DataFrame。注意，之前我们使用了CSV.read函数，传递给它一个包含要解析的文件名的字符串。这次，我们直接传递一个字节数组，并且它被正确处理。这种方法很有用，因为我们不需要在将CSV文件读入DataFrame之前将其保存到磁盘上。
- en: 12.1.4 Reading the GitHub developer data into a data frame
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1.4 将GitHub开发者数据读入DataFrame
- en: In this section, using the ingest_to_df function defined in listing 12.2, we
    will read the data into a data frame.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用第12.2节中定义的ingest_to_df函数将数据读入DataFrame。
- en: Creating the data frames
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 创建DataFrame
- en: 'In listing 12.3, we create two data frames. The first is edges_df. With the
    calls to the summary and describe functions, we learn that this data frame has
    289,003 rows and two columns: id_1 and id_2. The rows of this data frame represent
    edges in our GitHub developer graph. The second data frame is classes_df. It has
    37,700 rows and three columns: id, name, and ml_target. One row of this data frame
    represents information about one developer.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在12.3节中，我们创建了两个DataFrame。第一个是edges_df。通过调用summary和describe函数，我们了解到这个DataFrame有289,003行和两列：id_1和id_2。这个DataFrame的行代表我们GitHub开发者图中的边。第二个DataFrame是classes_df。它有37,700行和三列：id、name和ml_target。这个DataFrame的一行代表一个开发者的信息。
- en: The key node feature we are interested in is stored in the ml_target column.
    It takes two values, 0 and 1, where 0 indicates a web developer and 1 indicates
    a machine learning developer. Observe that only roughly 25% of developers in the
    data set are machine learning specialists.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感兴趣的关键节点特征存储在ml_target列中。它有两个值，0和1，其中0表示网页开发者，1表示机器学习开发者。观察发现，数据集中只有大约25%的开发者是机器学习专家。
- en: Listing 12.3 Constructing edge and node attribute data frames
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.3 构建边和节点属性DataFrame
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ Data frame containing the edges of the GitHub developer graph
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 包含GitHub开发者图边的DataFrame
- en: ❷ Data frame containing the targets for our classification problem
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 包含我们分类问题目标的DataFrame
- en: ❸ Closes the ZipFile.Reader object after we are done getting data from it
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 在从ZipFile.Reader对象获取数据后关闭它
- en: ❹ Passes a list of summary statistics we are interested in
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 传递我们感兴趣的汇总统计列表
- en: 'Before we continue our analysis, let’s look at the describe call. I introduced
    this function in chapter 8, where you learned that it can be passed more arguments
    than only the data frame we want to describe. In this example, I have limited
    the computed statistics to only those that we’re interested in for the analysis:
    min, max, mean, number of missing values, and column’s element type. If you want
    to see all default column statistics, you can call describe(edges_df) and describe(classes_df).'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续分析之前，让我们看看describe调用。我在第8章介绍了这个函数，你了解到它可以传递比我们想要描述的DataFrame更多的参数。在这个例子中，我将计算的统计信息限制为我们分析中感兴趣的那些：最小值、最大值、平均值、缺失值的数量和列的元素类型。如果你想看到所有默认的列统计信息，你可以调用describe(edges_df)和describe(classes_df)。
- en: 'At this point, if you have a GitHub account, you might be curious about whether
    you are included in the database that we analyze. You can check by using the findall
    function that we used previously in this chapter. Here, we use my bkamins name
    on GitHub:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，如果你有一个GitHub账户，你可能想知道你是否包含在我们分析的数据库中。你可以通过使用本章之前使用的findall函数来检查。这里，我们使用GitHub上的my
    bkamins名字：
- en: '[PRE8]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The returned vector is empty, which means that my name is not included in this
    data. Now let’s look for StefanKarpinski (one of the creators of the Julia language):'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 'The returned vector is empty, which means that my name is not included in this
    data. Now let’s look for StefanKarpinski (one of the creators of the Julia language):'
- en: '[PRE9]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This time, the check succeeds. Note that the id of StefanKarpinski is 1358,
    but it is row number 1359 in our data frame. Let’s fix this off-by-one issue.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: This time, the check succeeds. Note that the id of StefanKarpinski is 1358,
    but it is row number 1359 in our data frame. Let’s fix this off-by-one issue.
- en: Using broadcasting to update the contents of data frames
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Using broadcasting to update the contents of data frames
- en: 'An important feature we learn from listing 12.3 is that the developer’s identifier
    (columns id_1 and id_2 in edges_df and column id in classes_df) starts indexing
    with 0. Let’s increase all the indices by 1 so that they start from 1. This is
    needed because in section 12.2, we will use these edges to create a graph with
    the Graphs.jl package, and in this package, nodes in a graph use 1-based indexing,
    just like standard arrays in Julia. We accomplish the update by using broadcasting:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 'An important feature we learn from listing 12.3 is that the developer’s identifier
    (columns id_1 and id_2 in edges_df and column id in classes_df) starts indexing
    with 0. Let’s increase all the indices by 1 so that they start from 1. This is
    needed because in section 12.2, we will use these edges to create a graph with
    the Graphs.jl package, and in this package, nodes in a graph use 1-based indexing,
    just like standard arrays in Julia. We accomplish the update by using broadcasting:'
- en: '[PRE10]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The edges_df .+= 1 example shows that when broadcasting a data frame as a whole,
    it is treated as a two-dimensional object. Therefore, in this case, the operation
    gives the same result as we would get if we had a matrix instead of a data frame:
    we have incremented each cell in the data frame by 1.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 'The edges_df .+= 1 example shows that when broadcasting a data frame as a whole,
    it is treated as a two-dimensional object. Therefore, in this case, the operation
    gives the same result as we would get if we had a matrix instead of a data frame:
    we have incremented each cell in the data frame by 1.'
- en: The classes_df.id .+= 1 example shows that if you get a single column from a
    data frame, you can update it exactly as you update a vector—in this case, by
    also incrementing all its elements by 1.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: The classes_df.id .+= 1 example shows that if you get a single column from a
    data frame, you can update it exactly as you update a vector—in this case, by
    also incrementing all its elements by 1.
- en: A rule to remember is that broadcasting data frames works in the same way as
    for other arrays. Therefore, everything that you learned about broadcasting in
    Julia in general (covered in chapter 5) applies to data frame objects.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: A rule to remember is that broadcasting data frames works in the same way as
    for other arrays. Therefore, everything that you learned about broadcasting in
    Julia in general (covered in chapter 5) applies to data frame objects.
- en: 'Let’s look at a few more examples using a smaller df data frame (not related
    to our GitHub example) because is easier to follow visually:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 'Let’s look at a few more examples using a smaller df data frame (not related
    to our GitHub example) because it is easier to follow visually:'
- en: '[PRE11]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ Creates a data frame
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建数据框
- en: ❷ Squares all elements of the data frame
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将数据框中所有元素平方
- en: ❸ Replaces all missing elements in the data frame by 0 (the coalesce function
    was explained in chapter 5)
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将数据框中所有缺失元素替换为0（coalesce函数在第5章中已解释）
- en: ❹ Adds a vector [10 11, 12] to each column of the data frame
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 将向量[10 11, 12]添加到数据框的每一列
- en: ❺ Adds a one-row matrix [10 11] to each row of the data frame
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 将一行的矩阵[10 11]添加到数据框的每一行
- en: 'Going back to the GitHub example, our developer identifiers now start from
    1\. There is more to it. All developers have unique numbers, and the classes_df
    data frame stores them in sorted order, starting from developer 1 and ending with
    developer 37700\. We can easily check this by using the axes function you learned
    about in chapter 4:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 'Going back to the GitHub example, our developer identifiers now start from
    1\. There is more to it. All developers have unique numbers, and the classes_df
    data frame stores them in sorted order, starting from developer 1 and ending with
    developer 37700\. We can easily check this by using the axes function you learned
    about in chapter 4:'
- en: '[PRE12]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The previous classes_df.id .+= 1 example showed how you can update the existing
    column of a data frame by using broadcasting. However, instead of using classes_df.id,
    you could have written classes_df[:, :id] .+= 1 or classes _df[!, :id] .+= 1.
    You could also use "id" here instead of :id. A natural question is whether there
    is a difference between using : and ! as a row selector in these two assignments.
    Indeed, there is a subtle one. The classes_df[:, :id] .+= 1 operation updates
    the :id column in place, while classes_df[!, :id] .+= 1 allocates a new column
    in the data frame.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 'The previous classes_df.id .+= 1 example showed how you can update the existing
    column of a data frame by using broadcasting. However, instead of using classes_df.id,
    you could have written classes_df[:, :id] .+= 1 or classes _df[!, :id] .+= 1.
    You could also use "id" here instead of :id. A natural question is whether there
    is a difference between using : and ! as a row selector in these two assignments.
    Indeed, there is a subtle one. The classes_df[:, :id] .+= 1 operation updates
    the :id column in place, while classes_df[!, :id] .+= 1 allocates a new column
    in the data frame.'
- en: 'If you are wondering in which cases this choice makes a difference, consider
    the following example. Again, I use a new, small df data frame not related to
    the GitHub case study to make it easier to check the result of the operations
    we perform:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想知道在哪些情况下这个选择会有所不同，请考虑以下示例。同样，我使用一个新的、小的df数据框，它与GitHub案例研究无关，以便更容易检查我们执行的操作的结果：
- en: '[PRE13]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In this example, we see that df[!, :a] .= "x" works because it replaces the
    column with new data (the df.a .= "x" call would be equivalent). However, df[:,
    :a] .= "x" fails because it tries to update the existing column in place, and
    we cannot assign strings to a vector of integers.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们看到df[!, :a] .= "x"之所以有效，是因为它用新数据（df.a .= "x"调用将是等效的）替换了列。然而，df[:, :a]
    .= "x"失败，因为它试图就地更新现有的列，而我们无法将字符串分配给整数向量。
- en: 'The same patterns as we discussed for broadcasting an assignment (.= operator)
    to a column of a data frame apply also to a standard assignment (= operator) to
    an existing column. Here is an example:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论的将赋值操作（.=运算符）广播到数据框列的相同模式也适用于对现有列的标准赋值（=运算符）。以下是一个示例：
- en: '[PRE14]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In this example, we can see that the df[!, :a] = ["x", "y", "z"] operation (or,
    equivalently, df.a = ["x", "y", "z"]) works because it replaces the column. The
    df[:, :b] = ["x", "y", "z"] assignment fails because it is an in-place operation
    into an existing column, and we cannot convert a string to an integer. However,
    df[:, :c] = [11, 12, 13] works since we assign a vector of integers to the c column.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们可以看到df[!, :a] = ["x", "y", "z"]操作（或等价地，df.a = ["x", "y", "z"]）之所以有效，是因为它替换了列。df[:,
    :b] = ["x", "y", "z"]赋值失败，因为它是对现有列的就地操作，我们无法将字符串转换为整数。然而，df[:, :c] = [11, 12,
    13]之所以有效，是因为我们向c列分配了一个整数向量。
- en: 12.2 Computing additional node features
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.2 计算额外的节点特征
- en: In this section, you will learn how to integrate tabular data stored in a data
    frame with a graph by using the SimpleGraph type defined in the Graphs.jl package.
    We will create a graph from a list of edges stored in the edges_df data frame.
    Next, using the Graphs.jl package, we will compute several features of the graph’s
    nodes and add them as new columns to the classes_df data frame. If you will ever
    work with social media data, knowing how to analyze it by using the Graphs.jl
    package will be useful.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习如何通过使用Graphs.jl包中定义的SimpleGraph类型将存储在数据框中的表格数据与图集成。我们将从存储在edges_df数据框中的边列表创建一个图。接下来，使用Graphs.jl包，我们将计算图节点的几个特征，并将它们作为新列添加到classes_df数据框中。如果你将来会处理社交媒体数据，了解如何使用Graphs.jl包来分析它将是有用的。
- en: Graphs.jl package
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: Graphs.jl包
- en: This section presents only a limited set of functionalities provided by the
    Graphs.jl package. If you want to learn more about working with graphs in Julia,
    refer to the package documentation ([https://juliagraphs.org/Graphs.jl/dev](https://juliagraphs.org/Graphs.jl/dev/)/).
    Here, I will just comment that it supports all typical functionalities that are
    useful when working with graphs, including graph traversal, computing node distances,
    and centrality measures.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 本节仅介绍了Graphs.jl包提供的有限功能集。如果你想了解更多关于在Julia中使用图的信息，请参阅包文档（[https://juliagraphs.org/Graphs.jl/dev](https://juliagraphs.org/Graphs.jl/dev/)/）。在这里，我只是评论说它支持所有在处理图时有用的典型功能，包括图遍历、计算节点距离和中心性度量。
- en: 12.2.1 Creating a SimpleGraph object
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2.1 创建SimpleGraph对象
- en: In this section, we will create a Graph object. This object is useful because
    the Graphs.jl package offers multiple functions that will later allow you to efficiently
    query such an object about its properties—for example, neighbors of a particular
    node—from this graph.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将创建一个Graph对象。这个对象很有用，因为Graphs.jl包提供了多个函数，这些函数将允许你以后高效地查询此类对象的相关属性——例如，从图中查询特定节点的邻居。
- en: In listing 12.4, we use the Graphs.jl package to work with graphs. First, we
    create an empty graph with the SimpleGraph function and then iterate rows of the
    edges_df data frame to add edges to it by using the add_edge! function. Next,
    we check the number of edges and nodes in the graph. They are consistent with
    the number of rows in edges_df and classes_df data frames, respectively, as expected.
    In Graphs.jl, nodes are always numbered with consecutive integers, starting with
    1.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表12.4中，我们使用Graphs.jl包来处理图。首先，我们使用SimpleGraph函数创建一个空图，然后迭代edges_df数据框的行，使用add_edge!函数向其中添加边。接下来，我们检查图中的边和节点数量。它们与edges_df和classes_df数据框中的行数分别一致，正如预期的那样。在Graphs.jl中，节点始终使用连续整数编号，从1开始。
- en: Listing 12.4 Creating a graph from a list of edges
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.4 从边列表创建图
- en: '[PRE15]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: ❶ Creates a graph with 37,700 nodes and no edges
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建一个包含 37,700 个节点但没有边的图
- en: ❷ Adds edges to the graph by iterating rows of the edges_df data frame
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 通过迭代 edges_df 数据帧的行来向图中添加边
- en: ❸ Gets the number of edges in the graph
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 获取图中边的数量
- en: ❹ Gets the number of nodes (also called vertices) in the graph
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 获取图中节点数（也称为顶点数）
- en: Let’s look at the for (src, dst) in eachrow(edges_df) expression. Recall that
    edges_df has two columns. This means that each row of this data frame is a DataFrameRow
    that has two elements (we discussed DataFrameRow objects in chapter 9). When we
    iterate these two element objects, we can automatically destructure them into
    two variables (we discussed destructuring in chapter 10) by using a tuple syntax.
    In this case, these variables are src and dst (they need to be wrapped in parentheses).
    In the code, I use src and dst variable names because they are internally used
    in the Graphs.jl package. However, please keep in mind that our graph is undirected,
    so no orientation is applied to the edge.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 `for (src, dst) in eachrow(edges_df)` 表达式。回想一下，edges_df 有两列。这意味着这个数据帧的每一行都是一个包含两个元素的
    DataFrameRow（我们在第 9 章讨论了 DataFrameRow 对象）。当我们迭代这两个元素对象时，我们可以通过使用元组语法自动将它们解构为两个变量（我们在第
    10 章讨论了解构）。在这种情况下，这两个变量是 src 和 dst（它们需要用括号括起来）。在代码中，我使用 src 和 dst 变量名，因为它们在 Graphs.jl
    包内部使用。然而，请记住，我们的图是无向的，所以边没有方向。
- en: 'Here’s one more example of an iteration using a matrix instead of a data frame
    (to show that this is a general pattern that you can use):'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个使用矩阵而不是数据帧进行迭代的另一个例子（以表明这是一个你可以使用的通用模式）：
- en: '[PRE16]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Indeed, we see that the x1 and x2 variables get the first and the second elements
    of iterated rows of a matrix. This example uses the @show macro, which is useful
    in debugging as it shows the expression passed to it and its value.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，我们看到 x1 和 x2 变量获取了矩阵迭代行的第一个和第二个元素。这个例子使用了 @show 宏，它在调试中很有用，因为它显示了传递给它的表达式及其值。
- en: 12.2.2 Computing features of nodes by using the Graphs.jl package
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2.2 使用 Graphs.jl 包计算节点的特征
- en: 'In this section, using the gh graph, we will use the functionalities of the
    Graphs.jl library to compute some features of its nodes. We start with node degrees
    that can be obtained using the degree function:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，使用 gh 图，我们将使用 Graphs.jl 库的功能来计算其节点的某些特征。我们从节点度开始，可以使用 degree 函数获得：
- en: '[PRE17]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We can see that the first node has one neighbor, the second node has eight
    neighbors, and so forth. Let’s create the deg column in the classes_df data frame
    that stores this node degree information:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到第一个节点有一个邻居，第二个节点有八个邻居，以此类推。让我们在 classes_df 数据帧中创建一个 deg 列，以存储这个节点度信息：
- en: '[PRE18]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We can perform this assignment because we are sure that the classes_df data
    frame stores developers in increasing order, starting from 1 and ending with 37700\.
    If this were not the case, we would have to perform a join operation to properly
    match developers to their features. We discuss joins in chapter 13.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以执行这个赋值操作，因为我们确信 classes_df 数据帧按升序存储开发者，从 1 开始，到 37700 结束。如果不是这样，我们就必须执行一个连接操作，以正确地将开发者与其功能匹配。我们在第
    13 章讨论了连接。
- en: 'The syntax for creating columns is the same as the syntax for updating existing
    columns. Therefore, you could also have written classes_df[!, :deg] = degree(gh)
    or classes_df[:, :deg] = degree(gh) to add a column to a data frame. As with updating
    columns, there is a difference between using the ! and : row selectors. The !
    row selector stores the passed vector in the data frame without copying (the same
    happens when we update an existing column). The : row selector creates a copy
    of the passed vector. Here is an example showing this difference:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '创建列的语法与更新现有列的语法相同。因此，你也可以写成 `classes_df[!, :deg] = degree(gh)` 或 `classes_df[:,
    :deg] = degree(gh)` 来向数据帧添加列。与更新列一样，使用 ! 和 : 行选择器之间有一个区别。! 行选择器将传递的向量存储在数据帧中而不进行复制（当我们更新现有列时也会发生相同的情况）。:
    行选择器创建传递向量的副本。以下是一个显示这种差异的例子：'
- en: '[PRE19]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The x1 column is created without copying, so it stores the same vector as the
    x vector. The x2 column is created with copying, so it stores a vector that has
    the same contents but a different location in memory. Therefore, if we later changed
    the contents of the x vector, the contents of the x1 column would change, but
    the contents of the x2 column would not be affected.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: x1列是在不复制的情况下创建的，因此它存储与x向量相同的向量。x2列是通过复制创建的，因此它存储具有相同内容但内存中不同位置的向量。因此，如果我们后来更改了x向量的内容，x1列的内容将发生变化，但x2列的内容将不受影响。
- en: 'For completeness of the exposition, let me mention that you can also create
    columns by using broadcasting assignment. Here’s one example using the df data
    frame created in the preceding example:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完整地阐述，让我提一下，您也可以通过使用广播赋值来创建列。以下是一个使用前一个示例中创建的df数据框的示例：
- en: '[PRE20]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 12.2.3 Counting a node’s web and machine learning neighbors
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2.3 计算一个节点的网络和机器学习邻居数量
- en: In this section, we’ll compute two more features of the GitHub developers data
    frame. We want to compute the number of neighbors of a node that are web developers
    and the number of neighbors that are machine learning developers. This operation
    is slightly more complex than what we’ve typically performed in this book, and
    it uses many features of the Julia language that you have already learned.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将计算GitHub开发者数据框的另外两个特征。我们想要计算节点网络中是网络开发者的邻居数量以及是机器学习开发者的邻居数量。这个操作比我们在本书中通常执行的操作稍微复杂一些，并且它使用了您已经学习到的Julia语言中的许多特性。
- en: Iterating edges of a graph
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代图的边
- en: 'Before we perform this operation, let’s look at the edges function from the
    Graphs.jl library that returns an iterator of the edges of a graph:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们执行此操作之前，让我们看看Graphs.jl库中的edges函数，它返回一个图边的迭代器：
- en: '[PRE21]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let’s inspect its first element:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查它的第一个元素：
- en: '[PRE22]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We can see that the e1 object represents a single edge in the graph. Using the
    dump function, we inspect its structure and learn that it has two fields, src
    and dst, and we next check that they can be accessed using the property access
    syntax.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，e1对象代表图中的一个单边。使用dump函数，我们检查其结构并了解到它有两个字段，src和dst，然后我们检查它们可以使用属性访问语法访问。
- en: We know how to work with edges of the gh graph, so let’s turn to the function
    that computes the number of neighbors of a node that are web developers and the
    number that are machine learning developers.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道如何处理gh图的边，所以让我们转向计算是网络开发者还是机器学习开发者的节点邻居数量的函数。
- en: Defining a function that counts neighbors of a node
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 定义一个计算节点邻居数量的函数
- en: 'In listing 12.5, the deg_class function takes two arguments: a gh graph and
    the 0-1 vector class that indicates whether a developer works with machine learning
    or the web.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表12.5中，`deg_class`函数接受两个参数：一个gh图和一个0-1向量类，该类指示开发者是否与机器学习或网络工作。
- en: Using the zeros function, we create vectors in which we will store the number
    of neighbors that are machine learning and web developers, respectively. These
    vectors are initialized with integer zeros, indicated by the Int argument, and
    have a length equal to the number of developers we have in our data, which is
    the length of the class vector.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 使用zeros函数，我们创建了将存储机器学习和网络开发者邻居数量的向量。这些向量使用Int参数初始化为整数零，并且长度等于我们数据中的开发者数量，即类向量的长度。
- en: Next, we iterate edges of the graph. For a single edge, we store the numbers
    assigned to developers that are its ends in a and b variables. Next, we check
    whether the b developer is working with machine learning by using the class[b]
    == 1 condition. If this is the case, we increase the number of machine learning
    neighbors of developer a by one; otherwise, we do the same for the number of web
    developers for developer a. Then we do the same operation but check the type of
    developer a and update the neighbor count information for developer b. Finally,
    we return a tuple consisting of both vectors we have created.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们迭代图的边。对于单个边，我们将分配给该边两端的开发者的数字存储在a和b变量中。然后，我们使用class[b] == 1条件检查b开发者是否与机器学习工作。如果是这种情况，我们将开发者a的机器学习邻居数量增加一个；否则，我们为开发者a的网络开发者数量执行相同的操作。然后我们执行相同的操作，但检查开发者a的类型并更新b的邻居计数信息。最后，我们返回一个包含我们创建的两个向量的元组。
- en: Listing 12.5 The function that counts neighbors of a node
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.5 计算节点邻居数量的函数
- en: '[PRE23]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: ❶ Initializes the vectors with integer zeros
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用整数零初始化向量
- en: ❷ Iterates edges of the graph
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 迭代图的边
- en: ❸ Assigns to the a and b variables the ends of the iterated edge
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将迭代边的两端赋值给a和b变量
- en: ❹ Updates the number of neighbors of node a
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 更新节点a的邻居数量
- en: ❺ Updates the number of neighbors of node b
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 更新节点b的邻居数量
- en: 'Let’s see the deg_class function in action:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 deg_class 函数的实际应用：
- en: '[PRE24]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We add two columns to the classes_df data frame in one operation in one assignment.
    As previously discussed, in Julia, we can destructure an iterator from the right-hand
    side of the assignment (a tuple returned by the deg_class function in our case)
    to multiple variables passed on its left-hand side.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在一次赋值操作中向 classes_df 数据框添加了两列。如前所述，在 Julia 中，我们可以从赋值的右侧解构迭代器（在我们的情况下是 deg_class
    函数返回的元组）到其左侧传递的多个变量。
- en: Applying the function-barrier technique
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 应用函数屏障技术
- en: 'One more feature of the deg_class function that is important to highlight is
    that it will be fast. We are using the function-barrier technique that you learned
    in chapter 11 by passing the classes_df.ml_target vector to it. So, although the
    classes_df data frame is not type stable inside the deg_class function, Julia
    is able to identify the types of all variables and thus generate efficient code
    for its execution. Let’s check that the deg_class function is efficient with the
    @time and @code_warntype macros:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: deg_class 函数的一个重要特性是它将很快。我们通过传递 classes_df.ml_target 向量到它中来使用你在第11章中学到的函数屏障技术。所以，尽管在
    deg_class 函数内部 classes_df 数据框不是类型稳定的，但 Julia 能够识别所有变量的类型，从而为其执行生成有效的代码。让我们使用 @time
    和 @code_warntype 宏来检查 deg_class 函数是否高效：
- en: '[PRE25]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: In the timing produced by the @time macro, the most important information is
    that the code performs five allocations. The number of allocations does not grow
    proportionally to the number of iterations of the for edge in edges(gh) loop in
    the function (remember that we have almost 300,000 edges in the graph). This is
    a good signal indirectly indicating that the function is type stable.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在 @time 宏产生的计时中，最重要的信息是代码执行了五次分配。分配的数量并不与函数中 for edge in edges(gh) 循环的迭代次数成比例（记住我们在图中几乎有300,000条边）。这是一个间接指示函数类型稳定的良好信号。
- en: We get a confirmation of this when we inspect the output of the @code_warntype
    macro. I have truncated the preceding output, as it is quite long, but no types
    are presented in red (bold), and they are all concrete (recall the discussion
    of concrete types in chapter 5).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们检查 @code_warntype 宏的输出时，我们得到了这个确认。我已经截断了前面的输出，因为它相当长，但没有类型以红色（粗体）显示，并且它们都是具体的（回想一下第5章中关于具体类型的讨论）。
- en: Looking at the time that the operation takes, we can determine that even if
    all developers in our graph were connected by an edge (a complete graph), we could
    process it in a few seconds (on my laptop). Note that such a graph would be quite
    big, as it would have 710,626,150 edges (which can be computed by using the formula
    37700(37700-1)/2 for the number of two-element subsets of a set containing 37,700
    elements).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 通过观察操作所需的时间，我们可以确定即使我们图中的所有开发者都通过边连接（一个完全图），我们也能在几秒钟内（在我的笔记本电脑上）处理它。请注意，这样一个图会相当大，因为它将有710,626,150条边（可以通过使用包含37,700个元素的集合的两元素子集数量的公式37700(37700-1)/2来计算）。
- en: 'Exercise 12.1 Using the complete_graph(37700) call, create a complete graph
    on 37,700 nodes (the number of nodes we have in the gh graph). But beware: if
    you have less than 32 GB RAM on your machine, use a smaller graph size, as this
    exercise is memory intensive. Next, using the Base .summarysize function, check
    how much memory this graph takes. Finally, using the @time function, check how
    long the deg_class function would take on this graph to finish, using the classes_df.ml_target
    vector as the vector of developer types.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 练习12.1 使用 complete_graph(37700) 调用，在37,700个节点上创建一个完全图（我们在gh图中的节点数量）。但请注意：如果你的机器上少于32
    GB RAM，请使用较小的图大小，因为这个练习对内存密集型。接下来，使用 Base .summarysize 函数，检查这个图占用多少内存。最后，使用 @time
    函数，检查 deg_class 函数在这个图上完成所需的时间，使用 classes_df.ml_target 向量作为开发者类型的向量。
- en: Interpreting the results of the analysis
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 解释分析结果
- en: 'Let’s check the summary statistics of our classes_df data frame after adding
    the columns with additional graph features:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查添加了具有附加图特征的列后的 classes_df 数据框的摘要统计信息：
- en: '[PRE26]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Observe that the average node degree in a graph is a bit over 15\. We can cross-check
    this value by using the ne and nv functions. Since each edge contributes to the
    degree of two nodes, the average degree of the node in the whole graph should
    be two times the number of edges in the graph divided by the number of nodes in
    the graph:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 观察到图中节点的平均度数略大于 15。我们可以通过使用 ne 和 nv 函数来交叉检查这个值。由于每条边都贡献了两个节点的度数，因此整个图中节点的平均度数应该是图中边数乘以
    2 除以图中节点数：
- en: '[PRE27]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: We have obtained the same value as by averaging over degrees of individual nodes,
    as expected.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了与通过平均单个节点的度数得到的相同值，正如预期的那样。
- en: Also note that, on average, developers have more links to web developers than
    to machine learning developers. This is not surprising, as in the graph, almost
    75% of nodes are web developers. From the summary, we also learn from the information
    about the maximum and standard deviation columns that significant variability
    exists in node degrees of the graph (we will have to take this observation into
    account when analyzing the data later).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 还请注意，平均而言，开发者与网页开发者的链接比与机器学习开发者多。这并不奇怪，因为在图中，几乎 75% 的节点是网页开发者。从摘要中，我们还从最大值和标准差列的信息中了解到，图中节点的度数存在显著的变异性（我们将在分析数据时考虑这一观察结果）。
- en: 'Before moving forward, let’s check that for each node, the sum of the number
    of web neighbors and machine learning neighbors of a node is equal to its total
    degrees (as each neighbor of a node is either a web or machine learning developer):'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续前进之前，让我们检查对于每个节点，该节点的网页邻居数量和机器学习邻居数量的总和等于其总度数（因为一个节点的每个邻居要么是网页开发者，要么是机器学习开发者）：
- en: '[PRE28]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Indeed, this is the case.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 的确，这是正确的。
- en: Performing object consistency checks in DataFrames.jl
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在 DataFrames.jl 中执行对象一致性检查
- en: 'Performing data consistency checks is important when developing more complex
    solutions. For example, in DataFrames.jl, consistency checks of the DataFrame
    object are run when you execute selected operations on data frame objects. Here’s
    an example of when such a consistency check is triggered:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发更复杂的解决方案时执行数据一致性检查非常重要。例如，在 DataFrames.jl 中，当你对数据帧对象执行所选操作时，会运行 DataFrame
    对象的一致性检查。以下是一个一致性检查被触发时的示例：
- en: '[PRE29]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: This code creates a data frame with one row and two columns. Next, we add an
    element to only one of its columns with the push!(df.a, 2) operation (recall from
    chapter 10 that if you want to add a row to a data frame, you should use push!
    on the whole data frame). If we try to show this data frame next, we get an error
    indicating that the data frame is corrupted since all columns in a data frame
    must have the same number of elements. Don’t try to work with corrupted data frames.
    Instead, locate the part of the code that caused this problem and fix it.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码创建了一个包含一行两列的数据帧。接下来，我们使用 push!(df.a, 2) 操作仅向其一个列添加一个元素（回想第 10 章的内容，如果你想要向数据帧添加一行，你应该在整个数据帧上使用
    push!）。如果我们尝试显示此数据帧，我们会得到一个错误，表明数据帧已损坏，因为数据帧中的所有列必须具有相同数量的元素。不要尝试处理损坏的数据帧。相反，定位导致此问题的代码部分并修复它。
- en: 12.3 Using the split-apply-combine approach to predict the developer’s type
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.3 使用 split-apply-combine 方法预测开发者的类型
- en: In this section, we will check whether we can predict the type of a node by
    learning the number of its web and machine learning neighbors. Intuitively, we
    expect machine learning developers to have more connections with other machine
    learning developers. Similarly, we expect that web developers connect to web developers.
    You are going to learn how to apply the split-apply-combine strategy in DataFrames.jl,
    create complex plots using Plots.jl, and fit logistic regression with GLM.jl.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将检查我们是否可以通过学习一个节点的网页和机器学习邻居的数量来预测该节点的类型。直观上，我们预计机器学习开发者与其他机器学习开发者之间有更多的联系。同样，我们预计网页开发者会与网页开发者建立联系。你将学习如何在
    DataFrames.jl 中应用 split-apply-combine 策略，使用 Plots.jl 创建复杂的图表，以及使用 GLM.jl 进行逻辑回归。
- en: 12.3.1 Computing summary statistics of web and machine learning developer features
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.1 计算网页和机器学习开发者特征摘要统计
- en: In this section, we will check the average of the deg_ml and deg_web variables
    for web and machine learning developers separately.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将分别检查网页和机器学习开发者的 deg_ml 和 deg_web 变量的平均值。
- en: Approach using indexing
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 使用索引的方法
- en: 'First, let’s perform this computation by using the indexing syntax we learned
    in chapter 9:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们通过使用我们在第 9 章中学到的索引语法来执行这个计算：
- en: '[PRE30]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: In the loop, we iterate over the developer type (which is 0 or 1) and column
    name (which is deg_ml or deg_web) and print the conditional mean of the column.
    We see that web developers (encoded by 0) have many more web friends than machine
    learning friends on average. For machine learning developers, the number of web
    and machine learning contacts is comparable.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在循环中，我们遍历开发者类型（0或1）和列名（deg_ml或deg_web），并打印列的条件均值。我们看到网页开发者（编码为0）的平均网页朋友比机器学习朋友多得多。对于机器学习开发者，网页和机器学习联系人的数量相当。
- en: 'The preceding code works but is verbose, is not very readable, and produces
    output to the screen only. There must be a nicer way to perform these computations.
    Indeed, there is: the split-apply-combine pattern.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的代码虽然可行，但较为冗长，可读性不高，并且只将输出显示在屏幕上。必须有一种更优雅的方式来执行这些计算。确实如此：split-apply-combine模式。
- en: Described in “The Split-Apply-Combine Strategy for Data Analysis” by Hadley
    Wickham ([www.jstatsoft.org/article/view/v040i01](https://www.jstatsoft.org/article/view/v040i01)),
    this pattern is implemented in frameworks supporting data frame operations in
    many languages. If you know pandas in Python or dplyr in R, the concepts will
    be familiar. Figure 12.3 depicts this approach.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在Hadley Wickham的《数据分析的Split-Apply-Combine策略》一文中描述了这种模式（[www.jstatsoft.org/article/view/v040i01](https://www.jstatsoft.org/article/view/v040i01)），这种模式在许多支持数据帧操作的框架中得到了实现。如果你熟悉Python中的pandas或R中的dplyr，这些概念将很熟悉。图12.3展示了这种方法。
- en: '![CH12_F03_Kaminski2](../Images/CH12_F03_Kaminski2.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F03_Kaminski2](../Images/CH12_F03_Kaminski2.png)'
- en: Figure 12.3 In the split-apply-combine strategy, we split the source data frame
    by the ml_target column into two groups, apply the mean function to the deg_ml
    column, and combine the results back into a single data frame.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.3 在split-apply-combine策略中，我们根据ml_target列将源数据帧分割成两个组，对deg_ml列应用均值函数，并将结果合并回单个数据帧。
- en: operation specification syntax
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 操作规范语法
- en: In this section, I explain the split-apply-combine pattern in DataFrames.jl
    through an example. Chapter 13 covers the details of this topic.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我通过一个示例解释了DataFrames.jl中的split-apply-combine模式。第13章将涵盖这个主题的详细内容。
- en: 'If you want to aggregate data by groups in DataFrames.jl, you need to use two
    functions:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想在DataFrames.jl中对数据按组进行聚合，你需要使用两个函数：
- en: groupby—Splits a data frame; you learned about this function in chapter 11
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: groupby—将数据帧分割；你已经在第11章中学习了这个函数
- en: combine—Takes a GroupedDataFrame object and performs its aggregation
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: combine—接受一个GroupedDataFrame对象并执行其聚合
- en: 'We first group the classes_ml data frame by the ml_target column and then compute
    the means of the deg_ml and deg_web columns by group:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先按ml_target列对classes_ml数据帧进行分组，然后计算deg_ml和deg_web列的均值：
- en: '[PRE31]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We can see that, as expected, we have two groups in our gdf object. The first
    corresponds to the value of the ml_target column equal to 0 (web developers),
    and the second to 1 (machine learning developers). When we pass the GroupedDataFrame
    object to the combine function, it performs data aggregation operations groupwise.
    Here’s the syntax, which I’ll explain next:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，正如预期的那样，在我们的gdf对象中有两个组。第一个对应于ml_target列的值为0（网页开发者），第二个对应于1（机器学习开发者）。当我们把GroupedDataFrame对象传递给combine函数时，它会对数据进行分组聚合操作。下面是语法，我将在下文中解释：
- en: '[PRE32]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '❶ The specification of the operation in the combine function has three parts
    linked by the => operator: source column name, the function that should be applied
    to this column, and the target column name.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在combine函数中操作规范的指定由=>运算符连接的三个部分：源列名、应用于此列的函数以及目标列名。
- en: As a result of the combine function, we obtain a data frame whose first column
    is the variable on which we have grouped the gdf data frame (ml_target), and the
    following columns are the results of aggregations that we performed. We see that
    the numbers are the same as those we computed before using the for loop.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: combine函数的结果是一个数据帧，其第一列是我们对gdf数据帧进行分组的变量（ml_target），接下来的列是我们执行聚合操作的结果。我们看到这些数字与我们之前使用for循环计算的结果相同。
- en: The crucial element to understand in this example is the syntax of the single
    operation specification that the combine function accepts. Let’s focus on the
    :deg_ml => mean => :mean_deg_ml operation. This syntax tells the combine function
    that it should take the :deg_ml column, pass it to the mean function, and store
    the result in the :mean_deg_ml column. Since we have passed a GroupedDataFrame
    object to the combine function, these operations are applied groupwise. Figure
    12.4 explains this syntax further.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，理解的关键元素是combine函数接受的单一操作规范语法。让我们专注于:deg_ml => mean => :mean_deg_ml操作。这种语法告诉combine函数应该取:deg_ml列，将其传递给mean函数，并将结果存储在:mean_deg_ml列中。由于我们已经将GroupedDataFrame对象传递给combine函数，这些操作是按组应用的。图12.4进一步解释了这种语法。
- en: '![CH12_F04_Kaminski2](../Images/CH12_F04_Kaminski2.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F04_Kaminski2](../Images/CH12_F04_Kaminski2.png)'
- en: Figure 12.4 In this operation-specification syntax accepted by the combine function,
    you pass the source data for the computation, the operation that should be applied
    to the source data, and the target column name where the results of the computations
    should be stored.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.4 在这个由combine函数接受的操作规范语法中，你传递计算的数据源，应用于源数据的操作，以及计算结果应存储的目标列名。
- en: This operation specification syntax is designed to be flexible and easy to use
    programmatically (that is, any of the components of the operation specification
    could have been passed as a variable). In chapter 13, we will discuss more options
    that this syntax provides.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这种操作规范语法旨在设计得灵活且易于程序化使用（也就是说，操作规范的任何组件都可以作为变量传递）。在第13章中，我们将讨论这种语法提供的更多选项。
- en: DataFramesMeta.jl domain-specific language
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: DataFramesMeta.jl领域特定语言
- en: 'If you are a dplyr user from R, you might wonder if you can achieve the same
    result by using the assignment syntax. This is possible with the DataFramesMeta.jl
    package:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是一个来自R的dplyr用户，你可能想知道你是否可以通过使用赋值语法达到相同的结果。这是使用DataFramesMeta.jl包可以实现的：
- en: '[PRE33]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'In this syntax, you write @combine instead of combine, and then you can use
    assignment to specify operations. In the operations, we use symbols to refer to
    the column names of the data frame, so we use the : prefix in front of the names.
    This convenience comes at the cost that the :mean_deg_ml = mean(:deg_ml) expression
    is not valid Julia code. In computer science parlance, we call such code a *domain-specific
    language*. For this reason, in the DataFrames.jl ecosystem, two high-level APIs
    are provided for specifying operations when, for example, aggregating data:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种语法中，你写@combine而不是combine，然后你可以使用赋值来指定操作。在操作中，我们使用符号来引用数据框的列名，因此我们在名称前使用冒号前缀。这种便利性是以表达式:mean_deg_ml
    = mean(:deg_ml)不是有效的Julia代码为代价的。在计算机科学术语中，我们称这样的代码为*领域特定语言*。因此，在DataFrames.jl生态系统内，当需要指定操作时（例如，聚合数据），提供了两个高级API来指定操作：
- en: '*A standard evaluation API provided by DataFrames.jl*—This uses the => syntax
    described in figure 12.4\. This syntax is more verbose but easier to use programmatically
    and is valid Julia code.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*DataFrames.jl提供的标准评估API*—这使用了图12.4中描述的=>语法。这种语法更冗长，但更易于程序化使用，并且是有效的Julia代码。'
- en: '*A nonstandard evaluation API provided by the DataFramesMeta.jl package*—This
    uses the assignment operator. This syntax is shorter at the cost of relying on
    nonstandard evaluation of code. It is often preferred by users when working interactively
    with data frames.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*DataFramesMeta.jl包提供的非标准评估API*—这使用了赋值运算符。这种语法更简短，但以依赖代码的非标准评估为代价。当与数据框进行交互式工作时，用户通常更倾向于使用它。'
- en: 12.3.2 Visualizing the relationship between the number of web and machine learning
    neighbors of a node
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.2 可视化节点网络和机器学习邻居数量之间的关系
- en: 'Now that we’ve investigated the aggregate relationship between the type of
    the developer and the number of their machine learning and web neighbors, we can
    analyze it in more detail visually. Start with the following plot, which is shown
    in figure 12.5:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经调查了开发者的类型与其机器学习和网络邻居数量之间的聚合关系，我们可以更详细地通过视觉来分析它。以下是一个图表，如图12.5所示：
- en: '[PRE34]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '![CH12_F05_Kaminski2](../Images/CH12_F05_Kaminski2.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F05_Kaminski2](../Images/CH12_F05_Kaminski2.png)'
- en: 'Figure 12.5 In this scatterplot of the node’s number of machine learning and
    web neighbors,developer type is indicated by point color: black indicates a machine
    learning developer, and yellow (gray in the printed book) indicates a web developer.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.5 在这个节点机器学习和Web邻居数量的散点图中，开发者的类型由点颜色表示：黑色表示机器学习开发者，黄色（在印刷书中为灰色）表示Web开发者。
- en: 'Unfortunately, this plot is not very informative for the following key reasons:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这个图表对于以下关键原因来说并不是很有信息量：
- en: The distribution of the number of neighbors is highly skewed. (We already saw
    this when computing summary statistics of the data.)
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 邻居数量的分布高度偏斜。（我们在计算数据摘要统计信息时已经看到了这一点。）
- en: Many developers have the same number of web and machine learning neighbors,
    so points representing that data overlap.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许多开发者拥有相同数量的Web和机器学习邻居，因此代表这些数据的点重叠。
- en: 'We will solve these problems by using the following techniques:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过以下技术来解决这些问题：
- en: Plot data aggregated by the combination of the number of web and machine learning
    neighbors of a developer. In this way, we will have a single point on the plot
    for a single combination of these values.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 绘制按开发者的Web和机器学习邻居数量组合聚合的数据。这样，对于这些值的每个组合，图表上都将有一个单独的点。
- en: Manually change the axis of the plots to be in logarithmic scale. In this way,
    we will visually decompress the low-degree part of the plot.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手动将图表的轴改为对数尺度。这样，我们将从视觉上解压缩图表的低度部分。
- en: Add jitter (random noise) to the displayed data to further reduce the problems
    caused by many points on the plot.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向显示的数据添加抖动（随机噪声）以进一步减少由图表上许多点引起的问题。
- en: 'We’ll start with aggregation of the data. We want to have a data frame that,
    for each unique combination of values stored in the deg_ml and deg_web columns,
    gives us information about a fraction of web developers:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从数据的聚合开始。我们希望有一个数据框，对于存储在deg_ml和deg_web列中的每个唯一值组合，它都能给我们提供关于Web开发者比例的信息：
- en: '[PRE35]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: In this code we group and aggregate data in one shot. Since we want to aggregate
    data conditionally on two variables, we pass them as the two-element vector [:deg_ml,
    :deg_web] to groupby. In this case, we have to define an anonymous function x
    -> 1 - mean(x) that performs the aggregation. The reason is that mean(x) produces
    a fraction of machine learning developers, and we want to get a fraction of web
    developers.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在此代码中，我们一次性对数据进行分组和聚合。由于我们想要根据两个变量条件性地聚合数据，我们将它们作为包含两个元素的向量[:deg_ml, :deg_web]传递给groupby。在这种情况下，我们必须定义一个匿名函数x
    -> 1 - mean(x)来执行聚合。原因是mean(x)产生的是机器学习开发者的比例，而我们想要得到的是Web开发者的比例。
- en: 'It is important to note that we have to wrap the anonymous function in parentheses
    like this:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，我们必须将匿名函数用括号括起来，如下所示：
- en: '[PRE36]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'If we were to omit the parentheses, we would get the following result:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们省略括号，我们会得到以下结果：
- en: '[PRE37]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: As you can see, because of Julia operator precedence rules, the target column
    name gets interpreted as a part of our anonymous function definition, which is
    not our intention.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，由于Julia运算符优先级规则，目标列名被解释为匿名函数定义的一部分，这并非我们的意图。
- en: 'Before we move forward, take a look at the DataFramesMeta.jl syntax for the
    same operation:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续前进之前，看看DataFramesMeta.jl语法中相同的操作：
- en: '[PRE38]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'This is, in my opinion, easier to read than the syntax using the => operator.
    Now that we have our aggregated data, let’s check its summary statistics:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，这比使用=>运算符的语法更容易阅读。现在我们已经有了聚合后的数据，让我们检查其摘要统计信息：
- en: '[PRE39]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'What is important for plotting is that we have a minimum value for each axis
    equal to 0\. We cannot apply a standard logarithmic rescaling of axes (which could
    be done in Plots.jl using the xscale=:log and yscale=:log keyword arguments).
    Therefore, we will implement a custom axis transformation using the log1p function.
    This function calculates the natural logarithm of 1 plus its argument. Therefore,
    when passed 0, it returns 0:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 对于绘图来说，重要的是每个轴都有一个等于0的最小值。我们不能应用标准的轴对数缩放（这可以在Plots.jl中使用xscale=:log和yscale=:log关键字参数完成）。因此，我们将使用log1p函数实现自定义的轴变换。此函数计算其参数加1的自然对数。因此，当传递0时，它返回0：
- en: '[PRE40]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: In listing 12.6, we apply the log1p transformation to the data, also jittering
    it, and define custom ticks for the plot axes to match the performed transformation.
    In the gen_ticks function, we define ticks at 0 and consecutive powers of 2 up
    to a rounded value of the maximum number to be plotted; the function returns a
    tuple consisting of the tick location and tick label.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表 12.6 中，我们对数据进行 log1p 转换，并对其进行抖动处理，同时为绘图轴定义自定义刻度以匹配所执行转换。在 gen_ticks 函数中，我们定义了
    0 和 2 的连续幂次，直到接近要绘制的最大数值的舍入值；该函数返回一个包含刻度位置和刻度标签的元组。
- en: Listing 12.6 Plotting the scatterplot of aggregated web developer data
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.6 绘制聚合网络开发者数据的散点图
- en: '[PRE41]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: ❶ Function generating custom ticks for the plot
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 生成自定义刻度的函数
- en: ❷ Applies a log1p transformation to a value and adds a random jitter to it in
    the [-0.05,0.05] range
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 对一个值应用 log1p 转换，并在 [-0.05,0.05] 范围内添加随机抖动
- en: ❸ Sets a seed for the random number generator to ensure reproducibility of the
    results
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 为随机数生成器设置种子以确保结果的重复性
- en: ❹ Gives a color to each point plotted on the scatterplot corresponding to the
    fraction of web developers
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 为散点图上绘制的每个点指定颜色，对应于网络开发者的比例
- en: ❺ Sets the size of each point
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 设置每个点的大小
- en: ❻ Sets the width of the stroke of each point
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 设置每个点的描边宽度
- en: ❼ Sets the transparency of each point
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 设置每个点的透明度
- en: ❽ Sets custom ticks for the plot, ensuring that they span up to a maximum value
    to be plotted on each axis
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 为绘图设置自定义刻度，确保它们跨越每个轴上的最大绘图值
- en: Figure 12.6 shows the resulting plot. We can see several relationships. In general,
    as the number of web neighbors increases for a node, the probability that the
    neighbor is a web developer increases. Similarly, as the number of machine learning
    neighbors of a node increases, the probability that the neighbor is a machine
    learning developer increases.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.6 显示了生成的结果图。我们可以看到几个关系。一般来说，随着节点网络邻居数量的增加，邻居是网络开发者的概率增加。同样，随着节点机器学习邻居数量的增加，邻居是机器学习开发者的概率也增加。
- en: Additionally, we see that there is no point at the (0, 0) coordinate since each
    node in our graph has a positive degree. Finally, in general, a positive correlation
    seems to exist between the number of web and machine learning neighbors of a node.
    If a developer has many web neighbors, chances increase that they have also many
    machine learning neighbors. This relationship is especially visible for developers
    with a high degree.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们注意到在 (0, 0) 坐标处没有点，因为我们的图中的每个节点都有一个正度数。最后，一般来说，一个节点的网络和机器学习邻居的数量之间似乎存在正相关关系。如果一个开发者有很多网络邻居，那么他们也有很多机器学习邻居的可能性增加。这种关系对于度数高的开发者尤其明显。
- en: Now, let’s consider a few technical aspects related to figure 12.6 and the code
    generating it. First, observe that jitter is indeed useful in this plot. If we
    omitted it, we would see all the points with a machine learning degree equal to
    0 in one line, and they most likely would overlap. Second, the gen_ticks function
    takes one argument that is a maximum value that we want to plot on an axis. Then,
    with round(Int, log2(maxv)), we compute the power to which we need to raise the
    number 2 that is nearest to this number.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们考虑与图 12.6 及其生成代码相关的几个技术方面。首先，观察抖动确实在这个图中很有用。如果我们省略了它，我们就会看到所有机器学习度数为 0
    的点都在一条线上，它们很可能重叠。其次，gen_ticks 函数接受一个参数，即我们想在轴上绘制的最大值。然后，通过 round(Int, log2(maxv))，我们计算出需要将数字
    2 提升到最接近这个数的幂。
- en: '![CH12_F06_Kaminski2](../Images/CH12_F06_Kaminski2.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F06_Kaminski2](../Images/CH12_F06_Kaminski2.png)'
- en: Figure 12.6 In this scatterplot of a fraction of a node’s machine learning and
    web neighbors, the darker the point, the lower the fraction of web developers
    for a given number of machine learning and web neighbors.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.6 在这个节点机器学习和网络邻居的散点图中，点越暗，给定数量的机器学习和网络邻居中网络开发者的比例越低。
- en: Notice that this works nicely on our plot. For the x-axis, the largest machine
    learning degree is 1620, so we stop at 2048 (and not 1024). For the y-axis, the
    largest web degree is 8194, so we stop at 8192 (and not at 16384). Next, with
    [0; 2 .^ (0:max2)], we produce ticks starting with 0 and then at consecutive powers
    of 2\. Finally, with (log1p.(tick), tick), we return a tuple of locations of the
    ticks transformed with the log1p function and the tick labels.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这在我们的图表上工作得很好。对于x轴，最大的机器学习学位是1620，所以我们停在2048（而不是1024）。对于y轴，最大的网络学位是8194，所以我们停在8192（而不是16384）。接下来，使用[0;
    2 .^ (0:max2)]，我们产生从0开始的刻度，然后是2的连续幂。最后，使用(log1p.(tick), tick)，我们返回一个元组，包含使用log1p函数转换的刻度位置和刻度标签。
- en: Making plots, like the one in figure 12.6, can be quite time-consuming if you
    want to really make sure they are informative. The big advantage of the Plots.jl
    package is that it provides many options for customizing your plot. In the Plots.jl
    documentation ([https://docs.juliaplots.org/stable/attributes/](https://docs.juliaplots.org/stable/attributes/)),
    you can find an extensive list of available plotting options.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想确保图表真正具有信息性，制作图表，如图12.6中的图表，可能会相当耗时。Plots.jl包的大优点是它提供了许多自定义图表的选项。在Plots.jl文档([https://docs.juliaplots.org/stable/attributes/](https://docs.juliaplots.org/stable/attributes/))中，您可以找到可用的绘图选项的详尽列表。
- en: Exercise 12.2 Check to see how the plot in figure 12.6 will look if you remove
    jittering from it.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 练习12.2 检查如果从图中移除抖动，图12.6中的图表将如何看起来。
- en: 12.3.3 Fitting a logistic regression model predicting developer type
  id: totrans-255
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.3 适配预测开发者类型的逻辑回归模型
- en: In this section, we create a logistic regression model for checking the relationship
    between the ml_target variable and the deg_ml and deg_web variables. If you do
    not have experience with logistic regression models, you can find introductory
    information on this topic at [http://mng.bz/G1ZV](http://mng.bz/G1ZV).
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们创建一个逻辑回归模型来检查ml_target变量与deg_ml和deg_web变量之间的关系。如果您对逻辑回归模型没有经验，您可以在[http://mng.bz/G1ZV](http://mng.bz/G1ZV)找到有关此主题的入门信息。
- en: 'We will use the GLM.jl package to estimate the model parameters and, as usual,
    I will show you some of the GLM.jl features that are useful in practice:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用GLM.jl包来估计模型参数，并且，像往常一样，我会向您展示一些在实践中有用的GLM.jl特性：
- en: '[PRE42]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: First, let’s interpret the obtained result. All estimated coefficients are highly
    significant, which is indicated by very small values in the Pr(>|z|) column in
    the output. The positive log1p(deg_ml) coefficient means that as the number of
    machine learning neighbors of the node increases, the probability predicted by
    our model that this node represents a machine learning developer increases. Similarly,
    since the log1p(deg_web) coefficient is negative, we conclude that as the number
    of web neighbors of the node increases, the predicted probability that it represents
    a machine learning node decreases. Chapter 13 explains how such a model can be
    used to make predictions for new data.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们解释一下获得的结果。所有估计的系数都非常显著，这从输出中Pr(>|z|)列的非常小的值中可以看出。正的log1p(deg_ml)系数意味着随着节点机器学习邻居数量的增加，我们的模型预测该节点代表机器学习开发者的概率增加。同样，由于log1p(deg_web)系数是负的，我们得出结论，随着节点网络邻居数量的增加，它代表机器学习节点的预测概率会降低。第13章解释了如何使用此类模型对新数据进行预测。
- en: 'Now, let’s turn to implementing the model. To fit the logistic regression model,
    we use the glm function. In this case, we pass four arguments to it. The first
    is the model formula. Here, notably, observe that we can conveniently pass the
    variable transformations within the formula. In this case, since the data has
    a significant right skewness, we fit the model with features transformed using
    the log1p function. The @formula macro automatically identifies such transformations
    if we pass them and creates appropriate anonymous functions:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们转向模型的实现。为了适配逻辑回归模型，我们使用glm函数。在这种情况下，我们向它传递四个参数。第一个是模型公式。在这里，值得注意的是，我们可以方便地在公式中传递变量转换。在这种情况下，由于数据有显著的右偏斜，我们使用log1p函数转换的特征来适配模型。如果传递它们，@formula宏会自动识别此类转换并创建适当的匿名函数：
- en: '[PRE43]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Second, to fit the logistic regression, we need to inform glm that our target
    feature is binary (follows the binomial distribution) by passing the Binomial()
    argument. Finally, since we can fit multiple possible models to binary data, we
    choose logistic regression via the LogitLink() argument. If, for example, you
    want to fit a probit model ([www.econometrics-with-r.org/11-2-palr.html](http://www.econometrics-with-r.org/11-2-palr.html)),
    use ProbitLink() instead.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，为了拟合逻辑回归，我们需要通知 glm 我们的目标特征是二元的（遵循二项分布），通过传递 Binomial() 参数。最后，由于我们可以拟合多个可能的模型来处理二元数据，我们通过
    LogitLink() 参数选择逻辑回归。例如，如果您想拟合 probit 模型 ([www.econometrics-with-r.org/11-2-palr.html](http://www.econometrics-with-r.org/11-2-palr.html))，请使用
    ProbitLink() 代替。
- en: Exercise 12.3 Fit a probit model instead of a logit model to predict the ml_target
    variable. Use the ProbitLink() argument to the glm function.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 12.3 使用 probit 模型而不是 logit 模型来预测 ml_target 变量。使用 glm 函数的 ProbitLink() 参数。
- en: In this chapter, I show an example of how the GLM.jl package can be used to
    fit prediction models. If you would like more details about features of this package,
    refer to the package manual ([https://juliastats.org/GLM.jl/stable/](https://juliastats.org/GLM.jl/stable/)).
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我展示了如何使用 GLM.jl 包来拟合预测模型。如果您想了解更多关于此包的功能，请参阅包手册 ([https://juliastats.org/GLM.jl/stable/](https://juliastats.org/GLM.jl/stable/))。
- en: 12.4 Reviewing data frame mutation operations
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.4 检查数据框修改操作
- en: 'The key options that DataFrames.jl offers for mutating data frames are as follows:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrames.jl 提供的用于修改数据框的关键选项如下：
- en: '*A low-level API using assignment or broadcasted assignment*—An example operation
    using this API is df.x .= 1, setting the column x to 1 using broadcasting assignment.
    This API is sometimes referred to as *imperative* since you explicitly specify
    the way an operation should be performed.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用赋值或广播赋值进行低级 API*—使用此 API 的一个示例操作是 df.x .= 1，通过广播赋值将列 x 设置为 1。此 API 有时被称为
    *命令式*，因为您明确指定了操作应如何执行。'
- en: '*A high-level API using data frame mutation functions*—This API is sometimes
    referred to as *declarative* since you specify only the operation you want to
    have performed and delegate to DataFrames.jl the decision of how to execute it
    most efficiently. The high-level API is useful when you want to perform a split-apply-combine
    operation. Two flavors of this high-level API are available:'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用数据框修改函数进行高级 API*—此 API 有时被称为 *声明式*，因为您只需指定要执行的操作，并将如何最有效地执行它的决策委托给 DataFrames.jl。高级
    API 在您想要执行 split-apply-combine 操作时非常有用。此高级 API 有两种形式：'
- en: '*Using standard evaluation*—This is provided by DataFrames.jl and relies on
    operations specified using the pair (=>) notation. You have learned about the
    combine function that supports this API.'
  id: totrans-269
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用标准评估*—这是由 DataFrames.jl 提供的，并依赖于使用 (=>) 符号指定的操作。您已经了解了支持此 API 的 combine
    函数。'
- en: '*Using nonstandard evaluation*—This is provided by the DataFramesMeta.jl package
    and allows you to use the assignment (=) notation. I have shown you the @combine
    macro that supports this API.'
  id: totrans-270
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用非标准评估*—这是由 DataFramesMeta.jl 包提供的，并允许您使用赋值 (=) 符号。我已经向您展示了支持此 API 的 @combine
    宏。'
- en: This chapter focused on explaining how the low-level (imperative) API works.
    Chapter 13 presents a more detailed discussion of the high-level (declarative)
    API.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 本章重点解释了低级（命令式）API 的工作原理。第 13 章将更详细地讨论高级（声明式）API。
- en: The DataFrames.jl ecosystem provides these three options for working with data
    frame objects because different developers have different preferences for structuring
    their code. In this book, I discuss all three alternatives so you can pick the
    one that best matches your needs.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrames.jl 生态系统提供了这三个选项来处理数据框对象，因为不同的开发者对代码结构的偏好不同。在这本书中，我讨论了所有三种替代方案，以便您可以选择最适合您需求的方案。
- en: 12.4.1 Performing low-level API operations
  id: totrans-273
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.4.1 执行低级 API 操作
- en: 'You can use the low-level API to update a data frame’s columns in the following
    seven ways:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用低级 API 以以下七种方式更新数据框的列：
- en: Create a new column in a data frame without copying.
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在数据框中创建新列而不进行复制。
- en: Create a new column in a data frame via copying.
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过复制在数据框中创建新列。
- en: Create a new column in a data frame by using broadcasting.
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过广播在数据框中创建新列。
- en: Update an existing column in a data frame by replacing it.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过替换更新数据框中的现有列。
- en: Update an existing column in a data frame in place.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在数据框中就地更新现有列。
- en: Update an existing column in a data frame by using broadcasting to replace it.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用广播替换现有列来更新数据框中的现有列
- en: Update an existing column in a data frame in place by using broadcasting.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用广播就地更新数据框中的现有列
- en: We’ll take a look at each option next.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中查看每个选项。
- en: Create a new column in a data frame without copying
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 不复制创建数据框中的新列
- en: 'To assign a vector v to a new column a in a data frame df without copying,
    write one of the following:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 要将向量 v 赋值给数据框 df 中的新列 a 而不进行复制，请编写以下之一：
- en: '[PRE44]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Create a new column in a data frame via copying
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 通过复制创建数据框中的新列
- en: 'To copy a vector v to a new column a in a data frame df, write this:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 要将向量 v 复制到数据框 df 中的新列 a，请编写以下内容：
- en: '[PRE45]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Create a new column in a data frame by using broadcasting
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 使用广播创建数据框中的新列
- en: 'To broadcast a scalar or vector s to a new column a in a data frame df (allocating
    this new column), write one of the following:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 要将标量或向量 s 广播到数据框 df 中的新列 a（分配此新列），请编写以下之一：
- en: '[PRE46]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Update an existing column in a data frame by replacing it
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 通过替换现有列来更新数据框中的现有列
- en: 'To assign a vector v to an existing column a in a data frame df without copying
    (by replacing the existing column), write one of the following:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 要将向量 v 就地赋值给数据框 df 中的现有列 a 而不进行复制（通过替换现有列），请编写以下之一：
- en: '[PRE47]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Update an existing column in a data frame in place
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 使用广播就地更新数据框中的现有列
- en: 'To assign a vector v to an existing column a in a data frame df in place (by
    updating data in the existing column), write this:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 要将向量 v 就地赋值给数据框 df 中的现有列 a（通过更新现有列中的数据），请编写以下内容：
- en: '[PRE48]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The same rule can be used to update only selected rows r from the data frame
    (note that : is just a special kind of row selector):'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '同样的规则可以用来更新数据框中仅选择的行 r（请注意，: 只是一种特殊的行选择器）：'
- en: '[PRE49]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Update an existing column in a data frame by using broadcasting to replace it
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 使用广播替换现有列来更新数据框中的现有列
- en: 'To assign a scalar or vector s to an existing column a in a data frame df and
    replace it by using broadcasting, write this:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用广播将标量或向量 s 赋值给数据框 df 中的现有列 a 并替换它，请编写以下内容：
- en: '[PRE50]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Update an existing column in a data frame in place by using broadcasting
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 使用广播就地更新数据框中的现有列
- en: 'To assign a scalar or vector s to an existing column a in a data frame df in
    place (by updating data in the existing column) by using broadcasting, write this:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用广播将标量或向量 s 就地赋值给数据框 df 中的现有列 a（通过更新现有列中的数据），请编写以下内容：
- en: '[PRE51]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The same rule can be used to update only selected rows r from the data frame
    (an example of such a selector could be the 1:3 range; note that : is just a special
    kind of row selector):'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '同样的规则可以用来更新数据框中仅选择的行 r（此类选择器的示例可以是 1:3 范围；请注意，: 只是一种特殊的行选择器）：'
- en: '[PRE52]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'In the preceding options, I have included only the operations that are most
    used. You can find a full list of operations supported by the low-level API in
    the DataFrames.jl documentation ([http://mng.bz/z58r](http://mng.bz/z58r)). Be
    warned that the list is extensive and might be hard to learn by heart. As a rule
    of thumb, you can assume the following:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的选项中，我只包括了最常用的操作。您可以在 DataFrames.jl 文档中找到支持的低级 API 的完整操作列表（[http://mng.bz/z58r](http://mng.bz/z58r)）。请注意，列表很长，可能难以记忆。作为一个经验法则，您可以假设以下内容：
- en: Most of the time, the operations I have listed will be sufficient for your needs.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数情况下，我列出的操作将满足您的需求。
- en: The DataFrames.jl API was designed to support every kind of operation you could
    possibly want in terms of behavior related to copying, or avoiding copying, data.
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DataFrames.jl API 被设计为支持您可能需要的所有与复制或避免复制数据相关的行为操作。
- en: Therefore, if, in the future, you need to perform a special operation not covered
    here, you can refer to the documentation.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果将来您需要执行这里未涵盖的特殊操作，您可以参考文档。
- en: 'Comparison of ! and : row selector behavior'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '比较行选择器 ! 和 : 的行为'
- en: 'It is useful to highlight the difference between how ! and : row selectors
    work. Assume that column a is present in data frame df.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '强调 ! 和 : 行选择器的工作方式之间的差异是有用的。假设列 a 存在于数据框 df 中。'
- en: Let’s first start with reading the data from a data frame. If you use df[!,
    "a"] to get a column a from a data frame, then this operation returns a column
    stored in this data frame without making a copy, while df[:, "a"] returns a copy
    of this column.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先从数据框中读取数据开始。如果您使用 df[!, "a"] 从数据框中获取列 a，则此操作返回存储在此数据框中的列而不进行复制，而 df[:,
    "a"] 返回此列的副本。
- en: A different situation is when you use the same syntax on the left hand of the
    assignment. In this case, if you write df[:, "a"] = v or df[:, "a"] .= s, then
    the operation is in-place, that is, the data from the right side is written to
    an existing column. If you write df[!, "a"] = v, then column a is replaced by
    vector v without copying. Finally, writing df[!, "a"] .= s allocates a new vector
    and replaces column a with it.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种情况是，当你在赋值语句的左侧使用相同的语法时。在这种情况下，如果你写 df[:, "a"] = v 或 df[:, "a"] .= s，那么操作是就地进行的，即，右侧的数据被写入现有列。如果你写
    df[!, "a"] = v，那么列 a 将被替换为向量 v 而不进行复制。最后，写 df[!, "a"] .= s 会分配一个新的向量并将列 a 替换为它。
- en: Exercise 12.4 Create an empty data frame. Add a column a to it, storing values
    1, 2, and 3 without copying. Next, create another column in the data frame, called
    b, that is the same vector as column a (without copying). Check that columns a
    and b store the same vector. Storing two identical columns in a data frame is
    unsafe, so in column b, store its copy. Now check that columns a and b store the
    same data but are different objects. Update in place the first two elements of
    column a by 10.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 12.4 创建一个空数据帧。向其中添加一个名为 a 的列，存储值 1、2 和 3 而不进行复制。接下来，在数据帧中创建另一个名为 b 的列，它与列
    a 是相同的向量（不进行复制）。检查列 a 和 b 存储的是相同的向量。在数据帧中存储两个相同的列是不安全的，所以在列 b 中存储其副本。现在检查列 a 和
    b 存储的是相同的数据但它们是不同的对象。就地更新列 a 的前两个元素为 10。
- en: 12.4.2 Using the insertcols! function to mutate a data frame
  id: totrans-317
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.4.2 使用 insertcols! 函数变异数据帧
- en: In this section, before I finish the review of data frame mutation operations,
    you will learn about the insertcols! function. This function is used to add new
    columns to a data frame. It has a similar syntax to the DataFrame constructor,
    where you pass a pair column_name => value to add a column to a data frame.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，在我完成数据帧变异操作的回顾之前，你将了解 insertcols! 函数。这个函数用于向数据帧中添加新列。它的语法与 DataFrame 构造函数类似，其中你传递一个
    column_name => value 对来向数据帧中添加列。
- en: The special feature of the insertcols! function is that it allows you to add
    a column in any location in a data frame and checks whether the passed column
    name already exists in the target data frame (to avoid accidental overwriting
    of a column). You can find more details about the insertcols! function in the
    DataFrames.jl documentation ([http://mng.bz/09Gm](http://mng.bz/09Gm)).
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: insertcols! 函数的特殊之处在于它允许你在数据帧中的任何位置添加一个列，并检查传递的列名是否已在目标数据帧中存在（以避免意外覆盖列）。你可以在
    DataFrames.jl 文档中找到更多关于 insertcols! 函数的详细信息 ([http://mng.bz/09Gm](http://mng.bz/09Gm))。
- en: 'Here I will present a few examples of how it works. Start with the most basic
    pattern, inserting a column at the end of the data frame:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 我将展示一些关于它是如何工作的例子。从最基本模式开始，即在数据帧的末尾插入一个列：
- en: '[PRE53]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: ❶ Inserts a new column to a data frame at its end
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在数据帧的末尾插入一个新列
- en: ❷ Trying to insert a duplicate column name is an error by default.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 默认情况下，尝试插入重复的列名是一个错误。
- en: ❸ Scalars are automatically broadcasted as in the DataFrame constructor.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 标量会自动广播，就像在 DataFrame 构造函数中一样。
- en: 'Let’s continue this example by inserting a new column at a certain position
    in the data frame. To do this, we pass a second argument, specifying the position
    where the column should be added:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过在数据帧的某个位置插入一个新列来继续这个例子。为此，我们传递第二个参数，指定列应该添加的位置：
- en: '[PRE54]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: ❶ Inserts a new column in the first position in the data frame
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在数据帧的第一个位置插入一个新列
- en: ❷ Inserts a new column before the x column in the data frame
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在数据帧中 x 列之前插入一个新列
- en: ❸ Inserts a new column after the x column in the data frame, which is signaled
    by the after=true keyword argument
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 在数据帧中 x 列之后插入一个新列，这由 after=true 关键字参数表示
- en: Use of the => operator in DataFrames.jl
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrames.jl 中 => 运算符的使用
- en: The => operator is used in two contexts in DataFrames.jl that should not be
    confused.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 在 DataFrames.jl 中，=> 运算符在两个上下文中使用，不应混淆。
- en: The first context is the DataFrame constructor and the insertcols! function,
    where the syntax has the form column_name => value. This form does not involve
    any data manipulation. It is used to put new data into a data frame. It is consistent
    with the way dictionaries are populated in Julia.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个上下文是 DataFrame 构造函数和 insertcols! 函数，其中语法形式为 column_name => value。这种形式不涉及任何数据操作。它用于将新数据放入数据帧中。这与
    Julia 中字典的填充方式一致。
- en: 'The second context is operation syntax supported by the combine function (in
    chapter 13, you will learn that the same operation syntax is supported by other
    functions: select, select!, transform, transform!, subset, and subset!). The operation
    syntax is used for manipulation of data already present in the data frame. Its
    general structure, described in figure 12.4, is source_column => operation_ function
    => target_column_name.'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种上下文是 combine 函数支持的运算符语法（在第 13 章中，您将了解到其他函数（如 select、select!、transform、transform!、subset
    和 subset!）也支持相同的运算符语法）。运算符语法用于操作数据帧中已经存在的数据。其一般结构，如图 12.4 所示，是 source_column =>
    operation_function => target_column_name。
- en: Summary
  id: totrans-334
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: A graph is a data structure that consists of nodes and edges connecting nodes.
    You can work with graphs in Julia by using the Graphs.jl package. You will need
    to work with graphs if you analyze data from social media, like Twitter or Facebook,
    where nodes represent users and edges represent the relationships between them.
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图是一种由节点和连接节点的边组成的数据结构。您可以使用 Graphs.jl 包在 Julia 中处理图。如果您分析来自社交媒体的数据，如 Twitter
    或 Facebook，其中节点代表用户，边代表它们之间的关系，您将需要与图一起工作。
- en: The SHA module provides functions that allow you to compute hash values of data
    you work with. One of these often-used algorithms is SHA-256, available via the
    sha256 function. You can use it to validate that data you download from the web
    is not corrupted.
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SHA 模块提供了允许您计算所处理数据哈希值的函数。其中常用的一种算法是 SHA-256，通过 sha256 函数提供。您可以使用它来验证从网络下载的数据是否损坏。
- en: The ZipFile.jl package provides tools for working with ZIP archives. It is often
    used in data science projects, as in many cases, your data sources will be compressed
    in this format.
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ZipFile.jl 包提供了处理 ZIP 归档的工具。在数据科学项目中经常使用它，因为在许多情况下，数据源将以这种格式压缩。
- en: You can perform broadcasting operations on data frame objects just as you would
    on matrices. Broadcasting allows you to conveniently transform values stored in
    data frames.
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以对数据帧对象执行广播操作，就像对矩阵执行一样。广播允许您方便地转换数据帧中存储的值。
- en: DataFrames.jl provides a low-level API for mutating the contents of the data
    frame that is based on indexing syntax. You can use both assignment (= operator)
    and broadcasted assignment (.= operator) syntaxes when you perform such operations.
    In general, operations of the form df[:, column] = are performed in place, and
    operations of the form df[!, column] = or df.column = replace columns. This API
    was designed to provide the developer with full control over the way the operation
    should be performed.
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DataFrames.jl 提供了一个基于索引语法的低级 API，用于修改数据帧的内容。在执行此类操作时，您可以使用赋值（=运算符）和广播赋值（.=运算符）语法。通常，形式为
    df[:, column] = 的操作是在原地执行的，而形式为 df[!, column] = 或 df.column = 的操作则替换列。此 API 的设计是为了让开发者能够完全控制操作执行的方式。
- en: The Graphs.jl package defines the SimpleGraph type that can be used to represent
    graphs in Julia, as well as multiple functions that allow you to analyze the properties
    of graphs (for example, listing neighbors of a node). This package is useful when,
    in your analysis, you have data that has a network structure.
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Graphs.jl 包定义了 SimpleGraph 类型，它可以用来在 Julia 中表示图，以及多个允许您分析图属性（例如，列出节点的邻居）的函数。当您的分析中包含具有网络结构的数据时，此包非常有用。
- en: In the SimpleGraph type, graph nodes are represented as consecutive integers,
    starting with 1, and graph edges are represented as pairs of integers indicating
    the nodes they connect. Thanks to this representation, it is easy to keep node
    metadata in Julia collections that use 1-based indexing (for example, data frames).
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 SimpleGraph 类型中，图节点以从 1 开始的连续整数表示，图边以表示它们连接的节点的整数对表示。得益于这种表示方式，在 Julia 集合中使用基于
    1 的索引（例如，数据帧）时，很容易保持节点元数据。
- en: You can perform split-apply-combine operations on data frame objects by using
    the groupby and combine functions that are part of the high-level API in DataFrames.jl
    (more related functions are discussed in chapter 13). The combine function is
    used to perform aggregation operations per group. The split-apply-combine operation
    is often useful when summarizing data.
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以使用 DataFrames.jl 中的高级 API 中的 groupby 和 combine 函数对数据帧对象执行拆分-应用-组合操作（更多相关函数将在第
    13 章中讨论）。combine 函数用于对每个组执行聚合操作。在汇总数据时，拆分-应用-组合操作通常非常有用。
- en: 'The combine function performs aggregations of data based on the passed operation
    specification syntax. Its general structure is as follows: source_ column => operation_function
    => target_column_name. For example, :a => mean => :a_mean indicates that data
    from column :a should be passed to the mean function, and the result of the computation
    should be stored in the :a_mean column. Operation specification syntax is especially
    convenient when used programmatically, as it is formed from valid Julia code.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: combine函数根据传递的操作规范语法执行数据的聚合。其一般结构如下：source_column => operation_function => target_column_name。例如，:a
    => mean => :a_mean 表示应将列 :a 的数据传递给均值函数，并将计算结果存储在 :a_mean 列中。操作规范语法在程序化使用时特别方便，因为它由有效的Julia代码组成。
- en: You can use the DataFramesMeta.jl package to simplify the specification of aggregation
    operations in the @combine macro. In this syntax, you write operations by using
    an assignment form; for example, the :a_mean = mean(:a) form is equivalent to
    :a => mean => :a_mean in a standard operation specification syntax. The syntax
    accepted by @combine is more convenient to write and read, but relies on a nonstandard
    evaluation.
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以使用DataFramesMeta.jl包简化@combine宏中聚合操作的规范。在这个语法中，你通过使用赋值形式来编写操作；例如，:a_mean
    = mean(:a) 形式与标准操作规范语法中的 :a => mean => :a_mean 等价。@combine接受的语法更方便编写和阅读，但依赖于非标准评估。
- en: The Plots.jl package provides a rich list of options allowing you to flexibly
    shape plots you create. The list of available plot attributes can be found at
    [https://docs.juliaplots.org/stable/attributes/](https://docs.juliaplots.org/stable/attributes/).
    In practice, creating a customized plot that highlights the important aspects
    of data you analyze is often a key ingredient of success in data science projects.
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Plots.jl包提供了一系列丰富的选项，允许你灵活地塑造你创建的图表。可用的绘图属性列表可以在[https://docs.juliaplots.org/stable/attributes/](https://docs.juliaplots.org/stable/attributes/)找到。在实践中，创建一个突出显示你分析数据重要方面的定制图表通常是数据科学项目中成功的关键因素。
- en: Using the GLM.jl package, you can fit logistic or probit regressions. These
    models are used when your target variable is binary.
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用GLM.jl包，你可以拟合逻辑回归或概率回归。这些模型在你目标变量为二元时使用。
- en: The insertcols! function can be used to add columns to a data frame in place.
    This function allows you to add a column in any location in the source data frame.
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: insertcols!函数可用于在数据框中就地添加列。此函数允许你在源数据框的任何位置添加列。
