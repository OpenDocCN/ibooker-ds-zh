- en: Chapter 1\. Data science in a big data world
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第一章\. 大数据世界中的数据科学
- en: '*This chapter covers*'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章涵盖*'
- en: Defining data science and big data
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义数据科学和大数据
- en: Recognizing the different types of data
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别不同类型的数据
- en: Gaining insight into the data science process
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取对数据科学过程的洞察
- en: Introducing the fields of data science and big data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍数据科学和大数据领域
- en: Working through examples of Hadoop
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 Hadoop 的示例进行工作
- en: '*Big data* is a blanket term for any collection of data sets so large or complex
    that it becomes difficult to process them using traditional data management techniques
    such as, for example, the RDBMS (relational database management systems). The
    widely adopted RDBMS has long been regarded as a one-size-fits-all solution, but
    the demands of handling big data have shown otherwise. *Data science* involves
    using methods to analyze massive amounts of data and extract the knowledge it
    contains. You can think of the relationship between big data and data science
    as being like the relationship between crude oil and an oil refinery. Data science
    and big data evolved from statistics and traditional data management but are now
    considered to be distinct disciplines.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*大数据* 是一个总称，用于描述任何数据集，其规模或复杂性如此之大或复杂，以至于使用传统的数据管理技术（例如，关系数据库管理系统 RDBMS）处理它们变得困难。广泛采用的
    RDBMS 一直被视为一种万能解决方案，但处理大数据的需求已经证明并非如此。*数据科学* 涉及使用方法来分析大量数据并提取其中包含的知识。你可以将大数据与数据科学之间的关系比作原油与炼油厂之间的关系。数据科学和大数据起源于统计学和传统数据管理，但现在被认为是不同的学科。'
- en: 'The characteristics of big data are often referred to as the three Vs:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大数据的特征通常被称为三个 V：
- en: '***Volume*** —How much data is there?'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***体积*** —有多少数据？'
- en: '***Variety*** —How diverse are different types of data?'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***多样性*** —不同类型的数据有多多样？'
- en: '***Velocity*** —At what speed is new data generated?'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***速度*** —新数据以多快的速度生成？'
- en: 'Often these characteristics are complemented with a fourth V, veracity: How
    accurate is the data? These four properties make big data different from the data
    found in traditional data management tools. Consequently, the challenges they
    bring can be felt in almost every aspect: data capture, curation, storage, search,
    sharing, transfer, and visualization. In addition, big data calls for specialized
    techniques to extract the insights.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，这些特征还会补充一个第四个 V，即 veracity：数据有多准确？这四个特性使大数据与传统数据管理工具中发现的数据不同。因此，它们带来的挑战几乎可以在各个方面感受到：数据捕获、整理、存储、搜索、共享、传输和可视化。此外，大数据需要专门的技巧来提取洞察力。
- en: Data science is an evolutionary extension of statistics capable of dealing with
    the massive amounts of data produced today. It adds methods from computer science
    to the repertoire of statistics. In a research note from Laney and Kart, *Emerging
    Role of the Data Scientist and the Art of Data Science*, the authors sifted through
    hundreds of job descriptions for data scientist, statistician, and BI (Business
    Intelligence) analyst to detect the differences between those titles. The main
    things that set a data scientist apart from a statistician are the ability to
    work with big data and experience in machine learning, computing, and algorithm
    building. Their tools tend to differ too, with data scientist job descriptions
    more frequently mentioning the ability to use Hadoop, Pig, Spark, R, Python, and
    Java, among others. Don’t worry if you feel intimidated by this list; most of
    these will be gradually introduced in this book, though we’ll focus on Python.
    Python is a great language for data science because it has many data science libraries
    available, and it’s widely supported by specialized software. For instance, almost
    every popular NoSQL database has a Python-specific API. Because of these features
    and the ability to prototype quickly with Python while keeping acceptable performance,
    its influence is steadily growing in the data science world.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学是统计学的一种进化扩展，能够处理今天产生的海量数据。它将计算机科学的方法添加到统计学的工具箱中。在Laney和Kart的研究笔记《数据科学家的新角色与数据科学的艺术》中，作者们筛选了数百个数据科学家、统计学家和BI（商业智能）分析师的职位描述，以检测这些头衔之间的差异。将数据科学家与统计学家区分开来的主要因素是处理大数据的能力以及在机器学习、计算和算法构建方面的经验。他们的工具也往往有所不同，数据科学家的职位描述中更频繁地提到使用Hadoop、Pig、Spark、R、Python和Java等能力。如果你觉得这个列表让你感到害怕，请不要担心；尽管我们将重点关注Python，但本书中会逐渐介绍这些工具中的大多数。Python是数据科学的一个优秀语言，因为它拥有许多数据科学库，并且得到了专业软件的广泛支持。例如，几乎每个流行的NoSQL数据库都有一个特定的Python
    API。由于这些特性和使用Python快速原型设计同时保持可接受性能的能力，它在数据科学领域的影響力正在稳步增长。
- en: As the amount of data continues to grow and the need to leverage it becomes
    more important, every data scientist will come across big data projects throughout
    their career.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 随着数据量的持续增长以及利用数据的重要性日益凸显，每位数据科学家在其职业生涯中都将遇到大数据项目。
- en: 1.1\. Benefits and uses of data science and big data
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1\. 数据科学与大数据的益处和用途
- en: Data science and big data are used almost everywhere in both commercial and
    noncommercial settings. The number of use cases is vast, and the examples we’ll
    provide throughout this book only scratch the surface of the possibilities.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学与大数据在商业和非商业环境中几乎无处不在。用例的数量非常庞大，本书中提供的例子只是触及了可能性的表面。
- en: 'Commercial companies in almost every industry use data science and big data
    to gain insights into their customers, processes, staff, completion, and products.
    Many companies use data science to offer customers a better user experience, as
    well as to cross-sell, up-sell, and personalize their offerings. A good example
    of this is Google AdSense, which collects data from internet users so relevant
    commercial messages can be matched to the person browsing the internet. MaxPoint
    ([http://maxpoint.com/us](http://maxpoint.com/us)) is another example of real-time
    personalized advertising. Human resource professionals use people analytics and
    text mining to screen candidates, monitor the mood of employees, and study informal
    networks among coworkers. People analytics is the central theme in the book *Moneyball:
    The Art of Winning an Unfair Game*. In the book (and movie) we saw that the traditional
    scouting process for American baseball was random, and replacing it with correlated
    signals changed everything. Relying on statistics allowed them to hire the right
    players and pit them against the opponents where they would have the biggest advantage.
    Financial institutions use data science to predict stock markets, determine the
    risk of lending money, and learn how to attract new clients for their services.
    At the time of writing this book, at least 50% of trades worldwide are performed
    automatically by machines based on algorithms developed by *quants*, as data scientists
    who work on trading algorithms are often called, with the help of big data and
    data science techniques.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎每个行业的商业公司都使用数据科学和大数据来深入了解他们的客户、流程、员工、完成情况和产品。许多公司使用数据科学来为客户提供更好的用户体验，以及进行交叉销售、升级销售并个性化他们的产品。Google
    AdSense就是一个很好的例子，它收集互联网用户的数据，以便将相关的商业信息与浏览互联网的人匹配。MaxPoint ([http://maxpoint.com/us](http://maxpoint.com/us))是另一个实时个性化广告的例子。人力资源专业人士使用人员分析和文本挖掘来筛选候选人、监控员工的情绪以及研究同事之间的非正式网络。人员分析是《点球成金：不公平游戏的胜利艺术》一书的核心主题。在书中（和电影）我们看到，美国棒球的传统选秀过程是随机的，用相关信号取代它则改变了所有的一切。依靠统计数据，他们能够雇佣正确的球员，并在他们具有最大优势的地方与他们对抗。金融机构使用数据科学来预测股市、确定贷款风险以及学习如何吸引新客户为其服务。在撰写本书时，全球至少50%的交易是由基于由数据科学家（通常被称为“量化分析师”）开发的算法自动完成的，这些数据科学家专注于交易算法，并借助大数据和数据科学技术。
- en: Governmental organizations are also aware of data’s value. Many governmental
    organizations not only rely on internal data scientists to discover valuable information,
    but also share their data with the public. You can use this data to gain insights
    or build data-driven applications. *Data.gov* is but one example; it’s the home
    of the US Government’s open data. A data scientist in a governmental organization
    gets to work on diverse projects such as detecting fraud and other criminal activity
    or optimizing project funding. A well-known example was provided by Edward Snowden,
    who leaked internal documents of the American National Security Agency and the
    British Government Communications Headquarters that show clearly how they used
    data science and big data to monitor millions of individuals. Those organizations
    collected 5 billion data records from widespread applications such as Google Maps,
    Angry Birds, email, and text messages, among many other data sources. Then they
    applied data science techniques to distill information.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 政府机构也意识到数据的价值。许多政府机构不仅依赖内部数据科学家来发现有价值的信息，而且还与公众共享他们的数据。您可以使用这些数据来获得洞察力或构建数据驱动的应用程序。*Data.gov*只是其中一个例子；它是美国政府开放数据的家园。政府机构中的数据科学家有机会参与各种项目，例如检测欺诈和其他犯罪活动或优化项目资金。爱德华·斯诺登提供了一个著名的例子，他泄露了美国国家安全局和英国政府通信总部的内部文件，清楚地展示了他们如何使用数据科学和大数据来监控数百万个人。这些机构从广泛的来源收集了500亿条数据记录，包括谷歌地图、愤怒的小鸟、电子邮件和短信等。然后，他们应用数据科学技术来提炼信息。
- en: Nongovernmental organizations (NGOs) are also no strangers to using data. They
    use it to raise money and defend their causes. The World Wildlife Fund (WWF),
    for instance, employs data scientists to increase the effectiveness of their fundraising
    efforts. Many data scientists devote part of their time to helping NGOs, because
    NGOs often lack the resources to collect data and employ data scientists. DataKind
    is one such data scientist group that devotes its time to the benefit of mankind.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 非政府组织（NGO）也不陌生于使用数据。他们使用数据来筹集资金并捍卫他们的事业。例如，世界自然基金会（WWF）雇佣数据科学家来提高他们筹款活动的有效性。许多数据科学家将他们的一部分时间投入到帮助
    NGOs 中，因为 NGOs 通常缺乏收集数据和雇佣数据科学家的资源。DataKind 就是这样一组数据科学家，他们致力于造福人类。
- en: 'Universities use data science in their research but also to enhance the study
    experience of their students. The rise of massive open online courses (MOOC) produces
    a lot of data, which allows universities to study how this type of learning can
    complement traditional classes. MOOCs are an invaluable asset if you want to become
    a data scientist and big data professional, so definitely look at a few of the
    better-known ones: Coursera, Udacity, and edX. The big data and data science landscape
    changes quickly, and MOOCs allow you to stay up to date by following courses from
    top universities. If you aren’t acquainted with them yet, take time to do so now;
    you’ll come to love them as we have.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 大学在他们的研究中使用数据科学，同时也为了提高学生的学习体验。大规模开放在线课程（MOOC）的兴起产生了大量数据，这使得大学能够研究这种学习方式如何补充传统课程。如果你想要成为一名数据科学家和大数据专业人士，MOOCs
    是一项无价的资产，所以一定要看看其中一些较为知名的：Coursera、Udacity 和 edX。大数据和数据科学领域变化迅速，MOOCs 允许你通过跟随顶尖大学的课程来保持最新。如果你还没有熟悉它们，现在就花时间了解一下；你会像我们一样爱上它们的。
- en: 1.2\. Facets of data
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2\. 数据的方面
- en: 'In data science and big data you’ll come across many different types of data,
    and each of them tends to require different tools and techniques. The main categories
    of data are these:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学和大数据中，你会遇到许多不同类型的数据，每种数据通常都需要不同的工具和技术。数据的主要类别如下：
- en: Structured
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结构化
- en: Unstructured
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无结构化
- en: Natural language
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自然语言
- en: Machine-generated
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器生成
- en: Graph-based
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于图
- en: Audio, video, and images
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 音频、视频和图像
- en: Streaming
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流式传输
- en: Let’s explore all these interesting data types.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索所有这些有趣的数据类型。
- en: 1.2.1\. Structured data
  id: totrans-31
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.2.1\. 结构化数据
- en: Structured data is data that depends on a data model and resides in a fixed
    field within a record. As such, it’s often easy to store structured data in tables
    within databases or Excel files ([figure 1.1](#ch01fig01)). SQL, or Structured
    Query Language, is the preferred way to manage and query data that resides in
    databases. You may also come across structured data that might give you a hard
    time storing it in a traditional relational database. Hierarchical data such as
    a family tree is one such example.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化数据是依赖于数据模型并位于记录中固定字段内的数据。因此，它通常很容易在数据库中的表或 Excel 文件中存储结构化数据（[图 1.1](#ch01fig01)）。SQL，或结构化查询语言，是管理并查询数据库中数据的首选方式。你也可能遇到一些结构化数据，可能很难在传统的关系型数据库中存储。例如，家谱这样的层次数据就是这样一种数据。
- en: Figure 1.1\. An Excel table is an example of structured data.
  id: totrans-33
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 1.1\. Excel 表格是结构化数据的一个例子。
- en: '![](Images/01fig01_alt.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/01fig01_alt.jpg)'
- en: The world isn’t made up of structured data, though; it’s imposed upon it by
    humans and machines. More often, data comes unstructured.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，世界并不是由结构化数据构成的；它是人类和机器强加的。更常见的是，数据是无结构的。
- en: 1.2.2\. Unstructured data
  id: totrans-36
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.2.2\. 无结构化数据
- en: Unstructured data is data that isn’t easy to fit into a data model because the
    content is context-specific or varying. One example of unstructured data is your
    regular email ([figure 1.2](#ch01fig02)). Although email contains structured elements
    such as the sender, title, and body text, it’s a challenge to find the number
    of people who have written an email complaint about a specific employee because
    so many ways exist to refer to a person, for example. The thousands of different
    languages and dialects out there further complicate this.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 无结构化数据是难以适应数据模型的数据，因为其内容是特定于上下文或变化的。无结构化数据的一个例子是你的普通电子邮件（[图 1.2](#ch01fig02)）。尽管电子邮件包含结构化元素，如发件人、标题和正文文本，但找到写有关于特定员工的投诉邮件的人数是一项挑战，因为有许多方式可以指代一个人。成千上万的不同语言和方言进一步复杂化了这个问题。
- en: Figure 1.2\. Email is simultaneously an example of unstructured data and natural
    language data.
  id: totrans-38
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 1.2\. 电子邮件既是无结构化数据的例子，也是自然语言数据的例子。
- en: '![](Images/01fig02_alt.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/01fig02_alt.jpg)'
- en: A human-written email, as shown in [figure 1.2](#ch01fig02), is also a perfect
    example of natural language data.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图1.2](#ch01fig02)所示的人写电子邮件也是一个自然语言数据的完美示例。
- en: 1.2.3\. Natural language
  id: totrans-41
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.2.3\. 自然语言
- en: Natural language is a special type of unstructured data; it’s challenging to
    process because it requires knowledge of specific data science techniques and
    linguistics.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言是一种特殊类型的非结构化数据；它难以处理，因为它需要了解特定的数据科学技术和语言学知识。
- en: 'The natural language processing community has had success in entity recognition,
    topic recognition, summarization, text completion, and sentiment analysis, but
    models trained in one domain don’t generalize well to other domains. Even state-of-the-art
    techniques aren’t able to decipher the meaning of every piece of text. This shouldn’t
    be a surprise though: humans struggle with natural language as well. It’s ambiguous
    by nature. The concept of meaning itself is questionable here. Have two people
    listen to the same conversation. Will they get the same meaning? The meaning of
    the same words can vary when coming from someone upset or joyous.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言处理社区在实体识别、主题识别、摘要、文本补全和情感分析方面取得了成功，但在一个领域训练的模型并不很好地泛化到其他领域。即使是最先进的技巧也无法解读每一条文本的含义。然而，这并不令人惊讶：人类在处理自然语言上也存在困难。它本质上就是模糊的。意义本身的概念在这里也是值得怀疑的。让两个人听同一场对话，他们会得到相同的意义吗？同样的词语在不同的情绪下（如愤怒或喜悦）可能会有不同的含义。
- en: 1.2.4\. Machine-generated data
  id: totrans-44
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.2.4\. 机器生成数据
- en: Machine-generated data is information that’s automatically created by a computer,
    process, application, or other machine without human intervention. Machine-generated
    data is becoming a major data resource and will continue to do so. Wikibon has
    forecast that the market value of the *industrial Internet* (a term coined by
    Frost & Sullivan to refer to the integration of complex physical machinery with
    networked sensors and software) will be approximately $540 billion in 2020\. IDC
    (International Data Corporation) has estimated there will be 26 times more connected
    things than people in 2020\. This network is commonly referred to as *the internet
    of things*.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 机器生成数据是由计算机、过程、应用程序或其他机器在没有人类干预的情况下自动创建的信息。机器生成数据正成为主要的数据资源，并将继续如此。Wikibon预测，到2020年，*工业互联网*（Frost
    & Sullivan创造的一个术语，指复杂物理机械与网络传感器和软件的集成）的市场价值将达到约5400亿美元。IDC（国际数据公司）估计，到2020年，连接的设备数量将是人数的26倍。这个网络通常被称为*物联网*。
- en: The analysis of machine data relies on highly scalable tools, due to its high
    volume and speed. Examples of machine data are web server logs, call detail records,
    network event logs, and telemetry ([figure 1.3](#ch01fig03)).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 由于机器数据量巨大且速度快，其分析依赖于高度可扩展的工具。机器数据的例子包括网络服务器日志、通话详细记录、网络事件日志和遥测数据([图1.3](#ch01fig03))。
- en: Figure 1.3\. Example of machine-generated data
  id: totrans-47
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.3\. 机器生成数据的示例
- en: '![](Images/01fig03_alt.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/01fig03_alt.jpg)'
- en: The machine data shown in [figure 1.3](#ch01fig03) would fit nicely in a classic
    table-structured database. This isn’t the best approach for highly interconnected
    or “networked” data, where the relationships between entities have a valuable
    role to play.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1.3](#ch01fig03)中显示的机器数据非常适合经典的表结构数据库。这不是处理高度互联或“网络化”数据（其中实体之间的关系起着重要作用）的最佳方法。'
- en: 1.2.5\. Graph-based or network data
  id: totrans-50
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.2.5\. 基于图或网络的数据
- en: “Graph data” can be a confusing term because any data can be shown in a graph.
    “Graph” in this case points to mathematical *graph theory*. In graph theory, a
    graph is a mathematical structure to model pair-wise relationships between objects.
    Graph or network data is, in short, data that focuses on the relationship or adjacency
    of objects. The graph structures use nodes, edges, and properties to represent
    and store graphical data. Graph-based data is a natural way to represent social
    networks, and its structure allows you to calculate specific metrics such as the
    influence of a person and the shortest path between two people.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: “图数据”可能是一个令人困惑的术语，因为任何数据都可以以图表的形式展示。这里的“图”指的是数学上的*图论*。在图论中，图是一种数学结构，用于模拟对象之间的成对关系。简而言之，图或网络数据是关注对象关系或相邻性的数据。图结构使用节点、边和属性来表示和存储图形数据。基于图的数据是表示社交网络的自然方式，其结构允许你计算特定指标，例如一个人的影响力和两个人之间的最短路径。
- en: Examples of graph-based data can be found on many social media websites ([figure
    1.4](#ch01fig04)). For instance, on LinkedIn you can see who you know at which
    company. Your follower list on Twitter is another example of graph-based data.
    The power and sophistication comes from multiple, overlapping graphs of the same
    nodes. For example, imagine the connecting edges here to show “friends” on Facebook.
    Imagine another graph with the same people which connects business colleagues
    via LinkedIn. Imagine a third graph based on movie interests on Netflix. Overlapping
    the three different-looking graphs makes more interesting questions possible.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图形数据的示例可以在许多社交媒体网站上找到([图1.4](#ch01fig04))。例如，在领英上，你可以看到你在哪家公司认识的人。推特上的关注者列表是另一个基于图形数据的例子。其力量和复杂性来自于多个重叠的节点图。例如，想象这里连接的边表示“Facebook上的朋友”。想象另一个包含相同人物的图，通过领英连接商业同事。想象一个基于Netflix电影兴趣的第三张图。重叠这三个看起来不同的图使得提出更有趣的问题成为可能。
- en: Figure 1.4\. Friends in a social network are an example of graph-based data.
  id: totrans-53
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.4\. 社交网络中的朋友是图形数据的例子。
- en: '![](Images/01fig04_alt.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/01fig04_alt.jpg)'
- en: Graph databases are used to store graph-based data and are queried with specialized
    query languages such as SPARQL.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图形数据库用于存储基于图形的数据，并使用专门的查询语言（如SPARQL）进行查询。
- en: Graph data poses its challenges, but for a computer interpreting additive and
    image data, it can be even more difficult.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图形数据带来了挑战，但对于计算机解释加性和图像数据来说，可能更加困难。
- en: 1.2.6\. Audio, image, and video
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.2.6\. 音频、图像和视频
- en: Audio, image, and video are data types that pose specific challenges to a data
    scientist. Tasks that are trivial for humans, such as recognizing objects in pictures,
    turn out to be challenging for computers. MLBAM (Major League Baseball Advanced
    Media) announced in 2014 that they’ll increase video capture to approximately
    7 TB per game for the purpose of live, in-game analytics. High-speed cameras at
    stadiums will capture ball and athlete movements to calculate in real time, for
    example, the path taken by a defender relative to two baselines.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 音频、图像和视频是数据科学家面临特定挑战的数据类型。对于人类来说微不足道的任务，例如在图片中识别物体，对于计算机来说却很具挑战性。MLBAM（美国职业棒球大联盟高级媒体）在2014年宣布，他们将增加每场比赛的视频捕捉量，达到大约7
    TB，用于实时比赛分析。体育场的高速摄像机将捕捉球和运动员的动作，以实时计算，例如，防守球员相对于两条底线所走的路径。
- en: Recently a company called DeepMind succeeded at creating an algorithm that’s
    capable of learning how to play video games. This algorithm takes the video screen
    as input and learns to interpret everything via a complex process of deep learning.
    It’s a remarkable feat that prompted Google to buy the company for their own Artificial
    Intelligence (AI) development plans. The learning algorithm takes in data as it’s
    produced by the computer game; it’s streaming data.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，一家名为DeepMind的公司成功开发了一个算法，能够学习如何玩电子游戏。这个算法将视频屏幕作为输入，并通过深度学习过程的复杂过程学习解释一切。这是一个令人瞩目的成就，促使谷歌收购该公司以用于他们自己的人工智能(AI)开发计划。学习算法接受由计算机游戏产生的数据；这是流数据。
- en: 1.2.7\. Streaming data
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.2.7\. 流数据
- en: While streaming data can take almost any of the previous forms, it has an extra
    property. The data flows into the system when an event happens instead of being
    loaded into a data store in a batch. Although this isn’t really a different type
    of data, we treat it here as such because you need to adapt your process to deal
    with this type of information.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然流数据可以几乎采取之前任何形式，但它有一个额外的属性。当事件发生时，数据流入系统，而不是批量加载到数据存储中。尽管这并不是真正不同类型的数据，但我们在这里将其视为此类，因为您需要调整您的流程来处理此类信息。
- en: Examples are the “What’s trending” on Twitter, live sporting or music events,
    and the stock market.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 示例包括推特上的“热门趋势”、现场体育或音乐赛事，以及股市。
- en: 1.3\. The data science process
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3\. 数据科学流程
- en: The data science process typically consists of six steps, as you can see in
    the mind map in [figure 1.5](#ch01fig05). We will introduce them briefly here
    and handle them in more detail in [chapter 2](kindle_split_010.xhtml#ch02).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学流程通常包括六个步骤，如你在[图1.5](#ch01fig05)中的思维导图中所见。我们在这里简要介绍它们，并在[第2章](kindle_split_010.xhtml#ch02)中更详细地处理它们。
- en: Figure 1.5\. The data science process
  id: totrans-65
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.5\. 数据科学流程
- en: '![](Images/01fig05.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/01fig05.jpg)'
- en: 1.3.1\. Setting the research goal
  id: totrans-67
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.3.1\. 确定研究目标
- en: Data science is mostly applied in the context of an organization. When the business
    asks you to perform a data science project, you’ll first prepare a project charter.
    This charter contains information such as what you’re going to research, how the
    company benefits from that, what data and resources you need, a timetable, and
    deliverables. Throughout this book, the data science process will be applied to
    bigger case studies and you’ll get an idea of different possible research goals.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学主要在组织背景下应用。当业务要求你执行一个数据科学项目时，你首先准备一个项目章程。这个章程包含诸如你要研究什么、公司如何从中受益、你需要哪些数据和资源、时间表以及交付成果等信息。在整个书中，数据科学过程将应用于更大的案例研究，你将了解不同的可能研究目标。
- en: 1.3.2\. Retrieving data
  id: totrans-69
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.3.2\. 获取数据
- en: The second step is to collect data. You’ve stated in the project charter which
    data you need and where you can find it. In this step you ensure that you can
    use the data in your program, which means checking the existence of, quality,
    and access to the data. Data can also be delivered by third-party companies and
    takes many forms ranging from Excel spreadsheets to different types of databases.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 第二步是收集数据。你在项目章程中已经说明了需要哪些数据以及在哪里可以找到它们。在这一步中，你确保可以使用这些数据在你的程序中，这意味着检查数据的存续性、质量和可访问性。数据也可以由第三方公司提供，形式多样，从Excel表格到不同类型的数据库。
- en: 1.3.3\. Data preparation
  id: totrans-71
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.3.3\. 数据准备
- en: 'Data collection is an error-prone process; in this phase you enhance the quality
    of the data and prepare it for use in subsequent steps. This phase consists of
    three subphases: *data cleansing* removes false values from a data source and
    inconsistencies across data sources, *data integration* enriches data sources
    by combining information from multiple data sources, and *data transformation*
    ensures that the data is in a suitable format for use in your models.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 数据收集是一个容易出错的过程；在这个阶段，你提高数据质量，并为后续步骤的使用做准备。这个阶段包括三个子阶段：*数据清洗*从数据源中移除错误值和跨数据源的不一致性，*数据集成*通过结合来自多个数据源的信息来丰富数据源，*数据转换*确保数据以适合在模型中使用的形式。
- en: 1.3.4\. Data exploration
  id: totrans-73
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.3.4\. 数据探索
- en: Data exploration is concerned with building a deeper understanding of your data.
    You try to understand how variables interact with each other, the distribution
    of the data, and whether there are outliers. To achieve this you mainly use descriptive
    statistics, visual techniques, and simple modeling. This step often goes by the
    abbreviation EDA, for Exploratory Data Analysis.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 数据探索涉及对数据的更深入理解。你试图理解变量之间如何相互作用，数据的分布情况，以及是否存在异常值。为了实现这一点，你主要使用描述性统计、可视化技术和简单的建模。这一步通常被称为EDA，即探索性数据分析。
- en: 1.3.5\. Data modeling or model building
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.3.5\. 数据建模或模型构建
- en: In this phase you use models, domain knowledge, and insights about the data
    you found in the previous steps to answer the research question. You select a
    technique from the fields of statistics, machine learning, operations research,
    and so on. Building a model is an iterative process that involves selecting the
    variables for the model, executing the model, and model diagnostics.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，你使用模型、领域知识和之前步骤中找到的数据的见解来回答研究问题。你从统计学、机器学习、运筹学等领域选择一种技术。构建模型是一个迭代过程，涉及选择模型变量、执行模型和模型诊断。
- en: 1.3.6\. Presentation and automation
  id: totrans-77
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.3.6\. 展示和自动化
- en: Finally, you present the results to your business. These results can take many
    forms, ranging from presentations to research reports. Sometimes you’ll need to
    automate the execution of the process because the business will want to use the
    insights you gained in another project or enable an operational process to use
    the outcome from your model.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你将结果展示给业务部门。这些结果可以有多种形式，从演示文稿到研究报告。有时你需要自动化执行过程，因为业务可能希望在其他项目中使用你获得的认识，或者使运营流程能够使用模型的结果。
- en: '|  |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: An iterative process
  id: totrans-80
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 迭代过程
- en: The previous description of the data science process gives you the impression
    that you walk through this process in a linear way, but in reality you often have
    to step back and rework certain findings. For instance, you might find outliers
    in the data exploration phase that point to data import errors. As part of the
    data science process you gain incremental insights, which may lead to new questions.
    To prevent rework, make sure that you scope the business question clearly and
    thoroughly at the start.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 之前对数据科学过程的描述可能会给你一种印象，即你以线性方式走过这个过程，但现实中你往往需要退后一步，重新审视某些发现。例如，你可能在数据探索阶段发现异常值，指向数据导入错误。作为数据科学过程的一部分，你获得渐进式洞察，这可能导致新的问题。为了防止重复工作，确保你在开始时清晰地彻底界定业务问题。
- en: '|  |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Now that we have a better understanding of the process, let’s look at the technologies.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对这个过程有了更好的理解，让我们来看看相关的技术。
- en: 1.4\. The big data ecosystem and data science
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.4\. 大数据生态系统与数据科学
- en: Currently many big data tools and frameworks exist, and it’s easy to get lost
    because new technologies appear rapidly. It’s much easier once you realize that
    the big data ecosystem can be grouped into technologies that have similar goals
    and functionalities, which we’ll discuss in this section. Data scientists use
    many different technologies, but not all of them; we’ll dedicate a separate chapter
    to the most important data science technology classes. The mind map in [figure
    1.6](#ch01fig06) shows the components of the big data ecosystem and where the
    different technologies belong.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 目前存在许多大数据工具和框架，由于新技术快速出现，很容易感到迷茫。一旦你意识到大数据生态系统可以按具有相似目标和功能的技术分组，这将在本节中讨论。数据科学家使用许多不同的技术，但并非所有技术；我们将用单独的一章来介绍最重要的数据科学技术类别。图
    [1.6](#ch01fig06) 中的思维导图显示了大数据生态系统的组件以及不同技术所属的位置。
- en: Figure 1.6\. Big data technologies can be classified into a few main components.
  id: totrans-86
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 1.6\. 大数据技术可以分为几个主要组件。
- en: '![](Images/01fig06_alt.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/01fig06_alt.jpg)'
- en: Let’s look at the different groups of tools in this diagram and see what each
    does. We’ll start with distributed file systems.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看图中不同的工具组，看看每个工具的作用。我们将从分布式文件系统开始。
- en: 1.4.1\. Distributed file systems
  id: totrans-89
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.4.1\. 分布式文件系统
- en: 'A *distributed file system* is similar to a normal file system, except that
    it runs on multiple servers at once. Because it’s a file system, you can do almost
    all the same things you’d do on a normal file system. Actions such as storing,
    reading, and deleting files and adding security to files are at the core of every
    file system, including the distributed one. Distributed file systems have significant
    advantages:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 *分布式文件系统* 与普通文件系统类似，但不同的是它同时运行在多个服务器上。因为它是文件系统，所以你可以做几乎与在普通文件系统上相同的事情。诸如存储、读取、删除文件以及为文件添加安全措施等操作是每个文件系统的核心，包括分布式文件系统。分布式文件系统具有显著的优势：
- en: They can store files larger than any one computer disk.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们可以存储比任何单个计算机磁盘都大的文件。
- en: Files get automatically replicated across multiple servers for redundancy or
    parallel operations while hiding the complexity of doing so from the user.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件会自动在多个服务器之间进行复制，以实现冗余或并行操作，同时隐藏了这一过程的复杂性，对用户来说不可见。
- en: 'The system scales easily: you’re no longer bound by the memory or storage restrictions
    of a single server.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统易于扩展：你不再受单个服务器内存或存储限制的约束。
- en: In the past, scale was increased by moving everything to a server with more
    memory, storage, and a better CPU (vertical scaling). Nowadays you can add another
    small server (horizontal scaling). This principle makes the scaling potential
    virtually limitless.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去，通过将所有内容迁移到具有更多内存、存储和更好 CPU 的服务器（垂直扩展）来增加规模。如今，你可以添加另一个小型服务器（水平扩展）。这一原则使得扩展潜力几乎无限。
- en: 'The best-known distributed file system at this moment is the *Hadoop File System
    (HDFS)*. It is an open source implementation of the Google File System. In this
    book we focus on the Hadoop File System because it is the most common one in use.
    However, many other distributed file systems exist: *Red Hat Cluster File System*,
    *Ceph File System*, and *Tachyon File System*, to name but three.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 目前最知名的分布式文件系统是 *Hadoop 文件系统 (HDFS)*。它是对 Google 文件系统的一个开源实现。在这本书中，我们专注于 Hadoop
    文件系统，因为它是最常用的。然而，还存在许多其他分布式文件系统：*Red Hat 集群文件系统*、*Ceph 文件系统*和*Tachyon 文件系统*，仅举三个例子。
- en: 1.4.2\. Distributed programming framework
  id: totrans-96
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.4.2\. 分布式编程框架
- en: Once you have the data stored on the distributed file system, you want to exploit
    it. One important aspect of working on a distributed hard disk is that you won’t
    move your data to your program, but rather you’ll move your program to the data.
    When you start from scratch with a normal general-purpose programming language
    such as C, Python, or Java, you need to deal with the complexities that come with
    distributed programming, such as restarting jobs that have failed, tracking the
    results from the different subprocesses, and so on. Luckily, the open source community
    has developed many frameworks to handle this for you, and these give you a much
    better experience working with distributed data and dealing with many of the challenges
    it carries.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你在分布式文件系统中存储了数据，你希望利用它。在分布式硬盘上工作的一个重要方面是，你不会将数据移动到程序中，而是将程序移动到数据中。当你从零开始使用像C、Python或Java这样的通用编程语言时，你需要处理分布式编程带来的复杂性，比如重启失败的任务、跟踪不同子进程的结果等等。幸运的是，开源社区已经为这些开发了众多框架，这些框架为你提供了与分布式数据一起工作的更好体验，并帮助你应对许多挑战。
- en: 1.4.3\. Data integration framework
  id: totrans-98
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.4.3. 数据集成框架
- en: Once you have a distributed file system in place, you need to add data. You
    need to move data from one source to another, and this is where the data integration
    frameworks such as Apache Sqoop and Apache Flume excel. The process is similar
    to an extract, transform, and load process in a traditional data warehouse.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你建立了分布式文件系统，就需要添加数据。你需要将数据从一个来源移动到另一个来源，这正是数据集成框架如Apache Sqoop和Apache Flume大显身手的地方。这个过程类似于传统数据仓库中的提取、转换和加载过程。
- en: 1.4.4\. Machine learning frameworks
  id: totrans-100
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.4.4. 机器学习框架
- en: 'When you have the data in place, it’s time to extract the coveted insights.
    This is where you rely on the fields of machine learning, statistics, and applied
    mathematics. Before World War II everything needed to be calculated by hand, which
    severely limited the possibilities of data analysis. After World War II computers
    and scientific computing were developed. A single computer could do all the counting
    and calculations and a world of opportunities opened. Ever since this breakthrough,
    people only need to derive the mathematical formulas, write them in an algorithm,
    and load their data. With the enormous amount of data available nowadays, one
    computer can no longer handle the workload by itself. In fact, several algorithms
    developed in the previous millennium would never terminate before the end of the
    universe, even if you could use every computer available on Earth. This has to
    do with time complexity ([https://en.wikipedia.org/wiki/Time_complexity](https://en.wikipedia.org/wiki/Time_complexity)).
    An example is trying to break a password by testing every possible combination.
    An example can be found at [http://stackoverflow.com/questions/7055652/real-world-example-of-exponential-time-complexity](http://stackoverflow.com/questions/7055652/real-world-example-of-exponential-time-complexity).
    One of the biggest issues with the old algorithms is that they don’t scale well.
    With the amount of data we need to analyze today, this becomes problematic, and
    specialized frameworks and libraries are required to deal with this amount of
    data. The most popular machine-learning library for Python is Scikit-learn. It’s
    a great machine-learning toolbox, and we’ll use it later in the book. There are,
    of course, other Python libraries:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据已经到位时，就是提取宝贵见解的时候了。这时，你需要依赖机器学习、统计学和应用数学等领域。在第二次世界大战之前，所有事情都需要手工计算，这严重限制了数据分析的可能性。第二次世界大战后，计算机和科学计算得到了发展。一台计算机可以完成所有的计数和计算，从而打开了无限的可能性。自从这一突破以来，人们只需要推导出数学公式，将它们写成算法，并加载他们的数据。如今，可用的数据量如此巨大，一台计算机已无法独自处理工作负载。事实上，在上一个千年中开发的几个算法，即使你能使用地球上所有的计算机，也无法在宇宙末日之前终止。这与时间复杂度([https://en.wikipedia.org/wiki/Time_complexity](https://en.wikipedia.org/wiki/Time_complexity))有关。一个例子是尝试通过测试所有可能的组合来破解密码。一个例子可以在[http://stackoverflow.com/questions/7055652/real-world-example-of-exponential-time-complexity](http://stackoverflow.com/questions/7055652/real-world-example-of-exponential-time-complexity)找到。旧算法的最大问题之一是它们扩展性不好。今天我们需要分析的数据量如此之大，这变得成问题，需要专门的框架和库来处理这么大的数据量。Python最受欢迎的机器学习库是Scikit-learn。它是一个出色的机器学习工具箱，我们将在本书的后面使用它。当然，还有其他Python库：
- en: '***PyBrain for neural networks*** —Neural networks are learning algorithms
    that mimic the human brain in learning mechanics and complexity. Neural networks
    are often regarded as advanced and black box.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***PyBrain用于神经网络*** —神经网络是模仿人类大脑学习机制和复杂性的学习算法。神经网络通常被视为高级和黑盒。'
- en: '***NLTK or Natural Language Toolkit*** —As the name suggests, its focus is
    working with natural language. It’s an extensive library that comes bundled with
    a number of text corpuses to help you model your own data.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***NLTK或自然语言工具包*** —正如其名所示，它的重点是处理自然语言。这是一个功能丰富的库，附带多个文本语料库，以帮助您建模自己的数据。'
- en: '***Pylearn2*** —Another machine learning toolbox but a bit less mature than
    Scikit-learn.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***Pylearn2*** —另一个机器学习工具箱，但比Scikit-learn成熟度略低。'
- en: '***TensorFlow*** —A Python library for deep learning provided by Google.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***TensorFlow*** —由谷歌提供的用于深度学习的Python库。'
- en: The landscape doesn’t end with Python libraries, of course. Spark is a new Apache-licensed
    machine-learning engine, specializing in real-learn-time machine learning. It’s
    worth taking a look at and you can read more about it at [http://spark.apache.org/](http://spark.apache.org/).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这个领域不仅限于Python库。Spark是一个新的Apache许可的机器学习引擎，专注于实时机器学习。它值得一看，你可以在[http://spark.apache.org/](http://spark.apache.org/)了解更多关于它的信息。
- en: 1.4.5\. NoSQL databases
  id: totrans-107
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.4.5\. NoSQL数据库
- en: If you need to store huge amounts of data, you require software that’s specialized
    in managing and querying this data. Traditionally this has been the playing field
    of relational databases such as Oracle SQL, MySQL, Sybase IQ, and others. While
    they’re still the go-to technology for many use cases, new types of databases
    have emerged under the grouping of NoSQL databases.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要存储大量数据，你需要一种专门用于管理和查询这些数据的软件。传统上，这通常是关系数据库如Oracle SQL、MySQL、Sybase IQ等领域的游戏规则。虽然它们仍然是许多用例的首选技术，但新的数据库类型已经在NoSQL数据库的范畴下出现。
- en: 'The name of this group can be misleading, as “No” in this context stands for
    “Not Only.” A lack of functionality in SQL isn’t the biggest reason for the paradigm
    shift, and many of the NoSQL databases have implemented a version of SQL themselves.
    But traditional databases had shortcomings that didn’t allow them to scale well.
    By solving several of the problems of traditional databases, NoSQL databases allow
    for a virtually endless growth of data. These shortcomings relate to every property
    of big data: their storage or processing power can’t scale beyond a single node
    and they have no way to handle streaming, graph, or unstructured forms of data.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这个组的名称可能会误导人，因为在这个上下文中，“No”代表“不仅”。SQL功能不足并不是范式转变的最大原因，许多NoSQL数据库已经实现了SQL的版本。但是，传统数据库的不足之处在于它们无法很好地扩展。通过解决传统数据库的几个问题，NoSQL数据库允许数据几乎无限增长。这些问题与大数据的每个属性相关：它们的存储或处理能力无法扩展到单个节点，并且它们没有处理流、图或非结构化数据形式的方法。
- en: 'Many different types of databases have arisen, but they can be categorized
    into the following types:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 已经出现了许多不同类型的数据库，但它们可以被归类为以下几种类型：
- en: '***Column databases*** —Data is stored in columns, which allows algorithms
    to perform much faster queries. Newer technologies use cell-wise storage. Table-like
    structures are still important.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***列数据库*** —数据以列的形式存储，这使得算法能够执行更快的查询。较新的技术使用单元格存储。类似表的结构仍然很重要。'
- en: '***Document stores*** —Document stores no longer use tables, but store every
    observation in a document. This allows for a much more flexible data scheme.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***文档存储*** —文档存储不再使用表，而是将每个观察结果存储在文档中。这允许有更多灵活的数据模式。'
- en: '***Streaming data*** —Data is collected, transformed, and aggregated not in
    batches but in real time. Although we’ve categorized it here as a database to
    help you in tool selection, it’s more a particular type of problem that drove
    creation of technologies such as Storm.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***流数据*** —数据不是批量收集、转换和汇总，而是在实时进行。虽然我们将其分类为数据库以帮助您选择工具，但它更是一种特定类型的问题，推动了像Storm这样的技术创造。'
- en: '***Key-value stores*** —Data isn’t stored in a table; rather you assign a key
    for every value, such as org.marketing.sales.2015: 20000\. This scales well but
    places almost all the implementation on the developer.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***键值存储*** —数据不是存储在表中；相反，你为每个值分配一个键，例如org.marketing.sales.2015: 20000\. 这可以很好地扩展，但几乎所有的实现都放在了开发者身上。'
- en: '***SQL on Hadoop*** —Batch queries on Hadoop are in a SQL-like language that
    uses the map-reduce framework in the background.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***SQL on Hadoop*** —Hadoop上的批量查询使用类似于SQL的语言，在后台使用map-reduce框架。'
- en: '***New SQL*** —This class combines the scalability of NoSQL databases with
    the advantages of relational databases. They all have a SQL interface and a relational
    data model.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***新SQL*** —这个类别结合了NoSQL数据库的可扩展性和关系数据库的优点。它们都具有SQL接口和关系数据模型。'
- en: '***Graph databases*** —Not every problem is best stored in a table. Particular
    problems are more naturally translated into graph theory and stored in graph databases.
    A classic example of this is a social network.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***图数据库*** —并非每个问题都最适合存储在表中。某些问题更自然地转化为图论并存储在图数据库中。一个典型的例子是社交网络。'
- en: 1.4.6\. Scheduling tools
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.4.6\. 调度工具
- en: Scheduling tools help you automate repetitive tasks and trigger jobs based on
    events such as adding a new file to a folder. These are similar to tools such
    as CRON on Linux but are specifically developed for big data. You can use them,
    for instance, to start a MapReduce task whenever a new dataset is available in
    a directory.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 调度工具帮助你自动化重复性任务，并根据事件（如将新文件添加到文件夹）触发作业。这些工具类似于Linux上的CRON，但专门为大数据开发。例如，你可以使用它们在目录中可用新数据集时启动MapReduce任务。
- en: 1.4.7\. Benchmarking tools
  id: totrans-120
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.4.7\. 基准测试工具
- en: This class of tools was developed to optimize your big data installation by
    providing standardized profiling suites. A profiling suite is taken from a representative
    set of big data jobs. Benchmarking and optimizing the big data infrastructure
    and configuration aren’t often jobs for data scientists themselves but for a professional
    specialized in setting up IT infrastructure; thus they aren’t covered in this
    book. Using an optimized infrastructure can make a big cost difference. For example,
    if you can gain 10% on a cluster of 100 servers, you save the cost of 10 servers.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这类工具的开发是为了通过提供标准化的分析套件来优化你的大数据安装。分析套件是从一组代表性大数据作业中提取的。基准测试和优化大数据基础设施和配置通常不是数据科学家自己的工作，而是专业设置IT基础设施的人员的工作；因此，这些内容没有包含在这本书中。使用优化的基础设施可以产生很大的成本差异。例如，如果你可以在100台服务器的集群上提高10%，你就可以节省10台服务器的成本。
- en: 1.4.8\. System deployment
  id: totrans-122
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.4.8\. 系统部署
- en: Setting up a big data infrastructure isn’t an easy task and assisting engineers
    in deploying new applications into the big data cluster is where system deployment
    tools shine. They largely automate the installation and configuration of big data
    components. This isn’t a core task of a data scientist.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 设置大数据基础设施并不容易，而帮助工程师将新应用程序部署到大数据集群正是系统部署工具大放异彩的地方。它们在很大程度上自动化了大数据组件的安装和配置。这不是数据科学家的核心任务。
- en: 1.4.9\. Service programming
  id: totrans-124
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.4.9\. 服务编程
- en: Suppose that you’ve made a world-class soccer prediction application on Hadoop,
    and you want to allow others to use the predictions made by your application.
    However, you have no idea of the architecture or technology of everyone keen on
    using your predictions. Service tools excel here by exposing big data applications
    to other applications as a service. Data scientists sometimes need to expose their
    models through services. The best-known example is the REST service; REST stands
    for representational state transfer. It’s often used to feed websites with data.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你已经在Hadoop上开发了一个世界级的足球预测应用程序，并且你想允许其他人使用你应用程序做出的预测。然而，你对所有热衷于使用你预测的人的架构或技术一无所知。服务工具在这里表现出色，通过将大数据应用程序作为服务暴露给其他应用程序。数据科学家有时需要通过服务来公开他们的模型。最著名的例子是REST服务；REST代表表示状态转移。它通常用于向网站提供数据。
- en: 1.4.10\. Security
  id: totrans-126
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.4.10\. 安全性
- en: Do you want everybody to have access to all of your data? You probably need
    to have fine-grained control over the access to data but don’t want to manage
    this on an application-by-application basis. Big data security tools allow you
    to have central and fine-grained control over access to the data. Big data security
    has become a topic in its own right, and data scientists are usually only confronted
    with it as data consumers; seldom will they implement the security themselves.
    In this book we don’t describe how to set up security on big data because this
    is a job for the security expert.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否希望每个人都能够访问你所有的数据？你可能需要精细控制对数据的访问，但又不想逐个应用程序地管理。大数据安全工具允许你集中和精细地控制对数据的访问。大数据安全已经成为一个独立的话题，数据科学家通常只是作为数据消费者面对它；很少会自己实现安全。在这本书中，我们不描述如何在大数据上设置安全，因为这是一项安全专家的工作。
- en: 1.5\. An introductory working example of Hadoop
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.5\. Hadoop的入门级工作示例
- en: We’ll end this chapter with a small application in a big data context. For this
    we’ll use a Hortonworks Sandbox image. This is a virtual machine created by Hortonworks
    to try some big data applications on a local machine. Later on in this book you’ll
    see how Juju eases the installation of Hadoop on multiple machines.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将以一个大数据环境中的小型应用程序结束本章。为此，我们将使用 Hortonworks Sandbox 镜像。这是一个由 Hortonworks 创建的虚拟机，用于在本地机器上尝试一些大数据应用程序。在本书的后面部分，您将看到
    Juju 如何简化在多台机器上安装 Hadoop 的过程。
- en: We’ll use a small data set of job salary data to run our first sample, but querying
    a large data set of billions of rows would be equally easy. The query language
    will seem like SQL, but behind the scenes a MapReduce job will run and produce
    a straightforward table of results, which can then be turned into a bar graph.
    The end result of this exercise looks like [figure 1.7](#ch01fig07).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个小型的工作薪资数据集来运行我们的第一个示例，但查询包含数十亿行的大数据集同样简单。查询语言将类似于 SQL，但在幕后将运行一个 MapReduce
    作业，并生成一个简单的结果表，然后可以将其转换为条形图。这个练习的最终结果看起来像 [图 1.7](#ch01fig07)。
- en: 'Figure 1.7\. The end result: the average salary by job description'
  id: totrans-131
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 1.7\. 最终结果：按工作描述的平均薪资
- en: '![](Images/01fig07_alt.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/01fig07_alt.jpg)'
- en: To get up and running as fast as possible we use a Hortonworks Sandbox inside
    Virtual-Box. VirtualBox is a virtualization tool that allows you to run another
    operating system inside your own operating system. In this case you can run CentOS
    with an existing Hadoop installation inside your installed operating system.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 为了尽可能快地启动，我们在 VirtualBox 中使用 Hortonworks Sandbox。VirtualBox 是一种虚拟化工具，允许您在自己的操作系统内运行另一个操作系统。在这种情况下，您可以在已安装的操作系统内运行带有现有
    Hadoop 安装的 CentOS。
- en: 'A few steps are required to get the sandbox up and running on VirtualBox. Caution,
    the following steps were applicable at the time this chapter was written (February
    2015):'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 VirtualBox 上将沙盒启动并运行，需要几个步骤。注意，以下步骤是在撰写本章时（2015 年 2 月）适用的：
- en: '**1**.  Download the virtual image from [http://hortonworks.com/products/hortonworkssandbox/#install](http://hortonworks.com/products/hortonworkssandbox/#install).'
  id: totrans-135
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**1**. 从 [http://hortonworks.com/products/hortonworkssandbox/#install](http://hortonworks.com/products/hortonworkssandbox/#install)
    下载虚拟镜像。'
- en: '**2**.  Start your virtual machine host. VirtualBox can be downloaded from
    [https://www.virtualbox.org/wiki/Downloads](https://www.virtualbox.org/wiki/Downloads).'
  id: totrans-136
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**2**. 启动您的虚拟机主机。VirtualBox 可以从 [https://www.virtualbox.org/wiki/Downloads](https://www.virtualbox.org/wiki/Downloads)
    下载。'
- en: '**3**.  Press CTRL+I and select the virtual image from Hortonworks.'
  id: totrans-137
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**3**. 按下 CTRL+I 并从 Hortonworks 选择虚拟镜像。'
- en: '**4**.  Click Next.'
  id: totrans-138
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**4**. 点击下一步。'
- en: '**5**.  Click Import; after a little time your image should be imported.'
  id: totrans-139
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**5**. 点击导入；稍等片刻，您的镜像应该已经导入。'
- en: '**6**.  Now select your virtual machine and click Run.'
  id: totrans-140
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**6**. 现在选择您的虚拟机并点击运行。'
- en: '**7**.  Give it a little time to start the CentOS distribution with the Hadoop
    installation running, as shown in [figure 1.8](#ch01fig08). Notice the Sandbox
    version here is 2.1\. With other versions things could be slightly different.'
  id: totrans-141
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**7**. 稍等片刻，启动带有 Hadoop 安装的 CentOS 发行版，如图 1.8 所示。注意这里的沙盒版本是 2.1。在其他版本中可能会有所不同。'
- en: ''
  id: totrans-142
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Figure 1.8\. Hortonworks Sandbox running within VirtualBox
  id: totrans-143
  prefs:
  - PREF_BQ
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 1.8\. 在 VirtualBox 中运行的 Hortonworks Sandbox
- en: ''
  id: totrans-144
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](Images/01fig08_alt.jpg)'
  id: totrans-145
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![](Images/01fig08_alt.jpg)'
- en: You can directly log on to the machine or use SSH to log on. For this application
    you’ll use the web interface. Point your browser to the address [http://127.0.0.1:8000](http://127.0.0.1:8000)
    and you’ll be welcomed with the screen shown in [figure 1.9](#ch01fig09).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以直接登录到机器或使用 SSH 登录。对于此应用程序，您将使用 Web 界面。将您的浏览器指向地址 [http://127.0.0.1:8000](http://127.0.0.1:8000)，您将看到
    [图 1.9](#ch01fig09) 中所示的屏幕。
- en: Figure 1.9\. The Hortonworks Sandbox welcome screen available at [http://127.0.0.1:8000](http://127.0.0.1:8000)
  id: totrans-147
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 1.9\. 可在 [http://127.0.0.1:8000](http://127.0.0.1:8000) 找到的 Hortonworks Sandbox
    欢迎界面
- en: '![](Images/01fig09.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/01fig09.jpg)'
- en: Hortonworks has uploaded two sample sets, which you can see in HCatalog. Just
    click the HCat button on the screen and you’ll see the tables available to you
    ([figure 1.10](#ch01fig10)).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: Hortonworks 上传了两个样本集，您可以在 HCatalog 中看到它们。只需点击屏幕上的 HCat 按钮，您就会看到可用的表 ([图 1.10](#ch01fig10))。
- en: Figure 1.10\. A list of available tables in HCatalog
  id: totrans-150
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 1.10\. HCatalog 中可用的表列表
- en: '![](Images/01fig10.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/01fig10.jpg)'
- en: To see the contents of the data, click the Browse Data button next to the sample_07
    entry to get the next screen ([figure 1.11](#ch01fig11)).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看数据内容，请点击样本_07 条目旁边的浏览数据按钮，以获取下一屏幕 ([图 1.11](#ch01fig11))。
- en: Figure 1.11\. The contents of the table
  id: totrans-153
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.11。表格的内容
- en: '![](Images/01fig11_alt.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/01fig11_alt.jpg)'
- en: 'This looks like an ordinary table, and Hive is a tool that lets you approach
    it like an ordinary database with SQL. That’s right: in Hive you get your results
    using HiveQL, a dialect of plain-old SQL. To open the Beeswax HiveQL editor, click
    the Beeswax button in the menu ([figure 1.12](#ch01fig12)).'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来像是一个普通的表格，而Hive是一个工具，让你可以用SQL像普通数据库一样接近它。没错：在Hive中，你使用HiveQL（一种普通的SQL方言）来获取结果。要打开Beeswax
    HiveQL编辑器，请点击菜单中的Beeswax按钮（[图1.12](#ch01fig12)）。
- en: Figure 1.12\. You can execute a HiveQL command in the Beeswax HiveQL editor.
    Behind the scenes it’s translated into a MapReduce job.
  id: totrans-156
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.12。您可以在Beeswax HiveQL编辑器中执行HiveQL命令。幕后，它被转换为一个MapReduce作业。
- en: '![](Images/01fig12_alt.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/01fig12_alt.jpg)'
- en: 'To get your results, execute the following query:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取你的结果，执行以下查询：
- en: '[PRE0]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Click the Execute button. Hive translates your HiveQL into a MapReduce job and
    executes it in your Hadoop environment, as you can see in [figure 1.13](#ch01fig13).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 点击执行按钮。Hive将你的HiveQL转换为MapReduce作业，并在你的Hadoop环境中执行它，如图1.13所示。
- en: 'Figure 1.13\. The logging shows that your HiveQL is translated into a MapReduce
    job. Note: This log was from the February 2015 version of HDP, so the current
    version might look slightly different.'
  id: totrans-161
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.13。日志显示你的HiveQL被转换为一个MapReduce作业。注意：这个日志是从2015年2月的HDP版本中来的，所以当前版本可能看起来略有不同。
- en: '![](Images/01fig13_alt.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/01fig13_alt.jpg)'
- en: Best however to avoid reading the log window for now. At this point, it’s misleading.
    If this is your first query, then it could take 30 seconds. Hadoop is famous for
    its warming periods. That discussion is for later, though.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，现在最好避免阅读日志窗口。在这个阶段，它可能会误导人。如果你这是第一次查询，那么可能需要30秒。Hadoop以其预热期而闻名。不过，那个讨论留到以后再说。
- en: After a while the result appears. Great work! The conclusion of this, as shown
    in [figure 1.14](#ch01fig14), is that going to medical school is a good investment.
    Surprised?
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 过了一段时间，结果出现了。干得好！正如[图1.14](#ch01fig14)所示，结论是上医学院是一个好的投资。惊讶吗？
- en: 'Figure 1.14\. The end result: an overview of the average salary by profession'
  id: totrans-165
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.14。最终结果：按职业的平均工资概述
- en: '![](Images/01fig14_alt.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/01fig14_alt.jpg)'
- en: With this table we conclude our introductory Hadoop tutorial.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个表格，我们结束了我们的Hadoop入门教程。
- en: Although this chapter was but the beginning, it might have felt a bit overwhelming
    at times. It’s recommended to leave it be for now and come back here again when
    all the concepts have been thoroughly explained. Data science is a broad field
    so it comes with a broad vocabulary. We hope to give you a glimpse of most of
    it during our time together. Afterward, you pick and choose and hone your skills
    in whatever direction interests you the most. That’s what “Introducing Data Science”
    is all about and we hope you’ll enjoy the ride with us.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这一章只是个开始，但有时可能会觉得有点令人不知所措。建议现在先放一放，等到所有概念都彻底解释清楚后再回来。数据科学是一个广泛的领域，因此它包含了一个广泛的词汇表。我们希望在我们的时间里给你一个大多数内容的概览。之后，你可以挑选和选择，并在你最感兴趣的领域磨练你的技能。这就是“介绍数据科学”的全部内容，我们希望你能和我们一起享受这段旅程。
- en: 1.6\. Summary
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.6. 摘要
- en: 'In this chapter you learned the following:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了以下内容：
- en: '*Big data* is a blanket term for any collection of data sets so large or complex
    that it becomes difficult to process them using traditional data management techniques.
    They are characterized by the four Vs: velocity, variety, volume, and veracity.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*大数据*是一个总称，用于任何大型或复杂的数据集集合，以至于使用传统的数据管理技术处理它们变得困难。它们的特点是四个V：速度、多样性、体积和真实性。'
- en: '*Data science* involves using methods to analyze small data sets to the gargantuan
    ones big data is all about.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据科学*涉及使用方法来分析从小数据集到大数据集的所有内容。'
- en: 'Even though the *data science process* isn’t linear it can be divided into
    steps:'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管数据科学流程不是线性的，但它可以被分解为以下步骤：
- en: '**1**.  Setting the research goal'
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**1**. 确定研究目标'
- en: '**2**.  Gathering data'
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**2**. 收集数据'
- en: '**3**.  Data preparation'
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**3**. 数据准备'
- en: '**4**.  Data exploration'
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**4**. 数据探索'
- en: '**5**.  Modeling'
  id: totrans-178
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**5**. 模型'
- en: '**6**.  Presentation and automation'
  id: totrans-179
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**6**. 展示和自动化'
- en: 'The big data landscape is more than Hadoop alone. It consists of many different
    technologies that can be categorized into the following:'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大数据景观不仅仅是Hadoop。它由许多不同的技术组成，可以归类为以下几类：
- en: File system
  id: totrans-181
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件系统
- en: Distributed programming frameworks
  id: totrans-182
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式编程框架
- en: Data integration
  id: totrans-183
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集成
- en: Databases
  id: totrans-184
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据库
- en: Machine learning
  id: totrans-185
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习
- en: Security
  id: totrans-186
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全性
- en: Scheduling
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调度
- en: Benchmarking
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基准测试
- en: System deployment
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统部署
- en: Service programming
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务编程
- en: Not every big data category is utilized heavily by data scientists. They focus
    mainly on the file system, the distributed programming frameworks, databases,
    and machine learning. They do come in contact with the other components, but these
    are domains of other professions.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并非每个大数据类别都被数据科学家大量使用。他们主要关注文件系统、分布式编程框架、数据库和机器学习。他们确实会接触到其他组件，但这些是其他专业领域的范畴。
- en: Data can come in different forms. The main forms are
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据可以以不同的形式出现。主要形式包括
- en: Structured data
  id: totrans-193
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结构化数据
- en: Unstructured data
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非结构化数据
- en: Natural language data
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自然语言数据
- en: Machine data
  id: totrans-196
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器数据
- en: Graph-based data
  id: totrans-197
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于图的数据
- en: Streaming data
  id: totrans-198
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流数据
