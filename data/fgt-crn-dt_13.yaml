- en: 10 Churn demographics and firmographics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10 人口统计学和公司人口统计学
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Creating a dataset that includes demographic or firmographic information
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建包含人口统计学或公司人口统计学信息的数据库
- en: Converting date information to intervals and analyzing the relationship to churn
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将日期信息转换为区间并分析其与流失的关系
- en: Analyzing text categories for the relationship to churn
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析文本类别与流失之间的关系
- en: Forecasting churn probability with demographic or firmographic information
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用人口统计学或公司人口统计学信息预测流失概率
- en: Segmenting customers with demographic or firmographic information
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用人口统计学或公司人口统计学信息细分客户
- en: 'You now know all about using customer behavior data to segment your customers
    for the purpose of creating interventions to increase engagement. These strategies
    are the most important ones for increasing customer engagement and retention,
    which is why they are the focus of the book. But one other way to reduce your
    customer churn is not about intervening with your existing customers: find new
    customers who are more likely to be engaged to begin with. Identify facts about
    customers who tend to be more engaged, and then focus your customer acquisition
    efforts on finding more customers like them. Such facts are generally known as
    demographic data (data about individuals) and firmographic data (data about companies).
    For the purpose of this discussion, I use the following definitions.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你已经了解了如何使用客户行为数据来细分客户，以便创建干预措施来提高参与度。这些策略是提高客户参与度和保留率最重要的策略，这也是为什么它们是本书的重点。但降低客户流失率的一种其他方法并不是关于干预现有客户：找到一开始就更有可能参与的新客户。识别那些倾向于更积极参与的客户的事实，然后集中客户获取努力，寻找更多类似客户。这些事实通常被称为人口统计数据（关于个人的数据）和公司统计数据（关于公司的数据）。为了这次讨论的目的，我使用以下定义。
- en: DEFINITION Demographics are facts about individual customers, and firmographics
    are facts about customers that are companies (firms).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 定义：人口统计学是关于个人客户的实际情况，而公司人口统计学是关于作为公司的客户的实际情况。
- en: Demographics and firmographics generally are unchanging facts about the customer
    or facts that change only rarely. Demographics and firmographics do not include
    product use or subscription-derived metrics, but they can include facts about
    how the customer signed up or about the hardware a customer uses to access an
    online service. Normally, a business-to-consumer (B2C) or direct-to-consumer (D2C)
    company uses demographic data, whereas a business-to-business (B2B) company uses
    firmographic data. As you will see, demographics and firmographics differ in the
    specific pieces of information that are normally available. But the characteristics
    of that information are similar in either case, and for that reason, the techniques
    for handling demographics and firmographics are the same.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 人口统计学和公司人口统计学通常是关于客户的不变事实，或者仅偶尔变化的事实。人口统计学和公司人口统计学不包括产品使用或订阅衍生指标，但可以包括关于客户如何注册或关于客户用于访问在线服务的硬件的事实。通常，面向消费者（B2C）或直接面向消费者（D2C）的公司使用人口统计数据，而面向企业（B2B）的公司使用公司统计数据。正如你将看到的，人口统计学和公司人口统计学在通常可用的具体信息方面有所不同。但无论哪种情况，该信息的特点都是相似的，因此处理人口统计学和公司人口统计学的方法是相同的。
- en: NOTE This chapter uses the example of the social network simulation from the
    GitHub repository for the book ([https://github.com/carl24k/fight-churn](https://github.com/carl24k/fight-churn)),
    which is a consumer product. For that reason, I generally speak about demographics,
    but the same techniques apply to firmographics.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：本章使用GitHub仓库中书籍的社交网络模拟示例（[https://github.com/carl24k/fight-churn](https://github.com/carl24k/fight-churn)），这是一个消费者产品。因此，我通常讨论人口统计学，但同样的技术也适用于公司人口统计学。
- en: It is worth noting at the outset that targeting demographics is the least direct
    method of reducing churn because it doesn’t help your existing customers become
    more engaged. You can sometimes influence your customer’s behavior, but you cannot
    change the demographic or firmographic facts about them! Also, targeting acquisitions
    usually has limited impact because most products and services cannot get all the
    customers they would like from only one or a few preferred channels. Still, this
    approach can move the needle on churn over time, and it is worth your while to
    try every means at your disposal.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，针对人口统计数据进行定位是减少客户流失最不直接的方法，因为它不能帮助你的现有客户变得更加活跃。你有时可以影响客户的行为，但你不能改变他们的人口统计或企业统计数据！此外，针对收购的定位通常影响有限，因为大多数产品和服务的客户无法仅通过一个或几个首选渠道获得。尽管如此，这种方法可以在一段时间内推动客户流失率的变化，因此尝试你所能利用的每一种方法都是值得的。
- en: 'This chapter is organized as follows:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的组织结构如下：
- en: Section 10.1 describes typical demographic and firmographic data types and database
    schemas that contain it and teaches you how to extract such data as part of a
    dataset.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第10.1节描述了典型的人口统计和企业统计数据类型以及包含它们的数据库模式，并教你如何将此类数据作为数据集的一部分提取出来。
- en: 'Section 10.2 shows you how to individually analyze textual demographic data
    fields with category cohort analysis, which is a bit different from metric cohort
    analysis because it uses a new concept: confidence intervals.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第10.2节展示了如何使用类别队列分析单独分析文本人口统计数据字段，这与指标队列分析略有不同，因为它使用了一个新概念：置信区间。
- en: Section 10.3 teaches you to handle large numbers of demographic categories by
    combining them.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第10.3节教你如何通过组合来处理大量的人口统计类别。
- en: Section 10.4 demonstrates analyzing a date field for its relationship to churn
    (the same as metric cohort analysis after the date has been converted to a time
    interval).
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第10.4节展示了如何分析日期字段与其与客户流失的关系（在将日期转换为时间间隔后，与指标队列分析相同）。
- en: Section 10.5 teaches you the techniques necessary to fit churn probability models
    like regression and XGBoost when your data includes demographic data fields.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第10.5节教你如何在数据包括人口统计数据字段时，拟合客户流失概率模型，如回归和XGBoost。
- en: Section 10.6 extends the modeling in section 10.5 to forecasting and segmenting
    active customers by using demographic fields.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第10.6节将第10.5节中的建模扩展到使用人口统计字段进行预测和细分活跃客户。
- en: NOTE No real personal information was used to create this chapter. All examples
    are created from simulated data, designed to be similar to real case studies I
    have worked on.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：本章节中没有使用任何真实个人信息。所有示例均由模拟数据创建，旨在与我所参与的真实案例研究相似。
- en: 10.1 Demographic and firmographic datasets
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.1 人口统计和企业统计数据集
- en: First, I will explain what exactly I mean by demographic and firmographic data
    and how it differs from the metrics you have looked at throughout most of this
    book. Then I will use a social network simulation to demonstrate a typical method
    for creating a dataset that includes demographic data along with metrics.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我将解释我所说的“人口统计和企业统计数据”究竟是什么，以及它与你在本书大部分内容中看到的指标有何不同。然后，我将使用社交网络模拟来展示创建包含人口统计数据和指标的典型数据集的方法。
- en: 10.1.1 Types of demographic and firmographic data
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.1 人口统计和企业统计数据的类型
- en: Table 10.1 provides examples of demographic and firmographic data. Although
    this table covers the most common examples, there are many more possibilities.
    As you can see, some types of data are common to both consumers and firms in slightly
    different forms. An individual has a birthdate, and a company has a founding date,
    for example; a household has a number of members, and a company has a number of
    employees. Other items are specific to a consumer or businesses, such as a person’s
    education level or the company’s industry. Table 10.1 also shows the data type
    for the items listed.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.1提供了人口统计和企业统计数据的示例。尽管这个表格涵盖了最常见的例子，但还有许多其他可能性。正如你所看到的，某些类型的数据在消费者和企业中都是常见的，但形式略有不同。例如，个人有出生日期，公司有成立日期；家庭有成员数量，公司有员工数量。其他项目是针对消费者或企业的特定项目，例如个人的教育水平或公司的行业。表10.1还显示了列出的项目的数据类型。
- en: Table 10.1 Examples of demographic and firmographic data
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.1 人口统计和企业统计数据示例
- en: '| Demographic | Firmographic | Data type |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 人口统计 | 企业统计 | 数据类型 |'
- en: '| Date of birth | Founding date | Date |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 出生日期 | 成立日期 | 日期 |'
- en: '| Sales channel | Sales channel | String |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 销售渠道 | 销售渠道 | 字符串 |'
- en: '| Place of residence | Company domicile or geography | String |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 居住地 | 公司注册地或地理 | 字符串 |'
- en: '| Occupation | Industry or vertical | String |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 职业 | 行业或垂直领域 | 字符串 |'
- en: '| Hardware and OS information | Technology stack information | String |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 硬件和操作系统信息 | 技术堆栈信息 | 字符串 |'
- en: '| Number of household members | Number of employees | Number |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 家庭成员数量 | 员工数量 | 数量 |'
- en: '| Education level attained | Company stage (start-up, funding round, or public)
    | String |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 达到的教育水平 | 公司阶段（初创公司、融资轮次或上市） | 字符串 |'
- en: '| Gender | B2B or B2C business model | String |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 性别 | B2B或B2C商业模式 | 字符串 |'
- en: In principle, there isn’t much difference between using demographic facts and
    metrics to understand churn and segment customers.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 原则上，使用人口统计数据和指标来理解客户流失和细分客户之间没有太大的区别。
- en: TAKEAWAY To understand churn and form customer segments with demographic data,
    you form cohorts of customers based on the values of the demographic fields and
    compare the churn rates in each cohort.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**总结**：为了理解客户流失并基于人口统计数据形成客户细分，您根据人口字段值形成客户群组，并比较每个客户群组的流失率。'
- en: The non-numeric types are the reason why separate techniques are needed for
    demographic and firmographic data in comparison with metrics. If you are looking
    at numeric demographic data, the technique is the same as for metrics except for
    where the data comes from.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 非数值类型是相对于指标而言，在人口统计数据和公司统计数据中需要单独技术的原因。如果您正在查看数值人口统计数据，技术与方法相同，只是数据来源不同。
- en: 10.1.2 Account data model for the social network simulation
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**10.1.2 社交网络模拟的账户数据模型**'
- en: 'Because demographic data is tied to each account and rarely changes, it is
    standard to store it in a single database table indexed by account ID, as shown
    in table 10.2\. Table 10.2 includes some of the demographic fields that are part
    of the social network simulation:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 由于人口统计数据与每个账户相关联且很少改变，因此将其存储在单个数据库表中是标准的，该表按账户ID索引，如图表10.2所示。图表10.2包括一些属于社交网络模拟的人口字段：
- en: 'Channel (short for the sales channel) —The sales channel refers to how the
    customer found the product and signed up. All users sign up through one method,
    so the channel is a required field with no null values in the social network simulation.
    In the simulated social network dataset, the different sales channels are as follows:'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**渠道**（简称销售渠道）——销售渠道指的是客户如何找到产品并注册。所有用户都通过一种方法注册，因此渠道是一个必填字段，在社交网络模拟中没有空值。在模拟的社交网络数据集中，不同的销售渠道如下：'
- en: App store 1
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**应用商店1**'
- en: App store 2
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**应用商店2**'
- en: Web sign-up
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网络注册**'
- en: Date of birth —Many products require a customer to enter their date of birth
    as a statement that they are of (or older than) the minimum age to use the product.
    Because all users are required to enter something, the date of birth is a required
    field with no null values for the social network simulation.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**出生日期**——许多产品要求客户输入他们的出生日期作为他们达到（或超过）使用产品最低年龄的声明。因为所有用户都被要求输入某些信息，所以出生日期是一个必填字段，在社交网络模拟中没有空值。'
- en: Country —The country in which the user lives can often be derived from the user’s
    payment information or their localization choices in the software. In the social
    network simulation, users come from more than 20 countries, which are represented
    by two-character codes (from the International Standards Organization ISO 3166-1
    alpha-2 standard). For the social network simulation, the country field can include
    missing values (null values in the database). It is assumed that this setting
    is an optional setting; some users don’t bother to set it.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**国家**——用户的居住国家通常可以从用户的支付信息或他们在软件中的本地化选择中推导出来。在社交网络模拟中，用户来自20多个国家，这些国家由两位字符代码表示（来自国际标准化组织ISO
    3166-1 alpha-2标准）。对于社交网络模拟，国家字段可以包含缺失值（数据库中的空值）。假设这是一个可选设置；一些用户懒得设置它。'
- en: These three fields represent the minimal set necessary to demonstrate the techniques
    in this chapter. In a real product, there probably would be more fields, although
    the number varies considerably by product area. Many B2B companies know a great
    deal about their customers, but demographics can be sparse for consumer products
    with minimal sign-up requirements.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这些三个字段代表展示本章技术所需的最低集合。在实际产品中，可能存在更多字段，尽管这些字段的数目因产品领域而异。许多B2B公司对其客户了解很多，但对于需要最少注册要求的消费产品，人口统计数据可能很稀疏。
- en: Table 10.2 Typical account data schema *(continued)*
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**表10.2 典型账户数据模式（续**）'
- en: '| Column | Type | Notes |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 列 | 类型 | 备注 |'
- en: '| `account_id` | `integer` or `char` | The account ID linking to subscriptions,
    events, and metrics |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| `account_id` | `integer` 或 `char` | 连接到订阅、事件和指标的账户ID |'
- en: '| `channel` | `char` | The channel through which the customer purchased the
    app |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| `channel` | `char` | 客户购买应用的渠道 |'
- en: '| `date_of_birth` | `date` | The birthdate entered by the customer for age
    verification when they signed up |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| `date_of_birth` | `date` | 客户在注册时输入的用于年龄验证的出生日期 |'
- en: '| `country` | `char` | The country in which the user lives, represented by
    a two-character string |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| `country` | `char` | 用户居住的国家，由两个字符字符串表示 |'
- en: '| `...` | `...` | ... |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| `...` | `...` | ... |'
- en: '| `optional fields` | `char`, `float`, `int`, or `date` | Optional; platform
    specific |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| `optional fields` | `char`, `float`, `int`, 或 `date` | 可选；平台特定 |'
- en: In the rest of this section, I’ll show you how to put the data in such a schema
    to work fighting churn.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的其余部分，我将向您展示如何将数据放入这样的模式中，以便用于对抗流失。
- en: 10.1.3 Demographic dataset SQL
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.3 人口统计数据集SQL
- en: Given a schema of demographic data keyed by the account ID, the first step is
    exporting it from the database along with the dataset you usually create for the
    metrics. This way, you reuse all the existing code you have, showing when accounts
    renew and who has churned. Also, you will eventually combine the demographic data
    with the metrics in a single forecasting model, and by exporting the metrics and
    demographic fields together, you start with everything you are going to need.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个以账户ID为键的人口统计数据模式，第一步是从数据库中导出它以及您通常为指标创建的数据集。这样，您可以重用所有现有的代码，显示账户何时续订以及谁已经流失。此外，您最终会将人口统计数据与指标合并到一个单一预测模型中，通过一起导出指标和人口统计字段，您将拥有所有需要的东西。
- en: Figure 10.1 shows a typical result of such a data extraction. As in the dataset
    you have used since chapter 4, each row starts with the account ID, the observation
    date, and the churn indicator. The demographic fields come after those fields
    and before the metrics.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1显示了此类数据提取的典型结果。与自第4章以来使用的数据集一样，每一行都以账户ID、观察日期和流失指标开始。人口统计字段在这些字段之后和指标之前。
- en: '![](../Images/10-01.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/10-01.png)'
- en: Figure 10.1 Social network simulation dataset with demographic fields (result
    of listing 10.1)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1 社交网络模拟数据集，包含人口统计字段（列表10.1的结果）
- en: 'Listing 10.1 shows the SQL statement that creates a dataset like the one shown
    in figure 10.1\. Instead of the date_of_birth field, which was in the database,
    the dataset contains a field called customer_age. The one new technique listing
    10.1 introduces is the conversion of the date field for the birthdate to a time
    interval in years: the customer’s age.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.1显示了创建类似于图10.1所示的数据集的SQL语句。与数据库中的date_of_birth字段不同，数据集包含一个名为customer_age的字段。列表10.1介绍的新技术是将出生日期的日期字段转换为年数的时间间隔：客户的年龄。
- en: TAKEAWAY You convert demographic date fields to time intervals because then
    the numeric interval can be used for customer analysis and segmentation in the
    same way as a metric.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**要点**：您将人口统计数据字段转换为时间间隔，因为这样数字间隔就可以像指标一样用于客户分析和细分。'
- en: 'At a high level, the conversion is accomplished by subtracting the demographic
    date from the observation date, or vice versa:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在高层次上，转换是通过从观察日期减去人口统计数据或反之亦然来完成的：
- en: When the demographic date is in the past (such as a birthdate), you subtract
    the demographic date from the observation date, and the result is a positive interval
    representing the time since the demographic field at the time of the observation.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当人口统计数据在过去（例如出生日期）时，您从观察日期中减去人口统计数据，结果是表示观察时人口统计字段时间的正间隔。
- en: If the demographic date is in the future (such as the day of college graduation),
    subtract the observation date from the future date to keep the interval positive.
    Then the interval represents the time from the observation date until the date
    from the demographic data.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果人口统计数据在未来（例如大学毕业日）时，从观察日期减去未来日期以保持间隔为正。然后间隔表示从观察日期到人口统计数据日期的时间。
- en: Because the birthdate is in the past, listing 10.1 subtracts the birthdate from
    the observation date to get the customer’s age. In PostgreSQL, the interval is
    converted to an age in years by using the `date_part` function with the `'days'`
    parameter to get the interval length in days and then dividing by 365 (taking
    care with type conversions).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 由于出生日期在过去的日期中，列表10.1从观察日期中减去出生日期以获取客户的年龄。在PostgreSQL中，通过使用带有`'days'`参数的`date_part`函数将间隔转换为年，以获取天数间隔，然后除以365（注意类型转换）。
- en: Listing 10.1 Exporting a dataset with demographic data fields
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.1：导出包含人口统计数据字段的数据集
- en: '[PRE0]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ① Most of this listing is the same as listings 7.2 and 4.5.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ① 本列表的大部分内容与列表7.2和4.5相同。
- en: ② The channel string from the account table
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ② 从账户表中获取渠道字符串
- en: ③ The country string from the account table
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 从账户表中获取国家字符串
- en: ④ Subtracts the date of birth from the observation date
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 从观察日期中减去出生日期
- en: ⑤ JOINs with the account table
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 与账户表连接
- en: ⑥ Includes the demographic fields in the GROUP BY clause
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 在GROUP BY子句中包含人口统计数据字段
- en: 'Most of listing 10.1 is the same as the previous listings you’ve used to extract
    a dataset: observation dates are selected from the observation table and joined
    with metrics by using an aggregation to flatten the data. The other new aspects
    of listing 10.1 follow:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.1的大部分内容与您之前用于提取数据集的列表相同：从观察表中选择观察日期，并通过聚合与度量指标连接，以简化数据。列表10.1的其他新方面如下：
- en: The query makes an `INNER` `JOIN` on the account table (table 10.1) to select
    the fields for the channel, country, and date of birth.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询在账户表（表10.1）上执行一个`INNER` `JOIN`，以选择渠道、国家和出生日期的字段。
- en: Because these demographic fields are one per account in the account table, there
    is no need to aggregate these fields. Instead, the demographic fields are included
    in the `GROUP` `BY` clause.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于这些人口统计数据字段在账户表中每个账户只有一个，因此不需要对这些字段进行聚合。相反，人口统计数据字段包含在`GROUP` `BY`子句中。
- en: You should run listing 10.1 on the social network simulation to create the dataset
    that will be used throughout the rest of the chapter. Assuming that you are using
    the Python wrapper program to run the listings, the command is
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该在社交网络模拟上运行列表10.1以创建本章其余部分将使用的数据集。假设您正在使用Python包装程序运行列表，则命令是
- en: '[PRE1]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The result of listing 10.1 (saved in the output directory) should appear similar
    to figure 10.1 at the start of this section.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.1的结果（保存在输出目录中）应类似于本节开头图10.1。
- en: Tracking demographic and firmographic data changes and avoiding lookahead biases
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪人口统计数据和公司统计数据变化以及避免前瞻性偏差
- en: 'In this section, I describe storing demographic data as a single, unchanging
    value. But not all demographic or firmographic fields are truly unchanging: people
    and companies can move, companies can achieve new stages of development, people
    can achieve higher levels of education, and so on. To model such changes better,
    some companies track demographic data in a time-sensitive manner, either by adding
    effective-date timestamps to the account table or by tracking demographic fields
    in separate tables from the account itself (known as slowly changing dimensions
    in data warehouse terminology). Because these more advanced methods are not common,
    I don’t cover them in this book. If that situation is your situation, listing
    10.1 is modified to join the demographic data effective dates to the observation
    date.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我描述了将人口统计数据存储为单个、不变的值。但并非所有的人口统计数据或公司统计数据都是真正不变的：人们和公司可能会搬家，公司可能会达到新的发展阶段，人们可能会达到更高的教育水平，等等。为了更好地模拟这些变化，一些公司以时间敏感的方式跟踪人口统计数据，要么通过在账户表中添加有效日期戳，要么通过在账户本身之外跟踪人口统计数据字段（在数据仓库术语中称为缓慢变化维度）。由于这些更高级的方法并不常见，我在本书中不涉及它们。如果这种情况是您的情况，列表10.1被修改为将人口统计数据的有效日期与观察日期连接起来。
- en: The reason why the more complicated approach can be advantageous is that in
    some scenarios, treating demographic fields as static when they are not can result
    in a kind of lookahead bias in predicting churn using the demographic field. You
    see something about a customer in your historical dataset paired with a churn
    or renewal status in the past, but in a nonhistorical context (at the time of
    the observation timestamp), you would not have known that information. To make
    an example from firmographics, consider the company stage at a start-up or public
    company. Start-ups that go public must be successful and are less likely to go
    out of business and churn. If the data includes start-ups that went public in
    the past, the firmographic data identifies them as public companies because that
    was the current status when you created the dataset. But only successful start-ups
    go public, so the data becomes biased.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 更复杂的方法之所以可能具有优势，是因为在某些情况下，当种群字段不是静态的时将其视为静态，可能会导致使用种群字段预测客户流失时出现一种前瞻性偏差。你会在历史数据集中看到有关客户的一些信息，并配以过去流失或续订的状态，但在非历史背景下（在观察时间戳时），你不会知道这些信息。为了举例说明，从公司人口统计学的角度来看，考虑初创公司或上市公司的公司阶段。上市的公司必须成功，不太可能倒闭和流失。如果数据包括过去上市的公司，公司人口统计数据会将其识别为上市公司，因为当你创建数据集时，这是当前的状态。但只有成功的初创公司才会上市，因此数据变得有偏见。
- en: Such a bias can also confer unrealistic forecasting accuracy to a model. That
    said, this type of scenario is usually a second-order effect, which justifies
    the usual practice of ignoring the time-changing component of demographic and
    firmographic data.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这种偏差也可能给模型带来不切实际的预测准确性。话虽如此，这类场景通常是一个二级效应，这为通常忽略种群和公司人口统计数据的时间变化成分的做法提供了理由。
- en: 10.2 Churn cohorts with demographic and firmographic categories
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.2 带有种群和公司人口统计类别的流失群体
- en: 'Now that you’ve got a dataset with demographic data, you will compare the demographic
    cohorts by their churn rates to see how the demographic data is related to churn.
    At the start of the chapter, I told you that there are three types of demographics
    fields: dates, numbers, and strings. Earlier, I showed you that you should convert
    the dates to numeric intervals. In the cohort analysis, there are only two types:
    numbers and strings.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经拥有了一个包含种群数据的数据集，你将通过比较种群群体的流失率来查看种群数据与流失之间的关系。在章节开始时，我告诉你有三种类型的种群字段：日期、数字和字符串。之前，我展示了你应该将日期转换为数值区间。在群体分析中，只有两种类型：数字和字符串。
- en: Churn cohort analysis with numeric demographic data is exactly the same as cohorts
    based on metrics, as I will show briefly in section 10.4\. This section is about
    the new subject of comparing churn rates in cohorts by using demographic information
    described by strings.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 使用数值种群数据的流失群体分析与基于指标的群体分析完全相同，我将在第10.4节简要展示。这一节是关于新主题，即通过使用由字符串描述的种群信息来比较群体中的流失率。
- en: 10.2.1 Churn rate cohorts for demographic categories
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.1 种群类别的流失率群体
- en: The section is about demographic categories, so I start with a definition.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这一节是关于种群类别的，所以我从定义开始。
- en: DEFINITION For the purposes of this book, a category is one possible value of
    a demographic field described by a string.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 定义：在本书中，类别是指由字符串描述的种群字段的一个可能值。
- en: In the social network simulation, the categories associated with the channel
    field are appstore1, appstore2, and web. The categories associated with the country
    field are two-character codes such as BR, CA, and CN. It is possible for a value
    to be missing in a demographic field, so you can consider no value (null in the
    database) to be one additional category for every field.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在社交网络模拟中，与频道字段关联的类别是appstore1、appstore2和web。与国家字段关联的类别是两位字符代码，例如BR、CA和CN。在种群字段中可能缺少一个值，因此你可以认为每个字段没有值（数据库中的null）是一个额外的类别。
- en: NOTE For each demographic field, a customer can belong to only one category
    or have no value as a category.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：对于每个种群字段，客户只能属于一个类别，或者没有类别值。
- en: 'In principle, churn cohort analysis for demographic categories is simple: define
    a cohort with each category, and calculate the churn rates. But there are important
    differences between cohorts made from categories and cohorts made from metrics.
    As a result, you need to be more careful in how you compare the churn rates in
    cohorts defined by categories. Following are some important differences between
    cohorts based on metrics and cohorts based on categories:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 原则上，根据人口统计类别进行的流失率群体分析很简单：为每个类别定义一个群体，并计算流失率。但是，由类别和指标构成的群体之间存在重要的差异。因此，在比较由类别定义的群体的流失率时，你需要更加小心。以下是基于指标和基于类别的群体之间的一些重要差异：
- en: With metrics, the cohorts have a natural order given by the metrics. In most
    cases, categories do not have a meaningful order. Category-based cohorts, therefore,
    are harder to interpret because you cannot use the trend you see across categories
    as a guide for interpreting the differences in the churn rates.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于指标，群体有一个由指标给出的自然顺序。在大多数情况下，类别没有有意义的顺序。因此，基于类别的群体更难解释，因为你不能将你在类别间看到的趋势用作解释流失率差异的指南。
- en: For metrics of product use, you have natural expectations, such as “More use
    leads to lower churn” and “More cost for use leads to higher churn.” But there
    is no obvious expectation with categories.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于产品使用指标，你有自然的预期，例如“使用越多，流失率越低”和“使用成本越高，流失率越高”。但对于类别来说，没有明显的预期。
- en: When you define metric cohorts, you guarantee that each cohort has a significant
    portion of the observations—typically, 10% or more. With category-based cohorts,
    there is no guarantee of the minimum or maximum percentage of the data that might
    be captured in each cohort.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你定义指标群体时，你保证每个群体都有显著的观测值比例——通常是10%或更多。而对于基于类别的群体，没有保证每个群体中可能捕获的数据的最小或最大百分比。
- en: Based on my own experience, cohorts from demographics have weaker relationships
    to churn than cohorts based on product-use metrics.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我的经验，基于人口统计的群体与基于产品使用指标的群体相比，与流失率的关系较弱。
- en: TAKEAWAY You must be more careful making comparisons of churn rates in cohorts
    based on demographic categories than in cohorts based on metrics.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**总结**：在根据人口统计类别对群体进行流失率比较时，你必须比根据指标对群体进行流失率比较时更加小心。'
- en: By careful, I mean that you need to rely on strong evidence to make sure that
    the difference is significant. For that reason, you will use a new technique known
    as confidence intervals to make the comparison.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 当我说“小心”时，我的意思是你需要依赖强有力的证据来确保差异是显著的。因此，你将使用一种称为置信区间的新的技术来进行比较。
- en: 10.2.2 Churn rate confidence intervals
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.2 流失率置信区间
- en: To be more careful with churn rate comparisons between demographic cohorts,
    you should not simply calculate the churn rates in each cohort; you should also
    estimate best- and worst-case scenario churn rates in each cohort. This process
    is known as calculating confidence intervals.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在人口统计群体之间更小心地进行流失率比较，你不仅应该计算每个群体的流失率；你还应该估计每个群体的最佳和最坏情况下的流失率。这个过程被称为计算置信区间。
- en: DEFINITION Confidence intervals for a metric like the churn rate are the range
    from the best-case (lowest) estimate of the churn rate to the worst-case (highest)
    estimate for the churn rate.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义**：对于像流失率这样的指标，置信区间是从流失率最佳（最低）估计到最坏（最高）估计的范围。'
- en: 'Understanding confidence intervals starts with realizing that the churn rate
    you calculate on your customers is not the churn rate you want to measure. Consider
    the following:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 理解置信区间首先需要认识到你在客户上计算的流失率并不是你想要测量的流失率。考虑以下情况：
- en: What you want to know is what the churn rate would be on all the possible customers
    in the world who would match your cohort demographic category. That estimate would
    be the best estimate of future churn for that type of customer.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你想知道的是，在所有可能的、符合你群体人口统计类别的客户中，流失率会是多少。这个估计将是该类型客户未来流失的最佳估计。
- en: You can measure only the churn rate you have seen for the customers you have
    had.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你只能测量你看到过流失率的客户。
- en: 'This scenario is illustrated in figure 10.2\. You can’t be sure that the churn
    rate you have seen in past customers is what the churn rate is going to be for
    future customers. You may see a different churn rate in the future. Maybe you
    got lucky in the past and got better-than-average customers, or maybe the opposite
    is true; you never know. But you can expect two things:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况在图10.2中得到了说明。你不能确定你在过去客户中看到的流失率就是未来客户的流失率。你可能在将来看到不同的流失率。也许你在过去很幸运，得到了比平均水平更好的客户，或者情况可能正好相反；你永远不知道。但你可以期待以下两点：
- en: The churn rate you would see in the full universe of customers should be close
    to what you have seen in the past, assuming that you observed a reasonable number
    of customers in each cohort.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在整个客户群体中，你将看到的流失率应该接近你在过去看到的，假设你在每个群体中观察到了合理的客户数量。
- en: The more customers you see, the closer the churn rate you have seen in the past
    should be to the churn rate in the entire universe. Put another way, the more
    customers you see, the less uncertainty exists about the range of possible churn
    rates for the universe.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你看到的客户越多，你过去看到的流失率应该越接近整个群体的流失率。换句话说，你看到的客户越多，关于整个群体可能流失率范围的不确定性就越小。
- en: For this reason, people usually talk about confidence intervals as the range
    around the measured churn rate, which is known to be near the center of the best-
    and worst-case scenarios (but, as you will see, not necessarily at the center).
    To describe the measured churn and the best-case and worst-case estimates, we’ll
    use the following definitions.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，人们通常将置信区间视为围绕测量出的流失率的范围，这个范围被认为是最佳和最坏情况场景的中心附近（但，正如你将看到的，不一定在中心）。为了描述测量出的流失率以及最佳和最坏情况的估计，我们将使用以下定义。
- en: DEFINITION The measured churn rate on past customers is referred to as the expected
    value, and it is considered to be the most likely value for the universal churn
    rate. The upper confidence interval is the range from the expected churn rate
    to the worst-case estimate, described by the size of that range, or the worst-case
    churn minus the expected churn. The lower confidence interval is the range from
    the best-case estimate to the expected churn, described by the size of that range,
    or the expected churn minus the worst-case estimate.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 定义：过去客户的测量流失率被称为期望值，它被认为是普遍流失率最可能的价值。上限置信区间是从期望流失率到最坏情况估计的范围，该范围由该范围的大小或最坏情况流失率减去期望流失率来描述。下限置信区间是从最佳情况估计到期望流失率的范围，该范围由该范围的大小或期望流失率减去最坏情况估计来描述。
- en: Figure 10.2 illustrates the differences among the universal churn rate, your
    estimate, and the upper and lower confidence intervals for the estimate.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2展示了普遍流失率、你的估计以及估计的上限和下限置信区间的差异。
- en: '![](../Images/10-02.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/10-02.png)'
- en: Figure 10.2 Confidence intervals assess best- and worst-case scenarios.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2 置信区间评估最佳和最坏情况场景。
- en: 'I said the churn rate in each cohort should be close to the universal churn
    rate for such customers, assuming that you observed enough of them. How many is
    enough was discussed at length in chapter 5: ideally, you want to observe thousands
    of customers in each category, but hundreds may be enough.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我说每个群体的流失率应该接近这类客户的普遍流失率，假设你已经观察到了足够多的这类客户。多少算是足够，在第五章中进行了详细讨论：理想情况下，你希望观察每个类别的数千名客户，但数百名可能就足够了。
- en: When you use confidence intervals, the number of customers you use translates
    to the size of the confidence intervals. The more customers you measure the churn
    on, the narrower is the range of uncertainty around the churn rate. In section
    10.2.3, you will learn how to calculate confidence intervals and compare them.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 当你使用置信区间时，你所使用的客户数量将转化为置信区间的宽度。你测量的客户越多，围绕流失率的范围就越窄。在第10.2.3节中，你将学习如何计算置信区间并进行比较。
- en: TAKEAWAY Because you can’t calculate the universal churn rate measurement, you
    will instead calculate best- and worst-case estimates for the universal churn
    rate, given the available data.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 吸收要点：因为你不能计算普遍流失率的测量值，所以你将根据可用的数据计算普遍流失率的最佳和最坏情况估计。
- en: 10.2.3 Comparing demographic cohorts with confidence intervals
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.3 使用置信区间比较人口统计群体
- en: 'Figure 10.3 shows an example of comparing demographic cohorts with confidence
    intervals, which is the result for the channel category in the social network
    simulation. The basic idea is the same as the metric cohort plots you saw in earlier
    chapters, but there are a few significant differences:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3展示了使用置信区间比较人口群体示例，这是社交网络模拟中渠道类别的结果。基本思想与你在前几章中看到的度量群体图相同，但有一些显著的不同：
- en: The data is displayed in a bar chart instead of a line chart. The churn rate
    in each cohort is shown by the height of each bar.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据以柱状图的形式显示，而不是折线图。每个群体的流失率通过每个柱子的高度来表示。
- en: Each bar has a pair of lines above and below the main bar, showing the extent
    of the confidence intervals. The lines showing the confidence intervals in a plot
    are often known as error bars or whiskers.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个柱子上方和下方都有两条线，表示置信区间的范围。在图中表示置信区间的线通常被称为误差线或触须。
- en: The x-axis still identifies the cohort, but now it is a string label showing
    the category that the cohort represents.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: x轴仍然标识着群体，但现在它是一个字符串标签，显示该群体代表的类别。
- en: '![](../Images/10-03.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/10-03.png)'
- en: Figure 10.3 Channel churn rates with confidence intervals (output of listing
    10.2)
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3带有置信区间的渠道流失率（列表10.2的输出）
- en: In the category cohort plot, you are looking at not only the expected universal
    churn rates but also the best- and worst-case estimates, so you should use the
    confidence intervals as a guide to compare the significance of the difference
    between the category churn rates. This technique is known as statistical significance.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在类别群体图中，你不仅可以看到预期的普遍流失率，还可以看到最佳和最坏情况的估计，因此你应该使用置信区间作为比较类别流失率差异重要性的指南。这种技术被称为统计显著性。
- en: DEFINITION The difference between the churn rates in two different categories
    is statistically significant if the best-case churn rate (lower confidence interval)
    for one category is greater than the worst-case churn rate (upper confidence interval)
    for the other category. In that case, the two confidence intervals do not overlap.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 定义：如果某个类别的最佳流失率（下置信区间）大于另一个类别的最坏流失率（上置信区间），则两个不同类别之间的流失率差异在统计学上具有显著性。在这种情况下，两个置信区间不会重叠。
- en: Considering figure 10.3, you would say that the difference between the churn
    rates for the appstore1 and appstore2 categories is statistically significant
    because the confidence intervals are far apart. The worst-case churn rate for
    appstore2 is around 3.5%, and the best-case churn rate for appstore1 is around
    4.5%, so the two are not touching.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到图10.3，你会说appstore1和appstore2类别之间的流失率差异在统计学上具有显著性，因为置信区间相距甚远。appstore2的最坏情况流失率约为3.5%，而appstore1的最佳情况流失率约为4.5%，因此两者没有接触。
- en: But the difference between the churn rates for the appstore1 and the web customers
    is on the borderline for statistical significance because the confidence intervals
    are practically touching. The best-case churn for the web channel is around 5.4%,
    and the worst-case churn for appstore1 is also around 5.4%. According to a strict
    definition, you might say that the difference is not statistically significant.
    But in practice, statistical significance is not applied as a hard rule. If you
    have some reason to think that a difference is significant, you might still act
    on a difference in churn rates when there is a little overlap in the confidence
    intervals. In this case, I would say the fact that appstore2 is so different lends
    credibility to differences between the channels and, by extension, the differences
    between web and appstore1\. As you will see in figure 10.4, the confidence intervals
    for the web and appstore2 churn rates are not touching by just 0.02%, which you
    can’t tell in the figure. But whether confidence intervals overlap or don’t by
    such a small amount shouldn’t make a difference in your interpretation.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 但appstore1和网站客户之间的流失率差异在统计学上处于边缘，因为置信区间几乎接触。网站渠道的最佳流失率约为5.4%，而appstore1的最坏流失率也约为5.4%。根据严格的定义，你可能会说这种差异在统计学上并不显著。但在实践中，统计显著性并不是一条硬性规则。如果你有理由认为差异是显著的，即使置信区间有轻微的重叠，你仍然可以采取行动来处理流失率的变化。在这种情况下，我会说appstore2如此不同的事实使得渠道之间的差异以及由此产生的网站和appstore1之间的差异更具可信度。正如你将在图10.4中看到的，网站和appstore2的流失率置信区间仅相差0.02%，这在图中是看不出来的。但置信区间是否重叠或仅以如此小的幅度不重叠，不应影响你的解释。
- en: TAKEAWAY In practice, whether a difference in churn rates is statistically significant
    or not is not black and white when the edges of the confidence intervals are nearly
    touching or overlap a little bit.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: TAKEAWAY 在实践中，当置信区间的边缘几乎接触或略有重叠时，流失率差异是否具有统计学意义并不是非黑即白。
- en: 'Listing 10.2 shows the code that produces figure 10.3\. Listing 10.2 consists
    of a main function, `category_churn_cohorts`, that calls three helper functions:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.2显示了生成图10.3的代码。列表10.2由一个主函数`category_churn_cohorts`组成，该函数调用三个辅助函数：
- en: '`prepare_category_data`—Loads the data and fills any missing categories with
    the string `''-na-''`. This string clearly marks any customers that are missing
    a category.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prepare_category_data`—加载数据，并用字符串`''-na-''`填充任何缺失的类别。这个字符串清楚地标记了任何缺失类别的客户。'
- en: '`category_churn_summary`—Calculates the churn rates and the confidence intervals
    and puts all the results in a `DataFrame`, which is saved as a .csv file. (Details
    on the calculation follow the listing.)'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`category_churn_summary`—计算流失率及其置信区间，并将所有结果放入一个`DataFrame`中，该`DataFrame`保存为.csv文件。（计算细节见下文。）'
- en: '`category_churn_plot`—Plots the results in a bar chart, showing the confidence
    intervals and adding annotations. Confidence intervals are added by setting the
    `yerr` param of the bar function, which stands for *y* error bar.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`category_churn_plot`—以条形图的形式绘制结果，显示置信区间并添加注释。通过设置条形函数的`yerr`参数添加置信区间，该参数代表*y*误差条。'
- en: Listing 10.2 Analyzing category churn rates with confidence intervals
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.2 使用置信区间分析类别流失率
- en: '[PRE2]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ① Main function for the category analysis and plot
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ① 主函数用于类别分析和绘图
- en: ② Helper function prepare_category_data reads the dataset.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ② 辅助函数`prepare_category_data`读取数据集。
- en: ③ Calls category_ churn_summary to perform the analysis
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 调用`category_churn_summary`进行数据分析
- en: ④ Calls category_ churn_plot to make the plot
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 调用`category_churn_plot`来制作图表
- en: ⑤ Fills any missing values with a string '-na-'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 用字符串`'-na-'`填充任何缺失值
- en: ⑥ Uses category_churn_ summary to analyze the categories
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 使用`category_churn_summary`分析类别
- en: ⑦ Uses the Pandas aggregation function to group data by the category
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: ⑦ 使用Pandas聚合函数按类别分组数据
- en: ⑧ Calculates the confidence intervals
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: ⑧ 计算置信区间
- en: ⑨ Divides the category count by the total number of rows
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: ⑨ 将类别计数除以总行数
- en: ⑩ Copies the results into the summary DataFrame
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: ⑩ 将结果复制到摘要DataFrame中
- en: ⑪ Lower confidence interval = mean minus lower confidence bound
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: ⑪ 下置信区间 = 均值 - 下置信界限
- en: ⑫ Upper confidence interval = upper confidence minus mean
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: ⑫ 上置信区间 = 上置信度 - 均值
- en: ⑬ Saves the result
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: ⑬ 保存结果
- en: ⑭ Uses category_churn_plot to plot the result
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ⑭ 使用`category_churn_plot`来绘制结果
- en: ⑮ Scales the size of the plot based on the number of categories
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ⑮ 根据类别数量调整图表大小
- en: ⑯ The percentage of churns is the bar height.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ⑯ 流失率百分比是条形的高度。
- en: ⑰ The Y error bar is given by confidence intervals.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ⑰ Y误差条由置信区间给出。
- en: ⑱ Annotates the figure and saves it
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: ⑱ 注释图表并保存
- en: You should run the Python wrapper program to produce your own plot like figure
    10.3 for the simulated dataset. The command and its arguments to the wrapper program
    are
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该运行Python包装程序来生成自己的图表，如图10.3所示，对于模拟数据集。包装程序的命令及其参数如下
- en: '[PRE3]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Turning to the details of the calculation of the cohort churn rates in listing
    10.2, the average churn rate is calculated in the `category_churn_summary` function,
    using the Pandas `DataFrame` `groupby` and `agg` functions:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表10.2中转向队列流失率计算的细节，平均流失率是在`category_churn_summary`函数中计算的，使用Pandas的`DataFrame`
    `groupby`和`agg`函数：
- en: '[PRE4]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The following breaks down the details of this dense line:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是对这一密集行细节的分解：
- en: The `groupby` function is called with the category as the grouping variable.
    The result of this function is a specialized `DataFrameGroupBy` object that can
    be used to retrieve different results based on the grouping.
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`groupby`函数以类别作为分组变量被调用。此函数的结果是一个专门的`DataFrameGroupBy`对象，可以用来根据分组检索不同的结果。'
- en: 'After grouping, the desired measures are found by calling the aggregation function
    `agg` on `DataFrameGroupBy`. The results to be created by `DataFrameGroupBy` are
    specified in a dictionary where each dictionary key is a column to calculate aggregate
    functions and the value for the keys are one or more aggregate functions. In this
    case, you use the following:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在分组后，通过在`DataFrameGroupBy`上调用聚合函数`agg`来找到所需的度量。`DataFrameGroupBy`要创建的结果在字典中指定，其中每个字典键是要计算聚合函数的列，键的值是一个或多个聚合函数。在这种情况下，你使用以下内容：
- en: '[PRE5]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The first entry in the dictionary indicates that the column containing the category
    (the variable `cat_col`) should be aggregated with a count. For every category,
    show the number of rows in the dataset that had the category.
  id: totrans-160
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字典中的第一个条目表示包含类别（变量`cat_col`）的列应该通过计数进行聚合。对于每个类别，显示数据集中具有该类别的行数。
- en: The second entry in the dictionary indicates that the column containing the
    churn indicator should be aggregated by summing the number of churns and also
    calculating the mean, which results in the observed churn rate for the category.
  id: totrans-161
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字典中的第二个条目表示包含流失指标的列应该通过汇总流失数并计算均值进行聚合，这导致该类别的观察流失率。
- en: The result of the call to the function is a `DataFrame` with one row per category
    and columns containing the three aggregation results. The columns are labeled
    by tuples, combining the column and the aggregation. The column labeled `cat_col,'count'`
    contains the row count for the categories, for example, and the column labeled
    `'is_churn','mean'` contains the mean of the churn indicator, which is the churn
    rate.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 函数调用的结果是包含每类一行以及包含三个聚合结果的列的`DataFrame`。列通过元组标记，结合列和聚合。标记为`cat_col,'count'`的列包含类别的行数，例如，而标记为`'is_churn','mean'`的列包含流失指标的均值，即流失率。
- en: The function `category_churn_summary` in listing 10.2 uses the `statsmodels`
    module to calculate the confidence intervals. The function used is `statsmodels`.`stats`
    `.proportion.proportion_confint`, which is for calculating confidence intervals
    on measurements of percentages resulting from binary trials (which is what measuring
    churn rates amounts to, from a statistician’s point of view). The function `proportion`
    `_confint` takes as parameters the count in each category and the number of churn
    observations (passed by selection from the aggregation result `DataFrame` using
    the tuple labels I’ve described).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.2中的函数`category_churn_summary`使用`statsmodels`模块计算置信区间。使用的函数是`statsmodels`.`stats`
    `.proportion.proportion_confint`，用于计算二元试验（从统计学的角度来看，衡量流失率就是二元试验）的百分比测量结果的置信区间。`proportion_confint`函数将每个类别的计数和流失观察数（通过选择聚合结果的`DataFrame`中的元组标记来传递）作为参数。
- en: As mentioned early in the chapter, the number of observations and number of
    churns form the basis for calculation of the confidence intervals using statistics.
    The call to `proportion_confint` also passes the optional method parameter `method=`
    `'wilson'`. The Wilson method for calculating confidence intervals is the best
    choice for churn because it is known to produce the most accurate results when
    the proportion of events (in this case, churns) in the binary trials is small.
    I won’t go into details on how the Wilson method calculates confidence intervals,
    but there are many good resources online.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章开头所述，观察数和流失数是使用统计学计算置信区间的依据。调用`proportion_confint`时还传递了可选的方法参数`method=` `'wilson'`。计算置信区间的威尔逊方法对于流失率是最好的选择，因为它已知在二元试验（在这种情况下，流失）的事件比例较小时会产生最准确的结果。我不会详细介绍威尔逊方法如何计算置信区间，但网上有许多很好的资源。
- en: Figure 10.4 shows the data file output from the category churn cohort analysis
    with confidence intervals. This output contains all the information used to produce
    the channel cohort bar chart (figure 10.3) and more details. One important piece
    of information available in this file and not in the bar chart is the percentage
    of observations from each channel. Most organizations that acquire customers through
    different channels already have a good idea of the percentage of customers acquired
    through each channel. In such a case, you should compare the number in your dataset
    with the number measured by the sales department for quality assurance (to make
    sure that there are no problems in the data feed and so on).
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4显示了类别流失群体分析的数据文件输出，其中包含置信区间。此输出包含用于生成通道群体条形图（图10.3）和更多详细信息的所有信息。在此文件中可用而条形图中不可用的重要信息是每个通道的观察百分比。大多数通过不同渠道获取客户的组织已经对通过每个渠道获取的客户百分比有很好的了解。在这种情况下，您应该将数据集中的数字与销售部门为质量保证所测量的数字进行比较（以确保数据馈送没有问题等）。
- en: '![](../Images/10-04.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/10-04.png)'
- en: Figure 10.4 Data output of category churn cohorts for the channel field
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4 类别流失群体通道字段的数据输出
- en: The file output of listing 10.2 also shows the size of the low- and high-confidence
    intervals. In figure 10.4, you can see that the high interval is a little larger
    than the low interval. This asymmetry occurs because the churn probability is
    a small percentage. If the churn rate were 50%, the size of the confidence intervals
    would be symmetric.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.2的文件输出也显示了低置信区间和高置信区间的范围。在图10.4中，你可以看到高区间略大于低区间。这种不对称性是由于流失概率是一个小百分比。如果流失率为50%，置信区间的范围将是对称的。
- en: The other demographic field with categories in the simulated social network
    is the country. Figure 10.5 shows the churn cohort plot for the country categories.
    The churn cohort results for the country are different from the plot of the churn
    cohorts for the channel because there are many more countries. Because some of
    the countries have only a small percentage of the customers, some of the confidence
    intervals are large compared with the churn rates. In fact, as a result of the
    large confidence intervals, there are no statistically significant churn rate
    differences among the countries. All the confidence intervals in the country categories
    overlap the confidence intervals of the other categories by a large amount. (Figure
    10.5 shows no cases in which the confidence intervals overlap by a bit.)
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在模拟社交网络中，具有类别划分的另一个人口统计字段是国家。图10.5显示了国家类别的流失群体图。国家类别的流失群体结果与渠道的流失群体图不同，因为国家数量更多。由于一些国家只有很少一部分客户，因此一些置信区间的范围相对于流失率来说较大。实际上，由于置信区间较大，国家之间没有统计上显著的流失率差异。国家类别中的所有置信区间与其他类别的置信区间重叠很大。（图10.5没有显示置信区间略有重叠的案例。）
- en: '![](../Images/10-05.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/10-05.png)'
- en: Figure 10.5 Country cohort churn rates with confidence intervals (output of
    listing 9.2)
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5 国家群体流失率及置信区间（列表9.2的输出）
- en: 'Figure 10.6 displays the data file output for the country cohort churn analysis.
    It shows that most countries have less than 10% of the data and that some have
    as little as 1%. The countries with the smallest number of customer observations
    have the largest confidence intervals for the churn rate. SE had just 1% of the
    observations (236 observations), and with a measured churn of 5.9%, the lower
    end of the confidence interval is 3.6% and the upper end is 9.7%: a span of around
    6%. US, on the other hand, represents 15% of the observations (3,710 observations)
    with a similar observed churn rate of 5.3%, and the confidence intervals range
    from 4.7% to 6.1%—a span of only 1.5%.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.6显示了国家群体流失分析的数据文件输出。它显示大多数国家的数据不到10%，有些国家甚至只有1%。客户观察数量最少的国家，其流失率的置信区间最大。SE只有1%的观察值（236个观察值），测量的流失率为5.9%，置信区间的下限是3.6%，上限是9.7%，跨度大约为6%。另一方面，US代表了15%的观察值（3,710个观察值），观察到的流失率相似，为5.3%，置信区间从4.7%到6.1%，跨度仅为1.5%。
- en: '![](../Images/10-06.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/10-06.png)'
- en: Figure 10.6 Data output of category churn cohorts for the country field
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.6 国家字段类别流失群体的数据输出
- en: The results in figures 10.5 and 10.6 show that having too many categories is
    a problem for doing an effective churn cohort analysis. Section 10.3 teaches you
    a simple and effective way to deal with this problem.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5和10.6中的结果显示，拥有过多的类别会对进行有效的流失群体分析造成问题。第10.3节教你一种简单而有效的方法来处理这个问题。
- en: The significance level of the confidence intervals
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 置信区间的显著性水平
- en: 'The function `proportion_confint` has another parameter: the significance level,
    which I leave at the default value in my code. If you check the documentation
    for `proportion_confint`, you will find that the default significance level is
    0.05\. This parameter corresponds to what people call the 95% confidence level
    and represents the degree of certainty that the true universal churn rate is within
    the range defined by the best- and worst-case estimates.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 函数`proportion_confint`还有一个参数：显著性水平，我在代码中将其保留为默认值。如果你查看`proportion_confint`的文档，你会发现默认的显著性水平是0.05。此参数对应于人们所说的95%置信水平，表示真实总体流失率在最佳和最坏情况估计定义的范围内的不确定性程度。
- en: Like most things in statistics, the best- and worst-case churn rates are estimates,
    and the significance level determines the possibility that these estimates are
    also wrong. When people say “95% confidence,” they’re saying 100% minus this significance
    level. In other words, there is a 5% chance that the true universal churn rate
    is not within the stated bounds and a 95% chance that the universal churn rate
    is within the bounds.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 就像统计学中的大多数事情一样，最佳和最坏情况的流失率都是估计值，显著性水平决定了这些估计值也可能错误的可能性。当人们说“95%置信度”时，他们是在说100%减去这个显著性水平。换句话说，有5%的可能性，真实的普遍流失率不在所声明的界限内，有95%的可能性，普遍流失率在界限内。
- en: Lowering the significance-level parameter less than 0.05 results in larger confidence
    intervals, or a large difference between the best-case and worst-case estimates.
    If you use a lower significance level, it takes a larger difference between the
    churn rates for two categories to qualify as statistically significant (by having
    the confidence intervals that do not touch). On the other hand, a higher significance
    level (greater than 0.05) makes smaller confidence intervals, and it will be easier
    to say that differences are statistically significant, but you will be less sure
    that the universal churn rate for the category was within the stated bounds.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 将显著性水平参数降低到0.05以下会导致置信区间更大，或者最佳和最坏情况估计之间的差异更大。如果你使用较低的显著性水平，两个类别之间的流失率差异需要更大才能被视为具有统计学意义（通过置信区间不接触来实现）。另一方面，较高的显著性水平（大于0.05）会使置信区间更小，这将更容易说差异具有统计学意义，但你将不太确定该类别的普遍流失率是否在所声明的界限内。
- en: Choosing the significance level and interpreting confidence intervals is a controversial
    topic in statistics, and I’m trying to give you some simple best practices. My
    advice is to leave the significance parameter as the default. In principle, you
    should use a lower significance level for a demographic field that has a large
    number of categories (more than a few dozen). That way, you would apply more stringent
    criteria in determining which differences are significant.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 选择显著性水平和解释置信区间是统计学中的一个有争议的话题，我试图给你一些简单的最佳实践。我的建议是将显著性参数保留为默认值。原则上，你应该为具有大量类别（超过几十个）的人口统计字段使用较低的显著性水平。这样，你会在确定哪些差异是显著的时应用更严格的准则。
- en: 'In section 10.3, I will teach you another way of handling a large number of
    categories: grouping those that are less common. Overall my advice is to leave
    this parameter unchanged. I mention it here only because you might be asked what
    significance level you use to calculate the confidence intervals. (The answer
    is that you use the standard 0.05 significance level.)'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在第10.3节中，我将教你另一种处理大量类别的方法：将那些不太常见的类别分组。总的来说，我的建议是不要更改此参数。我之所以在这里提到它，是因为你可能被问及你使用什么显著性水平来计算置信区间。（答案是，你使用标准的0.05显著性水平。）
- en: 10.3 Grouping demographic categories
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.3 分组人口统计类别
- en: In section 10.2.3, I showed you that if you have a lot of categories, you run
    the risk that the number of observations in the rare categories will be too small
    to produce useful results. With few observations, the confidence intervals can
    become large, depending on the amount of data you have to work with. If you have
    millions of customers, you can have statistical significance for the results in
    even the rarest categories. Still, information overload can be a problem, and
    it can be desirable to look at fewer categories for that reason as well.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在第10.2.3节中，我向你展示了如果你有很多类别，你面临的风险是罕见类别中的观察数量可能太小，无法产生有用的结果。在观察数量较少的情况下，置信区间可能会变得很大，这取决于你可用于工作的数据量。如果你有数百万客户，你甚至可以对罕见类别中的结果具有统计学意义。尽管如此，信息过载也可能是一个问题，出于这个原因，查看较少的类别也可能是有利的。
- en: 10.3.1 Representing groups with a mapping dictionary
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.3.1 使用映射字典表示组
- en: The solution to the problem of having a lot of categories that represent small
    fractions of the data is grouping rare categories that are related. Countries
    can be grouped into regions, for example. Figure 10.7 illustrates mapping countries
    into regions by using a Python dictionary. The dictionary in figure 10.7 is literally
    a mapping from regions to lists of countries because that mapping is a more efficient
    way to express the relationship.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 解决具有大量类别且代表数据小部分的难题，可以通过分组相关罕见类别来实现。例如，可以将国家分组到地区。图10.7通过使用Python字典展示了如何将国家映射到地区。图10.7中的字典实际上是从地区到国家列表的映射，因为这种映射是表达这种关系的更有效方式。
- en: '![](../Images/10-07.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![图10.7](../Images/10-07.png)'
- en: Figure 10.7 Mapping group-simulated country categories into regions
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.7将分组模拟的国家类别映射到地区
- en: The code on which figure 10.7 is based is in the GitHub repository for this
    book, in the file fight-churn/listings/conf/socialnet_listings.json; look for
    the chapter 10 section and the key listing_10_3_grouped_category_cohorts. I’ll
    say more about how and why this particular mapping was chosen later, but for now,
    I will show you how this kind of grouping helps with the category cohort analysis.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 基于图10.7的代码位于本书的GitHub仓库中，位于文件fight-churn/listings/conf/socialnet_listings.json中；请查找第10章部分以及关键字listing_10_3_grouped_category_cohorts。我将在稍后详细介绍选择这种特定映射的原因，但现在，我将向您展示这种分组如何帮助进行类别群体分析。
- en: 10.3.2 Cohort analysis with grouped categories
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.3.2 分组类别群体分析
- en: Figure 10.8 shows the result of rerunning the cohort analysis based on regions
    instead of countries. As a result of the grouping, there are six categories. If
    you look at the data output that goes with the plot (not shown in the figure),
    you will see that every one of the new categories represents no less than 10%
    of the data; the smallest category is now the customers who do not have any country
    (`-na-`), which is 11%. As a result of the larger number of observations, the
    size of the confidence interval on every category in figure 10.8 is smaller than
    when the countries were separate (figure 10.5).
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.8显示了基于地区而不是国家重新运行群体分析的结果。由于分组，现在有六个类别。如果你查看与图表一起的数据输出（图中未显示），你会看到每个新类别代表的数据不少于10%；现在最小的类别是没有国家的客户（`-na-`），占11%。由于观察次数增加，图10.8中每个类别的置信区间大小比国家单独时（图10.5）更小。
- en: TAKEAWAY If your demographics include rare categories, you can simplify by grouping
    related categories. This approach reduces the churn rate confidence intervals
    and information overload.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '**要点** 如果你的人口统计数据包括罕见类别，可以通过分组相关类别来简化。这种方法可以减少流失率置信区间和信息过载。'
- en: Despite the smaller confidence intervals, figure 10.8 shows no statistically
    significant differences between the churn rates in any region. The confidence
    intervals around the churn rate in every region overlap significantly with all
    the others. The fact that there is no statistically significant difference in
    this simulated dataset doesn’t mean that you won’t find important relationships
    in your own product or service.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管置信区间较小，但图10.8显示在任何地区之间，流失率没有统计学上的显著差异。每个地区的流失率置信区间与其他所有置信区间显著重叠。在这个模拟数据集中没有统计学上的显著差异并不意味着你不会在自己的产品或服务中发现重要关系。
- en: '![](../Images/10-08.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![图10.8](../Images/10-08.png)'
- en: Figure 10.8 Churn cohorts for country categories grouped in regions
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.8展示了按地区分组的国家类别群体流失情况
- en: 'Listing 10.3 provides the code for performing the grouping and rerunning the
    category cohort analysis. This listing uses all the helper functions from the
    category cohort churn analysis (without grouping), and it adds only one new function
    to perform the grouping: `group_category_column`. This function has two main parts:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.3提供了执行分组和重新运行类别群体分析的代码。此列表使用类别群体流失分析的所有辅助函数（无分组），并添加了一个新函数来执行分组：`group_category_column`。此函数有两个主要部分：
- en: The first part inverts the mapping dictionary so that it is a mapping from country
    to region rather than from region to country. Inverting a dictionary can be done
    in a Python one-liner, using a double list comprehension. The first list comprehension
    iterates over the keys that were the regions, and the second list comprehension
    iterates over the values in each key, which were the countries. A dictionary mapping
    the old values to the old keys (country to region) is formed from the results.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一部分反转映射字典，使其成为从国家到地区的映射，而不是从地区到国家的映射。反转字典可以通过Python的单行表达式完成，使用双列表推导。第一个列表推导遍历曾是地区的键，第二个列表推导遍历每个键中的值，即国家。从结果中形成将旧值映射到旧键（国家到地区）的字典。
- en: After the mapping dictionary has been inverted, a new column is created in the
    `DataFrame`, using the `DataFrame` `apply` function. The `apply` function takes
    another function as a parameter, and that function is applied to all the elements
    in the column. In this case, the purpose is to look up the value in the inverted
    dictionary if one is present; otherwise, it returns the original value. The result
    of applying this function to the column is that every country that is part of
    one of the region groups will be mapped, and any country that is not will be copied
    as is. After this mapping, the code in listing 10.3 uses the analysis and plotting
    functions from listing 10.2, which did category cohort analysis on ungrouped categories.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在映射字典被反转后，使用`DataFrame`的`apply`函数在`DataFrame`中创建一个新的列。`apply`函数接受另一个函数作为参数，该函数应用于列中的所有元素。在这种情况下，目的是查找反转字典中的值（如果存在的话）；否则，返回原始值。将此函数应用于列的结果是，将映射到区域组中的每个国家，任何不属于的国家将按原样复制。在此映射之后，列表10.3中的代码使用了列表10.2中的分析和绘图函数，这些函数对未分组的类别进行了类别队列分析。
- en: The `group_category_column` function makes a name for the new column by prepending
    the word group to the original column name and dropping the original column from
    the result.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '`group_category_column`函数通过在原始列名称前添加单词group并为结果删除原始列来为新列命名。'
- en: Listing 10.3 Grouped category cohort analysis
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.3 分组类别队列分析
- en: '[PRE6]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ① This listing reuses the helper functions from listing 10.2.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: ① 此列表重新使用了列表10.2中的辅助函数。
- en: ② The main function is mostly the same as the regular category plot.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: ② 主函数大部分与常规类别图相同。
- en: ③ Calls helper function to map the category column to groups
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 调用辅助函数将类别列映射到组
- en: ④ Helper function from listing 10.2 analyzes the categories.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 列表10.2中的辅助函数分析类别。
- en: ⑤ This function maps the categories into groups with mapping dict.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 此函数使用映射字典将类别映射到组中。
- en: ⑥ Inverts the dictionary
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 反转字典
- en: ⑦ Makes a new name for the group column
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: ⑦ 为组列创建新名称
- en: ⑧ Transforms data with the DataFrame apply method and lambda
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: ⑧ 使用DataFrame的apply方法和lambda转换数据
- en: ⑨ Drops the original category column
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: ⑨ 删除原始类别列
- en: ⑩ Returns the new column name as the result
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: ⑩ 返回新的列名称作为结果
- en: 'You should run listing 10.3 to create your own cohort analysis where the countries
    are grouped into regions. Do this with the usual command to the Python wrapper
    program and these arguments:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该运行列表10.3以创建自己的队列分析，其中国家被分组到地区。使用通常的Python包装程序命令和这些参数执行此操作：
- en: '[PRE7]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'You should get a result that is qualitatively similar to figure 10.8, but don’t
    expect to get the specific churn rates in each group when you create your own
    version. The reason is that in the simulation, the countries have no relationship
    to churn and engagement and thus are random. (Believe me: I know because I created
    the simulation.) Although you should get confidence intervals of similar size
    to those in figure 10.8, don’t expect to get the same churn rates.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该得到一个与图10.8在定性上相似的结果，但不要期望在创建自己的版本时得到每个组的具体流失率。原因是模拟中，国家与流失和参与没有关系，因此是随机的。（相信我：我知道，因为我创建了模拟。）尽管您应该得到与图10.8中相似大小的置信区间，但不要期望得到相同的流失率。
- en: NOTE For the most part, this book has avoided having you analyze anything in
    the simulation that did not relate to churn in some way, to save you the time
    of generating and exploring meaningless data. But in real data from actual products
    and services, you should expect to find both events and demographic information
    that are unrelated to customer retention and churn.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：本书大部分内容都避免了让你分析那些与客户流失无关的模拟数据，以节省你生成和探索无意义数据的时间。但在实际产品和服务的真实数据中，你应该预期会找到一些与客户保留和流失无关的事件和人口统计信息。
- en: WARNING Do not take the results from the social network simulation from the
    book’s GitHub repository as a guide to what you can expect from your own product
    or service. The examples are a realistic-looking set of data for the purpose of
    demonstrating the methods to use on real data, but nothing more. The simulated
    results cannot be expected to predict the results for any real product or service.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 警告：不要将本书GitHub仓库中的社交网络模拟结果作为你自己的产品或服务的预期指南。这些例子是为了演示如何在真实数据上使用方法而设计的看起来很现实的数据集，但仅此而已。模拟结果不能预期预测任何真实产品或服务的任何结果。
- en: 10.3.3 Designing category groups
  id: totrans-216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.3.3 设计分类组
- en: 'Now that you know how to implement category groupings for a cohort analysis,
    I will give you some advice on how to pick such groupings. First, consider the
    scenario that you do not have a lot of data, so you are grouping categories to
    find enough observations in your cohorts (so that you end up with reasonable-size
    confidence intervals around the churn rates). If this situation is your situation,
    you don’t have the option to do something that is data driven based on your own
    data; you don’t have enough data to analyze the differences between the categories,
    and that’s the problem. In this case, you should group categories based on your
    knowledge of how the categories relate to one another. Apart from the country
    region example, some sensible groupings you may want to use include the following:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经知道了如何实现用于群体分析的分类分组，我将给你一些建议，告诉你如何选择这样的分组。首先，考虑这种情况：你没有很多数据，所以你正在分组分类以在你的群体中找到足够的观察结果（这样你最终会得到围绕流失率的合理大小的置信区间）。如果这是你的情况，你没有基于你自己的数据做数据驱动决策的选择；你没有足够的数据来分析分类之间的差异，这就是问题所在。在这种情况下，你应该根据你对分类之间关系的了解来分组分类。除了国家地区示例之外，你可能想要使用的合理分组包括以下内容：
- en: If you have a lot of categories for operating system versions, you can group
    them by major releases.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你有很多操作系统版本的分类，你可以根据主要版本将它们分组。
- en: If you have categories for industry sectors, you can group related ones such
    as banking and finance in one group and consumer products and retail in another.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你有一些行业部门的分类，你可以将相关的行业分组，例如将银行和金融放在一个组中，将消费品和零售放在另一个组中。
- en: If you have categories for occupations, you can group related fields such as
    doctors and dentists in one group and software engineers and data scientists in
    another.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你有一些职业的分类，你可以将相关的领域分组，例如将医生和牙医放在一个组中，将软件工程师和数据科学家放在另一个组中。
- en: If you have categories for education levels, you can group rare ones such as
    master’s degrees, doctorates, and so on.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你有一些教育水平的分类，你可以将罕见的教育水平，如硕士学位、博士学位等分组。
- en: Remember that your goal is to group the rare categories in a reasonable way
    and try to get a sense of any relationships. If you find some relationships, you
    can always revise your grouping to take advantage of the structure you discovered
    (as described later in this section).
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，你的目标是合理地分组罕见分类，并试图了解任何关系。如果你发现了一些关系，你总是可以修改你的分组，以利用你发现的任何结构（如本节后面所述）。
- en: 'Also note that you don’t have to slavishly follow standard definitions of groups:
    you should customize them based on the details of your product or service. In
    my own mapping from country to region, I made the following editorial decisions:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，你不必盲目遵循标准的群体定义：你应该根据你产品或服务的具体细节进行定制。在我从国家到地区的映射中，我做出了以下编辑决策：
- en: I didn’t include China (CN) in the Asia Pacific (APac) group because China alone
    represented more than 10% of the data samples, which is enough on its own.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我没有将中国（CN）包括在亚太地区（APac）组中，因为中国本身就代表了超过10%的数据样本，这本身就足够了。
- en: I chose to include Mexico (MX) with Latin America (LaAm) and not North America
    (LaAm) because if this were a real social network, I would expect that language
    and culture would be more significantly related to engagement than geography is
    related to engagement. (If my product or service had to do with industrial manufacturing
    and transportation, I probably would have focused on geographical rather than
    cultural relationships.)
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我选择将墨西哥（MX）与拉丁美洲（LaAm）而不是北美（LaAm）包括在内，因为如果这是一个真实的社会网络，我预计语言和文化与参与度的关系会比地理与参与度的关系更为显著。（如果我的产品或服务与工业制造和运输有关，我可能更关注地理关系而不是文化关系。）
- en: These are examples of some of the considerations you might want to use. My last
    piece of advice on the subject follows.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是一些你可能想要使用的考虑因素。关于这个主题的最后一项建议如下。
- en: WARNING Do not overthink your category groups or spend too much time on them.
    Remember the need for agility in your analysis. Do something that gives you a
    manageable result for a first pass, take feedback from your business colleagues,
    and iterate from there.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 警告：不要过度思考你的类别分组，也不要花太多时间在上面。记住分析中需要敏捷。做一些能让你得到可管理结果的第一步，从你的业务同事那里获取反馈，然后从那里迭代。
- en: 'On the other hand, consider that you have enough data to have narrow confidence
    intervals around every churn rate, and your problem is the information overload
    from too many categories (or after your first attempt at grouping, you achieved
    a similar result). Then you can take a more data-driven approach:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，考虑你拥有足够的数据来为每个流失率提供狭窄的置信区间，你的问题是来自太多类别（或在你第一次尝试分组后，你得到了类似的结果）的信息过载。然后你可以采取更数据驱动的方法：
- en: 'Run the category cohort analysis on the ungrouped categories; then use the
    churn rates you see from the first iteration to decide on groups to use in a second
    iteration:'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在未分组的类别上运行类别队列分析；然后使用第一次迭代中看到的流失率来决定在第二次迭代中使用的组：
- en: Group categories that are related according to your knowledge and that have
    similar churn rates.
  id: totrans-230
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据你的知识将相关且具有相似流失率的类别分组。
- en: In this context, a similar churn rate means that the two categories do not have
    a statistically significant difference in their churn rates. (Confidence intervals
    overlap.)
  id: totrans-231
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这个背景下，类似的流失率意味着这两个类别在流失率上没有统计学上的显著差异。（置信区间重叠。）
- en: If the two churn rates are different by a statistically significant amount (confidence
    intervals do not overlap), do not group them, even if you know that the categories
    are related.
  id: totrans-232
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果两个流失率在统计学上存在显著差异（置信区间不重叠），即使你知道这些类别是相关的，也不要将它们分组。
- en: You should still use groups based on knowledge as described. Do not group categories
    only on the grounds that the two categories have similar churn rates or other
    metrics.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你仍然应该使用如上所述的知识分组。不要仅仅因为两个类别在流失率或其他指标上有相似之处就分组。
- en: You can also use the correlation analysis described in section 10.5 as an additional
    way to assess the similarity between your groups based on their relationship to
    other metrics. But as you will see, the grouping algorithm you used for metrics
    does not work for categories, and I do not recommend using an automated method
    for this kind of grouping.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以使用第10.5节中描述的相关性分析作为评估你的组与其与其他指标关系相似性的额外方法。但正如你将看到的，你用于指标的分组算法不适用于类别，我不建议使用自动化的方法进行此类分组。
- en: If you have too many categories to handle by designing a grouping scheme from
    your knowledge (hundreds or thousands of categories), chances are that the information
    is not going to be helpful in your fight against churn. The businesspeople probably
    wouldn’t segment customers into such confusing categories.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有很多类别（数百或数千个）无法通过设计基于你知识的分组方案来处理，那么这些信息很可能对你的抗流失斗争没有帮助。商人们可能不会将客户细分到如此令人困惑的类别中。
- en: 10.4 Churn analysis for date- and numeric-based demographics
  id: totrans-236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.4 基于日期和数字人口统计的流失分析
- en: As I mentioned earlier, you should look at numeric demographic information with
    cohorts the same way that you do metrics. In section 10.1, I taught you that date
    type demographic and firmographic information can easily be converted to numeric
    intervals, so you can also use metric-style cohort analysis with date type demographic
    data. Because you learned how to analyze numeric customer data in chapter 5, this
    section is going to be a short demonstration.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 如我之前提到的，你应该以与度量相同的方式查看数值人口信息，在10.1节中，我教了你如何将日期类型的人口和企业信息轻松转换为数值区间，因此你也可以使用度量风格的队列分析来处理日期类型的人口数据。因为你在第5章中学习了如何分析数值客户数据，所以这一节将是一个简短的演示。
- en: 'The demographic information for the social network simulation includes the
    date of birth that the customer entered when they signed up, and listing 10.1
    converted this date to a numeric field in the social network simulation dataset:
    customer_age. Figure 10.9 shows the result of running a standard metric cohort
    analysis on customer age. The figure shows that in the social network simulation,
    the higher customer age is associated with higher churn. The lowest age cohort,
    with an average age around 15 years, has a churn rate around 4%, whereas the higher
    age cohorts (older than 60 years) have an average churn rate around 5.5%. The
    change in churn rates across cohorts is a little irregular, but it is consistent
    with the finding that older customers churn more (the effect is weak compared
    with the influence of their behavior that was demonstrated in chapters 5 and 7).'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 社交网络模拟的的人口信息包括客户在注册时输入的出生日期，并将10.1列表中的此日期转换为社交网络模拟数据集中的数值字段：customer_age。图10.9显示了在客户年龄上运行标准指标队列分析的结果。该图显示，在社交网络模拟中，客户年龄越高，流失率越高。最低年龄队列的平均年龄约为15岁，流失率约为4%，而较高年龄队列（60岁以上）的平均流失率约为5.5%。队列间流失率的变化略有不规则，但与发现老年客户流失率更高的事实一致（与第5章和第7章中展示的行为影响相比，这种影响较弱）。
- en: '![](../Images/10-09.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/10-09.png)'
- en: Figure 10.9 Customer demographic age cohort analysis
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.9 客户人口年龄队列分析
- en: 'To create your own version of figure 10.9 from the data you simulated, you
    must reuse the metric cohort listing 5.1 (with the filename listing_5_1_cohort_plot.py).
    The configuration already has a version that you run as follows:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 要从你模拟的数据中创建自己的图10.9版本，你必须重新使用指标队列列表5.1（文件名为listing_5_1_cohort_plot.py）。配置已经有一个版本，你可以按照以下方式运行：
- en: '[PRE8]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Your result can be somewhat different from figure 10.9 because the relationship
    is not strong and the data is randomly simulated. This example demonstrates that
    after you extract demographic information in numeric format in your dataset, you
    can analyze it with cohorts the same way that you would a metric.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 你的结果可能与图10.9有所不同，因为关系并不强，数据是随机模拟的。这个例子表明，在你从数据集中提取数值格式的人口信息后，你可以像分析度量一样使用队列来分析它。
- en: Confidence intervals for metric cohorts
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 指标队列的置信区间
- en: 'I interpret metric cohorts based on the consistency of the trend, but by now,
    you have probably realized that you could add confidence intervals around every
    point in a metric cohort plot. I don’t do this normally because it makes the plots
    too cluttered to show to businesspeople, and it’s usually not necessary for interpretation
    of the relationship to churn. But confidence intervals can help interpret metric
    cohort plots when the trend and significance are weak. Here’s one strategy I have
    used:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 我根据趋势的一致性来解释指标队列，但到现在为止，你可能已经意识到你可以在指标队列图中的每个点周围添加置信区间。我通常不这样做，因为这会使图表过于杂乱，难以向商业人士展示，而且通常对于解释流失率之间的关系来说并不必要。但是，置信区间可以帮助解释趋势和显著性较弱时的指标队列图。以下是我使用过的一种策略：
- en: Divide the metric into three cohorts. You are comparing customers who are low
    versus medium versus high in the metric. Large groups help make narrow confidence
    bounds.
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将度量分为三个队列。你正在比较低、中、高度量指标的客户。大型群体有助于使置信界限变窄。
- en: Plot the cohort averages with confidence bounds, and see whether the confidence
    bounds overlap. If the confidence intervals overlap, statistically significant
    differences exist between customers who are low versus medium versus high in the
    metric.
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制队列平均值与置信界限，并查看置信界限是否重叠。如果置信区间重叠，则在低、中、高度量指标的客户之间存在统计学上显著的差异。
- en: I leave this exercise to interested readers.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我把这个练习留给感兴趣的读者。
- en: 10.5 Churn forecasting with demographic data
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.5 使用人口数据进行流失率预测
- en: You have learned the techniques to analyze single demographic fields for their
    relationship to customer churn and retention. As with metrics, you may want to
    look at the influence on churn for all your demographic fields together to see
    how the combination predicts churn. Also, you should test forecasting with the
    demographic or firmographic data combined with your metrics. To do that, you need
    to convert demographic information in strings to an equivalent form as numeric
    information because the regression and XGBoost forecasting algorithms that you
    learned require only numeric inputs.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经学会了分析单个人口统计字段与其对客户流失和保留关系的技术。与指标一样，你可能想查看所有人口统计字段对流失的影响，以了解组合如何预测流失。此外，你应该测试将人口统计或公司统计数据与你的指标相结合的预测。为此，你需要将字符串形式的人口统计信息转换为等效的数值形式，因为你所学的回归和XGBoost预测算法仅需要数值输入。
- en: 10.5.1 Converting text fields to dummy variables
  id: totrans-251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.5.1 将文本字段转换为虚拟变量
- en: To use your string-type demographic information for forecasting, you will convert
    it to numeric data by using a technique known as dummy variables.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用你的字符串类型人口统计信息进行预测，你需要通过一种称为虚拟变量的技术将其转换为数值数据。
- en: DEFINITION A dummy variable is a binary variable that represents membership
    in a category, with `1` representing all customers in the category and `0` representing
    all customers that are not in the category.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 定义：虚拟变量是一个二元变量，表示一个类别中的成员资格，其中`1`表示该类别中的所有客户，而`0`表示不在该类别中的所有客户。
- en: If you studied data science in a computer science or engineering program, you
    may have learned about this technique, called one-hot encoding.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在一个计算机科学或工程项目中学习数据科学，你可能已经学过这种技术，称为独热编码。
- en: 'Figure 10.10 shows the process of creating dummy variables. Using dummy variables
    is similar to flattening metric data to create a dataset. In this case, a string
    demographic field is a tall data format in the sense that all the possible categories
    are stored in one column (using strings). To replace the column of strings with
    numeric data, you add one dummy variable column per unique string in the original
    data. Each columns is the dummy variable for one string category: all the customers
    who had a particular string get `1` in the column for that category and `0` in
    all the other columns. Then you drop the original string column and are left with
    a purely numeric dataset that still represents the same category information as
    the dataset that included strings.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.10显示了创建虚拟变量的过程。使用虚拟变量类似于将指标数据展平以创建数据集。在这种情况下，字符串人口统计字段在意义上是一个高数据格式，因为所有可能的类别都存储在一列中（使用字符串）。为了用原始数据中的每个唯一字符串添加一个虚拟变量列来替换字符串列，每个列是该字符串类别的虚拟变量：所有具有特定字符串的客户在该类别的列中得`1`，在其他所有列中得`0`。然后你删除原始字符串列，剩下的就是一个纯粹数值的数据集，它仍然代表与包含字符串的数据集相同的类别信息。
- en: '![](../Images/10-10.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/10-10.png)'
- en: Figure 10.10 Flattening a string variable to dummy variable columns
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.10 将字符串变量展平为虚拟变量列
- en: Figure 10.11 shows the result of creating dummy variables for the social network
    simulation. You can see that the string category labels for the channel and country
    are removed from the dataset. Instead, a set of new columns containing only zeros
    and ones represents the categories. Figure 10.11 also shows dummy variable columns
    for the country field grouped into regions, as they were earlier. The countries
    are still grouped because the same concerns about an overabundance of sparsely
    populated categories apply to forecasting, the same way that they did when you
    were looking at the country alone.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.11显示了创建社交网络模拟的虚拟变量的结果。你可以看到，渠道和国家字符串类别的标签已从数据集中移除。取而代之的是，一组只包含零和一的新的列代表这些类别。图10.11还显示了按地区分组的虚拟变量列，这与之前一样。国家仍然分组，因为关于稀疏类别过多的问题同样适用于预测，就像你在单独查看国家时的情况一样。
- en: '![](../Images/10-11.png)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/10-11.png)'
- en: Figure 10.11 Result of creating dummy variables for the simulated social network
    dataset
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.11 创建模拟社交网络数据集的虚拟变量结果
- en: Listing 10.4 provides the code to create a dataset with dummy variables like
    the one in figure 10.11\. Creating dummy variables is a standard function of a
    Pandas `DataFrame` (called `get_dummies`). This function automatically detects
    all the string-type columns in your dataset and replaces them with appropriate
    binary dummy variables. The names for the dummy variable columns are created by
    concatenating the original column name with the category string.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.4提供了创建与图10.11中类似的数据集的代码，其中包含虚拟变量。创建虚拟变量是Pandas `DataFrame`（称为`get_dummies`）的标准功能。此函数会自动检测数据集中所有字符串类型的列，并用适当的二进制虚拟变量替换它们。虚拟变量列的名称是通过将原始列名与类别字符串连接起来创建的。
- en: Listing 10.4 Creating dummy variables
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.4 创建虚拟变量
- en: '[PRE9]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ① Imports the group category mapping function from listing 10.3
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: ① 从列表10.3导入分组类别映射函数
- en: ② Reads in the raw data
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: ② 读取原始数据
- en: ③ Keys of the mapping dictionary are the categories to be mapped.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 映射字典的键是要映射的类别。
- en: ④ Calls the group mapping function
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 调用分组映射函数
- en: ⑤ Uses the Pandas get_dummies function
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 使用Pandas get_dummies函数
- en: ⑥ This version of the dataset is for XGBoost forecasting.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 此版本的数据集用于XGBoost预测。
- en: ⑦ Determines the dummy variable columns by set difference
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: ⑦ 通过集合差集确定虚拟变量列
- en: ⑧ Determines the original category columns by set difference
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: ⑧ 通过集合差集确定原始类别列
- en: ⑨ Saves a list of columns for consistency with grouped datasets
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: ⑨ 保存列列表以与分组数据集保持一致性
- en: ⑩ Includes churn if not being used for current customers
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: ⑩ 如果不是用于当前客户，则包括流失
- en: ⑪ Saves a dataset with only dummy variables
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: ⑪ 仅保存包含虚拟变量的数据集
- en: ⑫ Names the dataset consistently with a regular dataset
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: ⑫ 以与常规数据集一致的方式命名数据集
- en: ⑬ Saves the dataset with no demographic categories
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: ⑬ 保存没有人口统计类别的数据集
- en: 'Calling the package function `get_dummies` is not all that happens in listing
    10.4\. First, listing 10.4 applies the optional grouping of categories that you
    learned in section 10.2\. Then it is saved in three versions: the part with the
    original metrics and any numeric demographic information, a part with only the
    dummy variables, and everything together. Each version has a purpose, as follows:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表10.4中调用包函数`get_dummies`不仅仅是发生的事情。首先，列表10.4应用了你在第10.2节中学到的可选的类别分组。然后，它以三个版本保存：包含原始指标和任何数值人口统计信息的部分，仅包含虚拟变量的部分，以及全部内容。每个版本都有其目的，如下所述：
- en: The metrics and numeric demographic information must be converted to scores
    and run through the metric grouping algorithm. This process should happen without
    the dummy variables.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指标和数值人口统计信息必须转换为分数并通过指标分组算法运行。此过程应在没有虚拟变量的情况下进行。
- en: Saving the dummy variables by themselves facilitates running a regression analysis
    on the dummy variables alone.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单独保存虚拟变量便于对虚拟变量本身进行回归分析。
- en: The version with everything together is for XGBoost, which uses the untransformed
    metrics together with the dummy variables.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含所有内容的版本用于XGBoost，它使用未转换的指标与虚拟变量一起使用。
- en: These points will be explained further throughout the rest of this chapter,
    but for now, I will focus on explaining the rest of listing 10.4\. This code is
    mostly a mechanical use of the Pandas library, separating out the parts of the
    dataset. The only trick is using sets and operations related to the differences
    between sets to figure out which columns were added by making the dummy variables.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 这些点将在本章的其余部分进一步解释，但到目前为止，我将专注于解释列表10.4的其余部分。此代码主要是Pandas库的机械使用，分离数据集的部分。唯一的技巧是使用集合和与集合差异相关的操作来确定哪些列是通过创建虚拟变量而添加的。
- en: 'Listing 10.4 saves multiple versions of the dataset with different filename
    extensions:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.4保存了具有不同文件扩展名的多个数据集版本：
- en: The file with the postfix .dummies is the dataset with only the dummy variables.
    This file is also saved with the postfix .groupscore because that convention will
    be expected when you use the regression code on it. A listing of the columns is
    also saved with the postfix .groupmets because that also will be expected by the
    regression code, even though for the dummy variables, there will be no groups.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带有后缀.dummies的文件是仅包含虚拟变量的数据集。此文件也以后缀.groupscore保存，因为当你使用回归代码时，将期望遵循此约定。列的列表也以后缀.groupmets保存，因为回归代码也将期望这样做，尽管对于虚拟变量，将没有组。
- en: The file with the postfix .nocat is the file with numeric metrics and demographic
    fields. This file is simply saved and will be run through the usual scoring and
    grouping.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带有后缀 .nocat 的文件是包含数值指标和人口统计字段的文件。此文件简单保存，将通过常规评分和分组运行。
- en: The file with the postfix .xgbdummies will be reloaded by the XGBoost cross-validation.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带有后缀 .xgbdummies 的文件将由 XGBoost 交叉验证重新加载。
- en: 'You should run listing 10.4 to create your own version of the dataset with
    the string categories replaced by dummy variables (and the files described previously).
    If you are using the Python wrapper program, use the usual form of the command
    and these arguments:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该运行列表 10.4 来创建自己的数据集版本，将字符串类别替换为虚拟变量（以及之前描述的文件）。如果您使用 Python 包装程序，请使用通常的命令形式和这些参数：
- en: '[PRE10]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Your results should look similar to figure 10.11, although the precise accounts
    and their demographics will be different because the data is randomly generated.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 您的结果应类似于图 10.11，尽管精确的账户和其人口统计数据将不同，因为数据是随机生成的。
- en: 10.5.2 Forecasting churn with categorical dummy variables alone
  id: totrans-289
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.5.2 仅使用分类虚拟变量预测流失
- en: Now that you have a dataset with demographic dummy variables, it is instructive
    to try churn forecasting in a regression model with the demographic data alone.
    This exercise is intended to increase your understanding of the combined influence
    of the demographic variables on churn probabilities. As you will see, if you want
    to forecast churn as accurately as possible, use the demographic dummy variables
    and the metrics together, as described in section 10.5.4.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您有一个包含人口统计数据虚拟变量的数据集，尝试使用仅包含人口数据的回归模型进行流失预测是有教育意义的。这个练习旨在增加您对人口变量对流失概率综合影响的理解。正如您将看到的，如果您想要尽可能准确地预测流失，应使用人口统计数据虚拟变量和度量一起，如第
    10.5.4 节所述。
- en: 'If you run a regression cross-validation and then fit the model at the optimal
    `C` parameter, the results that you get are shown in figure 10.12\. The results
    show that the demographic dummy variables are weakly predictive of churn. The
    best AUC measurement found in the cross-validation is around 0.56, and the maximum
    lift is around 1.5\. If you recall from chapter 9, the regression using metrics
    resulted in an AUC higher than 0.7 and a lift higher than 4.0\. A low value of
    the `C` parameter can be used and then most of the dummy variables removed without
    affecting the AUC significantly, but the lift is best with a higher value of the
    `C` parameter: 0.32 or greater.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您运行回归交叉验证，然后在最佳 `C` 参数下拟合模型，您得到的结果如图 10.12 所示。结果显示，人口统计数据虚拟变量对流失率有弱预测性。交叉验证中找到的最佳
    AUC 测量值约为 0.56，最大提升值约为 1.5。如果您回忆第 9 章的内容，使用度量结果的回归导致了 AUC 高于 0.7 和提升高于 4.0。可以采用低
    `C` 参数值，然后删除大多数虚拟变量而不会显著影响 AUC，但提升值在 `C` 参数值较高时最佳：0.32 或更高。
- en: Figure 10.12 also shows the regression coefficients and impact on retention
    probability with the `C` parameter set to 0.32\. The dummy variables for the two
    appstore channels are assigned fairly large weights, which translates into a positive
    retention impact of 1.2% and 2.8%, respectively (churn reducing). The web channel
    gets zero weight, which reflects the fact that it has the highest churn because
    both of the other two channels were shown to have a positive impact. In this sense,
    the zero weight means that it is like the default, or baseline, and the other
    categories represent improvements.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.12 还显示了将 `C` 参数设置为 0.32 时的回归系数和保留概率的影响。两个应用商店频道的虚拟变量被分配了相当大的权重，分别转化为 1.2%
    和 2.8% 的积极保留影响（减少流失）。网络频道获得零权重，这反映了它具有最高的流失率，因为其他两个频道都显示出积极的影响。在这种情况下，零权重意味着它类似于默认值或基线，而其他类别代表改进。
- en: The `get_dummies` function also created a variable for a channel not available
    (`nan`), and this channel also got zero weight, because in this dataset, all customers
    have the channel assigned. (Pandas makes a `nan` column for every variable when
    the `na_default` parameter is set.) These effects are in line with the churn-rate
    differences you saw in the category cohort plot (figure 10.3).
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '`get_dummies` 函数还创建了一个对于不可用的频道（`nan`）的变量，并且这个频道也获得了零权重，因为在数据集中，所有客户都分配了频道。（当设置
    `na_default` 参数时，Pandas 为每个变量创建一个 `nan` 列。）这些效果与你在类别群体图（图 10.3）中看到的流失率差异一致。'
- en: Figure 10.12 also shows much smaller coefficients and retention impacts for
    the country group dummy variables. In this case, CN, Eur, and the missing data
    have a slight positive retention impact (churn rate lower), and LaAm and APac
    have a negative retention impact (churn rate higher). Again, these results are
    in line with what you saw in the cohort plot for the country groups (figure 10.8).
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.12还显示了国家组虚拟变量的系数和保留影响显著减小。在这种情况下，CN、Eur和缺失数据有轻微的正保留影响（流失率较低），而LaAm和APac有负保留影响（流失率较高）。再次强调，这些结果与你在国家组群体图（图10.8）中看到的结果一致。
- en: '![](../Images/10-12.png)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/10-12.png)'
- en: Figure 10.12 Regression results with a dummy category variable dataset
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.12展示了使用虚拟类别变量数据集的回归结果
- en: 'Figure 10.12 was created from the listings from previous chapters, and there
    are already versions of the configuration prepared for you to do this. To create
    the regression cross-validation chart from figure 10.12, use the command for regression
    cross-validation, version 4, as follows:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.12是从前几章的列表中创建的，已经为你准备好了配置版本来做这件事。要创建图10.12的回归交叉验证图，请使用以下回归交叉验证命令，版本4：
- en: '[PRE11]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'To find the coefficients with the `C` parameter fixed at 0.32, use the command
    to run the regression with a fixed value of `C`:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 要找到固定`C`参数为0.32的系数，请使用以下命令运行固定`C`值的回归：
- en: '[PRE12]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Your result for cross-validation should be similar to figure 10.12, and so should
    your result for coefficients on the channels, which are randomly assigned to customers
    but in such a way that they produce consistent results in the simulation. You
    may get different results for the small weights and impact of the country group
    because in the simulation they are random.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 你的交叉验证结果应该类似于图10.12，你的渠道系数结果也应该如此，这些渠道是随机分配给客户的，但在模拟中它们会产生一致的结果。你可能因为国家组的小权重和影响而得到不同的结果，因为在模拟中它们是随机的。
- en: 10.5.3 Combining dummy variables with numeric data
  id: totrans-302
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.5.3 将虚拟变量与数值数据结合
- en: In earlier sections, I mentioned that you cannot use the type of grouping that
    you use for metrics when you are working with dummy variables derived from categories.
    Instead, I suggested separating the dummy variables from the metrics and processing
    the metrics as usual. In this section, I provide details on the reason and this
    process. I start by explaining some facts about correlations involving dummy variables
    because that will help make it clear why you do not group categorical dummy variables
    along with the metrics.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我提到当你使用从类别派生出的虚拟变量时，你不能使用你在度量时使用的分组类型。相反，我建议将虚拟变量与度量分开，并按常规处理度量。在本节中，我将详细介绍原因和这个过程。我首先解释一些关于涉及虚拟变量的相关性的事实，因为这有助于阐明为什么你不应该将类别虚拟变量与度量一起分组。
- en: Figure 10.13 shows the portion of the correlation matrix from the social network
    simulation that relates the demographic categories for channel and country to
    one another and to the metrics. (You haven’t run the code to create this correlation
    matrix yet, but you will soon.) The portion of the correlation matrix with metric-to-`metric
    correlations is omitted in figure 10.13\. One distinctive feature that might sur`prise
    you is the categories; dummy variables from each field are negatively correlated
    with the other dummy variables from the same field. This is especially true for
    the channel field, which had only three categories where the correlation is as
    low as -0.74\. For the country groups, the negative correlations between the regions
    are around -0.2.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.13显示了社会网络模拟中与渠道和国家的相关矩阵部分，这些部分与人口统计类别相关联。（你还没有运行代码来创建这个相关矩阵，但很快你将这么做。）图10.13省略了与度量到度量相关性的相关矩阵部分。一个可能让你感到惊讶的显著特征是类别；每个字段的虚拟变量与其他字段的虚拟变量呈负相关。这在渠道字段中尤其如此，该字段只有三个类别，相关性低至-0.74。对于国家组，区域之间的负相关性大约为-0.2。
- en: '![](../Images/10-13.png)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/10-13.png)'
- en: Figure 10.13 Correlation matrix for the social network simulation demographic
    categories
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.13展示了社会网络模拟人口统计类别的相关矩阵
- en: 'The reason for the negative correlations between the categories is due to the
    exclusive nature of category membership: if a customer is in one category, it
    gives them `1` for that category’s dummy variable, and it requires that they have
    `0` for the other dummy variables from the same field. That exclusivity for the
    binary indicator results in a negative measured correlation from the definition
    of the correlation coefficient: when one dummy variable takes a high value (`1`),
    the others take low values (`0`). This explains why the kind of grouping you used
    for the metric variables will not group demographic categories from the same demographic
    field. That algorithm uses a high correlation to indicate that the variables should
    form group members.'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '**负相关原因**：类别之间的负相关性是由于类别成员的排他性：如果一个客户属于一个类别，它会给该类别的虚拟变量赋予`1`，并要求他们从同一字段的其他虚拟变量中具有`0`。这种二元指标的排他性导致从相关系数的定义来看，负的测量相关性：当一个虚拟变量取高值（`1`）时，其他虚拟变量取低值（`0`）。这解释了为什么你用于指标变量的分组方式不会将同一人口字段的人口统计类别分组。该算法使用高相关性来指示变量应形成组成员。'
- en: 'Considering the rest of figure 10.13, the demographic category dummy variables
    are mostly uncorrelated with the metrics, but there are a few exceptions:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关性分析**：考虑到图10.13的其余部分，人口统计类别虚拟变量与指标大多不相关，但有一些例外：'
- en: The channels appstore1 and web have negative correlation with messages and replies.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**相关性**：渠道appstore1和web与消息和回复有负相关性。'
- en: The channel appstore2 has positive correlation with messages and replies.
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正相关性**：渠道appstore2与消息和回复有正相关性。'
- en: The channel web also has positive correlation with posts.
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正相关性**：渠道web也与帖子有正相关性。'
- en: When you use demographic categories to understand customer churn and retention,
    it can be worthwhile to look at the correlation matrix using the dummy variables,
    because it can reveal things about how different groups of your customers use
    the product. But you should not group the demographic dummy variables with your
    metric groups, even when they are correlated.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '**分析**：当你使用人口统计类别来理解客户流失和保留时，使用虚拟变量查看相关矩阵可能是值得的，因为它可以揭示关于你的客户如何使用产品的不同群体的一些信息。但即使它们相关，你也不应将人口统计虚拟变量与你的指标组别分组。'
- en: TAKEAWAY The correlations between demographic dummy variables and other metrics
    can help you understand your customers better, but you should not group dummy
    variables with other dummy variables or with metrics.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '**总结**：人口统计虚拟变量与其他指标之间的相关性可以帮助你更好地了解你的客户，但你不应将虚拟变量与其他虚拟变量或指标分组。'
- en: 'Back in chapter 6, I advised you to use correlation between metrics as a way
    of assessing the relatedness of the metrics and determining which should be grouped.
    But there are a few reasons why this same approach doesn’t carry over with dummy
    variables created from demographic categories:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '**回顾**：在第六章中，我建议你使用指标之间的相关性作为评估指标相关性和确定哪些应该分组的方法。但有几个原因说明这种方法不适用于从人口统计类别创建的虚拟变量：'
- en: You can calculate correlation coefficients for 0/1 binary variables, but correlation
    coefficients are not meant for this purpose. In statistics, other metrics are
    better for measuring relatedness between binary variables. When you calculate
    correlation coefficient with your dummy variables, it’s not as good a measure
    of relatedness as correlation between metrics.
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**相关性系数**：你可以计算0/1二进制变量的相关系数，但相关系数并不适用于此目的。在统计学中，其他指标更适合测量二进制变量之间的相关性。当你用虚拟变量计算相关系数时，它并不是衡量相关性的好方法。'
- en: The demographic categories are not related in the same way as behaviors that
    you group by using correlation. When two behaviors (such as using two product
    features) are correlated, usually they are part of a single activity or process.
    Therefore, it is reasonable to represent the overall process with an average of
    the scores, which is not normally the case for a demographic category and any
    other metric.
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**相关性解释**：人口统计类别与使用相关性分组的行为方式不同。当两种行为（例如使用两个产品功能）相关时，通常它们是单个活动或过程的一部分。因此，用得分的平均值来表示整个过程是合理的，但这通常不适用于人口统计类别和任何其他指标。'
- en: For these reasons, my advice is that if you want to use demographic dummy variables
    to forecast churn, you should keep all dummy variables separate from the groups.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '**原因**：因此，我的建议是，如果你想使用人口统计虚拟变量来预测客户流失，你应该保持所有虚拟变量与组别分开。'
- en: TAKEAWAY Run the metrics and numeric demographic fields through a standard preparation
    process without demographic dummy variables, and then combine them with dummy
    variables at the end.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '**总结**：在标准准备过程中运行度量数值人口统计字段，不使用人口统计虚拟变量，然后在最后将它们与虚拟变量结合。'
- en: This result is illustrated in figure 10.14.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 此结果如图 10.14 所示。
- en: '![](../Images/10-14.png)'
  id: totrans-320
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/10-14.png)'
- en: Figure 10.14 Metric groups, metric scores, and categories in one dataset
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.14 一个数据集中包含度量组、度量分数和类别
- en: 'To create your own dataset like the one in figure 10.13, the first step is
    running the data-preparation process that you learned in earlier chapters on the
    version of the dataset that has the metrics and numeric demographic information.
    There is a version of the listing configuration prepared for you to do that with
    one command. Recall that listing 8.1 (with the filename listing_8_1_prepare_data.py)
    was the combined data-preparation function, and this is the third use of it (version
    3):'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建如图 10.13 所示的自己的数据集，第一步是在具有度量数值人口统计信息的版本的数据集上运行你在早期章节中学到的数据准备过程。有一个列表配置版本为你准备，只需一个命令即可完成：
- en: '[PRE13]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: After processing the metrics, combine them with the dummy variables. A new function
    shown in listing 10.5 is a straightforward application of a Pandas `DataFrame`
    manipulation. The group scores produced from the metrics are merged with the file
    for the dummies. The merge is performed with the Pandas `DataFrame` `merge` function,
    using the indices of both `DataFrame`s to perform an `INNER` `JOIN`. The final
    step in listing 10.4 combines the `DataFrame` that lists the group metrics with
    the names of the dummy variables; such a file will be expected by the code that
    runs the regression on the combined dataset.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理度量后，将它们与虚拟变量结合。列表 10.5 中显示的新函数是 Pandas `DataFrame` 操作的直接应用。从度量产生的组分数与虚拟变量的文件合并。合并是通过
    Pandas `DataFrame` 的 `merge` 函数执行的，使用两个 `DataFrame` 的索引进行 `INNER` `JOIN`。列表 10.4
    的最后一步是将列出组度量的 `DataFrame` 与虚拟变量的名称结合；这样的文件将被用于在合并数据集上运行回归的代码所期望。
- en: Listing 10.5 Merging dummy variables with grouped metric scores
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.5 合并虚拟变量与分组度量分数
- en: '[PRE14]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ① Loads the file containing the dummy variable dataset
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: ① 加载包含虚拟变量数据集的文件
- en: ② Drops the churn column
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: ② 删除流失列
- en: ③ Loads the metric group scores
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 加载度量组分数
- en: ④ Merges the dummy variables and metric group scores
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 合并虚拟变量和度量组分数
- en: ⑤ Saves the merged file under the name for the group scores
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 将合并的文件以组分数的名称保存
- en: ⑥ Loads the group metric listing from the metric-only data
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 从仅度量数据中加载组度量列表
- en: ⑦ Loads the listing of the dummy variables
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: ⑦ 加载虚拟变量列表
- en: ⑧ Combines the two metric lists and saves it
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: ⑧ 将两个度量列表合并并保存
- en: 'You should run listing 10.5 on your own simulated social network dataset to
    prepare for forecasting in section 10.5.4\. Issue the usual command to the Python
    wrapper program with these arguments:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该在模拟的社会网络数据集上运行列表 10.5，为 10.5.4 节中的预测做准备。使用以下参数向 Python 包装程序发出常规命令：
- en: '[PRE15]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'After running listing 10.5, one of the results should be a dataset like the
    one you saw in figure 10.14\. Also, now that you have created the combined dataset,
    you can make a correlation matrix like the one I showed you at the start of this
    section (figure 10.13). Use a version of the correlation matrix listing configuration
    by issuing the following command with these arguments:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 运行列表 10.5 后，其中一个结果应该是一个类似于你在图 10.14 中看到的数据集。现在，既然你已经创建了合并后的数据集，你可以创建一个类似于我在本节开头（图
    10.13）展示的相关矩阵。使用以下命令和这些参数发出相关矩阵列表配置的版本：
- en: '[PRE16]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Running listing 6.2 with parameter configuration version 3 creates the raw data
    for a correlation matrix like the one shown in figure 10.13\. The formatting for
    figure 10.13 was done in a spreadsheet program (as explained in chapter 6).
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 使用参数配置版本 3 运行列表 6.2 创建了如图 10.13 所示的相关矩阵的原始数据。图 10.13 的格式是在电子表格程序中完成的（如第 6 章所述）。
- en: 10.5.4 Forecasting churn with demographic and metrics combined
  id: totrans-340
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.5.4 结合人口统计和度量进行客户流失预测
- en: Now that you have created a dataset combining the group metric scores and the
    demographic category dummy variables, you can run a regression or machine learning
    model to forecast churn probabilities. Figure 10.15 shows the result of the regression.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经创建了一个结合组度量分数和人口统计类别虚拟变量的数据集，你可以运行回归或机器学习模型来预测客户流失概率。图 10.15 显示了回归的结果。
- en: The cross-validation of the `C` parameter shows that many of the variables can
    be assigned zero weight before accuracy is affected. Figure 10.15 also shows the
    weights resulting from the regression when the `C` parameter is set to 0.04\.
    Nearly all the demographic dummy variables have zero weight and retention impact
    (and a few of the metrics as well).
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: '`C`参数的交叉验证显示，在准确性受到影响之前，许多变量可以被分配为零权重。图10.15还显示了当`C`参数设置为0.04时回归产生的权重。几乎所有的人口统计虚拟变量都有零权重和保留影响（以及一些度量指标也是如此）。'
- en: 'Figure 10.15 was created by using listings from chapter 9\. To run your own
    regression on the dataset with dummy variables and metrics combined, you can use
    prepared versions of the configuration. To run the cross-validation of the regression
    `C` parameter (listing 9.5) shown in figure 10.15, use the following command:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.15是通过使用第9章的列表创建的。要在包含虚拟变量和度量指标的数据集上运行自己的回归，你可以使用准备好的配置版本。要运行图10.15中显示的回归`C`参数（列表9.5）的交叉验证，请使用以下命令：
- en: '[PRE17]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: To run the regression with the `C` parameter fixed (listing 9.4) at 0.04 on
    the combined dummy variables and metrics dataset, use the command
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 要在包含虚拟变量和度量指标的数据集上运行固定`C`参数（列表9.4）为0.04的回归，请使用以下命令
- en: '[PRE18]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Those commands produce results similar to figure 10.15, although you may have
    different weights on the country group dummy variables because they are assigned
    randomly in the simulation.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 这些命令产生与图10.15类似的结果，尽管你可能在国家群体虚拟变量上有不同的权重，因为它们在模拟中被随机分配。
- en: You may wonder why the regression coefficients in figure 10.15 show that the
    channel demographic variable had no influence on the churn prediction, but early
    in the chapter, both the cohort churn analysis with confidence intervals and the
    regression on the dummy variables showed that the channel was strongly predictive
    of churn (and retention). What’s going on here? Is something wrong in the regression?
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道为什么图10.15中的回归系数显示渠道人口统计变量对客户流失预测没有影响，但在本章早期，无论是带有置信区间的队列流失分析还是虚拟变量的回归，都显示渠道对客户流失（和保留）有很强的预测性。这里发生了什么？回归中有什么问题吗？
- en: '![](../Images/10-15.png)'
  id: totrans-349
  prefs: []
  type: TYPE_IMG
  zh: '![图10.15](../Images/10-15.png)'
- en: Figure 10.15 Regression result for dataset combining metric scores and category
    dummy variables
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.15为结合度量分数和类别虚拟变量的数据集的回归结果
- en: Nothing is wrong. When taken together with the behavioral metrics, the channel
    provides no additional information about churn, and the regression discovers this
    fact. The customer channels are correlated with certain behaviors, and behavior
    causes customer churn and retention in the simulation. When you look at the channel
    alone, it is related to churn rates, but when combined with the behavioral metrics
    in a regression, the regression algorithm automatically determines the most explanatory
    factors and removes the others. The regression correctly determines that customer
    engagement is most predictable by watching the metrics and not the channels.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 没有什么问题。当与行为指标一起考虑时，该渠道不会提供关于客户流失的额外信息，回归也发现了这一点。客户渠道与某些行为相关，在模拟中，行为导致客户流失和保留。当你单独看渠道时，它与流失率相关，但当与回归中的行为指标结合时，回归算法会自动确定最解释性的因素并去除其他因素。回归正确地确定，通过观察指标而不是渠道，客户参与度最可预测。
- en: TAKEAWAY Demographic categories are often related to churn and engagement because
    customers from different demographics behave differently. But if you use detailed
    behavioral metrics, you will usually find that behaviors are the underlying drivers
    of retention in a predictive forecast.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: '**要点**：人口统计类别通常与客户流失和参与度相关，因为来自不同人口统计的客户行为不同。但如果你使用详细的行为指标，你通常会发现行为是预测性预测中保留的潜在驱动因素。'
- en: I told you that understanding demographics and firmographics is a secondary
    method of fighting churn because behavior can (sometimes) be modified by interventions
    but demographics cannot (ever). The fact that demographics are not usually helpful
    in predicting churn is another reason why I emphasize understanding behavior with
    metrics when fighting churn. But even if a demographic field is not useful for
    predicting churn, it does not detract from the primary use of demographics in
    fighting churn.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 我曾告诉你们，理解人口统计和公司统计是应对客户流失的次要方法，因为行为可以通过干预（有时）进行修改，但人口统计却不能（永远不能）。人口统计通常对预测客户流失没有帮助，这也是我强调在应对客户流失时理解行为与指标的原因。即使人口统计字段对预测客户流失没有用，也不会影响其在应对客户流失中的主要用途。
- en: TAKEAWAY If you see a strong relationship between demographics and retention
    in your cohort analysis, you should try to emphasize your best demographics in
    your acquisition efforts. It doesn’t matter if those same demographics are not
    predictive of engagement in a regression with behavioral metrics.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: '**要点** 如果您在群体分析中看到人口统计与保留率之间存在强烈的关系，您应该在您的获取努力中强调您最好的人口统计。即使这些相同的人口统计在包含行为指标的回归中不是预测参与度的指标，这也无关紧要。'
- en: WARNING Do not assume that your own product or sevice’s churn data will show
    exactly the same result as I presented here from the simulation. The social network
    simulation was designed to mimic the result that I have most commonly seen when
    studying customer churn, but there can always be exceptions, and your product
    may be one of them.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: '**警告** 不要假设您自己的产品或服务的流失数据将显示与我在此处从模拟中展示的完全相同的结果。社交网络模拟是为了模仿我在研究客户流失时最常见的结果，但总会有例外，您的产品可能就是其中之一。'
- en: If you find that your own demographics are strongly predictive of churn, even
    when you have factored in behavioral metrics, you should check your data to see
    whether it can be improved. Make sure that all relevant customer behaviors are
    represented by your events and that your metrics adequately capture the relationships
    between your events and churn. Demographic correlations with unmeasured behaviors
    can lead to a result in which demographics predict churn, even when including
    metrics. If that’s the case, you would be better off figuring out what those behaviors
    are so that you can measure them and attempt to influence them for the better.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您发现您自己的人口统计在考虑了行为指标后仍然强烈预测流失，您应该检查您的数据是否可以改进。确保所有相关的客户行为都通过您的事件表示，并且您的指标充分捕捉了您的事件与流失之间的关系。与未测量的行为相关的人口统计相关性可能导致即使在包含指标的情况下，人口统计预测流失的结果。如果是这样，您最好找出这些行为是什么，以便您可以测量它们并尝试改善它们。
- en: You can also test how much improvement demographic variables make for prediction
    with a machine learning model like XGBoost. The result of such an experiment is
    shown in figure 10.16\. The demographic variables add around 0.005 to the AUC
    of XGBoost, or one-half of 1%. Figure 10.16 also shows the improvement in the
    regression AUC, which is even smaller (but an improvement nonetheless).
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以测试人口统计变量在像XGBoost这样的机器学习模型中对预测的改进程度。这种实验的结果如图10.16所示。人口统计变量使XGBoost的AUC增加了约0.005，或者说增加了1%的一半。图10.16还显示了回归AUC的改进，这个改进甚至更小（但仍然是一个改进）。
- en: '![](../Images/10-16.png)'
  id: totrans-358
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/10-16.png)'
- en: Figure 10.16 Accuracy comparison with demographic data
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.16 带有人口数据的准确度比较
- en: TAKEAWAY The highest predictive accuracy comes from XGBoost using demographic
    data combined with detailed customer metrics. XGBoost may find demographics more
    helpful in prediction than regression does.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: '**要点** 最高预测准确度来自使用人口统计数据和详细客户指标的XGBoost。XGBoost可能比回归更认为人口统计在预测中更有帮助。'
- en: 'To reproduce the XGBoost result in figure 10.16, you can run a version of the
    XGBoost cross-validation listing configuration with the following command (listing_9_6_crossvalidate_xgb.py):'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 要在图10.16中重现XGBoost的结果，您可以使用以下命令运行XGBoost交叉验证列表配置版本（listing_9_6_crossvalidate_xgb.py）：
- en: '[PRE19]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Note that the listing and configuration create the results for XGBoost with
    demographic variables. If you have been following along, you should have already
    found the accuracy for the other models and datasets.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，列表和配置创建了包含人口统计变量的XGBoost的结果。如果您一直在跟随，您应该已经找到了其他模型和数据集的准确度。
- en: 10.6 Segmenting current customers with demographic data
  id: totrans-364
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.6 使用人口统计数据细分现有客户
- en: 'The final subject for this chapter is how to use demographic information as
    part of the effort to segment customers. As the data person, you’re not responsible
    for defining the segments or intervening with customers, but you do need to provide
    the data so that the businesspeople can do their jobs effectively. The final dataset
    for segmenting customers should include the following elements:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的最后一个主题是如何将人口统计信息作为细分客户努力的一部分。作为数据人员，您不负责定义细分或与客户互动，但您确实需要提供数据，以便业务人员能够有效地完成工作。用于细分客户的最终数据集应包括以下要素：
- en: All customers active on the most recently available date
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有在最近可用日期活跃的客户
- en: Scores for metric groups
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指标组的分数
- en: The original (unscaled) metric values for metrics that were not grouped
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未分组的指标的原生（未缩放）指标值
- en: Categorical demographic information in string format
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以字符串格式表示的类别人口统计信息
- en: Categories grouped where appropriate
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在适当的地方分组类别
- en: Churn forecast probabilities (optional)
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流失预测概率（可选）
- en: Figure 10.17 is an example of a dataset that has all those features.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.17是一个具有所有这些特征的示例数据集。
- en: 'Creating such a dataset requires a few steps:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 创建这样的数据集需要几个步骤：
- en: Extract all the metrics and demographic information for current customers from
    the database.
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从数据库中提取当前客户的全部指标和人口统计信息。
- en: Reprocess the metric information to form groups, using the score parameters
    and loading matrix from the historical data.
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用历史数据中的分数参数和加载矩阵重新处理指标信息以形成组。
- en: Save a version of the dataset that has all the desired features.
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存一个包含所有所需特征的版本的数据集。
- en: Note that this process also creates a dataset ready for churn probability forecasting
    on active customers. That version combines scores for all the metrics and numeric
    demographic data but dummy variables for the demographic categories.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这个过程还会创建一个为活跃客户进行流失概率预测准备好的数据集。该版本结合了所有指标的分数和数值人口统计数据，但人口统计类别的虚拟变量。
- en: '![](../Images/10-17.png)'
  id: totrans-378
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/10-17.png)'
- en: Figure 10.17 Dataset to segment customers with metric group scores, metrics,
    and demographic information
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.17 按指标分组得分、指标和人口统计信息对客户进行分段的示例数据集
- en: Listing 10.6 provides the SQL statement to extract demographic data along with
    all metrics for currently active customers. This listing is almost the same as
    similar listings in chapters 4 and 8, so I’ll explain it only briefly. The main
    portion of the SQL program is the aggregation to flatten the metrics. The new
    feature is to join on the account table and also select the channel country and
    the date of birth. The date of birth is converted to a time interval representing
    the customer’s age in years (following the pattern used to create the historical
    dataset with demographic data presented earlier in this chapter).
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.6提供了提取当前活跃客户所有指标和人口统计数据的SQL语句。这个列表几乎与第4章和第8章中类似的列表相同，所以我只会简要解释。SQL程序的主要部分是对指标进行聚合以简化指标。新功能是在账户表上进行连接，并选择渠道国家和出生日期。出生日期被转换为表示客户年龄的年数的时间间隔（遵循本章前面创建包含人口统计数据的历史数据集时使用的模式）。
- en: Listing 10.6 Exporting metrics and demographic data for currently active customers
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.6 导出当前活跃客户的指标和人口统计数据
- en: '[PRE20]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: ① Most of this listing is the same as listings 4.6 and 8.3.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: ① 列表的大部分内容与列表4.6和8.3相同。
- en: ② The channel string from the account table
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: ② 来自账户表的渠道字符串
- en: ③ The country string from the account table
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 来自账户表的国别字符串
- en: ④ Subtracts the date of birth from the observation date
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 从观察日期中减去出生日期
- en: ⑤ JOINs with the account table
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 与账户表进行JOIN操作
- en: ⑥ Includes the demographic fields in the GROUP BY clause
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 在GROUP BY子句中包含人口统计字段
- en: 'You can run listing 10.6 on your own simulated social network dataset to create
    your own dataset file for the current customers by running the following command
    and these arguments:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过运行以下命令和这些参数在自己的模拟社交网络数据集上运行列表10.6来创建自己的当前客户数据集文件：
- en: '[PRE21]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The Python program that converts the raw data for current customers to versions
    that can be used for forecasting and segmenting is shown in listing 10.7\. Much
    of listing 10.7 is similar to the transformation that you saw in chapter 8, and
    it includes several helper functions from chapters 7, 8, and 10\. But listing
    10.7 also includes a few new steps to accommodate the demographic data.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.7展示了将当前客户的原始数据转换为可用于预测和分段的版本的Python程序。列表10.7的大部分内容与第8章中看到的转换类似，并包括第7章、第8章和第10章中的几个辅助函数。但列表10.7还包括一些新步骤以适应人口统计数据。
- en: The one important new technique in listing 10.7 is what I call aligning the
    dummy variables in the historical and current datasets. The Pandas `get_dummies`
    function (called from listing 10.4 `dummy_variables`) creates dummy variable columns
    for every category in the data frame, but the categories in the historical dataset
    and the current dataset may not match. Typically, the historical dataset has enough
    customer observations that you will see a rare category in a few customers, but
    the current dataset will have fewer customers and may not include any examples
    of the rare category. The result in that case would be that the historical dataset
    has a column that the current dataset does not have. This situation would cause
    a failure when you try to forecast churn probabilities on the current dataset.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.7中的一个重要新技术是我所说的在历史数据和当前数据集中对齐虚拟变量。Pandas的`get_dummies`函数（从列表10.4的`dummy_variables`调用）为数据框中的每个类别创建虚拟变量列，但历史数据集和当前数据集中的类别可能不匹配。通常，历史数据集有足够的客户观察结果，你会在几个客户中看到罕见的类别，但当前数据集将拥有更少的客户，可能不包含任何罕见类别的示例。在这种情况下，历史数据集将有一个当前数据集没有的列。这种情况会导致你在尝试在当前数据集上预测客户流失概率时失败。
- en: 'The same problem would happen if a category goes out of use historically and
    is no longer present in the current dataset. The reverse problem would occur if
    a new category comes into use: the historical dataset may lack the category, and
    only the current dataset includes it. In summary, aligning the categories does
    two things:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个类别在历史上不再使用且不再存在于当前数据集中，同样的问题会发生。如果新类别开始使用，则会出现相反的问题：历史数据集可能缺少该类别，而只有当前数据集包含它。总之，对齐类别做两件事：
- en: Adds to the current dataset, for any category in the historical data that is
    missing, a new dummy variables column containing zeros. This way, the current
    dataset is equivalent in its columns to the historical dataset, and zeros are
    the correct categorical value for a category of which no one is part.
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于历史数据集中缺失的任何类别，添加一个包含零的新虚拟变量列。这样，当前数据集在列上与历史数据集等效，零是无人参与的类别的正确分类值。
- en: Drops any categories from the dummy variables for the current dataset that were
    missing in the historical dataset. Again, this step aligns the columns in the
    historical and current datasets. If the category was not available in the historical
    dataset, you don’t know whether or how it’s predictive of churn, so removing it
    is correct for the purpose of forecasting.
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从当前数据集的虚拟变量中删除在历史数据集中缺失的任何类别。同样，此步骤使历史数据集和当前数据集中的列对齐。如果该类别在历史数据集中不可用，你不知道它是否以及如何预测客户流失，因此删除它是正确的预测目的。
- en: Overall, the main steps in listing 10.7 are
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，列表10.7中的主要步骤是
- en: 'Run the `dummy_variables` creation listing from earlier in this chapter (listing
    10.4), using the path to the current dataset. This code saves three versions of
    the data:'
  id: totrans-397
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从本章前面（列表10.4）运行`dummy_variables`创建列表，使用当前数据集的路径。此代码保存了数据的三种版本：
- en: Only the numeric fields for further processing by scoring and grouping
  id: totrans-398
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只有用于进一步评分和分组的数值字段
- en: Only the dummy variables to merge back together with the scores and groups later
  id: totrans-399
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只有用于稍后与分数和组合并的虚拟变量
- en: The numeric fields and dummy variables together, which is used by XGBoost (this
    file is saved from within the `dummy_variables` function)
  id: totrans-400
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数值字段和虚拟变量一起使用，这是XGBoost使用的（此文件是从`dummy_variables`函数中保存的）
- en: Load the dummy variables derived from the current dataset.
  id: totrans-401
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载从当前数据集派生的虚拟变量。
- en: Run the `align_dummies` helper function that takes care of inconsistencies between
    the two sets of dummy variables.
  id: totrans-402
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行`align_dummies`辅助函数，该函数负责处理两组虚拟变量之间的不一致性。
- en: 'Load the dataset with only numeric fields that were created from the current
    data by the `dummy_variables` function. Also load the loading matrix and score
    parameters created from the historical dataset. Run this current dataset through
    the reprocessing steps you learned in chapter 8:'
  id: totrans-403
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载由`dummy_variables`函数从当前数据创建的仅包含数值字段的数据集。同时加载从历史数据集创建的加载矩阵和分数参数。将此当前数据集通过你在第8章中学到的重新处理步骤运行：
- en: Transform any skewed columns.
  id: totrans-404
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转换任何偏斜的列。
- en: Transform any columns with fat tails.
  id: totrans-405
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转换任何具有厚尾的列。
- en: Rescale the data so all fields are scores with a mean near 0 and a standard
    deviation near 1.
  id: totrans-406
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新缩放数据，使所有字段都是接近0均值的分数，接近1的标准差。
- en: Combine any correlated metrics by using the loading matrix created on the historical
    data.
  id: totrans-407
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过使用在历史数据上创建的加载矩阵，结合任何相关的指标。
- en: Merge the dummy variables with the metric group and score data, and save this
    version of the dataset. This version can be used for forecasting churn probabilities
    for current customers.
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将虚拟变量与指标分组和得分数据合并，并保存此版本的数据集。这个版本可以用于预测当前客户的流失概率。
- en: 'Create the version of the dataset designed to be used by businesspeople for
    segmenting. This version of the dataset combines the following elements:'
  id: totrans-409
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个用于业务人员细分的数据集版本。此数据集版本结合以下元素：
- en: Scores for the grouped metrics
  id: totrans-410
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分组指标的得分
- en: The original (untransformed) metrics for those that are not grouped
  id: totrans-411
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 那些未分组的原始（未转换）指标
- en: The original strings (not the dummy variables) for the demographic categories
  id: totrans-412
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人口统计类别的原始字符串（而不是虚拟变量）
- en: Listing 10.1 Preparing a current customer dataset with demographic fields
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.1 准备包含人口统计字段的当前客户数据集
- en: '[PRE22]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: ① Runs the function dummy_variables on the current dataset
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: ① 在当前数据集上运行dummy_variables函数
- en: ② Calls helper function to align current dummies with historical ones
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: ② 调用辅助函数以将当前虚拟列与历史虚拟列对齐
- en: ③ Prepares the current data without categories
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 准备不带类别的当前数据
- en: ④ Merges the group score data with the dummy data
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 将分组得分数据与虚拟数据合并
- en: ⑤ Saves the result using the original dataset name
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 使用原始数据集名称保存结果
- en: ⑥ Uses the function to prepare the data for use in segmenting
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 使用该函数准备用于细分的数据
- en: ⑦ Makes a set from the file listing current dummy variables
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: ⑦ 从文件列出当前虚拟变量创建一个集合
- en: ⑧ Makes a set from the file listing original dummy variables
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: ⑧ 从文件列出原始虚拟变量创建一个集合
- en: ⑨ Set difference finds dummy columns in original but not current.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: ⑨ 差分设置发现原始数据中有虚拟列但当前数据中没有。
- en: ⑩ For any dummy missing in the new data, adds a column of zeros
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: ⑩ 对于新数据中缺失的任何虚拟变量，添加一个零列
- en: ⑪ Set difference finds dummy columns in current but not original.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: ⑪ 差分设置发现当前数据中有虚拟列但原始数据中没有。
- en: ⑫ Drops dummy columns in current but not original
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: ⑫ 在当前数据中删除但不在原始数据中的虚拟列
- en: ⑬ Group columns have more than one loading matrix entry.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: ⑬ 分组列有多个加载矩阵条目。
- en: ⑭ Standard metric columns have one loading matrix entry.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: ⑭ 标准指标列有一个加载矩阵条目。
- en: ⑮ Adds the category variable names to the list
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: ⑮ 将类别变量名称添加到列表中
- en: ⑯ Makes the segmenting data
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: ⑯ 创建细分数据
- en: 'You can run listing 10.7 with the Python wrapper program with the following
    command and these arguments:'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用以下命令和这些参数使用Python包装程序运行列表10.7：
- en: '[PRE23]'
  id: totrans-432
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This code creates three files for the current customer data for the purposes
    described previously:'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码为当前客户数据创建三个文件，用于之前描述的目的：
- en: Forecasting with regression
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用回归进行预测
- en: Forecasting with XGBoost
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用XGBoost进行预测
- en: Segmenting by businesspeople
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过业务人员进行细分
- en: 'If you want to forecast with the regression model, use listing 8.5 (with the
    filename listing_8_5_churn_forecast.py) with the following command and these parameters:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想使用回归模型进行预测，请使用列表8.5（文件名为listing_8_5_churn_forecast.py），使用以下命令和这些参数：
- en: '[PRE24]'
  id: totrans-438
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: If you want to forecast with the XGBoost model (with the filename listing_9_7_churn
    _forecast_xgb.py), use
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想使用XGBoost模型（文件名为listing_9_7_churn_forecast_xgb.py）进行预测，请使用
- en: '[PRE25]'
  id: totrans-440
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Regarding the dataset for segmenting customers that your business colleagues
    will use, it is important to realize that for businesspeople, demographic data
    is important even when it does not relate to churn and retention. The marketing
    department, for example, will need to write different copy for engagement campaigns
    targeting customers in different countries or regions. In a large organization,
    the marketing department probably has access to all of that kind of information
    through its own system, but I include everything here for the sake of completeness.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 关于你的业务同事将使用的客户细分数据集，重要的是要认识到，对于业务人员来说，即使与流失和保留无关，人口统计数据也很重要。例如，营销部门将需要为针对不同国家或地区的客户的不同参与活动编写不同的副本。在一个大型组织中，营销部门可能通过自己的系统访问所有这些信息，但我包括所有这些信息是为了完整性。
- en: TAKEAWAY Demographic information can be relevant to designing interventions
    with customers, even when it is not related to engagement and retention.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 吸收要点：即使与参与和保留无关，人口统计信息也可能与设计客户干预措施相关。
- en: Summary
  id: totrans-443
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Demographic and firmographic data are facts about the customers that do not
    change over time, like metrics. The type of demographic/firmographic fields can
    be date, numeric, or string.
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人口和公司数据是关于客户的事实，这些事实不会随时间改变，就像度量一样。人口/公司字段的类型可以是日期、数字或字符串。
- en: Date type information about customers can be converted to intervals and analyzed
    using the same techniques as metrics.
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户的日期类型信息可以转换为区间，并使用与度量相同的技巧进行分析。
- en: To compare the churn rate in cohorts defined by demographic category strings,
    you use confidence intervals that are best- and worst-case estimates for the churn
    rate.
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要比较由人口类别字符串定义的群体中的流失率，你使用的是对流失率的最优和最差估计的置信区间。
- en: Churn rates in different categories are said to be different by a statistically
    significant amount when the confidence intervals around their churn rates do not
    overlap.
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当围绕其流失率的置信区间不重叠时，说不同类别中的流失率有统计学上显著的差异。
- en: If you have many categories representing small percentages of the customer population,
    you should group related categories before analyzing them.
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你有很多类别代表占客户人口比例很小的部分，你应该在分析之前将这些相关类别分组。
- en: Grouping demographic categories is usually done using previous knowledge, and
    the mapping can be efficiently represented by using a dictionary.
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通常使用先验知识对人口类别进行分组，并且可以使用字典有效地表示这种映射。
- en: To use demographic categories in regression or machine learning forecasting,
    convert them to columns of binary dummy variables.
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要在回归或机器学习预测中使用人口类别，将它们转换为二元虚拟变量的列。
- en: Dummy variables are not grouped with metric scores, but investigating the correlation
    between dummy variables in metrics can provide useful information.
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虚拟变量不与度量得分分组，但调查度量中虚拟变量之间的相关性可以提供有用的信息。
- en: Using demographic information can improve forecasting accuracy, but it is usually
    a secondary contribution compared with behavior-based metrics.
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用人口信息可以提高预测准确性，但通常与基于行为的度量相比，它是一个次要的贡献。
