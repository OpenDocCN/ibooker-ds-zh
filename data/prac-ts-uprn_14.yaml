- en: Chapter 14\. Financial Applications
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第14章 金融应用
- en: Financial markets are the granddaddy of all time series data. If you pay for
    proprietary trading data on a high-tech exchange, you can receive terabyte-sized
    floods of data that can take days to process, even with high-performance computing
    and embarrassingly parallel processing.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 金融市场是所有时间序列数据的鼻祖。如果您在高科技交易所购买专有交易数据，您可以接收到大量数据，可能需要数天才能处理，即使使用高性能计算和尴尬并行处理也是如此。
- en: High-frequency traders are among the newest and most infamous members of the
    finance community, and they trade on information and insights resulting from time
    series analysis at the microsecond level. On the other hand, traditional trading
    firms—looking at longer-term time series over hours, days, or even months—continue
    to succeed in the markets, showing that time series analysis for financial data
    can be conducted in a myriad of successful ways and at timescales spanning many
    orders of magnitude, from milliseconds to months.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 高频交易者是金融界最新和最臭名昭著的成员之一，他们根据微秒级别的时间序列分析得出的信息和见解进行交易。另一方面，传统的交易公司——查看长期时间序列，例如几小时、几天甚至几个月——继续在市场上获得成功，表明金融数据的时间序列分析可以通过多种成功的方式和时间尺度进行，从毫秒到月份的数量级不等。
- en: Note
  id: totrans-3
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: '*Embarrassingly parallel* describes data processing tasks where the results
    of processing one segment of data are in no way dependent on the values of another
    segment of data. In such cases it’s embarrassingly easy to convert data analysis
    tasks to run in parallel rather than in sequence to take advantage of multicore
    or multimachine computing options.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '*尴尬并行* 描述了数据处理任务，其中处理一个数据段的结果与另一个数据段的值无关。在这种情况下，将数据分析任务转换为并行运行而不是顺序运行，以利用多核或多机计算选项是非常容易的。'
- en: Consider, for example, the task of computing the daily mean of minute-by-minute
    returns on a given stock. Each day can be treated separately and in parallel.
    In contrast, computing the exponentially weighted moving average of daily volatility
    is not embarrassingly parallel because the value for a particular day depends
    on the values for the days before it. Sometimes tasks that are not embarrassingly
    parallel can still be executed partly in parallel, but it depends on the details.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑计算给定股票的每日分钟级回报的日均值的任务。每天可以单独并行处理。相比之下，计算每日波动率的指数加权移动平均不是尴尬并行的，因为特定日的值取决于之前几天的值。有时候并不尴尬并行的任务仍然可以部分并行执行，但这取决于具体情况。
- en: 'Here, we will work through a classic example of time series analysis for fun
    and for profit: predicting tomorrow’s stock returns for the S&P 500.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将通过一个经典的时间序列分析示例来进行乐趣和盈利：预测标准普尔500指数明天的股票回报。
- en: Obtaining and Exploring Financial Data
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取和探索金融数据
- en: 'It can be exceedingly difficult to obtain financial data if you have a particular
    product or temporal resolution you are seeking. In such cases you usually need
    to buy data. But historical stock prices are widely available from a variety of
    services, including:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有特定产品或时间分辨率需要，获取金融数据可能非常困难。在这种情况下，通常需要购买数据。但是，历史股票价格可以从多种服务中广泛获取，包括：
- en: Yahoo Finance. While Yahoo has discontinued servicing its historical data API,^([1](ch14.html#idm45576014920792))
    historical daily data is [available for download](https://perma.cc/RQ6D-U4JX).
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 雅虎财经。虽然雅虎已停止服务其历史数据API，但可以[下载历史每日数据](https://perma.cc/RQ6D-U4JX)。^([1](ch14.html#idm45576014920792))
- en: Newer companies, such as [AlphaVantage](https://www.alphavantage.co/) and [Quandl](https://www.quandl.com)
    offer a combination of historical and real-time price information for stock data.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新公司，如[AlphaVantage](https://www.alphavantage.co/)和[Quandl](https://www.quandl.com)，提供股票数据的历史和实时价格信息的组合。
- en: 'We limit our analysis to freely available daily stock price data from Yahoo.
    We download data for the S&P 500 spanning dates from 1990 through 2019\. In the
    following code, we see what columns are available in the downloaded data set and
    plot the daily closing price to start exploring our data (see [Figure 14-1](#fig-1401)):'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将分析限制在从Yahoo获取的免费提供的每日股票价格数据上。我们下载了1990年至2019年的标准普尔500指数数据。在以下代码中，我们看到下载数据集中的可用列，并绘制每日收盘价来开始探索我们的数据（见[图14-1](#fig-1401)）：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We can see the values are notably different at the beginning and end of the
    date period covered by the CSV files. The change in values is even more apparent
    when we plot the full time series for the closing price ([Figure 14-2](#fig-1402))
    than it is when we look at samples from the data frame.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，在覆盖CSV文件日期周期的开始和结束时，值明显不同。当我们查看收盘价格的完整时间序列时（见 [图 14-2](#fig-1402)），这种价值变化比查看数据框中的样本时更为明显。
- en: A look at [Figure 14-2](#fig-1402) shows that the time series is not stationary.
    We also see that there may be different “regimes.” For reasons clearly seen in
    the plot, financial analysts are keen to develop models identifying regime shifts
    in stock prices. There appear to be different regimes even if we may not have
    an exact definition of where one ends and another begins.^([2](ch14.html#idm45576014813576))
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 查看 [图 14-2](#fig-1402) 可以发现，该时间序列不是平稳的。我们还可以看到可能存在不同的“制度”。由于图中清晰可见的原因，金融分析师热衷于开发识别股票价格制度转变的模型。即使我们可能没有确切的定义，不同的制度似乎存在于这些转变之间[^2]。
- en: '![](assets/ptsa_1401.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ptsa_1401.png)'
- en: Figure 14-1\. Raw data from the beginning and end of the CSV file. Notice that
    the values change noticeably from 1990 to 2019—no surprise to anyone familiar
    with the history of the US financial markets.
  id: totrans-16
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14-1\. CSV文件起始和结束时的原始数据。注意，从1990年到2019年，值有明显变化——对熟悉美国金融市场历史的人来说并不奇怪。
- en: '![](assets/ptsa_1402.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ptsa_1402.png)'
- en: Figure 14-2\. The daily closing price of the S&P 500 is not a stationary time
    series.
  id: totrans-18
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14-2\. 标准普尔500指数的日收盘价格不是平稳的时间序列。
- en: The potential for change points and different regimes suggests that it could
    be a good idea to break the data set into different sub-data sets to be modeled
    separately. However, we want to keep all the data together because daily data
    does not produce many data points in a few decades; we need to keep all the data
    we can. We consider whether we can justify keeping all this data together if we
    are only interested in day-ahead forecasts.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 变化点和不同制度的潜力表明，将数据集分成不同的子数据集进行单独建模可能是个好主意。然而，我们希望保持所有数据在一起，因为几十年来的日数据并不产生很多数据点；我们需要尽可能保留所有数据。我们考虑，即使我们只对未来一天的预测感兴趣，我们是否能够证明保持所有这些数据是合理的。
- en: 'We can consider whether normalizing data can make data from different time
    periods comparable. Let’s take a look at a week’s worth of scaled closing prices
    for three different decades within the time series ([Figure 14-3](#fig-1403)):'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以考虑是否归一化数据可以使不同时间段的数据可比。让我们看看在时间序列内三个不同十年的一周内缩放后的收盘价格（见 [图 14-3](#fig-1403)）：
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We plot closing prices over three weeks in three different decades, each scaled
    by that week’s mean as per the preceding code. The relative percentage changes
    from day to day in the course of a week seem about the same across the decades.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们绘制了三个不同十年内三周的收盘价，每个周的均值如前述代码所示。在一周内，每天之间的相对百分比变化似乎在几个十年间都大致相同。
- en: These plots are promising. While the mean values and variance of the closing
    prices have changed substantially over time, the plots suggest similar behavior
    over time once we normalize the data to its mean value for a given decade.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这些图表显示了很大的希望。虽然收盘价格的均值和方差随时间变化很大，但图表表明一旦我们将数据归一化到给定十年的均值，随时间的行为趋势相似。
- en: Given this, we next consider whether we can find a way to make all data over
    the full time period similar enough to train meaningfully with a model. We want
    to know whether there is a way to transform the data that is financially meaningful
    but also makes the data comparable across the entire time period.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于此，我们接下来考虑是否可以找到一种方法使整个时间段内的所有数据足够相似，以便用模型进行有意义的训练。我们想知道是否有一种方法可以转换数据，在金融上有意义的同时使整个时间段的数据可比。
- en: '![](assets/ptsa_1403.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ptsa_1403.png)'
- en: Figure 14-3\. Scaled mean closing prices for a week in May 1990, 2000, and 2018.
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14-3\. 1990年、2000年和2018年5月的一周均值缩放后的收盘价格。
- en: 'We compute the daily return, that is, the change in price from the start to
    the end of each trading day (see [Figure 14-4](#fig-1404)):'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们计算每个交易日的日收益率，即从每个交易日开始到结束的价格变动（见 [图 14-4](#fig-1404)）：
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As we can see in [Figure 14-4](#fig-1404), this alone is not enough to make
    the data comparable. We will also have to find a way to normalize the data without
    a lookahead so that the values we are using for inputs and outputs into our model
    are more even throughout the time period of interest. We will see how to do this
    in the next section.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[图14-4](#fig-1404)中看到的，单独这还不足以使数据可比较。我们还必须找到一种方法，在没有前瞻性的情况下对数据进行归一化，以便我们用于模型的输入和输出值在感兴趣的时间段内更加均匀。我们将在下一节中看到如何做到这一点。
- en: '![](assets/ptsa_1404.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ptsa_1404.png)'
- en: Figure 14-4\. Daily returns show a near-zero mean over time, but the variance
    of daily returns changes markedly in different time periods. It is behavior like
    this that has inspired models such as GARCH, which was briefly discussed in [Chapter 6](ch06.html#statistical_model_for_time_series).
  id: totrans-31
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图14-4。每日收益显示随时间几乎为零的均值，但每日收益的方差在不同时间段明显变化。正是这种行为启发了GARCH等模型的发展，这在[第6章](ch06.html#statistical_model_for_time_series)中简要讨论过。
- en: Preprocessing Financial Data for Deep Learning
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习的财务数据预处理
- en: 'Our data preprocessing will be done in three steps:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据预处理将分三个步骤完成：
- en: We will form new, economically meaningful quantities of interest out of the
    raw inputs.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将从原始输入中形成新的经济意义上的感兴趣的数量。
- en: We will compute an exponentially weighted moving average and variance of the
    quantities of interest so that we can scale them without a lookahead.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将计算感兴趣的数量的指数加权移动平均和方差，以便我们可以在没有前瞻性的情况下对其进行缩放。
- en: We will package our results in a format appropriate for the recurrent deep learning
    model we will use to fit the data.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将把我们的结果打包成适合我们将用于拟合数据的递归深度学习模型的格式。
- en: Financial Time Series Is Its Own Discipline
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 金融时间序列是其自身的学科
- en: Financial time series is an entire discipline with thousands of academics diligently
    trying to understand how the financial markets work, both for profit and for smart
    regulation. There are numerous statistical models that have been developed to
    treat some of the tricky aspects of financial data that we have touched on here,
    such as the GARCH model. If you are seeking to apply statistics and machine learning
    to financial time series modeling, you should study the history of quantitative
    finance and the major classes of commonly deployed models.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 金融时间序列是一个整体学科，数千名学者在勤奋地努力理解金融市场的运作，无论是出于利润还是智能监管。已经开发了许多统计模型来处理我们在这里涉及的金融数据的一些棘手方面，例如GARCH模型。如果您希望将统计学和机器学习应用于金融时间序列建模，您应该研究量化金融的历史以及常用模型的主要类别。
- en: Adding Quantities of Interest to Our Raw Values
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加感兴趣的数量到我们的原始数值
- en: 'We’ve already computed daily return in the previous section. Another quantity
    of interest we can form from the raw inputs is daily *volatility*, which is the
    difference between the highest and lowest prices recorded during the trading day.
    This can be easily computed given the raw data (see [Figure 14-6](#fig-1406)):'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在前一节中计算了每日收益。我们可以从原始输入中形成的另一个感兴趣的数量是每日*波动率*，即在交易日内记录的最高和最低价格之间的差异。给定原始数据，这可以很容易地计算出来（见[图14-6](#fig-1406)）：
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Just as the daily return prices are a nonstationary time series, so too is the
    daily volatility time series. This further confirms that we need to find a way
    to scale these appropriately. We also want to do so without introducing a lookahead.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 就像每日收益价格是非平稳时间序列一样，每日波动率时间序列也是如此。这进一步确认了我们需要找到一种适当的方法来进行适当的缩放。我们还希望这样做而不引入前瞻性。
- en: '![](assets/ptsa_1406.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ptsa_1406.png)'
- en: Figure 14-6\. Daily volatility is a positive value time series (by definition)
    that shows noticeably different degrees of variance at different points in the
    S&P 500 time series.
  id: totrans-44
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图14-6。每日波动率是一个正值时间序列（根据定义），在标准普尔500指数时间序列的不同点显示出显著不同的方差。
- en: Scaling Quantities of Interest Without a Lookahead
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在没有前瞻性的情况下扩展感兴趣的数量
- en: 'We will forecast the daily return one day ahead. Some quantities of interest
    that could be helpful include:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将预测未来一天的每日收益。一些可能有帮助的感兴趣的数量包括：
- en: Previous daily returns
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 先前的每日收益
- en: Previous daily volatility
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 先前的每日波动率
- en: Previous daily volume
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 先前的每日成交量
- en: We will scale each of these quantities by subtracting out the exponentially
    weighted moving average and then dividing by the exponentially weighted standard
    deviation. Our earlier weekly data exploration showed that with appropriate preprocessing
    the various quantities of interest can be made into stationary time series.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过减去指数加权移动平均值然后除以指数加权标准差来缩放这些量中的每一个。我们早期的每周数据探索显示，通过适当的预处理，我们感兴趣的各种量可以变成平稳的时间序列。
- en: 'First we compute the exponentially weighted moving average of every column
    in the data frame, and plot the daily volatility’s exponentially weighted moving
    average (see [Figure 14-8](#fig-1408)). Contrast this with the plot in [Figure 14-7](#fig-1407).
    This plot is much smoother due to the averaging. Note that there is a parameter
    here that you should effectively consider part of your model, as a hyperparameter,
    even though it’s used in the data preprocessing step: the half-life of the exponential
    smoothing. Your model’s behavior will certainly depend on this parameter:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们计算数据帧中每列的指数加权移动平均，并绘制每日波动率的指数加权移动平均值（参见[图 14-8](#fig-1408)）。与[图 14-7](#fig-1407)中的图相比，这个图更加平滑，因为有了平均化效果。请注意，这里有一个参数，你应该将其有效地考虑为模型的一部分，作为超参数，尽管它用于数据预处理步骤中：指数平滑的半衰期。你的模型行为肯定会依赖于这个参数：
- en: '[PRE4]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](assets/ptsa_1407.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ptsa_1407.png)'
- en: Figure 14-7\. The plot of the exponentially weighted moving average of daily
    volatility is much smoother than the plot of the raw values but still shows a
    nonstationary time series.
  id: totrans-54
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14-7\. 每日波动率的指数加权移动平均图比原始值的图更加平滑，但仍显示出非平稳的时间序列。
- en: 'We can then use that value, as well as the exponentially weighted moving variance
    calculated here, to scale values of interest in a way that results in series with
    more consistent behavior over time (see [Figure 14-8](#fig-1408)):'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这个值，以及在此处计算的指数加权移动方差，按一种方式缩放感兴趣的值，以便产生随时间更一致行为的系列（参见[图 14-8](#fig-1408)）：
- en: '[PRE5]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](assets/ptsa_1408.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ptsa_1408.png)'
- en: Figure 14-8\. Transforming the data with exponentially weighted mean and variance
    results in a much more even time series with comparable values throughout the
    time period all the way from 1990 to 2019.
  id: totrans-58
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14-8\. 使用指数加权平均和方差转换数据会得到一个时间序列更加平稳的结果，从1990年到2019年整个时间段内的值可比性很高。
- en: 'We transform all three raw inputs of interest into a scaled version as follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将感兴趣的三个原始输入转换为如下的缩放版本：
- en: '[PRE6]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Finally, we drop the `NA` results that come from exponential smoothing:^([3](ch14.html#idm45576014059992))
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们丢弃由指数平滑产生的`NA`结果：^([3](ch14.html#idm45576014059992))
- en: '[PRE7]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Formatting Our Data for a Neural Network
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为神经网络格式化我们的数据
- en: Our data is stored in a Pandas data frame at the moment, and our planned inputs
    are stored alongside many raw inputs we have no intention of using. Also, for
    a neural network we will shape our data into the TNC format, which, you might
    recall, stands for time × number of samples × channels. For this reason we need
    to do some more preprocessing even after the rescaling work we have already discussed.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 目前我们的数据存储在一个Pandas数据帧中，我们计划的输入与许多我们不打算使用的原始输入一起存储。另外，对于神经网络，我们将把我们的数据格式化为TNC格式，你可能还记得，这代表时间
    × 样本数 × 通道数。因此，即使在我们已经讨论过的重新缩放工作之后，我们仍需要进行一些预处理。
- en: First we portion out our data into training and testing components:^([4](ch14.html#idm45576013934088))
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将数据分为训练和测试组件：^([4](ch14.html#idm45576013934088))
- en: '[PRE8]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Notice there is something of a problem with what we are predicting based on
    how we set up `Y` here. Think about this for a minute before you continue reading.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在我们这里设置`Y`的基础上，存在一些问题。在继续阅读之前，请花一分钟思考一下这个问题。
- en: The problem with this setup is that the `Y` value is the scaled return rather
    than just the return. This is better for training because the values fall within
    the appropriate range, but it also means that the `Y` we are predicting is not
    the actual return that interests us but rather that return adjusted by a moving
    average. We are forecasting how much our return differs from the exponentially
    weighted moving average rather than just predicting the return.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这个设置的问题在于`Y`值是缩放后的回报，而不仅仅是回报。这对训练更好，因为值落在适当的范围内，但这也意味着我们预测的`Y`并不是我们感兴趣的实际回报，而是由移动平均调整过的回报。我们在预测时是在预测我们的回报与指数加权移动平均的差异。
- en: This is not wrong per se, but it does mean that we are making our task easier
    than the true forecasting task. We should be aware of this so that when our training
    looks better than our model’s actual performance, we’ll know it’s partly because
    in training we focus on a hybrid task, whereas ultimately making money off this
    model would depend only on the true forecasting.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，这并不是错的，但这意味着我们让任务变得比真正的预测任务更容易。我们应该意识到这一点，因此当我们的训练看起来比我们模型实际表现更好时，我们知道这部分原因是因为在训练中，我们关注一个混合任务，而最终要通过这个模型赚钱只取决于真正的预测。
- en: We focus on the training data and now need to put `X` into the format expected
    by a recurrent neural network architecture, namely TNC. We do this with a series
    of NumPy operations.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们专注于训练数据，现在需要将`X`放入递归神经网络架构所期望的TNC格式中。我们通过一系列NumPy操作来实现这一点。
- en: 'Originally, `X` is two-dimensional, as it comes from a Pandas data frame. We
    want to add a third dimension, axis 1 (so pushing the second dimension out to
    axis 2, where the axes are numbered from 0 up):'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，`X`是二维的，因为它来自Pandas数据框架。我们想添加第三个维度，即轴1（因此将第二个维度推到轴2，其中轴从0开始编号）：
- en: '[PRE9]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Our temporal axis is already axis 0 because the data frame was sorted temporally.
    The last axis, now axis 2, is already the “channel axis” because our inputs each
    occupy one column of that dimension.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的时间轴已经是轴0，因为数据框架已按时间排序。最后一个轴，现在是轴2，已经是“通道轴”，因为我们的每个输入占据该维度的一列。
- en: We will try a model that will see 10 time steps—that is 10 days of data looking
    backward. So we need to cut off axis 0 to be of length 10\. We chop along axis
    0 every 10 rows, and we reform the resulting list of submatrices such that the
    number of samples (i.e., length of the resulting list) becomes the dimension of
    the second axis:^([5](ch14.html#idm45576013794584))
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将尝试一个模型，它将看到10个时间步长——即向后查看10天的数据。因此，我们需要截断轴0以长度为10。我们每10行沿轴0进行切片，并重新组合产生的子矩阵列表，使得样本数量（即生成列表长度）成为第二轴的维度:^([5](ch14.html#idm45576013794584))
- en: '[PRE10]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Given the TNC format, we have time series of length 10, with three parallel
    inputs. Of these we have 699 examples. The batch size will determine how many
    batches make up an epoch, where an epoch is one cycle through our data.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 根据TNC格式，我们有长度为10的时间序列，具有三个并行输入。这些中有699个示例。批量大小将决定一个epoch由多少批组成，其中一个epoch是对我们数据的一个循环。
- en: We don’t have very much data to train on, given how few examples we appear to
    have. How did we go from 30 years of data to not much data? The answer is that
    each data point has, as of now, only been included in one sample time series.
    However, each data point could be in 10 different time series, occupying a different
    position in each one.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于我们似乎只有很少的示例，我们没有太多数据可以训练。我们是如何从30年的数据变得没有多少数据的呢？答案是，目前每个数据点仅包含在一个样本时间序列中。但是，每个数据点可以在10个不同的时间序列中，每个时间序列占据不同的位置。
- en: 'This may not be immediately obvious, so let’s look at a simple example. Assume
    we have the following time series:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能不是显而易见的，因此让我们看一个简单的例子。假设我们有以下时间序列：
- en: 1, 3, 5, 11, 3, 2, 22, 11, 5, 7, 9
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 1, 3, 5, 11, 3, 2, 22, 11, 5, 7, 9
- en: 'We want to train a neural network with this time series, this time assuming
    a time window of length 3\. If we use the data preparation we just performed,
    our time series examples would be:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望用这个时间序列训练一个神经网络，这次假设时间窗口长度为3。如果使用我们刚刚执行的数据准备，我们的时间序列示例将是：
- en: 1, 3, 5
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1, 3, 5
- en: 11, 3, 2
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 11, 3, 2
- en: 22, 11, 5
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 22, 11, 5
- en: 7, 9, _
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 7, 9, _
- en: 'However, there is no reason to privilege the start of our data as somehow having
    to set the beginnings and ends of each sample time series. The windows are arbitrary.
    Some equally valid time series, sliced out of the whole in a window, are:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，并没有理由特别偏向我们的数据的起始点，好像必须设定每个样本时间序列的开始和结束。这些窗口是任意的。一些同样有效的时间序列，从整体中以窗口切出来，包括：
- en: 3, 5, 11
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3, 5, 11
- en: 2, 22, 11
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2, 22, 11
- en: 5, 7, 9
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 5, 7, 9
- en: So if we needed more data, we would be well served to generate time series samples
    as we slid a window over the entire data set. That would produce more individual
    time series samples than we have done with our method of chopping the data into
    non-overlapping time series samples. Keep this in mind when preparing your own
    data sets. Below, you will see we use this sliding window method to preprocess
    our data.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们需要更多数据，最好生成时间序列样本，因为我们在整个数据集上滑动窗口，这将产生比我们通过将数据切成不重叠时间序列样本所做的更多的个体时间序列样本。在准备自己的数据集时请记住这一点。下面，您将看到我们使用这种滑动窗口方法预处理我们的数据。
- en: Building and Training an RNN
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建立和训练一个递归神经网络
- en: 'As mentioned in the introduction to this chapter, financial time series are
    notoriously difficult to model and understand. Even as the finance industry continues
    to be a mainstay of the Western economy, experts agree that predictions are very
    difficult to make. For this reason, we look for a technique that is well suited
    for a complicated system with potentially nonlinear dynamics, namely a deep learning
    neural network. However, due to our lack of data, we choose a simple recurrent
    neural network (LSTM) architecture and training regime described by these parameters:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章开头提到的，金融时间序列模型和理解通常是非常困难的。尽管金融行业继续是西方经济的支柱，专家们一致认为预测是非常困难的。因此，我们寻找一种适合于具有潜在非线性动态的复杂系统的技术，即深度学习神经网络。然而，由于我们缺乏数据，我们选择了一个简单的递归神经网络（LSTM）架构和训练方案，具体由以下参数描述：
- en: '[PRE11]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'In contrast to [Chapter 10](ch10.html#dl_for_time_series_chapter), we use the
    TensorFlow package rather than MXNet so you can see another example of a widely
    used deep learning framework. In TensorFlow, we define variables for all the quantities
    we will use in our network, even with changing values that represent inputs. For
    the inputs we use `placeholders`, which are a way of letting the graph know what
    shape to expect:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 与[第 10 章](ch10.html#dl_for_time_series_chapter)相比，我们使用的是 TensorFlow 软件包而不是 MXNet，这样你就可以看到另一个广泛使用的深度学习框架示例。在
    TensorFlow 中，我们为网络中使用的所有量定义变量，即使是具有代表输入的变化值。对于输入，我们使用 `placeholders`，这是一种让图形知道期望形状的方法：
- en: '[PRE12]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Then we build our network and implement loss calculation and optimization steps:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们构建我们的网络并实现损失计算和优化步骤：
- en: '[PRE13]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We have a fairly complicated way of feeding in the data due to what we discussed
    earlier, namely that each data point should be in multiple time series depending
    on which offset we use. Here we treat the same data formatting problem we discussed
    at greater length in [Chapter 10](ch10.html#dl_for_time_series_chapter):'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们早前讨论过的原因，我们有一种相当复杂的数据输入方式，即每个数据点应该位于多个时间序列中，这取决于我们使用的偏移量。在这里，我们处理了与[第 10 章](ch10.html#dl_for_time_series_chapter)中详细讨论的相同的数据格式化问题：
- en: '[PRE14]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Here we see our training and testing metrics:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们看到我们的训练和测试指标：
- en: '[PRE15]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The error metric we chose does not give us an idea of how well our overall
    data matches the results, so plotting is helpful. We plot both out-of-sample performance
    (important) and in-sample performance (less important), as shown in [Figure 14-9](#fig-1409):'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择的误差度量标准并不能告诉我们整体数据与结果的匹配情况，所以绘图是有帮助的。我们绘制了在样本外表现（重要）和样本内表现（不那么重要），如 [图 14-9](#fig-1409)
    所示：
- en: '[PRE16]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![](assets/ptsa_1409.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ptsa_1409.png)'
- en: Figure 14-9\. The actual return values for a subsection of the test period (solid
    line) are plotted against the forecasts from the neural network (dashed line).
    The scale of the forecast is so different from the actual data that it’s difficult
    to assess the model.
  id: totrans-104
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14-9\. 测试期间某一子段的实际返回值（实线）与神经网络预测（虚线）的绘图。预测的尺度与实际数据非常不同，这使得评估模型变得困难。
- en: 'We can see that our predicted values for the returns don’t tend to be at the
    same value as the actual returns. We check the Pearson correlation next:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，我们对收益的预测值通常与实际收益不一致。接下来我们检查皮尔逊相关性：
- en: '[PRE17]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: These numbers might look grim if you haven’t already worked with financial time
    series. In this industry, our model may be useful despite the plot and despite
    the *p*-value. In finance, a correlation that is positive is exciting and something
    that can be improved upon incrementally. In fact, many research projects, when
    starting out, can’t necessarily get to such “high” correlations.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你之前没有处理过金融时间序列，这些数字可能看起来令人沮丧。在这个行业中，尽管有图表和 *p* 值，我们的模型可能仍然有用。在金融领域，一个正相关的结果是令人兴奋的，而且可以逐步改进。实际上，许多研究项目在起步时并不能达到这样的“高”相关性。
- en: 'We can get a better idea of whether the predictions at least go in the same
    direction by scaling the predicted returns up an order of magnitude and plotting
    again ([Figure 14-10](#fig-1410)):'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将预测收益扩大一个数量级并再次绘图，来更好地了解预测是否至少在同一个方向上变化 ([图 14-10](#fig-1410))：
- en: '[PRE18]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![](assets/ptsa_1410.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ptsa_1410.png)'
- en: Figure 14-10\. A better sense of how the model’s predictions (dashed line) compare
    to the actual data (solid line). However, with such a low correlation we are more
    likely to think we see a pattern than to actually see one. For this reason, quantitative
    metrics will serve us better than visual assessments for noisy financial data.
  id: totrans-111
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14-10\. 更好地理解模型预测（虚线）与实际数据（实线）的比较。然而，由于相关性很低，我们更可能认为看到了某种模式，而实际上并非如此。因此，对于嘈杂的金融数据，定量指标比视觉评估更有用。
- en: 'If you have read blogs about using deep learning for financial time series,
    you may very well find the performance here disappointing. For example, you have
    likely seen blog posts where someone applies a simple multilayer LSTM to some
    daily stock data and produces predictions that look almost identical to the actual
    stock market data, even out of sample. There are two important reasons those results
    may look good but are actually not impressive:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经阅读过有关使用深度学习处理金融时间序列的博客，您很可能会发现这里的表现令人失望。例如，您可能已经看到某人将简单的多层LSTM应用于某些日常股票数据，并产生几乎与实际股市数据相同的预测，即使是在样本外。这些结果看起来不错，但实际上并不令人印象深刻的原因有两个重要的原因：
- en: Preprocessing the code to scale it with an out-of-the-box scaling solution such
    as `sklearn.preprocessing.MinMaxScaler`. This is not ideal because it includes
    a lookahead by using the values across all time to scale data.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对代码进行预处理，使用像`sklearn.preprocessing.MinMaxScaler`这样的开箱即用的缩放解决方案来调整代码规模。这并不理想，因为它包含了使用所有时间段的值来缩放数据的前瞻性。
- en: Predicting price rather than returns. This is a much easier task—for starters,
    an excellent prediction of price on day *T* + 1 is price on day *T*. Thus, it’s
    easy to build a model that appears to predict price reasonably well and makes
    impressive graphs. Unfortunately, such models can’t be used to make money.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测价格而不是收益。这是一个更容易的任务——首先，对于第 *T* + 1 天的价格的出色预测是第 *T* 天的价格。因此，很容易构建一个似乎能够合理预测价格并生成令人印象深刻图表的模型。不幸的是，这种模型不能用来赚钱。
- en: We have attempted a more realistic industry example, which means the challenge
    is greater and the plots won’t be as satisfying.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尝试了一个更真实的行业示例，这意味着挑战更大，而结果图形不会那么令人满意。
- en: Needless to say, we haven’t completed a full analysis of the model’s performance.
    Doing so would give us insight into how to build our next model, what we might
    have overlooked, and whether a deep learning model can justify its additional
    complexity relative to a linear model. There are a lot of paths to take from here
    to improve model performance.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 毫无疑问，我们尚未对模型的性能进行全面分析。这样做将为我们提供洞察，以便建立下一个模型，了解我们可能忽视的问题，并确定深度学习模型在相对于线性模型的额外复杂性是否合理。从这里出发，有许多改进模型性能的途径。
- en: 'There are many ways we can improve this model, which you should consider as
    extensions of this code:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多方法可以改进此模型，您应该将其视为此代码的扩展：
- en: Add more inputs from the raw data by generating additional features based on
    these inputs. We did not use all the raw input columns, and there are other ways
    to re-express these quantities that could be useful. You might consider categorical
    variables, such as “Did the high or the low for the day coincide with the opening
    or closing?” (there are several binary conditions packed into that one question).
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过基于这些输入生成附加特征来从原始数据中添加更多输入。我们没有使用所有原始输入列，还有其他重新表达这些数量的方法可能会有用。您可以考虑分类变量，例如“当天高点或低点是否与开盘或收盘一致？”（这个问题中包含了几个二元条件）。
- en: Integrate parallel time series for other stocks. This will add further information
    and data to train on.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成其他股票的并行时间序列。这将增加进一步的信息和数据用于训练。
- en: Use data at several different timescales. One widely cited paper that does this
    discusses an architecture called [ClockworkRNN](https://perma.cc/9C62-7GFK).
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用几个不同的时间尺度的数据。一篇广泛引用的论文讨论了一个名为[ClockworkRNN](https://perma.cc/9C62-7GFK)的架构。
- en: Augment your data by taking existing time series examples and adding jitter.
    This will help with the fact that this data set does not offer much data.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过采用现有时间序列示例并添加抖动来增强您的数据。这将有助于解决这组数据提供的数据不足的问题。
- en: Allow your network architecture to grow if you have scaled up the number of
    inputs or the amount of data. A more complicated architecture is not always a
    way to improve performance, but it can be appropriate if you see that your network
    is topping out.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您已经扩展了输入数量或数据量，请允许您的网络架构增长。更复杂的架构并不总是提高性能的方法，但如果您发现网络性能达到了极限，则可能是适当的选择。
- en: Try training the data in chronological order, rather than our approach of cycling
    through the data several times per epoch. Sometimes this be quite helpful (but
    it depends on the data set). Given that we saw the behavior of time series change
    over time, it might be better to end training with the last data last so that
    the changed behavior is reflected in the weights.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试按时间顺序训练数据，而不是我们每个epoch循环多次数据的方法。有时这可能非常有帮助（但这取决于数据集）。鉴于我们看到时间序列行为随时间变化，可能更好地以最后数据来结束训练，以便权重反映出行为的变化。
- en: 'Consider different loss functions. Here we used an L2 norm, which tends to
    punish larger differences much more than small differences. Given the domain,
    however, we might want to evaluate success differently. Perhaps we just want to
    get the predicted sign of the daily return right and not worry so much about its
    magnitude. In this case we could consider setting the targets as categorical variables:
    positive, negative, zero. In the case of categorical data, we usually want to
    use a cross-entropy measure of loss. However, given that this is not purely categorical
    data, since it’s ranked (that is, zero is closer to negative than positive is
    to negative), we might want to use a custom loss function to reflect this.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑不同的损失函数。这里我们使用了L2范数，它倾向于比小差异更严重地惩罚大差异。然而，鉴于领域的不同，我们可能希望以不同的方式评估成功。也许我们只想正确预测每日回报的符号，而不太关心其大小。在这种情况下，我们可以考虑将目标设定为分类变量：正、负、零。对于分类数据，通常我们希望使用交叉熵损失度量。然而，由于这并不是纯粹的分类数据，而是排名的（即零更接近于负而不是正更接近于负），我们可能希望使用自定义损失函数来反映这一点。
- en: Consider building an ensemble of simple neural networks rather than a single
    one. Keep each individual network small. Ensembles are particularly useful for
    low signal-to-noise data, such as financial data.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑构建一组简单的神经网络集成，而不是单个的。保持每个单独的网络较小。集成对于低信噪比数据特别有用，例如金融数据。
- en: Determine why the scale of the forecasts is so different from the scale of the
    actual values. Consider starting by assessing whether the loss function we used
    is problematic given the strong preponderance of zero value daily returns.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定为什么预测的规模与实际值的规模如此不同。考虑首先评估我们使用的损失函数是否存在问题，考虑到每日收益强烈倾向于零值。
- en: As you can see, there are myriad ways to improve a network’s performance or
    tune its functionality. How you do so will depend on the data set. It is always
    helpful to use visualizations of your network’s performance, domain knowledge,
    and a firmly defined goal (which in this case is likely “make money”) to drive
    how you refine your model. Otherwise, you can easily get lost in the overwhelming
    number of choices you have.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，有很多方法可以改进网络的性能或调整其功能。如何做取决于数据集。始终使用网络性能的可视化、领域知识和明确定义的目标（在这种情况下可能是“赚钱”）来推动你精细调整模型的方式是非常有帮助的。否则，你可能会在大量的选择中迷失方向。
- en: More Resources
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多资源
- en: 'Joumana Ghosn and Yoshua Bengio, [“Multi-Task Learning for Stock Selection,”](https://perma.cc/GR7A-5PQ5)
    Cambridge: MIT Press, 1996, https://perma.cc/GR7A-5PQ5.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 朱曼娜·戈斯恩和约书亚·本吉奥，《股票选择的多任务学习》，剑桥：麻省理工学院出版社，1996年，https://perma.cc/GR7A-5PQ5。
- en: This 1997 paper provides a very early example of applying a neural network to
    the problem of financial markets. In this case, the author used what would now
    be considered a quite simple network with minimal data, but they nonetheless found
    their network could learn to pick stocks profitably. Interestingly, this is also
    an early example of multitask learning.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇1997年的论文提供了将神经网络应用于金融市场问题的一个非常早期的例子。在这种情况下，作者使用了现在被认为是相当简单的网络和最少的数据，但他们仍然发现他们的网络能够盈利地选择股票。有趣的是，这也是多任务学习的早期例子之一。
- en: Lawrence Takeuchi and Yu-Ying Lee, [“Applying Deep Learning to Enhance Momentum
    Trading Strategies in Stocks,”](https://perma.cc/GJZ5-4V6Z) 2013, https://perma.cc/GJZ5-4V6Z.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 劳伦斯·竹内和李宇莹，《应用深度学习增强股票动量交易策略》，2013年，https://perma.cc/GJZ5-4V6Z。
- en: In this paper, the authors interpret their neural network through the lens of
    “momentum training”, a traditional way of quantitatively forecasting the financial
    markets in a pre-machine learning world. This paper is interesting for its discussion
    of how training decisions were made and model performance evaluated.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇论文中，作者通过“动量训练”的视角解释了他们的神经网络，这是在机器学习之前量化预测金融市场的传统方式。该论文对于其讨论如何做出训练决策和评估模型性能是很有趣的。
- en: '[“Is anyone making money by using deep learning in trading?”](https://perma.cc/Z8C9-V8FX)
    *Quora*, https://perma.cc/Z8C9-V8FX.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[“有人在交易中使用深度学习赚钱吗？”](https://perma.cc/Z8C9-V8FX) *Quora*, https://perma.cc/Z8C9-V8FX.'
- en: In this question and answer, we see a variety of opinions regarding the extent
    to which deep learning has been successful in financial applications. As described
    in some of the answers, any profitable IP would likely be heavily protected by
    non-disclosure agreements and the profit incentive so that in this industry it
    can be very difficult to assess what state-of-the-art performance is. The answers
    also point to a wide rang of potential financial applications - predicting returns
    is just one problem among many.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个问题和答案中，我们看到了关于深度学习在金融应用中成功程度的各种观点。正如一些答案所描述的那样，任何盈利的知识产权可能会受到严格的保密协议和利润激励的保护，在这个行业中很难评估目前的最先进性能。答案还指出了一系列潜在的金融应用——预测回报只是众多问题中的一个。
- en: ^([1](ch14.html#idm45576014920792-marker)) Incidentally, this created quite
    a bit of nonworking code in the R and Python communities.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch14.html#idm45576014920792-marker)) 顺便提一句，这在 R 和 Python 社区中产生了相当多的无效代码。
- en: ^([2](ch14.html#idm45576014813576-marker)) Note that the S&P 500 is also tricky
    because it is a composite of many different stocks as inputs, with weightings
    periodically adjusted and with a factor that is entirely proprietary also used
    to divide the weighted average of the stocks. For this reason, strong domain knowledge
    and an understanding of how different actions taken by companies can affect their
    stock prices and their S&P 500 weightings would also be important to better understand
    the long-term behavior we see here.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch14.html#idm45576014813576-marker)) 注意，标准普尔 500 指数也很棘手，因为它是许多不同股票的组合作为输入，其权重定期调整，并且完全专有的因子也用于划分股票的加权平均值。因此，强大的领域知识和对公司采取不同行动如何影响其股票价格及其标准普尔
    500 权重的理解，也是更好地理解我们在此看到的长期行为的重要因素。
- en: ^([3](ch14.html#idm45576014059992-marker)) Instead of dropping these, we could
    also set the value of the exponentially smoothed column to the only value known
    at that time. In either case, this is not important.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch14.html#idm45576014059992-marker)) 我们可以选择不舍弃它们，而是将指数平滑列的值设置为当时已知的唯一值。无论哪种情况，这都不重要。
- en: ^([4](ch14.html#idm45576013934088-marker)) The usual caveat that we should really
    have a separate validation set to avoid information leaking backward from the
    test set applies here, but I’m trying to keep the code simple.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch14.html#idm45576013934088-marker)) 我们通常应该有一个单独的验证集，以避免信息从测试集向后泄漏，但我试图保持代码简单。
- en: '^([5](ch14.html#idm45576013794584-marker)) For R users: remember Python counts
    from 0, so the second axis is axis 1, not axis 2\.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch14.html#idm45576013794584-marker)) 对于 R 用户而言：请记住 Python 是从 0 开始计数的，因此第二轴是轴
    1，而不是轴 2。
