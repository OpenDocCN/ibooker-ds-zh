- en: 1 Introduction to Fluentd
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 Fluentd简介
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Examining use cases for logs and log events
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查日志和日志事件的使用案例
- en: Identifying the value of log unification
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定日志统一的价值
- en: Differentiating between log analytics and unified logging
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 区分日志分析和统一日志
- en: Understanding monitoring concepts
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解监控概念
- en: Understanding Fluentd and Fluent Bit
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解Fluentd和Fluent Bit
- en: Before getting into the details of Fluentd, we should first focus on the motivations
    for using a tool such as Fluentd. How can logging help us? What are log analytics,
    and why is log unification necessary? These are among the questions we will work
    to answer in this chapter. We’ll highlight the kinds of activities logging can
    help or enable us to achieve.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入了解Fluentd之前，我们应该首先关注使用Fluentd等工具的动机。日志如何帮助我们？日志分析是什么，为什么日志统一是必要的？这些问题是我们将在本章中努力回答的。我们将强调日志可以帮助或使我们能够实现的活动类型。
- en: Let’s also take a step back and understand some contemporary thinking around
    how systems are measured and monitored; understanding these ideas will mean we
    can use our tools more effectively. After all, a tool is only as good as the user
    creating the configuration or generating log events to be used.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们退一步，理解一些关于系统如何衡量和监控的当代思考；理解这些想法意味着我们可以更有效地使用我们的工具。毕竟，一个工具的好坏取决于创建配置或生成用于日志事件的用户的技能。
- en: As we do this, it is worth exploring how Fluentd has evolved and understanding
    why it holds its position within the industry. If you are considering Fluentd
    as a possible tool or looking to make a case for its adoption, then it is helpful
    to understand its “origin story,” as this will inform how Fluentd may be perceived.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们这样做的时候，探索Fluentd如何演变以及它为什么在行业中占据其位置是值得的。如果你正在考虑Fluentd作为可能的工具，或者想要为其采用做出案例，那么了解它的“起源故事”是有帮助的，因为这将告诉我们Fluentd可能被如何看待。
- en: 1.1 Elevator pitch for Fluentd
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 Fluentd的简短介绍
- en: Given that you’re looking at this book, we presume you have at least heard of
    Fluentd and probably have a vague sense of what it is. Let’s start with the “elevator
    pitch” as to what Fluentd and Fluent Bit are.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 由于你在看这本书，我们假设你至少听说过Fluentd，可能对其有一个模糊的了解。让我们从Fluentd和Fluent Bit的“简短介绍”开始。
- en: The primary purpose of Fluentd and its sibling Fluent Bit is to capture log
    events from a diverse range of possible sources (infrastructure such as network
    switches, OS, custom applications, and prebuilt applications, including Platform
    as a Service and Software as a Service). It then gets those events to an appropriate
    tool where the log events can be processed to extract meaning and insight, and
    possibly trigger actions. Fluentd’s primary job is not to perform detailed log
    analytics itself, although it can derive meaning, and deeper analysis could be
    incorporated into its configuration if needed.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd及其兄弟产品Fluent Bit的主要目的是从各种可能的来源（如网络交换机、操作系统、自定义应用程序和预构建应用程序，包括平台即服务和软件即服务）捕获日志事件。然后，它将这些事件传递到适当的工具，以便对日志事件进行处理，提取意义和洞察，并可能触发操作。Fluentd的主要工作不是自己执行详细的日志分析，尽管它可以提取意义，如果需要，更深入的分析可以集成到其配置中。
- en: By unifying the log events from all the sources of logs impacting the operation
    of our solution, we have the opportunity to see the big picture. For example,
    was the error in the database the cause of an error returned to a user by the
    application, or was the database error a symptom of the operating system not being
    able to write to storage?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '通过统一影响我们解决方案操作的日志来源的日志事件，我们有看到整体情况的机会。例如，数据库中的错误是否是应用程序返回给用户的错误的原因，或者数据库错误是操作系统无法写入存储的症状？ '
- en: 1.1.1 What is a log event?
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.1 什么是日志事件？
- en: 'We’ve described Fluentd in terms of log events, so what qualifies as a *log
    event*? A log event is best described as the following:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经用日志事件来描述Fluentd，那么什么算是**日志事件**呢？日志事件最好这样描述：
- en: Log events are humanly readable information that is primarily textual in nature.
    The textual information can range from unstructured to highly structured.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志事件是可读的信息，主要是文本性的。文本信息可以从非结构化到高度结构化。
- en: Each log event has a place in time, defined with a timestamp (usually absolute
    01:00:00 1 Jan 1970, but could be relative +0.60), or time can be inferred by
    the log event’s position in a series of events.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个日志事件都有一个时间点，由时间戳定义（通常是绝对时间 01:00:00 1 Jan 1970，但可能是相对时间 +0.60），或者时间可以通过日志事件在一系列事件中的位置来推断。
- en: Each event also has an explicit or implicit association to a location that can
    be associated with a component running in a location that may be physical or logical.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个事件都与一个显式或隐式的位置关联，该位置可以与在物理或逻辑位置上运行的组件关联。
- en: Let’s illustrate the point. Anyone with some coding experience will probably
    recognize the screenshot shown in figure 1.1 as an extract of log output. In this
    case, the output is generated by Fluentd. As you can see, there is a timestamp
    for the event; a location, which comes from the host the events are occurring
    on; and some additional semistructured content.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们举例说明。任何有编程经验的人都会很可能认出图1.1中显示的截图是日志输出的摘录。在这种情况下，输出是由Fluentd生成的。如您所见，事件有一个时间戳；一个位置，它来自事件发生的宿主；以及一些额外的半结构化内容。
- en: '![](../Images/CH01_F01_Wilkins.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH01_F01_Wilkins.png)'
- en: Figure 1.1 Log output from Fluentd
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 Fluentd的日志输出
- en: 1.1.2 Fluentd compared to middleware
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.2 Fluentd与中间件的比较
- en: Those who have worked with middleware (e.g., Apache Camel, MuleSoft, Oracle
    SOA Suite) will appreciate the idea of describing Fluentd as an enterprise service
    bus specialized in logs. Figure 1.2 suggests this, with the concept of input and
    output and capabilities to route and transform the log events. This will become
    ever more apparent as the book progresses.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 与中间件（例如，Apache Camel、MuleSoft、Oracle SOA Suite）合作过的人会欣赏将Fluentd描述为一种专注于日志的企业服务总线这一想法。图1.2展示了这一点，其中包含了输入和输出的概念以及路由和转换日志事件的能力。随着本书的深入，这一点将变得更加明显。
- en: '![](../Images/CH01_F02_Wilkins.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH01_F02_Wilkins.png)'
- en: Figure 1.2 Illustration showing different types of Fluentd plugins and their
    relationship to the core
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 展示不同类型的Fluentd插件及其与核心关系的插图
- en: NOTE If you’d like to explore this analogy further, you might consider reading
    the liveBook version of Open-Source ESBs in Action by Tijs Rademakers and Jos
    Dirksen (Manning, 2008) at [http://mng.bz/Nx6n](http://mng.bz/Nx6n).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：如果您想进一步探索这个类比，您可以考虑阅读Tijs Rademakers和Jos Dirksen所著的《开源企业服务总线实战》（Manning，2008）的liveBook版本，网址为[http://mng.bz/Nx6n](http://mng.bz/Nx6n)。
- en: Definition *Middleware* is a generic term covering software that provides services
    to software applications beyond those available from the operating system. Often
    this entails connecting different pieces of software. It can sometimes be described
    as “software glue.”
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 *中间件* 是一个通用术语，涵盖为软件应用提供服务的软件，这些服务超出了操作系统可提供的服务。通常这涉及到连接不同的软件组件。有时它可以被描述为“软件胶水”。
- en: Definition An *enterprise service bus* is a specific category of middleware
    for passing data in a near-real-time manner between pieces of software. This usually
    includes the sequencing of the execution of the different software components
    as well.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 *企业服务总线* 是一种特定的中间件类别，用于以近乎实时的方式在软件组件之间传递数据。这通常包括不同软件组件执行顺序的排序。
- en: 1.2 Why do we produce logs?
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 我们为什么会产生日志？
- en: 'We create log entries for a wide range of reasons. Some of the use cases for
    logs are only needed a fraction of the time but are invaluable when needed. Nearly
    every use case we can think of will fall into one of the following categories:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们出于各种原因创建日志条目。日志的一些用例可能只需要很少的时间，但在需要时却非常有价值。我们所能想到的几乎所有用例都将属于以下类别之一：
- en: '*Debugging* *—*Knowing which parts of the code are being executed in a scenario
    makes it easy to isolate a bug. Yes, we have debuggers, and so on, but often it’s
    just as easy to drop a few log lines in to help. Some of these log messages will
    be left in to provide assurance that things are running fine during production.
    Other lines of log messages may be disabled while we’re not developing and testing
    software. Note that we would never recommend trying to connect to a production
    environment with a debugger. Allowing a production system to log information intended
    for debugging should be done with an understanding of the possible consequences
    (later in the book, we’ll explore why this is so).'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*调试* *—*知道在某个场景中哪些代码部分正在执行，使得隔离错误变得容易。是的，我们有调试器等工具，但通常在日志中添加几行信息来帮助也是同样容易的。其中一些日志消息将被保留，以确保在生产过程中一切运行正常。在其他情况下，日志消息的某些行可能在我们开发或测试软件时被禁用。请注意，我们绝不会建议尝试使用调试器连接到生产环境。允许生产系统记录用于调试的信息应该是在理解可能后果的情况下进行的（本书后面我们将探讨为什么是这样）。'
- en: '*Unexpected data values or abnormal conditions occurring* *—*When code encounters
    data values that are out of bounds, sometimes it is better to flag and keep going,
    as you would see when'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*意外数据值或异常情况发生* — 当代码遇到超出范围的数据值时，有时最好是标记并继续执行，就像你会在以下情况中看到的那样：'
- en: 'Using the default condition in a switch statement, when the code should have
    a value you have allowed for in the switch. But as a result of a change or bug
    elsewhere, your code needs to gracefully handle the situation and make it known
    (e.g., the classic problem of a presentation layer [UI] differing from the backend
    supported data values):'
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在switch语句中使用默认条件，当代码应该有一个你在switch中允许的值时。但由于其他地方的变化或错误，你的代码需要优雅地处理这种情况并使其为人所知（例如，经典的问题是在表现层[UI]与后端支持的数据值不同）：
- en: '[PRE0]'
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Applying defensive coding. For example, before using an object variable, checking
    that it isn’t null—a standard action when first loading configuration data to
    ensure everything is as expected.
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用防御性编程。例如，在使用对象变量之前，检查它是否不为空——这是一个在首次加载配置数据时确保一切如预期的标准操作。
- en: Reporting when the code handling connection issues experiences an error, and
    you’re going to fall back and try again. This is so we can understand the cause
    of a slow response that impacts user experience from the logs.
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当处理连接问题的代码遇到错误，你将回退并再次尝试时，需要报告这种情况。这样我们才能从日志中了解影响用户体验的缓慢响应的原因。
- en: '*Audit and security*—We live in a world where internal and external actors
    try to get hold of data for illegitimate use. To help us watch for misuse, we
    need to know what is going on. Events need to be recorded, if not reported. Sometimes
    this is to search for abnormal behavior patterns, and other times to show that
    the system did everything as it should. We often see this kind of use case referred
    to as *forensic logging* or *application security monitoring* and *security information
    and event management* (SIEM). Bringing log events together that can create an
    audit trail is important. A single out-of-norm event may be insignificant. But
    when you can see the same kind of event reoccurring regularly in an unusual manner,
    over time it may point to something more suspicious.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*审计和安全* — 我们生活在一个内部和外部行为者试图获取数据以进行非法使用的世界中。为了帮助我们监视滥用行为，我们需要了解正在发生的事情。事件需要被记录，如果没有报告。有时这是为了寻找异常行为模式，有时是为了表明系统已经按照预期完成了所有操作。我们经常看到这种用法案例被称为*取证日志*或*应用安全监控*以及*安全信息和事件管理*（SIEM）。将可以创建审计跟踪的日志事件汇集在一起是很重要的。单个异常事件可能微不足道。但当你看到同一种事件以不寻常的方式定期发生时，随着时间的推移，它可能指向更可疑的事情。'
- en: Logging, security, and log forensics
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 记录、安全和日志取证
- en: 'For further insight into forensic logging, this article provides some insights
    into the realities of using logs: [http://bit.ly/Fluentd-ForensicLogging](http://bit.ly/Fluentd-ForensicLogging).
    And this Gartner article adds additional color to this landscape: [http://bit.ly/AppSecurityMonitoring](http://bit.ly/AppSecurityMonitoring).'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了深入了解日志取证，本文提供了一些关于使用日志的现实情况的见解：[http://bit.ly/Fluentd-ForensicLogging](http://bit.ly/Fluentd-ForensicLogging)。此外，这篇Gartner文章也为这一领域增添了更多色彩：[http://bit.ly/AppSecurityMonitoring](http://bit.ly/AppSecurityMonitoring)。
- en: The National Institute of Standards and Technology (NIST) also provides an excellent
    guide on logging for security purposes in “Guide to Computer Security Log Management”
    ([http://mng.bz/ExWd](http://mng.bz/ExWd)). While the title may suggest that the
    content is for a security specialist, it does offer a good entry into this application
    of logging for anyone in the IT industry.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 美国国家标准与技术研究院（NIST）还在“计算机安全日志管理指南”中提供了关于安全目的日志记录的优秀指南（[http://mng.bz/ExWd](http://mng.bz/ExWd)）。虽然标题可能暗示内容是为安全专家准备的，但它确实为IT行业的任何人提供了进入这种日志应用的良好途径。
- en: '*Root cause analysis*—Sometimes we see a problem, but the cause isn’t apparent.
    Often this is because we are looking only at the logs from a small set of components.
    For example, an application based on its logs appears to slow down over time,
    but there is no evidence of a memory leak. Only when we bring logs together from
    all the sources can we identify a cause and separate other problems as side effects.
    For example, our application could be fine. Still, we use another service on the
    same server, which never releases CPU threads properly, resulting in the server
    slowly running out of resources to run all applications. But this can’t be seen
    until all the information is presented together.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*根本原因分析*—有时我们看到一个问题，但原因并不明显。通常这是因为我们只查看一小部分组件的日志。例如，一个基于其日志的应用程序似乎随着时间的推移而变慢，但没有内存泄漏的证据。只有当我们从所有来源汇总日志时，我们才能确定原因，并将其他问题作为副作用分离出来。例如，我们的应用程序可能运行良好。然而，我们在同一服务器上使用另一个服务，该服务从未正确释放CPU线程，导致服务器逐渐耗尽资源以运行所有应用程序。但这种情况只有在所有信息都展示在一起时才能被发现。'
- en: '*Determining the cause of performance issues*—Tools such as *Prometheus* ([https://prometheus.io/](https://prometheus.io/))
    and *Grafana* ([https://grafana.com/](https://grafana.com/)) are well known for
    gathering metric data to provide insight into the performance of software being
    run. While the data may show you what is happening, it doesn’t necessarily tell
    you why. It is textual logs that describe what is happening—whether that is database
    query logs or application thread traces.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*确定性能问题的原因*—如*Prometheus* ([https://prometheus.io/](https://prometheus.io/))和*Grafana*
    ([https://grafana.com/](https://grafana.com/))这样的工具因收集指标数据以提供正在运行的软件性能的见解而闻名。虽然数据可能显示正在发生的事情，但它并不一定告诉你原因。是文本日志描述了正在发生的事情——无论是数据库查询日志还是应用程序线程跟踪。'
- en: '*Anomaly detection*—While a system may appear to operate perfectly fine and
    yields the expected results when a solution is tested, anomalies occur in the
    results during the system’s regular operation. Logging can facilitate the detection
    of such issues by helping to find correlations in the log events when anomalies
    arise, providing an indicator of the cause.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*异常检测*—虽然一个系统在测试解决方案时可能看起来运行得很好并产生预期的结果，但在系统的常规操作中，结果中可能会出现异常。日志记录可以通过在出现异常时帮助找到日志事件之间的相关性，从而促进此类问题的检测，提供原因的指示。'
- en: An example of this was the occurrence of the Intel Pentium FDIV bug in the 1990s,
    where an error in the design of specific Pentium processors meant that while the
    software ran perfectly, some calculations in specific conditions produced an incorrect
    result. If we log events such as the outcomes of important calculations even when
    the software is running as expected, it becomes easier to spot any possible anomalies
    and examine activities to identify the origin of the anomaly (for more detail,
    see [https://en.wikipedia.org/wiki/Pentium_FDIV_bug](https://en.wikipedia.org/wiki/Pentium_FDIV_bug)).
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这种情况的例子之一是20世纪90年代英特尔奔腾FDIV错误的发生，其中特定奔腾处理器的设计错误意味着尽管软件运行完美，但在某些特定条件下的一些计算产生了错误的结果。如果我们即使在软件按预期运行时记录事件，如重要计算的结果，那么就更容易发现任何可能的异常，并检查活动以确定异常的来源（更多详情，见[https://en.wikipedia.org/wiki/Pentium_FDIV_bug](https://en.wikipedia.org/wiki/Pentium_FDIV_bug))）。
- en: Another example of an anomaly that can be seen is running our apps in production
    environments where we share resources with other processes. Our test environments
    show that everything is fine, but in production, we experience out-of-memory errors.
    These scenarios can result from test conditions being subtly different than production,
    where we may have been able to use more memory than is available in production
    conditions. Seeing what else is running and the details around the errors can
    help diagnose resource conflict issues. Not as high profile as a chip flaw, but
    still an issue that can be challenging to isolate.
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 另一个可以观察到的异常例子是在生产环境中运行我们的应用程序，其中我们与其他进程共享资源。我们的测试环境显示一切正常，但在生产中，我们遇到了内存不足错误。这些场景可能源于测试条件与生产环境略有不同，在生产环境中，我们可能能够使用比生产条件中可用的更多内存。查看正在运行的其他内容以及错误周围的细节可以帮助诊断资源冲突问题。虽然不像芯片缺陷那样引人注目，但仍然是一个可能具有挑战性的隔离问题。
- en: '*Operational effectiveness and troubleshooting*—Mature, well-produced log events
    can include the use of error codes. An error code can be linked to a particular
    problem and guidance on how to resolve the issue.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*运营效率和故障排除*—成熟的、高质量的日志事件可以包括错误代码的使用。错误代码可以链接到特定问题，并提供有关如何解决问题的指导。'
- en: '*Determine when to trigger subsequent actions* *—*Use log events to recognize
    specific needs and initiate processes automatically instead of requiring manual
    intervention.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*确定何时触发后续操作* *—*使用日志事件来识别特定的需求并自动启动流程，而不是需要人工干预。'
- en: This can be particularly helpful for legacy states where the software and hardware
    environments are fragile and poorly understood but operationally critical; people
    become risk-averse to change (or may not even be able to implement change for
    off-the-shelf solutions). Therefore, to implement tasks like preventive measures
    for errors, we need to implement solutions outside the application being monitored.
    This could be simply watching for completion messages reporting success, at which
    point the next operation or error prevention can be started.
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这对于软件和硬件环境脆弱且理解不充分但运营上至关重要的传统状态尤其有帮助；人们会变得对改变持谨慎态度（或者甚至可能无法为现成解决方案实施改变）。因此，为了实施诸如错误预防措施等任务，我们需要在监控的应用程序之外实施解决方案。这可能仅仅是监视报告成功的完成消息，此时可以启动下一个操作或错误预防。
- en: 1.3 Evolving ideas
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.3 发展中的理念
- en: Ideas around log management and the application of logging have been evolving
    a fair bit over the last four or five years; this is partly driven by the rapid
    progression of containerization. Docker and Kubernetes and the effective growth
    in individual small services (microservices/macroservices/mini-services) to support
    dynamic and hyper-scaling mean environments and deployed applications are far
    more transient in nature. Other factors such as broader adoption to varying degrees
    of *DevOps* have also evolved. The net result is that a couple of concepts have
    developed that are worth noting.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 关于日志管理和日志应用的理念在过去四五年里发展了很多；这部分是由于容器化的快速进展。Docker和Kubernetes以及单个小型服务（微服务/宏服务/迷你服务）的有效增长，以支持动态和超规模环境，意味着部署的应用程序在本质上更加短暂。其他因素，如*DevOps*的广泛采用，也在一定程度上得到了发展。最终结果是，发展出了一些值得注意的概念。
- en: 1.3.1 Four golden signals
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.1 四个黄金信号
- en: '*Observability* was probably the first of the modern monitoring concepts to
    develop. Discussions around observability started to gain mainstream recognition
    around 2016 and showed up in what have become referential texts, such as Google’s
    site reliability engineering (SRE) guide (available at [https://landing.google.com/sre/sre-book/toc/)](https://landing.google.com/sre/sre-book/toc/).
    The idea isn’t new; it’s just been well defined.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*可观测性*可能是现代监控概念中最早发展起来的。关于可观测性的讨论从2016年开始逐渐获得主流认可，并出现在了一些参考文本中，如谷歌的网站可靠性工程（SRE）指南（可在[https://landing.google.com/sre/sre-book/toc/](https://landing.google.com/sre/sre-book/toc/)找到）。这个想法并不新颖；只是定义得很好。'
- en: 'Observability essentially states that we should track or observe and measure
    what software is doing to manage and understand a system. Industry thinking has
    evolved this premise to the tracking of four specific signals, often referred
    to as the *four golden signals* of SRE: latency, errors, traffic, and saturation.
    These four signals are sometimes referred to as *metrics*, *measures*, or *indicators*
    (the language is used interchangeably; personally, the term *signal* feels very
    binary, and life is rarely that). Here is what the signals mean:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 可观测性本质上是指我们应该跟踪或观察并测量软件正在做什么，以便管理和理解一个系统。行业思维已经将这个前提发展到了跟踪四个特定的信号，通常被称为SRE的*四个黄金信号*：延迟、错误、流量和饱和度。这四个信号有时被称为*指标*、*度量*或*指标*（语言是可互换的；就我个人而言，我认为*信号*这个词非常二元，而生活很少是那样的）。以下是这些信号的含义：
- en: '*Latency* *—*How long it’s taking to address a request. A growing latency indicates
    potential performance issues from the increasing demand of need, or lack of performance
    tuning, for software or configuration.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*延迟* *—*处理请求所需的时间。延迟的增长可能表明由于需求的增加或缺乏性能调整，软件或配置可能存在潜在的性能问题。'
- en: '*Errors* *—*Problems that can impact the service and the frequency, and whether
    they are self-recovered (e.g., not getting a DB connection means fall back and
    try again). Fluentd will come into its own handling errors, as we will see as
    we progress through the book.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*错误* *—*可能影响服务的问题及其频率，以及它们是否可以自我恢复（例如，无法获取数据库连接意味着回退并重试）。随着我们继续阅读本书，我们将看到Fluentd在处理错误方面将发挥其独特的作用。'
- en: '*Traffic* *—*Increased traffic can indicate growing demand or malicious intent,
    depending on the gain or loss of effectiveness if traffic drops.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*流量* *—*流量的增加可能表明需求增长或恶意意图，这取决于流量下降时效果的增加或减少。'
- en: '*Saturation* *—*Reflects how full or heavily used a system is (e.g., CPU and
    disk utilization). Once a system passes a certain saturation threshold, performance
    degradation will be experienced as the operating system has to dedicate more effort
    to manage its limited resources.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*饱和度* *—*反映系统满载或使用程度（例如，CPU和磁盘利用率）。一旦系统超过某个饱和阈值，性能下降将会发生，因为操作系统需要投入更多努力来管理其有限的资源。'
- en: While deriving all four signals from logs alone is not desirable (e.g., service
    degradation would require us to hold multiple performance measures over time and
    compare them), halfway-decent logging can yield the signals given the use of timestamping.
    Latency could be derived by the time difference between the first and last log
    events occurring; for example, throughput could be indicated through volumes of
    log entries.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 仅从日志中推导出所有四个信号并不理想（例如，服务降级需要我们持有多个性能指标并在一段时间内进行比较），但半合理的日志记录使用时间戳可以产生所提供的信号。延迟可以通过第一个和最后一个日志事件发生的时间差来推导；例如，吞吐量可以通过日志条目量来表示。
- en: 1.3.2 Three pillars of observability
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.2 可观测性的三个支柱
- en: 'Another perspective of observability that has become popular in the industry
    relates to the character of the things we monitor. The type of information gathered
    when monitoring can be described by one of several definitions. As a result, observability
    is made up of three pillars, or core ideas:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个在业界变得流行的可观测性视角与我们所监控事物的特性有关。在监控时收集的信息类型可以通过几种定义之一来描述。因此，可观测性由三个支柱或核心思想组成：
- en: '*Metrics* *—*Typically numerical and quantify the state of things. We then
    regularly sample the data points in the environment (e.g., CPU utilization).'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*指标* *—*通常为数值型，用于量化事物的状态。我们随后会定期采样环境中的数据点（例如，CPU利用率）。'
- en: '*Logs* *—*Primarily textual but event-based, therefore having characteristics
    of time and description (e.g., Simple Network Management Protocol [SNMP] traps).'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*日志* *—*主要是文本型但基于事件，因此具有时间和描述的特性（例如，简单网络管理协议 [SNMP] 捕获）。'
- en: '*Traces* *—*Tracking execution flows and the time it takes for transactions
    and subtransactions to execute different steps. Trace logs are largely numerical,
    being made up of timestamps as code executions enter and leave different parts
    of the solution. To provide these times with context, identifiers, such as transaction
    ID and the entry and exit points, are identified.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*跟踪* *—*追踪执行流程以及事务和子事务执行不同步骤所需的时间。跟踪日志主要是数值型，由代码执行进入和离开解决方案不同部分的时戳组成。为了提供这些时间的上下文，标识符，如事务ID和入口和出口点，被识别。'
- en: Everyone will be familiar with metrics, as we have all at some point needed
    to see how hard a CPU is working or have experienced constraints because of a
    lack of memory or how much storage is available on our hard disks.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 每个人都会熟悉指标，因为我们都有过需要查看CPU工作强度或因内存不足或硬盘存储空间不足而遇到限制的经历。
- en: Tracing is probably most strongly associated with the *OpenTracing* initiative
    ([https://opentracing.io/](https://opentracing.io/)) and the *Cloud Native Computing
    Foundation* (*CNCF*) project *Jaeger* ([https://jaegertracing.io/](https://jaegertracing.io/)).
    OpenTracing has combined with a project called OpenCensus ([https://opencensus.io/](https://opencensus.io/))
    to form *OpenTelemetry* ([https://opentelemetry.io/](https://opentelemetry.io/)).
    Yet logging may contribute to this space, as specific log entries may act as a
    measuring point within a trace—particularly within legacy solutions. There is
    the risk that people will merge thinking about tracing with logging. It is often
    desirable to correlate trace performance information back to logs, so logs can
    be used as a key diagnostic tool in determining where the low performance occurs.
    However, the tooling available to each pillar has distinct differences and strengths.
    We can see this by considering Jaeger’s visualization of execution paths (traces)
    versus Fluentd’s ability to parse log events and trigger actions. While these
    CNCF projects have brought tracing to the fore, the idea isn’t new, and many service
    bus solutions (such as Oracle SOA Suite and MuleSoft) have some sort of mechanism
    for tracing. The difference is that *OpenTracing* and *OpenTelemetry* are trying
    to drive standardization.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪最强烈地与*OpenTracing*倡议([https://opentracing.io/](https://opentracing.io/))和*云原生计算基金会*（*CNCF*）项目*Jaeger*([https://jaegertracing.io/](https://jaegertracing.io/))相关联。OpenTracing与名为OpenCensus([https://opencensus.io/](https://opencensus.io/))的项目结合，形成了*OpenTelemetry*([https://opentelemetry.io/](https://opentelemetry.io/))。然而，日志可能也会对这个领域做出贡献，因为特定的日志条目可能作为跟踪中的测量点——尤其是在传统解决方案中。存在一种风险，人们会将跟踪与日志的思考合并。通常，人们希望将跟踪性能信息关联回日志，以便日志可以作为确定低性能发生位置的关键诊断工具。然而，每个支柱可用的工具具有不同的差异和优势。我们可以通过考虑Jaeger对执行路径（跟踪）的可视化与Fluentd解析日志事件并触发操作的能力来看到这一点。虽然这些CNCF项目将跟踪推到了前台，但这个想法并不新颖，许多服务总线解决方案（如Oracle
    SOA Suite和MuleSoft）都有某种跟踪机制。区别在于*OpenTracing*和*OpenTelemetry*试图推动标准化。
- en: We are seeing signs that these standards are being adopted by open source implementation
    frameworks and commercial solutions. How does this relate to Fluentd? Depending
    upon the log output, it can represent a means to trace execution (e.g., record
    a transaction, an identifier, an execution point in the codebase, and a time).
    In other words, a trace is a specialized log. This relationship and the deployment
    models being supported make Fluentd and Fluent Bit capable of being part of an
    OpenTelemetry solution. As a result, the OpenTelemetry Protocol (OTLP) is being
    incorporated into Fluentd. All these measures play a part at different levels
    of a solution (infrastructure to business logic), as figure 1.3 illustrates.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到这些标准正在被开源实现框架和商业解决方案所采用。这与Fluentd有何关联？根据日志输出，它可以代表一种追踪执行（例如，记录交易、标识符、代码库中的执行点和时间）的方式。换句话说，追踪是一种特殊的日志。这种关系以及支持的部署模型使得Fluentd和Fluent
    Bit能够成为OpenTelemetry解决方案的一部分。因此，OpenTelemetry协议（OTLP）被纳入Fluentd。所有这些措施在解决方案的不同层级（从基础设施到业务逻辑）中发挥作用，如图1.3所示。
- en: '![](../Images/CH01_F03_Wilkins.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH01_F03_Wilkins.png)'
- en: Figure 1.3 Three pillars of observability as applied to a solution stack
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 将可观察性三要素应用于解决方案堆栈
- en: 'The definitions for the layers are as follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 各层的定义如下：
- en: '*Business application monitoring*—This presents pure abstracted business application
    monitoring or business activity monitoring (BAM) and relates to the measurement
    of application/business tasks described by things like Business Process Execution
    Language (BPEL).'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*商业应用监控*—这代表的是纯粹的业务应用监控或业务活动监控（BAM），与描述业务流程执行语言（BPEL）等内容的业务任务测量相关。'
- en: '*Application monitoring*—This reflects traditional monitoring of applications
    and middleware/workflow technologies such as Oracle’s SOA Suite or Microsoft’s
    BizTalk underpinning BPEL implementations.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*应用监控*—这反映了传统应用和中间件/工作流技术（如Oracle的SOA Suite或Microsoft的BizTalk支撑BPEL实现）的监控。'
- en: '*Virtual machine/container monitoring*—This measures whether the engine that
    shares host computing services gives appropriate levels of resources to the guest
    environment(s). It monitors to ensure that the virtualized hardware is running
    smoothly.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*虚拟机/容器监控*—这衡量的是共享主机计算服务的引擎是否为虚拟化环境（们）提供了适当的资源级别。它监控以确保虚拟化硬件运行顺畅。'
- en: '*Host/infrastructure monitoring*—This detects hardware problems, such as storage
    capacity, overheating CPUs, fan failures, and so on.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*主机/基础设施监控*—这可以检测硬件问题，例如存储容量、过热CPU、风扇故障等。'
- en: NOTE More information about BAM can be found in the liveBook version of Activiti
    in Action by Tijs Rademakers (Manning, 2012) at [http://mng.bz/DxgR](http://mng.bz/DxgR).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：有关BAM的更多信息，请参阅Tijs Rademakers在《Activiti in Action》的liveBook版本（Manning，2012）中的内容[http://mng.bz/DxgR](http://mng.bz/DxgR)。
- en: Of these two concepts, I believe the four signals are better considered as measures.
    By measuring the data that each signal describes, the signal will indicate whether
    something is right or wrong. More importantly, do the changes in the signals being
    received show a trend or pattern that at least means that the solution being monitored
    is not degrading anymore? Ideally, we want a trend indicating continued improvement.
    Regardless, this information will not give you information on the root problem.
    For example, signals showing a highly saturated system won’t tell you why the
    system is saturated, which can occur if code is stuck in an infinite loop. For
    this, you still need to understand what the software is doing. This is not to
    say signals are wrong; they are, without a doubt, the best way to provide a cue
    that there’s an issue. But it is through the lens of the three pillars, I believe,
    that a deeper appreciation of what is or isn’t happening can be achieved with
    the sight of cause and effect in the way software is behaving.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两个概念中，我认为四个信号更好地被视为衡量标准。通过测量每个信号所描述的数据，信号将指示某事是否正确或错误。更重要的是，接收到的信号变化是否显示出趋势或模式，至少意味着被监控的解决方案不再恶化？理想情况下，我们希望看到一个持续改进的趋势。无论如何，这些信息不会给你关于根本问题的信息。例如，显示系统高度饱和的信号不会告诉你为什么系统会饱和，这可能发生在代码陷入无限循环时。对于这一点，你仍然需要了解软件正在做什么。这并不是说信号是错误的；毫无疑问，它们是提供问题线索的最佳方式。但我相信，通过这三个支柱的视角，我们可以更深入地理解软件行为中的因果关系，从而更好地理解正在发生或没有发生的事情。
- en: You may have observed that, in the reasons for logging (for debugging, audit,
    etc.), various activities will be handled by more than one or two individuals
    in an organization. Once an organization grows beyond a certain size, we have
    specialists working in different areas. The specialization of roles brings pressure
    for different tooling. While many monitoring tools have plugin features, and so
    on, they may not support every individual need. This can mean we end up with multiple
    tools in an Enterprise IT landscape, and in some organizations, people and organization
    politics will further complicate the IT tooling landscape. Yet, they all need
    a blend of data from the same source systems.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，在日志记录的原因（用于调试、审计等）中，各种活动将由组织中的不止一两个人处理。一旦组织规模超过一定规模，我们就会有在不同领域工作的专业人士。角色的专业化给不同的工具带来了压力。虽然许多监控工具都有插件功能等，但它们可能不支持每个个体的需求。这可能导致我们在企业IT环境中拥有多个工具，在某些组织中，人员和组织政治将进一步复杂化IT工具环境。然而，它们都需要来自同一源系统的数据混合。
- en: 1.4 Log unification
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.4 日志统一
- en: Fluentd, Logstash, and other related tools are sometimes referred to as *log
    unification tools*. But what is meant by this, and what value(s) should a unification
    tool have? Let’s look more closely at the value of unification and differentiate
    it from some other associated ideas.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd、Logstash和其他相关工具有时被称为*日志统一工具*。但这是什么意思，一个统一工具应该具备哪些价值？让我们更深入地看看统一的价值，并将其与其他相关概念区分开来。
- en: The Cambridge English Dictionary describes *unification* as “the act or process
    of bringing together or combining things or people” ([http://mng.bz/lax2](http://mng.bz/lax2)).
    This is what we use Fluentd for—collecting log events from diverse sources and
    bringing them together with a single tool so the log events can be processed and
    sent to the appropriate endpoint solutions(s).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 剑桥高阶英汉双解词典将*统一*描述为“将事物或人聚集或结合的行为或过程”([http://mng.bz/lax2](http://mng.bz/lax2))。这正是我们使用Fluentd的目的——从不同的来源收集日志事件，并使用单一工具将它们汇集在一起，以便处理日志事件并将其发送到适当的端点解决方案。
- en: This ability is essential, as it provides many significant benefits; we have
    touched on some of these when looking at the application of logs. As we bring
    these value points together, we can roughly group them into log sourcing and log-based
    insights.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这种能力是必不可少的，因为它提供了许多显著的好处；我们在查看日志应用时已经提到了一些。当我们把这些价值点汇集在一起时，我们可以大致将它们分为日志来源和基于日志的洞察。
- en: 'The log sourcing benefits include the following:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 日志源的优势包括以下内容：
- en: It eases the task of locating and retrieving logs and log events. Through a
    single platform, locating relevant log events becomes far easier. We can route
    the log events to a convenient location/tool, rather than needing to access multiple
    platforms with potentially many different locations and ways of accessing the
    log events.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它简化了定位和检索日志和日志事件的任务。通过单一平台，定位相关日志事件变得远更容易。我们可以将日志事件路由到方便的位置/工具，而不是需要访问多个平台，这些平台可能有多个不同的位置和访问日志事件的方式。
- en: With virtualization, containerization, and more recently functions as a service,
    the hosting of logic becomes transient, so the means to easily gather log information
    before it is lost is more critical than ever. Using Fluentd, we can configure
    lightweight processes into these transient environments that push log events to
    a durable location.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着虚拟化、容器化和最近的服务即函数的出现，逻辑的托管变得短暂，因此，在信息丢失之前轻松收集日志信息的方法比以往任何时候都更加关键。使用Fluentd，我们可以将这些短暂环境中配置轻量级进程，将日志事件推送到持久的位置。
- en: A single technology brings logs events together regardless of the source or
    target. As a result, log event management becomes easier and more accessible.
    We don’t have to master how all the different ways to log events can be captured
    and stored (e.g., Syslog, SNMP, Log4J, and the many other log forms and protocols),
    as Fluentd makes this easier.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单一技术可以将来自不同来源或目标的日志事件汇集在一起。因此，日志事件管理变得更加容易和可访问。我们不必掌握所有不同方式捕获和存储日志事件的方法（例如，Syslog、SNMP、Log4J以及许多其他日志形式和协议），因为Fluentd使这变得更容易。
- en: Operating systems are complex, made up of many discrete processes and applications.
    Often, discrete components come with their own logs. We need to bring these together
    to trace an event through the different components. Some of this has been solved
    with operating systems and network equipment adopting a small group of standards
    like Syslog and SNMP traps.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作系统复杂，由许多离散的过程和应用组成。通常，离散组件会附带自己的日志。我们需要将这些组件汇集在一起，以追踪事件通过不同的组件。一些问题已经通过操作系统和网络设备采用了一小群标准（如Syslog和SNMP陷阱）来解决。
- en: It would be easy to think that Syslog and SNMP can meet all our logging needs.
    But software is more than a bunch of OS components that can use SNMP or Syslog,
    so we need to bring these sources together at another level of unification. For
    example, Syslog is predominantly a Linux solution; its use of UDP means there
    is a risk of event loss, and UDP has size limits. The data structures and predefined
    values are infrastructure-centric, to name a few of the Syslog constraints.
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 人们很容易认为Syslog和SNMP可以满足我们所有的日志需求。但软件不仅仅是使用SNMP或Syslog的操作系统组件的集合，因此我们需要在另一个统一层面上将这些来源汇集起来。例如，Syslog主要是一个Linux解决方案；它使用UDP意味着存在事件丢失的风险，UDP有大小限制。数据结构和预定义值以基础设施为中心，仅举Syslog约束的几个例子。
- en: In the era of the network and the internet, our applications pass events through
    many different managed devices, creating a real change in the number of places
    where our communications could be disrupted. Unifying the log events at this scale
    of distribution brings the problem to manageable proportions.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在网络和互联网时代，我们的应用程序通过许多不同的管理设备传递事件，这实际上改变了我们的通信可能被中断的地点数量。在如此大规模的分布中统一日志事件，将问题缩小到可管理的规模。
- en: 'The log-based insights include the following:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 基于日志的洞察包括以下内容：
- en: It is easier to create holistic view(s) of log events, allowing us to see the
    cause and effect more easily.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它更容易创建日志事件的全面视图，使我们更容易看到因果关系。
- en: With logs unified into an analytics platform, the data can be capitalized on
    with processes such as
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将日志统一到分析平台中，可以利用以下过程来利用数据
- en: Searching across all the logs in one accessible location
  id: totrans-91
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在一个可访问的位置搜索所有日志
- en: Identifying trends and patterns in the production environment
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在生产环境中识别趋势和模式
- en: Extracting analytical data enabling forecasting future likely behavior
  id: totrans-93
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取分析数据，以预测未来可能的行为
- en: Looking at user behavior to determine if the systems are subject to misuse or
    patterns of malicious actions
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过观察用户行为来确定系统是否受到滥用或恶意行为的模式
- en: A unification platform creates the opportunity for us to move from a reactive,
    post-event analysis approach to identifying issues and then proactively acting
    on them as they occur. This potentially can extend to a position where we identify
    warning signs and proactively perform actions to avoid a problem. The ability
    to become proactive comes from the unification tool’s ability to filter, route,
    and apply meaning to log events.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个统一化平台为我们提供了一个从被动的事件后分析方法转向识别问题并在它们发生时积极采取行动的机会。这可能会扩展到我们识别预警信号并积极采取行动以避免问题的位置。能够变得积极的能力来自于统一化工具过滤、路由和应用日志事件意义的能力。
- en: Infrastructure as a Service and Platform as a Service have brought whole new
    levels of dynamic change and routing complexity. As a result, the unifying of
    logs reduces the scale of the challenge of tracking what could be impacting our
    solution.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础设施即服务（IaaS）和平台即服务（PaaS）带来了全新的动态变化和路由复杂性。因此，日志的统一化减少了跟踪可能影响我们解决方案的因素的挑战规模。
- en: While we have discussed the why and what of log unification, we should also
    differentiate it from other concepts associated with processing log events, particularly
    log analytics.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们已经讨论了日志统一化的原因和内容，但我们还应该将其与其他与处理日志事件相关的概念区分开来，尤其是日志分析。
- en: Note For more information about SNMP, see the liveBook version of Software Telemetry
    by Jamie Riedesel (Manning, 2021) at [https://livebook.manning.com/book/software-telemetry/chapter-2/155](https://livebook.manning.com/book/software-telemetry/chapter-2/155).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：有关SNMP的更多信息，请参阅Jamie Riedesel（Manning，2021年）所著的《软件遥测》的liveBook版本，链接为[https://livebook.manning.com/book/software-telemetry/chapter-2/155](https://livebook.manning.com/book/software-telemetry/chapter-2/155)。
- en: 1.4.1 Unifying logs vs. log analytics
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.4.1 日志统一化与日志分析的比较
- en: Many tools in the logging space come into the category of log analytics, where
    the focus is on applying data-analysis techniques such as pattern searching, using
    complex rules across many data records. Such processing is often associated with
    big data and search engine technologies. The best known of these is probably Splunk,
    as a purely commercial product, and Elasticsearch, as an open source solution
    with commercial options.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 许多日志空间中的工具都属于日志分析类别，其重点在于应用数据分析技术，如模式搜索，在多个数据记录中使用复杂规则。这种处理通常与大数据和搜索引擎技术相关联。其中最著名的可能是Splunk，作为一个纯商业产品，以及Elasticsearch，作为一个开源解决方案，同时提供商业选项。
- en: The log events need to be ingested into an analytics engine to enable log analysis
    to be performed. Such analytical processes may include event correlation (e.g.,
    determining which systems or components generate the most errors or when the fault
    frequency relates to a particular event during the day). Getting log events into
    the engine can be done manually if necessary. Typically, analytics products like
    Splunk have tools to harvest or aggregate the log events using one of the more
    common protocols in the analytics engine. These services are then deployed to
    multiple locations to gather different log sources. This is a simple act of aggregation,
    as the harvesting is not intelligent; there is no possibility of handling the
    log events effectively until they are in the analytics engine. Harvesters typically
    don’t have the same levels of connectivity and configuration seen with unification
    tools.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 日志事件需要被摄入到分析引擎中，以便能够执行日志分析。这些分析过程可能包括事件相关性（例如，确定哪些系统或组件产生最多的错误，或者故障频率与一天中特定事件的关系）。如果需要，可以将日志事件手动输入到引擎中。通常，像Splunk这样的分析产品具有使用分析引擎中更常见的协议来收集或聚合日志事件的工具。然后，将这些服务部署到多个位置以收集不同的日志源。这是一个简单的聚合行为，因为收集不是智能的；只有在它们进入分析引擎之前，才有可能有效地处理日志事件。收集器通常不具有与统一化工具相同的连接性和配置水平。
- en: The differentiator is that a log analytics engine’s strength is applying search
    and computational science to many logs, not the gathering and routing of log events.
    Whereas the strength of unification tools is sourcing and delivering the log events,
    it typically has relatively simplistic analytical capabilities such as event counts
    over time.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 区别在于，日志分析引擎的优势在于将搜索和计算科学应用于大量日志，而不是日志事件的收集和路由。而统一化工具的优势在于获取和传递日志事件，它通常具有相对简单的分析能力，例如事件随时间的变化计数。
- en: Both technologies have some standard capabilities, regarding the transformation/application
    of meaning to the data (i.e., the process of data becoming usable information).
    Without these abilities, neither solution can be very effective. Both technologies
    have strong event-filtering capabilities, but are applied in different ways.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种技术都有一些标准功能，涉及将意义转化为数据（即数据变为可用信息的过程）。没有这些能力，任何解决方案都无法非常有效。这两种技术都有强大的事件过滤能力，但应用方式不同。
- en: definition *Log routing is when* log events are taken and then directed through
    a middleware tool, such as Fluentd, to the applications that need those log events.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 *日志路由是指* 将日志事件提取后通过中间件工具，例如 Fluentd，导向需要这些日志事件的应用程序。
- en: Definition *Log aggregation* means log events are taken and sent to a central
    location to be processed.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 *日志聚合* 指的是将日志事件提取并发送到一个中央位置进行处理。
- en: 1.5 Software stacks
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.5 软件栈
- en: 'The industry has been talking about software stacks since 2000 (some have attributed
    this term to David Axmark and Michael “Monty” Widenius, cofounders of MySQL),
    when the best-known stack was named: the LAMP (Linux, Apache, MySQL, PHP) stack.
    By *software stack*, we mean a standard combination of products (typically open
    source) used together to deliver software solutions. Another well-known stack
    is MEAN (MongoDB, Express, AngularJS, Node.js). A complete list of stacks can
    be found at [https://en.wikipedia.org/wiki/Solution_stack](https://en.wikipedia.org/wiki/Solution_stack).'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 自从 2000 年以来，业界一直在讨论软件栈（有些人将这个术语归功于 MySQL 的共同创始人 David Axmark 和 Michael “Monty”
    Widenius），当时最知名的栈被命名为：LAMP 栈（Linux、Apache、MySQL、PHP）。我们所说的 *软件栈* 指的是一组标准的产品组合（通常是开源产品），它们一起用于提供软件解决方案。另一个知名的栈是
    MEAN（MongoDB、Express、AngularJS、Node.js）。完整的栈列表可以在 [https://en.wikipedia.org/wiki/Solution_stack](https://en.wikipedia.org/wiki/Solution_stack)
    找到。
- en: Software stacks or solution stacks
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 软件栈或解决方案栈
- en: It is worth noting that people often use the terms *software* stack and *solution*
    stack interchangeably. In most cases, this is reasonable; the stack provides a
    complete solution, such as log management; we just need to apply the configuration.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，人们经常将 *软件栈* 和 *解决方案栈* 互换使用。在大多数情况下，这是合理的；栈提供了一个完整的解决方案，例如日志管理；我们只需要应用配置。
- en: But it isn’t valid in cases where the stack provides all the elements on which
    a solution can be built; the MEAN stack contains all the components to build a
    lot of solutions, but you have to add your own software to the MEAN stack to deliver
    a solution.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 但在栈提供了构建解决方案所需的所有元素的情况下，这就不成立了；MEAN 栈包含了构建许多解决方案的所有组件，但你必须将你自己的软件添加到 MEAN 栈中才能提供解决方案。
- en: 1.5.1 ELK stack
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.5.1 ELK 栈
- en: The best-known stack within the software landscape for log processing is ELK
    (Elasticsearch, Logstash, Kibana). This combination of products provides the ability
    to perform log analytics with Elasticsearch, visualization through Kibana, and
    log routing and aggregation with Logstash. The ELK stack has fitted together so
    well because all three components, while open source, have been developed by Elastic
    ([www.elastic.co](http://www.elastic.co)), which has been successful, like Red
    Hat, with an open source–based business model.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件领域中，用于日志处理的最佳知名栈是 ELK（Elasticsearch、Logstash、Kibana）。这个产品组合提供了使用 Elasticsearch
    进行日志分析、通过 Kibana 进行可视化和使用 Logstash 进行日志路由和聚合的能力。ELK 栈之所以能够如此完美地结合在一起，是因为这三个组件（虽然都是开源的）都是由
    Elastic（[www.elastic.co](http://www.elastic.co)）开发的，Elastic 与 Red Hat 一样，采用基于开源的商业模式取得了成功。
- en: While a single vendor for these components leads to them being neatly integrated
    and complementing each other’s features, it also means that development effort
    can be heavily influenced by the vendor’s business model and objectives. For Elastic,
    this is to sell more services and enterprise extensions to the different parts
    of the ELK stack. This issue can be addressed by the open source product being
    governed by an external and neutral organization such as Apache, CNCF, or the
    Linux Foundation. But ELK is not subject to such governance.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然单一供应商为这些组件提供了整洁的集成和相互补充的功能，但也意味着开发工作可能会受到供应商的商业模式和企业目标的重度影响。对于 Elastic 来说，这是为了向
    ELK 栈的不同部分销售更多服务和企业扩展。这个问题可以通过由外部和中立组织（如 Apache、CNCF 或 Linux 基金会）管理的开源产品来解决。但
    ELK 并不受此类治理。
- en: Unfortunately, Logstash, as part of this stack, has been impacted by the perception
    that it is biased to Elasticsearch as a target solution for log events (which
    may or may not be valid). Logstash does have plugins for products other than Elasticsearch.
    However, it could be argued that these plugins have had to come from vendors wanting
    to compete with Elasticsearch in the ELK stack, or Elastic has had to implement
    them to remain competitive. In comparison to Elastic, the founders of Fluentd
    didn’t have their own analytics product as a preferred location for log events
    to be sent. We could also consider the adoption of Fluentd by CNCF as an implicit
    recognition of being free from these biases. It also helps that the community
    around Fluentd has produced more plugins, making it more flexible than Logstash.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，作为此堆栈的一部分，Logstash 受到了它偏向于将 Elasticsearch 作为日志事件的最终解决方案（这可能有效也可能无效）的印象的影响。Logstash
    确实为除 Elasticsearch 之外的产品提供了插件。然而，可以争辩说，这些插件必须来自想要在 ELK 堆栈中与 Elasticsearch 竞争的供应商，或者
    Elastic 必须实施它们以保持竞争力。相比之下，Fluentd 的创始人没有自己的分析产品作为日志事件发送的首选位置。我们还可以考虑 CNCF 对 Fluentd
    的采用作为一种隐含的认可，即它不受这些偏见的影响。此外，Fluentd 围绕的社区产生了更多的插件，使其比 Logstash 更灵活。
- en: This has led to a variant stack known as EFK that is gaining traction (Elasticsearch,
    Fluentd, Kibana). As Fluentd has plugins for Elasticsearch and Kibana, this alternate
    stack is viewed as equally capable but with greater flexibility for unification.
    OpenShift, for example, adopted EFK to manage log events (see [http://mng.bz/YwDj](https://shortener.manning.com/YwDj)).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了被称为 EFK 的变体堆栈，它正在获得关注（Elasticsearch, Fluentd, Kibana）。由于 Fluentd 为 Elasticsearch
    和 Kibana 提供了插件，这个替代堆栈被视为具有同等的能力，但具有更大的统一灵活性。例如，OpenShift 采用了 EFK 来管理日志事件（见 [http://mng.bz/YwDj](https://shortener.manning.com/YwDj)）。
- en: As shown in figure 1.4, both ELK and EFK have lightweight, smaller variants
    of the unification capability. Beat’s relationship to Logstash is the same as
    Fluent Bit’s relationship to Fluentd (more on Beats and Fluent Bit later in this
    chapter).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 1.4 所示，ELK 和 EFK 都有轻量级、较小的统一能力变体。Beat 与 Logstash 的关系与 Fluent Bit 与 Fluentd
    的关系相同（关于 Beats 和 Fluent Bit 的更多内容将在本章后面介绍）。
- en: '![](../Images/CH01_F04_Wilkins.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH01_F04_Wilkins.png)'
- en: Figure 1.4 ELK vs. EFK software stacks, illustrating how the stacks differ and
    which products are involved in each stack
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.4 ELK 与 EFK 软件堆栈对比，展示了堆栈之间的差异以及每个堆栈中涉及的产品
- en: 1.5.2 Comparing Fluentd and Logstash
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.5.2 比较 Fluentd 和 Logstash
- en: In table 1.1, we have tried to draw out the differentiators of the two products.
    Both have a lot in common, which is why it is possible to replace Logstash with
    Fluentd in the stack. However, there are differences worth highlighting.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在表 1.1 中，我们尝试总结了两款产品的不同之处。它们有很多共同点，这也是为什么在堆栈中可以用 Fluentd 替换 Logstash 的原因。然而，也有一些值得强调的差异。
- en: Table 1.1 Fluentd and Logstash comparison
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1.1 Fluentd 和 Logstash 对比
- en: '| Aspect | Fluentd | Logstash |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 方面 | Fluentd | Logstash |'
- en: '| Primary contributor and product governance | Treasure Data governed by CNCF
    | Elastic |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 主要贡献者和产品治理 | Treasure Data，由 CNCF 管理 | Elastic |'
- en: '| Commercially supported versions | Yes | Yes (more robust option, as support
    can cover the full stack) |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 商业支持版本 | 是 | 是（更稳健的选项，因为支持可以涵盖整个堆栈） |'
- en: '| Plugins available | ~500 | ~200 |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 可用的插件 | ~500 | ~200 |'
- en: '| Configuration style | Declarative—use of tags | Procedural—use of if-then-else
    constructs. |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 配置风格 | 声明式——使用标签 | 过程式——使用 if-then-else 构造。 |'
- en: '| Performance | Comparatively (to Logstash) lower memory footprint | Comparatively
    (to Fluentd) higher memory footprint |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 性能 | 与 Logstash 相比，内存占用较低 | 与 Fluentd 相比，内存占用较高 |'
- en: '| Caching | Highly configurable cache options with file and memory caching
    out the box | In-memory queue with a fixed size |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 缓存 | 默认提供高度可配置的缓存选项，包括文件和内存缓存 | 具有固定大小的内存队列 |'
- en: '| Language/run-time machine | CRuby—no run time required for core | JRuby with
    dependency on Java run time (JVM) |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 语言/运行时机器 | CRuby—不需要核心运行时 | JRuby，依赖于 Java 运行时 (JVM) |'
- en: 1.5.3 The relationship between Fluentd and Fluent Bit
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.5.3 Fluentd 和 Fluent Bit 之间的关系
- en: Fluentd has a small C-based kernel, but the bulk of the product is built using
    Ruby. This brings a bit of a tradeoff. The core tradeoff with Ruby is that it
    runs on an interpreter (although several variants utilize the Java Virtual Machine,
    Truffle, and so on, instead of the original interpreter, such as JRuby, used by
    Logstash). Ruby uses a packaging tool known as Gems to provide additional libraries
    and even applications. To enable Fluentd to be used in Internet of Things (IoT)
    situations, a smaller resource footprint is needed for devices like a smart meter
    or Raspberry Pi. The objective of creating a minimal footprint version of Fluentd
    led to the creation of Fluent Bit. Fluent Bit provides a subset of the Fluentd
    features, focusing on taking log events and routing them to a more centralized
    location. The log events can then be processed (filtered, transformed, enriched,
    etc.) more effectively—as you would expect of Fluentd. Table 1.2 the differences
    between Fluentd and Fluent Bit.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd 拥有一个基于 C 的小型内核，但大部分产品是用 Ruby 构建的。这带来了一些权衡。与 Ruby 相关的核心权衡是它在解释器上运行（尽管有几个变体使用
    Java 虚拟机、Truffle 等代替原始解释器，如 Logstash 使用的 JRuby）。Ruby 使用名为 Gems 的打包工具来提供额外的库甚至应用程序。为了使
    Fluentd 能够在物联网（IoT）场景中使用，需要为智能电表或树莓派等设备提供更小的资源占用。创建 Fluentd 最小占用版本的目标导致了 Fluent
    Bit 的诞生。Fluent Bit 提供了 Fluentd 部分功能，专注于将日志事件路由到更集中的位置。然后可以更有效地处理日志事件（过滤、转换、丰富等），正如您期望
    Fluentd 那样。表 1.2 展示了 Fluentd 和 Fluent Bit 之间的差异。
- en: Table 1.2 Fluentd vs. Fluent Bit
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1.2 Fluentd 与 Fluent Bit 对比
- en: '| Aspect | Fluentd | Fluent Bit |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 方面 | Fluentd | Fluent Bit |'
- en: '| Development language | Written using C & Ruby | Written using C to minimize
    the deployment footprint |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| 开发语言 | 使用 C 和 Ruby 编写 | 使用 C 编写以最小化部署占用空间|'
- en: '| Dependencies | Dependency upon RubyGems | No dependencies (unless customized)
    |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| 依赖项 | 依赖于 RubyGems | 无依赖（除非自定义）|'
- en: '| Storage and memory footprint | Memory requirements ~20 MB, depending upon
    configuration and plugins | ~150 Kb |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 存储和内存占用 | 内存需求约为 20 MB，具体取决于配置和插件 | 约 150 Kb |'
- en: '| Plugins available | Able to leverage approximately 300 prebuilt and third-party
    plugins | Restricted to the in-built plugins and 30 other extensions.Input    
                               OutputCPU stats                       FluentdTreasureKernel
    messages         HTTPMemory stats                 LibrarySerial interfaces    
           ElasticsearchTCP                                   InfluxDBLog Files  
                           NATSDocker                             StatisticsMQTT  
                                 Treasure Data Service |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 可用的插件 | 能够利用大约 300 个预构建和第三方插件 | 限制为内置插件和 30 个其他扩展。输入 | 输出 | CPU 状态 | Fluentd
    TreasureKernel 消息 | HTTP | 内存状态 | 图书馆 | 串行接口 | Elasticsearch | TCP | InfluxDB
    | 日志文件 | NATS | Docker | 统计数据 | MQTT | Treasure Data 服务 |'
- en: '| OS support | Prebuilt installers for a wide range of OSes covering most flavors
    of Windows, OS X, Linux | A number of small-footprint Linux variants based on
    CentOS, Debian (and derivatives, such as Raspbian), and Ubuntu for x86 and AArch
    processors have been built.Other OSes such as BSD-based Unixes may be supported,
    but there are no guarantees for plugins. |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 操作系统支持 | 提供适用于各种操作系统预构建安装程序，涵盖大多数 Windows、OS X、Linux 版本 | 基于 CentOS、Debian（及其衍生版本，如
    Raspbian）和 Ubuntu 的多种小尺寸 Linux 变体，适用于 x86 和 AArch 处理器。其他基于 BSD 的 Unix 操作系统可能得到支持，但对于插件没有保证。|'
- en: Despite these differences, Fluent Bit and Fluentd are more than capable of working
    together, as we’ll see later in the book. IoT isn’t the only use case that lends
    itself well to the use of Fluent Bit. When considering microservices, small footprints
    and rapid startup times are highly desirable for some containers. We’ll explore
    the deployment possibilities later in the book for microservices and the use of
    Fluentd or Fluent Bit.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '尽管存在这些差异，但 Fluent Bit 和 Fluentd 还是完全能够协同工作，正如我们在本书后面的内容中将会看到的。物联网并不是唯一适合使用
    Fluent Bit 的用例。当考虑微服务时，对于某些容器来说，小尺寸和快速启动时间是非常理想的。我们将在本书后面的内容中探讨微服务的部署可能性以及 Fluentd
    或 Fluent Bit 的使用。 '
- en: 1.5.4 The relationship between Logstash and Beats
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.5.4 Logstash 与 Beats 之间的关系
- en: 'The relationship between Beats and Logstash does differ a bit from that between
    Fluentd and Fluent Bit. For a start, the Beats are actually a set of individual
    small footprint components collecting data for one thing. Each individual Beat
    solution is built upon a Go library called *libbeat*, compared with Logstash’s
    use of Java. The Beats family are made up of the following:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Beats 与 Logstash 之间的关系与 Fluentd 与 Fluent Bit 之间的关系略有不同。首先，Beats 实际上是一套小型组件集合，用于收集特定类型的数据。每个单独的
    Beat 解决方案都是基于名为 *libbeat* 的 Go 库构建的，与 Logstash 使用 Java 相比。Beats 家族包括以下内容：
- en: '*Filebeat*—Collects log files (with specific modules to handle Apache, server
    logs, etc.)'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Filebeat*—收集日志文件（具有特定模块以处理 Apache、服务器日志等）'
- en: '*Packetbeat*—Collects network packet data (DNS, HTTP, ICMP, etc.)'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Packetbeat*—收集网络数据包数据（DNS、HTTP、ICMP 等）'
- en: '*Metricbeat*—Collects server metrics'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Metricbeat*—收集服务器指标'
- en: '*Heartbeat* *—*Provides an uptime monitor'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Heartbeat* *—* 提供正常运行时间监控'
- en: '*Auditbeat* *—*Collects audit events to monitor activities through systemd
    ([http://mng.bz/6Z9o](http://mng.bz/6Z9o)) and Auditd ([http://mng.bz/oa5d](http://mng.bz/oa5d))
    on Linux'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Auditbeat* *—* 收集审计事件，通过 systemd ([http://mng.bz/6Z9o](http://mng.bz/6Z9o))
    和 Auditd ([http://mng.bz/oa5d](http://mng.bz/oa5d)) 在 Linux 上监控活动'
- en: '*Winlogbeat*—Integrates into Windows OS to run PowerShell scripts and Sysmon,
    among others'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Winlogbeat*—集成到 Windows 操作系统，运行 PowerShell 脚本和 Sysmon 等'
- en: '*Functionbeat*—Works with serverless solutions, currently just on AWS (Amazon
    Web Services)'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Functionbeat*—与无服务器解决方案协同工作，目前仅限于 AWS (Amazon Web Services)'
- en: The libbeat library has been made available as open source. It has made it a
    lot easier (and given the assurance of code independence) for third parties, including
    the open source community, to build more Beat solutions using the framework. All
    the beats use a shared data structure definition to communicate the data collected.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: libbeat 库已作为开源软件提供。这使得第三方，包括开源社区，使用该框架构建更多 Beat 解决方案变得更加容易（并提供了代码独立性的保证）。所有
    Beats 都使用共享的数据结构定义来传递收集的数据。
- en: 1.6 Log routing as a vehicle for security
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.6 日志路由作为安全手段
- en: With infrastructure becoming increasingly configuration-driven rather than being
    physical boxes and cables, the points where data can have ingress and egress to
    an environment can increase quickly, as it is simply a case of configuring new
    points where data can come and go. It is preferable that the number of points
    at which data passes between public and private networks be limited—this is just
    one of many reasons for having backend (or reverse) proxies. With logging agents
    in the pure aggregation model, each node wants to talk directly to the point of
    aggregation. This can be mitigated if the solution can tolerate network proxies.
    But would it not be better to use a proxy that better understands what is being
    routed, such as Fluentd?
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 随着基础设施越来越多地由配置驱动，而不是物理盒子和电缆，数据可以进入和离开环境的位置可以迅速增加，因为这只是一个配置新点的问题，数据可以进出。最好限制数据在公共网络和私有网络之间传输的点数——这仅仅是拥有后端（或反向）代理的许多原因之一。在纯聚合模型中，日志代理的每个节点都希望直接与聚合点通信。如果解决方案可以容忍网络代理，则可以减轻这种情况。但使用更了解正在路由的内容的代理，如
    Fluentd，不是更好吗？
- en: Definition *Proxies* are servers that retrieve resources on behalf of a client
    from one or more servers. The retrieved resources are then returned to the requestor,
    appearing as originating from the proxy server itself. Proxies are described as
    a backend or reverse if deployed closer to the server performing the computation
    rather than the (usually lightweight) client. Proxies are usually implemented
    to optimize network load by implementing traffic caching and applying security
    by controlling where data enters and leaves a network.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 *代理* 是代表客户端从一台或多台服务器检索资源的服务器。检索到的资源随后返回给请求者，看起来就像是从代理服务器本身发出的。如果部署在执行计算的（通常是轻量级）客户端而不是服务器附近，则代理被描述为后端或反向代理。代理通常通过实现流量缓存和应用通过控制数据进入和离开网络的方式来优化网络负载。
- en: The log routing capabilities of Fluentd, as we’ll see, allow us to use Fluentd
    nodes as routers/consolidators of logs, meaning we can control network exposure,
    as well as several other considerations.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，Fluentd 的日志路由功能允许我们使用 Fluentd 节点作为日志的路由器/整合器，这意味着我们可以控制网络暴露，以及考虑其他几个方面。
- en: Security considerations within Fluentd go beyond configuring routing to control
    network points for ingress and egress of logs in networks. Fluentd supports the
    use of SSL/TLS certificates, so that the data being sent between Fluentd nodes
    or between Fluentd and other networked services (e.g. MongoDB) is secure. This
    increases security by making checks for authenticity and the ability to encrypt
    the data. Today, security needs to be an aspect of everything we do, rather than
    a bolt-on; we’ll address such issues directly where appropriate throughout the
    book.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在Fluentd中的安全考虑不仅限于配置路由来控制网络中的日志的入网和出网。Fluentd支持使用SSL/TLS证书，以确保Fluentd节点之间或Fluentd与其他网络服务（例如MongoDB）之间传输的数据是安全的。这通过验证真实性和加密数据的能力提高了安全性。今天，安全需要成为我们行动的各个方面的一个方面，而不仅仅是附加的；我们将在适当的地方直接解决这些问题。
- en: 1.7 Log event life cycle
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.7 日志事件生命周期
- en: Another perspective worth considering is the life cycle of a log event. When
    a software component of some kind generates a log entry, to get value from it,
    it needs to be passed through a life cycle, shown in figure 1.5.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个值得考虑的视角是日志事件的周期。当某种类型的软件组件生成日志条目时，为了从中获得价值，它需要通过一个生命周期，如图1.5所示。
- en: '![](../Images/CH01_F05_Wilkins.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图1.5 Wilkins](../Images/CH01_F05_Wilkins.png)'
- en: Figure 1.5 The typical life cycle for a log event
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5 日志事件的典型生命周期
- en: As figure 1.5 shows, we start with capturing the log event (*information source
    capture*), and as the event flows down, it gains more meaning and value. Based
    on what we’ve already discussed, any log unification tool, including Fluentd,
    is most effective with the information source capture and the *structure* *and
    route* phases. The *aggregate* *and analyze* phase will see features for analysis
    focusing on individual events but will lean on aggregating and analyzing aggregated
    logs. *Visualize data* is the product’s weakest area. Given these tools’ routing
    and connectivity capabilities, the *notify* *and alert* phase is easily realized
    by connecting suitable services. Not only that, but there is also the potential
    for this phase to be moved upward, as we don’t always need the analytics products
    to decide whether it is necessary to notify and alert.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如图1.5所示，我们首先从捕获日志事件（*信息源捕获*）开始，随着事件的流动，它获得了更多的意义和价值。基于我们之前讨论的内容，任何日志统一工具，包括Fluentd，在信息源捕获以及*结构*和*路由*阶段最为有效。*聚合*和*分析*阶段将看到针对单个事件的特性，但将依赖于聚合和分析聚合日志。*可视化数据*是产品的薄弱环节。鉴于这些工具的路由和连接能力，通过连接合适的服务，*通知*和*警报*阶段可以轻松实现。不仅如此，这一阶段还有可能向上移动，因为我们并不总是需要分析产品来决定是否需要通知和警报。
- en: As shown in the figure, tools like Fluentd support the upper half of the life
    cycle very well (from capture to aggregate and some of the analyze stage). The
    lower half is well supported by log analytics (*aggregate* *and analyze*, *visualize
    data*, *notify* *and* *alert*).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 如图中所示，Fluentd等工具在生命周期上半部分（从捕获到聚合以及部分分析阶段）支持得非常好。下半部分则由日志分析（*聚合*和*分析*，*可视化数据*，*通知*和*警报*）得到很好的支持。
- en: 1.8 Evolution of Fluentd
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.8 Fluentd的演变
- en: In this section, we will look at the events that led to the creation of Fluentd
    and its rapid growth in adoption. Figure 1.6 shows a timeline of key events in
    the evolution of Fluentd.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨导致Fluentd创建及其快速普及的事件。图1.6显示了Fluentd演变过程中的关键事件的时序图。
- en: '![](../Images/CH01_F06_Wilkins.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![图1.5 日志事件的典型生命周期](../Images/CH01_F06_Wilkins.png)'
- en: Figure 1.6 Timeline of events that have influenced Fluentd
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.6 影响Fluentd的关键事件的时序图
- en: 1.8.1 Treasure Data
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.8.1 Treasure Data
- en: Fluentd’s origins go back to 2011 when *big data*, through the use of Hadoop,
    was impacting mainstream IT. As a Silicon Valley startup, Treasure Data was established
    to create value around Hadoop-based processing of semi-structured data. Treasure
    Data found it needed a tool to help it capture data from multiple sources and
    ingest the data into a Hadoop data store. As a result, it set about building Fluentd
    and made it available as free and open source software (FOSS) using the Apache
    2 License ([www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)).
    This made it easy to build upon, extend, and exploit the tool. As a result, developers
    (other than just those working for Treasure Data) contributed to and extended
    Fluentd.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd的起源可以追溯到2011年，当时通过使用Hadoop，**大数据**正在影响主流IT。作为硅谷的一家初创公司，Treasure Data成立是为了围绕基于Hadoop的半结构化数据处理创造价值。Treasure
    Data发现它需要一个工具来帮助它从多个来源捕获数据并将数据摄取到Hadoop数据存储中。因此，它着手构建Fluentd，并使用Apache 2许可证（[www.apache.org/licenses/LICENSE2.0](http://www.apache.org/licenses/LICENSE2.0)）将其作为免费和开源软件（FOSS）发布。这使得构建、扩展和利用工具变得容易。因此，除了为Treasure
    Data工作的开发者之外，其他开发者也对Fluentd做出了贡献并进行了扩展。
- en: NOTE To learn more about Hadoop, check out the liveBook version of *Mastering
    Large Datasets with Python* by John T. Wolohan (Manning, 2020) at [http://mng.bz/do2o](http://mng.bz/do2o).
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：想了解更多关于Hadoop的信息，请查看John T. Wolohan所著的《Mastering Large Datasets with
    Python》的liveBook版本（Manning, 2020），链接为[http://mng.bz/do2o](http://mng.bz/do2o)。'
- en: In 2013, Fluentd got a big boost due to the recommendation by AWS for data collection
    across and onto their platform. This was further helped by Google using Fluentd
    with its BigQuery product and then incorporating Fluentd into its monitoring solution.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 2013年，由于AWS推荐在其平台上进行数据收集，Fluentd得到了很大的推动。这进一步得到了谷歌使用Fluentd与其BigQuery产品相结合，并将其纳入其监控解决方案的帮助。
- en: Treasure Data background
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: Treasure Data背景
- en: Treasure Data was founded in 2011 to deliver business value using big data technologies
    such as Hadoop. However, Sadayuki Furuhashi and the team at Treasure Data found
    they needed a tool to help them capture and ingest data and set about building
    Fluentd. It was made available as open source in October 2011\. Since 2011, Treasure
    Data has developed several specialist areas such as Customer Information Systems
    and the Internet of Things (IoT).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: Treasure Data成立于2011年，旨在通过使用Hadoop等大数据技术来提供商业价值。然而，Sadayuki Furuhashi和Treasure
    Data的团队发现他们需要一个工具来帮助他们捕获和摄取数据，于是着手构建Fluentd。它于2011年10月作为开源软件发布。自2011年以来，Treasure
    Data已开发出几个专业领域，如客户信息系统和物联网（IoT）。
- en: Treasure Data has since been acquired by the microprocessor company Arm (and,
    in turn, Arm was acquired by NVIDIA) and spun out to be a business in the SoftBank
    Group Corp. However, Fluentd is still important to Treasure Data, and the team
    continues to be very active committers to GitHub for several important open source
    projects, including Fluentd and Fluent Bit.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 自那时起，Treasure Data已被微处理器公司Arm收购（随后Arm又被NVIDIA收购），并从SoftBank Group Corp.中分离出来成为一个业务。然而，Fluentd对Treasure
    Data仍然很重要，并且团队继续是GitHub上几个重要开源项目（包括Fluentd和Fluent Bit）的非常活跃的贡献者。
- en: 1.8.2 CNCF
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.8.2 CNCF
- en: The next major event for Fluentd was its adoption by the Cloud Native Computing
    Foundation (CNCF). CNCF’s existence was strongly influenced by Google in conjunction
    with the Linux Foundation to give Kubernetes a vendor-neutral home. Kubernetes
    is designed to run multiple containers across one or more servers, with containers
    hosting one or more different applications. Not to mention that containers can
    be started and torn down on the different servers as needed. From this, it is
    clear that corralling and routing log data is a critical challenge that can be
    answered well by Fluentd’s capabilities.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd的下一个重大事件是它被云原生计算基金会（CNCF）采用。CNCF的存在受到了谷歌和Linux基金会的强烈影响，旨在为Kubernetes提供一个中立的家园。Kubernetes旨在在一台或多台服务器上运行多个容器，容器托管一个或多个不同的应用程序。更不用说容器可以根据需要在不同服务器上启动和关闭。从这个角度来看，收集和路由日志数据是一个关键挑战，而Fluentd的功能可以很好地解决这个问题。
- en: Fluentd’s history with the CNCF
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd与CNCF的历史
- en: Google donated Kubernetes to the CNCF and made it possible for competing enterprises
    to bring together and collaborate more effectively on Kubernetes and its ecosystem.
    Like CNCF’s parent, the Linux Foundation, all its projects are open source and
    supported by many contributors. Fluentd was among the first projects after Kubernetes
    to come under the CNCF’s governance and, as a result, was an early graduate.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌向CNCF捐赠了Kubernetes，使得竞争企业能够更有效地在Kubernetes及其生态系统中协作。像CNCF的母公司Linux Foundation一样，所有项目都是开源的，并得到了许多贡献者的支持。Fluentd是Kubernetes之后第一个受到CNCF治理的项目，因此它是一个早期的毕业生。
- en: 1.8.3 Relationship to major cloud vendors PaaS/IaaS
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.8.3 与主要云供应商PaaS/IaaS的关系
- en: 'Infrastructure as a Service (IaaS) and Platform as a Service (PaaS) solutions
    have influenced and been influenced by CNCF projects. It is only natural that
    those technologies have the best chance of being incorporated or supported by
    cloud platform offerings. When it comes to Fluentd, we have seen the major vendors
    (AWS, Azure, Google, Oracle, DigitalOcean, Alibaba, etc.) do one of the following:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 基础设施即服务（IaaS）和平台即服务（PaaS）解决方案受到了CNCF项目的启发，同时也影响了CNCF项目。这些技术有最好的机会被云平台服务所整合或支持。当涉及到Fluentd时，我们已经看到主要供应商（AWS、Azure、Google、Oracle、DigitalOcean、阿里巴巴等）采取了以下行动之一：
- en: Directly leverage Fluentd for their own needs (e.g., Google, Oracle)
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 直接利用Fluentd满足自己的需求（例如，谷歌、甲骨文）
- en: Package it up as part of a larger offering (Bitnami, Google Stackdriver)
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将其打包为更大服务的一部分（Bitnami、Google Stackdriver）
- en: Expose their various services to being accessible as inputs or outputs to their
    services (AWS—S3, RDS, CloudWatch, Beanstalk, etc.)
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将他们的各种服务暴露为输入或输出，以便他们的服务可以访问（AWS—S3、RDS、CloudWatch、Beanstalk等）
- en: For example, AWS has output plugins for its storage services. AWS’s CloudWatch
    solution can both receive and send log information to Fluentd. As we have seen,
    Google embraced Fluentd early on.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，AWS为其存储服务提供了输出插件。AWS的CloudWatch解决方案可以接收和发送日志信息到Fluentd。正如我们所见，谷歌早期就采用了Fluentd。
- en: Beyond the IaaS cloud offerings, there is a range of specialist PaaS services
    for performing log analytics, ranging from Loggly ([www.loggly.com](https://www.loggly.com))
    to Datadog ([www.datadoghq.com](https://www.datadoghq.com)). These vendors have
    provided plugins into Fluentd, so it becomes effortless for customers to route
    log data to these services.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 除了IaaS云服务之外，还有一系列专门针对日志分析的平台即服务（PaaS）服务，从Loggly([www.loggly.com](https://www.loggly.com))到Datadog([www.datadoghq.com](https://www.datadoghq.com))。这些供应商已经为Fluentd提供了插件，因此客户将这些日志数据路由到这些服务变得轻而易举。
- en: 1.9 Where can Fluentd and Fluent Bit be used?
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.9 Fluentd和Fluent Bit在哪里可以使用？
- en: Fluentd and Fluent Bit can be used or adapted to almost any situation, from
    running in containers to being deployed on IoT devices to mainframe solutions.
    As we have seen, Fluent Bit’s footprint is small enough to operate on a vast range
    of IoT devices, which is reflected in part by Arm’s acquisition of Treasure Data.
    Fluentd and Fluent Bit together cover at least 90% of the OS platforms in use
    today. As already discussed, Fluentd works well with cloud offerings, but it is
    not bound to the cloud and can work in more traditional virtualized or dedicated
    server deployments.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd和Fluent Bit可以用于或适应几乎任何情况，从在容器中运行到部署在物联网设备上，再到大型机解决方案。正如我们所见，Fluent Bit的体积足够小，可以在广泛的物联网设备上运行，这在某种程度上反映了Arm对Treasure
    Data的收购。Fluentd和Fluent Bit一起覆盖了至少90%今天使用的操作系统平台。正如已经讨论过的，Fluentd与云服务配合良好，但它并不局限于云，也可以在更传统的虚拟化或专用服务器部署中工作。
- en: The more relevant question should be, will deploying Fluentd or Fluent Bit make
    your job easier? Should you use Fluent Bit or Fluentd?
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 更相关的问题应该是，部署Fluentd或Fluent Bit是否会让你工作更轻松？你应该使用Fluent Bit还是Fluentd？
- en: Using Fluentd and Fluent Bit, from a basic laptop or desktop machine, to servers,
    physical and virtual, running Windows and Linux OSes, can be done without any
    worries. This means that as we get hands-on in the rest of the book, putting Fluentd
    into action should be possible. The possible exception is chapter 8, when we run
    Kubernetes and Docker, which will need a bit more power, but we’re still talking
    about a midrange desktop or laptop. But understanding the limits of Fluentd can
    help beyond that.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Fluentd和Fluent Bit，从基本的笔记本电脑或台式机，到服务器，无论是物理的还是虚拟的，运行Windows和Linux操作系统，都可以无忧无虑地进行。这意味着在我们继续本书的其余部分，将Fluentd投入实际应用应该是可能的。可能的例外是第8章，当我们运行Kubernetes和Docker时，这将需要更多的计算能力，但我们仍然在谈论中端桌面或笔记本电脑。但了解Fluentd的限制可以帮助我们超越这一点。
- en: 1.9.1 Platform constraints
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.9.1 平台限制
- en: Beyond the OS and hardware, platform constraints are minimal. The most basic
    environment just needs to be able to run the Ruby engine. Ruby is supported by
    a range of standard package-based installations (yum, Homebrew, apt, RubyInstaller
    for Windows, to name a few). Making the installation for all the standard OSes
    is straightforward, and the package managers should help resolve any dependency
    issues. But for the less common environments, Ruby also provides a “from source”
    installation guide (www.ruby-lang.org/). If there isn’t a prebuilt installation
    option for Fluentd itself—a rare situation given the prebuilt installers covered
    (RPM, Deb, MSI, and RubyGems)—then the Fluentd website ([https://fluentd.org](https://fluentd.org))
    provides details of how to achieve an installation from the source code.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 除了操作系统和硬件之外，平台限制很小。最基本的环境只需要能够运行 Ruby 引擎。Ruby 被多种基于标准的包安装方式支持（yum、Homebrew、apt、Windows
    的 RubyInstaller 等）。为所有标准操作系统进行安装很简单，包管理器应有助于解决任何依赖性问题。但对于不太常见的环境，Ruby 也提供了“从源码”安装指南（www.ruby-lang.org/）。如果
    Fluentd 本身没有预构建的安装选项——考虑到已涵盖的预构建安装程序（RPM、Deb、MSI 和 RubyGems），那么 Fluentd 网站 ([https://fluentd.org](https://fluentd.org))
    提供了如何从源代码进行安装的详细信息。
- en: Depending upon the configurations that need to be established, Fluentd has additional
    plugins that may be required. Fluentd plugins are typically deployed using RubyGems
    (an open source package manager for Ruby components; [https://rubygems.org/)](https://rubygems.org/).
    Gems can be installed from a local location if you need stringent network controls.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 根据需要设置的配置，Fluentd 可能需要额外的插件。Fluentd 插件通常使用 RubyGems（Ruby 组件的开源包管理器；[https://rubygems.org/](https://rubygems.org/)）进行部署。如果需要严格的网络控制，可以从本地位置安装
    Gems。
- en: Optionally, there are prebuilt solutions that can be deployed to Docker and
    Kubernetes if preferred. We will address the question of deployment of Fluentd
    as part of Kubernetes later in the book.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，还有预构建的解决方案可以部署到 Docker 和 Kubernetes。我们将在本书的后面部分讨论 Fluentd 作为 Kubernetes
    部署的问题。
- en: The last option—while we believe it is possible, we haven’t heard of it being
    tried—is the creation of a platform-native binary of Fluentd through the use of
    GraalVM ([https://www.graalvm.org/docs/getting-started/](https://www.graalvm.org/docs/getting-started/)).
    GraalVM is a next-generation language virtual machine that incorporates Java (JVM)
    and several other language interpreter packs, including Ruby ([https://github.com/oracle/truffleruby](https://github.com/oracle/truffleruby)).
    But GraalVM also can create platform native binaries for Java and the other supported
    languages as well.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个选项——虽然我们认为这是可能的，但我们还没有听说有人尝试过——是通过使用 GraalVM ([https://www.graalvm.org/docs/getting-started/](https://www.graalvm.org/docs/getting-started/))
    创建 Fluentd 的平台原生二进制文件。GraalVM 是一种下一代语言虚拟机，它集成了 Java（JVM）和包括 Ruby 在内的其他几种语言解释器包（[https://github.com/oracle/truffleruby](https://github.com/oracle/truffleruby)）。但
    GraalVM 也可以为 Java 和其他支持的语言创建平台原生二进制文件。
- en: With Fluentd deployed, it needs to read one or more configuration files that
    tells Fluentd (typically installed as a daemon process in production) what it
    should do.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 部署 Fluentd 后，它需要读取一个或多个配置文件，这些文件告诉 Fluentd（通常在生产中作为守护进程安装）它应该做什么。
- en: Definition A *daemon* is a computer program that runs as a background process
    and is usually started and stopped by the operating system when it starts up and
    shuts down. This term is more commonly associated with Linux- and Unix-based operating
    systems. Often, applications designed to operate this way will have their name
    end with a *d*; for example, *syslogd* is a daemon that implements system logging
    (Syslog) in Linux. In Windows operating systems, these processes are referred
    to as *Windows services*.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 A *守护进程* 是一种作为后台进程运行的计算机程序，通常在操作系统启动和关闭时由操作系统启动和停止。这个术语更常与基于 Linux 和 Unix
    的操作系统相关联。通常，设计为以这种方式运行的应用程序其名称将以 *d* 结尾；例如，*syslogd* 是在 Linux 中实现系统日志（Syslog）的守护进程。在
    Windows 操作系统中，这些进程被称为 *Windows 服务*。
- en: So, any deployment location needs to be able to read the file and ideally allow
    updates to the file for Fluentd. Fluent Bit can use a configuration file or even
    interpret the configuration from a command-line parameter.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，任何部署位置都需要能够读取文件，并且理想情况下允许对 Fluentd 的文件进行更新。Fluent Bit 可以使用配置文件，甚至可以从命令行参数中解释配置。
- en: 1.10 Fluentd UI-based editing
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.10 基于 Fluentd UI 的编辑
- en: Fluentd does have a browser-delivered user interface. Figure 1.7 illustrates
    one of the UI screens to give a sense of what it is like.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd确实有一个浏览器提供的用户界面。图1.7展示了UI屏幕之一，以展示其外观。
- en: When it comes to working with Fluentd’s UI, it can perform a range of tasks
    such as
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到使用Fluentd的UI时，它可以执行一系列任务，例如
- en: Editing the configuration file
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编辑配置文件
- en: Managing a Fluentd instance in terms of stopping and starting
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从停止和启动的角度管理Fluentd实例
- en: Getting plugins patched or installed
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取插件修补或安装
- en: Inspecting Fluentd’s logs
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查Fluentd的日志
- en: We will focus directly on the configuration file for this book, as this will
    help explore the more complex nuances and is more mature than the UI. We’ll take
    a brief tour of the UI in chapter 2 once we have completed the installation of
    Fluentd.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将直接关注本书的配置文件，因为这有助于探索更复杂的细微差别，并且比UI更成熟。一旦完成Fluentd的安装，我们将在第2章中简要浏览UI。
- en: '![](../Images/CH01_F07_Wilkins.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH01_F07_Wilkins.png)'
- en: Figure 1.7 Part of the Fluentd UI
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7 Fluentd UI的一部分
- en: In addition to the web-based UI, there is an additional plugin for Microsoft’s
    Visual Studio Code that will help with syntax highlighting when editing configuration
    files. The plugin can be used to help address typical issues like missing brackets.
    This plugin can be downloaded from within Visual Studio Code or from [http://mng.bz/GOeA](http://mng.bz/GOeA).
    Other editors, such as Sublime Text, also have open source packages/plugins to
    support the syntax editing of the Fluentd configuration file.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 除了基于Web的UI之外，还有一个用于Microsoft的Visual Studio Code的插件，可以帮助在编辑配置文件时进行语法高亮。此插件可用于帮助解决诸如缺少括号等典型问题。此插件可以从Visual
    Studio Code内部或从[http://mng.bz/GOeA](http://mng.bz/GOeA)下载。其他编辑器，如Sublime Text，也有开源包/插件来支持Fluentd配置文件的语法编辑。
- en: UI for Fluent Bit?
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: Fluent Bit的UI？
- en: Given the intention to make Fluent Bit’s footprint as small as possible, incorporating
    a UI would go against that principle. Typical Fluent Bit uses are to source the
    log events and forward them to the point of aggregation where more processing
    of events can happen (e.g., Fluentd or a log analytics tool). This means the configurations
    should be comparatively simple, and the need for a UI is limited. The case for
    an integrated UI would go against the minimized footprint goal.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到使Fluent Bit的占用空间尽可能小，引入UI将与这一原则相悖。典型的Fluent Bit使用是将日志事件源和转发到聚合点，在那里可以进一步处理事件（例如，Fluentd或日志分析工具）。这意味着配置应该相对简单，对UI的需求有限。集成UI的案例将与最小化占用空间的目标相悖。
- en: 1.11 Plugins
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.11 插件
- en: As mentioned earlier, Fluentd’s plugins in the breadth and depth of coverage
    outweigh most if not all competition. We cannot cover every possible plugin in
    the following chapters, so we’ll focus on those that help illustrate core ideas
    and represent cases that most Fluentd deployments are likely to encounter.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Fluentd的插件在覆盖范围和深度上超过了大多数，如果不是所有竞争者。我们无法在以下章节中涵盖每个可能的插件，因此我们将专注于那些有助于说明核心思想和代表大多数Fluentd部署可能遇到的情况的插件。
- en: 'But given the scope of plugins, it is worth getting a sense of what is available
    and what could be achieved. Fluentd plugins can be grouped into the following
    categories, and with each category, we have provided some examples:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 但鉴于插件的范畴，了解可用的内容和可能实现的内容是值得的。Fluentd插件可以分为以下类别，并且对于每个类别，我们都提供了一些示例：
- en: Inputs
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入
- en: '*File storage*—AWS S3, text files (HTTP log files, etc.)'
  id: totrans-212
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*文件存储*—AWS S3, 文本文件（HTTP日志文件等）'
- en: '*Data(base) source*—MongoDB, MySQL, generic SQL (for all ANSI SQL DBs)'
  id: totrans-213
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据源*—MongoDB, MySQL, 通用SQL（适用于所有ANSI SQL数据库）'
- en: '*Event sources*—AWS Kinesis, Kafka, AWS CloudWatch, GCP Pub/Sub, RabbitMQ'
  id: totrans-214
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*事件源*—AWS Kinesis, Kafka, AWS CloudWatch, GCP Pub/Sub, RabbitMQ'
- en: '*OS*—System, HTTP Endpoint, dstat, SNMP'
  id: totrans-215
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*操作系统*—系统，HTTP端点，dstat，SNMP'
- en: '*App servers*—IIS (Internet Information Services), WebSphere, Tomcat'
  id: totrans-216
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*应用服务器*—IIS (Internet Information Services), WebSphere, Tomcat'
- en: Outputs
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出
- en: '*File storage*—AWS S3, Google Cloud Storage, File'
  id: totrans-218
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*文件存储*—AWS S3, Google Cloud Storage, 文件'
- en: '*Database storage*—BigQuery, MongoDB, InfluxDB, MySQL, SQL Server'
  id: totrans-219
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据库存储*—BigQuery, MongoDB, InfluxDB, MySQL, SQL Server'
- en: '*Event storage*—Kafka, Google Stackdriver, AWS CloudWatch, Prometheus'
  id: totrans-220
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*事件存储*—Kafka, Google Stackdriver, AWS CloudWatch, Prometheus'
- en: '*Log analytics tools*—Splunk, Datadog, Elasticsearch'
  id: totrans-221
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*日志分析工具*—Splunk, Datadog, Elasticsearch'
- en: '*Notifications*—Slack, Mail, HipChat, Twitter, Twilio, PagerDuty'
  id: totrans-222
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*通知*—Slack, 邮件, HipChat, Twitter, Twilio, PagerDuty'
- en: Log/Event Manipulation (parsers, filters, and formatters)
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志/事件操作（解析器、过滤器、格式化器）
- en: '*Map*—Log format mapper'
  id: totrans-224
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Map*—日志格式映射器'
- en: '*Numeric Monitor*—Generates stats relating to logs'
  id: totrans-225
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数值监控器*—生成与日志相关的统计数据'
- en: '*Text to JSON*'
  id: totrans-226
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*文本转 JSON*'
- en: '*Key/Value Parsing*'
  id: totrans-227
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*键/值解析*'
- en: '*GeoIP*—Translating IP addresses to geographic location based on published
    information (for more information on the use of GeoIP, see the liveBook version
    of Securing DevOps by Julien Vehent (Manning, 2018) at [http://mng.bz/raJJ](http://mng.bz/raJJ).'
  id: totrans-228
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*GeoIP*—根据公开信息将 IP 地址转换为地理位置（关于 GeoIP 的更多信息，请参阅 Julien Vehent（Manning, 2018）所著的《Securing
    DevOps》的 liveBook 版本，详情请见 [http://mng.bz/raJJ](http://mng.bz/raJJ)）'
- en: '*JWT*—Working with JSON Web Tokens (more background on this can be found in
    the liveBook version of OpenID Connect in Action by Prabath Siriwardena (Manning,
    2022) at [http://mng.bz/VlMy](http://mng.bz/VlMy).'
  id: totrans-229
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*JWT*—处理 JSON Web Tokens（关于此的更多背景信息可以在 Prabath Siriwardena（Manning, 2022）所著的《OpenID
    Connect in Action》的 liveBook 版本中找到，详情请见 [http://mng.bz/VlMy](http://mng.bz/VlMy)）'
- en: '*Redaction*—The masking of data so sensitive data values can’t be seen by those
    not authorized to do so'
  id: totrans-230
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*红字删除*—对敏感数据值进行屏蔽，使得未经授权的人无法看到'
- en: '*Formatters*—The means to lay out the data into different structures and potentially
    different notations (e.g., XML to JSON)'
  id: totrans-231
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*格式化器*—将数据布局成不同的结构以及可能的不同的表示法（例如，XML 到 JSON）'
- en: Storage
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储
- en: '*Caching*—Redis, Memcached'
  id: totrans-233
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*缓存*—Redis, Memcached'
- en: '*Persistent storage*—Local file, SQL databases, S3 Block storage'
  id: totrans-234
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*持久化存储*—本地文件，SQL 数据库，S3 块存储'
- en: '*Service Discovery*—Configuration to find other nodes that understand Fluentd’s
    comms mechanisms'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*服务发现*—配置以查找理解 Fluentd 通信机制的其它节点'
- en: Note A complete list of available Fluentd plugins is managed at [www.fluentd.org/plugins/all](https://www.fluentd.org/plugins/all).
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：可用的 Fluentd 插件完整列表由 [www.fluentd.org/plugins/all](https://www.fluentd.org/plugins/all)
    管理。
- en: 1.12 How Fluentd can be used to make operational tasks easier
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.12 如何使用 Fluentd 使操作任务更简单
- en: Throughout this chapter, we have examined a number of the scenarios and use
    cases that Fluentd can help with. As we progress through the book, we will introduce
    scenarios and look at increasing complexity.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了 Fluentd 可以帮助解决的一些场景和用例。随着本书的进展，我们将介绍更多场景并观察其复杂性的增加。
- en: 1.12.1 Actionable log events
  id: totrans-239
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.12.1 可操作的日志事件
- en: Rather than waiting until log events are collected together before anything
    is done with the content, it is possible to create configurations so that as they
    are received, they can be processed. Such processing could include filtering to
    find the events that require immediate attention. If a system logs an event that
    typically only occurs shortly before the solution fails—for example, the OS goes
    into a panic state (for more on kernel panic, see [https://wiki.osdev.org/Kernel_Panic](https://wiki.osdev.org/Kernel_Panic))—then
    as soon as that event is detected, we could send a message to someone responsible
    for handling such events via near real-time channels like PagerDuty or Slack (we
    will illustrate the Slack scenario in chapter 4). But actionable log events can
    easily extend further, such as triggering a script to perform automated remediation
    (e.g., purging or archiving older log files so storage isn’t exhausted).
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是等到日志事件收集在一起后再对内容进行处理，可以创建配置，以便在接收到它们时立即进行处理。这种处理可能包括过滤以找到需要立即关注的事件。如果一个系统记录了一个通常只在解决方案失败前很短的时间内发生的事件——例如，操作系统进入恐慌状态（关于内核恐慌的更多信息，请见
    [https://wiki.osdev.org/Kernel_Panic](https://wiki.osdev.org/Kernel_Panic)）——那么一旦检测到该事件，我们就可以通过近实时通道（如
    PagerDuty 或 Slack）向负责处理此类事件的人发送消息（我们将在第 4 章中说明 Slack 场景）。但可操作的日志事件可以很容易地扩展到更远，例如触发脚本以执行自动修复（例如，清除或存档旧日志文件，以免耗尽存储空间）。
- en: 1.12.2 Making logs more meaningful
  id: totrans-241
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.12.2 使日志更有意义
- en: The actionable event can also be extended to provide a means by which log events
    can be made more meaningful. In larger, long-lived organizations, there are legacy
    solutions that are still business-critical (they are typically very large and
    embody lots of logic to ensure compliance to requirements that very few people
    understand). As a result, the replacement cost can be huge, and no one wants to
    take on the risk of making modifications, even to improve log messages to make
    support easier. But such problems can be addressed; those innocent-looking log
    messages that are harbingers of doom if someone doesn’t execute some remediation
    soon can be modified to have things like error codes attached. Ops people can
    then easily find the operational protocol.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 可操作的事件也可以扩展，以提供一种使日志事件更具意义的方法。在更大、寿命更长的组织中，有一些仍然是业务关键性的遗留解决方案（它们通常非常大，包含大量逻辑以确保符合很少人理解的要求）。因此，替换成本可能非常高，没有人愿意承担修改的风险，即使是为了改善日志消息以简化支持。但这些问题是可以解决的；那些看似无辜但如果不立即采取补救措施就会带来灾难的日志消息可以被修改，添加诸如错误代码等内容。运维人员可以轻松找到操作协议。
- en: The application of meaning can go further; some logs will have structures that
    don’t align to standard formats, such as JSON and XML. But Fluentd can be used
    to impose structure quickly and early, so downstream, the log events can be handled
    more efficiently. If an application accidentally logs sensitive data, the sooner
    such information is removed or masked, the better. Otherwise, all downstream log-processing
    solutions have to implement a far more stringent security setup, because they
    will be receiving sensitive data such as credit card data (*PCI compliance*),
    personal data (*General Data Protection Regulation*), or data subject to similar
    legislation. If such issues become a problem, and the source of their logs can’t
    be fixed, Fluentd can filter out or modify the log event to mask such content.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 意义的运用可以更进一步；一些日志的结构可能不符合标准格式，如JSON和XML。但Fluentd可以用来快速和早期地强加结构，因此，下游的日志事件可以更有效地处理。如果一个应用程序意外地记录了敏感数据，那么越早移除或屏蔽此类信息，就越好。否则，所有下游的日志处理解决方案都必须实施更加严格的设置，因为它们将接收敏感数据，如信用卡数据（*PCI合规性*）、个人数据（*通用数据保护条例*）或受类似立法约束的数据。如果这些问题成为问题，并且日志的来源无法修复，Fluentd可以过滤或修改日志事件以屏蔽此类内容。
- en: 1.12.3 Polyglot environments
  id: totrans-244
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.12.3 多语言环境
- en: Over the last 10 years, there has been an explosion of different programming
    languages. As a result, we often talk about *polyglot* environments where many
    different languages are used in an end-to-end solution; for example, R or Python
    may be used to extract deep meaning from data, while web interfaces could be written
    in JavaScript. Backend solutions could be Java, Scala, Clojure, dot Net (.NET),
    and PHP. Thick client applications working with the same backend could be written
    with C#, VB.Net, or Swift. In these types of environments, we need an agnostic
    solution of the implementation language of applications. Fluentd provides this,
    but many languages have libraries that allow log events to be passed in an optimized
    manner directly to Fluentd.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的10年里，不同的编程语言数量激增。因此，我们经常讨论*多语言*环境，在这种环境中，许多不同的语言被用于端到端解决方案；例如，R或Python可能被用来从数据中提取深层含义，而Web界面可以用JavaScript编写。后端解决方案可能是Java、Scala、Clojure、.Net
    (.NET)和PHP。与相同后端协同工作的厚客户端应用程序可以用C#、VB.Net或Swift编写。在这些类型的环境中，我们需要一个对应用程序实现语言中立的解决方案。Fluentd提供了这样的解决方案，但许多语言都有库，允许以优化的方式直接将日志事件传递到Fluentd。
- en: 1.12.4 Multiple targets
  id: totrans-246
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.12.4 多个目标
- en: The multiple targets issue embodies the fact that it is common to have teams
    dedicated to specific tasks in larger organizations, such as information security.
    Different teams want to use different tools to support their specialism—for example,
    algorithms are particularly good at detecting patterns indicating malicious security
    activities.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 多个目标问题体现了在大型组织中，团队通常专注于特定任务的事实，例如信息安全。不同的团队希望使用不同的工具来支持他们的专业领域——例如，算法在检测表示恶意安全活动的模式方面特别有效。
- en: 1.12.5 Controlling log data costs
  id: totrans-248
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.12.5 控制日志数据成本
- en: Log events, like any operational data, need storage and consume network capacity
    when moved, which results in costs. That cost can be noticeable when large volumes
    of uncompressed or unfiltered text exit a cloud provider’s network and are communicated
    over a business’s internet connection. Yet, at the same time, we don’t want to
    be overly parsimonious with logging; otherwise, we will never appreciate what
    is happening. Fluentd can help with this by filtering and storing some log events
    locally where the log events have limited value. But the log information that
    can be of further help can get sent onward to a central location. Not only that,
    but the transmission can also be optimized through compression mechanisms (bulk
    log events can be highly compressed).
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 日志事件，就像任何运营数据一样，需要存储，在移动时消耗网络容量，这会产生成本。当大量未压缩或未过滤的文本从云服务提供商的网络中流出并通过企业的互联网连接进行通信时，这种成本可能会很明显。然而，与此同时，我们又不希望过度节俭地对待日志记录；否则，我们将永远无法理解正在发生的事情。Fluentd
    可以通过过滤和存储一些日志事件以本地化方式帮助解决这个问题，其中日志事件的价值有限。但可以进一步帮助的日志信息可以发送到中央位置。不仅如此，传输还可以通过压缩机制（批量日志事件可以高度压缩）进行优化。
- en: 1.12.6 Logs to metrics
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.12.6 日志到指标
- en: Previously we introduced the three pillars of observability (logs, traces, metrics).
    In some cases, we want to get metrics, such as how many occurrences of a log event
    occur, or which process is alive or dead by looking at logs for signs of life
    (i.e., whether events have been created). With the plugins, it is possible to
    generate such measures and share such data with Prometheus and Grafana.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 之前我们介绍了可观测性的三个支柱（日志、追踪、指标）。在某些情况下，我们希望通过查看日志的生命迹象（即事件是否已被创建）来获取指标，例如日志事件的发生次数，或者哪个进程是活跃的或已死亡的。通过插件，可以生成此类度量并使用
    Prometheus 和 Grafana 共享此类数据。
- en: This can be extended through the possibility of Fluentd monitoring its own deployed
    nodes—when you get into complex distributed use cases, this can also be highly
    desirable. After all, Fluentd is just another piece of software and is therefore
    as vulnerable to bugs as any other code.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过 Fluentd 监控其自身已部署节点的可能性来扩展——当涉及到复杂的分布式用例时，这也可能非常理想。毕竟，Fluentd 只是一块软件，因此与其他代码一样容易受到错误的影响。
- en: 1.12.7 Rapid operational consolidation
  id: totrans-253
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.12.7 快速运营整合
- en: Company mergers and acquisitions can drive the need to consolidate operational
    resources, such as operational teams. Such consolidation will happen quicker than
    any process to consolidate major IT systems. We can easily direct log data to
    current operational support team tools to monitor and reduce the time and effort
    to absorb new systems into the operations organization through log unification.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 公司的合并和收购可以推动对运营资源（如运营团队）整合的需求。这种整合将比整合主要 IT 系统的任何流程都要快。我们可以通过日志统一轻松地将日志数据导向当前运营支持团队工具，以监控和减少将新系统纳入运营组织的时间和精力。
- en: Summary
  id: totrans-255
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Key concepts influencing modern thinking around monitoring come from ideas such
    as Google’s four golden signals and the three pillars of observability.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 影响现代监控思维的核心理念来源于诸如谷歌的四个黄金信号和可观测性的三个支柱等思想。
- en: Log analytics differs from log unification by focusing on a platform to mine
    the log data. In contrast, log unification is about bringing logs together and
    directing the content to necessary tools.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志分析不同于日志统一，它侧重于一个平台来挖掘日志数据。相比之下，日志统一是关于将日志汇集在一起并将内容导向必要的工具。
- en: Fluentd and Fluent Bit started as open source initiatives from Treasure Data
    before coming under the governance of the CNCF.
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fluentd 和 Fluent Bit 最初是 Treasure Data 的开源倡议，后来在 CNCF 的治理下运营。
- en: Fluentd and Fluent Bit are not aligned to any analytics platform. Considering
    the association with CNCF has helped the adoption of Fluentd by IaaS and PaaS
    vendors as either a part of a monitoring product or service or as supporting connectivity
    between Fluentd and their product.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fluentd 和 Fluent Bit 并未与任何分析平台对齐。考虑到与 CNCF 的关联，Fluentd 已被 IaaS 和 PaaS 供应商采用，无论是作为监控产品或服务的一部分，还是作为
    Fluentd 与其产品之间的支持连接。
- en: Fluentd has seen strong adoption in the microservices space, but it can fit
    equally well with a legacy landscape.
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fluentd 在微服务领域得到了广泛的应用，但它同样可以很好地适应遗留环境。
- en: Fluentd has a broad range of plugins available and a framework that enables
    custom plugins to be developed when needed.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fluentd 提供了广泛的插件，并有一个框架，允许在需要时开发自定义插件。
- en: Fluent Bit trades off the highly pluggable nature for a tiny optimized footprint.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fluent Bit 在高度可插拔性和微小优化的足迹之间进行了权衡。
- en: Both Fluentd and Fluent Bit can support the majority of platforms with prebuilt
    artifacts. Both are open source solutions; it is possible to build the kernel
    and plugins on just about any conceivable platform.
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fluentd 和 Fluent Bit 都可以支持大多数平台，并提供预构建的工件。两者都是开源解决方案；几乎可以在任何可想象的平台之上构建内核和插件。
- en: The application of logging is wide-ranging and offers value during the software’s
    entire life cycle.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志记录的应用范围广泛，在整个软件生命周期中都能提供价值。
- en: Fluentd supports a wide range of use cases, from debugging distributed solutions
    to operational monitoring.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fluentd 支持广泛的用例，从调试分布式解决方案到运营监控。
- en: Understand how Fluentd fits into the EFK software stack, and what the differences
    are between the ELK and EFK software stacks.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解 Fluentd 如何融入 EFK 软件栈，以及 ELK 和 EFK 软件栈之间的区别。
