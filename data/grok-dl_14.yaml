- en: 'Chapter 15\. Deep learning on unseen data: introducing federated learning'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第15章\. 对未见数据进行的深度学习：介绍联邦学习
- en: '**In this chapter**'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**本章内容**'
- en: The problem of privacy in deep learning
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习中的隐私问题
- en: Federated learning
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 联邦学习
- en: Learning to detect spam
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习检测垃圾邮件
- en: Hacking into federated learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 窃取联邦学习
- en: Secure aggregation
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全聚合
- en: Homomorphic encryption
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同态加密
- en: Homomorphically encrypted federated learning
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同态加密联邦学习
- en: “Friends don’t spy; true friendship is about privacy, too.”
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “朋友不会互相监视；真正的友谊也关乎隐私。”
- en: ''
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Stephen King, *Hearts in Atlantis* (1999)*'
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*斯蒂芬·金，《海特斯堡之心》（1999年）*'
- en: The problem of privacy in deep learning
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 深度学习中的隐私问题
- en: Deep learning (and tools for it) often means you have access to y- your training
    data
  id: totrans-13
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 深度学习（及其工具）通常意味着你可以访问你的训练数据
- en: As you’re keenly aware by now, deep learning, being a subfield of machine learning,
    is all about learning from data. But often, the data being learned from is incredibly
    personal. The most meaningful models interact with the most personal information
    about human lives and tell us things about ourselves that might have been difficult
    to know otherwise. To paraphrase, a deep learning model can study thousands of
    lives to help you better understand your own.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所敏锐地意识到的，深度学习作为机器学习的一个子领域，全部都是关于从数据中学习。但通常，被学习的数据极其个人化。最有意义的模型与人类生活中最个人化的信息互动，并告诉我们一些可能难以通过其他方式了解的事情。换句话说，深度学习模型可以研究成千上万人的生活，帮助你更好地理解自己。
- en: The primary natural resource for deep learning is training data (either synthetic
    or natural). Without it, deep learning can’t learn; and because the most valuable
    use cases often interact with the most personal datsets, deep learning is often
    a reason behind companies seeking to aggregate data. They need it in order to
    solve a particular use case.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的主要自然资源是训练数据（无论是合成的还是自然的）。没有它，深度学习就无法学习；而且因为最有价值的使用案例通常与最个人化的数据集互动，深度学习往往是公司寻求聚合数据的原因。他们需要它来解决特定的使用案例。
- en: 'But in 2017, Google published a very exciting paper and blog post that made
    a significant dent in this conversation. Google proposed that we don’t need to
    centralize a dataset in order to train a model over it. The company proposed this
    question: what if instead of bringing all the data to one place, we could bring
    the model to the data? This is a new, exciting subfield of machine learning called
    *federated learning*, and it’s what this chapter is about.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 但在2017年，谷歌发布了一篇非常激动人心的论文和博客文章，对这次对话产生了重大影响。谷歌提出，我们不需要集中一个数据集来在上面训练模型。公司提出了这个问题：如果我们不能将所有数据带到一处，我们能否将模型带到数据那里？这是一个新的、令人兴奋的机器学习子领域，称为*联邦学习*，这正是本章的主题。
- en: '|  |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: What if instead of bringing the corpus of training data to one place to train
    a model, you could bring the model to the data wherever it’s generated?
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不是将训练数据集带到一处来训练模型，而是能够将模型带到数据生成的任何地方，会怎么样呢？
- en: '|  |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: This simple reversal is extremely important. First, it means in order to participate
    in the deep learning supply chain, people don’t technically have to send their
    data to anyone. Valuable models in healthcare, personal management, and other
    sensitive areas can be trained without requiring anyone to disclose information
    about themselves. In theory, people could retain control over the only copy of
    their personal data (at least as far as deep learning is concerned).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这种简单的逆转极其重要。首先，这意味着为了参与深度学习供应链，人们实际上不必将他们的数据发送给任何人。在医疗保健、个人管理和其他敏感领域，有价值的模型可以在不要求任何人透露个人信息的情况下进行训练。理论上，人们可以保留对自己个人数据唯一副本的控制权（至少在深度学习方面）。
- en: This technique will also have a huge impact on the competitive landscape of
    deep learning in corporate competition and entrepreneurship. Large enterprises
    that previously wouldn’t (or couldn’t, for legal reasons) share data about their
    customers can potentially still earn revenue from that data. There are some problem
    domains where the sensitivity and regulatory constraints surrounding the data
    have been a headwind to progress. Healthcare is one example where datasets are
    often locked up tight, making research challenging.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术将对企业竞争和创业中的深度学习竞争格局产生巨大影响。以前不会（或不能，由于法律原因）共享客户数据的大型企业可能仍然可以从这些数据中获得收入。在有些领域，数据的敏感性和监管约束一直是进步的阻力。医疗保健就是一个例子，数据集通常被严格锁定，使得研究变得困难。
- en: Federated learning
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 联邦学习
- en: You don’t have to have access to a dataset in order to learn from it
  id: totrans-23
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 你不必访问数据集才能从中学习
- en: The premise of federated learning is that many datasets contain information
    that’s useful for solving problems (for example, identifying cancer in an MRI),
    but it’s hard to access these relevant datasets in large enough quantities to
    train a suitably strong deep learning model. The main concern is that, even though
    the dataset has information sufficient to train a deep learning model, it also
    has information that (presumably) has nothing to do with learning the task but
    could potentially harm someone if it were revealed.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 联邦学习的前提是许多数据集包含对解决问题有用的信息（例如，在MRI中识别癌症），但很难以足够的数量访问这些相关的数据集来训练一个足够强大的深度学习模型。主要担忧是，尽管数据集有足够的信息来训练深度学习模型，但它还包含了一些（可能）与学习任务无关的信息，如果泄露可能会对某人造成潜在伤害。
- en: Federated learning is about a model going into a secure environment and learning
    how to solve a problem without needing the data to move anywhere. Let’s jump into
    an example.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 联邦学习是指模型进入一个安全的环境，学习如何解决问题，而不需要数据移动到任何地方。让我们来看一个例子。
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '***1* Dataset from [http://www2.aueb.gr/users/ion/data/enron-spam/](http://www2.aueb.gr/users/ion/data/enron-spam/)**'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 数据集来自 [http://www2.aueb.gr/users/ion/data/enron-spam/](http://www2.aueb.gr/users/ion/data/enron-spam/)**'
- en: Learning to detect spam
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 学习检测垃圾邮件
- en: Let’s say you want to train a model across people’s emails to detect spam
  id: totrans-29
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 假设你想要在人们的电子邮件上训练一个模型来检测垃圾邮件
- en: 'The use case we’ll talk about is email classification. The first model will
    be trained on a publicly available dataset called the Enron dataset, which is
    a large corpus of emails released from the famous Enron lawsuit (now an industry
    standard email analytics corpus). Fun fact: I used to know someone who read/annotated
    this dataset professionally, and people emailed all sorts of crazy stuff to each
    other (much of it very personal). But because it was all released to the public
    in the court case, it’s free to use now.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要讨论的使用案例是电子邮件分类。第一个模型将在一个公开可用的数据集上训练，这个数据集被称为Enron数据集，它是一批来自著名Enron诉讼案（现在是一个行业标准的电子邮件分析语料库）的大量电子邮件。有趣的事实：我曾经认识一个人，他专业地阅读/注释了这个数据集，人们互相发送了各种各样的疯狂东西（其中很多非常私人）。但由于它在法庭案件中公开发布，现在可以免费使用。
- en: The code in the previous section and this section is just the preprocessing.
    The input data files (ham.txt and spam.txt) are available on the book’s website,
    [www.manning.com/books/grokking-deep-learning](http://www.manning.com/books/grokking-deep-learning);
    and on GitHub at [https://github.com/iamtrask/Grokking-Deep-Learning](https://github.com/iamtrask/Grokking-Deep-Learning).
    You preprocess it to get it ready to forward propagate into the embedding class
    created in [chapter 13](kindle_split_021.xhtml#ch13) when you created a deep learning
    framework. As before, all the words in this corpus are turned into lists of indices.
    You also make all the emails exactly 500 words long by either trimming the email
    or padding it with `<unk>` tokens. Doing so makes the final dataset square.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 上一节和这一节的代码只是预处理。输入数据文件（ham.txt和spam.txt）可在本书的网站上找到，[www.manning.com/books/grokking-deep-learning](http://www.manning.com/books/grokking-deep-learning)；以及GitHub上[https://github.com/iamtrask/Grokking-Deep-Learning](https://github.com/iamtrask/Grokking-Deep-Learning)。你预处理它以准备好将其前向传播到在[第13章](kindle_split_021.xhtml#ch13)中创建的嵌入类。和之前一样，这个语料库中的所有单词都被转换成了索引列表。你还通过截断电子邮件或用
    `<unk>` 标记填充它，使所有电子邮件正好500个单词长。这样做使得最终数据集是方形的。
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'With these nice `train()` and `test()` functions, you can initialize a neural
    network and train it using the following few lines. After only three iterations,
    the network can already classify on the test dataset with 99.45% accuracy (the
    test dataset is balanced, so this is quite good):'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 有这些不错的 `train()` 和 `test()` 函数，你可以使用以下几行代码初始化一个神经网络并对其进行训练。仅经过三次迭代，网络就可以在测试数据集上以99.45%的准确率进行分类（测试数据集是平衡的，所以这相当不错）：
- en: '|'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '|'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '|'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Let’s make it federated
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 让我们将其变为联邦学习
- en: The previous example was plain vanilla deep learning. Let’s protect privacy
  id: totrans-41
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 之前的例子是普通的深度学习。让我们保护隐私
- en: 'In the previous section, you got the email example. Now, let’s put all the
    emails in one place. This is the old-school way of doing things (which is still
    far too common in the world). Let’s start by simulating a federated learning environment
    that has multiple different collections of emails:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，你得到了电子邮件的例子。现在，让我们把所有电子邮件放在一个地方。这是老式的方法（这在世界上仍然非常普遍）。让我们首先模拟一个联邦学习环境，它包含多个不同的电子邮件集合：
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Easy enough. Now you can do the same training as before, but across each person’s
    email database all at the same time. After each iteration, you’ll average the
    values of the models from Bob, Alice, and Sue and evaluate. Note that some methods
    of federated learning aggregate after each batch (or collection of batches); I’m
    keeping it simple:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 足够简单。现在你可以像以前一样进行相同的训练，但同时在每个人的电子邮件数据库中进行。每次迭代后，你将平均鲍勃、爱丽丝和苏的模型值并评估。请注意，一些联邦学习的聚合方法在每个批次（或批次集合）之后进行；我保持简单：
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The next section shows the results. The model learns to nearly the same performance
    as before, and in theory you didn’t have access to the training data—or did you?
    After all, each person is changing the model somehow, right? Can you really not
    discover anything about their dataset?
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个部分将展示结果。模型的学习效果几乎与之前相同，从理论上讲，你没有访问到训练数据——或者你有吗？毕竟，每个人都在以某种方式改变模型，对吧？你真的不能发现任何关于他们的数据集的信息吗？
- en: '[PRE6]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Hacking into federated learning
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 窃取联邦学习
- en: Let’s use a toy example to see how to still learn the training dataset
  id: totrans-49
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 让我们用一个玩具示例来看看如何仍然学习训练数据集
- en: 'Federated learning has two big challenges, both of which are at their worst
    when each person in the training dataset has only a small handful of training
    examples. These challenges are performance and privacy. As it turns out, if someone
    has only a few training examples (or the model improvement they send you uses
    only a few examples: a training batch), you can still learn quite a bit about
    the data. Given 10,000 people (each with a little data), you’ll spend most of
    your time sending the model back and forth and not much time training (especially
    if the model is really big).'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 联邦学习面临两大挑战，这两个挑战在训练数据集中每个人只有少量训练示例时最为严重。这些挑战是性能和隐私。实际上，如果某人只有少量训练示例（或者他们发送给你的模型改进只使用了少量示例：一个训练批次），你仍然可以学到很多关于数据的信息。假设有10,000人（每人有一些数据），你将花费大部分时间在来回发送模型，而不是在训练（尤其是如果模型非常大时）。
- en: 'But we’re getting ahead of ourselves. Let’s see what you can learn when a user
    performs a weight update over a single batch:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们跑题了。让我们看看当用户在单个批次上执行权重更新时，你能学到什么：
- en: '[PRE7]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Bob is going to create an update to the model using an email in his inbox.
    But Bob saved his password in an email to himself that says, “My computer password
    is pizza.” Silly Bob. By looking at which weights changed, you can figure out
    the vocabulary (and infer the meaning) of Bob’s email:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 鲍勃将使用他收件箱中的一封电子邮件来创建对模型的更新。但鲍勃把他自己的密码保存在一封发给自己的电子邮件中，说：“我的电脑密码是披萨。”愚蠢的鲍勃。通过查看哪些权重发生了变化，你可以推断出鲍勃电子邮件的词汇（并推断其含义）：
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: And just like that, you learned Bob’s super-secret password (and probably his
    favorite food, too). What’s to be done? How can you use federated learning if
    it’s so easy to tell what the training data was from the weight update?
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样，你学会了鲍勃的超秘密密码（也许还有他最喜欢的食物）。怎么办？如果从权重更新中很容易看出训练数据，你该如何使用联邦学习？
- en: Secure aggregation
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安全聚合
- en: Let’s average weight updates from zillions of people before anyone can see them
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在任何人看到之前，让我们平均来自成千上万人的权重更新
- en: The solution is to never let Bob put a gradient out in the open like that. How
    can Bob contribute his gradient if people shouldn’t see it? The social sciences
    use an interesting technique called *randomized response*.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案是永远不要让鲍勃像那样公开地发布梯度。如果人们不应该看到它，鲍勃如何贡献他的梯度？社会科学使用一种有趣的技巧，称为*随机响应*。
- en: It goes like this. Let’s say you’re conducting a survey, and you want to ask
    100 people whether they’ve committed a heinous crime. Of course, all would answer
    “No” even if you promised them you wouldn’t tell. Instead, you have them flip
    a coin twice (somewhere you can’t see), and tell them that if the first coin flip
    is heads, they should answer honestly; and if it’s tails, they should answer “Yes”
    or “No” according to the second coin flip.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 它是这样的。假设你正在进行一项调查，你想询问100个人他们是否犯过严重的罪行。当然，即使你承诺不会告诉任何人，他们也会回答“没有”。相反，你让他们抛两次硬币（在你看不见的地方），并告诉他们如果第一次抛硬币是正面，他们应该诚实地回答；如果是反面，他们应该根据第二次抛硬币的结果回答“是”或“否”。
- en: Given this scenario, you never actually ask people to tell you whether they
    committed crimes. The true answers are hidden in the random noise of the first
    and second coin flips. If 60% of people say “Yes,” you can determine (using simple
    math) that about 70% of the people you surveyed committed heinous crimes (give
    or take a few percentage points). The idea is that the random noise makes it plausible
    that any information you learn about the person came from the noise instead of
    from them.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，你实际上从未要求人们告诉你他们是否犯了罪。真正的答案隐藏在第一次和第二次抛硬币的随机噪声中。如果60%的人说“是”，你可以通过简单的数学计算确定，大约70%的受访者犯了严重的罪行（上下几个百分点）。这个想法是，随机噪声使得你了解到关于个人的任何信息可能来自噪声而不是他们自己。
- en: '|  |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**Privacy via plausible deniability**'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**通过可辩驳的否认来保护隐私**'
- en: The level of chance that a particular answer came from random noise instead
    of an individual protects their privacy by giving them plausible deniability.
    This forms the basis for secure aggregation and, more generally, much of differential
    privacy.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 特定答案来自随机噪声而不是个人的概率水平，通过提供可辩驳的否认来保护他们的隐私。这构成了安全聚合的基础，以及更广泛地，差分隐私的大部分内容。
- en: '|  |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: You’re looking only at aggregate statistics overall. (You never see anyone’s
    answer directly; you see only pairs of answers or perhaps larger groupings.) Thus,
    the more people you can aggregate before adding noise, the less noise you have
    to add to hide them (and the more accurate the findings are).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 你只看到整体的汇总统计数据。（你永远不会直接看到任何人的答案；你只看到答案对或更大的分组。）因此，在添加噪声之前，你可以聚合更多的人，你就不需要添加太多的噪声来隐藏他们（并且结果会更加准确）。
- en: 'In the context of federated learning, you could (if you wanted) add a ton of
    noise, but this would hurt training. Instead, first sum all the gradients from
    all the participants in such a way that no one can see anyone’s gradient but their
    own. The class of problems for doing this is called *secure aggregation*, and
    in order to do it, you’ll need one more (very cool) tool: *homomorphic encryption*.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在联邦学习的背景下，你可以（如果你愿意）添加大量的噪声，但这会损害训练。相反，首先将所有参与者的梯度求和，这样没有人能看到除了自己的梯度以外的任何人的梯度。这类问题被称为
    *安全聚合*，为了做到这一点，你还需要一个额外的（非常酷）工具：*同态加密*。
- en: Homomorphic encryption
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 同态加密
- en: You can perform arithmetic on encrypted values
  id: totrans-69
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 你可以对加密值执行算术运算
- en: One of the most exciting frontiers of research is the intersection of artificial
    intelligence (including deep learning) and cryptography. Front and center in this
    exciting intersection is a very cool technology called homomorphic encryption.
    Loosely stated, homomorphic encryption lets you perform computation on encrypted
    values without decrypting them.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 研究中最激动人心的前沿之一是人工智能（包括深度学习）与密码学的交叉领域。在这个激动人心的交叉点中，有一个非常酷的技术叫做同态加密。简单来说，同态加密允许你在不解密的情况下对加密值进行计算。
- en: In particular, we’re interested in performing addition over these values. Explaining
    exactly how it works would take an entire book on its own, but I’ll show you how
    it works with a few definitions. First, a *public key* lets you encrypt numbers.
    A *private key* lets you decrypt encrypted numbers. An encrypted value is called
    a *ciphertext*, and an unencrypted value is called a *plaintext*.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是我们对在这些值上执行加法感兴趣。详细解释其工作原理需要一本整本书，但我会用几个定义来展示它是如何工作的。首先，一个 *公钥* 允许你加密数字。一个
    *私钥* 允许你解密加密的数字。加密的值称为 *密文*，未加密的值称为 *明文*。
- en: 'Let’s see an example of homomorphic encryption using the phe library. (To install
    the library, run `pip install phe` or download it from GitHub at [https://github.com/n1analytics/python-paillier](https://github.com/n1analytics/python-paillier)):'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过使用 phe 库的例子来看看同态加密。（要安装库，请运行 `pip install phe` 或从 GitHub [https://github.com/n1analytics/python-paillier](https://github.com/n1analytics/python-paillier)
    下载）：
- en: '[PRE10]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '***1* Encrypts the number 5**'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 加密数字 5**'
- en: '***2* Encrypts the number 3**'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 加密数字 3**'
- en: '***3* Adds the two encrypted values**'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 将两个加密值相加**'
- en: '***4* Decrypts the result**'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 解密结果**'
- en: '[PRE11]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This code encrypts two numbers (5 and 3) and adds them together while they’re
    still encrypted. Pretty neat, eh? There’s another technique that’s a sort-of cousin
    to homomorphic encryption: *secure multi-party computation*. You can learn about
    it at the “Cryptography and Machine Learning” blog ([https://mortendahl.github.io](https://mortendahl.github.io)).'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码在加密状态下将两个数字（5和3）相加。非常巧妙，不是吗？还有一种技术与同态加密有点类似：*安全多方计算*。你可以在“密码学与机器学习”博客（[https://mortendahl.github.io](https://mortendahl.github.io)）上了解它。
- en: Now, let’s return to the problem of secure aggregation. Given your new knowledge
    that you can add together numbers you can’t see, the answer becomes plain. The
    person who initializes the model sends a `public_key` to Bob, Alice, and Sue so
    they can each encrypt their weight updates. Then, Bob, Alice, and Sue (who don’t
    have the private key) talk directly to each other and accumulate all their gradients
    into a single, final update that’s sent back to the model owner, who decrypts
    it with the `private_key`.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们回到安全聚合的问题。鉴于你新获得的知识，你可以将你看不见的数字相加，答案就变得显而易见了。初始化模型的个人将一个`public_key`发送给鲍勃、爱丽丝和苏，这样他们就可以分别加密他们的权重更新。然后，鲍勃、爱丽丝和苏（他们没有私钥）直接相互沟通，并将所有梯度累积成一个单一、最终的更新，发送回模型所有者，该所有者使用`private_key`对其进行解密。
- en: Homomorphically encrypted federated learning
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 同态加密联邦学习
- en: Let’s use homomorphic encryption to protect the gradients being aggregated
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 让我们使用同态加密来保护正在聚合的梯度
- en: '[PRE12]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Now you can run the new training scheme, which has an added step. Alice, Bob,
    and Sue add up their homomorphically encrypted models before sending them back
    to you, so you never see which updates came from which person (a form of plausible
    deniability). In production, you’d also add some additional random noise sufficient
    to meet a certain privacy threshold required by Bob, Alice, and Sue (according
    to their personal preferences). More on that in future work.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以运行新的训练方案，它增加了一个步骤。爱丽丝、鲍勃和苏在将模型发送回你之前，将他们的同态加密模型相加，这样你就永远不会看到哪些更新来自哪个人（一种合理的否认形式）。在生产中，你还会添加一些额外的随机噪声，足以满足鲍勃、爱丽丝和苏（根据他们的个人偏好）所需的一定隐私阈值。更多内容将在未来的工作中介绍。
- en: '[PRE13]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Summary
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 摘要
- en: Federated learning is one of the most exciting breakthroughs in deep learning
  id: totrans-87
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 联邦学习是深度学习中最激动人心的突破之一
- en: I firmly believe that federated learning will change the landscape of deep learning
    in the coming years. It will unlock new datasets that were previously too sensitive
    to work with, creating great social good as a result of this newly available entrepreneurial
    opportunities. This is part of a broader convergence between encryption and artificial
    intelligence research that, in my opinion, is the most exciting convergence of
    the decade.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我坚信，联邦学习将在未来几年改变深度学习的格局。它将解锁之前由于过于敏感而无法处理的新的数据集，从而为这种新出现的创业机会创造巨大的社会效益。这是加密与人工智能研究更广泛融合的一部分，在我看来，这是十年中最激动人心的融合。
- en: The main thing holding back these techniques from practical use is their lack
    of availability in modern deep learning toolkits. The tipping point will be when
    anyone can run `pip install...` and then have access to deep learning frameworks
    where privacy and security are first-class citizens, and where techniques such
    as federated learning, homomorphic encryption, differential privacy, and secure
    multi-party computation are all built in (and you don’t have to be an expert to
    use them).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 阻碍这些技术在实际应用中发挥作用的因素主要是它们在现代深度学习工具包中的不可用性。转折点将是任何人都可以运行`pip install...`然后获得访问深度学习框架的权限，在这些框架中，隐私和安全是首要公民，并且内置了联邦学习、同态加密、差分隐私和安全多方计算等技术（而且你不需要是专家就能使用它们）。
- en: Out of this belief, I’ve been working with a team of open source volunteers
    as a part of the OpenMined project for the past year, extending major deep learning
    frameworks with these primitives. If you believe in the importance of these tools
    to the future of privacy and security, come check us out at [http://openmined.org](http://openmined.org)
    or at the GitHub repository ([https://github.com/OpenMined](https://github.com/OpenMined)).
    Show your support, even if it’s only starring a few repos; and do join if you
    can (slack.openmined.org is the chat room).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 出于这种信念，我在过去一年中作为OpenMined项目的一部分，与一群开源志愿者一起工作，将这些原语扩展到主要的深度学习框架中。如果你相信这些工具对未来隐私和安全的重要性，请访问我们的网站[http://openmined.org](http://openmined.org)或GitHub仓库([https://github.com/OpenMined](https://github.com/OpenMined))。即使只是给几个仓库点个赞，也请表达你的支持；如果你能加入我们，那就更好了（聊天室：slack.openmined.org）。
