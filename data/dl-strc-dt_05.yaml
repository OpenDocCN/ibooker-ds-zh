- en: 5 Preparing and building the model
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 准备和构建模型
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Revisiting the dataset and determining which features to use to train the model
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新审视数据集，并确定用于训练模型的特征
- en: Refactoring the dataset to include timeslots when there is no delay
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对数据集进行重构，包括没有延误的时间段
- en: Transforming the dataset into the format expected by the Keras model
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据集转换为 Keras 模型期望的格式
- en: Building a Keras model automatically based on the structure of the data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据数据结构自动构建 Keras 模型
- en: Examining the structure of the model
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查模型结构
- en: Setting parameters, including activation and optimization functions and learning
    rate
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置参数，包括激活函数和优化函数以及学习率
- en: This chapter begins with a quick reexamination of the dataset to consider which
    columns can legitimately be used to train the model. Then we’ll go over the transformations
    required to get the data from the format in which we have been manipulating it
    (Pandas dataframes) to the format expected by the deep learning model. Next, we
    will go over the code for the model itself and see how the model is built up layer
    by layer based on the category of the input columns. We wrap up by reviewing methods
    you can use to examine the structure of the model and the parameters you can use
    to adjust how the model is trained.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章首先快速回顾数据集，以考虑哪些列可以合法用于训练模型。然后，我们将讨论将数据从我们一直在操作的形式（Pandas 数据框）转换为深度学习模型期望的形式所需的转换。接下来，我们将查看模型的代码本身，并了解模型是如何根据输入列的类别逐层构建的。最后，我们将回顾你可以用来检查模型结构的方法以及你可以用来调整模型训练参数的方法。
- en: 'All the preceding chapters in this book have been building up to this point.
    After examining the problem, preparing the data, we are finally ready to dig into
    the deep learning model itself. One thing to keep in mind as you go through this
    chapter: if you have not worked directly with deep learning models before, you
    may find the code for the model to be somewhat anticlimactic after all the detailed
    work required to prepare the data. This feeling may be familiar to you from using
    Python libraries for classic machine learning algorithms. The code to apply logistic
    regression or linear regression to a dataset that has been prepared for training
    isn’t exciting, particularly if you have had to create nontrivial code to tame
    a real-world dataset. You can see the code described in this chapter in the streetcar_
    model_training notebook.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的所有前几章都为这一刻做准备。在检查问题、准备数据之后，我们终于准备好深入研究深度学习模型本身了。在阅读本章时要注意的一点是：如果你之前没有直接与深度学习模型工作过，你可能会发现模型的代码在完成所有详细的数据准备工作之后显得有些平淡无奇。这种感觉可能与你使用
    Python 库进行经典机器学习算法时相似。将逻辑回归或线性回归应用于已准备好的训练数据集的代码并不令人兴奋，尤其是如果你不得不编写非平凡的代码来驯服现实世界的数据集。你可以在这章中看到描述的代码，在
    streetcar_model_training 笔记本中。
- en: 5.1 Data leakage and features that are fair game for training the model
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 数据泄露和可用于训练模型的公平特征
- en: 'Before we get into the details of the code that constitutes the model, we need
    to review which columns (either columns from the original dataset or columns derived
    from the original columns) are legitimate to use to train the model. If we need
    to use the model to predict streetcar delays, we need to ensure that we avoid
    data leakage. *Data leakage* occurs when you train a model using data (including
    the outcome that you’re trying to predict) from outside the training dataset.
    If you succumb to data leakage when you train a model by depending on data that
    isn’t available at the point when you want to make a prediction, you risk the
    following problems:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨构成模型的代码细节之前，我们需要回顾哪些列（无论是原始数据集的列还是从原始列派生出的列）是合法用于训练模型的。如果我们需要使用模型来预测电车延误，我们需要确保避免数据泄露。*数据泄露*发生在你使用训练数据集之外的数据（包括你试图预测的结果）来训练模型时。如果你在训练模型时依赖于在你想要做出预测时不可用的数据，你可能会遇到以下问题：
- en: Undermining your ability to make predictions
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 削弱你做出预测的能力
- en: Getting a performance measurement for your model that is too optimistic
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获得过于乐观的模型性能度量
- en: To understand the problem of data leakage, consider a simple model that predicts
    the sale price of houses in a given property market. For this model, you have
    a set of information about houses that have sold recently in this market. You
    can use this information to train a model that you will later use to predict the
    sales price of houses that are being put on the market, as shown in figure 5.1.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解数据泄露的问题，考虑一个简单的模型，该模型预测特定房地产市场中的房屋销售价格。对于这个模型，你有一组关于该市场最近售出的房屋的信息。你可以使用这些信息来训练一个模型，你稍后可以使用这个模型来预测即将上市房屋的销售价格，如图5.1所示。
- en: '![CH05_F01_Ryan](../Images/CH05_F01_Ryan.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F01_Ryan](../Images/CH05_F01_Ryan.png)'
- en: Figure 5.1 Training and applying a model to predict house prices
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1 训练和应用模型以预测房价
- en: Figure 5.2 shows the features that are available for you to choose from in the
    sold-houses dataset.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2显示了在已售房屋数据集中可供你选择的特征。
- en: '![CH05_F02_Ryan](../Images/CH05_F02_Ryan.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F02_Ryan](../Images/CH05_F02_Ryan.png)'
- en: Figure 5.2 Features available in the dataset of sold houses
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2 已售房屋数据集中的可用特征
- en: 'Our goal is to make a prediction about the selling price for a house when it
    initially goes on the market, potentially weeks before it sells. When the house
    is ready to go on the market, the following features will be available:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目的是在房屋首次上市时对其销售价格进行预测，这可能在它售出之前几周。当房屋准备上市时，以下特征将可用：
- en: Number of bedrooms
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卧室数量
- en: Number of bathrooms
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卫生间数量
- en: Floor space
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 层面积
- en: Frontage
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 前景
- en: We know that selling price (the feature that we want to predict) won’t be available.
    What about these features?
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道销售价格（我们想要预测的特征）将不可用。那么这些特征呢？
- en: Time on market
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 市场时间
- en: Asking price
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 出售价格
- en: Time on market won’t be available when we want to make a prediction because
    the house has not been on the market yet, so we should not use this feature to
    train the model. Asking price is a bit more ambiguous; it may or may not be available
    at the point when we want to make the prediction. This example shows that we need
    a deeper understanding of the real-world business situation before we can determine
    whether a given feature will lead to data leakage.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要进行预测时，市场时间将不可用，因为房屋尚未上市，因此我们不应使用此特征来训练模型。要价有些模糊；在我们想要进行预测的时候，它可能可用也可能不可用。这个例子表明，在我们确定给定特征是否会导致数据泄露之前，我们需要对现实世界的业务情况有更深入的了解。
- en: 5.2 Domain expertise and minimal scoring tests to prevent data leakage
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 领域专业知识与最小评分测试以防止数据泄露
- en: What can you do to prevent the data leakage problems described in section 5.1?
    If you already have domain expertise in the business problem that your deep learning
    model is trying to solve, it will be easier for you to avoid data leakage. One
    of the rationales for this book is to enable you to exercise deep learning on
    problems in your everyday work so that you can take advantage of the domain expertise
    that you possess from doing your job.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以采取哪些措施来防止5.1节中描述的数据泄露问题？如果你已经在你尝试解决的深度学习模型所涉及的业务问题中拥有领域专业知识，那么你将更容易避免数据泄露。本书的一个目的就是让你能够在日常工作中练习深度学习，以便你能利用你在工作中所拥有的领域专业知识。
- en: Returning to the house-prices example (section 5.1), what would happen if you
    trained your model using features that have been identified as sources of data
    leakage, such as time on market? First, during the training, you probably would
    see model performance (measured by accuracy, for example) that looks good. This
    great performance, however, is misleading. It’s the equivalent of a teacher being
    happy about her students’ performance on a test when every student had a peek
    at the answers during the test. The students didn’t legitimately do well because
    they were exposed to information that should not have been available to them at
    the time of the test. The second result of data leakage is that when you finish
    training the model and try to apply it, you will find that some of the features
    that you need to feed the model to get a prediction are missing.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 回到5.1节中的房屋价格示例，如果你使用已被识别为数据泄露来源的特征（如市场时间）来训练你的模型，会发生什么？首先，在训练过程中，你可能看到模型性能（例如，通过准确率来衡量）看起来很好。然而，这种出色的性能是误导性的。这相当于一位教师在考试期间每个学生都偷看了答案时对学生的表现感到高兴。学生们并没有真正做得好，因为他们接触到了在考试时不应接触到的信息。数据泄露的第二个结果是，当你完成模型训练并尝试应用它时，你会发现一些你需要提供以获得预测的特征缺失。
- en: In addition to applying domain knowledge (such as the time on market not being
    known when a house first goes on the market), what can you do to prevent data
    leakage? A minimal scoring test on an early iteration of the model can help. In
    the house-prices example, we could take a provisional version of the trained model
    and apply data from one or two houses that are newly on the market. The prediction
    may be poor because the training iterations are not complete, but this exercise
    will expose features the model requires that aren’t available at prediction time,
    allowing us to remove them from the training process.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 除了应用领域知识（例如，当房子首次上市时，市场时间未知），你还能做什么来防止数据泄露？对模型早期迭代进行最小评分测试可以帮助。在房价示例中，我们可以采用训练模型的临时版本，并应用一两个新上市房屋的数据。由于训练迭代尚未完成，预测可能不准确，但这项练习将揭示模型所需的特征，这些特征在预测时不可用，从而允许我们从训练过程中删除它们。
- en: 5.3 Preventing data leakage in the streetcar delay prediction problem
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 防止电车延误预测问题中的数据泄露
- en: In the streetcar delay example, we want to predict whether a given streetcar
    trip is going to be delayed. In this context, including the Incident column as
    a feature to train the model would constitute data leakage, because before the
    trip is taken, we don’t know whether a given trip will have a delay and, if so,
    the nature of the delay. We don’t know what, if any, value the Incident column
    will have for a given streetcar trip before the trip is taken.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在电车延误示例中，我们想要预测一次特定的电车行程是否会延误。在这种情况下，将事件列作为特征来训练模型将构成数据泄露，因为在行程开始之前，我们不知道一次特定的行程是否会延误，以及如果会延误，延误的性质是什么。在行程开始之前，我们不知道事件列对一次特定的电车行程将有什么值。
- en: As shown in figure 5.3, the Min Delay and Min Gap columns also cause data leakage.
    Our label (the value we are trying to predict) is derived from Min Delay and is
    correlated with Min Gap, so both of these columns are potential sources of data
    leakage. We won’t know these values when we want to predict whether a given streetcar
    trip is going to be delayed.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如图5.3所示，最小延误和最小间隔列也会导致数据泄露。我们的标签（我们试图预测的值）来自最小延误，并与最小间隔相关联，因此这两个列都是潜在的数据泄露来源。当我们想要预测一次特定的电车行程是否会延误时，我们不会知道这些值。
- en: '![CH05_F03_Ryan](../Images/CH05_F03_Ryan.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F03_Ryan](../Images/CH05_F03_Ryan.png)'
- en: Figure 5.3 Columns in the original dataset that can cause data leakage
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3 原始数据集中可能导致数据泄露的列
- en: 'Looking at the problem another way, which columns contain information that
    will be legitimately available to us when we want to make delay predictions for
    a particular trip or a set of trips? The information that the user provides at
    prediction time is described in chapter 8\. The information provided by the user
    depends on the type of deployment:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 从另一个角度来看这个问题，哪些列包含在我们想要为特定行程或一系列行程做出延误预测时将合法可用的信息？用户在预测时提供的信息在第8章中描述。用户提供的信息取决于部署的类型：
- en: '*Web* (figure 5.4)—In the web deployment of the model, the user selects seven
    scoring parameters (route, direction, and date/time details) that will be fed
    into the trained model to get a prediction.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Web*（图5.4）——在模型的Web部署中，用户选择七个评分参数（路线、方向和日期/时间细节），这些参数将被输入到训练好的模型中以获得预测。'
- en: '![CH05_F04_Ryan](../Images/CH05_F04_Ryan.png)'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![CH05_F04_Ryan](../Images/CH05_F04_Ryan.png)'
- en: Figure 5.4 Information provided by the user in the web deployment of the model
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.4 Web部署中用户提供的信息
- en: '*Facebook Messenger* (figure 5.5)—In the Facebook Messenger deployment of the
    model, the date/time details default to the current time when the prediction is
    made if the user doesn’t provide them explicitly. In this deployment, the user
    needs to provide only two scoring parameters: the route and the direction of their
    intended streetcar trip.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Facebook Messenger*（图5.5）——在Facebook Messenger模型的部署中，如果用户没有明确提供，日期/时间细节默认为预测时的当前时间。在这个部署中，用户只需要提供两个评分参数：他们打算乘坐的电车行程的路线和方向。'
- en: '![CH05_F05_Ryan](../Images/CH05_F05_Ryan.png)'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![CH05_F05_Ryan](../Images/CH05_F05_Ryan.png)'
- en: Figure 5.5 Information provided by the user in the Facebook Messenger deployment
    of the model
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.5 Facebook Messenger模型部署中用户提供的信息
- en: 'Let’s check these parameters to ensure that we’re not risking data leakage:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查这些参数以确保我们不会冒着数据泄露的风险：
- en: '*Route* —When we want to predict whether a streetcar trip will be delayed,
    we’ll know what route (such as Route 501 Queen or Route 503 Kingston Road) the
    trip will take.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*路线* —当我们想要预测街车行程是否会延误时，我们将知道行程将采取哪条路线（例如 501 王后路线或 503 金斯顿路）。'
- en: '*Direction* —We’ll know the direction (northbound, southbound, eastbound or
    westbound) of the trip at the time we want to predict whether it will be delayed.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*方向* —当我们想要预测行程是否会延误时，我们将知道行程的方向（北行、南行、东行或西行）。'
- en: 'We will also know the following date/time information (because the user sets
    the values explicitly in the web deployment or because we assume the current date/time
    in the Facebook Messenger deployment):'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将知道以下日期/时间信息（因为用户在 Web 部署中明确设置了值，或者因为我们假设 Facebook Messenger 部署中的当前日期/时间）：
- en: Hour
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小时
- en: Day (day of the week, such as Monday)
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 天（星期几，例如星期一）
- en: Day of month
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 月份中的某一天
- en: Month
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 月份
- en: Year
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 年份
- en: 'We’d like to include one more feature in the data entry for predictions: Location.
    This feature is a bit trickier. If we look at the Location information in the
    source dataset as shown in figure 5.6, we know that we won’t have this information
    when we want to predict whether a streetcar trip will have delays. But we will
    know the start and end points of the trip (such as a trip on the 501 Queen route
    starting at Queen and Sherbourne and going to Queen and Spadina).'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望在预测数据输入中包含一个额外的特征：位置。这个特征有点复杂。如果我们查看图 5.6 中源数据集中的位置信息，我们知道在我们要预测街车行程是否会延误时，我们不会有这些信息。但我们将知道行程的起点和终点（例如，501
    王后路线的行程从女王街和舍伯恩街出发，到女王街和斯帕丁纳街）。
- en: '![CH05_F06_Ryan](../Images/CH05_F06_Ryan.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F06_Ryan](../Images/CH05_F06_Ryan.png)'
- en: Figure 5.6 Values in the Location column
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.6 位置列中的值
- en: How can we correlate these start and end points with the likelihood that a delay
    will occur at a particular point on the trip? Unlike subway lines, which have
    stations that define distinct portions of the route, streetcar routes are fairly
    fluid. Many stops occur along a route, and these stops are not static, like those
    at subway stations; streetcar stops get moved. One approach that we will investigate
    in chapter 9 is dividing each route into sections and predicting whether a delay
    will occur in any of the sections that make up the entire trip along the streetcar
    route. For now, we are going to examine a version of the model that doesn’t include
    location data so that we can go through the model from end to end the first time
    without too much additional complexity.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何将这些起点和终点与行程中特定点的延误可能性相关联？与有站点的地铁线路不同，街车路线相对灵活。许多站点沿着路线分布，这些站点不是静态的，就像地铁站一样；街车站点会移动。我们将在第
    9 章中探讨的一种方法是，将每条路线划分为几个部分，并预测在整个街车路线上的行程中，任何部分是否会发生延误。现在，我们将检查一个不包含位置数据的模型版本，这样我们就可以在第一次从头到尾通过模型时，不会遇到太多的额外复杂性。
- en: If we limit ourselves to training the streetcar delay model to the columns we
    have identified (route, direction, and the date/time columns), we can prevent
    data leakage and be confident that the model we are training will be capable of
    making predictions about new streetcar trips.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将训练街车延误模型限制在我们已识别的列（路线、方向和日期/时间列），我们可以防止数据泄露，并确信我们正在训练的模型将能够对新街车行程做出预测。
- en: 5.4 Code for exploring Keras and building the model
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4 探索 Keras 和构建模型的代码
- en: When you have cloned the GitHub repo ([http://mng.bz/v95x](http://mng.bz/v95x))
    associated with this book, you’ll find the code related to exploring Keras and
    building the streetcar delay prediction model in the notebooks subdirectory. The
    next listing shows the files that contain the code described in this chapter.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 当你克隆了与本书相关的 GitHub 仓库 ([http://mng.bz/v95x](http://mng.bz/v95x)) 后，你将在 notebooks
    子目录中找到与探索 Keras 和构建街车延误预测模型相关的代码。下一条列表显示了包含本章描述的代码的文件。
- en: Listing 5.1 Code in the repo related to exploring Keras and building the model
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.1 与探索 Keras 和构建模型相关的代码
- en: '[PRE0]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Directory for the pickled dataframe that is the output of the data preparation
    steps
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 数据准备步骤输出为 pickled dataframe 的目录
- en: ❷ Notebook containing code to refactor the input dataset and build the model
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 包含重构输入数据集和构建模型的代码的笔记本
- en: ❸ Config file for the model training notebook, with parameters including the
    name of the pickled dataframe that is input to the model training notebook
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 模型训练笔记本的配置文件，包括输入到模型训练笔记本的 pickled dataframe 的名称
- en: ❹ Example of using the Keras sequential API to define a simple deep learning
    model (see section 5.10 for details)
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 使用 Keras 顺序 API 定义简单深度学习模型的示例（详细信息请见第 5.10 节）
- en: ❺ Example of using the Keras functional API to define a simple deep learning
    model (see section 5.10 for details)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 使用 Keras 功能 API 定义简单深度学习模型的示例（详细信息请见第 5.10 节）
- en: 5.5 Deriving the dataframe to use to train the model
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.5 推导用于训练模型的 dataframe
- en: In chapters 1-4, we went through many steps to clean and transform the data,
    including
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 1-4 章中，我们经历了许多步骤来清洗和转换数据，包括
- en: Replacing redundant values with a single consistent value, such as replacing
    `eastbound` , `e/b` , and `eb` with e in the Direction column
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将冗余值替换为单个一致值，例如在方向列中将 `eastbound`、`e/b` 和 `eb` 替换为 e
- en: Removing records with invalid values, such as records with Route values that
    aren’t valid streetcar routes
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除具有无效值的记录，例如具有无效路线值的记录
- en: Replacing categorical values with numeric identifiers
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将分类值替换为数值标识符
- en: Figure 5.7 shows the outcomes of these transformations.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.7 显示了这些转换的结果。
- en: '![CH05_F07_Ryan](../Images/CH05_F07_Ryan.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F07_Ryan](../Images/CH05_F07_Ryan.png)'
- en: Figure 5.7 The input dataset after the transformations up to the end of chapter
    4
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.7 到第 4 章末的转换后的输入数据集
- en: Will this dataset be sufficient to train a model to meet our goal of predicting
    whether a given streetcar trip will be delayed? The answer is no. As it stands
    now, this dataset has only records for delays. What’s missing is information about
    all the situations when there were no delays. What we need is a refactored dataset
    that also has records of all the times when there were no delays on a particular
    route in a particular direction.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集是否足够训练一个模型以实现预测给定电车行程是否会延迟的目标？答案是：不。目前，这个数据集只有延迟的记录。缺少的是关于所有没有延迟的情况的信息。我们需要的是一个重构的数据集，它也记录了在特定路线和特定方向上没有延迟的所有时间。
- en: Figure 5.8 summarizes the difference between the original dataset and the refactored
    dataset. In the original dataset, every record describes a delay, including the
    time, route, direction, and incident that caused the delay. In the refactored
    dataset, there is a record for every combination of time slot (every hour since
    January 1, 2014), route, and direction, whether or not there was a delay on that
    route in that direction during that time slot.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.8 总结了原始数据集和重构数据集之间的差异。在原始数据集中，每条记录描述了一个延迟，包括时间、路线、方向和导致延迟的事件。在重构数据集中，对于每个时间槽（从
    2014 年 1 月 1 日以来的每小时），路线和方向的组合都有一个记录，无论在那个时间槽内该路线在该方向上是否有延迟。
- en: '![CH05_F08_Ryan](../Images/CH05_F08_Ryan.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F08_Ryan](../Images/CH05_F08_Ryan.png)'
- en: Figure 5.8 Comparing the original dataset with the refactored dataset
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.8 比较原始数据集与重构数据集
- en: Figure 5.9 shows explicitly what the refactored dataset looks like. If there
    is a delay in a given time slot (an hour in a particular day) on a given route
    in a given direction, count is nonzero; otherwise, count is zero. The snippet
    of the refactored dataset in figure 5.9 shows that there were no delays on Route
    301 in the eastbound direction between midnight and 5 a.m. on January 1, 2014.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.9 明确显示了重构数据集的外观。如果在给定时间槽（特定一天的小时）的给定路线的给定方向上有延迟，计数不为零；否则，计数为零。图 5.9 中重构数据集的片段显示，在
    2014 年 1 月 1 日午夜到早上 5 点之间，301 路线在东行方向上没有发生任何延迟。
- en: '![CH05_F09_Ryan](../Images/CH05_F09_Ryan.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F09_Ryan](../Images/CH05_F09_Ryan.png)'
- en: Figure 5.9 Refactored dataset with a row for each route/direction/time-slot
    combination
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.9 每个路线/方向/时间槽组合的行重构数据集
- en: Figure 5.10 summarizes the steps to get the refactored dataset that has an entry
    for every time-slot/route/direction combination.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.10 总结了获取每个时间槽/路线/方向组合条目的重构数据集的步骤。
- en: '![CH05_F10_Ryan](../Images/CH05_F10_Ryan.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F10_Ryan](../Images/CH05_F10_Ryan.png)'
- en: Figure 5.10 Refactoring the dataframe
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.10 重构 dataframe
- en: 'Following are the steps:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤：
- en: Create a `routedirection_frame` dataframe containing a row for each route/ direction
    combination (figure 5.11).
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个包含每个路线/方向组合的行 `routedirection_frame` 数据框（图 5.11）。
- en: '![CH05_F11_Ryan](../Images/CH05_F11_Ryan.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F11_Ryan](../Images/CH05_F11_Ryan.png)'
- en: Figure 5.11 routedirection_frame dataframe
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.11 路向帧数据框
- en: Create a `date_frame` dataframe, containing a row for each date in the period
    from which training data will be selected (figure 5.12).
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个包含从中选择训练数据的日期范围的每个日期的 `date_frame` 数据框（图 5.12）。
- en: '![CH05_F12_Ryan](../Images/CH05_F12_Ryan.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F12_Ryan](../Images/CH05_F12_Ryan.png)'
- en: Figure 5.12 date_frame dataframe
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.12 date_frame 数据框
- en: Create an `hour_frame` dataframe, containing a row for each hour of the day
    (figure 5.13).
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个包含每天每小时一行数据的 `hour_frame` 数据框（图 5.13）。
- en: '![CH05_F13_Ryan](../Images/CH05_F13_Ryan.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F13_Ryan](../Images/CH05_F13_Ryan.png)'
- en: Figure 5.13 hour_frame dataframe
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.13 hour_frame 数据框
- en: Combine these three dataframes to get the `result2` dataframe (figure 5.14).
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这三个数据框合并以获得 `result2` 数据框（图 5.14）。
- en: '![CH05_F14_Ryan](../Images/CH05_F14_Ryan.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F14_Ryan](../Images/CH05_F14_Ryan.png)'
- en: Figure 5.14 result2 dataframe
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.14 result2 数据框
- en: 'Add derived columns for the components of the date to the `result2` dataframe:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将日期的组成部分的派生列添加到 `result2` 数据框中：
- en: '[PRE1]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Drop extraneous columns from the input dataset (`merged_data` dataframe) and
    combine it with the `result2` dataframe to get the completed refactored dataframe
    (figure 5.15).
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从输入数据集（`merged_data` 数据框）中删除多余的列，并将其与 `result2` 数据框合并，以获得完成重构的数据框（图 5.15）。
- en: '![CH05_F15_Ryan](../Images/CH05_F15_Ryan.png)'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![CH05_F15_Ryan](../Images/CH05_F15_Ryan.png)'
- en: Figure 5.15 Completed refactored dataframe
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.15 完成重构的数据框
- en: 'To compare the size of the dataset before and after refactoring, a dataset
    with 56,000 rows results in a refactored dataset with 2.5 million rows to cover
    a five-year period. The start and end of the time period covered by this refactored
    dataset is controlled by these variables, defined in the overall parameters block:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较重构前后的数据集大小，一个包含 56,000 行的数据集在重构后变成了包含 2.5 百万行以覆盖五年期间的数据集。这个重构数据集覆盖的时间段的开始和结束由以下变量控制，这些变量定义在整体参数块中：
- en: '[PRE2]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The start date corresponds with the beginning of the delay dataset in January
    2014\. You can change the end date by updating the parameters in the config file
    streetcar_ model_training_config.yml, but note that you want to keep `end_date`
    no later than the latest delay data from the original source ([http://mng.bz/4B2B](http://mng.bz/4B2B)).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 开始日期与 2014 年 1 月延迟数据集的开始相对应。你可以通过更新配置文件 streetcar_model_training_config.yml
    中的参数来更改结束日期，但请注意，你希望 `end_date` 不晚于原始来源的最新延迟数据（[http://mng.bz/4B2B](http://mng.bz/4B2B)）。
- en: 5.6 Transforming the dataframe into the format expected by the Keras model
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.6 将数据框转换为 Keras 模型期望的格式
- en: The Keras model expects tensors as input. You can think of a tensor as being
    a generalization of a matrix. A matrix is a 2D tensor, and a vector is a 1D tensor.
    Figure 5.16 summarizes common terms for tensors by dimension.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 模型期望输入张量。你可以将张量视为矩阵的推广。矩阵是一个二维张量，而向量是一个一维张量。图 5.16 总结了按维度总结的张量常见术语。
- en: '![CH05_F16_Ryan](../Images/CH05_F16_Ryan.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F16_Ryan](../Images/CH05_F16_Ryan.png)'
- en: Figure 5.16 Tensor summary
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.16 张量摘要
- en: When we have made all the data transformations that we need to make in Pandas
    dataframes, the final step before feeding this data into the model to train is
    putting the data in the tensor format required by the Keras model. By leaving
    this transformation as the final step before training the model, we get to enjoy
    the convenience and familiarity of Pandas dataframes until we need to put the
    data in the format expected by the Keras model. The code to perform this transformation
    is in the `transform` method of the `prep_for_keras_input` class, shown in the
    next listing. This class is part of the pipelines described in chapter 8 that
    perform transformations on data for training and scoring.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在 Pandas 数据框中完成所有需要进行的所有数据转换后，在将数据输入模型进行训练之前的最后一步是将数据放入 Keras 模型所需的张量格式。通过将这种转换作为训练模型之前的最后一步，我们可以在需要将数据放入
    Keras 模型期望的格式之前，享受到 Pandas 数据框的便利性和熟悉感。执行此转换的代码位于 `prep_for_keras_input` 类的 `transform`
    方法中，如下所示。这个类是第 8 章中描述的管道的一部分，该管道对训练和评分的数据进行转换。
- en: Listing 5.2 Code to put the data in the tensor format required by the model
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.2 将数据放入模型所需的张量格式的代码
- en: '[PRE3]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ List that will contain numpy arrays for each column
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将包含每个列的 numpy 数组的列表
- en: ❷ Append the numpy array for the current categorical column to the overall list.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将当前分类列的 numpy 数组追加到整体列表中。
- en: ❸ Append the numpy array for the current text column to the overall list.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将当前文本列的 numpy 数组追加到整体列表中。
- en: ❹ Append the numpy array for the current continuous column to the overall list.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 将当前连续列的 numpy 数组追加到整体列表中。
- en: This code is flexible. Like the rest of the code in this example, as long as
    the columns from the input dataset are categorized correctly, this code will work
    with a wide variety of tabular structured data. It isn’t specific to the streetcar
    dataset.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码是灵活的。像本例中的其他代码一样，只要输入数据集的列被正确分类，这段代码就可以与各种表格结构化数据一起工作。它并不特定于电车数据集。
- en: 5.7 A brief history of Keras and TensorFlow
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.7 Keras 和 TensorFlow 的简要历史
- en: We have reviewed the final set of transformations that the dataset needs to
    go through in preparation to train a deep learning model. This section provides
    background on Keras, the high-level deep learning framework used to create the
    model for the primary example in this book. We will begin in this section by briefly
    reviewing the history of Keras and its relationship with TensorFlow, the low-level
    deep learning framework. In section 5.8, we will review the steps required to
    migrate from TensorFlow 1.x to TensorFlow 2, the backend deep learning framework
    used for the code examples in this book. In section 5.9, we will briefly contrast
    the Keras/TensorFlow framework with the other major deep learning framework, PyTorch.
    In section 5.10, we will review two code examples that show how the layers of
    a deep learning model are built in Keras. With this background on Keras, we will
    be ready to examine how the Keras framework is used to implement the streetcar
    delay prediction deep learning model in section 5.11.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经审查了数据集在准备训练深度学习模型之前需要经历的最终转换集。本节提供了关于 Keras 的背景信息，Keras 是用于创建本书主要示例中模型的通用深度学习框架。我们将从本节开始，简要回顾
    Keras 的历史及其与低级深度学习框架 TensorFlow 的关系。在第 5.8 节中，我们将回顾从 TensorFlow 1.x 迁移到 TensorFlow
    2（本书代码示例所使用的后端深度学习框架）所需的步骤。在第 5.9 节中，我们将简要对比 Keras/TensorFlow 框架与其他主要深度学习框架 PyTorch。在第
    5.10 节中，我们将回顾两个代码示例，展示如何在 Keras 中构建深度学习模型的层。有了关于 Keras 的这些背景知识，我们就可以准备检查 Keras
    框架是如何用于实现第 5.11 节中的电车延迟预测深度学习模型的了。
- en: Keras began its life as a frontend for a variety of backend deep learning frameworks,
    including TensorFlow ([https://www.tensorflow.org](https://www.tensorflow.org/))
    and Theano. The purpose of Keras was to provide a set of accessible, easy-to-use
    APIs that developers could use to explore deep learning. When Keras was released
    in 2015, the deep learning backend libraries that it supported (first Theano and
    then TensorFlow) provided a broad range of functions but could be challenging
    for beginners to master. With Keras, developers could get started with deep learning
    by using familiar syntax and without having to worry about all the details exposed
    in the backend libraries.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 最初是作为各种后端深度学习框架的前端而诞生的，包括 TensorFlow ([https://www.tensorflow.org](https://www.tensorflow.org/))
    和 Theano。Keras 的目的是提供一套易于访问、易于使用的 API，开发者可以使用这些 API 来探索深度学习。当 Keras 在 2015 年发布时，它所支持的深度学习后端库（最初是
    Theano，然后是 TensorFlow）提供了一系列广泛的功能，但对于初学者来说可能难以掌握。有了 Keras，开发者可以通过使用熟悉的语法开始深度学习，而无需担心后端库中暴露的所有细节。
- en: If you were starting a deep learning project back in 2017, your choices included
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是在 2017 年开始一个深度学习项目，你的选择包括
- en: Using TensorFlow libraries directly
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 直接使用 TensorFlow 库
- en: Using Keras as a frontend to TensorFlow
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 Keras 作为 TensorFlow 的前端使用
- en: Using Keras with another backend, such as Theano (although by 2017 backends
    other than TensorFlow were becoming rare)
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Keras 与其他后端，如 Theano（尽管到 2017 年，除了 TensorFlow 之外的后端变得越来越少见）
- en: 'Although most people who used Keras for deep learning projects exploited TensorFlow
    as the backend, Keras and TensorFlow were distinct, separate projects. All this
    changed in 2019 with the release of TensorFlow 2:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管大多数使用 Keras 进行深度学习项目的人使用了 TensorFlow 作为后端，但 Keras 和 TensorFlow 是两个独立的项目。所有这些都在
    2019 年随着 TensorFlow 2 的发布而改变：
- en: Coders using Keras for deep learning are encouraged to use the `tf.keras` package
    integrated into TensorFlow rather than free-standing Keras.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 鼓励使用 Keras 进行深度学习的程序员使用集成到 TensorFlow 中的 `tf.keras` 包，而不是独立的 Keras。
- en: TensorFlow users are encouraged to use Keras (via the `tf.keras` package in
    TensorFlow) as the high-level API for TensorFlow. As of TensorFlow 2, Keras is
    the official high-level API for TensorFlow ([http://mng.bz/xrWY](http://mng.bz/xrWY)).
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 鼓励 TensorFlow 用户使用 Keras（通过 TensorFlow 中的 `tf.keras` 包）作为 TensorFlow 的高层 API。截至
    TensorFlow 2，Keras 是 TensorFlow 的官方高层 API ([http://mng.bz/xrWY](http://mng.bz/xrWY))。
- en: In short, Keras and TensorFlow, which had originally been separate but related
    projects, have come together. In particular, as new TensorFlow point releases
    come out (such as TensorFlow 2.2.0 [[http://mng.bz/yrnJ](http://mng.bz/yrnJ) ],
    released in May 2020), they will include improvements in the backend as well as
    improvements in the Keras frontend. You can find more details about the relationship
    between Keras and TensorFlow, particularly the role played by TensorFlow in the
    overall operation of a deep learning model defined with Keras, in the *Deep Learning
    with Python* chapter on Keras and TensorFlow ([http://mng.bz/AzA7](http://mng.bz/AzA7)).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，原本是独立但相关的项目 Keras 和 TensorFlow 已经合并。特别是，随着新的 TensorFlow 点版本发布（例如，2020 年
    5 月发布的 TensorFlow 2.2.0 [[http://mng.bz/yrnJ](http://mng.bz/yrnJ)]），它们将包括后端以及
    Keras 前端的改进。您可以在 Keras 和 TensorFlow 的 *Python 深度学习* 章节中找到有关 Keras 和 TensorFlow
    之间关系的更多详细信息，特别是 TensorFlow 在使用 Keras 定义的深度学习模型整体操作中扮演的角色（[http://mng.bz/AzA7](http://mng.bz/AzA7)）。
- en: 5.8 Migrating from TensorFlow 1.x to TensorFlow 2
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.8 从 TensorFlow 1.x 迁移到 TensorFlow 2
- en: The deep learning model code described in this chapter and chapter 6 was originally
    written to use self-standing Keras with TensorFlow 1.x as a backend. TensorFlow
    2 was released while this book was being written, so I decided to migrate to the
    integrated Keras environment in TensorFlow 2\. Thus, to run the code in streetcar_model_training
    .ipynb , you need to have TensorFlow 2 installed in your Python environment. If
    you have other deep learning projects that have not moved to TensorFlow 2, you
    can create a Python virtual environment specifically for the code example in this
    book and install TensorFlow 2 there. That way, you will not introduce changes
    in your other deep learning projects.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 本章和第 6 章中描述的深度学习模型代码最初是编写为使用独立的 Keras，以 TensorFlow 1.x 作为后端。在本书编写期间，TensorFlow
    2 已发布，因此我决定迁移到 TensorFlow 2 中的集成 Keras 环境。因此，要在 streetcar_model_training .ipynb
    中运行代码，您需要在 Python 环境中安装 TensorFlow 2。如果您有尚未迁移到 TensorFlow 2 的其他深度学习项目，您可以为此书中的代码示例创建一个特定的
    Python 虚拟环境，并在其中安装 TensorFlow 2。这样，您就不会在您的其他深度学习项目中引入更改。
- en: 'This section summarizes the changes that I needed to make to the code in the
    model training notebook to migrate it from self-standing Keras with TensorFlow
    1.x as a backend to Keras in the context of TensorFlow 2\. The TensorFlow documentation
    includes comprehensive migration steps at [https://www.tensorflow.org/guide/migrate](https://www.tensorflow.org/guide/migrate).
    Following is a brief summary of the steps I took:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 本节总结了我在模型训练笔记本中需要进行的代码更改，以将其从使用 TensorFlow 1.x 作为后端的独立 Keras 迁移到 TensorFlow
    2 上下文中的 Keras。TensorFlow 文档中包含了全面的迁移步骤，网址为 [https://www.tensorflow.org/guide/migrate](https://www.tensorflow.org/guide/migrate)。以下是我在以下步骤中采取的简要总结：
- en: 'Upgraded my existing level of TensorFlow to the latest TensorFlow 1.x level:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将我的现有 TensorFlow 版本升级到最新版本的 TensorFlow 1.x：
- en: '[PRE4]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Ran the model training notebook end to end to validate that everything worked
    in the latest level of TensorFlow 1.x.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完整运行模型训练笔记本以验证在最新版本的 TensorFlow 1.x 中一切是否正常工作。
- en: Ran the upgrade script tf_upgrade_v2 on the model training notebook.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在模型训练笔记本上运行升级脚本 tf_upgrade_v2。
- en: Changed all Keras import statements to reference the tf.keras package (including
    changing `from keras import regularizers` to `from tensorflow.keras import regularizers`).
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有 Keras 导入语句更改为引用 tf.keras 包（包括将 `from keras import regularizers` 更改为 `from
    tensorflow.keras import regularizers`）。
- en: Ran the model training notebook end to end with the updated import statements
    to validate that everything worked.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用更新的导入语句完整运行模型训练笔记本以验证一切是否正常工作。
- en: Created a Python virtual environment, following the instructions at [https://
    janakiev.com/blog/jupyter-virtual-envs](https://janakiev.com/blog/jupyter-virtual-envs).
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下网址的说明创建了 Python 虚拟环境：[https://janakiev.com/blog/jupyter-virtual-envs](https://janakiev.com/blog/jupyter-virtual-envs)。
- en: 'Installed TensorFlow 2 in the Python virtual environment. This step was necessary
    because the Rasa chatbot framework that is part of the Facebook Messenger deployment
    approach described in chapter 8 requires TensorFlow 1.x. By installing TensorFlow
    2 in a virtual environment, we can exploit the virtual environment for the model
    training steps without breaking the deployment prerequisite for TensorFlow 1.x.
    Here is the command to install TensorFlow 2:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Python 虚拟环境中安装了 TensorFlow 2。这一步骤是必要的，因为第 8 章中描述的 Facebook Messenger 部署方法的一部分
    Rasa 聊天机器人框架需要 TensorFlow 1.x。通过在虚拟环境中安装 TensorFlow 2，我们可以利用虚拟环境进行模型训练步骤，而不会破坏
    TensorFlow 1.x 的部署先决条件。以下是安装 TensorFlow 2 的命令：
- en: '[PRE5]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The process of migrating to TensorFlow 2 was painless, and thanks to Python
    virtual environments, I was able to apply this migration where I needed it for
    the model training without causing any side effects for the rest of my Python
    projects.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移到 TensorFlow 2 的过程非常顺利，多亏了 Python 虚拟环境，我能够在需要的地方进行模型训练迁移，而不会对我的其他 Python 项目造成任何副作用。
- en: 5.9 TensorFlow vs. PyTorch
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.9 TensorFlow 与 PyTorch
- en: 'Before exploring Keras in more depth, it’s worth quickly discussing the other
    major library that is currently used for deep learning: PyTorch ([https://pytorch.org](https://pytorch.org)).
    PyTorch was developed by Facebook and made available as open source in 2017\.
    The article at [http://mng.bz/Moj2](http://mng.bz/Moj2) makes a succinct comparison
    of the two libraries. The community that uses TensorFlow is currently larger than
    the one that uses PyTorch, although PyTorch is growing quickly. PyTorch has a
    stronger presence in the academic/research world (and is the basis of the coding
    aspects of the fast.ai course described in chapter 9), whereas TensorFlow is predominant
    in industry.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在更深入地探索 Keras 之前，快速讨论一下目前用于深度学习的另一个主要库：PyTorch ([https://pytorch.org](https://pytorch.org))。PyTorch
    由 Facebook 开发，并于 2017 年作为开源软件发布。在 [http://mng.bz/Moj2](http://mng.bz/Moj2) 的文章中对这两个库进行了简洁的比较。目前使用
    TensorFlow 的社区比使用 PyTorch 的社区大，尽管 PyTorch 的增长速度很快。PyTorch 在学术界/研究界有更强的存在感（并且是第9章中描述的
    fast.ai 课程编码方面的基础），而 TensorFlow 在工业界占主导地位。
- en: 5.10 The structure of a deep learning model in Keras
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.10 Keras 中深度学习模型的架构
- en: You may recall that chapter 1 described a neural network as a series of nodes
    organized in layers, each of which has weights associated with it. In simple terms,
    during the training process these weights get updated repeatedly until the loss
    function is minimized and the accuracy of the model’s predictions is optimized.
    In this section, we will show how the abstract idea of layers introduced in chapter
    1 is manifested in code in Keras by reviewing two simple deep learning models.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还记得，第1章将神经网络描述为由层组织的一系列节点，每一层都与一些权重相关联。简单来说，在训练过程中，这些权重会反复更新，直到损失函数最小化，并且模型预测的准确性得到优化。在本节中，我们将通过回顾两个简单的深度学习模型来展示第1章中引入的层这一抽象概念如何在
    Keras 代码中体现。
- en: 'There are two ways to define the layers of a Keras model: the sequential API
    and the functional API. The sequential API is the simpler method but is less flexible;
    the functional API has more flexibility but is a bit more complex to use.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 Keras 模型的层有两种方式：顺序 API 和功能 API。顺序 API 是更简单的方法，但灵活性较低；功能 API 更灵活，但使用起来稍微复杂一些。
- en: To illustrate these two APIs, we are going to look at how we would create minimal
    Keras deep learning models with both approaches for MNIST ([https://www.tensorflow
    .org/datasets/catalog/mnist](https://www.tensorflow.org/datasets/catalog/mnist)).
    If you have not encountered MNIST before, it is a dataset made up of labeled images
    of handwritten digits. The `x` values come from the image files, and the labels
    (`y` values) are the text representations of the digits. The goal of a model exercising
    MNIST is to correctly identify the digit for the handwritten images. MNIST is
    commonly used as a minimal dataset for exercising deep learning models. If you
    want more background on MNIST and how it is used to exercise deep learning frameworks,
    a great article at [http://mng.bz/Zr2a](http://mng.bz/Zr2a) provides more details.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这两个 API，我们将探讨如何使用两种方法创建最小的 Keras 深度学习模型，用于 MNIST ([https://www.tensorflow.org/datasets/catalog/mnist](https://www.tensorflow.org/datasets/catalog/mnist))。如果你之前没有遇到过
    MNIST，它是由手写数字的标记图像组成的数据库。`x` 值来自图像文件，标签（`y` 值）是数字的文本表示。MNIST 模型的目标是正确识别手写图像中的数字。MNIST
    通常用作练习深度学习模型的简化数据集。如果你想要更多关于 MNIST 以及它是如何用于练习深度学习框架的背景信息，一篇优秀的文章在 [http://mng.bz/Zr2a](http://mng.bz/Zr2a)
    提供了更多细节。
- en: 'It is worth noting that MNIST is not a structured dataset according to the
    definition of structured data in chapter 1\. There are two reasons for choosing
    MNIST for the examples in this section, even though it’s not a structured dataset:
    the published starter examples of the Keras APIs use MNIST, and there is no recognized
    structured dataset for exercising deep learning models that is equivalent to MNIST.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，MNIST 并不是一个根据第1章中结构化数据的定义所定义的结构化数据集。尽管它不是一个结构化数据集，但选择 MNIST 作为本节示例的原因有两个：Keras
    API 的已发布入门示例使用 MNIST，并且没有公认的与 MNIST 相当的结构化数据集用于训练深度学习模型。
- en: With the sequential API, the model definition takes as an argument an ordered
    list of layers. You can select layers that you want to include in your model from
    the list of supported Keras layers in TensorFlow 2 ([http://mng.bz/awaJ](http://mng.bz/awaJ)).
    The code snippet in listing 5.3 comes from keras_sequential _api_mnist.py. It
    is adapted from the TensorFlow 2 documentation ([http://mng.bz/ RMAO](http://mng.bz/RMAO))
    and shows a simple deep learning model for MNIST that uses the Keras sequential
    API.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 使用顺序API，模型定义接受一个有序的层列表作为参数。您可以从TensorFlow 2中支持的Keras层列表中选择您想要包含在模型中的层（[http://mng.bz/awaJ](http://mng.bz/awaJ)）。列表5.3中的代码片段来自`keras_sequential_api_mnist.py`，它改编自TensorFlow
    2文档（[http://mng.bz/RMAO](http://mng.bz/RMAO)），并展示了一个简单的MNIST深度学习模型，该模型使用Keras顺序API。
- en: Listing 5.3 Code for an MNIST model using the Keras sequential API
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.3 使用Keras顺序API的MNIST模型代码
- en: '[PRE6]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ Define Keras sequential model
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 定义Keras顺序模型
- en: ❷ Flatten layer that reshapes the input tensor to a tensor with a shape equal
    to the number of elements in the input tensor
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 展平层，将输入张量重塑为形状等于输入张量元素数量的张量
- en: ❸ Dense layer that does the standard operation of getting the dot product of
    the input to the layer and the weights in the layer, plus the bias
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 密集层执行标准操作，即计算层的输入与层中的权重以及偏置的点积
- en: ❹ Dropout layer that randomly turns off a proportion of the network
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ Dropout层，随机关闭网络的一部分
- en: ❺ Output dense layer
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 输出密集层
- en: ❻ Compile the model, specifying the loss function, the optimizer, and the metric
    to be tracked in the training process.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 编译模型，指定损失函数、优化器和训练过程中要跟踪的指标。
- en: ❼ Fit the model by adjusting the weights to minimize the loss function.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 通过调整权重以最小化损失函数来拟合模型。
- en: ❽ Assess model performance
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 评估模型性能
- en: 'This simple example of a Keras deep learning model has several characteristics
    in common with non-deep-learning models that you have already seen:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这个Keras深度学习模型的简单示例与您已经看到的非深度学习模型有几个共同特点：
- en: The input dataset is split into train and test subsets. The train subset is
    used in the training process to adjust the weights in the model. The test dataset
    is applied to the trained model to assess its performance; in this example, according
    to the accuracy (that is, how closely the predictions for the model match the
    actual output values).
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入数据集被分为训练集和测试集。训练集用于训练过程中调整模型中的权重。测试数据集应用于训练好的模型以评估其性能；在这个例子中，根据准确率（即模型的预测与实际输出值的接近程度）。
- en: Both the training and test datasets are made up of input `x` values (for MNIST,
    images of handwritten digits) and labels or `y` values (for MNIST, the ASCII digits
    corresponding to the handwritten digits).
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练集和测试集都由输入`x`值（对于MNIST，手写数字的图像）和标签或`y`值（对于MNIST，对应手写数字的ASCII数字）组成。
- en: Both non-deep-learning and deep learning models have similar statements to define
    and fit the model. The code snippets in the next listing contrast the statements
    to define and fit a logistic regression model and a Keras deep learning model.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非深度学习和深度学习模型在定义和拟合模型时都有类似的语句。下一列表中的代码片段对比了定义和拟合逻辑回归模型和Keras深度学习模型的语句。
- en: Listing 5.4 Code to contrast a logistic regression model and a Keras model
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列表5.4对比逻辑回归模型和Keras模型的代码
- en: '[PRE7]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ Define the logistic regression model.
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 定义逻辑回归模型。
- en: ❷ Fit the logistic regression model.
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 调整逻辑回归模型。
- en: '❸ First part of defining the Keras deep learning model: defining the layers'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❸ 定义Keras深度学习模型的第一部分：定义层
- en: '❹ Second part of defining the Keras deep learning model: setting the compilation
    parameters'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❹ 定义Keras深度学习模型的第二部分：设置编译参数
- en: ❺ Fit the Keras deep learning model.
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❺ 拟合Keras深度学习模型。
- en: Figure 5.17 shows the output of the `plot_model` function for the MNIST sequential
    API model.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.17显示了`plot_model`函数对MNIST顺序API模型的输出。
- en: '![CH05_F17_Ryan](../Images/CH05_F17_Ryan.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F17_Ryan](../Images/CH05_F17_Ryan.png)'
- en: Figure 5.17 plot_model output for simple sequential API Keras model
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.17简单顺序API Keras模型的plot_model输出
- en: By contrast with the sequential API, the Keras functional API has a more complex
    syntax but provides greater flexibility. In particular, the functional API allows
    you to define a model with multiple inputs. As you will see in section 5.13, the
    extended example in this book exploits the functional API because it requires
    multiple inputs.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 与序列API相比，Keras功能API的语法更复杂，但提供了更大的灵活性。特别是，功能API允许您定义具有多个输入的模型。正如您将在第5.13节中看到的，本书中的扩展示例利用了功能API，因为它需要多个输入。
- en: The code snippet in listing 5.5 comes from keras_ functional_api_mnist.py. It
    is adapted from [https://www .tensorflow.org/guide/keras/functional](https://www.tensorflow.org/guide/keras/functional)
    and shows how you would use the Keras functional API to define a simple deep learning
    model for the same MNIST problem for which we showed a sequential API solution.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.5中的代码片段来自keras_ functional_api_mnist.py。它改编自[https://www .tensorflow.org/guide/keras/functional](https://www.tensorflow.org/guide/keras/functional)，展示了如何使用Keras功能API定义一个简单的深度学习模型，用于解决我们之前展示的序列API解决方案相同的MNIST问题。
- en: Listing 5.5 Code for an MNIST model using the Keras functional API
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.5使用Keras功能API的MNIST模型代码
- en: '[PRE8]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ Define layer that flattens the input tensor by reshaping it to a tensor with
    a shape equal to the number of elements in the input tensor
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 定义层，通过重新塑形输入张量，将其转换为与输入张量元素数量相等的张量
- en: ❷ Dense layer that does the standard operation of getting the dot product of
    the input to the layer and the weights in the layer, plus the bias
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 执行标准操作的密集层，即计算层的输入与层中的权重以及偏置的乘积
- en: ❸ Dropout layer that randomly turns off a proportion of the network
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 随机关闭网络一部分比例的Dropout层
- en: ❹ Output dense layer
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 输出密集层
- en: ❺ Compile the model, specifying the loss function, the optimizer, and the metric
    to be tracked in the training process.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 编译模型，指定损失函数、优化器和训练过程中要跟踪的指标。
- en: ❻ Fit the model (with parameters set for the training dataset, batch size, number
    of epochs, and subset of the training set to reserve for validation) by adjusting
    the weights to minimize the loss function.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 通过调整权重以最小化损失函数，将模型（使用训练数据集的参数、批量大小、训练轮数以及为验证保留的训练集子集）拟合。
- en: ❼ Assess the model performance.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 评估模型性能。
- en: You can see a lot of similarity between the sequential API and functional API
    approaches to this problem. The `loss` function is defined the same way, for example,
    and the `compile` and `fit` statements are the same. What is different between
    the sequential API and the functional API is the definition of the layers. In
    the sequential API approach, the layers are defined in a single list, whereas
    in the functional API approach, the layers are recursively defined, with each
    layer being built on its predecessors.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到序列API和功能API在此问题上的许多相似之处。例如，`loss`函数的定义方式相同，`compile`和`fit`语句也相同。序列API和功能API之间的不同之处在于层的定义。在序列API方法中，层定义在一个单独的列表中，而在功能API方法中，层是递归定义的，每个层都是在其前驱层的基础上构建的。
- en: Figure 5.18 shows the output of `plot_model` for this simple functional API
    Keras model.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.18显示了此简单功能API Keras模型的`plot_model`输出。
- en: '![CH05_F18_Ryan](../Images/CH05_F18_Ryan.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F18_Ryan](../Images/CH05_F18_Ryan.png)'
- en: Figure 5.18 plot_model output for the simple functional API Keras model
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.18简单功能API Keras模型的plot_model输出
- en: 'In this section, we have examined a couple of simple Keras models and reviewed
    the essential characteristics of two approaches offered in Keras: the sequential
    API and the functional API. In section 5.13, we will see how the streetcar delay
    prediction model takes advantage of the flexibility of the functional API.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们考察了几种简单的Keras模型，并回顾了Keras提供的两种基本方法的关键特性：序列API和功能API。在第5.13节中，我们将看到街道延误预测模型如何利用功能API的灵活性。
- en: 5.11 How the data structure defines the Keras model
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.11数据结构如何定义Keras模型
- en: In chapter 3, you learned that the columns in the structured dataset are categorized
    as categorical, continuous, or text (figure 5.19).
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在第3章中，您了解到结构化数据集中的列被分类为分类、连续或文本（图5.19）。
- en: '![CH05_F19_Ryan](../Images/CH05_F19_Ryan.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F19_Ryan](../Images/CH05_F19_Ryan.png)'
- en: Figure 5.19 Column categories in the streetcar dataset
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.19街道数据集的列类别
- en: '*Continuous* — These values are numeric. Examples of common continuous values
    include temperatures, currency values, time spans (such as elapsed hours), and
    counts of objects or activities. In the streetcar example, Min Delay and Min Gap
    (the columns containing the number of minutes of delay incurred by the delay and
    the length in minutes of the resulting gap between streetcars) are continuous
    columns. The latitude and longitude values derived from the Location column are
    also treated as continuous columns.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*连续* —这些值是数值。常见的连续值示例包括温度、货币值、时间跨度（如已过小时数）和对象或活动的计数。在街车示例中，最小延迟和最小间隔（包含延迟造成的分钟数和街车之间产生的间隔长度的分钟数）是连续列。从位置列派生出的纬度和经度值也被视为连续列。'
- en: '*Categorical* —These values can be single strings, such as the days of the
    week, or collections of one or more strings that constitute an identifier, such
    as the names of the U.S. states. The number of distinct values in categorical
    columns can range from two to several thousand. Most of the columns in the streetcar
    dataset are categorical, including Route, Day, Location, Incident, Direction,
    and Vehicle.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*类别* —这些值可以是单个字符串，例如一周中的某一天，或者由一个或多个字符串组成的标识符集合，例如美国各州的名称。类别列中不同值的数量可以从两个到几千个不等。街车数据集中的大多数列都是类别列，包括路线、日期、位置、事件、方向和车辆。'
- en: '*Text* —These values are sets of strings.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*文本* —这些值是字符串集合。'
- en: It’s essential to organize the input dataset into these categories because the
    categories define how the deep learning model code is assembled in the deep learning
    approach described in this book. The layers of the Keras model are built up based
    on these categories, with each category having its own structure of layers.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 将输入数据集组织成这些类别是至关重要的，因为这些类别定义了本书中描述的深度学习方法中深度学习模型代码的组装方式。Keras模型的层是基于这些类别构建的，每个类别都有自己的层结构。
- en: 'The following illustrations summarize the layers that are built up for categorical
    and text columns. Figure 5.20 shows the layers that get built for categorical
    columns:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 以下插图总结了为类别和文本列构建的层。图5.20显示了为类别列构建的层：
- en: '*Embedding* —As explained in section 5.12, embeddings provide a way for the
    model to learn the relationships between values in categorical categories in the
    context of the overall prediction the model is making.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*嵌入* —如第5.12节所述，嵌入提供了一种方法，使模型能够在整体预测的上下文中学习类别中值之间的关系。'
- en: '*Batch normalization* —Batch normalization is a method of preventing overfitting
    (a model working well on the dataset it was trained on, but poorly on other data)
    by controlling how much weights change in hidden layers.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*批量归一化* —批量归一化是一种通过控制隐藏层中权重变化量来防止过拟合（模型在训练数据集上表现良好，但在其他数据上表现不佳）的方法。'
- en: '*Flatten* —Reshape the input to prepare for subsequent layers.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*展平* —将输入重塑以准备后续层。'
- en: '*Dropout* —Use this technique to prevent overfitting. With dropout, as the
    name suggests, rotating, random subsets of nodes in the network are ignored in
    forward and backward passes through the network.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*丢弃* —使用此技术来防止过拟合。正如其名所示，丢弃技术会在网络的前向和反向传播过程中忽略网络中节点的随机子集。'
- en: '*Concatenate* —Join the layers for this input with layers for the other inputs.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*连接* —将此输入的层与其他输入的层连接起来。'
- en: '![CH05_F20_Ryan](../Images/CH05_F20_Ryan.png)'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![CH05_F20_Ryan](../Images/CH05_F20_Ryan.png)'
- en: Figure 5.20 Keras layers for categorical inputs
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.20 Keras类别输入层
- en: Figure 5.21 shows the layers that get built for text input columns. In addition
    to the layers for categorical columns, text columns get a GRU layer. A *GRU* ([https://keras
    .io/api/layers/recurrent_layers/gru](https://keras.io/api/layers/recurrent_layers/gru))
    is a kind of recurrent neural network (RNN), the class of deep learning models
    commonly used for text processing. What sets RNNs apart from other neural networks
    are the gates that control how much previous inputs affect the way that current
    input changes weights in the model. The interesting point is that the actions
    of these gates—how much is “remembered” from previous input—is learned in the
    same way that the generic weights in the network are learned. Adding this layer
    to the set of layers for text columns means, at a high level, that the order of
    words in the text column (not the presence of individual words alone) contributes
    to the training of the model.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.21显示了为文本输入列构建的层。除了分类列的层之外，文本列还获得一个GRU层。*GRU*（[https://keras.io/api/layers/recurrent_layers/gru](https://keras.io/api/layers/recurrent_layers/gru)）是一种循环神经网络（RNN），这是深度学习模型中常用的一种文本处理模型。RNN与其他神经网络的不同之处在于控制先前输入对当前输入如何改变模型中权重的影响的门。有趣的是，这些门的行为——从先前输入中“记住”多少——是以与网络中通用权重相同的方式学习的。将此层添加到文本列的层集中意味着，从高层次来看，文本列中单词的顺序（而不仅仅是单个单词的存在）有助于模型的训练。
- en: '![CH05_F21_Ryan](../Images/CH05_F21_Ryan.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F21_Ryan](../Images/CH05_F21_Ryan.png)'
- en: Figure 5.21 Keras layers for text inputs
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.21 Keras文本输入层
- en: We’ve reviewed the layers that are added to the deep learning model for categorical
    and text columns. What about continuous columns? These columns don’t have any
    special additional layers and are concatenated directly into the overall model.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经回顾了添加到深度学习模型中的分类和文本列的层。那么连续列呢？这些列没有特殊额外的层，而是直接连接到整体模型中。
- en: 'This section briefly described the layers in the deep learning model that are
    built up for each of the three column types in a structured dataset: continuous,
    categorical, and text. In section 5.13, we will go in detail through the code
    that implements these layers.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 本节简要描述了在结构化数据集中为每种列类型（连续、分类和文本）构建的深度学习模型中的层。在5.13节中，我们将详细讲解实现这些层的代码。
- en: 5.12 The power of embeddings
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.12 嵌入的力量
- en: In section 5.11, you saw the layers that get defined for each type of column
    in a structured dataset. In particular, you saw that categorical and text columns
    get embedding layers. In this section, we will examine embeddings and how they
    are used. We will return to the power of embeddings in chapter 7 in an experiment
    that demonstrates the effect of categorical column embeddings on the performance
    of the model.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在5.11节中，您看到了在结构化数据集中为每种类型的列定义的层。特别是，您看到了分类和文本列获得嵌入层。在本节中，我们将检查嵌入及其应用。在第7章中，我们将通过一个实验回到嵌入的强大功能，该实验展示了分类列嵌入对模型性能的影响。
- en: Embeddings come from the world of natural language processing, in which they
    are used to map words to a numeric representation. Embeddings are an important
    topic for this book because they are essential for enabling a deep learning model
    to exploit categorical and text columns in a structured dataset. This section
    is not an exhaustive description of embeddings—a topic that deserves a book of
    its own—but it introduces the concept and describes why embeddings are needed
    in a deep learning project on structured data. You can find a more detailed description
    of embeddings in the section on text embeddings in Stephan Raaijmakers’s *Deep
    Learning for Natural Language Processing* ([http://mng.bz/2WXm](http://mng.bz/2WXm)).
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入来自自然语言处理领域，其中它们用于将单词映射到数值表示。嵌入是本书的一个重要主题，因为它们对于使深度学习模型能够利用结构化数据集中的分类和文本列至关重要。本节并不是嵌入的全面描述——这是一个值得单独成书的话题，但它介绍了该概念并描述了为什么在结构化数据的深度学习项目中需要嵌入。您可以在Stephan
    Raaijmakers的《深度学习自然语言处理》一书中找到嵌入的更详细描述（[http://mng.bz/2WXm](http://mng.bz/2WXm)）。
- en: 'The excellent article at [http://mng.bz/1gzn](http://mng.bz/1gzn) states that
    embeddings are *representations of categorical values* *as learned, low-dimensional
    continuous vectors* . That’s a lot of information in one sentence. Let’s look
    at it piece by piece:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在[http://mng.bz/1gzn](http://mng.bz/1gzn)上的优秀文章中指出，嵌入是**作为学习到的低维连续向量**对分类值的**表示**。这句话包含了大量信息。让我们逐个分析：
- en: '*Representations of categorical values* —Recall the definition of categorical
    values from chapter 3: These values can be “single strings, such as the days of
    the week, or collections of one or more strings that constitute an identifier,
    such as the names of the U.S. states. The number of distinct values in categorical
    columns can range from two to several thousand.” The columns in the streetcar
    dataset that have embeddings associated with them include the categorical columns
    Route, Day, Location, Incident, Direction, and Vehicle.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*类别值的表示* —回想一下第3章中类别值的定义：这些值可以是“单个字符串，如一周中的某一天，或者由一个或多个字符串组成的标识符集合，如美国各州的名称。类别列中不同值的数量可以从两个到几千个不等。”与嵌入相关的街车数据集的列包括类别列路线、日期、位置、事件、方向和车辆。'
- en: '*Learned* —Like the deep learning model weights introduced in chapter 1, the
    values of embeddings are learned. The values of embeddings are initialized before
    training and then get updated through iterations of the deep learning model. The
    result is that after the embeddings have been learned, the embeddings for categorical
    values that tend to produce the same outcome are closer to one another. Consider
    the context of days of the week (Monday to Sunday) as a derived feature of the
    streetcar delay dataset. Suppose that delays are less common on weekends. If this
    is the case, the embeddings learned for Saturday and Sunday will be closer to
    one another than to the embeddings learned for the weekdays.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*学习得到的* —就像第1章中介绍的深度学习模型权重一样，嵌入的值是通过学习得到的。嵌入的值在训练之前被初始化，然后通过深度学习模型的迭代更新。结果是，在嵌入被学习之后，那些倾向于产生相同结果的类别值的嵌入会更接近彼此。考虑一周中的日子（从星期一到星期日）作为街车延误数据集的派生特征。假设周末的延误较少。如果是这样，周六和周日的嵌入将比工作日的嵌入更接近。'
- en: '*Low-dimensional* —This term means that the dimension of the embedding vectors
    is low compared with the number of categorical values. In the model created for
    the main example in this book, the Route column has more than 1,000 distinct values
    but has an embedding with a dimension of 10.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*低维* —这个术语意味着嵌入向量的维度相对于类别值的数量来说是低的。在本书中主要示例创建的模型中，路线列有超过1,000个不同的值，但其嵌入维度为10。'
- en: '*Continuous* —This term means that the values in the embedding are represented
    by floating-point values as opposed to the integers that represent the categorical
    values themselves.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*连续的* —这个术语意味着嵌入中的值由浮点数表示，而不是表示类别值的整数。'
- en: 'A famous illustration of embeddings ([https://arxiv.org/pdf/1711.09160.pdf](https://arxiv.org/pdf/1711.09160.pdf))
    demonstrates how they can capture the relationships between the categorical values
    with which they are associated. This illustration shows the relationship between
    the vectors associated with four words in Word2Vec ([http://mng.bz/ggGR](http://mng.bz/ggGR)):'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 一个著名的嵌入示例（[https://arxiv.org/pdf/1711.09160.pdf](https://arxiv.org/pdf/1711.09160.pdf)）展示了它们如何捕捉与它们相关联的类别值之间的关系。这个示例显示了Word2Vec（[http://mng.bz/ggGR](http://mng.bz/ggGR)）中与四个单词相关的向量之间的关系：
- en: '[PRE9]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This says that the embedding vector for king minus the embedding vector for
    man plus the embedding vector for woman is close to the embedding vector for queen.
    In this example, arithmetic on the embeddings matches the semantic relationship
    between the words associated with the embeddings. This example shows the power
    of embeddings to map non-numeric, categorical values to a planar space where the
    values can be manipulated like numbers.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着国王的嵌入向量减去男人的嵌入向量再加上女人的嵌入向量接近于皇后的嵌入向量。在这个例子中，对嵌入的算术运算与与嵌入相关联的单词之间的语义关系相匹配。这个例子展示了嵌入将非数值、类别值映射到平面空间的能力，在这个空间中，值可以像数字一样被操作。
- en: A secondary benefit of embeddings is that they can be used to illustrate implicit
    relationships among categorical values. You get unsupervised learning analysis
    of the categories for free as you are solving the supervised learning problem.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入的另一个好处是，它们可以用来说明类别值之间的隐含关系。当你解决监督学习问题时，你会免费获得对类别进行无监督学习分析。
- en: 'A final benefit of embeddings is that they give you a way to incorporate categorical
    values into a deep learning framework without the drawbacks of one-hot encoding
    ([http://mng.bz/P1Av](http://mng.bz/P1Av)). In one-hot encoding, if there are
    seven values (such as for the days of the week), each value is represented by
    a vector of size 7 with six `0` s and a single `1` :'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入的最后一个好处是，它们为你提供了一种将分类值纳入深度学习框架的方法，而无需一热编码的缺点（[http://mng.bz/P1Av](http://mng.bz/P1Av)）。在一热编码中，如果有七个值（如一周中的日子），每个值都由一个大小为
    7 的向量表示，其中包含六个 `0` 和一个 `1`：
- en: 'Monday: [1,0,0,0,0,0,0]'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 星期一：[1,0,0,0,0,0,0]
- en: 'Tuesday: [0,1,0,0,0,0,0,0]'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 星期二：[0,1,0,0,0,0,0,0]
- en: . . .
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: . . .
- en: 'Sunday: [0,0,0,0,0,0,0,1]'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 星期日：[0,0,0,0,0,0,0,1]
- en: In a structured dataset, a one-hot encoding of the days-of-the-week category
    would require seven columns, which is not too bad for a category with a small
    number of values. But what about the Vehicle column, which has hundreds of values?
    You can see how one-hot encoding will quickly explode the number of columns in
    the dataset and the memory requirements to process the data. By exploiting embeddings
    in deep learning, we can deal with categorical columns without the poor scaling
    behavior of one-hot encoding.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在结构化数据集中，一周中各天的分类的一热编码需要七个列，对于一个值数量较少的分类来说，这并不算太糟糕。但关于车辆列，它有数百个值呢？你可以看到一热编码如何迅速增加数据集中的列数以及处理数据的内存需求。通过利用深度学习中的嵌入，我们可以处理分类列，而无需一热编码的糟糕缩放行为。
- en: This section is a brief introduction to the topic of embeddings. The benefits
    of using embeddings include the ability to manipulate non-numeric values that
    are analogous to common numeric operations, the ability to get unsupervised learning-type
    categorization on values in a categorical range as a byproduct of solving a supervised
    learning problem, and the ability to train deep learning models with categorical
    inputs without the drawbacks of one-hot encoding.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 本节简要介绍了嵌入主题。使用嵌入的好处包括能够操作类似于常见数值操作的类似非数值值，能够在解决监督学习问题的副产品中获得对分类范围内值的无监督学习型分类，以及能够在没有一热编码的缺点的情况下使用分类输入训练深度学习模型。
- en: 5.13 Code to build a Keras model automatically based on the data structure
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.13 基于数据结构自动构建 Keras 模型的代码
- en: The Keras model is made of up of a sequence of layers through which input columns
    flow to generate a prediction of a delay in a given route/direction/time-slot
    combination. Figure 5.22 shows the layers that the input columns flow through,
    depending on their data category (continuous, categorical, or text), along with
    examples of the kinds of data in each category. To examine the options you have
    for exploring these layers, see section 5.14.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 模型由一系列层组成，输入列通过这些层流动以生成给定路线/方向/时间槽组合的延迟预测。图 5.22 展示了输入列流经的层，以及根据其数据类别（连续、分类或文本）的示例数据类型。要查看探索这些层的选项，请参阅第
    5.14 节。
- en: '![CH05_F22_Ryan](../Images/CH05_F22_Ryan.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F22_Ryan](../Images/CH05_F22_Ryan.png)'
- en: Figure 5.22 Keras layers by column type with examples
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.22 按列类型划分的 Keras 层及示例
- en: The next listing shows the code that assigns each of the columns to one of these
    categories.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个列表展示了将每个列分配到这些类别之一的代码。
- en: Listing 5.6 Code that assigns columns to categories
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.6 将列分配给类别的代码
- en: '[PRE10]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ❶ The set of text columns in the refactored model is empty.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在重构后的模型中，文本列的集合为空。
- en: ❷ The set of continuous columns in the refactored model is empty.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在重构后的模型中，连续列的集合为空。
- en: ❸ excludefromcolist is the set of columns that will not train the model.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ `excludefromcolist` 是将不会训练模型的列集合。
- en: ❹ collist is the list of categorical columns. Here, it is generated by taking
    the list of columns and removing the text columns, continuous columns, and excluded
    columns.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ `collist` 是分类列的列表。在这里，它是通过从列列表中移除文本列、连续列和排除列生成的。
- en: These column lists—`textcols` , `continuouscols` , and `collist` —are used throughout
    the code to determine what actions are taken on the columns, including how the
    layers of the deep learning model are built up for each column that is being used
    to train the model. The following sections show the layers added for each column
    type.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这些列列表——`textcols`、`continuouscols` 和 `collist`——在代码中用于确定对列采取的操作，包括如何为每个用于训练模型的列构建深度学习模型的层。以下各节展示了为每种列类型添加的层。
- en: The following listing shows what the training data looks like before it is applied
    to the model for training. The training data is a list of numpy arrays—one array
    for each column in the training data.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表显示了在应用于模型进行训练之前，训练数据的样子。训练数据是一个numpy数组的列表——每个训练数据列一个数组。
- en: Listing 5.7 Format of the data before being used to train the model
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.7 在用于训练模型之前的数据格式
- en: '[PRE11]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ numpy array for hour. Values range from 0-23.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 用于小时的numpy数组。值范围从0到23。
- en: ❷ numpy array for route. Values range from 0-14.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 用于路线的numpy数组。值范围从0到14。
- en: ❸ numpy array for day of the week. Values range from 0-6.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 用于星期的numpy数组。值范围从0到6。
- en: ❹ numpy array for month. Values range from 0-11.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 用于月份的numpy数组。值范围从0到11。
- en: ❺ numpy array for year. Values range from 0-6.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 用于年份的numpy数组。值范围从0到6。
- en: ❻ numpy array for day of the month. Values range from 0-30.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 用于月份天数的numpy数组。值范围从0到30。
- en: ❼ numpy array for direction. Values range from 0 4.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 用于方向的numpy数组。值范围从0到4。
- en: 'The code that assembles the layers for each type of column is in the streetcar_
    model_training notebook in the `get_model()` function. Following is the code block
    in `get_model()` for continuous columns, which simply have the input layer flow
    through:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 组装每种类型列层的代码位于`streetcar_model_training`笔记本中的`get_model()`函数中。以下是`get_model()`函数中用于连续列的代码块，它只是让输入层流过：
- en: '[PRE12]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In the code block in `get_model()` for categorical columns, we see that these
    columns get embeddings and batch normalization layers, as the next listing shows.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在`get_model()`函数的分类列代码块中，我们看到这些列获得了嵌入和批归一化层，如下一列表所示。
- en: Listing 5.8 Code to apply embeddings and batch normalization to categorical
    columns
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.8 将嵌入和批归一化应用于分类列的代码
- en: '[PRE13]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ Start with the input.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从输入开始。
- en: ❷ Append the input layer for this column to the list of input layers, which
    will be used in the model definition statement.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将此列的输入层追加到输入层列表中，该列表将在模型定义语句中使用。
- en: ❸ Add the embedding layer.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 添加嵌入层。
- en: ❹ Add the batch normalization layer.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 添加批归一化层。
- en: In the code block in `get_model` `()` for text columns, we see that these columns
    get layers for embeddings, batch normalization, dropout, and a GRU, as shown next.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在`get_model` `()`函数的文本列代码块中，我们看到这些列获得了嵌入、批归一化、dropout和GRU层，如下所示。
- en: Listing 5.9 Code to apply the appropriate layers to text columns
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.9 将适当的层应用于文本列的代码
- en: '[PRE14]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ❶ Start with the input.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从输入开始。
- en: ❷ Append the input layer for this column to the list of input layers, which
    will be used in the model definition statement.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将此列的输入层追加到输入层列表中，该列表将在模型定义语句中使用。
- en: ❸ Add the embedding layer.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 添加嵌入层。
- en: ❹ Add the batch normalization layer. By default, samples are normalized individually.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 添加批归一化层。默认情况下，样本是单独归一化的。
- en: ❺ Add the dropout layer and the GRU layer.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 添加dropout层和GRU层。
- en: In this section, we’ve gone through the code that makes up the heart of the
    Keras deep learning model for the streetcar delay prediction problem. We’ve seen
    how the `get_model()` function builds up the layers of the model based on the
    types (continuous, categorical, and text) of the input columns. Because the `get_model()`
    function does not depend on the tabular structure of any particular input dataset,
    this function works with a wide variety of input datasets. Like the rest of the
    code in this example, as long as the columns from the input data set are categorized
    correctly, the code in the `get_model()` function will generate a Keras model
    for a wide variety of tabular structured data.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们探讨了构成街车延误预测问题的Keras深度学习模型核心的代码。我们看到了`get_model()`函数如何根据输入列的类型（连续、分类和文本）构建模型的层。由于`get_model()`函数不依赖于任何特定输入数据集的表格结构，因此此函数可以与各种输入数据集一起使用。像本例中的其他代码一样，只要输入数据集的列被正确分类，`get_model()`函数就会为各种表格结构数据生成Keras模型。
- en: 5.14 Exploring your model
  id: totrans-271
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.14 探索你的模型
- en: 'The model that we have created to predict streetcar delays is relatively simple
    but can still be somewhat overwhelming to understand if you have not encountered
    Keras before. Luckily, you have utilities you can use to examine the model. In
    this section, we will review three utilities that you can use to explore your
    model: `model.summary` `(), plot_model` `,` and TensorBoard.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建的用于预测街车延误的模型相对简单，但如果之前没有遇到过Keras，理解起来可能仍然有些令人困惑。幸运的是，你可以使用一些工具来检查模型。在本节中，我们将回顾三个你可以用来探索模型的工具：`model.summary`
    `()`、`plot_model` `()`和TensorBoard。
- en: The `model.summary()` API lists each of the layers in the model, its output
    shape, the number of parameters, and the layer that is fed into it. The snippet
    of `model .summary()` output in figure 5.23 shows the input layers daym, year,
    Route, and hour. You can see how daym is connected to embedding_1, which is in
    turn connected to batch_normalization_1, which is connected to flatten_1.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '`model.summary()` API 列出了模型中的每一层，其输出形状、参数数量以及输入到其中的层。图 5.23 中的 `model.summary()`
    输出片段显示了输入层 daym、year、Route 和 hour。你可以看到 daym 如何连接到 embedding_1，而 embedding_1 又连接到
    batch_normalization_1，batch_normalization_1 再连接到 flatten_1。'
- en: '![CH05_F23_Ryan](../Images/CH05_F23_Ryan.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F23_Ryan](../Images/CH05_F23_Ryan.png)'
- en: Figure 5.23 model.summary() output
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.23 `model.summary()` 输出
- en: When you initially create a Keras model, the output of `model.summary` `()`
    can really help you understand how the layers are connected and validate your
    assumptions about how the layers are related.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 当你最初创建一个 Keras 模型时，`model.summary()` 的输出可以真正帮助你理解层的连接方式，并验证你对层之间关系的假设。
- en: If you want a graphical perspective of how the layers of the Keras model are
    related, you can use the `plot_model` function ([https://keras.io/visualization](https://keras.io/visualization/)).
    `model.summary()` produces information about the model in tabular format; the
    file generated by `plot_ model` illustrates the same information graphically.
    `model.summary()` is easier to use. Because `plot_model` is dependent on the Graphviz
    package (a Python implementation of the Graphviz [[https://www.graphviz.org](https://www.graphviz.org)
    ] visualization software), it can take some work to get `plot_model` working in
    a new environment, but the effort pays off if you need an accessible way to explain
    your model to a wider audience.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要一个关于 Keras 模型层之间关系的图形视角，可以使用 `plot_model` 函数 ([https://keras.io/visualization](https://keras.io/visualization/))。`model.summary()`
    以表格格式生成有关模型的信息；由 `plot_model` 生成的文件以图形方式说明了相同的信息。`model.summary()` 更容易使用。因为 `plot_model`
    依赖于 Graphviz 软件包（Graphviz [[https://www.graphviz.org](https://www.graphviz.org)
    ] 可视化软件的 Python 实现），在新的环境中使 `plot_model` 工作可能需要一些工作，但如果需要一种向更广泛的受众解释你的模型的方法，这种努力是值得的。
- en: 'Here is what I needed to do to get `plot_model` to work in my Windows 10 environment:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的 Windows 10 环境中使 `plot_model` 工作所需进行的操作如下：
- en: '[PRE15]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: When I completed these Python library updates, I downloaded and installed the
    Graphviz package ([https://graphviz.gitlab.io/download](https://graphviz.gitlab.io/download/))
    in Windows. Finally, to get `plot_model` to work in Windows, I had to update the
    `PATH` environment variable to explicitly include the bin directory in the install
    path for Graphviz.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 当我完成这些 Python 库更新后，我在 Windows 中下载并安装了 Graphviz 软件包 ([https://graphviz.gitlab.io/download](https://graphviz.gitlab.io/download/))。最后，为了在
    Windows 中使 `plot_model` 工作，我必须更新 `PATH` 环境变量，以显式包含 Graphviz 安装路径中的 bin 目录。
- en: The following listing shows the code in the streetcar_model_training notebook
    that invokes `plot_model`.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的列表显示了 streetcar_model_training 笔记本中调用 `plot_model` 的代码。
- en: Listing 5.10 Code to invoke plot_model
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.10 调用 plot_model 的代码
- en: '[PRE16]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ❶ Check whether the save_model_plot switch is set in the streetcar model training
    config file.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 检查在街车模型训练配置文件中是否设置了 save_model_plot 开关。
- en: ❷ If so, set the filename and path where the model plot will be saved.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 如果设置了，请设置模型图将保存的文件名和路径。
- en: ❸ Call plot_model with the model object and the fully qualified filename as
    parameters.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 使用模型对象和完全限定的文件名作为参数调用 `plot_model`。
- en: 'Figure 5.24 and 5.25 show the output of `plot_model` for the streetcar delay
    prediction model. The start of the layers for each column is highlighted with
    a number:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.24 和 5.25 显示了街车延迟预测模型的 `plot_model` 输出。每个列的层开始处用数字突出显示：
- en: Direction
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 方向
- en: Hour
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 小时
- en: Year
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 年
- en: Route
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 路线
- en: Month
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 月
- en: Day of month
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 月份的日
- en: Day
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 日
- en: '![CH05_F24_Ryan](../Images/CH05_F24_Ryan.png)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F24_Ryan](../Images/CH05_F24_Ryan.png)'
- en: Figure 5.24 Output of plot_model showing the layers in the model (top portion)
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.24 `plot_model` 输出显示了模型中的层（顶部部分）
- en: '![CH05_F25_Ryan](../Images/CH05_F25_Ryan.png)'
  id: totrans-297
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F25_Ryan](../Images/CH05_F25_Ryan.png)'
- en: Figure 5.25 Output of plot_model showing the layers in the model (bottom portion)
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.25 `plot_model` 输出显示了模型中的层（底部部分）
- en: Figure 5.26 shows a closeup of `plot_model` output for the day column.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.26 显示了 `plot_model` 对日列输出的近距离视图。
- en: In addition to `model` `.summary()` and `plot_model,` you can use the TensorBoard
    utility to examine the characteristics of a trained model. TensorBoard ([https://www.
    tensorflow.org/tensorboard/get_started](https://www.tensorflow.org/tensorboard/get_started))
    is a tool provided with TensorFlow that allows you to graphically track metrics
    such as loss and accuracy, and to generate a diagram of the model graph.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 除了`model` `.summary()` 和 `plot_model`，您还可以使用TensorBoard实用程序来检查训练模型的特性。TensorBoard
    ([https://www.tensorflow.org/tensorboard/get_started](https://www.tensorflow.org/tensorboard/get_started))
    是TensorFlow提供的一个工具，它允许您图形化跟踪指标，如损失和准确率，并生成模型图的图表。
- en: '![CH05_F26_Ryan](../Images/CH05_F26_Ryan.png)'
  id: totrans-301
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F26_Ryan](../Images/CH05_F26_Ryan.png)'
- en: Figure 5.26 Closeup of the layers for the day column
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.26 天数列层的特写
- en: 'To use TensorBoard with the streetcar delay prediction model, follow these
    steps:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用TensorBoard与电车延误预测模型一起使用，请按照以下步骤操作：
- en: 'Import the required libraries:'
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的库：
- en: '[PRE17]'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Define a callback for TensorBoard that includes the path for TensorBoard logs,
    as shown in this snippet from the `set_early_stop` function in the streetcar_
    model_training notebook.
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个TensorBoard回调，包括TensorBoard日志的路径，如从电车_模型训练笔记本中的`set_early_stop`函数此片段所示。
- en: Listing 5.11 Code to define callbacks
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 列表5.11 定义回调的代码
- en: '[PRE18]'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ❶ If the tensorboard_callback parameter is set to True in the streetcar_model_training
    config file, define a callback for TensorBoard.
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 如果在电车_model_training配置文件中将tensorboard_callback参数设置为True，则定义一个TensorBoard回调。
- en: ❷ Define a log file path, using the current date.
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 定义一个使用当前日期的日志文件路径。
- en: ❸ Define the tensorboard callback with the log directory path as a parameter.
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❸ 使用日志目录路径作为参数定义tensorboard回调。
- en: ❹ Add the tensorboard callback to the overall list of callbacks. Note that the
    tensorboard callback will be invoked only if early_stop is True.
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❹ 将tensorboard回调添加到整体回调列表中。请注意，只有当early_stop为True时，tensorboard回调才会被调用。
- en: Train the model with `early_stop` set to `True` so that the callback list (including
    the TensorBoard callback) is included as a parameter.
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型训练时`early_stop`设置为`True`，以便将回调列表（包括TensorBoard回调）作为参数包含在内。
- en: When you have trained a model with a TensorBoard callback defined, you can start
    TensorBoard with the following command in the terminal, as the next listing shows.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 当您使用已定义TensorBoard回调的训练模型时，您可以在终端中使用以下命令启动TensorBoard，如下所示。
- en: Listing 5.12 Commands to invoke TensorBoard
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.12 调用TensorBoard的命令
- en: '[PRE19]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: ❶ Command to start TensorBoard. The logdir value corresponds with the directory
    set in the definition of the TensorBoard callback.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 启动TensorBoard的命令。logdir值与TensorBoard回调定义中设置的目录相对应。
- en: ❷ The command returns the URL to use to launch TensorBoard for this training
    run.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 命令返回用于启动此训练运行的TensorBoard的URL。
- en: Now if you open the URL returned by the TensorBoard command in your browser,
    you will see the TensorBoard interface. Figure 5.27 shows TensorBoard with the
    accuracy results by epoch for a training run of the streetcar delay prediction
    model.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 现在如果您在浏览器中打开TensorBoard命令返回的URL，您将看到TensorBoard界面。图5.27显示了TensorBoard，其中包含了针对电车延误预测模型训练运行的每个epoch的准确率结果。
- en: '![CH05_F27_Ryan](../Images/CH05_F27_Ryan.png)'
  id: totrans-320
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F27_Ryan](../Images/CH05_F27_Ryan.png)'
- en: Figure 5.27 TensorBoard showing model accuracy
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.27 显示模型准确率的TensorBoard
- en: 'In this section, you’ve seen three options for getting information about your
    model: `model` `.summary()` , `plot_model` , and TensorBoard. TensorBoard in particular
    has a rich set of features for exploring your model. You can get a detailed description
    of the many visualization options for TensorBoard in the TensorFlow documentation
    ([https://www.tensorflow.org/tensorboard/get_started](https://www.tensorflow.org/tensorboard/get_started)).'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您已经看到了获取模型信息的三种选项：`model` `.summary()`，`plot_model` 和TensorBoard。特别是TensorBoard具有丰富的功能，用于探索您的模型。您可以在TensorFlow文档中找到TensorBoard的许多可视化选项的详细描述（[https://www.tensorflow.org/tensorboard/get_started](https://www.tensorflow.org/tensorboard/get_started)）。
- en: 5.15 Model parameters
  id: totrans-323
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.15 模型参数
- en: The code includes a set of parameters that control the operation of the model
    and its training process. Figure 5.28 summarizes the valid values and purposes
    of these parameters. A detailed description of the standard parameters (including
    learning rate, loss function, activation function, batch size, and number of epochs)
    is beyond the scope of this book. You can find a succinct summary of the key hyperparameters
    at [http://mng.bz/Ov8P](http://mng.bz/Ov8P).
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 代码包括一组控制模型及其训练过程的参数。图5.28总结了这些参数的有效值和用途。关于标准参数（包括学习率、损失函数、激活函数、批量大小和epoch数量）的详细描述超出了本书的范围。你可以在[http://mng.bz/Ov8P](http://mng.bz/Ov8P)找到关键超参数的简洁总结。
- en: You can use the parameters listed in figure 5.28 to adjust the behavior of the
    model. If you are adapting this model to a different dataset, you may want to
    begin with a smaller learning rate until you get an idea of whether the model
    is converging on a good result. You will also want to reduce the number of epochs
    for your first few iterations of training the model on a new dataset until you
    get an idea of how long it takes for an epoch to complete on your dataset in your
    training environment.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用图5.28中列出的参数来调整模型的行为。如果你正在将此模型适应不同的数据集，你可能想要从较小的学习率开始，直到你对模型是否收敛到良好的结果有一个概念。你还将想要减少在新的数据集上训练模型的前几次迭代的epoch数量，直到你对在训练环境中完成一个epoch所需的时间有一个概念。
- en: The `output_activation` parameter controls whether the model predicts a category
    (such as streetcar trip delayed/streetcar trip not delayed) or a continuous value
    (such as “streetcar trip delayed by 5 minutes”). Given the size of the input dataset
    for streetcar delays, I chose a category prediction for the model. But if you
    adapt this model for a different dataset, as described in chapter 9, you may decide
    to use a continuous prediction, and you can adjust the `output_activation` parameter
    to a value for a continuous prediction, such as linear.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: '`output_activation`参数控制模型是预测一个类别（如电车行程延误/电车行程未延误）还是连续值（如“电车行程延误5分钟”）。考虑到电车延误输入数据集的大小，我选择了类别预测模型。但如果你根据第9章的描述将此模型适应不同的数据集，你可能决定使用连续预测，并且你可以调整`output_activation`参数到一个连续预测的值，例如线性。'
- en: '![CH05_F28_Ryan](../Images/CH05_F28_Ryan.png)'
  id: totrans-327
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F28_Ryan](../Images/CH05_F28_Ryan.png)'
- en: Figure 5.28 Parameters you can set in the code to control the model and its
    training
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.28 你可以在代码中设置的参数以控制模型及其训练
- en: These parameters are defined in the config file streetcar_model_training_config.yml.
    Chapter 3 introduced config files with Python as a way to keep hardcoded values
    out of your code and to make adjusting parameters faster and less error-prone.
    The excellent article at [http://mng.bz/wpBa](http://mng.bz/wpBa) has a good description
    of the value of config files.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 这些参数在配置文件`streetcar_model_training_config.yml`中定义。第3章介绍了使用Python作为配置文件的方式，以将硬编码的值从代码中排除，并使调整参数更快、更少出错。在[http://mng.bz/wpBa](http://mng.bz/wpBa)的出色文章中对配置文件的价值有很好的描述。
- en: 'You would need to change the parameters listed in figure 5.28 rarely, if at
    all, when you are going through training iterations. Here’s what these parameters
    control:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行训练迭代时，你很少需要更改图5.28中列出的参数。以下是这些参数控制的内容：
- en: '*Learning rate* controls the magnitude of changes to the weights per iteration
    during training of a model. If the learning rate is too high, you can end up skipping
    the optimal weights, and if it’s too low, progress toward the optimal weights
    can be extremely slow. The learning rate value that is originally set in the code
    should be adequate, but you can adjust this value to see how it affects the progress
    of training of the model.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*学习率*控制模型训练过程中每迭代权重变化的幅度。如果学习率过高，你可能会跳过最优权重，如果过低，则向最优权重的进展可能非常缓慢。代码中最初设置的学习率值应该是足够的，但你也可以调整此值以查看它如何影响模型的训练进度。'
- en: '*Dropout rate* controls the proportion of the network that is omitted in training
    iterations. As we mentioned in section 5.11, with dropout rotating, random subsets
    of nodes in the network are ignored in forward and backward passes through the
    network to reduce overfitting.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*辍学率*控制了在训练迭代中网络中被忽略的部分比例。正如我们在第5.11节中提到的，通过dropout旋转，网络中的随机节点子集在网络的正向和反向传播过程中被忽略，以减少过拟合。'
- en: '*L2_lambda* controls regularization of the GRU RNN layer. This parameter affects
    only text input columns. Regularization constrains the weights in the model to
    reduce overfitting. By forcing down the size of the weights, regularization prevents
    the model from being influenced too much by particular characteristics of the
    training set. You can think of regularization as making the model more conservative
    ([https://arxiv.org/ftp/arxiv/papers/2003/2003.05182.pdf](https://arxiv.org/ftp/arxiv/papers/2003/2003.05182.pdf))
    or simpler.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*L2_lambda*控制GRU RNN层的正则化。此参数仅影响文本输入列。正则化限制了模型中的权重以减少过拟合。通过降低权重的大小，正则化防止模型过多地受到训练集特定特征的影响。您可以将正则化视为使模型更加保守([https://arxiv.org/ftp/arxiv/papers/2003/2003.05182.pdf](https://arxiv.org/ftp/arxiv/papers/2003/2003.05182.pdf))或更简单。'
- en: '*Loss function* is the function that is optimized by the model. The goal of
    the model is to optimize this function to lead to the best predictions from the
    model. You can see a comprehensive description of the choices for loss functions
    available with Keras at [http://mng.bz/qNM6](http://mng.bz/qNM6). The streetcar
    delay model predicts a binary choice (whether or not there will be a delay on
    a particular trip), so `binary_crossentropy` is the default choice for the `loss`
    function.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*损失函数*是模型优化的函数。模型的目标是优化此函数以从模型中获得最佳预测。您可以在[Keras中可用的损失函数选择](http://mng.bz/qNM6)的全面描述中看到。街车延误模型预测二元选择（是否会在特定行程中延误），因此`binary_crossentropy`是`loss`函数的默认选择。'
- en: '*Output activation* is the function in the final layer of the model that generates
    the final output. The default setting for this value, `hard_sigmoid` , will generate
    output between `0` and `1`.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*输出激活*是模型最后一层中生成最终输出的函数。此值的默认设置`hard_sigmoid`将在`0`和`1`之间生成输出。'
- en: '*Batch size* is the number of records processed before the model is updated.
    You should not need to update this value.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*批量大小*是指在模型更新之前处理的记录数。您通常不需要更新此值。'
- en: '*Epochs* is the number of complete passes through the training sample. You
    can adjust this value, starting with a small value to get initial results and
    then increasing the value if you see better results with a larger number of epochs.
    Depending on how long it takes to run a single epoch, you may need to balance
    the additional model performance from more epochs against the time taken to run
    more epochs.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Epochs*是通过训练样本的完整遍历次数。您可以调整此值，从较小的值开始以获得初始结果，然后在看到更多epoch数时获得更好的结果。根据运行单个epoch所需的时间，您可能需要平衡更多epoch带来的额外模型性能与运行更多epoch所需的时间。'
- en: For the two parameters that define the loss function and the output activation
    function, *Deep Learning with Python* contains a useful section ([http://mng.bz/7GX7](http://mng.bz/7GX7))
    that goes into greater detail on the options for these parameters and the kinds
    of problems to which you would apply those options.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 对于定义损失函数和输出激活函数的两个参数，*使用Python进行深度学习*包含一个有用的部分([http://mng.bz/7GX7](http://mng.bz/7GX7))，该部分更详细地介绍了这些参数的选项以及您将应用这些选项的问题类型。
- en: Summary
  id: totrans-339
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: The code that makes up a deep learning model can be deceptively anticlimactic,
    but it is the heart of a complete solution that has a raw dataset coming in one
    end and a deployed trained model coming out the other end.
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构成深度学习模型的代码可能看起来平淡无奇，但它是一个完整解决方案的核心，该方案一端输入原始数据集，另一端输出部署的训练模型。
- en: Before training a deep learning model with a structured dataset, we need to
    confirm that all the columns on which the model will be trained will be available
    at scoring time. If we train the model on data that we won’t have when we want
    to make a prediction with the model, we risk getting overly optimistic training
    performance for the model and ending up with a model that cannot generate useful
    predictions.
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在使用结构化数据集训练深度学习模型之前，我们需要确认模型将要训练的所有列在评分时都将可用。如果我们用我们不会在想要用模型进行预测时拥有的数据进行模型训练，我们可能会得到过于乐观的训练性能，最终得到一个无法生成有用预测的模型。
- en: The Keras deep learning model needs to be trained on the data formatted as a
    list of numpy arrays, so the dataset needs to be transformed from a Pandas dataframe
    to a list of numpy arrays.
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras深度学习模型需要在格式化为numpy数组列表的数据上训练，因此数据集需要从Pandas数据框转换为numpy数组列表。
- en: TensorFlow and Keras began as separate but related projects. Beginning with
    TensorFlow 2.0, Keras has become the official high-level API for TensorFlow, and
    its recommended libraries are packaged as part of TensorFlow.
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow和Keras最初是两个独立但相关的项目。从TensorFlow 2.0开始，Keras已成为TensorFlow的官方高级API，并且其推荐库被打包为TensorFlow的一部分。
- en: The Keras functional API combines ease of use with flexibility and is the Keras
    API that we use for the streetcar delay prediction model.
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras功能API结合了易用性、灵活性和可扩展性，是我们用于电车延误预测模型的Keras API。
- en: 'The layers of the streetcar delay prediction model are generated automatically
    based on the categories of the columns: continuous, categorical, and text.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电车延误预测模型的层是根据列的类别自动生成的：连续型、分类型和文本型。
- en: Embeddings are a powerful concept adapted from the world of natural language
    processing. With embeddings, you associate vectors with non-numeric values such
    as the values in categorical columns. The benefits of using embeddings include
    the ability to manipulate non-numeric values that are analogous to common numeric
    operations, the ability to get unsupervised learning-type categorization on values
    in a categorical range as a byproduct of solving a supervised learning problem,
    and the ability to avoid the drawbacks of one-hot encoding (the other common approach
    to assigning numeric values to non-numeric tokens).
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 嵌入（Embeddings）是从自然语言处理领域借鉴的一个强大概念。使用嵌入，您可以将向量与非数值值（如分类列中的值）关联起来。使用嵌入的好处包括能够操作类似于常见数值操作的数值，能够在解决监督学习问题的过程中作为副产品获得对分类范围内值的无监督学习型分类，以及能够避免独热编码（为非数值标记分配数值值的另一种常见方法）的缺点。
- en: You can use a variety of approaches to explore your Keras deep learning model,
    including `model.summary()` (for a tabular view), `plot_model` (for a graphical
    view), and TensorBoard (for an interactive dashboard).
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以使用多种方法来探索您的Keras深度学习模型，包括`model.summary()`（用于表格视图）、`plot_model`（用于图形视图）和TensorBoard（用于交互式仪表板）。
- en: You control the behavior of the Keras deep learning model and its training process
    through a set of parameters. For the streetcar delay prediction model, these parameters
    are defined in the streetcar_model_training_config.yml config file.
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以通过一组参数来控制Keras深度学习模型及其训练过程。对于电车延误预测模型，这些参数在streetcar_model_training_config.yml配置文件中定义。
