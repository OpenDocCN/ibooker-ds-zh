- en: 7 How do you measure classification models? Accuracy and its friends
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7 如何衡量分类模型？准确率及其朋友
- en: In this chapter
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中
- en: 'types of errors a model can make: false positives and false negatives'
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型可能犯的错误类型：假阳性和假阴性
- en: 'putting these errors in a table: the confusion matrix'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将这些错误放入表格中：混淆矩阵
- en: what are accuracy, recall, precision, F-score, sensitivity, and specificity,
    and how are they used to evaluate models
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确率、召回率、精确率、F分数、敏感性和特异性是什么，以及它们如何用于评估模型
- en: what is the ROC curve, and how does it keep track of sensitivity and specificity
    at the same time
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ROC曲线是什么，它是如何同时跟踪敏感性和特异性的
- en: '![](../Images/7-unnumb-1.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/7-unnumb-1.png)'
- en: This chapter is slightly different from the previous two—it doesn’t focus on
    building classification models; instead, it focuses on evaluating them. For a
    machine learning professional, being able to evaluate the performance of different
    models is as important as being able to train them. We seldom train a single model
    on a dataset; we train several different models and select the one that performs
    best. We also need to make sure models are of good quality before putting them
    in production. The quality of a model is not always trivial to measure, and in
    this chapter, we learn several techniques to evaluate our classification models.
    In chapter 4, we learned how to evaluate regression models, so we can think of
    this chapter as its analog but with classification models.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章与前面两章略有不同——它不专注于构建分类模型；相反，它专注于评估它们。对于机器学习专业人士来说，能够评估不同模型的性能与能够训练它们一样重要。我们很少在数据集上训练单个模型；我们训练几个不同的模型，并选择表现最好的一个。我们还需要确保模型在投入生产前具有良好的质量。模型的质量并不总是容易衡量，在本章中，我们学习了几种评估我们的分类模型的技术。在第4章中，我们学习了如何评估回归模型，因此我们可以将本章视为其类比，但针对的是分类模型。
- en: The simplest way to measure the performance of a classification model is by
    calculating its accuracy. However, we’ll see that accuracy doesn’t paint the whole
    picture, because some models exhibit great accuracy but are not good models anyway.
    To fix this, we’ll define some useful metrics, such as precision and recall. Then
    we’ll combine them into a new, more powerful metric called the F-score. These
    metrics are widely used by data scientists to evaluate their models. However,
    in other disciplines, such as medicine, other similar metrics are used, such as
    sensitivity and specificity. Using these last two metrics, we’ll be able to build
    a curve called the receiver operating characteristic (ROC) curve. The ROC curve
    is a simple plot that gives us great insights into our models.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 测量分类模型性能的最简单方法是通过计算其准确率。然而，我们将看到准确率并不能描绘出整个画面，因为一些模型虽然准确率很高，但本质上并不好。为了解决这个问题，我们将定义一些有用的指标，例如精确率和召回率。然后我们将它们结合成一个新且更强大的指标，称为F分数。这些指标被数据科学家广泛用于评估他们的模型。然而，在其他学科，如医学中，使用其他类似的指标，例如敏感性和特异性。使用这两个最后的指标，我们将能够构建一个称为接收者操作特征（ROC）曲线的曲线。ROC曲线是一个简单的图表，它为我们提供了对模型的深刻见解。
- en: 'Accuracy: How often is my model correct?'
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准确率：我的模型有多正确？
- en: In this section, we discuss accuracy, the simplest and most common measure of
    classification models. The accuracy of a model is the percentage of times that
    a model is correct. In other words, it is the ratio between the number of correctly
    predicted data points and the total number of data points. For example, if we
    evaluate a model on a test dataset of 1,000 samples, and the model predicted the
    correct label of the samples 875 times, then this model has an accuracy of 875/1000
    = 0.875, or 87.5%.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论准确率，这是分类模型最简单和最常用的度量。模型的准确率是指模型正确的时间百分比。换句话说，它是正确预测的数据点数与总数据点数的比率。例如，如果我们对一个包含1,000个样本的测试数据集进行模型评估，并且模型正确预测了样本的标签875次，那么这个模型的准确率为875/1000
    = 0.875，或87.5%。
- en: Accuracy is the most common way to evaluate a classification model, and we should
    always use it. However, sometimes accuracy doesn’t fully describe the performance
    of the model, as we’ll see shortly. Let’s begin by looking at two examples that
    we’ll study throughout this chapter.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率是评估分类模型最常见的方法，我们应该始终使用它。然而，有时准确率并不能完全描述模型的性能，正如我们很快将看到的。让我们首先看看本章我们将研究的两个例子。
- en: 'Two examples of models: Coronavirus and spam email'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 两个模型的例子：冠状病毒和垃圾邮件
- en: In this chapter, we use our metrics to evaluate several models on two datasets.
    The first dataset is a medical dataset of patients, where some of them have been
    diagnosed with coronavirus. The second dataset is a dataset of emails that have
    been labeled as spam or not spam. As we learned in chapter 1, *spam* is the term
    used for junk email, and *ham* is the term used for email that is not spam. In
    chapter 8, we’ll study a dataset like this in much more detail, when we learn
    the naive Bayes algorithm. In this chapter, we aren’t building models. Instead,
    we use the models as black boxes and evaluate them based on how many of the data
    points they predict correctly or incorrectly. Both datasets are completely imaginary.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用我们的指标评估了两个数据集上的几个模型。第一个数据集是患者医疗数据集，其中一些患者已被诊断为冠状病毒。第二个数据集是电子邮件数据集，这些电子邮件已被标记为垃圾邮件或非垃圾邮件。正如我们在第一章中学到的，*垃圾邮件*是指垃圾邮件，而*非垃圾邮件*是指非垃圾邮件。在第八章中，当我们学习朴素贝叶斯算法时，我们将更详细地研究这样的数据集。在本章中，我们不是构建模型，而是将模型作为黑盒使用，并根据它们预测正确或错误的数据点数量来评估它们。这两个数据集都是完全虚构的。
- en: 'Medical dataset: A set of patients diagnosed with coronavirus'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 医疗数据集：一组被诊断为冠状病毒的病人
- en: Our first dataset is a medical dataset with 1,000 patients. Out of them, 10
    have been diagnosed with coronavirus, and the remaining 990 have been diagnosed
    as healthy. Thus, the labels in this dataset are “sick” or “healthy,” corresponding
    to the diagnosis. The goal of a model would be to predict the diagnosis based
    on the features of each patient.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一组数据集是一个包含1,000名患者的医疗数据集。其中，10人被诊断为冠状病毒，其余990人被诊断为健康。因此，这个数据集中的标签是“生病”或“健康”，对应于诊断。模型的目标是根据每个患者的特征预测诊断。
- en: 'Email dataset: A set of emails labeled spam or ham'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 电子邮件数据集：一组被标记为垃圾邮件或非垃圾邮件的电子邮件
- en: Our second dataset is a dataset of 100 emails. Out of them, 40 are spam, and
    the remaining 60 are ham. The labels in this dataset are “spam” and “ham,” and
    the goal of a model would be to predict the label based on the features of the
    email.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第二个数据集是一个包含100封电子邮件的数据集。其中，40封是垃圾邮件，其余60封是非垃圾邮件。这个数据集中的标签是“垃圾邮件”和“非垃圾邮件”，模型的目标是根据电子邮件的特征预测标签。
- en: A super effective yet super useless model
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 一个超级有效却又超级无用的模型
- en: Accuracy is a very useful metric, but does it paint the whole picture of the
    model? It doesn’t, and we’ll illustrate this with an example. For now, let’s focus
    on the coronavirus dataset. We’ll come back to the email dataset in the next section.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率是一个非常有用的指标，但它能否描绘出模型的完整图景呢？答案是否定的，我们将通过一个例子来阐述这一点。目前，让我们专注于冠状病毒数据集。我们将在下一节回到电子邮件数据集。
- en: 'Suppose a data scientist tells us the following: “I have developed a test for
    coronavirus that takes 10 seconds to run, doesn’t require any examinations, and
    has an accuracy of 99%!” Should we be excited or skeptical? We’d probably be skeptical.
    Why? We’ll soon see that calculating a model’s accuracy sometimes isn’t enough.
    Our model may have an accuracy of 99% and yet be completely useless.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 假设一位数据科学家告诉我们以下内容：“我开发了一种冠状病毒检测方法，只需10秒钟即可运行，不需要任何检查，并且准确率为99%！”我们应该感到兴奋还是怀疑？我们可能会怀疑。为什么？我们很快就会看到，计算模型的准确率有时并不足够。我们的模型可能准确率为99%，但可能完全无用。
- en: Can we think of a completely useless model that predicts coronavirus in our
    dataset, yet is correct 99% of the time? Recall that our dataset contains 1,000
    patients, and out of those, 10 have coronavirus. Feel free to put this book down
    for a moment and think of how to build a model that detects coronavirus and that
    is correct 99% of the time for this dataset.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能否想象一个完全无用的模型，该模型可以预测我们数据集中的冠状病毒，并且在这个数据集中99%的时间都是正确的？回想一下，我们的数据集包含1,000名患者，其中10人有冠状病毒。请随意放下这本书，思考一下如何构建一个可以检测冠状病毒的模型，并且在这个数据集中99%的时间都是正确的。
- en: 'It could be a model like this: simply diagnose every patient as healthy. That’s
    a simple model, but it’s still a model; it’s the model that predicts everything
    as one class.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是一个这样的模型：简单地将每个患者诊断为健康。这是一个简单的模型，但仍然是一个模型；这是一个预测所有事物属于一个类别的模型。
- en: What is the accuracy of this model? Well, out of 1,000 tries, it’s incorrect
    10 times and correct 990 times. This gives an accuracy of 99%, just like we promised.
    However, the model equates to telling everyone that they are healthy in the middle
    of a global pandemic, which is terrible!
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型的准确率是多少呢？嗯，在1,000次尝试中，它有10次错误，990次正确。这给出了99%的准确率，正如我们承诺的那样。然而，这个模型等同于在一场全球大流行期间告诉每个人他们都健康，这是非常糟糕的！
- en: What is the problem with our model, then? The problem is that errors are not
    created equal, and some mistakes are much more expensive than others, as we’ll
    see in the next section.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们模型的问题是什么？问题是错误并不平等，有些错误比其他错误代价更高，正如我们将在下一节中看到的。
- en: How to fix the accuracy problem? Defining different types of errors and how
    to measure them
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何解决准确率问题？定义不同类型的错误以及如何衡量它们
- en: In the previous section, we built a useless model that had great accuracy. In
    this section, we study what went wrong. Namely, we study what the problem was
    with calculating accuracy in that model, and we introduce some slightly different
    metrics that will give us better evaluations of this model.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们构建了一个具有高准确率的无用模型。在本节中，我们研究出了什么问题。也就是说，我们研究在那个模型中计算准确率的问题，并介绍了一些略微不同的指标，这些指标将给我们提供对这个模型更好的评估。
- en: The first thing we need to study is types of errors. In the next section, we
    see that some errors are more critical than others. Then in the sections “Storing
    the correctly and incorrectly
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要研究的第一件事是错误的类型。在下一节中，我们看到某些错误比其他错误更关键。然后在“存储正确和错误分类点”到“召回率、精确率或F分数”的章节中，我们学习了不同的指标，这些指标比准确率更能捕捉这些关键错误。
- en: classified points in a table” to “Recall, precision, or F-scores,” we learn
    different metrics that are more equipped to catch these critical errors than accuracy.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: “将分类点放入表格”到“召回率、精确率或F分数”，我们学习了不同的指标，这些指标比准确率更能捕捉这些关键错误。
- en: 'False positives and false negatives: Which one is worse?'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 假阳性和假阴性：哪一个更糟糕？
- en: 'In many cases, the total number of errors doesn’t tell us everything about
    the model’s performance, and we need to dig in deeper and identify certain types
    of errors in different ways. In this section, we see two types of errors. What
    are the two types of errors that the coronavirus model can make? It can diagnose
    a healthy person as sick or a sick person as healthy. In our model, we label the
    sick patients as positive, by convention. The two error types are called false
    positives and negatives, as follows:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，错误总数并不能告诉我们关于模型性能的所有信息，我们需要深入挖掘并以不同的方式识别不同类型的错误。在本节中，我们看到两种错误类型。冠状病毒模型可能犯的两种错误类型是什么？它可以诊断一个健康的人为生病，或者一个生病的人为健康。在我们的模型中，我们按照惯例将生病患者标记为正例。这两种错误类型被称为假阳性和假阴性，如下所示：
- en: '**False positive**: a healthy person who is incorrectly diagnosed as sick'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阳性**：被错误地诊断为生病的人'
- en: '**False negative**: a sick person who is incorrectly diagnosed as healthy'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阴性**：被错误地诊断为健康的人'
- en: 'In the general setting, a false positive is a data point that has a negative
    label, but the model falsely classifies it as positive. A false negative is a
    data point that has a positive label, but the model falsely classified it as negative.
    Naturally, the cases that are correctly diagnosed also have names, as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在一般设置中，一个假阳性是一个具有负标签的数据点，但模型错误地将其分类为正类。一个假阴性是一个具有正标签的数据点，但模型错误地将其分类为负类。自然地，正确诊断的案例也有名称，如下所示：
- en: '**True positive**: a sick person who is diagnosed as sick'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真阳性**：被诊断为生病的人'
- en: '**True negative**: a healthy person who is diagnosed as healthy'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真阴性**：被诊断为健康的人'
- en: In the general setting, a true positive is a data point that has a positive
    label that is correctly classified as positive, and a true negative is one with
    a negative label that is correctly classified as negative.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在一般设置中，一个真阳性是一个具有正标签的数据点，它被正确分类为正类，一个真阴性是一个具有负标签的数据点，它被正确分类为负类。
- en: 'Now, let’s look at the email dataset. Let’s say we have a model that predicts
    whether each email is spam or ham. We consider the positives to be the spam emails.
    Therefore, our two types of errors follow:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看电子邮件数据集。假设我们有一个模型，它预测每封邮件是垃圾邮件还是正常邮件。我们将垃圾邮件视为正例。因此，我们的两种错误类型如下：
- en: '**False positive**: a ham email that is incorrectly classified as spam'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阳性**：被错误地分类为垃圾邮件的正常邮件'
- en: '**False negative**: a spam email that is incorrectly classified as ham'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阴性**：被错误地分类为垃圾邮件的正常邮件'
- en: 'And the correctly classified emails are the following:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 正确分类的邮件如下：
- en: '**True positive**: a spam email that is correctly classified as spam'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真阳性**：被正确分类为垃圾邮件的垃圾邮件'
- en: '**True negative**: a ham email that is correctly classified as ham'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真阴性**：被正确分类为正常邮件的正常邮件'
- en: 'Figure 7.1 shows a graphical representation of the models, in which the vertical
    line is the boundary, the zone to the left of the line is the negative zone, and
    the zone to the right is the positive zone. The triangles are the points with
    positive labels, and the circles are the points with negative labels. The four
    quantities defined above are the following:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1展示了模型的图形表示，其中垂直线是边界，线左侧的区域是负区域，线右侧的区域是正区域。三角形是带有正标签的点，圆圈是带有负标签的点。上面定义的四个量如下：
- en: 'Triangle to the right of the line: true positive'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线右侧的三角形：真阳性
- en: 'Triangle to the left of the line: false negative'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线左侧的三角形：假阴性
- en: 'Circle to the right of the line: false positive'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线右侧的圆圈：假阳性
- en: 'Circle to the left of the line: true negative'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线左侧的圆圈：真阴性
- en: '![](../Images/7-1.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图7-1](../Images/7-1.png)'
- en: Figure 7.1 Examples of two models that are widely used in real life and that
    we’ll use throughout this chapter. On the left, a coronavirus model where the
    people are diagnosed as healthy or sick. On the right, a spam-detection model
    where the emails are classified as spam or ham. For each model, we have highlighted
    some of their errors and separated them as false positives and false negatives.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1展示了两个在现实生活中广泛使用且我们将在本章中使用的模型示例。在左边，是一个冠状病毒模型，其中人们被诊断为健康或生病。在右边，是一个垃圾邮件检测模型，其中电子邮件被分类为垃圾邮件或正常邮件。对于每个模型，我们都突出了一些错误，并将它们分为假阳性和假阴性。
- en: 'Notice that both models in figure 7.1 produce the following quantities:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到图7.1中的两个模型都产生了以下量：
- en: Three true positives
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 三个真阳性
- en: Four true negatives
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 四个真阴性
- en: One false positive
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个假阳性
- en: Two false negatives
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两个假阴性
- en: To see the difference between the coronavirus model and the spam model, we need
    to analyze which one is worse between the false positives and the false negatives.
    Let’s do this for each model separately.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解冠状病毒模型和垃圾邮件模型之间的区别，我们需要分析在假阳性和假阴性之间哪一个更糟糕。让我们分别对每个模型进行这种分析。
- en: Analyzing false positives and negatives in the coronavirus model
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 分析冠状病毒模型中的假阳性和假阴性
- en: 'Let’s stop and think. In the coronavirus model, which one sounds like a worse
    mistake: a false positive or a false negative? In other words, what is worse:
    to incorrectly diagnose a healthy patient as sick, or a sick patient as healthy?
    Let’s say that when we diagnose a patient as healthy, we send them home with no
    treatment, and that when we diagnose a patient as sick, we send them for more
    tests. Incorrectly diagnosing a healthy person may be a small nuisance, because
    it means a healthy person will have to stay for extra tests. However, incorrectly
    diagnosing a sick person means that a sick person won’t get treatment, their condition
    may worsen, and they may potentially infect many others. Thus, **in the coronavirus
    model, a false negative is much worse than a false positive**.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们停下来思考一下。在冠状病毒模型中，哪一种错误听起来更糟糕：假阳性还是假阴性？换句话说，什么更糟糕：错误地将健康患者诊断为生病，还是将生病患者诊断为健康？让我们假设，当我们诊断患者为健康时，我们会让他们不带治疗回家，而当我们诊断患者为生病时，我们会让他们进行更多测试。错误地诊断健康人可能只是一个小麻烦，因为这意味着健康人将不得不进行额外的测试。然而，错误地诊断生病的人意味着生病的人将得不到治疗，他们的病情可能会恶化，他们可能会潜在地感染许多人。因此，**在冠状病毒模型中，假阴性比假阳性要糟糕得多**。
- en: Analyzing false positives and negatives in the spam email model
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 分析垃圾邮件模型中的假阳性和假阴性
- en: 'Now we’ll do the same analysis on the spam model. In this case, let’s say that
    if our spam classifier classifies an email as spam, then this email is automatically
    deleted. If it classifies it as ham, then the email is sent to our inbox. Which
    one sounds like a worse mistake: a false positive or a false negative? In other
    words, what is worse, to incorrectly classify a ham email as spam and delete it,
    or to incorrectly classify a spam email as ham and send it to the inbox? I think
    we can agree that deleting a good email is much worse than sending a spam email
    to the inbox. The occasional spam email in our inbox can be annoying, but a deleted
    ham email can be a complete disaster! Imagine the sadness we would feel in our
    heart if our grandma sent us a very kind email telling us she baked cookies, and
    our filter deleted it. Therefore, **in the spam email model, a false positive
    is much worse than a false negative**.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将对垃圾邮件模型进行同样的分析。在这种情况下，让我们假设如果我们的垃圾邮件分类器将一封邮件分类为垃圾邮件，那么这封邮件就会被自动删除。如果它将其分类为正常邮件，那么邮件就会被发送到我们的收件箱。哪种错误听起来更糟糕：假阳性还是假阴性？换句话说，将一封正常邮件错误地分类为垃圾邮件并删除它，或者将一封垃圾邮件错误地分类为正常邮件并发送到收件箱，哪种更糟糕？我想我们可以同意，删除一封好邮件比将垃圾邮件发送到收件箱更糟糕。我们收件箱中偶尔出现的垃圾邮件可能会让人烦恼，但删除一封正常邮件可能是一场灾难！想象一下，如果我们的奶奶给我们发了一封非常友好的邮件，告诉我们她烤了饼干，而我们的过滤器删除了它，我们心里会感到多么的悲伤。因此，**在垃圾邮件模型中，假阳性比假阴性要糟糕得多**。
- en: This is where the two models differ. In the coronavirus model, a false negative
    is worse, whereas in the spam email model, a false positive is worse. The problem
    with measuring the accuracy in any of these two models is that the accuracy considers
    both types of errors as equally serious and doesn’t tell them apart.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是两种模型的不同之处。在冠状病毒模型中，假阴性结果更糟糕，而在垃圾邮件模型中，假阳性结果更糟糕。在这两种模型中测量准确性的问题在于，准确性将这两种错误视为同等严重，并且无法区分它们。
- en: In the section “A super effective yet super useless model,” we had an example
    of a model that diagnosed every patient as healthy. This model made only 10 errors
    among 1,000 patients. However, all those 10 were false negatives, which is terrible.
    If those 10 were false positives instead, the model would be much better.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在“一个超级有效但超级无用的模型”这一节中，我们有一个例子，这个模型诊断出每个病人都是健康的。这个模型在1000名病人中只犯了10个错误。然而，这10个都是假阴性，这是非常糟糕的。如果这10个是假阳性，那么这个模型会好得多。
- en: In the following sections, we’ll devise two new metrics, similar to accuracy.
    The first metric helps us deal with models in which false negatives are worse,
    and the second one helps us deal with models in which false positives are worse.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将设计两个新的度量标准，类似于准确性。第一个度量标准帮助我们处理假阴性更糟糕的模型，第二个度量标准帮助我们处理假阳性更糟糕的模型。
- en: 'Storing the correctly and incorrectly classified points in a table: The confusion
    matrix'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 将正确和错误分类的点存储在表格中：混淆矩阵
- en: In the previous subsection, we learned about false positives, false negatives,
    true positives, and true negatives. To keep track of these four entities, we put
    them together in a table aptly named *the confusion matrix.* For binary classification
    models (models that predict two classes), the confusion matrix has two rows and
    two columns. In the rows we write the true labels (in the medical example, this
    is the condition of the person, sick or healthy), and in the columns we write
    the predicted labels (the diagnosis of the person, sick or healthy). The general
    confusion matrix is illustrated in table 7.1, and specific ones for examples of
    models in these two datasets are shown in tables 7.2 to 7.5\. This is called a
    confusion matrix because it makes it easy to see if the model is confusing two
    classes, namely the positive (sick) and the negative (healthy).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的子节中，我们学习了假阳性、假阴性、真阳性和真阴性。为了跟踪这四个实体，我们将它们放在一起，组成一个恰如其分的表格，称为*混淆矩阵*。对于二元分类模型（预测两个类别的模型），混淆矩阵有两行两列。在行中我们写上真实标签（在医疗例子中，这是人的状况，生病或健康），而在列中我们写上预测标签（人的诊断，生病或健康）。一般混淆矩阵如图7.1所示，具体的一个例子是这两个数据集中模型的具体混淆矩阵，如表7.2至7.5所示。这被称为混淆矩阵，因为它使得我们很容易看出模型是否混淆了两个类别，即阳性（生病）和阴性（健康）。
- en: Table 7.1 The confusion matrix helps us count how many times each class is predicted
    correctly and how many times each class is confused with a different class. In
    this matrix, the rows represent the label, and the columns represent the prediction.
    The elements in the diagonal are classified correctly, and the elements off the
    diagonal are not.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 表7.1 混淆矩阵帮助我们计算每个类别被正确预测的次数以及每个类别被错误地与其他类别混淆的次数。在这个矩阵中，行代表标签，列代表预测。对角线上的元素被正确分类，而对角线外的元素没有被正确分类。
- en: '| Person’s condition | Predicted positive | Predicted negative |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| 人的状况 | 预测为阳性 | 预测为阴性 |'
- en: '| Positive | Number of true positives | Number of false negatives |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| 阳性 | 真阳性数量 | 假阴性数量 |'
- en: '| Negative | Number of false positives | Number of true negatives |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 阴性 | 假阳性数量 | 真阴性数量 |'
- en: For our existing model (the one that diagnoses every patient as healthy), which
    from now on we call coronavirus model 1, the confusion matrix is illustrated in
    table 7.2.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们现有的模型（将每个病人都诊断为健康的模型），从现在起我们称之为冠状病毒模型1，其混淆矩阵如图7.2所示。
- en: Table 7.2 The confusion matrix of our coronavirus model helps us dig into our
    model and tell the two types of errors apart. This model makes 10 false negative
    errors (a sick person diagnosed healthy) and zero false positive errors (a healthy
    person diagnosed sick). Notice that the model creates too many false negatives,
    which are the worst type of error in this case, which implies that this model
    is not very good.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 表7.2 我们冠状病毒模型的混淆矩阵帮助我们深入分析模型，区分两种类型的错误。此模型产生了10个假阴性错误（将生病的人诊断为健康），没有假阳性错误（将健康的人诊断为生病）。请注意，模型产生了过多的假阴性，这是在这种情况下最糟糕的错误类型，这表明此模型并不很好。
- en: '| Coronavirus model 1 | Diagnosed sick (predicted positive) | Diagnosed healthy
    (predicted negative) |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 冠状病毒模型1 | 诊断为生病（预测为阳性） | 诊断为健康（预测为阴性） |'
- en: '| Sick (positive) | 0 (number of true positives) | 10 (number of false negatives)
    |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 病人（阳性） | 0（真阳性数量） | 10（假阴性数量） |'
- en: '| Healthy (negative) | 0 (number of false positives) | 990 (number of true
    negatives) |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 健康（阴性） | 0（假阳性数量） | 990（真阴性数量） |'
- en: For problems with more classes, we have a larger confusion matrix. For example,
    if our model classifies images into aardvarks, birds, cats, and dogs, then our
    confusion matrix is a four-by-four matrix, where along the rows we have the true
    labels (the type of animal), and along the columns we have the predicted labels
    (the type of animal that the model predicted). This confusion matrix also has
    the property that the correctly classified points are counted in the diagonal,
    and the incorrectly classified are counted off the diagonal.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 对于有更多类别的复杂问题，我们有一个更大的混淆矩阵。例如，如果我们的模型将图像分类为河马、鸟类、猫和狗，那么我们的混淆矩阵是一个四阶矩阵，其中行代表真实标签（动物的类型），列代表预测标签（模型预测的动物类型）。这个混淆矩阵也具有这样的性质，即正确分类的点被计在对角线上，而错误分类的点被计在对角线外。
- en: 'Recall: Among the positive examples, how many did we correctly classify?'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 回忆：在所有阳性例子中，我们正确分类了多少个？
- en: Now that we know the two types of errors, in this section, we learn a metric
    that will give coronavirus model 1 a much lower score. We have established that
    the problem with this model is that it gives us too many false negatives, namely,
    that it diagnoses too many sick people as healthy.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了两种类型的错误，在本节中，我们将学习一个将给冠状病毒模型1带来更低分数的指标。我们已经确定，这个模型的问题在于它给我们太多的假阴性，即它将太多的病人诊断为健康。
- en: Let’s assume, for a moment, that we don’t mind false positives at all. Say that
    if the model diagnoses a healthy person as sick, the person may need to take an
    extra test or quarantine for a little longer, but this is no problem at all. Naturally,
    this is not the case; false positives are also expensive, but for now, let’s pretend
    that they’re not. In this case, we need a metric that replaces accuracy and that
    places importance on finding positive cases and cares less about mistakenly classifying
    negative cases.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们暂时假设我们根本不在乎假阳性。比如说，如果模型将一个健康的人诊断为生病，这个人可能需要额外做一次测试或隔离一段时间，但这根本不是问题。当然，这并不是实际情况；假阳性也是昂贵的，但现在让我们假装它们不是问题。在这种情况下，我们需要一个指标来替代准确率，并且这个指标重视找到阳性病例，而对错误地将阴性病例分类则不太关心。
- en: 'To find this metric, we need to evaluate what our goal is. If we want to cure
    coronavirus, then what we really want is the following: out of all the sick people
    in the world, we want to find them all. It doesn’t matter if we accidentally find
    others who aren’t sick, as long as we find all the sick ones. This is the key.
    This new metric, called *recall*, measures precisely that: out of the sick people,
    how many did our model diagnose correctly?'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 要找到这个指标，我们需要评估我们的目标是什么。如果我们想治愈冠状病毒，那么我们真正想要的是以下内容：在世界上所有生病的人中，我们希望找到他们所有人。我们偶然找到不生病的人没关系，只要我们找到所有生病的人。这是关键。这个新指标，称为*召回率*，精确地衡量了这一点：在生病的人中，我们的模型诊断出多少是正确的？
- en: 'In more general lingo, recall finds the proportion of correct predictions among
    the data points with a positive label. This is the number of true positives, divided
    by the total number of positives. Coronavirus model 1 has a total of 0 true positives
    among 10 positives, so its recall is 0/10 = 0\. Another way to put it is as the
    number of true positives divided by the sum of true positives and false negatives,
    as shown here:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在更一般的术语中，召回率找到具有正标签的数据点中的正确预测比例。这是真阳性的数量除以总正数。冠状病毒模型1在10个正数中有0个真阳性，所以它的召回率是0/10
    = 0。另一种说法是，真阳性数除以真阳性数和假阴性数的总和，如下所示：
- en: '![](../Images/07_01_E01.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/07_01_E01.png)'
- en: In contrast, let’s say we had a second model called coronavirus model 2\. The
    confusion matrix of this model is shown in table 7.3\. This second model made
    more mistakes than the first model—it made 50 total mistakes as opposed to only
    10\. The accuracy of the second model is 950/1000 = 0.95, or 95%. In terms of
    accuracy, the second model is not as good as the first model.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 与此相反，假设我们有一个第二个模型，称为冠状病毒模型2。这个模型的混淆矩阵显示在表7.3中。这个第二个模型比第一个模型犯的错误更多——总共犯了50个错误，而第一个模型只犯了10个。第二个模型的准确率是950/1000
    = 0.95，或者说95%。从准确率来看，第二个模型不如第一个模型好。
- en: However, the second model correctly diagnosed eight out of the 10 sick people
    and 942 out of the 1,000 people. In other words, it has two false negatives and
    48 false positives.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，第二个模型正确诊断了10个生病患者中的8个和1000人中的942个。换句话说，它有两个假阴性和48个假阳性。
- en: Table 7.3 The confusion matrix of our second coronavirus model
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 表7.3 第二个冠状病毒模型的混淆矩阵
- en: '| Coronavirus model 2 | Diagnosed sick | Diagnosed healthy |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 冠状病毒模型2 | 诊断为生病 | 诊断为健康 |'
- en: '| Sick | 8 (true positives) | 2 (false negatives) |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 生病 | 8（真阳性） | 2（假阴性） |'
- en: '| Healthy | 48 (false positives) | 942 (true negatives) |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 健康 | 48（假阳性） | 942（真阴性） |'
- en: 'The recall of this model is the number of true positives (eight sick people
    correctly diagnosed) divided by the total number of positives (10 sick people),
    which is 8/10 = 0.8, or 80%. In terms of recall, the second model is much better.
    Let’s summarize these calculations for clarity as follows:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型的召回率是真阳性数（8个正确诊断的生病患者）除以总正数（10个生病患者），即8/10 = 0.8，或者说80%。从召回率来看，第二个模型要好得多。为了清晰起见，让我们如下总结这些计算：
- en: 'Coronavirus Model 1:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 冠状病毒模型1：
- en: True positives (sick patients diagnosed sick and sent for more tests) = 0
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 真阳性（被诊断为生病并送进行更多测试的生病患者）= 0
- en: False negatives (sick patients diagnosed healthy and sent home) = 10
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 假阴性（被诊断为健康并送回家的生病患者）= 10
- en: Recall = 0/10 = 0%
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率 = 0/10 = 0%
- en: 'Coronavirus Model 2:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 冠状病毒模型2：
- en: True positives (sick patients diagnosed sick and sent for more tests) = 8
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 真阳性（被诊断为生病并送进行更多测试的生病患者）= 8
- en: False negatives (sick patients diagnosed healthy and sent home) = 2
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 假阴性（被诊断为健康并送回家的生病患者）= 2
- en: Recall = 8/10 = 80%
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率 = 8/10 = 80%
- en: Models like the coronavirus model, in which false negatives are much more expensive
    than false positives, are *high recall models*.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在冠状病毒模型这样的模型中，假阴性比假阳性更昂贵，它们是*高召回率模型*。
- en: Now that we have a better metric, could we fool this metric in the same way
    we fooled accuracy? In other words, can we build a model that has total recall?
    Well, get ready for a surprise, because we can. If we build a model that diagnoses
    every patient as sick, this model has a 100% recall. However, this model is terrible,
    too, because although it has zero false negatives, it has too many false positives
    to make it a good model. It seems that we still need more metrics to be able to
    evaluate our models properly.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了更好的指标，我们能否像欺骗准确度那样欺骗这个指标？换句话说，我们能否构建一个具有完全召回率的模型？好吧，准备好惊喜吧，因为我们能。如果我们构建一个将每个病人都诊断为生病的模型，这个模型将有100%的召回率。然而，这个模型也很糟糕，因为它虽然零假阴性，但假阳性太多，以至于它不是一个好的模型。看来我们仍然需要更多的指标来正确评估我们的模型。
- en: 'Precision: Among the examples we classified as positive, how many did we correctly
    classify?'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度：在我们分类为正例的例子中，我们正确分类了多少个？
- en: In the previous section we learned recall, a metric that measures how well our
    model did with false negatives. That metric worked well for the coronavirus model—we’ve
    seen that this model can’t afford to have too many false negatives. In this section,
    we learn about a similar metric, *precision*, which measures how well our model
    does with false positives. We’ll use this metric to evaluate the spam email model,
    because this model can’t afford to have too many false positives.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们学习了召回率，这是一个衡量我们的模型在假阴性方面表现如何的指标。这个指标对冠状病毒模型很有用——我们已经看到这个模型不能承受太多的假阴性。在本节中，我们将学习一个类似的指标，*精确度*，它衡量我们的模型在假阳性方面的表现。我们将使用这个指标来评估垃圾邮件模型，因为这个模型不能承受太多的假阳性。
- en: 'Just as we did with recall, to come up with a metric, we first need to define
    our goal. We want a spam filter that doesn’t delete any ham emails. If instead
    of deleting emails, it sends them to a spam box. Then we need to look into that
    spam box and hope that we do not see a single ham email. Thus, our metric should
    measure precisely that: Among the emails in our spam box, how many were actually
    spam? In other words, out of the emails that are predicted to be spam, how many
    of them are actually spam? This is our metric, and we call it *precision*.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在召回率中所做的那样，为了提出一个指标，我们首先需要定义我们的目标。我们希望有一个不会删除任何正常邮件的垃圾邮件过滤器。如果它不是删除邮件，而是将它们发送到垃圾邮件箱中。那么我们需要查看那个垃圾邮件箱，并希望我们看不到一封正常邮件。因此，我们的指标应该精确地衡量这一点：在我们垃圾邮件箱中的邮件中，有多少实际上是垃圾邮件？换句话说，在预测为垃圾邮件的邮件中，实际上有多少是垃圾邮件？这是我们指标，我们称之为*精确度*。
- en: 'More formally, precision considers only the data points that have been labeled
    positive, and among those, how many are true positives. Because the data points
    that are predicted positive are the union of the true positives and the false
    positives, the formula is the following:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 更正式地说，精确度只考虑被标记为正面的数据点，并在其中考虑有多少是真阳性。因为预测为正面的数据点是真阳性和假阳性的并集，所以公式如下：
- en: '![](../Images/07_01_E02.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/07_01_E02.png)'
- en: Remember that in our dataset of 100 emails, 40 are spam and 60 are ham. Say
    we trained the following two models called spam model 1 and spam model 2\. Their
    confusion matrices are shown in tables 7.4 and 7.5.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，在我们的100封邮件数据集中，有40封是垃圾邮件，60封是正常邮件。假设我们训练了以下两个模型，称为垃圾邮件模型 1 和垃圾邮件模型 2。它们的混淆矩阵分别显示在表7.4和7.5中。
- en: Table 7.4 The confusion matrix of our first spam model
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 表7.4 第一个垃圾邮件模型的混淆矩阵
- en: '| Spam model 1 | Predicted spam | Predicted ham |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 垃圾邮件模型 1 | 预测为垃圾邮件 | 预测为正常邮件 |'
- en: '| Spam | 30 (true positives) | 10 (false negatives) |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 垃圾邮件 | 30 (真阳性) | 10 (假阴性) |'
- en: '| Ham | 5 (false positives) | 55 (true negatives) |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 正常邮件 | 5 (假阳性) | 55 (真阴性) |'
- en: Table 7.5 The confusion matrix of our second spam model
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 表7.5 第二个垃圾邮件模型的混淆矩阵
- en: '| Spam model 2 | Predicted spam | Predicted ham |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 垃圾邮件模型 2 | 预测为垃圾邮件 | 预测为正常邮件 |'
- en: '| Spam | 35 (true positives) | 5 (false negatives) |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 垃圾邮件 | 35 (真阳性) | 5 (假阴性) |'
- en: '| Ham | 10 (false positives) | 50 (true negatives) |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 正常邮件 | 10 (假阳性) | 50 (真阴性) |'
- en: 'In terms of accuracy, it seems that both models are just as good—they both
    make correct predictions 85% of the time (85 correct out of 100 emails). However,
    at first glance, it seems that the first model is better than the second one,
    because the first model deletes only five ham emails, and the second one deletes
    10 of them. Now let’s calculate the precision as follows:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 从准确度来看，似乎这两个模型都相当好——它们都正确预测了85%的时间（100封邮件中有85封正确）。然而，乍一看，第一个模型似乎比第二个模型好，因为第一个模型只删除了五封正常邮件，而第二个模型删除了十封。现在让我们按照以下方式计算精确度：
- en: 'Spam Model 1:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 垃圾邮件模型 1：
- en: True positives (spam emails deleted) = 30
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真阳性（删除的垃圾邮件）= 30
- en: False positives (ham emails deleted) = 5
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假阳性（删除的普通邮件）= 5
- en: Precision = 30/35 = 85.7%
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精确率 = 30/35 = 85.7%
- en: 'Spam Model 2:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 垃圾邮件模型2：
- en: True positives (spam emails deleted) = 35
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真阳性（删除的垃圾邮件）= 35
- en: False positives (ham emails deleted) = 10
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假阳性（删除的普通邮件）= 10
- en: Precision = 35/45 = 77.7%
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精确率 = 35/45 = 77.7%
- en: 'Just as we thought: precision gave a higher score to the first model than to
    the second model. We conclude that models like the spam model, in which false
    positives are much more expensive than false negatives, are *high precision models*.
    And why is the first model better than the second one? The second model deleted
    10 good (ham) emails, but the first model deleted only five of them. The second
    model may have cleaned up more spam than the first one, but that doesn’t make
    up for the five ham emails it deleted.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所想：精确率给第一个模型比第二个模型更高的分数。我们得出结论，像垃圾邮件模型这样的模型，其中假阳性比假阴性更昂贵，是*高精确率模型*。那么为什么第一个模型比第二个模型好？第二个模型删除了10封好（普通）邮件，但第一个模型只删除了其中5封。第二个模型可能清理了比第一个模型更多的垃圾邮件，但这不能弥补它删除的5封普通邮件。
- en: 'Now, in the same way we tricked accuracy and recall, we can also trick precision.
    Consider the following spam filter: a spam filter that never detects any spam.
    What is the precision of this model? This is complicated, because there are zero
    spam emails deleted (zero true positives) and zero ham emails deleted (zero false
    positives). We won’t attempt to divide zero over zero, because this book would
    burst into flames, but by convention, a model that makes no false positive mistakes
    has a precision of 100%. But, of course, a spam filter that does nothing is not
    a good spam filter.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，就像我们欺骗准确率和召回率一样，我们也可以欺骗精确率。考虑以下垃圾邮件过滤器：一个永远不会检测到任何垃圾邮件的垃圾邮件过滤器。这个模型的精确率是多少？这很复杂，因为删除的垃圾邮件为零（零真阳性）和删除的普通邮件为零（零假阳性）。我们不会尝试将零除以零，因为这本书会燃烧起来，但按照惯例，没有错误假阳性的模型精确率为100%。但是，当然，一个什么都不做的垃圾邮件过滤器不是一个好的垃圾邮件过滤器。
- en: This goes to show that no matter how good our metrics are, they can always be
    fooled. That doesn’t mean they don’t work. Accuracy, precision, and recall are
    useful tools in a data scientist’s toolbox. It is up to us to decide which ones
    are good for our model, by deciding what errors are more expensive than others.
    Always be careful to not fall into the trap of thinking that a model is good before
    evaluating it with different metrics.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明，无论我们的指标有多好，它们总是可以被欺骗。这并不意味着它们不起作用。准确率、精确率和召回率是数据科学家工具箱中有用的工具。取决于我们决定哪些对我们的模型更有用，通过决定哪些错误比其他错误更昂贵。始终小心，不要在评估不同指标之前就认为模型是好的。
- en: 'Combining recall and precision as a way to optimize both: The F-score'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 将召回率和精确率结合作为优化两者的一种方式：F分数
- en: In this section, we discuss the F-score, a metric that combines both recall
    and precision. In the previous sections, we saw two examples, the coronavirus
    model and the spam model, in which either false negatives or false positives were
    more important. However, in real life, both are important, even if they are important
    to different degrees. For example, we may want a model that doesn’t misdiagnose
    any sick person but that also doesn’t misdiagnose too many healthy people, because
    misdiagnosing a healthy person may involve unnecessary and painful testing, or
    even an unnecessary surgery, which could affect their health negatively. In the
    same way, we may want a model that doesn’t delete any of our good emails. But
    to be a good spam filter, it still needs to catch a lot of spam; otherwise, it’s
    useless. The F-score has a parameter *β* accompanying it, so the more common term
    is *F*[β]-score. When *β* = 1, it is called the *F*[1]-score.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论F分数，这是一个结合了召回率和精确率的指标。在前面的章节中，我们看到了两个例子，即冠状病毒模型和垃圾邮件模型，其中错误否定或错误肯定更重要。然而，在现实生活中，两者都很重要，即使它们的重要性程度不同。例如，我们可能希望一个模型不会误诊任何病人，但也不会误诊太多健康人，因为误诊一个健康人可能涉及不必要的痛苦测试，甚至是不必要的手术，这可能会对他们的健康产生负面影响。同样，我们可能希望一个模型不会删除我们的任何好邮件。但为了成为一个好的垃圾邮件过滤器，它仍然需要捕捉到大量的垃圾邮件；否则，它就毫无用处。F分数有一个伴随的参数*β*，所以更常见的术语是*F*[β]-分数。当*β*
    = 1时，它被称为*F*[1]-分数。
- en: Calculating the F-score
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 计算F分数
- en: Our goal is to find a metric that gives us some number between the recall and
    the precision. The first thing that comes to mind is the average between recall
    and precision. Would this work? It would, but it’s not the one we pick, for one
    fundamental reason. A good model is one that has good recall and good precision.
    If a model has, say, recall of 50% and precision of 100%, the average is 75%.
    This is a good score, but the model may not be, because a recall of 50% is not
    very good. We need a metric that behaves like the average but that is closer to
    the minimum value of the two.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是找到一个介于召回率和精确率之间的指标。首先想到的是召回率和精确率的平均值。这会有效吗？会的，但这并不是我们选择的方案，有一个基本原因。一个好的模型应该具有好的召回率和好的精确率。如果一个模型，比如说，召回率为50%，精确率为100%，那么平均值为75%。这是一个不错的分数，但模型可能并不好，因为50%的召回率并不理想。我们需要一个指标，它的行为类似于平均值，但更接近这两个数值中的最小值。
- en: 'A quantity that is like the average of two numbers is called the harmonic mean.
    Whereas the average of two numbers *a* and *b* is (*a* + *b*)/2, their harmonic
    mean is 2*ab*/(*a* + *b*). The harmonic mean has this property: it is always smaller
    than or equal to the average. If the numbers *a* and *b* are equal, one can quickly
    check that their harmonic mean is equal to both of them, just like the average.
    But in other cases, the harmonic mean is smaller. Let’s look at an example: If
    *a* = 1 and *b* = 9, their average is 5\. The harmonic mean is ![](../Images/07_01_E03.png)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于两个数平均值的量称为调和平均数。两个数a和b的平均值是(a + b)/2，它们的调和平均数是2ab/(a + b)。调和平均数具有以下性质：它总是小于或等于平均值。如果a和b相等，可以快速检查它们的调和平均数等于它们两者，就像平均值一样。但在其他情况下，调和平均数会更小。让我们看一个例子：如果a
    = 1且b = 9，它们的平均值是5。调和平均数是![图片](../Images/07_01_E03.png)
- en: 'The *F*[1]-score is defined as the harmonic mean between the precision and
    the recall, as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '*F*[1]-分数定义为精确率和召回率的调和平均，如下所示：'
- en: '![](../Images/07_01_E04.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/07_01_E04.png)'
- en: If both numbers are high, the *F*[1]-score is high. However, if one of them
    is low, the *F*[1]-score will be low. The purpose of the *F*[1]-score is to measure
    if both recall and precision are high and to ring a bell when one of these two
    scores is low.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这两个数值都较高，*F*[1]-分数也会较高。然而，如果其中一个数值较低，*F*[1]-分数将会较低。*F*[1]-分数的目的是衡量召回率和精确率是否都较高，并在其中一个分数较低时发出警报。
- en: Calculating the *F*[β]-score
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 计算*F*[β]-分数
- en: In the previous subsection, we learned about the *F*[1]-score, a score that
    combines recall and precision, for the purpose of evaluating a model. However,
    sometimes we want more recall than precision, or vice versa. Thus, when we combine
    the two scores, we may want to give one of them more weight. This means that sometimes
    we may want a model that cares both about false positives and false negatives
    but assigns more weight to one of them. For example, the coronavirus model cares
    much more about false negatives, because people’s lives may depend on a correct
    identification of the virus, but it still doesn’t want to create too many false
    positives, because we may not want to spend excessive resources retesting healthy
    people. The spam model cares much more about false positives, because we really
    wouldn’t want to delete good emails but still doesn’t want to create too many
    false negatives, because we wouldn’t want our inbox cluttered with spam messages.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一小节中，我们学习了*F*[1]-分数，这是一个结合召回率和精确率的分数，用于评估模型。然而，有时我们希望召回率高于精确率，或者相反。因此，当我们结合这两个分数时，我们可能希望给其中一个分数赋予更多的权重。这意味着有时我们可能希望一个既关注假阳性也关注假阴性的模型，但更重视其中一个。例如，冠状病毒模型对假阴性非常关注，因为人们的生命可能取决于对病毒的准确识别，但它仍然不希望产生过多的假阳性，因为我们可能不想浪费过多的资源重新检测健康的人。垃圾邮件模型对假阳性非常关注，因为我们真的不希望删除好的电子邮件，但也不希望产生过多的假阴性，因为我们不希望我们的收件箱被垃圾邮件消息所充斥。
- en: This is where *F*[β]-score comes into play. The formula for the *F*[β]-score
    may look complicated at first, but once we look at it carefully, it does exactly
    what we want. The *F*[β]-score uses a parameter called *β* (the Greek letter beta),
    which can take any positive value. The point of *β* is to act as a dial that we
    turn to emphasize precision or recall. More specifically, if we slide the *β*
    dial to zero, we get full precision; if we slide it to infinity, we get full recall.
    In general, the lower the value of *β*, the more we emphasize precision, and the
    higher the value of *β*, the more we emphasize recall.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是 *F*[β]-分数发挥作用的地方。*F*[β]-分数的公式可能一开始看起来很复杂，但一旦我们仔细观察，它确实做了我们想要的事情。*F*[β]-分数使用一个称为
    *β*（希腊字母贝塔）的参数，它可以取任何正数值。*β* 的作用就像一个旋钮，我们可以转动它来强调精确率或召回率。更具体地说，如果我们把 *β* 旋钮滑到零，我们得到完全的精确率；如果我们把它滑到无穷大，我们得到完全的召回率。一般来说，*β*
    的值越低，我们越强调精确率，而 *β* 的值越高，我们越强调召回率。
- en: 'This is where *F*[β]-score is defined as follows (where precision is *P* and
    recall is *R*):'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '*F*[β]-分数的定义如下（其中精确率为 *P*，召回率为 *R*）：'
- en: '![](../Images/07_01_E05.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/07_01_E05.png)'
- en: Let’s analyze this formula carefully by looking at some values for *β*.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过观察一些 *β* 的值来仔细分析这个公式。
- en: '**Case 1**: ***β* = 1**'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '**案例 1**：***β* = 1**'
- en: 'When *β* is equal to 1, the *F*[β]-score becomes the following:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 当 *β* 等于 1 时，*F*[β]-分数变为以下形式：
- en: '![](../Images/07_01_E06.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/07_01_E06.png)'
- en: This is the same as the *F*[1]-score that considers recall and precision equally.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这与考虑召回率和精确率同等重要的 *F*[1]-分数相同。
- en: '**Case 2**: ***β* = 10**'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '**案例 2**：***β* = 10**'
- en: 'When *β* is equal to 10, the *F*[β]-score becomes the following:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 当 *β* 等于 10 时，*F*[β]-分数变为以下形式：
- en: '![](../Images/07_01_E07.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/07_01_E07.png)'
- en: This can be written as
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以写成
- en: '![](../Images/07_01_E08.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/07_01_E08.png)'
- en: This is similar to the *F*[1]-score, except notice how it gives much more importance
    to *R* than to *P*. To see this, notice that the limit as *β* tends to ∞ of the *F*[β]-score
    is *R*. Therefore, when we want a score between recall and precision that gives
    more weight to recall, we pick a value of *β* that is larger than 1\. The larger
    the value, the more emphasis we put on the recall and less on the precision.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这与 *F*[1]-分数类似，但请注意它对 *R* 的重视程度远高于 *P*。为了看到这一点，请注意当 *β* 趋向于 ∞ 时，*F*[β]-分数的极限是
    *R*。因此，当我们想要一个介于召回率和精确率之间的分数，且更重视召回率时，我们选择一个大于 1 的 *β* 值。值越大，我们对召回率的重视程度就越高，对精确率的重视程度就越低。
- en: '**Case 3**: ***β* = 0.1**'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '**案例 3**：***β* = 0.1**'
- en: 'When *β* is equal to 0.1, the *F*[β]-score becomes the following:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 当 *β* 等于 0.1 时，*F*[β]-分数变为以下形式：
- en: '![](../Images/07_01_E09.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/07_01_E09.png)'
- en: Just like before, we can write this as
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 就像之前一样，我们可以写成
- en: '![](../Images/07_01_E10.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/07_01_E10.png)'
- en: This is similar to the formula from case 2, except this one gives *P* a lot
    more importance. Therefore, when we want a score between recall and precision
    that gives more weight to precision, we pick a value of *β* that is smaller than
    1\. The smaller the value, the more emphasis we put on the precision and less
    on the recall. In the limits, we say that a value of *β* = 0 gives us the precision,
    and a value of *β* = ∞ gives us the recall.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这与案例 2 中的公式类似，但这个公式给 *P* 的重视程度更高。因此，当我们想要一个介于召回率和精确率之间的分数，且更重视精确率时，我们选择一个小于
    1 的 *β* 值。值越小，我们对精确率的重视程度就越高，对召回率的重视程度就越低。在极限情况下，我们说 *β* = 0 给我们的是精确率，而 *β* =
    ∞ 给我们的是召回率。
- en: 'Recall, precision, or F-scores: Which one should we use?'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率、精确率或 F 分数：我们应该使用哪一个？
- en: Now, how do we put recall and precision into practice? When we have a model,
    is it a high recall or a high precision model? Do we use the F-score? If so, which
    value of *β*should we pick? The answers to these questions are up to us, the data
    scientists. It is important for us to know the problem we are trying to solve
    very well to decide which error, between a false positive and a false negative,
    is more expensive.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们如何将召回率和精确率付诸实践？当我们有一个模型时，它是高召回率还是高精确率的模型？我们使用 F 分数吗？如果是这样，我们应该选择哪个 *β*
    值？这些问题的答案取决于我们，作为数据科学家。对我们来说，了解我们试图解决的问题非常重要，以便决定哪种错误，即假阳性或假阴性，代价更高。
- en: In the previous two examples, we can see that because the coronavirus model
    needs to focus more on recall than on precision, we should pick a large value
    of *b*, say, for example, 2\. In contrast, the spam model needs to focus more
    on precision than on recall, so we should pick a small value of *β*, say, 0.5\.
    For more practice analyzing models and estimating what values of *β* to use, see
    exercise 7.4 at the end of the chapter.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在前两个例子中，我们可以看到，由于冠状病毒模型需要更多地关注召回率而不是精确度，我们应该选择一个较大的 *b* 值，比如说，例如，2。相比之下，垃圾邮件模型需要更多地关注精确度而不是召回率，因此我们应该选择一个较小的
    *β* 值，比如说，0.5。为了更多练习分析模型和估计应该使用哪些 *β* 值，请参阅章节末尾的练习7.4。
- en: 'A useful tool to evaluate our model: The receiver operating characteristic
    (ROC) curve'
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估我们模型的有用工具：接收者操作特征（ROC）曲线
- en: 'In the section “How to fix the accuracy problem?,” we learned how to evaluate
    a model using metrics such as precision, recall, and the F-score. We also learned
    that one of the main challenges of evaluating a model lies in the fact that more
    than one type of error exists and different types of errors have different levels
    of importance. We learned two types of errors: false positives and false negatives.
    In some models, false negatives are much more expensive than false positives,
    and in some models, it’s the opposite.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在“如何解决准确度问题？”这一节中，我们学习了如何使用精确度、召回率和F分数等指标来评估模型。我们还了解到，评估模型的主要挑战之一在于存在多种类型的错误，并且不同类型的错误具有不同的重要性水平。我们学习了两种类型的错误：假阳性和假阴性。在某些模型中，假阴性比假阳性代价更高，而在某些模型中则相反。
- en: 'In this section, I teach you a useful technique to evaluate a model based on
    its performance on false positives and negatives at the same time. Furthermore,
    this method has an important feature: a dial that allows us to gradually switch
    between a model that performs well on false positives and one that performs well
    on false negatives. This technique is based on a curve called the *receiver operating
    characteristic (ROC) curve*.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我将向您介绍一种有用的技术，用于根据模型在假阳性和假阴性方面的表现来评估模型。此外，这种方法有一个重要的特性：一个旋钮，允许我们逐渐在表现良好的假阳性模型和表现良好的假阴性模型之间切换。这种技术基于一个称为
    *接收者操作特征（ROC）曲线* 的曲线。
- en: Before we learn the ROC curve, we need to introduce two new metrics called specificity
    and sensitivity. Actually, only one of them is new. The other one, we’ve seen
    before.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习ROC曲线之前，我们需要介绍两个新的指标，称为特异性和灵敏度。实际上，其中之一是新的。另一个，我们之前已经见过。
- en: 'Sensitivity and specificity: Two new ways to evaluate our model'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 灵敏度和特异性：评估我们模型的新方法
- en: 'In the section “How to fix the accuracy problem?,” we defined recall and precision
    as our metrics and found that they were useful tools to measure our model both
    for false negatives and for false positives. However, in this section, we use
    two different, yet very similar, metrics: *sensitivity* and *specificity*. These
    have a similar use to the previous ones, but they are more useful for us when
    we have to build the ROC curve. Furthermore, although precision and recall are
    more widely used by data scientists, sensitivity and specificity are more common
    in the medical field. Sensitivity and specificity are defined as follows:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在“如何解决准确度问题？”这一节中，我们定义了召回率和精确度作为我们的指标，并发现它们是衡量我们模型对假阴性和假阳性的有用工具。然而，在本节中，我们使用两个不同但非常相似的指标：*灵敏度*
    和 *特异性*。它们与之前的指标有相似的作用，但当我们需要构建ROC曲线时，它们对我们更有用。此外，尽管精确度和召回率在数据科学家中更广泛使用，但灵敏度和特异性在医学领域更为常见。灵敏度和特异性定义为以下内容：
- en: '**Sensitivity (true positive rate)**: the capacity of the test to identify
    the positively labeled points. This is the ratio between the number of true positives
    and the total number of positives. (Note: this is the same as recall).'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '**灵敏度（真阳性率）**：测试识别正标签点的容量。这是真阳性数与总阳性数的比率。（注意：这与召回率相同）。'
- en: '![](../Images/07_01_E11.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/07_01_E11.png)'
- en: '**Specificity (true negative rate)**: the capacity of the test to identify
    the negatively labeled points. This is the ratio between the number of true negatives
    and the total number of negatives.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '**特异性（真阴性率）**：测试识别负标签点的容量。这是真阴性数与总阴性数的比率。'
- en: '![](../Images/07_01_E12.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/07_01_E12.png)'
- en: As I mentioned, sensitivity is the same as recall. However, specificity is not
    the same as precision (each nomenclature is popular in different disciplines,
    and for that reason, we use them both here). We see this more in detail in the
    section “Recall is sensitivity, but precision and specificity are different.”
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 如我所述，灵敏度与召回率相同。然而，特异性与精确度不同（每个名称在不同的学科中都很流行，因此我们在这里都使用它们）。我们将在“召回率是灵敏度，但精确度和特异性不同”这一节中更详细地了解这一点。
- en: In the coronavirus model, the sensitivity is the proportion of sick people that
    the model has correctly diagnosed, among all the sick people. The specificity
    is the proportion of healthy people the model has correctly diagnosed, among the
    healthy people. We are more concerned about correctly diagnosing sick people,
    so we need the coronavirus model to have *high sensitivity*.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在冠状病毒模型中，灵敏度是指模型正确诊断的患病人数占所有患病人数的比例。特异性是指模型正确诊断的健康人数占所有健康人数的比例。我们更关心正确诊断患病人群，因此我们需要冠状病毒模型具有**高灵敏度**。
- en: In the spam-detection model, the sensitivity is the proportion of spam messages
    we correctly deleted, among all the spam messages. The specificity is the proportion
    of ham emails we correctly sent to the inbox, among all the ham emails. Because
    we are more concerned about correctly detecting the ham emails, we need the spam
    detection model to have *high specificity*.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在垃圾邮件检测模型中，灵敏度是指我们正确删除的垃圾邮件占所有垃圾邮件的比例。特异性是指我们正确发送到收件箱的普通邮件占所有普通邮件的比例。因为我们更关心正确检测普通邮件，所以我们需要垃圾邮件检测模型具有**高特异性**。
- en: To clarify the previous concepts, let’s look at them in the graphical example
    we are working on. Namely, let’s calculate the specificity and sensitivity for
    our two models in figure 7.2 (which is the same as figure 7.1).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 为了阐明前面的概念，让我们看看我们正在工作的图形示例。也就是说，让我们计算图7.2（与图7.1相同）中我们两个模型的特异性和灵敏度。
- en: '![](../Images/7-21.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7-21.png)'
- en: Figure 7.2 On the left, a coronavirus model where the people are diagnosed as
    healthy or sick; on the right, a spam detection model where the emails are classified
    as spam or ham
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2 左边是一个冠状病毒模型，其中人们被诊断为健康或患病；右边是一个垃圾邮件检测模型，其中电子邮件被分类为垃圾邮件或普通邮件
- en: 'As we saw previously, these two models produce the following quantities:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前所见，这两个模型产生了以下数量：
- en: Three true positives
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 三个真阳性
- en: Four true negatives
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 四个真阴性
- en: One false positive
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个假阳性
- en: Two false negatives
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两个假阴性
- en: Now let’s calculate the specificity and sensitivity of these models.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来计算这些模型的特异性和灵敏度。
- en: Calculating the specificity
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 计算特异性
- en: 'In this case, we calculate sensitivity as follows: among the positive points,
    how many did the model classify correctly? This is equivalent to asking: among
    the triangles, how many are located to the right of the line? There are five triangles,
    and the model classified three of them correctly to the right of the line, so
    the sensitivity is 3/5, which equals 0.6, or 60%.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们计算灵敏度的方法是：在所有阳性点中，模型正确分类了多少个？这相当于问：在所有三角形中，有多少个位于线的右侧？共有五个三角形，模型正确地将三个位于线的右侧的三角形分类，因此灵敏度是3/5，等于0.6，或60%。
- en: Calculating the sensitivity
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 计算灵敏度
- en: 'We calculate specificity as follows: among the negative points, how many did
    the model classify correctly? This is equivalent to asking: among the circles,
    how many are located to the left of the line? There are five circles, and the
    model classified four of them correctly to the left of the line, so the specificity
    is 4/5, which equals 0.8, or 80%.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们计算特异性的方法是：在所有阴性点中，模型正确分类了多少个？这相当于问：在所有圆形中，有多少个位于线的左侧？共有五个圆形，模型正确地将四个位于线的左侧的圆形分类，因此特异性是4/5，等于0.8，或80%。
- en: 'The receiver operating characteristic (ROC) curve: A way to optimize sensitivity
    and specificity in a model'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 接收者操作特征（ROC）曲线：一种优化模型灵敏度和特异性的方法
- en: In this section, we see how to draw the receiver operating characteristic (ROC)
    curve, which will give us a lot of information about the model. In short, what
    we’ll do is slowly modify the model and record the sensitivity and specificity
    of the model at each time step.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看到如何绘制接收者操作特征（ROC）曲线，这将为我们提供关于模型的大量信息。简而言之，我们将缓慢修改模型并记录每个时间步长模型的灵敏度和特异性。
- en: The first and only assumption we need to make about our model is that it returns
    the prediction as a continuous value, namely, as a probability. This is true about
    models such as logistic classifiers, where the prediction is not a class, such
    as positive/negative, but a value between 0 and 1, such as 0.7\. What we normally
    do with this value is pick a threshold, such as 0.5, and classify every point
    that receives a prediction higher than or equal to the threshold as positive and
    every other point as negative. However, this threshold can be any value—it need
    not be 0.5\. Our procedure consists in varying this threshold from 0 all the way
    to 1 and recording the sensitivity and specificity of the model at each threshold
    value.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对模型需要做的第一个也是唯一的一个假设是，它返回的预测是一个连续值，即概率。这在像逻辑分类器这样的模型中是正确的，其中预测不是一个类别，例如正/负，而是一个介于0和1之间的值，例如0.7。我们通常用这个值来选择一个阈值，例如0.5，并将预测值高于或等于阈值的每个点分类为阳性，其他点分类为阴性。然而，这个阈值可以是任何值——它不必是0.5。我们的程序包括从0到1改变这个阈值，并记录每个阈值值下模型的灵敏度和特异性。
- en: 'Let’s look at an example. We calculate the sensitivity and specificity for
    three different thresholds: 0.2, 0.5, and 0.8\. In figure 7.3, we can see how
    many points are to the left and right of the line for each one of these thresholds.
    Let’s study them in detail. Remember that sensitivity is the ratio of true positives
    over all positives, and specificity is the ratio of true negatives over all negatives.
    Also remember that for each one of these, there are five total positives and five
    total negatives.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个例子。我们计算三个不同阈值（0.2、0.5和0.8）的灵敏度和特异性。在图7.3中，我们可以看到每个阈值下有多少点位于线的左侧和右侧。让我们详细研究一下。记住，灵敏度是所有阳性中的真阳性比率，特异性是所有阴性中的真阴性比率。还要记住，对于这些中的每一个，总共有五个阳性，五个阴性。
- en: Threshold = 0.2
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 阈值 = 0.2
- en: 'Number of true positives: 4'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 真阳性数量：4
- en: '**Sensitivity**: ⅘'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '**灵敏度**：五分之五'
- en: 'Number of true negatives: 3'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 真阴性数量：3
- en: '**Specificity**: ⅗'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '**特异性**：五分之四'
- en: Threshold = 0.5
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 阈值 = 0.5
- en: 'Number of true positives: 3'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 真阳性数量：3
- en: '**Sensitivity**: ⅗'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '**灵敏度**：五分之四'
- en: 'Number of true negatives: 4'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 真阴性数量：4
- en: '**Specificity**: ⅘'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '**特异性**：五分之五'
- en: Threshold = 0.2
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 阈值 = 0.2
- en: 'Number of true positives: 2'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 真阳性数量：2
- en: '**Sensitivity**: ⅖'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '**灵敏度**：五分之四'
- en: 'Number of true negatives: 5'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 真阴性数量：5
- en: '**Specificity**: ⁵/₅ = 1'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '**特异性**：五/五 = 1'
- en: Note that a low threshold leads to many positive predictions. Therefore, we
    will have few false negatives, implying a high sensitivity score, and many false
    positives, implying a low specificity score. Similarly, a high threshold implies
    a low sensitivity score and a high specificity score. As we move the threshold
    from low to high, the sensitivity decreases, and the specificity increases. This
    is an important point that we’ll touch on later in this chapter, when we get to
    the point of deciding the best threshold for our model.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，低阈值会导致许多阳性预测。因此，我们将有很少的假阴性，这意味着高灵敏度分数，以及许多假阳性，这意味着低特异性分数。同样，高阈值意味着低灵敏度分数和高特异性分数。当我们从低阈值移动到高阈值时，灵敏度降低，特异性增加。这是一个重要的观点，我们将在本章后面的部分讨论，当我们到达决定模型最佳阈值的时候。
- en: Now we are ready to build the ROC curve. First, we consider a threshold of 0
    and slowly increase the value of this threshold by small intervals, until it reaches
    1\. For every increment in threshold, we pass over exactly one point. The values
    of the thresholds are not important—what is important is that at every step, we
    pass over exactly one point (this is possible because all the points give us different
    scores, but it’s not a requirement in general). Thus, we’ll refer to the steps
    as 0, 1, 2,..., 10\. In your head, you should imagine the vertical line in figure
    7.3 starting at 0 and moving slowly from left to right, sweeping one point at
    a time, until reaching 1\. These steps are recorded in table 7.6, together with
    the number of true positives and negatives, sensitivity, and specificity at each
    step.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备构建ROC曲线。首先，我们考虑一个阈值为0，并逐渐以小的间隔增加这个阈值，直到它达到1。对于阈值的每次增加，我们恰好通过一个点。阈值的具体值并不重要——重要的是在每一步，我们恰好通过一个点（这是可能的，因为所有点都给出了不同的分数，但这不是一般性的要求）。因此，我们将这些步骤称为0、1、2、...、10。在你的脑海中，你应该想象图7.3中的垂直线从0开始，缓慢地从左向右移动，每次扫过一个点，直到达到1。这些步骤记录在表7.6中，包括每个步骤的真阳性、真阴性、灵敏度和特异性。
- en: One thing to notice is that in the first step (step 0), the line is at threshold
    0\. This means every point is classified as positive by the model. All the positive
    points are also classified as positive, so every positive is a true positive.
    This means that at timestep 0, the sensitivity is 5/5 = 1\. But because every
    negative point is classified as positive, there are no true positives, so the
    specificity is 0/5 = 0\. Similarly, at the last step (step 10), the threshold
    is 1, and we can check that because every point is classified as negative, the
    sensitivity is now 0 and the specificity is 1\. For clarity, the three models
    in figure 7.3 are highlighted in table 7.6 as timesteps 4, 6, and 8, respectively.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到的一点是，在第一步（步骤0）中，线位于阈值0。这意味着模型将每个点都分类为正样本。所有正样本也被分类为正样本，因此每个正样本都是真阳性。这意味着在时间步0，敏感度为5/5
    = 1。但由于每个负样本都被分类为正样本，没有真阳性，因此特异性为0/5 = 0。同样，在最后一步（步骤10）中，阈值为1，我们可以检查出由于每个点都被分类为负样本，敏感度现在为0，特异性为1。为了清晰起见，图7.3中的三个模型在表7.6中分别突出显示为时间步4、6和8。
- en: '![](../Images/7-31.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/7-31.png)'
- en: Figure 7.3 The effects of moving the threshold on the sensitivity and the specificity.
    On the left, we have a model with a low threshold; in the middle, we have one
    with a medium threshold; and on the right, we have one with a high threshold.
    For each of the models, there are five positive and five negative points. Each
    model is represented by the vertical line. The model predicts that the points
    to the right of the line are positive and those to the left are negative. For
    each of the models, we’ve counted the number of true positives and true negatives,
    that is, the number of positive and negative points that have been correctly predicted.
    We have used those to calculate the sensitivity and the specificity. Note that
    as we increase the threshold (i.e., as we move the vertical line from left to
    right), the sensitivity goes down and the specificity goes up.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.3 移动阈值对敏感性和特异性的影响。在左侧，我们有一个低阈值的模型；在中间，我们有一个中等阈值的模型；在右侧，我们有一个高阈值的模型。对于每个模型，都有五个正样本和五个负样本。每个模型由一条垂直线表示。模型预测位于线右侧的点为正样本，位于线左侧的点为负样本。对于每个模型，我们计算了真阳性和真阴性的数量，即正确预测的正样本和负样本的数量。我们使用这些数据来计算敏感性和特异性。请注意，随着阈值的增加（即，随着垂直线从左向右移动），敏感度下降，特异性上升。
- en: Table 7.6 All the timesteps in the process of increasing our threshold, which
    is an important step in building our ROC curve. At each timestep, we record the
    number of true positives and true negatives. We then calculate the specificity
    of the model by dividing the number of true positives by the total number of positives.
    As a final step, we calculate the specificity by dividing the number of true negatives
    by the total number of negatives.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 表7.6 在提高我们的阈值的过程中所有的时间步，这是构建ROC曲线的重要步骤。在每个时间步，我们记录真阳性和真阴性的数量。然后，我们通过将真阳性的数量除以正样本总数来计算模型的特异性。作为最后一步，我们通过将真阴性的数量除以负样本总数来计算特异性。
- en: '| Step | True positives | Sensitivity | True negatives | Specificity |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| 步骤 | 真阳性 | 敏感度 | 真阴性 | 特异性 |'
- en: '| 0 | 5 | 1 | 0 | 0 |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 5 | 1 | 0 | 0 |'
- en: '| 1 | 5 | 1 | 1 | 0.2 |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 5 | 1 | 1 | 0.2 |'
- en: '| 2 | 4 | 0.8 | 1 | 0.2 |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 4 | 0.8 | 1 | 0.2 |'
- en: '| 3 | 4 | 0.8 | 2 | 0.4 |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 4 | 0.8 | 2 | 0.4 |'
- en: '| 4 | 4 | 0.8 | 3 | 0.6 |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 4 | 0.8 | 3 | 0.6 |'
- en: '| 5 | 3 | 0.6 | 3 | 0.6 |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 3 | 0.6 | 3 | 0.6 |'
- en: '| 6 | 3 | 0.6 | 4 | 0.8 |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 3 | 0.6 | 4 | 0.8 |'
- en: '| 7 | 2 | 0.4 | 4 | 0.8 |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 2 | 0.4 | 4 | 0.8 |'
- en: '| 8 | 2 | 0.4 | 5 | 1 |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 2 | 0.4 | 5 | 1 |'
- en: '| 9 | 1 | 0.2 | 5 | 1 |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 1 | 0.2 | 5 | 1 |'
- en: '| 10 | 0 | 0 | 5 | 1 |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 0 | 0 | 5 | 1 |'
- en: As a last step, we plot the sensitivity and specificity values. This is the
    ROC curve, which we see in figure 7.4\. In this figure, each of the black points
    corresponds to a timestep (indicated inside the point), the horizontal coordinate
    corresponds to the sensitivity, and the vertical coordinate to the specificity.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后一步，我们绘制了敏感性和特异性值。这是ROC曲线，如图7.4所示。在这个图中，每个黑色点对应一个时间步（点内指示），水平坐标对应敏感度，垂直坐标对应特异性。
- en: '![](../Images/7-41.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/7-41.png)'
- en: Figure 7.4 Here we can see the ROC curve corresponding to our ongoing example,
    which gives us a great deal of information on our model. The highlighted dots
    correspond to the timesteps obtained by moving our threshold from 0 to 1, and
    each dot is labeled by the timestep. On the horizontal axis we record the sensitivity
    of the model at each timestep, and on the vertical axis we record the specificity.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.4 在这里，我们可以看到对应于我们正在进行的示例的ROC曲线，它为我们提供了关于模型的大量信息。高亮的点对应于将阈值从0移动到1时获得的timesteps，每个点都标有timesteps。在横轴上，我们记录了每个timesteps的模型敏感性，在纵轴上，我们记录了特异性。
- en: 'A metric that tells us how good our model is: The AUC (area under the curve)'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 一个告诉我们模型有多好的指标：AUC（曲线下的面积）
- en: As we’ve seen before in this book, evaluating a machine learning model is a
    highly important task, and in this section, we discuss how to use the ROC curve
    to evaluate a model. For this, we’ve done all the work already—all that is left
    is to calculate the area under the curve, or AUC. At the top of figure 7.5, we
    can see three models, in which the prediction is given by the horizontal axis
    (from 0 to 1). On the bottom, you can see the three corresponding ROC curves.
    Each one of the squares has size 0.2 times 0.2\. The number of squares under each
    curve are 13, 18, and 25, which amounts to areas under the curve of 0.52, 0.72,
    and 1.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本书之前所见，评估机器学习模型是一项非常重要的任务，在本节中，我们将讨论如何使用ROC曲线来评估模型。为此，我们已经完成了所有工作——剩下的只是计算曲线下的面积，即AUC。在图7.5的顶部，我们可以看到三个模型，其中预测值由横轴给出（从0到1）。在底部，你可以看到三个相应的ROC曲线。每个方块的尺寸是0.2乘以0.2。每个曲线下的方块数量分别是13、18和25，这相当于曲线下的面积是0.52、0.72和1。
- en: Note that the best a model can do is an AUC of 1, which corresponds to the model
    on the right. The worst a model can do is an AUC of 0.5, because this means the
    model is as good as random guessing. This corresponds to the model on the left.
    The model in the middle is our original model, with an AUC of 0.72.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，一个模型最好的AUC是1，这对应于图右边的模型。一个模型最差的AUC是0.5，因为这意味着模型的表现与随机猜测一样好。这对应于图左边的模型。中间的模型是我们的原始模型，AUC为0.72。
- en: '![](../Images/7-51.png)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/7-51.png)'
- en: Figure 7.5 In this figure, we can see that AUC, or area under the curve, is
    a good metric to determine how good a model is. The higher the AUC, the better
    the model. On the left, we have a bad model with an AUC of 0.52\. In the middle,
    we have a good model with an AUC of 0.72\. On the right, we have a great model
    with an AUC of 1.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.5 在这个图中，我们可以看到AUC，即曲线下的面积，是一个很好的指标，可以用来确定模型的好坏。AUC越高，模型越好。在左边，我们有一个AUC为0.52的坏模型。在中间，我们有一个AUC为0.72的好模型。在右边，我们有一个AUC为1的伟大模型。
- en: What about a model with an AUC of zero? Well, this is tricky. A model with an
    AUC of zero would correspond to a model that classifies every point wrong. Is
    this a bad model? It’s actually a very good model, because all we have to do to
    fix it is to flip all the positive and negative predictions and get a perfect
    model. It’s the same effect as having a person that lies every single time they
    get a true-or-false question. All we have to do to get them to tell the truth
    is to flip all their answers. This means the worst we can have in a binary classification
    model is an AUC of 0.5, because this corresponds to a person who lies 50% of the
    time. They give us no information because we never know if they are telling the
    truth or lying! Incidentally, if we have a model with an AUC less than 0.5, we
    can flip the positive and negative predictions and obtain a model with an AUC
    larger than 0.5.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 那么AUC为零的模型呢？这有点棘手。AUC为零的模型对应于一个将每个点都分类错误的模型。这是一个坏模型吗？实际上，这是一个非常好的模型，因为要修复它，我们只需要翻转所有正负预测，就能得到一个完美的模型。这就像有一个人每次在回答是非问题时都撒谎一样。要让他们说实话，我们只需要翻转他们所有的答案。这意味着在二元分类模型中，最坏的情况是AUC为0.5，因为这对应于一个撒谎50%的人。他们给我们没有信息，因为我们永远不知道他们在说真话还是撒谎！顺便说一句，如果我们有一个AUC小于0.5的模型，我们可以翻转正负预测，从而得到一个AUC大于0.5的模型。
- en: How to make decisions using the ROC curve
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 如何使用ROC曲线做出决策
- en: The ROC is a powerful graphic that gives us a lot of information about our model.
    In this section, we learn how we can use it to improve our model. In short, we
    use the ROC to tweak the threshold in a model and apply it to pick the best model
    for our use case.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: ROC是一个强大的图形，它为我们提供了关于模型的大量信息。在本节中，我们学习如何使用它来改进我们的模型。简而言之，我们使用ROC调整模型中的阈值，并将其应用于选择最适合我们用例的最佳模型。
- en: 'At the beginning of this chapter, we introduced two models, the coronavirus
    model and the spam-detection model. These models were very different because,
    as we saw, the coronavirus model requires high sensitivity, whereas the spam-detection
    model requires high specificity. Every model requires some amount of sensitivity
    and specificity based on the problem we are to solve. Let’s say we are in the
    following situation: we are training a model that is supposed to have high sensitivity,
    and we get a model with low sensitivity and high specificity. Is there any way
    we can trade off some specificity and gain some sensitivity?'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的开头，我们介绍了两个模型，即冠状病毒模型和垃圾邮件检测模型。这些模型非常不同，因为我们看到，冠状病毒模型需要高敏感性，而垃圾邮件检测模型需要高特异度。每个模型都需要一定程度的敏感性和特异度，这取决于我们要解决的问题。假设我们处于以下情况：我们正在训练一个应该具有高敏感性的模型，但我们得到了一个低敏感性而高特异度的模型。我们是否有办法牺牲一些特异度以换取一些敏感性？
- en: The answer is yes! We can trade off specificity and sensitivity by moving the
    threshold. Recall that when we first defined the ROC curve, we noticed that the
    lower the threshold, the higher sensitivity and lower specificity in the model,
    and the higher the threshold, the lower sensitivity and higher specificity in
    the model. When the vertical line corresponding to the threshold is at the very
    left, every point is predicted to be positive, so all the positives are true positives,
    whereas when the vertical line is at the very right, every point is predicted
    to be negative, so all the negatives are true negatives. As we move the line to
    the right, we lose some true positives and gain some true negatives, thus the
    sensitivity decreases and the specificity increases. Notice that as the threshold
    moves from 0 to 1, we move up and to the left in the ROC curve, as figure 7.6
    illustrates.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是肯定的！我们可以通过调整阈值来权衡特异性和敏感性。回想一下，当我们首次定义ROC曲线时，我们注意到阈值越低，模型的敏感性越高而特异度越低，反之，阈值越高，模型的敏感性越低而特异度越高。当对应的阈值垂直线位于最左侧时，所有点都被预测为阳性，因此所有阳性都是真阳性，而当时垂直线位于最右侧时，所有点都被预测为阴性，因此所有阴性都是真阴性。当我们向右移动这条线时，我们失去了一些真阳性并获得了某些真阴性，因此敏感性降低而特异度提高。请注意，当阈值从0移动到1时，我们在ROC曲线上向上并向左移动，如图7.6所示。
- en: '![](../Images/7-61.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/7-61.png)'
- en: Figure 7.6 The threshold of the model has a lot to do with the sensitivity and
    the specificity, and this relationship will help us pick the perfect threshold
    for our model. On the left, we have our model and, on the right, the corresponding
    ROC curve. As we increase or decrease the threshold, we change the sensitivity
    and specificity of the model, and this change is illustrated by moving in the
    ROC curve.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6 模型的阈值与敏感性和特异度有很大关系，这种关系将帮助我们为我们的模型选择完美的阈值。在左侧，我们有我们的模型，在右侧，是对应的ROC曲线。当我们增加或减少阈值时，我们改变模型的敏感性和特异度，这种变化通过在ROC曲线上的移动来表示。
- en: Why does this happen? The threshold tells us where we draw the line on classifying
    a point. For example, in the coronavirus model, the threshold tells us where we
    draw the line on a person being sent for more tests or sent home. A model with
    a low threshold is a model that sends people for extra tests if they so much as
    show mild symptoms. A model with a high threshold is one that needs the people
    to show strong symptoms to send them for more tests. Because we want to catch
    all the sick people, we want a low threshold for this model, which means we want
    a model with high sensitivity. For clarity, in figure 7.7, we can see the three
    thresholds used previously, as well as the points where they correspond in the
    curve.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么会发生这种情况呢？阈值告诉我们我们在分类一个点时在哪里划线。例如，在冠状病毒模型中，阈值告诉我们我们在决定一个人是否需要进一步检测或回家时在哪里划线。低阈值的模型是指即使有轻微症状也会让人进行额外检测的模型。高阈值的模型是指需要人们表现出强烈症状才会让人进行更多检测的模型。因为我们希望捕捉到所有生病的人，所以我们希望这个模型的阈值低，这意味着我们希望这个模型具有高敏感性。为了清晰起见，在图7.7中，我们可以看到之前使用的三个阈值，以及它们在曲线中的对应点。
- en: If we want our model to have high sensitivity, we just push the threshold to
    the left (i.e., decrease it) until we get to a point in the curve that has as
    much sensitivity as we want. Note that the model may lose some specificity, and
    that’s the price we pay. In contrast, if we want higher specificity, we push the
    threshold to the right (i.e., increase it) until we get to a point in the curve
    that has as much specificity as we want. Again, we lose some sensitivity during
    this process. The curve tells us exactly how much of one we gain and lose, so
    as data scientists, this is a great tool to help us decide the best threshold
    for our model. In figure 7.8, we can see a more general example with a bigger
    dataset.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想让我们的模型具有高敏感性，我们只需将阈值推向左侧（即减小它），直到我们到达曲线上具有我们想要的敏感度的点。请注意，模型可能会失去一些特异性，这是我们付出的代价。相比之下，如果我们想要更高的特异性，我们将阈值推向右侧（即增加它），直到我们到达曲线上具有我们想要的特异性的点。同样，在这个过程中，我们会失去一些敏感性。曲线告诉我们我们获得了多少以及失去了多少，因此作为数据科学家，这是一个帮助我们决定模型最佳阈值的伟大工具。在图7.8中，我们可以看到一个具有更大数据集的更一般化的例子。
- en: '![](../Images/7-71.png)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7-71.png)'
- en: Figure 7.7 The parallel between the threshold of the model and its ROC. The
    model on the left has a high threshold, low sensitivity, and high specificity.
    The model in the middle has medium values for threshold, sensitivity, and specificity.
    The model on the right has a low threshold, high sensitivity, and low specificity.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.7 模型阈值与其ROC曲线的平行关系。左侧的模型具有高阈值、低敏感性和高特异性。中间的模型在阈值、敏感性和特异性方面具有中等值。右侧的模型具有低阈值、高敏感性和低特异性。
- en: '![](../Images/7-81.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7-81.png)'
- en: Figure 7.8 In this more general scenario, we can see an ROC curve and three
    points on it corresponding to three different thresholds. If we want to pick a
    threshold that gives us high specificity, we pick the one on the left. For a model
    with high sensitivity, we pick the one on the right. If we want a model that has
    a good amount of both sensitivity and specificity, we pick the one in the middle.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.8 在这个更一般化的场景中，我们可以看到一个ROC曲线和三个与之对应的点，分别对应三个不同的阈值。如果我们想要选择一个具有高特异性的阈值，我们选择左侧的一个。对于具有高敏感性的模型，我们选择右侧的一个。如果我们想要一个既有较高敏感性又有较高特异性的模型，我们选择中间的一个。
- en: If we need a high sensitivity model, such as the coronavirus model, we would
    pick the point on the right. If we need a high specificity model, such as the
    spam-detection model, we may pick the point on the left. However, if we want relatively
    high sensitivity and specificity, we may go for the point in the middle. It’s
    our responsibility as data scientists to know the problem well enough to make
    this decision properly.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们需要一个高敏感性的模型，例如冠状病毒模型，我们会选择右侧的点。如果我们需要一个高特异性的模型，例如垃圾邮件检测模型，我们可能会选择左侧的点。然而，如果我们想要相对较高的敏感性和特异性，我们可能会选择中间的点。作为数据科学家，我们有责任对问题有足够的了解，以便正确地做出这个决定。
- en: Recall is sensitivity, but precision and specificity are different
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率是敏感性，但精确性和特异性是不同的
- en: At this point you may be wondering how we can remember all these terms off the
    top of our head. The answer is, they’re hard not to get confused. Most data scientists
    (including the author) often need to quickly look them up in Wikipedia to make
    sure they’re not confusing them. We could use a mnemonic to help us remember which
    one is which.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，你可能想知道我们如何能够立刻记住所有这些术语。答案是，它们很难不混淆。大多数数据科学家（包括作者）经常需要快速在维基百科上查找它们，以确保它们不会混淆。我们可以使用助记符来帮助我们记住哪个是哪个。
- en: For example, when we think of recall, think of a car company that made a car
    with a fatal design flaw. They need to find all the faulty cars and *recall* them.
    If they accidentally get more cars that are not faulty, they simply return them.
    However, not finding one of the faulty cars would be terrible. Thus, recall cares
    about finding all the positively labeled examples. This represents a model with
    high *recall*.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当我们想到召回率时，想想一个制造了具有致命设计缺陷的汽车的公司。他们需要找到所有有缺陷的汽车并将它们召回。如果他们意外地得到了一些非有缺陷的汽车，他们只需将它们退回。然而，找不到一辆有缺陷的汽车将是可怕的。因此，召回率关注的是找到所有正标签的示例。这代表了一个具有高召回率的模型。
- en: On the other hand, if we work for this car company, and we went a little overboard
    and started recalling *all* the cars, our boss may come over and say, “Hey, you
    are sending too many cars to fix, and we are running out of resources. Can you
    please be more selective and send me *precisely* those that are faulty?” Then
    we need to add precision to the model and try to find only the ones that are faulty,
    even if we accidentally miss some of the faulty ones (hopefully not!). This represents
    a model with high *precision*.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果我们为这家汽车公司工作，并且我们做得有点过头，开始召回**所有**的汽车，我们的老板可能会过来对我们说：“嘿，你送来修理的汽车太多了，我们的资源快用完了。你能更挑剔一点，只送那些有故障的吗？”然后我们需要在模型中添加精确度，并尝试只找到那些有故障的汽车，即使我们不小心错过了其中一些（希望不会！）。这代表了一个具有高**精确度**的模型。
- en: When it comes to specificity and sensitivity, think of an earthquake sensor
    that beeps every time there is an earthquake. This sensor is tremendously *sensitive*.
    If a butterfly sneezes in the next house, the sensor beeps. This sensor will capture
    all the earthquakes for sure, but it will also capture many other things that
    are not an earthquake. This represents a model with high *sensitivity*.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈到特异性和灵敏度时，想象一个地震传感器，每次有地震时都会发出蜂鸣声。这个传感器非常**灵敏**。如果隔壁房子里的蝴蝶打喷嚏，传感器也会发出蜂鸣声。这个传感器肯定会捕捉到所有的地震，但它也会捕捉到许多其他不是地震的东西。这代表了一个具有高**灵敏度**的模型。
- en: Now, let’s imagine that this sensor has a dial, and we turn its sensitivity
    all the way down. Now the sensor will beep only when there’s a lot of movement.
    When that sensor beeps, we *know* it’s an earthquake. The problem is that it may
    miss some smaller or medium earthquakes. In other words, this sensor is very *specific*
    to earthquakes, so it will most likely not beep with anything else. This represents
    a model with high *specificity*.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们想象这个传感器有一个旋钮，我们将它的灵敏度调到最低。现在，传感器只有在有大量移动时才会发出蜂鸣声。当传感器发出蜂鸣声时，我们知道那是地震。问题是它可能会错过一些较小或中等的地震。换句话说，这个传感器对地震非常**特异**，所以它不太可能对其他任何事情发出蜂鸣声。这代表了一个具有高**特异性**的模型。
- en: 'If we go back and read the previous four paragraphs, we may notice the following
    two things:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们回顾前面的四个段落，我们可能会注意到以下两点：
- en: Recall and sensitivity are very similar.
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回忆和灵敏度非常相似。
- en: Precision and specificity are very similar.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精确度和特异性非常相似。
- en: At the very least, recall and sensitivity have the same purpose, which is measuring
    how many false negatives there are. Similarly, precision and specificity also
    have the same purpose, which is measuring how many false positives there are.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 至少，召回率和灵敏度有相同的目的，即测量有多少假反例。同样，精确度和特异性也有相同的目的，即测量有多少假正例。
- en: 'It turns out that recall and sensitivity are *exactly* the same thing. However,
    precision and specificity are not the same thing. Although they don’t measure
    the same, they both punish models with a high number of false positives. How to
    remember all these metrics? A graphical heuristic can help us remember recall,
    precision, sensitivity, and specificity. In figure 7.9, we see a confusion matrix
    with the four quantities: true positives, true negatives, false positives, and
    false negatives. If we focus on the top row (the positively labeled examples),
    we can calculate recall by dividing the number in the left column by the sum of
    the numbers in both columns. If we focus on the leftmost column (the examples
    that are predicted as positive), we can calculate precision by dividing the number
    on the top row by the sum of the numbers in both rows. If we focus on the bottom
    row (the negatively labeled examples), we can calculate specificity by dividing
    the number on the left column by the sum of the numbers on both columns. In other
    words'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，回忆和灵敏度实际上是同一件事。然而，精确度和特异性并不相同。尽管它们测量的不是同一指标，但它们都会惩罚那些有大量误报的模型。如何记住所有这些指标呢？一个图形化的启发式方法可以帮助我们记住召回率、精确度、灵敏度和特异性。在图7.9中，我们看到一个混淆矩阵，包含四个量：真正例、真反例、假正例和假反例。如果我们关注顶部行（标记为正的例子），我们可以通过将左列的数字除以两列数字之和来计算召回率。如果我们关注最左边的列（预测为正的例子），我们可以通过将顶行的数字除以两行数字之和来计算精确度。如果我们关注底部行（标记为负的例子），我们可以通过将左列的数字除以两列数字之和来计算特异性。换句话说
- en: Recall and sensitivity correspond to the top row.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 召回率和灵敏度对应于顶部行。
- en: Precision corresponds to the left column.
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精确度对应于最左边的列。
- en: Specificity corresponds to the bottom row.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特异性对应于底部行。
- en: '![](../Images/7-91.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/7-91.png)'
- en: 'Figure 7.9 The top row of the confusion matrix gives us recall and sensitivity:
    the ratio between the number of true positives and the sum of true positives and
    false negatives. The leftmost column gives us precision: the ratio between the
    number of true positives and the sum of true positives and false positives. The
    bottom row gives us specificity: the ratio between the number of false positives
    and the sum of false positives and true negatives.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.9混淆矩阵的顶部行给出了召回率和灵敏度：真正例数与真正例数和假阴性数之和的比率。最左侧的列给出了精度：真正例数与真正例数和假阳性数之和的比率。底部行给出了特异性：假阳性数与假阳性数和真阴性数之和的比率。
- en: 'To wrap up, these quantities are the following in both of our models:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 总结起来，这些量在我们的两个模型中如下：
- en: 'Medical model:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 医学模型：
- en: '**Recall and sensitivity**: among the sick people (positives), how many were
    correctly diagnosed as sick?'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**召回率和灵敏度**：在生病的人（阳性）中，有多少被正确诊断为生病？'
- en: '**Precision**: among the people diagnosed as sick, how many were actually sick?'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**精度**：在诊断为生病的人中，实际上有多少是生病的？'
- en: '**Specificity**: among the healthy people (negatives), how many were correctly
    diagnosed as healthy?'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特异性**：在健康的人（阴性）中，有多少被正确诊断为健康？'
- en: 'Email model:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 邮件模型：
- en: '**Recall and sensitivity**: among the spam emails (positives), how many were
    correctly deleted?'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**召回率和灵敏度**：在垃圾邮件（阳性）中，有多少被正确删除？'
- en: '**Precision**: among the deleted emails, how many were actually spam?'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**精度**：在删除的邮件中，实际上有多少是垃圾邮件？'
- en: '**Specificity**: among the ham emails (negatives), how many were correctly
    sent to the inbox?'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特异性**：在垃圾邮件（阴性）中，有多少被正确发送到收件箱？'
- en: Summary
  id: totrans-267
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Being able to evaluate a model is as important as being able to train one.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够评估一个模型与能够训练一个模型一样重要。
- en: We can use several important metrics to evaluate a model. The ones we learned
    in this chapter are accuracy, recall, precision, F-score, specificity, and sensitivity.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以使用几个重要的指标来评估一个模型。在本章中我们学习的是准确度、召回率、精度、F分数、特异性和灵敏度。
- en: Accuracy calculates the ratio between correct predictions and total predictions.
    It is useful but can fail in certain cases, especially when the positive and negative
    labels are unbalanced.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确度计算正确预测与总预测之间的比率。它是有用的，但在某些情况下可能会失败，尤其是在正负标签不平衡的情况下。
- en: 'Errors are divided into two categories: false positives and false negatives.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 错误分为两类：假阳性和假阴性。
- en: A false positive is a negatively labeled point, which the model incorrectly
    predicts as positive.
  id: totrans-272
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假阳性是一个负标签点，模型错误地预测为阳性。
- en: A false negative is a positively labeled point, which the model incorrectly
    predicts as negative.
  id: totrans-273
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假阴性是一个正标签点，模型错误地预测为阴性。
- en: For some models, false negatives and false positives are given different levels
    of importance.
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于某些模型，假阴性和假阳性被赋予不同的重要性级别。
- en: Recall and precision are useful metrics to evaluate models, especially when
    the models give false negatives and false positives different levels of importance.
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 召回率和精度是评估模型的有用指标，尤其是在模型对假阴性和假阳性赋予不同重要性的情况下。
- en: Recall measures how many of the positive points were correctly predicted by
    the model. Recall is low when the model creates many false negatives. For this
    reason, recall is a useful metric in models in which we don’t want many false
    negatives, such as models for medical diagnosis.
  id: totrans-276
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 召回率衡量模型正确预测的正点数。当模型产生许多假阴性时，召回率会很低。因此，在我们不希望有太多假阴性的模型中，如医学诊断模型，召回率是一个有用的指标。
- en: Precision measures how many of the points that the model predicted as positive
    are actually positive. Precision is low when the model creates many false positives.
    For this reason, precision is a useful metric in models in which we don’t want
    many false positives, such as spam email models.
  id: totrans-277
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精度衡量模型预测为正点的点中，实际上有多少是正点。当模型产生许多误报时，精度会很低。因此，在我们不希望有太多误报的模型中，如垃圾邮件模型，精度是一个有用的指标。
- en: '*F*[1]-score is a useful metric that combines recall and precision. It returns
    a value in between recall and precision but which is closer to the smaller of
    the two.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*F*[1]-分数是一个有用的指标，它结合了召回率和精度。它返回一个介于召回率和精度之间的值，但更接近于两者中较小的一个。'
- en: '*F*[β]-score is a variation of *F*[1]-score, in which one can adjust the parameter
    *β* to give either precision or recall a higher importance. Higher values of *β*
    give recall more importance, and lower values of *β* give precision more importance.
    *F*[β]-score is particularly useful to evaluate models in which either precision
    or recall is more important than the other one, but we still care about both metrics.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*F*[β]-分数是 *F*[1]-分数的一种变体，其中可以调整参数 *β* 以给予精度或召回更高的权重。*β* 的值越高，召回的重要性就越大，而 *β*
    的值越低，精度的重要性就越大。*F*[β]-分数特别适用于评估精度或召回比另一个更重要，但我们仍然关心这两个指标的模型。'
- en: Sensitivity and specificity are two useful metrics that help us evaluate models.
    They are highly used in medical fields.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 灵敏度和特异性是两个有用的指标，帮助我们评估模型。它们在医学领域被高度使用。
- en: Sensitivity, or true positive ratio, measures how many of the positive points
    were correctly predicted by the model. Sensitivity is low when the model creates
    many false negatives. For this reason, sensitivity is a useful metric to use in
    medical models where we don’t want to accidentally leave many healthy patients
    without treatment.
  id: totrans-281
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 灵敏度，或真正正例比率，衡量模型正确预测了多少个正例。当模型产生许多假阴性时，灵敏度会很低。因此，在医疗模型中，我们不想意外地让许多健康患者得不到治疗时，灵敏度是一个有用的指标。
- en: Specificity, or true negative ratio, measures how many of the negative points
    were correctly predicted by the model. Specificity is low when the model creates
    many false positives. For this reason, specificity is a useful metric in medical
    models where we don’t want to accidentally treat or do further invasive tests
    on patients who are healthy.
  id: totrans-282
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特异性，或真正负例比率，衡量模型正确预测了多少个负例。当模型产生许多假阳性时，特异性会很低。因此，在医疗模型中，我们不想意外地治疗或对健康患者进行进一步侵入性测试时，特异性是一个有用的指标。
- en: Recall and sensitivity are the exact same thing. However, precision and specificity
    are not the same thing. Precision makes sure that most of the predicted positives
    are truly positive, and specificity checks that most of the true negatives have
    been detected.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 召回率和灵敏度是同一回事。然而，精度和特异性不是同一回事。精度确保大多数预测的正例确实是正例，而特异性检查大多数真正负例是否已经被检测到。
- en: As we increase the threshold in a model, we decrease its sensitivity and increase
    its specificity.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们提高模型中的阈值时，我们降低其灵敏度并提高其特异性。
- en: The ROC, or receiver operating characteristic curve, is a useful graph that
    helps us keep track of the sensitivity and specificity of the model for each different
    value of the threshold.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ROC，或接收者操作特征曲线，是一个有用的图表，帮助我们跟踪模型在每个不同阈值下的灵敏度和特异性。
- en: The ROC also helps us determine how good a model is, using the area under the
    curve, or AUC. The closer the AUC is to 1, the better the model. The closer the
    AUC is to 0.5, the worse the model.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ROC（接受者操作特征曲线）也帮助我们确定模型的好坏，使用曲线下的面积，或AUC。AUC越接近1，模型越好。AUC越接近0.5，模型越差。
- en: By looking at the ROC curve, we can make decisions on what threshold to use
    to give us good values for both the sensitivity and the specificity, depending
    on how much of each our model expects. This makes the ROC curve one of the most
    popular and useful ways to evaluate and improve a model.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过观察ROC曲线，我们可以根据模型对每种值的预期来决定使用什么阈值，以同时获得灵敏度和特异性的良好值。这使得ROC曲线成为评估和改进模型最受欢迎和最有用的一种方式。
- en: Exercises
  id: totrans-288
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习
- en: Exercise 7.1
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 7.1
- en: A video site has established that a particular user likes animal videos and
    absolutely nothing else. In the next figure, we can see the recommendations that
    this user got when logging in to the site.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 一个视频网站已经确定一个特定的用户喜欢动物视频，而且绝对没有其他喜好。在下图中，我们可以看到当用户登录网站时收到的推荐。
- en: '![](../Images/7-unnumb-2.png)'
  id: totrans-291
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7-unnumb-2.png)'
- en: 'If this is all the data we have on the model, answer the following questions:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这是我们关于模型的所有数据，回答以下问题：
- en: What is the accuracy of the model?
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型的准确度是多少？
- en: What is the recall of the model?
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型的召回率是多少？
- en: What is the precision of the model?
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型的精度是多少？
- en: What is the *F*[1]-score of the model?
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型的 *F*[1]-分数是多少？
- en: Would you say that this is a good recommendation model?
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你会说这是一个好的推荐模型吗？
- en: Exercise 7.2
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 7.2
- en: 'Find the sensitivity and specificity of the medical model with the following
    confusion matrix:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 找出以下混淆矩阵中医疗模型的灵敏度和特异性：
- en: '|  | Predicted sick | Predicted healthy |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '|  | 预测患病 | 预测健康 |'
- en: '| Sick | 120 | 22 |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '| 患病 | 120 | 22 |'
- en: '| Healthy | 63 | 795 |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '| 健康 | 63 | 795 |'
- en: Exercise 7.3
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 7.3
- en: For the following models, determine which error is worse, a false positive or
    a false negative. Based on that, determine which of the two metrics, precision
    or recall, we should emphasize on when evaluating each of the models.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 对于以下模型，确定哪种错误更严重，是假阳性还是假阴性。基于此，确定在评估每个模型时，我们应该强调哪个指标，是精确度还是召回率。
- en: A movie-recommendation system that predicts whether a user will watch a movie
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一种电影推荐系统，预测用户是否会观看电影
- en: An image-detection model used in self-driving cars that detects whether an image
    contains a pedestrian
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一种用于自动驾驶汽车中的图像检测模型，用于检测图像中是否包含行人
- en: A voice assistant at home that predicts whether the user gave it an order
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一种预测用户是否向其下达命令的家庭语音助手
- en: Exercise 7.4
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 7.4
- en: 'We are given the following models:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 我们被赋予以下模型：
- en: A self-driving car model for detecting a pedestrian based on the image from
    the car’s camera
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一种基于汽车摄像头图像检测行人的自动驾驶汽车模型
- en: A medical model for diagnosing a deadly illness based on the patient’s symptoms
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一种基于患者症状诊断致命疾病的医学模型
- en: A recommendation system for movies based on the user’s previous movies watched
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一种基于用户之前观看的电影的电影推荐系统
- en: A voice assistant that determines whether the user needs assistance given the
    voice command
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一种根据语音命令确定用户是否需要帮助的语音助手
- en: A spam-detection model that determines whether an email is spam based on the
    words in the email
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一种基于电子邮件中单词确定电子邮件是否为垃圾邮件的垃圾邮件检测模型
- en: We are given the task of evaluating these models using *F*[β]-scores. However,
    we haven’t been given the values of *β* to use. What value of *β* would you use
    to evaluate each of the models?
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 我们被赋予的任务是使用 *F*[β]-分数来评估这些模型。然而，我们没有给出要使用的 *β* 值。您会使用什么 *β* 值来评估每个模型？
