- en: 8 Quality control for data annotation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8 数据标注的质量控制
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Calculating the accuracy of an annotator compared with ground truth data
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算标注者与真实数据之间的准确性
- en: Calculating the overall agreement and reliability of a dataset
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算数据集的整体一致性和可靠性
- en: Generating a confidence score for each training data label
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为每个训练数据标签生成置信度分数
- en: Incorporating subject-matter experts into annotation workflow
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将主题专家纳入标注工作流程
- en: Breaking a task into simpler subtasks to improve annotation
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将任务分解成更简单的子任务以改进标注
- en: You have your machine learning model ready to go, and you have people lined
    up to annotate your data, so you are almost ready to deploy! But you know that
    your model is going to be only as accurate as the data that it is trained on,
    so if you can’t get high-quality annotations, you won’t have an accurate model.
    You need to give the same task to multiple people and take the majority vote,
    right?
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 您的机器学习模型已经准备就绪，您也安排了人员来标注您的数据，所以您几乎可以部署了！但您知道，您的模型将只与它所训练的数据一样准确，所以如果您无法获得高质量的数据标注，您将不会有一个准确的模型。您需要将相同的任务分配给多个人，并取多数人的意见，对吧？
- en: Unfortunately, your annotation task is probably much harder. I’ve seen annotation
    underestimated more often than any other part of the human-in-the-loop machine
    learning cycle. Even if you have a simple labeling task—such as deciding whether
    an image contains a pedestrian, an animal, a cyclist, or a sign—how do you decide
    on the right threshold for majority agreement among annotators when all those
    annotators have seen different combinations of tasks? How do you know when your
    overall agreement is so low that you need to change your guidelines or the way
    you define your task? The statistics to calculate agreement in even the simpler
    labeling tasks are more advanced than the statistics underlying most neural models,
    so understanding them takes time and practice.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，您的标注任务可能要困难得多。我见过标注被低估的情况比机器学习循环中任何其他部分都要多。即使您有一个简单的标注任务——比如决定一张图片是否包含行人、动物、骑自行车的人或标志——当所有这些标注者都看到了不同的任务组合时，您如何决定标注者之间多数一致性的正确阈值？您如何知道当整体一致性如此低时，您需要改变您的指南或定义任务的方式？即使在简单的标注任务中计算一致性的统计方法也比大多数神经模型背后的统计方法更高级，因此理解它们需要时间和实践。
- en: This chapter and the next two chapters use the concepts of *expected* and *actual*
    annotation accuracy. If, for example, someone guessed randomly for each annotation,
    we would expect them to get some percentage correct, so we adjust the actual accuracy
    to account for a baseline of random chance. The concepts of *expected* and *actual*
    behavior apply to many types of tasks and annotation scenarios.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章和接下来的两章使用*预期*和*实际*标注准确性的概念。例如，如果有人对每个标注随机猜测，我们预计他们会得到一定比例的正确答案，因此我们将实际准确率调整以考虑随机机会的基础线。*预期*和*实际*行为的概念适用于许多类型的任务和标注场景。
- en: 8.1 Comparing annotations with ground truth answers
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.1 将标注与真实答案进行比较
- en: 'The simplest method for measuring annotation quality is also one of the most
    powerful: compare the responses from each annotator with a set of known answers,
    called *ground truth answers.* An annotator might annotate 1,000 items, of which
    100 have known answers. If the annotator gets 80 of those known answers correct,
    you can estimate that they are 80% accurate over the 1,000 items.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 测量标注质量的最简单方法也是最强大的方法之一：将每个标注者的响应与一组已知答案（称为*真实答案*）进行比较。一个标注者可能会标注1,000个项目，其中100个有已知答案。如果标注者正确地回答了其中80个已知答案，那么您可以估计他们在1,000个项目中的准确率是80%。
- en: You can implement the creation of ground truth data incorrectly in many ways,
    however, and unfortunately almost all errors make your dataset appear to be more
    accurate than it is. If you are creating your evaluation data and training data
    at the same time and don’t have good quality controls, you will end up with the
    same kinds of errors in both your training data and evaluation data. The resulting
    model may predict the wrong label in some contexts, but the ground truth evaluation
    data will have the same type of errors, so you may not realize that you have the
    errors until you deploy your application and it fails.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，你可以以许多方式错误地实现真实数据的创建，而且不幸的是，几乎所有错误都会使你的数据集看起来比实际更准确。如果你在创建评估数据和训练数据的同时没有良好的质量控制，你将在训练数据和评估数据中遇到相同类型的错误。结果模型可能在某些上下文中预测错误的标签，但真实数据评估将具有相同类型的错误，因此你可能直到部署你的应用程序并失败之前都不会意识到你有错误。
- en: 'The most common cause of errors is wrong items sampled for ground truth. Three
    general sampling strategies identify the items that should become ground truth
    data:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 错误的最常见原因是采样了错误的项目作为真实数据。三种一般的采样策略识别出应该成为真实数据的项目：
- en: '*A random sample of data*—You should evaluate the accuracy of your individual
    annotators on random data. If a random selection isn’t possible, or if you know
    that a random sample is not representative of the population that your application
    is serving, you should try to get a sample that is as close to representative
    as possible.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据的一个随机样本*——你应该评估你的单个标注者在随机数据上的准确性。如果随机选择不可行，或者如果你知道随机样本不能代表你的应用程序所服务的群体，你应该尝试获取尽可能接近代表性的样本。'
- en: '*A sample of data with the same distribution of features and labels as the
    batch of data that is being annotated*—If you are using active learning, this
    sample should be a random sample from your current iteration of active learning,
    which allows you to calculate the (human) accuracy of each sample of data and,
    by extension, the accuracy of the dataset as a whole.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*与正在标注的数据批次具有相同特征和标签分布的数据样本*——如果你正在使用活动学习，这个样本应该是你当前活动学习迭代的随机样本，这允许你计算每个数据样本的（人工）准确性，以及由此推断出整个数据集的准确性。'
- en: '*A sample of data found during the annotation process that is most useful for
    annotation guidelines*—These guidelines often exemplify important edge cases that
    are useful for teaching the annotators to be as accurate as possible.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在标注过程中找到的数据样本，这些样本对于标注指南非常有用*——这些指南通常举例说明了重要的边缘情况，这些情况对于教导标注者尽可能准确非常有用。'
- en: Within our diagram for human-in-the-loop architectures, if we zoom in on the
    annotation component, we see that the workflow is a little more complicated than
    the high-level diagram shown in figure 8.1.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的人类在环架构图中，如果我们放大查看标注组件，我们会发现工作流程比图8.1中展示的高级图要复杂一些。
- en: '![](../Images/CH08_F01_Munro.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F01_Munro.png)'
- en: Figure 8.1 The flow of information for annotation. In addition to taking data
    sampled according to our current active learning strategies, we sample a random
    or representative set of data and data that some annotators have already seen.
    Sampling random/representative data lets us calculate the accuracy of annotators
    in a way that makes it easier to determine their reliability across datasets and
    whether they are candidates for promotion to experts. Sampling within the current
    active learning batch allows us to calculate the accuracy for this particular
    dataset. Sampling during the annotation process finds items that are most useful
    for annotation guidelines and for adjudication by experts.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1 标注的信息流。除了根据我们当前的活动学习策略采样的数据外，我们还采样了一组随机或代表性的数据以及一些标注者已经看到的数据。采样随机/代表性数据使我们能够以使确定标注者在数据集间的可靠性以及他们是否是晋升为专家的候选人为易的方式计算标注者的准确性。在当前的活动学习批次中进行采样，使我们能够计算特定数据集的准确性。在标注过程中进行采样，找到对标注指南和专家裁决最有用的项目。
- en: To be confident that your ground truth items are as accurate as possible, you
    need to draw on many of the methods in this chapter and possibly the next two
    chapters. You must be confident that your ground truth items have few errors;
    otherwise, you will create misleading guidelines and won’t have reliable accuracy
    metrics, resulting in bad training data. You can’t cut corners. If your ground
    truth items are only items that had the highest agreement, you are likely to have
    oversampled the easiest items to annotate, which will make your accuracy look
    better than it is.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保你的真实标签尽可能准确，你需要借鉴本章以及可能的后两章中的许多方法。你必须确信你的真实标签错误很少；否则，你会创建误导性的指南，并且不会有可靠的准确度指标，从而导致训练数据质量差。你不能走捷径。如果你的真实标签只是那些达成高度一致的项目，你很可能会过度采样最容易标注的项目，这会使你的准确度看起来比实际更好。
- en: When you have a ground truth dataset that you can use to evaluate each annotator,
    you can calibrate your annotation projects to be higher-quality and more efficient.
    Using interannotator agreement for quality control also becomes much more effectively
    with a small but reliable ground truth dataset to support it. As chapter 9 shows,
    you can still get reliable signals from the least accurate annotator when you
    know their pattern of errors.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 当你有一个可以用来评估每个标注员的真实标签数据集时，你可以调整你的标注项目以使其质量更高、效率更高。使用标注员间的一致性进行质量控制，在有少量但可靠的真实标签数据集的支持下，也会变得更加有效。正如第9章所示，当你知道他们的错误模式时，即使是最不准确的标注员也能提供可靠的信号。
- en: '![](../Images/CH08_F02_Munro.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![图8.2](../Images/CH08_F02_Munro.png)'
- en: Figure 8.2 Throughout the remainder of this chapter and in chapters 9 and 10,
    we will use this example data. Five annotators—named Alex, Blake, Cameron, Dancer,
    and Evan—have annotated an image according to the object in that image. We will
    assume that the image is the same type that was used in previous chapters, with
    four labels, “Animal,” “Cyclist,” “Pedestrian,” and “Sign.” In this example, Alex
    has seen seven images (tasks 1, 3, 5, 6, 7, 8, and 9); annotated the first three
    as “Pedestrian”; and annotated each of the rest as “Cyclist,” “Pedestrian,” “Animal,”
    or “Sign.” The image on the right shows what the annotation interface might look
    like.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2在本章的剩余部分以及第9章和第10章中，我们将使用这个示例数据。五位标注员——名为Alex、Blake、Cameron、Dancer和Evan——根据图像中的对象标注了一张图片。我们将假设这张图片与之前章节中使用的图片类型相同，有四个标签：“动物”、“骑自行车的人”、“行人”和“标志”。在这个例子中，Alex看到了七张图片（任务1、3、5、6、7、8和9）；将前三张标注为“行人”；将剩下的每张标注为“骑自行车的人”、“行人”、“动物”或“标志”。右边的图片显示了标注界面的可能外观。
- en: In this chapter and chapter 9, we will use the example data shown in figure
    8.2\. Although your datasets will have many more items than the 11 rows in figure
    8.2, these 11 rows are enough for learning the kinds of quality controls that
    you might implement. We will use different variations of the correct answer for
    the data in figure 8.2 throughout this chapter but keep the annotations the same
    as in the figure. For this section, let’s assume that we had ground truth labels
    for each of these examples.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章和第9章中，我们将使用图8.2中显示的示例数据。尽管你的数据集可能比图8.2中的11行包含更多的项目，但这11行足以让你学习可能实施的质量控制类型。在本章中，我们将使用图8.2中数据的正确答案的不同变体，但保持注释与图中的相同。对于本节，让我们假设我们为这些示例中的每一个都提供了真实标签。
- en: What should you call an annotator?
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该如何称呼标注员？
- en: Many terms are used for a person who creates training and evaluation data, including
    rater, *coder, adjudicator, agent, assessor, editor, judge, labeler, oracle, worker*,
    and *turker* (from the Mechanical Turk platform, sometimes used for other software).
    In industry, the annotator might go by their job title, such as *analyst*, by
    the skill they are using, such as *linguist*, or by their employment status, such
    as *contractor* or *gig-economy worker*. In other cases, an annotator is referred
    to as a *subject-matter expert*, sometimes truncated to *expert* or to the acronym
    *SME* (pronounced “smee”).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 对于创建训练和评估数据的人，有许多术语，包括评分员、*编码员、裁决员、代理、评估员、编辑、裁判、标签员、先知、工人*和*Turker*（来自Mechanical
    Turk平台，有时用于其他软件）。在工业界，标注员可能以他们的职位名称，如*分析师*，他们使用的技能，如*语言学家*，或他们的就业状态，如*承包商*或*零工经济工作者*来称呼自己。在其他情况下，标注员被称为*主题专家*，有时缩写为*专家*或缩写词*SME*（发音为“smee”）。
- en: If you are searching for additional reading, make sure to try the different
    names as search terms. You might find similar papers on *interannotator agreement*,
    *inter-rater agreement*, and *intercoder agreement*, for example.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在寻找额外的阅读材料，请确保尝试不同的名称作为搜索词。您可能会找到关于*注解员间一致性*、*评分者间一致性*和*编码者间一致性*等类似论文。
- en: This book uses the term *annotator* because it is the least likely to be confused
    with any other role. If you’re working with people who annotate data, use the
    correct title for that person in your organization. This book also avoids saying
    *training* annotators (to eliminate confusion with training a model) and uses
    terms such as *guidelines* and *instructions* instead of *training materials*.
    Again, use the preferred description in your organization for the process of teaching
    annotators the instructions for a given task.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 本书使用“注解员”这个术语，因为它最不可能与其他角色混淆。如果您与注解数据的人合作，请使用您组织中该人员的正确头衔。本书还避免使用“训练”注解员（以消除与训练模型混淆）的说法，并使用诸如“指南”和“说明”之类的术语代替“培训材料”。再次提醒，请使用您组织中该过程的首选描述来教授注解员特定任务的说明。
- en: 8.1.1 Annotator agreement with ground truth data
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1.1 注解员与真实数据的一致性
- en: 'The basic math for agreement with ground truth data in labeling tasks is simple:
    the percentage of known answers that an annotator scored correctly. Figure 8.3
    gives hypothetical accuracy for each annotator on our example data.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 标签任务中与真实数据一致性的基本数学很简单：注解员正确评分的已知答案的百分比。图8.3给出了我们示例数据中每个注解员的假设准确度。
- en: '![](../Images/CH08_F03_Munro.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F03_Munro.png)'
- en: Figure 8.3 An example of annotator accuracy compared with ground truth data.
    Assume that the Ground Truth column has the known answers for each task (image
    labels). We calculate each annotator’s accuracy as the fraction that they got
    correct.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.3 注解员准确度与真实数据对比的示例。假设真实数据列包含每个任务的已知答案（图像标签）。我们计算每个注解员的准确度为他们正确回答的比例。
- en: You typically want to adjust results like those in figure 8.3 according to a
    baseline of random chance guessing. We can calculate three baselines for our random-chance
    labeling. Let’s assume that 75% of the images are “Pedestrian,” 10% are “Sign,”
    10% are “Cyclist,” and 5% are “Animal.” The three baselines are
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，您希望根据随机猜测的基线调整如图8.3所示的结果。我们可以为我们随机机会标签计算三个基线。假设75%的图像是“行人”，10%是“标志”，10%是“骑自行车的人”，5%是“动物”。这三个基线是
- en: '*Random*—The annotator guesses one of the four labels. This baseline is 25%
    in our example data because we have four labels.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*随机*—注解员猜测四个标签中的一个。在我们的示例数据中，这个基线是25%，因为我们有四个标签。'
- en: '*Most frequent label (mode label)*—The annotator knows that “Pedestrian” is
    the most frequent label, so they always guess that label. This baseline is 75%.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*最频繁的标签（众数标签）*—注解员知道“行人”是最频繁的标签，因此他们总是猜测这个标签。这个基线是75%。'
- en: '*Data frequency*—The annotator guesses according to the frequency of each label.
    They guess “Pedestrian” 75% of the time, “Sign” 10% of the time, and so on. This
    baseline can be calculated as the sum of the squares of each probability.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据频率*—注解员根据每个标签的频率进行猜测。他们75%的时间猜测“行人”，10%的时间猜测“标志”，等等。这个基线可以计算为每个概率平方的和。'
- en: Figure 8.4 shows the calculations.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.4显示了计算过程。
- en: '![](../Images/CH08_F04_Munro.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F04_Munro.png)'
- en: Figure 8.4 The three calculations for different accuracies that would be expected
    through random chance, showing a wide range of expected accuracy depending on
    what baseline we use
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.4 通过随机机会预期不同准确度的三种计算，显示根据我们使用的基线，预期准确度范围广泛。
- en: The adjusted accuracy normalizes the annotator’s score so that the baseline
    from random guessing becomes 0\. Let’s assume that someone had 90% accuracy overall.
    Their actual accuracy, adjusted for chance, is shown in figure 8.5.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 调整后的准确度将注解员的分数进行标准化，使得随机猜测的基线变为0。假设某人的总体准确度为90%。他们的实际准确度，经过机会调整，如图8.5所示。
- en: '![](../Images/CH08_F05_Munro.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F05_Munro.png)'
- en: 'Figure 8.5 Different ways of establishing a baseline expected from random guessing
    or chance-adjusted accuracy when testing annotators against ground truth data.
    *Top*: How we normalize the result. If someone was randomly choosing a label,
    they would sometimes pick the correct one, so we measure accuracy in terms of
    distance between the random accuracy and 1\. *Bottom*: How the different adjusted
    accuracies look with our example data. Note that the normalized score of 60% accuracy
    for always guessing “Pedestrian” is different from the 90% raw accuracy score
    or 86.7% when normalized according to the number of labels. This example highlights
    why the correct baseline for expected accuracy is so important. There are cases
    in which each of the three baselines is the better choice, so it is important
    to know all three.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.5展示了在测试注释者与真实数据对比时，从随机猜测或机会调整的准确性中建立不同基线预期的方式。*顶部*：我们如何归一化结果。如果有人随机选择标签，他们有时会选中正确的标签，所以我们用随机准确性和1之间的距离来衡量准确性。*底部*：不同的调整准确性在我们的示例数据中的外观。请注意，总是猜测“行人”的60%准确率的归一化分数与90%的原始准确率分数或根据标签数量归一化时的86.7%不同。这个例子突出了为什么正确的预期准确性基线如此重要。在某些情况下，这三个基线中的每一个都是更好的选择，因此了解所有三个都是很重要的。
- en: As figure 8.5 shows, we have different ways to normalize the annotation counts.
    The most common one used in the statistics community is *data frequency* a datacentric
    way to think of expected behavior. It always falls between the random selection
    and the most frequent, so it has the nice property of being the safe middle option.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如图8.5所示，我们有不同的方法来归一化注释计数。在统计学界最常用的方法是*数据频率*，这是一种以数据为中心的方式来思考预期行为。它总是在随机选择和最频繁之间，因此它具有作为安全中间选项的优良特性。
- en: Because the expected baseline becomes zero, any result less than zero means
    that the person guessed worse than random chance. Typically, this result means
    that the annotator understood the instructions incorrectly or was scamming the
    system in a simple way, such as always guessing a response that isn’t the most
    frequent. In any of these cases, normalizing the baseline to zero gives us an
    easy way to set up alerts for any task. No matter what the task is, a negative
    score after adjusting for random chance should cause an alert in your annotation
    process!
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 因为预期的基线变为零，任何小于零的结果都意味着该人猜测的结果比随机机会更差。通常，这个结果意味着注释者没有正确理解指示，或者以简单的方式欺骗系统，例如总是猜测一个最不频繁的响应。在任何这些情况下，将基线归一化到零为我们提供了一个简单的方法来设置任何任务的警报。无论任务是什么，调整随机机会后的负分都应该在你的注释过程中引发警报！
- en: If you are familiar with the literature on quality control for annotation, you
    know that a metric that is normalized according to the expected behavior is often
    called *chance-corrected* or *chance-adjusted*. In many cases throughout this
    book, the expected behavior is not random chance, such as when we ask annotators
    what they expect other annotators to choose (chapter 9). The more general term
    *expected* is used for those cases, but for objective labeling tasks, *expected*
    and *chance* mean the same thing.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你熟悉关于注释质量控制的文献，你知道根据预期行为归一化的度量通常被称为*机会校正*或*机会调整*。在这本书的许多情况下，预期行为不是随机机会，例如当我们询问注释者他们期望其他注释者选择什么时（第9章）。对于这些情况，更一般的术语*预期*被使用，但对于客观标签任务，*预期*和*机会*意味着同一件事。
- en: 8.1.2 Which baseline should you use for expected accuracy?
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1.2 应该使用哪个基线来衡量预期的准确性？
- en: For the three baselines for expected accuracy—random, data frequency, and most
    frequent—calculating all three metrics will help with your intuition about the
    data. The right metric to normalize your accuracy will be specific to your task
    and the experience of the people labeling the data.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 对于预期的准确性三个基线——随机、数据频率和最频繁——计算所有三个度量将有助于你对数据的直观认识。用于归一化准确性的正确度量将具体取决于你的任务和标注数据的人的经验。
- en: When a person is first working on a task, they will not have intuition about
    which label is more frequent, so they are more likely to be closer to random labeling.
    But after some time, they realize that one label is much more frequent than the
    others and may feel safe guessing that label when they are uncertain. For that
    reason, chapter 11 is devoted entirely to user interfaces for annotation.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个人刚开始从事一项任务时，他们不会对哪个标签更频繁有直观的认识，因此他们更有可能接近随机标签。但过了一段时间后，他们会意识到其中一个标签比其他标签更频繁，并且在不确定时可能会感到安全地猜测那个标签。因此，第11章完全致力于注释的用户界面。
- en: 'My practical recommendation is to wait until an after annotator becomes familiar
    with a task and then apply the strictest baseline: the most frequent label. You
    can consider the first few minutes, hours, or days of your task to be a ramp-up
    period for the annotator to become familiar. When an annotator has a strong intuition
    about the data, they will be taking the relative frequency of the labels into
    account. As you will see in section 8.2.3, however, data frequency is more relevant
    for calculating agreement at the level of the entire dataset. So it’s important
    to understand all the baselines and apply them at the right time.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我的实际建议是在标注员熟悉一项任务后再应用最严格的基线：最频繁的标签。您可以将任务的最初几分钟、几小时或几天视为标注员熟悉任务的预热期。当标注员对数据有强烈的直觉时，他们会考虑标签的相对频率。然而，如第8.2.3节所示，数据频率对于计算整个数据集层面的协议更为相关。因此，了解所有基线并在正确的时间应用它们是很重要的。
- en: Good quality control for data annotation can take a lot of resources and should
    be factored into your budget. See the following sidebar for an example of how
    quality control led to the engagement of a different set of annotators for a project.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对数据标注进行高质量控制可能需要大量资源，并且应该纳入您的预算考虑。请参阅以下侧边栏，了解质量控制如何导致为项目聘请了不同的一组标注员。
- en: Consider the total cost of annotation projects
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑标注项目的总成本
- en: '*Expert anecdote by Matthew Honniba*l'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*马修·霍尼巴尔的专家轶事*'
- en: It helps to communicate directly with the people who are annotating your data,
    like anyone else in your organization. Inevitably, some of your instructions won't
    work in practice, and you will need to work closely with your annotators to refine
    them. You’re also likely to keep refining the instructions and adding annotations
    long after you go into production. If you don’t take the time to factor in refining
    the instructions and discarding wrongly labeled items, it is easy to end up with
    an outsourced solution that looked cheap on paper but was expensive in practice.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 与标注您数据的个人直接沟通是有帮助的，就像与您组织中的任何其他人一样。不可避免的是，您的一些指示在实际操作中可能不起作用，您需要与标注员紧密合作来完善它们。您也可能在生产开始后继续完善指示和添加标注。如果您不花时间考虑完善指示和丢弃错误标记的项目，很容易得到一个表面上看起来很便宜但实际上很昂贵的外包解决方案。
- en: In 2009, I was part of a joint project between the University of Sydney and
    a major Australian news publisher that required named entity recognition, named
    entity linking, and event linking. Although academics were increasingly using
    crowdsourced workers at that time, we instead built a small team of annotators
    that we contracted directly. This ended up being much cheaper in the long run,
    especially for the more complicated “entity linking” and “event linking” tasks
    where crowdsourced workers struggled and our annotators were helped by working
    and communicating with us directly.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 2009年，我参与了悉尼大学和一家主要澳大利亚新闻出版商之间的联合项目，该项目需要命名实体识别、命名实体链接和事件链接。尽管当时学术界越来越多地使用众包工作者，但我们还是直接建立了一个小型标注员团队。从长远来看，这最终证明要便宜得多，尤其是在对于众包工作者难以应对的更复杂的“实体链接”和“事件链接”任务中，我们的标注员通过与我们的直接工作和沟通得到了帮助。
- en: '*Matthew Honnibal is creator of the spaCy NLP library and co-founder of Explosion.
    He has been working on NLP research since 2005*.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '*马修·霍尼巴是spaCy NLP库的创建者和Explosion的联合创始人。自2005年以来，他一直在从事NLP研究*。'
- en: 8.2 Interannotator agreement
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.2 标注者间一致性
- en: When data scientists talk about their machine learning models being more accurate
    than people, they often mean that the models are more accurate than the average
    person. Speech recognition technologies, for example, are now more accurate than
    the average English speaker for nontechnical transcription in common accents.
    How can we evaluate the quality of these speech recognition technologies if humans
    can’t create evaluation data with that level of accuracy?
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据科学家谈论他们的机器学习模型比人更准确时，他们通常意味着模型比普通人更准确。例如，语音识别技术现在在非技术性转录的常见口音中比普通英语说话者更准确。如果人类无法以这种准确度创建评估数据，我们如何评估这些语音识别技术的质量？
- en: 'The “wisdom of the crowd” produces data that is more accurate than any one
    human. For more than a century, people have studied how to aggregate the judgments
    of multiple people into a single, more accurate result. In the earliest examples,
    it was famously shown that when multiple people guess the weight of a cow, the
    average of all the guesses was close to correct. That result doesn’t mean that
    everyone was less accurate than average: individuals will guess the weight of
    a cow more accurately than the average, but the average guess was closer to the
    real weight than most people.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: “群众的智慧”产生的数据比任何单个人类更准确。一个多世纪以来，人们一直在研究如何将多人的判断汇总成一个更准确的结果。在最早的例子中，有著名的研究表明，当多人猜测一头牛的重量时，所有猜测的平均值接近正确。这个结果并不意味着每个人的准确性都低于平均值：个人猜测牛的重量可能比平均值更准确，但平均猜测比大多数人更接近真实重量。
- en: So when data scientists brag that their model is more accurate than humans,
    they often mean that their model is more accurate than the agreement among the
    annotators, which is called *interannotator agreement*. Model accuracy and annotator
    agreement are two different numbers that shouldn’t be compared directly, so try
    to avoid making this common mistake.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当数据科学家吹嘘他们的模型比人类更准确时，他们通常意味着他们的模型比标注者之间的一致性更准确，这被称为*标注者间一致性*。模型准确性和标注者一致性是两个不同的数字，不应直接比较，因此请尽量避免犯这个常见错误。
- en: It is possible, however, to create training data that is more accurate than
    every individual person who contributed to annotations, and this chapter returns
    to this topic in section 8.3 after introducing the basics.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有可能创建比所有参与标注的个体更准确的训练数据，本章在介绍基础知识后，将在第8.3节回到这个话题。
- en: 8.2.1 Introduction to interannotator agreement
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.1 标注者间一致性简介
- en: Interannotator agreement is typically calculated on a –1 to 1 scale, where 1
    is perfect agreement, –1 is perfect disagreement, and 0 is random-chance labeling.
    We calculate the agreement by asking how much better our agreement is than expected,
    similar to our earlier individual annotator accuracy score, but in this case for
    agreement. Figure 8.6 shows an example.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 标注者间一致性通常在-1到1的范围内计算，其中1是完全一致，-1是完全不一致，0是随机标签。我们通过询问我们的协议比预期好多少来计算一致性，类似于我们之前提到的单个标注者准确度评分，但在此情况下是针对一致性。图8.6展示了示例。
- en: '![](../Images/CH08_F06_Munro.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F06_Munro.png)'
- en: Figure 8.6 How agreement metrics are calculated. Agreement is typically on a
    –1 to 1 scale, where 1 is perfect agreement, –1 is perfect disagreement, and 0
    is random distribution. The resulting agreement is variously known as *actual
    agreement, adjusted agreement*, or *agreement adjusted for random chance*.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.6展示了如何计算一致性指标。一致性通常在-1到1的范围内，其中1是完全一致，-1是完全不一致，0是随机分布。这种一致性结果被称为*实际一致性、调整后一致性*或*随机机会调整后的一致性*。
- en: Figure 8.6 shows how we calculate agreement that takes random chance agreement
    into account. This adjustment is similar to adjusting accuracy according to ground
    truth answers, but in this case, it compares annotators.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.6展示了如何计算考虑随机机会一致性的方法。这种调整类似于根据真实答案调整准确度，但在此情况下，它是比较标注者。
- en: We cover different types of interannotator agreement in this book, including
    overall agreement at the level of the entire dataset, individual agreement between
    annotators, agreement between labels, and agreement on a per-task basis. The concepts
    are fairly simple, and we will start with the simple naive agreement algorithm
    in figure 8.7\. This algorithm is so simple that you shouldn’t use it, but it
    is a useful starting point for understanding the equations in this chapter and
    the next two chapters.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 本书涵盖了不同类型的标注者间一致性，包括整个数据集层面的总体一致性、标注者之间的个体一致性、标签间的一致性以及基于每个任务的特定一致性。这些概念相对简单，我们将从图8.7中的简单朴素一致性算法开始介绍。这个算法非常简单，以至于你不应该使用它，但它理解本章及下一章中方程的有用起点。
- en: '![](../Images/CH08_F07_Munro.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F07_Munro.png)'
- en: Figure 8.7 A naive way to find agreement per annotator, agreement per task,
    and overall agreement for the entire set of annotations. We calculate the expected
    agreement in terms of randomly selecting one of four labels. We calculate the
    agreements for each task in the large middle table. We derive the per-person and
    per-task agreements from the Agreements table. We derive the overall agreement
    by using the combination of the expected and the average task-level agreement.
    Although you shouldn’t use this method for your actual data, because it is too
    simple, the diagram is useful for highlighting the concepts.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.7 以一种天真方式找到每个标注者的协议、每个任务的协议以及整个标注集的整体协议。我们以随机选择四个标签中的一个来计算预期一致性。我们在中间的大表中计算每个任务的协议。我们从协议表中推导出每个人的和每个任务的协议。我们通过结合预期和平均任务级协议来推导出整体协议。尽管你不应该用这种方法处理你的实际数据，因为它太简单了，但这个图对于突出概念是有用的。
- en: 'Figure 8.7 shows the basic idea behind three types of agreements. Although
    all of these calculations are sensible, they fall short a little. Here are some
    shortcomings of figure 8.7, highlighting the complications in calculating agreement:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.7展示了三种类型一致性的基本思想。尽管所有这些计算都是合理的，但它们在某种程度上有所不足。以下是图8.7的一些不足之处，突出了计算一致性中的复杂性：
- en: The overall expected agreement is based on the number of labels, but some labels
    are more frequent than others. If a fifth label was never chosen, it would seem
    strange to reduce the overall expected agreement as a result.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总体预期一致性基于标签数量，但有些标签比其他标签更常见。如果第五个标签从未被选择，那么由于这个原因降低总体预期一致性似乎是不合适的。
- en: The person agreement seems to unfairly penalize people for errors that other
    people make on the same task. Evan, for example, always agrees with the majority
    vote for the label but has the second-lowest agreement score.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 个人一致性似乎不公平地惩罚了人们在同一任务上犯的错误。例如，Evan总是同意多数投票的标签，但他的一致性得分是第二低的。
- en: The task agreement scores seem to be overly optimistic because they do not take
    into account the accuracy of individual annotators.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务一致性得分似乎过于乐观，因为它们没有考虑到个别标注者的准确性。
- en: The actual agreement averages the task agreement, but it would be much lower
    if we decided to calculate it by averaging the person agreement. What is the right
    way to aggregate the individual agreements to produce a more correct overall observed
    actual agreement?
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实际一致性平均了任务一致性，但如果我们决定通过平均个人一致性来计算，它将会低得多。正确汇总个人一致性以产生更准确的总体观察实际一致性的方法是什么？
- en: Task 11 has only one response, so it seems wrong to calculate the response as
    being 100% in agreement; there is nothing for that one response to agree with.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务11只有一个响应，所以将其计算为100%一致似乎是不正确的；对于这个响应来说，没有什么可以达成一致的地方。
- en: We are not tracking agreement for labels. Is “Pedestrian” more likely to be
    confused than “Sign,” for example?
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们没有跟踪标签的一致性。例如，“行人”是否比“标志”更容易混淆？
- en: We are not taking the overall number of annotations into account. Especially
    with a relatively small number of annotations, there might be artifacts of the
    data size (although this is less relevant for typical training datasets with thousands
    of items).
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们没有考虑总的标注数量。特别是在标注数量相对较少的情况下，可能会有数据规模的艺术品效应（尽管这对于典型的包含数千个项目的训练数据集来说不太相关）。
- en: You can play around with this implementation as a spreadsheet at [http://mng.bz/
    E2qj](http://mng.bz/E2qj). This spreadsheet also contains some of the other equations
    in this chapter.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这个电子表格中尝试这个实现，电子表格的链接是[http://mng.bz/ E2qj](http://mng.bz/E2qj)。这个电子表格还包含本章中的一些其他方程式。
- en: 'Sections 8.2.2 through 8.2.7 are dedicated to the best ways to address these
    issues. Although the math gets more complicated than anything you’ve seen so far
    in this book, keep in mind that it is solving one simple question:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 8.2.2至8.2.7节专门讨论了处理这些问题的最佳方法。尽管数学计算比本书中之前看到的任何内容都要复杂，但请记住，它解决的是一个简单的问题：
- en: '*How can we fairly calculate the agreement between annotators to evaluate the
    accuracy of our dataset, individual tasks, individual labels, or individual annotators*?'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们如何公平地计算标注者间的一致性来评估我们数据集、单个任务、单个标签或个别标注者的准确性*？'
- en: 8.2.2 Benefits from calculating interannotator agreement
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.2 计算标注者间一致性的好处
- en: 'You can use interannotator agreement as part of your human-in-the-loop machine
    learning strategy in multiple ways:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以用标注者间一致性作为你人类在环机器学习策略的一部分，以多种方式使用：
- en: '*The reliability of your dataset*—Do the annotators agree with one another
    often enough that you can rely on the labels that have been created? If not, you
    may need to redesign your instructions or the task as a whole.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*您数据集的可靠性*—标注者是否经常达成一致，以至于您可以依赖已经创建的标签？如果不是，您可能需要重新设计您的指示或整个任务。'
- en: '*The least reliable annotators*—Do any individual annotators disagree with
    the others too often? They may have misunderstood the task or may not be qualified
    to keep taking part. Either way, you may want to ignore their past annotations
    and potentially get new judgments. Alternatively, an unreliable annotator may
    in fact have valid but underrepresented annotations, especially for subjective
    tasks (see “Measuring natural variation” later in this list).'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*最不可靠的标注者*—是否有任何标注者与其他人太频繁地发生分歧？他们可能误解了任务，或者可能不具备继续参与的条件。无论如何，您可能想要忽略他们过去的标注，并可能获得新的判断。或者，一个不可靠的标注者实际上可能有一些有效但代表性不足的标注，尤其是在主观任务中（参见本列表后面的“测量自然变异”）。'
- en: '*The most reliable annotators*—The annotators with high agreement are likely
    to be the most accurate for your task, so identifying these people for potential
    reward and promotion is helpful.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*最可靠的标注者*—高度一致的标注者可能是您任务中最准确的人，因此识别这些人以获得潜在的奖励和晋升是有帮助的。'
- en: '*Collaboration between annotators*—Do any annotators agree nearly perfectly?
    They might be sharing notes innocently because they sit near one another, in which
    case you need to remove those responses from any calculations of agreement that
    assumes independence. On the other hand, this result may be evidence that a bot
    is duplicating one person’s work so that the person wrongly gets paid twice. Regardless
    of the underlying cause, it is helpful to know when two sets of answers are only
    one set that has been repeated.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*标注者之间的协作*—是否有任何标注者几乎完美地达成一致？他们可能因为坐得很近而无意中共享笔记，在这种情况下，您需要从任何假设独立性的协议计算中移除这些响应。另一方面，这个结果可能是证据表明一个机器人正在复制一个人的工作，使得这个人错误地得到了两次报酬。无论根本原因是什么，了解两组答案实际上只是一组重复的答案是有帮助的。'
- en: '*An annotator’s consistency over time*—If you give the same task to the same
    person at different times, do they give the same result? This metric, known as
    *intra-annotator agreement* can be evidence that an annotator is not paying attention,
    that your task has ordering effects, and/or that the task is inherently subjective.
    Also, the annotator may be genuinely changing their mind as they see more data,
    which is known as *concept evolution.*'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*标注者随时间的一致性*—如果您在不同的时间给同一个人相同的任务，他们是否给出相同的结果？这个指标，被称为*标注者内部一致性*，可以证明标注者没有注意，您的任务有顺序效应，以及/或者任务本质上是主观的。此外，标注者可能随着看到更多数据而真正改变主意，这被称为*概念演变*。'
- en: '*Creating examples for the instructions*—You can assume that items with high
    agreement among a large number of annotators are correct and let these items become
    examples in the guidelines for new annotators. Because you run two risks with
    this strategy—some errors will still get through and propagate, and only easier
    tasks will get through with higher agreement—you should not use it as your only
    strategy for creating ground truth data.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*为指示创建示例*—您可以假设在大量标注者之间高度一致的项目是正确的，并让这些项目成为新标注者指南中的示例。因为您使用这种策略有两个风险——一些错误仍然会通过并传播，并且只有更容易的任务会通过更高的协议——因此您不应将其作为创建地面真实数据的唯一策略。'
- en: '*Evaluating the inherent difficulty of a machine learning problem*—In general,
    if the task is hard for humans, it will be hard for your model. This information
    is especially helpful for adapting to new domains. If your data historically has
    90% agreement, but data from a new source has only 70% agreement, this result
    tells you to expect your model to be less accurate on data from that new source.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*评估机器学习问题的内在难度*—一般来说，如果任务对人类来说很难，那么对您的模型来说也会很难。这个信息对于适应新领域特别有帮助。如果您的数据历史上具有90%的一致性，但来自新来源的数据只有70%的一致性，这个结果告诉您，您的模型在来自那个新来源的数据上可能不太准确。'
- en: '*Measuring the accuracy of your dataset*—If you know the individual reliability
    of each annotator and how many people have annotated each item, you can calculate
    the probability that any given label will be annotated incorrectly. From this
    result, you can calculate the overall accuracy of your data. Taking individual
    annotator accuracy into account gives you a better upper boundary for the accuracy
    of a model that is trained on the data, compared with simple interannotator agreement.
    Models can be more or less sensitive to noise in the training data, so the limit
    is not a hard one. The limit *is* a hard limit on how precisely you can measure
    your model’s accuracy, because you can’t calculate your model’s accuracy to be
    higher than your dataset’s accuracy.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*测量数据集的准确性*—如果你知道每个注释者的个人可靠性以及有多少人注释了每个项目，你可以计算出任何给定标签被错误注释的概率。从这个结果中，你可以计算出数据的整体准确性。考虑个人注释者的准确性，与简单的注释者间一致性相比，为你提供了一个更好的模型准确性的上限。模型对训练数据中的噪声可能更敏感或不太敏感，所以这个限制并不是一个严格的限制。这个限制*是*一个严格的限制，即你如何精确地测量模型准确性的上限，因为你不能将模型的准确性计算得高于数据集的准确性。'
- en: '*Measuring natural variation*—For some datasets, lack of agreement is a good
    thing because it can indicate that multiple annotation interpretations are valid.
    If you have a task that is subjective, you may want to ensure that you have a
    diverse selection of annotators so that no one set of social, cultural, or linguistic
    backgrounds is inadvertently resulting in biased data.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*测量自然变异*—对于某些数据集，缺乏一致性是一件好事，因为它可以表明多个注释解释是有效的。如果你有一个主观的任务，你可能想确保你有多样化的注释者选择，这样就不会无意中导致数据存在偏见。'
- en: '*Escalating difficult tasks to experts*—This example was covered in chapter
    7, and we return to it again in section 8.5\. Low agreement between less-qualified
    workers might mean that the task should be routed to an expert automatically for
    review.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*将困难任务提升到专家级别*—这个例子在第7章中已经讨论过，我们再次在第8.5节中回到它。低资格的工人之间的低一致性可能意味着该任务应该自动路由给专家进行审查。'
- en: The remainder of section 8.2 contains some of the best current methods for calculating
    agreement in your data.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 8.2节剩余部分包含了计算数据集中一致性的最佳当前方法。
- en: Don’t use agreement as the only measure of accuracy
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 不要仅使用一致性作为准确性的唯一衡量标准
- en: 'You should not rely on interannotator agreement alone to find the correct label
    for your data; always use interannotator agreement in combination with ground
    truth data. Many data scientists resist this practice, because it means losing
    training data. If 5% of the labeled data is set aside for quality control, for
    example, they have 5% less data for their model to train on. Although no one likes
    having less training data, in the real world you can have the opposite effect:
    if you are relying on interannotator agreement alone for your labels, you will
    use more than 5% more human judgments because you can use ground truth data to
    calibrate your agreement better.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 你不应该仅依靠注释者间一致性来找到数据的正确标签；始终将注释者间一致性与真实数据结合使用。许多数据科学家反对这种做法，因为这意味着失去了训练数据。例如，如果5%的标记数据被留出用于质量控制，那么他们用于模型训练的数据就少了5%。虽然没有人喜欢训练数据减少，但在现实世界中，你可能会有相反的效果：如果你仅依靠注释者间一致性来获取标签，你将使用超过5%更多的人工判断，因为你可以使用真实数据来更好地校准你的一致性。
- en: Looking at agreement alone can also hide cases in which the wrong annotations
    agree. Without ground truth data, you won’t be able to calibrate for these errors.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 仅查看一致性也可能隐藏错误注释达成一致的情况。没有真实数据，你将无法对这些错误进行校准。
- en: On the other hand, agreement allows you to extend your accuracy analysis beyond
    what is practical with ground truth data alone, so you get the biggest benefits
    when you combine agreement with ground truth data. For example, you can calculate
    the accuray of each annotator with ground truth data and then use that accuracy
    as your confidence when aggregating multiple annotations for a task. This chapter
    and chapter 9 show many examples of combining agreement and ground truth data,
    depending on the problem you are solving, but they are introduced independently
    to explain the concepts in isolation.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，一致性允许你将准确度分析扩展到仅使用真实数据无法实现的范围之外，因此当你将一致性与真实数据结合使用时，你会获得最大的好处。例如，你可以使用真实数据计算每个注释者的准确性，然后使用这个准确性作为你在聚合多个注释进行任务时的置信度。本章和第9章展示了根据你解决的问题，结合一致性和真实数据的许多示例，但它们是独立引入的，以解释孤立的概念。
- en: 8.2.3 Dataset-level agreement with Krippendorff’s alpha
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.3 使用 Krippendorff 的 alpha 进行数据集级别的一致性
- en: '*Krippendorff’s* *alpha* is a method that aims to answer a simple question:
    what is the overall agreement in my dataset? To account for the fact that not
    every item will be annotated by every annotator, Krippendorff’s alpha made considerable
    advances on existing agreement algorithms that were popular in social sciences
    when used for tasks such as measuring the level of agreement in surveys and census
    data.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '*Krippendorff 的* *alpha* 是一种旨在回答简单问题的方法：我的数据集中整体一致性如何？为了考虑到并非每个项目都会被每个注释者标注的事实，Krippendorff
    的 alpha 在用于诸如测量调查和人口普查数据中的一致性水平等任务时，对现有的社会科学中流行的协议算法进行了重大改进。'
- en: 'The simple interpretation of Krippendorff’s alpha is that it is a [–1,1] range,
    which can be read as follows:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Krippendorff 的 alpha 简单解释是它是一个 [–1,1] 范围，可以如下阅读：
- en: '*>0.8*—This range is reliable. If you apply Krippendorff’s alpha to your data,
    and you get a result of 0.8 or higher, you have high agreement and a dataset that
    you can use to train your model.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*>0.8*—这个范围是可靠的。如果您将 Krippendorff 的 alpha 应用于您的数据，并且得到的结果为 0.8 或更高，您具有高度的一致性，并且可以用来训练您模型的可靠数据集。'
- en: '*0.67–0.8*—This range has low reliability. It is likely that some of the labels
    are highly consistent and others are not.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*0.67–0.8*—这个范围可靠性低。可能有些标签非常一致，而有些则不是。'
- en: '*0–0.67*—At less than 0.67, your dataset is considered to have low reliability.
    Something is probably wrong with your task design or with the annotators.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*0–0.67*—小于 0.67 时，您的数据集被认为可靠性低。您的任务设计或注释者可能存在问题。'
- en: '*0*—Random distribution.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*0*—随机分布。'
- en: '*–1*—Perfect disagreement.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*–1*—完全不一致。'
- en: Krippendorff’s alpha also has the nice property that it can be used for categorical,
    ordinal, hierarchical, and continuous data. Most of the time in practice, you
    can use Krippendorff’s alpha without knowing how the algorithm works and interpret
    the output according to the 0.8 and 0.67 thresholds. But in order to understand
    what is happening under the hood and when it might not be appropriate, it is a
    good idea to get an intuition for the mathematics. Don’t worry if you don’t get
    all the steps on the first go. When I re-derived all the equations in this book,
    it took me longer to derive Krippendorff’s alpha than any of the active learning
    or machine learning algorithms.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: Krippendorff 的 alpha 还有一个很好的特性，它可以用于分类、有序、层次和连续数据。在实践中，大多数时候您可以使用 Krippendorff
    的 alpha 而不必了解算法的工作原理，并根据 0.8 和 0.67 阈值来解释输出。但是，为了理解底层发生的事情以及何时可能不合适，了解数学直觉是个好主意。如果您第一次没有完全理解所有步骤，请不要担心。当我重新推导这本书中的所有方程时，推导
    Krippendorff 的 alpha 比任何主动学习或机器学习算法都花的时间更长。
- en: 'Krippendorff’s alpha aims to calculate the same metric as the simple example
    in figure 8.7 earlier in this chapter: what is our actual agreement relative to
    our expected agreement? We’ll start with a partial implementation of Krippendorff’s
    alpha that works for mutually exclusive labels and then move to a more general
    version.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Krippendorff 的 alpha 旨在计算与本章前面图 8.7 中的简单示例相同的指标：我们的实际一致性相对于预期一致性如何？我们将从一个适用于互斥标签的
    Krippendorff 的 alpha 的部分实现开始，然后转向更通用的版本。
- en: 'The expected agreement for Krippendorff’s alpha is the data frequency: the
    sum of the squares of the frequency of each label for a labeling task. The actual
    agreement for Krippendorff’s alpha comes from the average amount that each annotation
    agrees with the other annotations for the same task. Krippendorff’s alpha makes
    a slight adjustment to the average, epsilon, to account for the loss of precision
    given the finite number of annotations.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: Krippendorff 的 alpha 的预期一致性是数据频率：对每个标签进行标注任务时每个标签频率的平方和。Krippendorff 的 alpha
    的实际一致性来自每个注释与同一任务的其他注释的平均一致程度。Krippendorff 的 alpha 对平均值，即 epsilon，进行轻微调整，以考虑到有限注释数量导致的精度损失。
- en: Krippendorff’s alpha is the adjusted agreement of the expected and actual agreement
    from figure 8.6\. We can see Krippendorff’s alpha from our example data using
    a simplified representation in figure 8.8.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Krippendorff 的 alpha 是图 8.6 中预期一致性和实际一致性的调整协议。我们可以通过图 8.8 中的简化表示看到我们的示例数据中的
    Krippendorff 的 alpha。
- en: '![](../Images/CH08_F08_Munro.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH08_F08_Munro.png)'
- en: Figure 8.8 A simplified Krippendorff’s alpha that provides an overall score
    for the reliability of the annotators for our example data. The expected agreement
    is the sum of squares of the frequency of each label. The actual agreement is
    the average amount by which each annotation agreed with the other annotations
    for that task, with a small adjustment (epsilon) made to account for precision
    in our calculations.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.8展示了简化的Krippendorff的alpha，为我们的示例数据提供了注释者可靠性的总体得分。预期的协议是每个标签频率的平方和。实际的协议是每个注释与其他注释对该任务的协议的平均量，并对计算中的精度进行了小的调整（epsilon）。
- en: The agreement in figure 8.8 is much lower than our “naive agreement” in figure
    8.7 (0.803 compared with 0.921), so it shows that we need to be careful in how
    we calculate agreement and that small changes in our assumptions can result in
    large differences in our quality control metrics.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.8中的协议比图8.7中的“天真协议”低得多（0.803与0.921相比），这表明我们在计算协议时需要小心，并且我们假设的小变化可能会导致质量控制指标的大幅差异。
- en: Figure 8.8 is a partial implementation of Krippendorff’s alpha. The full equation
    takes into account the fact that you might weight some types of disagreements
    more severely than others. The full implementation of Krippendorff’s alpha is
    shown in figure 8.9.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.8是Krippendorff的alpha的部分实现。完整方程考虑了您可能对某些类型的差异进行更严重加权的可能性。Krippendorff的alpha的完整实现如图8.9所示。
- en: '![](../Images/CH08_F09_Munro.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F09_Munro.png)'
- en: 'Figure 8.9 Krippendorff’s alpha, calculating the overall level of agreement
    in a dataset to determine whether it is reliable enough to use for training data.
    The inputs are the white areas: the annotations (bottom left) and the label weights
    (top middle). Because we have mutually exclusive labels, this example has each
    label weighted only with itself. If we had hierarchical, ordinal, or other types
    of data, we would enter different values as label weights. The top row of calculations
    contains the expected agreement by random chance, and the bottom row of calculations
    calculates the actual agreement in the data. The two rows are used to calculate
    the expected agreement (pe) and actual agreement (pa) for the dataset, from which
    the adjusted overall agreement alpha is calculated.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.9展示了Krippendorff的alpha，计算数据集中协议的整体水平，以确定它是否足够可靠用于训练数据。输入是白色区域：注释（左下角）和标签权重（右上角）。因为我们有互斥的标签，所以这个例子中每个标签只与自身加权。如果我们有层次结构、顺序或其他类型的数据，我们将输入不同的值作为标签权重。计算的上行包含随机机会的预期协议，计算的下行计算数据中的实际协议。这两行用于计算数据集的预期协议（pe）和实际协议（pa），从而计算出调整后的总体协议alpha。
- en: Although figure 8.9 shows some complicated processes, the main difference between
    it and figure 8.8 come from how Krippendorff’s alpha incorporates the label weights.
    The label-weights component allows Krippendorff’s alpha to be adapted to different
    types of problems, such as continuous, ordinal, or other tasks in which multiple
    labels can be applied to one item.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然图8.9显示了某些复杂的过程，但与图8.8的主要区别在于Krippendorff的alpha如何纳入标签权重。标签权重组件允许Krippendorff的alpha适应不同类型的问题，例如连续、顺序或其他任务，在这些任务中，多个标签可以应用于一个项目。
- en: 'For more details, look at the implementations in the spreadsheet introduced
    in section 8.2.1\. You can see that the expected agreement and actual agreement
    need to take in some matrix operations to incorporate the weights in the full
    Krippendorff’s alpha implementation, compared with the partial implementation.
    Also, the epsilon adjustment takes the weights into account and is not simply
    the inverse of the total count. The general idea behind the simple and full implementations
    is the same, however: we are calculating an adjusted agreement according to the
    actual and expected agreements. If you keep that concept in mind and appreciate
    the fact that all the extra steps in the full implementation of Krippendorff’s
    alpha come from the flexibility needed for different types of annotations, you
    have the right idea about how to apply it.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 更多细节，请参阅第8.2.1节中介绍的电子表格中的实现。您可以看到，预期的协议和实际的协议需要一些矩阵运算来将权重纳入完整的Krippendorff的alpha实现中，与部分实现相比。此外，epsilon调整考虑了权重，并且不仅仅是总计数量的倒数。简单实现和完整实现背后的基本思想是相同的：我们正在根据实际协议和预期协议计算一个调整后的协议。如果您记住这个概念，并理解到Krippendorff的alpha完整实现中的所有额外步骤都源于对不同类型注释的灵活性需求，那么您对如何应用它就有了正确的理解。
- en: When do I need to calculate confidence intervals for Krippendorff’s alpha?
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我什么时候需要计算Krippendorff的alpha的置信区间？
- en: This book omits the extensions to Krippendorff’s alpha for calculating the confidence
    intervals because the confidence intervals anticipate the kind of smaller surveys
    that Krippendorff’s alpha was designed for. Most of the time, you won’t need confidence
    intervals for training data because the biggest factor for confidence intervals
    will be the total number of judgments. Because your training data will likely
    contain thousands or even millions of examples, the confidence intervals will
    be tiny.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 本书省略了Krippendorff的alpha在计算置信区间方面的扩展，因为置信区间预计的是Krippendorff的alpha设计的小型调查类型。大多数时候，你不需要对训练数据进行置信区间，因为置信区间的最大因素将是总的判断数量。因为你的训练数据可能包含数千甚至数百万个示例，置信区间将会非常小。
- en: You need to worry about confidence intervals only if you are going to use Krippendorff’s
    alpha on a small dataset or a small subset of your dataset. Note that if you are
    using a small amount of data because of a cutting-edge, lightly supervised, few-shot,
    or data-augmentation technique, you’ll need better statistical knowledge to help
    ensure significance for your smaller datasets. You may have assumed that less
    data makes the required supporting infrastructure easier to build, but the opposite
    is true.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 只有当你打算在一个小型数据集或数据集的小子集上使用Krippendorff的alpha时，你才需要担心置信区间。请注意，如果你因为前沿技术、轻度监督、少样本或数据增强技术而使用少量数据，你需要更好的统计知识来帮助确保你较小数据集的重要性。你可能认为数据越少，所需的支持基础设施就越容易构建，但事实正好相反。
- en: Even in these edge cases, I don’t recommend relying on confidence intervals
    alone. If you have a small number of training examples, you should include other
    types of quality control, including review tasks for experts and incorporating
    known ground truth examples. Otherwise, your confidence intervals will be so wide
    that it will be difficult to trust a model built on the data.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在这些边缘情况下，我也不建议仅依赖置信区间。如果你只有少量训练示例，你应该包括其他类型的质量控制，包括专家的审查任务和包含已知的真实示例。否则，你的置信区间将会非常宽泛，这将使得基于数据的模型难以被信任。
- en: Alternatives to Krippendorff’s alpha
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Krippendorff的alpha的替代方案
- en: You may encounter alternatives to Krippendorff’s alpha in the literature, such
    as Cohen’s kappa and Fleiss’s kappa. Krippendorff’s alpha is generally seen as
    being a refinement of those earlier metrics. The differences are details such
    as whether all errors should be punished equally, the correct way to calculate
    the expected prior, the treatment of missing values, and how to aggregate the
    overall agreement (aggregating per annotation, like Krippendorff’s alpha, or per
    task/annotator, like Cohen’s kappa). The additional reading in section 8.6 has
    some examples.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能在文献中遇到Krippendorff的alpha的替代方案，如Cohen的kappa和Fleiss的kappa。Krippendorff的alpha通常被视为那些早期指标的改进。差异在于细节，例如是否应该对所有的错误进行同等惩罚，正确计算预期先验的方法，处理缺失值的方式，以及如何汇总整体一致性（按注释汇总，如Krippendorff的alpha，或按任务/标注者汇总，如Cohen的kappa）。第8.6节中的附加阅读有一些例子。
- en: 'You may also encounter Krippendorff’s alpha expressed in terms of disagreement,
    instead of agreement, including in Krippendorff’s own publications. The techniques
    are mathematically equivalent and produce the same alpha value. Agreement is more
    widely used than disagreement in other metrics and is arguably more intuitive,
    which is why agreement is used here. Assume that disagreement is the complement
    of agreement: D = (1 – P). Keep this assumption in mind when you look at the literature
    and libraries, which may have versions of Krippendorff’s alpha that are calculated
    by using disagreement.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可能遇到以不一致性而非一致性来表示的Krippendorff的alpha，这在Krippendorff自己的出版物中也有体现。这些技术在数学上是等价的，并产生相同的alpha值。在其他指标中，一致性比不一致性更广泛地被使用，并且可以说是更直观的，这就是为什么这里使用一致性的原因。假设不一致性是一致性的补数：D
    = (1 – P)。当你查看文献和图书馆时，请记住这个假设，其中可能包含使用不一致性计算出的Krippendorff的alpha版本。
- en: 8.2.4 Calculating Krippendorff’s alpha beyond labeling
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.4 计算Krippendorff的alpha超出标签
- en: Here are some examples of how Krippendorff’s alpha can be used for tasks that
    are more complicated than mutually exclusive labeling tasks. Figure 8.10 shows
    how we can change the label weights in the Krippendorff’s alpha equation to capture
    ordinal and rotational data.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些例子说明Krippendorff的alpha可以用于比互斥标签任务更复杂的任务。图8.10展示了我们如何改变Krippendorff的alpha方程中的标签权重来捕捉序数和旋转数据。
- en: '![](../Images/CH08_F10_Munro.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F10_Munro.png)'
- en: Figure 8.10 An example of three types of classification tasks and how the label
    weights from Krippendorff’s alpha can be used for those tasks. The first example
    repeats the label weights from figure 8.9, showing the mutually exclusive labeling
    tasks that have been used as an example throughout this chapter. The second example
    shows an ordinal scale from “Bad” to “Excellent,” where we want to give partial
    credit to adjacent annotations such as “Good” and “Excellent.” The third example
    shows rotational categories—in this case, the compass points. In this case, we
    give a partial score to anything that is off by 90 degrees, such as “North” and
    “West,” but a zero score to anything that is off by 180 degrees, such as “North”
    and “South.”
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.10 三种类型分类任务的示例以及如何使用Krippendorff的alpha的标签权重来完成这些任务。第一个例子重复了图8.9中的标签权重，展示了本章一直用作例子的互斥标签任务。第二个例子显示了一个从“差”到“优秀”的序量尺度，我们希望对相邻标注如“好”和“优秀”给予部分信用。第三个例子显示了旋转类别——在这种情况下，是罗盘指针。在这种情况下，我们对偏离90度的任何事物给予部分分数，如“北”和“西”，但对偏离180度的任何事物给予零分，如“北”和“南”。
- en: The rest of this chapter sticks to mutually exclusive labeling. We’ll cover
    to other types of machine learning problems in chapter 9.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的其余部分将坚持使用互斥标签。我们将在第9章中介绍其他类型的机器学习问题。
- en: Krippendorff’s alpha has some shortcomings when it’s used for training data,
    because it was originally derived for use cases such as when a school is randomly
    distributing exam papers across multiple graders (annotators). It doesn’t capture
    the fact that some annotators will have a different expected agreement based on
    what they have seen. When creating training data, we have many good reasons to
    distribute annotations nonrandomly, such as giving a hard example to additional
    people to adjudicate. Sections 8.2.5 through 8.2.7 differ from Krippendorff’s
    alpha in key ways for calculating agreement at annotator, label, and task levels.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 当Krippendorff的alpha用于训练数据时，它有一些不足之处，因为它最初是为了使用案例如学校随机将考试卷分发给多个评分者（标注者）而推导出来的。它没有捕捉到一些标注者将根据他们所看到的不同情况而有不同的预期一致性的事实。在创建训练数据时，我们有很好的理由非随机地分配标注，例如给额外的人提供困难示例以进行裁决。第8.2.5节至第8.2.7节在计算标注者、标签和任务级别的一致性方面与Krippendorff的alpha有显著的不同。
- en: 8.2.5 Individual annotator agreement
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.5 单个标注者一致性
- en: Agreement at individual annotator level can be useful in multiple ways. For
    one thing, it can tell you how reliable each annotator is. You can calculate agreement
    at the macro level, calculating an annotator’s reliability across every response
    they made, or you may want to see whether they have higher or lower agreement
    for certain labels or segments of the data. This result might tell you that the
    annotator is more or less accurate or may highlight a diverse set of valid annotations.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在单个标注者级别上的一致性可以从多个方面有用。一方面，它可以告诉你每个标注者的可靠性如何。你可以在宏观层面上计算一致性，计算标注者在其所做每个响应中的可靠性，或者你可能想看看他们是否对某些标签或数据片段有更高或更低的一致性。这个结果可能会告诉你标注者更准确或更不准确，或者可能突出一系列有效的标注。
- en: The simplest metric for agreement between annotators is to calculate how often
    each annotator agrees with the majority of people for a given task. Figure 8.11
    shows an example.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 对于标注者之间的一致性，最简单的度量方法是计算每个标注者在给定任务中与大多数人达成一致的情况有多频繁。图8.11展示了示例。
- en: '![](../Images/CH08_F11_Munro.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F11_Munro.png)'
- en: Figure 8.11 The per-annotator agreement with the most common annotation for
    each task (majority agreement). This example shows that two annotators, Blake
    and Evan, always agreed with the majority. This method is the simplest way to
    calculate agreement between annotators; it can be effective when you have a large
    number of annotators per task but is rarely used for creating training data due
    to budget constraints. This method can provide insight into your data but should
    not be your sole means of determining data quality.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.11 每个任务中每个标注者与最常见标注的一致性（多数一致性）。这个例子表明，两个标注者，Blake和Evan，总是与多数人达成一致。这是计算标注者之间一致性的最简单方法；当每个任务有大量标注者时，这种方法可能有效，但由于预算限制，很少用于创建训练数据。这种方法可以提供对数据的洞察，但不应该是确定数据质量的唯一手段。
- en: Majority agreement, as shown in figure 8.11, looks at the number of times a
    person agrees with the most commonly annotated label for each task. This result
    can also be calculated as a count of the fraction of times that a person agrees
    with the majority, but it is a little more accurate when normalized for agreement
    on a per-annotation basis. In figure 8.11 and other example data in this chapter,
    Cameron and Dancer agree that task 3 is “Cyclist,” even though most people think
    task 3 is “Pedestrian.” By contrast, Alex is the only one who thinks that task
    9 is “Sign.” So in our Majority Agreement table in figure 8.11, Cameron and Dancer
    get 0.5 for task 3, and Alex gets 0 for task 9.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 如图8.11所示，多数同意度考虑的是一个人同意每个任务中最常标注的标签的次数。这个结果也可以计算为一个人同意多数的次数的分数，但按每个标注的同意度进行归一化时，它会更准确一些。在图8.11和本章中的其他示例数据中，Cameron和Dancer同意任务3是“自行车手”，尽管大多数人认为任务3是“行人”。相比之下，Alex是唯一一个认为任务9是“标志”的人。因此，在我们的多数同意度表（图8.11）中，Cameron和Dancer在任务3上得到0.5分，而Alex在任务9上得到0分。
- en: Majority agreement can provide a good quick check on whether your annotators
    have seen easier or harder examples. In the naive agreement example in figure
    8.6 earlier in this chapter, Evan has the next-to-lowest agreement (0.836), but
    they have the equal highest agreement in figure 8.11 (1.0). In other words, Evan
    had low agreement on average with other people but always agreed with the majority.
    This result tells you that Evan saw tasks with lower overall agreement than other
    people. A good agreement metric, therefore, should take into account the fact
    that Evan saw harder tasks.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 多数同意度可以快速检查你的标注者是否看到了更容易或更难示例。在本章前面的图8.6中的简单同意度示例中，Evan的同意度次低（0.836），但在图8.11中，他们的同意度与最高（1.0）相同。换句话说，Evan与其他人的平均同意度较低，但总是与多数人意见一致。这个结果告诉你，Evan看到了其他人整体同意度较低的任务。因此，一个好的同意度指标应该考虑到Evan看到了更难的任务这一事实。
- en: Expected agreement is the biggest piece missing from figure 8.11\. Figure 8.12
    shows one way to calculate expected agreement, which shows that Evan has the lowest
    expected agreement if they always chose “Pedestrian.”
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 预期同意度是图8.11中缺失的最大部分。图8.12展示了计算预期同意度的一种方法，它表明如果他们总是选择“行人”，Evan的预期同意度最低。
- en: '![](../Images/CH08_F12_Munro.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F12_Munro.png)'
- en: Figure 8.12 The per-annotator agreement is calculated in terms of the actual
    agreements (bottom right), with the expected agreement calculated on a per-annotator
    basis (top middle). Note that Evan has an expected agreement of only 0.15\. In
    other words, if Evan guessed the most common label, “Pedestrian,” every time,
    they would agree with about 15% of the other annotations on their tasks. By contrast,
    Alex could have guessed “Pedestrian” every time and got about 51% agreement. This
    method takes into account the fact that Evan saw tasks with lower agreement that
    were presumably more difficult.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.12 每个标注者的同意度是根据实际同意度（右下角）计算的，预期同意度是根据每个标注者计算的（中间顶部）。注意，Evan的预期同意度仅为0.15。换句话说，如果Evan每次都猜测最常见的标签“行人”，他们将与大约15%的其他标注在他们的任务上达成一致。相比之下，Alex每次都可以猜测“行人”并得到大约51%的同意度。这种方法考虑到了Evan看到了同意度较低的任务，这些任务可能更难。
- en: The first thing to notice in figure 8.12 is that we are using the most frequent
    label (mode label) to calculate our baseline. Recall that Krippendorff’s alpha
    uses the same number of labels in the data, as though they were assigned randomly.
    In our example, someone might randomly assign 13 “Pedestrian” labels, 7 “Sign”
    labels, and so on. While this example is the (statistical) definition of an expected
    distribution, it is unlikely that a human annotator will have that probability
    for each label in mind when annotating. The more likely scenario is that an annotator
    will have an intuition about the most frequent label (mode label). This result
    is common in data labeling. Often, one label is obviously more frequent than all
    the others and feels like a safe default option. There are ways to mitigate the
    problem of bad labels because a person feels pressured to label a default option
    when they are uncertain, which we’ll cover in chapter 9\. Here, we’ll treat this
    most common label as our expected baseline.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在8.12图中，首先要注意的是我们正在使用最频繁的标签（众数标签）来计算我们的基线。回想一下，Krippendorff的alpha在数据中使用相同数量的标签，就像它们是随机分配的一样。在我们的例子中，有人可能会随机分配13个“行人”标签，7个“标志”标签等等。虽然这个例子是（统计上的）期望分布的定义，但一个人类标注者在标注时不太可能对每个标签的概率有意识。更可能的情况是，标注者会对最频繁的标签（众数标签）有一个直觉。这种结果在数据标注中很常见。通常，一个标签明显比其他所有标签更频繁，感觉像是一个安全的默认选项。有方法可以减轻由于人们感到有压力在不确定时标注默认选项而导致的不良标签问题，我们将在第9章中介绍。在这里，我们将这个最常见的标签视为我们的期望基线。
- en: The second difference between figure 8.12 and standard Krippendorff’s alpha
    calculation is that figure 8.12 calculates agreement per task, whereas Krippendorff’s
    alpha calculates agreement per annotation. If you have the same number of annotations
    per task, the numbers would be identical. In our example data, task 3 has five
    annotations, so it effectively has a larger weight than the other tasks in Krippendorff’s
    alpha. Krippendorff’s alpha, however, gives task 3 the same weight as every other
    task when calculating individual agreement.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 8.12图与标准Krippendorff的alpha计算的第二点不同在于，8.12图计算的是每个任务的协议，而Krippendorff的alpha计算的是每个标注的协议。如果你每个任务都有相同数量的标注，那么这些数字将是相同的。在我们的示例数据中，任务3有五个标注，因此在Krippendorff的alpha中它实际上比其他任务有更大的权重。然而，在计算个别协议时，Krippendorff的alpha给任务3与其他任务相同的权重。
- en: You don’t want to give different weights to different tasks for data annotation
    for many reasons. You might deliberately give the same task to more annotators
    to resolve disagreements, for example, or you might give easier tasks to fewer
    people based on the label or external information. In both cases, Krippendorff’s
    alpha would be biased toward the more difficult tasks, giving you an artificially
    low score. If you truly have a random distribution of annotators across tasks,
    and it is arbitrary that some tasks end up with more annotations, the standard
    Krippendorff’s alpha approach is fine.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 由于许多原因，你不想为数据标注的不同任务赋予不同的权重。例如，你可能故意将相同的任务分配给更多的标注者以解决分歧，或者你可能根据标签或外部信息将较容易的任务分配给较少的人。在这两种情况下，Krippendorff的alpha都会偏向于更困难的任务，从而给出一个人为的低分。如果你确实在任务之间有标注者的随机分布，并且某些任务最终有更多的标注是随机的，那么标准的Krippendorff的alpha方法是可以的。
- en: Don’t p-hack Krippendorff’s alpha by iteratively removing annotators with the
    lowest agreement
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 不要通过迭代去除与最低一致性的标注者来p-hack Krippendorff的alpha
- en: Often, you want to ignore the annotations made by your least-accurate annotators.
    You can improve the overall agreement and accuracy of your training data by removing
    the worst performers and giving their tasks to other annotators.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，你希望忽略你最不准确的标注者的标注。通过去除表现最差的标注者并将他们的任务分配给其他标注者，你可以提高训练数据的整体协议和准确性。
- en: You would make a mistake, however, if you iteratively removed the worst performers
    until your dataset reaches the magic k-alpha=0.8 number, which indicates high
    agreement. Using the threshold of significance itself as a threshold for removing
    people is what Regina Nuzzo called p-hacking in Nature in 2014 ([http://mng.bz/8NZP](http://mng.bz/8NZP)).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你迭代地去除表现最差的，直到你的数据集达到神奇的k-alpha=0.8数字，这表明高度一致，那么你将犯一个错误。将显著性阈值的本身作为去除人员的阈值，这就是Regina
    Nuzzo在2014年《自然》杂志上所说的p-hacking([http://mng.bz/8NZP](http://mng.bz/8NZP))。
- en: 'Instead of relying on Krippendorff’s alpha, you should remove people by one
    of the following criteria, in order of preference:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是依赖Krippendorff的alpha，你应该根据以下标准之一，按照优先顺序去除人员：
- en: '*Use a different criterion from Krippendorff’s alpha to decide who is a good
    or bad performer*. Ideally, you should use the annotator’s agreement with known
    ground truth answers. Then you can use that criterion to remove the worst performers.
    You can set a threshold level of accuracy on the known answers or decide that
    you will remove some percentage of annotators (such as the worst 5%). You should
    make the decision about a threshold or percentage without taking Krippendorff’s
    alpha into account.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用与Krippendorff的alpha系数不同的标准来决定谁是好或坏的绩效者*。理想情况下，你应该使用标注者与已知真实答案的一致性。然后你可以使用这个标准来移除最差的绩效者。你可以在已知答案上设置一个准确性的阈值水平，或者决定移除一定比例的标注者（例如最差的5%）。你应该在没有考虑Krippendorff的alpha系数的情况下做出关于阈值或百分比的决策。'
- en: '*Remove low performers who are statistical outliers in terms of how badly they
    performed*. Use this technique if you are confident about your mathematical skills.
    If you can calculate that all the agreement scores fall in a normal distribution,
    for example, you can remove any annotator with agreement that is three standard
    deviations below the average agreement. If you are not confident in your ability
    to identify the type of distribution and the appropriate outlier metric, stick
    to the first option and create additional questions with known answers if necessary.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*移除那些在表现方面统计上异常低下的低绩效者*。如果你对自己的数学技能有信心，可以使用这个技术。例如，如果你能计算出所有的一致性评分都落在正态分布中，你可以移除任何一致性评分低于平均一致性三个标准差的标注者。如果你不自信能够识别分布类型和适当的异常值指标，坚持第一个选项，并在必要时创建有已知答案的额外问题。'
- en: '*Decide in advance what your expected percent of low-performing annotators
    will be, and remove only those annotator*s. If you typically find that 5% perform
    poorly, remove the bottom 5%, but do not keep going if you are not yet at your
    target agreement. This approach could contain a little bias, because you are still
    using Krippendorff’s alpha to calculate the lowest 5%. The bias is probably minor,
    however, and in any case, you shouldn’t use this approach if you can use the first
    two options.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*事先决定你预期的低绩效标注者的百分比，并只移除那些标注者*。如果你通常发现5%的表现不佳，移除表现最差的5%，但如果你还没有达到目标协议，不要继续这样做。这种方法可能包含一点偏见，因为你仍在使用Krippendorff的alpha系数来计算最低的5%。然而，这种偏见可能很小，在任何情况下，如果你可以使用前两种方法，你不应该使用这种方法。'
- en: What happens if you p-hack Krippendorff’s alpha? You may get bad instructions
    or an impossible task, but you will never learn that result. You may end up removing
    everyone except annotators who happened to be sitting next to one another and
    sharing notes.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你用p-hack Krippendorff的alpha系数，可能会得到糟糕的指示或不可能完成的任务，但你永远不会学到那个结果。你可能会最终只留下那些碰巧坐在一起并共享笔记的标注者。
- en: If you have established that an annotator is not reliable enough to trust, you
    should remove that annotator’s judgments from your calculation of agreement. Figure
    8.13 shows this result with our example data, assuming that we removed the first
    person.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经确定一个标注者不够可靠，不足以信任，你应该从你的协议计算中移除该标注者的判断。图8.13展示了我们的示例数据，假设我们移除了第一个人。
- en: '![](../Images/CH08_F13_Munro.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F13_Munro.png)'
- en: Figure 8.13 Recalculating agreement for our annotators after the first annotator
    has been removed. Note that three of the four scores went up compared with figure
    8.12, but Blake’s agreement dropped slightly, and Evan went from second-highest
    to lowest agreement.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.13 在移除第一个标注者后重新计算我们的标注者的一致性。注意，与图8.12相比，四个评分中的三个有所上升，但Blake的一致性略有下降，Evan从第二高的一致性降至最低。
- en: 'As figure 8.13 shows when compared with figure 8.12, you generally expect overall
    agreement to go up when the least-accurate person is removed, but some individual
    agreement scores may still go down (as in the case of Blake), and the rankings
    may change considerably, as is the case with Evan. Evan has the highest agreement
    when we calculate agreement with the majority in figure 8.11 but has the lowest
    agreement when we calculate for chance-adjusted agreement after Alex is removed
    in figure 8.13\. This figure is a good example of why you need to be careful about
    using agreement as the only way to calculate accuracy: your choices can produce
    different results for individuals.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 如图8.13所示，与图8.12相比，当你移除最不准确的人时，你通常期望整体一致性上升，但某些个别一致性分数可能仍然会下降（如Blake的情况），排名也可能发生很大变化，如Evan的情况。当我们计算图8.11中的多数一致性时，Evan具有最高的共识，但在图8.13中移除Alex后计算机会调整的共识时，他具有最低的共识。这个图是为什么你需要小心使用一致性作为计算准确性的唯一方式的一个很好的例子：你的选择可以为个人产生不同的结果。
- en: '![](../Images/CH08_F14_Munro.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F14_Munro.png)'
- en: 'Figure 8.14 Annotation confusion matrices: compared with ground truth data
    in our example data (top) and compared with every pairwise agreement or disagreement
    (bottom)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.14 注释混淆矩阵：与我们示例数据中的真实数据（顶部）相比，以及与每个成对的一致或不一致（底部）相比
- en: 8.2.6 Per-label and per-demographic agreement
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.6 每标签和每人口统计一致性
- en: Ideally, you have some ground truth labels for your dataset, so you can use
    these labels to plot the errors in a confusion matrix. This confusion matrix is
    identical to the kind that you use for machine learning models, except that it
    is the pattern of human errors in place of model errors.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，你有一些数据集的真实标签，这样你就可以使用这些标签在混淆矩阵中绘制错误。这个混淆矩阵与用于机器学习模型的混淆矩阵相同，只是它用人类错误模式代替了模型错误。
- en: You can also use a confusion matrix for agreement, plotting which annotations
    occur with others. Figure 8.14 shows the matrices for our example data.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用混淆矩阵来表示一致性，绘制哪些注释与其他注释一起发生。图8.14显示了我们的示例数据中的矩阵。
- en: This second type of confusion matrix doesn’t tell you what the errors are—only
    where the agreement or disagreement occurs. With either type of matrix, you can
    see where the greatest pairwise confusion occurs in your annotations, and this
    information should help you refine your instructions for annotators, as well as
    indicate which labels may be hardest for your model to predict.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这种混淆矩阵的第二种类型不会告诉你错误是什么——只会告诉你一致或不一致发生在哪里。使用任何一种矩阵，你都可以看到在你的注释中最大的成对混淆发生在哪里，这些信息应该有助于你改进对注释者的指令，以及指出哪些标签可能对你的模型预测最困难。
- en: 8.2.7 Extending accuracy with agreement for real-world diversity
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.7 使用一致性扩展现实世界多样性中的准确性
- en: It can be especially useful to use agreement as an extension of accuracy when
    you want to track a large number of fine-grained demographics. If you want to
    track the intersection of demographics, you may have too many combinations of
    demographic categories for which you are able to collect enough ground truth data.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 当你想跟踪大量细粒度的人口统计时，使用一致性作为准确性的扩展特别有用。如果你想跟踪人口统计的交集，你可能会有太多的人口统计类别组合，以至于你无法收集足够多的真实数据。
- en: Consider the example where we suspected that images taken at night are more
    difficult to annotate than images taken during the day. Now suppose that you also
    want to track the accuracy of annotation across 1,000 locations. You are unlikely
    to have a large volume of ground truth labels for every one of these 24,000 time/place
    combinations, because it would be expensive to create so much ground truth data.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑这样一个例子，我们怀疑夜间拍摄的照片比白天拍摄的照片更难注释。现在假设你还想跟踪1,000个地点的注释准确性。对于这24,000个时间/地点组合中的每一个，你不太可能都有大量的真实标签，因为创建如此多的真实数据会非常昂贵。
- en: Therefore, looking at agreement for each of the 24,000 time/place combinations
    is your best window into the difficulty of each demographic intersection. There
    won’t always be a perfect correlation between agreement and accuracy, but this
    approach can reveal some areas of high agreement that you can review and potentially
    target for more ground truth data.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，查看每个24,000个时间/地点组合的一致性，是你了解每个人口统计交叉点难度的最佳窗口。一致性不一定总是与准确性完美相关，但这种方法可以揭示一些高度一致的区域，你可以对这些区域进行审查，并可能针对这些区域收集更多的真实数据。
- en: 8.3 Aggregating multiple annotations to create training data
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.3 聚合多个注释以创建训练数据
- en: Task-level confidence is the most important quality control metric for many
    annotation projects, because it allows us to aggregate the (potentially conflicting)
    annotations of each annotator and create the label that will become the training
    and evaluation data.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多标注项目来说，任务级别的置信度是最重要的质量控制指标，因为它允许我们聚合（可能存在冲突的）每位标注者的标注，并创建将成为训练和评估数据的标签。
- en: 'Therefore, it is important to understand how to combine multiple annotations
    to create the single label that will become the actual label. Aggregating multiple
    annotations in a task builds on the other types of quality control metrics that
    you have seen in this chapter: we want to take our confidence in each annotator
    into account when calculating the overall agreement for a given task, and ideally,
    we want to know whether this particular task is inherently easier or more difficult.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，了解如何组合多个标注以创建将成为实际标签的单个标签非常重要。在任务中聚合多个标注建立在本章中看到的其他类型的质量控制指标之上：我们希望在计算给定任务的总体一致性时考虑每位标注者的置信度，并且理想情况下，我们希望知道这个特定的任务是否本质上更容易或更难。
- en: 8.3.1 Aggregating annotations when everyone agrees
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3.1 当所有人都同意时聚合标注
- en: It can be easiest to think about agreement in terms of the chance of error instead
    of the chance of being correct. Suppose that we have three annotators and they
    are each 90% accurate. The chance that any one annotator makes an error is 10%.
    The chance that a second annotator made an error on the same task is 10%, so combined,
    there is a 1% (0.1 × 0.1 = 0.01) chance that two people made an error on the same
    item. With three annotators, that chance becomes a 0.1% chance (0.1 × 0.1 × 0.1).
    In other words, there is a 1-in-1,000 chance of being incorrect and a 0.999 chance
    of being correct. If three annotators are 90% accurate, and all three agree, we
    can assume with 99.9% confidence that the label is correct. Letting the accuracy
    of the *ith* annotator be *a*[i], the overall confidence that the label is correct
    is
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 可以最容易地用出错概率而不是正确概率来考虑一致性。假设我们有三位标注者，他们每个人的准确率都是90%。任何一位标注者犯错的概率是10%。第二位标注者在同一任务上犯错的概率也是10%，所以结合起来，两个人在同一项上犯错的概率是1%（0.1
    × 0.1 = 0.01）。对于三位标注者来说，这个概率变成了0.1%（0.1 × 0.1 × 0.1）。换句话说，出错的可能性是千分之一，正确的可能性是0.999。如果三位标注者的准确率都是90%，并且他们都同意，我们可以有99.9%的信心认为标签是正确的。让第*i*位标注者的准确率为*a*[i]，那么标签正确的整体置信度是
- en: '![](../Images/CH08_F14_Munro_E01.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH08_F14_Munro_E01.png)'
- en: Unfortunately, this method has limitations because it assumes that the errors
    are independent. If the first annotator makes an error, does the second annotator
    still have only a 10% chance of error, or do the errors tend to cluster or diverge?
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这种方法存在局限性，因为它假设错误是独立的。如果第一个标注者犯了一个错误，第二个标注者是否仍然只有10%的出错概率，或者错误倾向于聚集或发散？
- en: It is easy to imagine scenarios in which the patterns of errors are nonrandom.
    Most obviously, some tasks tend to be harder than others. If 10% of all tasks
    lead to people choosing the wrong label, perhaps that task is where all three
    annotators made mistakes. If you have a task with a large number of labels, this
    problem is less common, because people are less likely to choose the same wrong
    label. You often want to reduce your tasks to as few annotations as possible to
    make them more efficient, so there is a trade-off between accuracy and cost.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 很容易想象出错误模式非随机性的场景。最明显的是，有些任务比其他任务更难。如果10%的所有任务会导致人们选择错误的标签，那么可能就是所有三位标注者都犯错的那个任务。如果你有一个具有大量标签的任务，这个问题就不太常见，因为人们不太可能选择相同的错误标签。你通常希望将任务减少到尽可能少的标注，以提高效率，因此在准确性和成本之间有一个权衡。
- en: 'The ground truth data allows you to calculate the following: for each incorrect
    annotation, what % of annotations for the task are also incorrect? Let’s work
    through an example. Assume that in our example data, every item’s actual label
    is the one shown in figure 8.3 earlier in the chapter. The following table shows
    two tasks, 3 and 9, with the errors in bold:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 地面真实数据允许你计算以下内容：对于每个错误的标注，有多少百分比的任务标注也是错误的？让我们通过一个例子来分析。假设在我们示例数据中，每个项目的实际标签是本章8.3节中较早展示的图8.3所示的标签。以下表格显示了两个任务，3和9，其中错误用粗体表示：
- en: '| Task 3 | **Pedestrian** | **Pedestrian** | Cyclist | Cyclist | **Pedestrian**
    |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| 任务3 | **行人** | **行人** | 骑行者 | 骑行者 | **行人** |'
- en: '| Task 9 | **Sign** |  | Animal | Animal | Animal |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| 任务9 | **标志** |  | 动物 | 动物 | 动物 |'
- en: In task 3, each of the three wrong “Pedestrian” annotations agrees with the
    two other “Pedestrian” annotations, giving us six total agreements for the incorrect
    label. Note this number is in the column sum(AW) from Krippendorff’s alpha. In
    task 9, the “Sign” error was alone, so there are no agreeing errors. For the correct
    answers, we have two agreements in task 3 (the two “Cyclists” annotations agreeing
    with each other) and each of three “Animals” annotations agreeing with each other.
    So in total, there are eight cases of annotators agreeing with one another when
    they are correct and six cases of annotators agreeing with one another when they
    are incorrect. To calculate how often incorrect annotations agree, we calculate
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在任务3中，三个错误的“行人”标注都与另外两个“行人”标注一致，为我们提供了六个关于错误标签的总共识。注意这个数字来自Krippendorff的alpha中的列sum(AW)。在任务9中，“符号”错误是唯一的，因此没有达成共识的错误。对于正确答案，我们在任务3中有两个共识（两个“骑自行车的人”标注相互一致）和三个“动物”标注中的每一个都相互一致。因此，当标注员正确时，他们之间达成共识的情况总共有八种，当标注员错误时，他们之间达成共识的情况有六种。为了计算错误标注达成共识的频率，我们计算
- en: Correlation of errors = 6 / (8 + 6) = 0.429
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 错误的相关性 = 6 / (8 + 6) = 0.429
- en: Therefore, although our overall error rate is 10%, the likelihood that errors
    in annotation will co-occur is 42.9%—more than four times higher! After the first
    error, we should assume that errors co-occur at this rate. With agreement from
    three annotators, the overall confidence in our label would be
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，尽管我们的整体错误率是10%，但标注错误同时发生的可能性是42.9%——比四倍还高！在第一个错误发生后，我们应该假设错误以这种速率同时发生。当三位标注员达成一致时，我们对标签的整体信心将是
- en: 1 – (0.1 × 0.429 × 0.429) = 0.982
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 1 – (0.1 × 0.429 × 0.429) = 0.982
- en: So instead of having 99.9% confidence, we are have 98.2% confidence in our label
    when all three annotators agree, going from an error in every 1,000 items to an
    error in about every 55 items.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们不是有99.9%的信心，而是在三位标注员达成一致时，我们有98.2%的信心，从每1,000个项目中的一个错误降低到大约每55个项目中的一个错误。
- en: 'The opposite pattern can also occur, in which the pattern of errors diverges.
    Let’s assume that the three annotators are still 90% accurate individually, but
    they make different errors. One annotator makes most of their errors identifying
    “Sign,” whereas another annotator might make most of their errors identifying
    “Animal.” They might make errors on different images, so the chance that the errors
    will co-occur is 2%:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 相反的情况也可能发生，其中错误模式会发散。假设三位标注员各自仍然有90%的准确率，但他们犯的错误不同。一位标注员在识别“符号”时犯的错误最多，而另一位标注员可能在识别“动物”时犯的错误最多。他们可能在不同的图像上犯错误，因此错误同时发生的概率是2%：
- en: 1 – (0.1 × 0.02 × 0.02) = 0.99996
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 1 – (0.1 × 0.02 × 0.02) = 0.99996
- en: In this case, where your annotators have complementary skills, you can be 99.996%
    confident that agreement between annotators means that your annotation is correct,
    and so an error occurs once in every 25,000 items.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，如果你的标注员具有互补的技能，你可以有99.996%的信心认为标注员之间的共识意味着你的标注是正确的，因此错误每25,000个项目中发生一次。
- en: 8.3.2 The mathematical case for diverse annotators and low agreement
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3.2 多样化的标注员和低共识的数学案例
- en: There is a big difference in how errors pattern across annotators, as the example
    in section 8.3.1 showed. We can expand on this example as the mathematical proof
    that having a diverse set of annotators will result in more accurate data.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 标注员之间错误模式存在很大差异，正如第8.3.1节中的例子所示。我们可以通过这个例子来扩展数学证明，即拥有多样化的标注员将导致更准确的数据。
- en: Given the same overall error rate on a per-annotation basis, the data with the
    highest accuracy will have the lowest agreement, because the errors are spread
    out and create more opportunities for disagreement. Therefore, this condition
    has the lowest Krippendorff’s alpha score, showing why we don’t want to rely on
    Krippendorff’s alpha score alone because it can penalize diversity unfairly. You
    can see this result in our example data with a Krippendorff’s alpha score of 0.803\.
    If we spread out the disagreements so that there is no more than one disagreement
    per task, however, we get a Krippendorff’s alpha score of 0.685\. So even though
    our data has the same frequency for each label and the majority is much more reliable,
    our dataset looks less reliable.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个标注的基础上，如果整体错误率相同，那么准确率最高的数据将具有最低的一致性，因为错误分散并创造了更多不一致的机会。因此，这个条件具有最低的Krippendorff的alpha分数，显示了为什么我们不能仅仅依赖Krippendorff的alpha分数，因为它可能不公平地惩罚多样性。你可以在我们的示例数据中看到这个结果，Krippendorff的alpha分数为0.803。然而，如果我们分散不一致，使得每个任务中不超过一个不一致，那么我们得到的Krippendorff的alpha分数为0.685。所以尽管我们的数据每个标签的频率相同，而且大多数数据更加可靠，但我们的数据集看起来不那么可靠。
- en: 'It is easy to imagine scenarios in which the agreement is clustered: some examples
    are harder than others or annotators have subjective but similar judgments. It
    is also easy to imagine scenarios in which agreement is divergent: annotators
    are diverse and bring different but legitimate perspectives to the data.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 容易想象出一些意见一致聚集的场景：有些例子比其他例子更难，或者标注者有主观但相似的判断。也容易想象出意见不一致的场景：标注者多样化，为数据带来不同但合法的视角。
- en: It is difficult, however, to imagine real-world scenarios in which annotators
    are making errors completely independently (except perhaps because of fatigue).
    Yet almost all agreement metrics make the assumption of independence, which is
    why they should be used with caution. As this section and section 8.3.1 show,
    our ground truth data allows us to calibrate to the correct numbers for a given
    dataset. The advanced methods in chapter 9 go into more detail on data-driven
    agreement metrics.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，很难想象出标注者在完全独立地犯错误的真实世界场景（除了可能因为疲劳之外）。然而，几乎所有的协议指标都做出了独立性的假设，这就是为什么它们应该谨慎使用。正如本节和第8.3.1节所示，我们的真实数据允许我们对给定数据集进行校准。第9章的高级方法更详细地介绍了数据驱动的协议指标。
- en: 8.3.3 Aggregating annotations when annotators disagree
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3.3 当标注者意见不一致时的标注聚合
- en: When annotators disagree, you are essentially converging a probability distribution
    across all the potential labels. Let’s expand our example from task 3 and assume
    that everyone is 90% accurate on average (figure 8.15).
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 当标注者意见不一致时，你实际上是在将所有潜在标签的概率分布进行收敛。让我们扩展任务3的例子，并假设平均每个人准确率为90%（图8.15）。
- en: '![](../Images/CH08_F15_Munro.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F15_Munro.png)'
- en: Figure 8.15 Using per-annotator accuracy as probabilities for per-task agreement
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.15 使用每个标注者的准确率作为每个任务的协议概率
- en: 'In figure 8.15, we have three annotators who labeled the image in this task
    as “Pedestrian” and two who labeled it “Cyclist.” The simplest way to calculate
    confidence when not all annotators agree is to treat the confidences as a weighted
    vote. Let’s assume that we’re calculating confidence for task 3 and that we have
    90% confidence in every annotator:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在图8.15中，我们有三位标注者将这个任务中的图像标注为“行人”，两位标注为“骑行者”。当不是所有标注者意见一致时，计算信心的最简单方法是将信心视为加权投票。假设我们正在计算任务3的信心，并且对每个标注者的信心为90%：
- en: Pedestrian = 3 * 0.9 = 2.7
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 行人 = 3 * 0.9 = 2.7
- en: Cyclist = 2 * 0.9 = 1.8
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 骑行者 = 2 * 0.9 = 1.8
- en: Confidence in Pedestrian = 2.7 / (2.7 + 1.8) = 0.6
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 行人信心 = 2.7 / (2.7 + 1.8) = 0.6
- en: Confidence in Cyclist = 1.8 / (2.7 + 1.8) = 0.4
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 骑行者信心 = 1.8 / (2.7 + 1.8) = 0.4
- en: Another way to think of this calculation is that because we’re equally confident
    in everyone in this example, three-fifths of the annotators agree, so we are 3/5
    = 60% confident.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种思考这种计算的方式是，因为我们在这个例子中对每个人都同样有信心，五分之三的标注者意见一致，所以我们有3/5 = 60%的信心。
- en: One problem with this method is that it does not leave any confidence for other
    labels. Recall that when we had perfect agreement, there was still a small chance
    that it was wrong and that therefore, the correct label was one not annotated
    by anyone. We can incorporate the possibility that a non-annotated label might
    be correct by treating the confidence as a probability distribution and assume
    that all other labels get the weight divided among them, as shown in figure 8.16.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的一个问题是它没有为其他标签留下任何置信度。回想一下，当我们达成完全一致时，仍然存在错误的可能性，因此正确的标签可能是没有人标注的标签。我们可以通过将置信度视为概率分布，并假设所有其他标签都分得相同的权重，来纳入非标注标签可能正确的可能性，如图8.16所示。
- en: '![](../Images/CH08_F16_Munro.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F16_Munro.png)'
- en: Figure 8.16 Expanding all the confidences in annotators to give some weight
    to all labels. We have 0.9 confidence for each annotator, so we distribute the
    remaining 0.1 across the other labels.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.16 将所有注释员的置信度扩展到给予所有标签一定的权重。我们每个注释员的置信度为0.9，因此我们将剩余的0.1分配给其他标签。
- en: This example gives a conservative estimate to confidence, with a large amount
    of weight going to unseen answers. Note also this method is not the one we used
    when there was perfect agreement. There are several ways to get a more accurate
    probability distribution for the annotations, most of which involve a regression
    or machine learning model because they can’t be computed with simple heuristics
    like those used here. Chapter 9 covers these advanced approaches. This example
    is enough to build on for the remainder of this chapter.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例给出了对置信度的保守估计，大量权重分配给了未见过的答案。注意，这种方法并不是在完全一致的情况下我们所使用的。有几种方法可以得到更精确的注释概率分布，其中大多数涉及回归或机器学习模型，因为它们不能像这里使用的简单启发式方法那样计算。第9章涵盖了这些高级方法。这个例子足以支撑本章剩余部分的内容。
- en: 8.3.4 Annotator-reported confidences
  id: totrans-203
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3.4 注释员报告的置信度
- en: Annotators often have good intuitions about their own errors and which tasks
    are inherently harder than others. As part of the annotation process, you can
    ask when annotators are less than 100% confident on a certain task. An example
    with our data might look like figure 8.17.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 注释员通常对自己的错误以及哪些任务本质上比其他任务更难有很好的直觉。作为标注过程的一部分，您可以询问注释员在某个特定任务上的置信度低于100%时的情况。使用我们的数据的一个例子可能看起来像图8.17。
- en: '![](../Images/CH08_F17_Munro.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F17_Munro.png)'
- en: Figure 8.17 Requesting confidence explicitly from the annotator is an alternative
    (or addition) to calculating the confidence in their response from their accuracy
    and/or agreement.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.17 明确请求注释员的置信度是计算他们响应的准确性和/或一致性作为置信度的替代方案（或补充）。
- en: You could also request the entire probability distribution, as shown in figure
    8.18.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以请求整个概率分布，如图8.18所示。
- en: '![](../Images/CH08_F18_Munro.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F18_Munro.png)'
- en: Figure 8.18 Requesting the annotator confidence for every label as an alternative
    to dividing their remaining confidence across the other labels programmatically
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.18 以请求注释员对每个标签的置信度作为替代方案，而不是将剩余的置信度按程序分配给其他标签
- en: With the approach shown in figure 8.18, you can treat the entered amount as
    the probability for this label for this annotator, or you might choose to ignore
    all annotations when the annotator is less than 100% confident. This kind of interface
    can be extended to ask annotators how other annotators might respond to the question,
    which has some nice statistical outcomes that help with accuracy and diversity,
    especially for subjective tasks. These extensions are covered in chapter 9.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 使用图8.18所示的方法，您可以把输入的金额视为该注释员对该标签的概率，或者当注释员的置信度低于100%时，您可以选择忽略所有注释。这种类型的界面可以扩展为询问注释员其他注释员可能如何回答该问题，这有助于提高准确性和多样性，尤其是在主观任务中。这些扩展在第9章中有所介绍。
- en: Entering this information can greatly increase the annotation time for a simple
    labeling task like our example, so you will have to weigh the cost of capturing
    this information against the value that it adds.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 输入此类信息可以大大增加简单标注任务（如我们的示例）的标注时间，因此您必须权衡捕捉此类信息的成本与它所增加的价值。
- en: '8.3.5 Deciding which labels to trust: Annotation uncertainty'
  id: totrans-212
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3.5 决定信任哪些标签：注释不确定性
- en: 'When you have the probability distribution for your labels for a given task,
    you need to set a threshold for when not to trust a label and decide what to do
    if you don’t trust the label. You have three options when you don’t trust the
    label:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 当你有一个给定任务的标签的概率分布时，你需要设置一个阈值，以确定何时不相信标签，并决定如果不相信标签时该做什么。当你不相信标签时，你有三个选项：
- en: Assign the task to an additional annotator, and recalculate the confidence to
    see whether the confidence is high enough.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将任务分配给额外的标注员，并重新计算置信度，以查看置信度是否足够高。
- en: Assign the task to an expert annotator to adjudicate on the correct label (more
    on this topic in section 8.4).
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将任务分配给专家标注员以裁决正确的标签（更多关于这个主题的内容在第8.4节中）。
- en: Exclude this item from the dataset so that a potential error won’t produce errors
    in the model.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将此项目从数据集中排除，以防止潜在的错误在模型中产生错误。
- en: Generally, you want to avoid the third scenario because you are wasting the
    effort put into that task. You are also risking introducing bias into your data
    because the harder tasks are unlikely to be random. Budget or staffing constraints
    might prevent you from giving the same task to many people, however.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，你想要避免第三种情况，因为你正在浪费投入到该任务中的努力。你也在风险将偏差引入你的数据，因为更难的任务不太可能是随机的。然而，预算或人员限制可能阻止你将相同的任务分配给许多人。
- en: 'Before you can make a decision about whether you trust your label, you need
    to work out how to calculate overall confidence in your label. Let’s assume that
    our probability distribution is taken from the example we have been using in this
    chapter:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在你能够决定是否相信你的标签之前，你需要弄清楚如何计算你对标签的整体置信度。假设我们的概率分布是从本章中我们一直在使用的例子中得到的：
- en: Pedestrian = 0.553
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 行人 = 0.553
- en: Sign = 0.033
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 符号 = 0.033
- en: Cyclist = 0.380
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 骑行者 = 0.380
- en: Animal = 0.033
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 动物 = 0.033
- en: 'We have different ways to calculate our overall confidence uncertainty: look
    only at the 0.553 confidence for “Pedestrian,” take into account the next-most-confident
    label (“Cyclist”), or take all the potential labels into account.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有不同方法来计算我们的整体置信度不确定性：只看“行人”的0.553置信度，考虑下一个最自信的标签（“骑行者”），或者考虑所有潜在的标签。
- en: 'If you recall from chapter 3, this scenario is the same one that we had with
    uncertainty sampling for active learning. You have different ways to measure your
    uncertainty for annotation agreement, and each method makes a different assumption
    about what you care about. Using PyTorch, the example can be expressed as a tensor:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从第3章回忆起来，这个场景与主动学习中的不确定性采样相同。你有不同的方式来衡量你的标注一致性的不确定性，每种方法都对你关心的事情做出了不同的假设。使用PyTorch，这个例子可以表示为一个张量：
- en: prob = torch.tensor([0.533, 0.033, 0.380, 0.033])
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: prob = torch.tensor([0.533, 0.033, 0.380, 0.033])
- en: Reproducing the equations from chapter 3, we can calculate different uncertainty
    scores, as shown in figure 8.19.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 重新复制第3章中的方程，我们可以计算不同的不确定性分数，如图8.19所示。
- en: '![](../Images/CH08_F19_Munro.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F19_Munro.png)'
- en: Figure 8.19 Different methods of calculating an uncertainty score for a probability
    distribution. These methods are the same one that are used in active learning
    to calculate uncertainty (or confidence) from a model’s prediction, used here
    to calculate uncertainty for agreement among annotators.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.19 计算概率分布的不确定性分数的不同方法。这些方法与在主动学习中从模型的预测中计算不确定性（或置信度）的方法相同，此处用于计算标注者之间的一致性的不确定性。
- en: 'For our example, we get these uncertainty scores (remember that 1.0 is the
    most uncertain):'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的例子，我们得到这些不确定性分数（记住1.0是最不确定的）：
- en: Least confidence = 0.6227
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最小置信度 = 0.6227
- en: Margin of confidence = 0.8470
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 置信度范围 = 0.8470
- en: Ratio of confidence = 0.7129
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 置信度比 = 0.7129
- en: Entropy = 0.6696
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 熵 = 0.6696
- en: To get our overall confidence, instead of uncertainty, we subtract one of these
    metrics from 1.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 为了得到我们的整体置信度，而不是不确定性，我们从1中减去这些指标之一。
- en: After you have your uncertainty scores, you can plot your overall annotation
    accuracy at different scores on your ground truth data. Then you can use this
    plot to calculate the accuracy threshold that will give you the desired accuracy
    for your data (figure 8.20).
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在你有了不确定性分数之后，你可以在你的真实数据上绘制不同分数的整体标注准确性。然后你可以使用这个图来计算给你数据带来所需准确性的准确度阈值（图8.20）。
- en: '![](../Images/CH08_F20_Munro.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F20_Munro.png)'
- en: Figure 8.20 Calculating the threshold at which you can trust your annotations.
    In this example, the desired annotation accuracy of ~0.96, calculated on ground
    truth data, will be achieved if items with agreement uncertainty below ~0.65 are
    trusted.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.20计算你可以信任的标注的阈值。在这个例子中，如果信任低于~0.65的一致性不确定性的项目，那么在基准数据上计算出的期望标注准确率约为~0.96将得以实现。
- en: 'You plot a curve like the one shown in figure 8.20 for each of the uncertainty
    metrics as one way to decide which is the best for your data: which uncertainty
    sampling method selects the most items at the right threshold?'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以为每个不确定性指标绘制如图8.20所示的曲线，作为决定哪个最适合你的数据的一种方法：哪种不确定性采样方法在正确的阈值下选择了最多的项目？
- en: The rank order of the different uncertainty scores is identical for binary data,
    so if you have broken your task into binary problems, you can choose any one of
    these metrics and not worry about deciding which is best for your data.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 对于二元数据，不同不确定性分数的排序是相同的，所以如果你已经将任务分解为二元问题，你可以选择这些指标中的任何一个，而不用担心决定哪个最适合你的数据。
- en: As an alternative to calculating the threshold on your ground truth data, as
    in figure 8.20, you can find the best threshold for your machine learning model’s
    accuracy when trained on data at different thresholds. Try different thresholds
    for which items to ignore and then observe the downstream accuracy of your model
    with each threshold. Your model’s sensitivity to errors in the training data will
    probably change with the total number of training items, so you may want to keep
    revisiting past training data and reevaluate the threshold with each new addition
    to the training data.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 作为在图8.20中计算阈值的一种替代方法，你可以找到在数据不同阈值上训练时，你的机器学习模型准确性的最佳阈值。尝试不同的阈值以确定哪些项目可以忽略，然后观察每个阈值下模型的下游准确性。你的模型对训练数据中错误的敏感性可能会随着训练项目总数的增加而改变，因此你可能希望定期回顾过去的训练数据，并在每次添加新的训练数据时重新评估阈值。
- en: 8.4 Quality control by expert review
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.4 专家审查质量控制
- en: 'One of the most common methods of quality control is to engage SMEs to label
    the most important data points. Generally, experts are rarer and/or more expensive
    than other workers, so you typically give some tasks only to experts, often for
    one of these reasons:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 质量控制中最常见的方法之一是聘请领域专家对最重要的数据点进行标记。通常，专家比其他工作者更稀缺且/或更昂贵，因此你通常只给专家分配一些任务，通常有以下原因之一：
- en: To annotate a subset of items to become ground truth examples for guidelines
    and quality control
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了将部分项目标注为指南和质量控制的基准示例
- en: To adjudicate examples that have low agreement among nonexpert annotators
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了裁决非专家标注者之间低一致性的示例
- en: To annotate a subset of items to become machine learning evaluation items, for
    which human label accuracy is more important
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了将部分项目标注为机器学习评估项目，其中人工标签的准确性更为重要
- en: To annotate items that are known to be important for external reasons. If you
    are annotating data from your customers, for example, you may want expert annotators
    to focus on examples from the customers who generate the most revenue for you
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了标注已知因外部原因而重要的项目。例如，如果你正在标注来自客户的数据，你可能希望专家标注者专注于为你创造最多收入的客户的示例
- en: 'Figure 8.21 copies a figure from chapter 7 about using experts for review.
    It illustrates the first two examples in the preceding list: creating ground truth
    examples for guidelines and quality control, and adjudicating examples that have
    low agreement (confusing items).'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.21复制了第7章关于使用专家进行审查的图。它说明了前面列表中的前两个例子：为指南和质量控制创建基准示例，以及裁决具有低一致性的示例（混淆项）。
- en: '![](../Images/CH08_F21_Munro.png)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F21_Munro.png)'
- en: 'Figure 8.21 Three workflows for expert in-house annotation, repeated from chapter
    7\. The bottom two workflows show different ways that experts might be incorporated:
    adjudicating items that were difficult for annotators and creating guidelines
    for annotators. Both workflows might exist in the same task, and there might be
    many more steps for more complicated workflows.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.21重复了第7章中关于专家内部标注的三个工作流程。底部两个工作流程展示了专家可能被纳入的不同方式：裁决标注者难以处理的项目和为标注者制定指南。这两个工作流程可能存在于同一个任务中，并且对于更复杂的工作流程可能有更多步骤。
- en: To aggregate annotations after expert review, you can treat that expert as being
    one additional annotator, or you can ignore the previous annotations and calculate
    confidence in terms of the confidence in the expert(s). Choose the latter option
    if you know that your experts are much more reliable than most of your workforce.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在专家审查后汇总标注时，你可以将这位专家视为一个额外的标注员，或者你可以忽略之前的标注，并从专家（们）的置信度来计算置信度。如果你知道你的专家比大多数员工更可靠，请选择后者。
- en: 8.4.1 Recruiting and training qualified people
  id: totrans-251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.4.1 招聘和培训合格人员
- en: As we discussed in chapter 7, it is common to have SMEs in-house, but you can
    often outsource this expertise. An annotator who has been working on annotation
    for autonomous vehicles for several years, for example, is highly skilled. See
    chapter 7 for more information about choosing the right workforce for your tasks,
    including experts.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在第7章中讨论的，内部拥有领域专家是很常见的，但你通常可以将这种专业知识外包出去。例如，一位已经从事自动驾驶车辆标注工作多年的标注员，其技能非常高超。有关为你的任务选择合适的劳动力，包括专家在内的更多信息，请参阅第7章。
- en: 8.4.2 Training people to become experts
  id: totrans-253
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.4.2 培训人员成为专家
- en: You can take a data-driven approach to identifying experts within your nonexpert
    annotator pool. Keeping track of individual annotator accuracy, not overall dataset
    accuracy alone, will allow you to discover experts and promote them to that role.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以采取数据驱动的方法来识别非专家标注员池中的专家。跟踪个别标注员的准确率，而不仅仅是整体数据集的准确率，将帮助你发现专家并将他们提升到该角色。
- en: As a stepping stone to making some annotators expert adjudicators, you might
    allow those annotators to review but not adjudicate the work of others. This approach
    will let those people get intuition about the common errors that people are making.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 作为使一些标注员成为专家裁决者的垫脚石，你可能允许这些标注员审查但不裁决他人的工作。这种方法将使这些人获得关于人们常犯的常见错误的直觉。
- en: You should track the demographics of your experts, as you track the demographics
    of your annotators, to ensure diversity (except when tracking violates their privacy).
    An annotator’s age, country of residence, education level, gender, language fluency,
    and many other factors may be important for a task. If you don’t track the demographics
    of your annotators and use agreement as one metric for determining the best annotators,
    you run the risk of taking biases from your annotator pool into your expert annotator
    pool. For this reason, you should ideally identify experts from representative
    data, not a random sample.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该跟踪专家的人口统计数据，就像你跟踪标注员的人口统计数据一样，以确保多样性（除非跟踪违反了他们的隐私）。标注员的年龄、居住国家、教育水平、性别、语言流利度以及许多其他因素可能对任务很重要。如果你不跟踪标注员的人口统计数据，并使用一致性作为确定最佳标注员的一个指标，你可能会将标注员池中的偏见带入专家标注员池。因此，理想情况下，你应该从代表性数据中识别专家，而不是随机样本。
- en: 8.4.3 Machine-learning-assisted experts
  id: totrans-257
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.4.3 机器学习辅助的专家
- en: 'A common use case for SMEs is for their daily tasks to be augmented by machine
    learning. If you recall from chapter 1, human-in-the-loop machine learning can
    have two distinct goals: making a machine learning application more accurate with
    human input, and improving a human task with the aid of machine learning.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 对于中小企业来说，使用机器学习来增强日常任务是一种常见的用例。如果你还记得第1章的内容，人机交互的机器学习可以有两个不同的目标：通过人工输入使机器学习应用更加准确，以及通过机器学习的辅助来提高人工任务的效果。
- en: Search engines are a great example. You may be a domain expert in some scientific
    field searching for a particular research paper. The search engine helps you find
    this paper after you type the right search terms and learns from what you clicked
    to become more accurate.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索引擎是一个很好的例子。你可能是一位在某个科学领域具有专业知识的专家，正在寻找一篇特定的研究论文。在输入正确的搜索词后，搜索引擎会帮助你找到这篇论文，并通过你点击的内容来提高其准确性。
- en: Another common use case is e-discovery. Like search, but often with a more sophisticated
    interface, e-discovery is used in contexts such as audits where expert analysts
    are trying to find certain information in a large amount of text. Suppose the
    audit was for a legal case to detect fraud. An expert analyst in fraud detection
    might use a tool to find relevant documents and communications for that legal
    case, and that tool might adapt to what the analyst has found, surfacing all the
    similar documents and communications that have been tagged as relevant in the
    case so far. E-discovery was a $10 billion industry in 2020\. Although you may
    not have heard about it in machine learning circles, it is one of the single largest
    use cases for machine learning.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常见的用例是电子发现。与搜索类似，但通常具有更复杂的界面，电子发现用于审计等场景，专家分析师试图在大量文本中找到某些信息。假设审计是为了检测欺诈的法律案件。欺诈检测的专家分析师可能会使用一个工具来找到该法律案件的相关文档和通信，该工具可能会根据分析师找到的内容进行调整，显示迄今为止已标记为相关的所有类似文档和通信。2020年，电子发现是一个价值1000亿美元的行业。尽管您可能在机器学习领域没有听说过它，但它是最大的单一机器学习用例之一。
- en: 'You can deploy the same quality control measures in these cases: look for agreement
    between experts, employ adjudication by higher-level experts, evaluate against
    known answers, and so on. The expert, however, will likely be using an interface
    that supports their day-to-day tasks, not the annotation process itself. The interface
    may not be optimized for collecting training data, and their work process might
    introduce ordering effects that you can’t control. So the user interface implications
    for quality control in chapter 11 will be important in these contexts.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下，您可以部署相同的质量控制措施：寻找专家之间的共识，采用高级专家的裁决，对照已知答案进行评估，等等。然而，专家很可能会使用支持他们日常任务的界面，而不是注释过程本身。界面可能没有针对收集训练数据进行优化，而且他们的工作流程可能会引入您无法控制的顺序效应。因此，第11章中质量控制的用户界面在这些情况下将非常重要。
- en: 8.5 Multistep workflows and review tasks
  id: totrans-262
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.5 多步骤工作流程和审查任务
- en: 'One of the most effective ways to get higher-quality labels is to break a complicated
    task into smaller subtasks. You can get several benefits from breaking your task
    into simpler subtasks:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 提高标签质量的最有效方法之一是将复杂任务分解成更小的子任务。将任务分解成更简单的子任务可以获得以下好处：
- en: People generally work faster and more accurately on simpler tasks.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人们通常在更简单的任务上工作得更快、更准确。
- en: It is easier to perform quality control on simpler tasks.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对更简单的任务进行质量控制更容易。
- en: You can engage different workforces for different subtasks.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以为不同的子任务聘请不同的劳动力。
- en: 'The main downside is the overhead of managing the more complicated workflows.
    You will end up with a lot of custom code to route data based on certain conditions,
    and that code may not be reusable for other work. I have never seen an annotation
    platform that solved these problems with plug-and-play or drop-down options: there
    are almost always complicated combinations of conditions that require coding or
    a coding-like environment to be implemented fully.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 主要缺点是管理更复杂工作流程的开销。您最终会有一大堆基于特定条件路由数据的自定义代码，而这些代码可能无法用于其他工作。我从未见过一个通过即插即用或下拉选项解决这些问题的标注平台：几乎总是需要编码或类似编码环境来完全实现复杂的条件组合。
- en: Figure 8.22 shows how we might break an object labeling task into multiple steps,
    the last one being a review task for the preceding step.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.22展示了我们如何将对象标注任务分解成多个步骤，最后一个步骤是对前一个步骤的审查任务。
- en: '![](../Images/CH08_F22_Munro.png)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F22_Munro.png)'
- en: Figure 8.22 An example of a multistep workflow. If we divide steps 2–4 among
    the four object types, we have 13 total tasks. The individual responses in step
    1 and the evaluation in step 4 are binary tasks. Therefore, although our goal
    is to create a bounding box that requires the advanced quality control metrics
    from chapter 9, we can use the simpler label-based quality control metrics for
    this chapter. Compared with a single task that captures every bounding box in
    one go, we can expect higher throughput and accuracy because annotators are concentrating
    on one task at a time; easier budgeting if we’re paying per task, because there
    will be less variability in the time needed per task; and easier division of tasks
    among workforces if only some annotators are trusted for the most complicated
    tasks.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.22 多步骤工作流程的示例。如果我们把步骤2-4分配给四种对象类型，我们总共有13个任务。步骤1中的个别响应和步骤4中的评估是二元任务。因此，尽管我们的目标是创建一个需要第9章高级质量控制指标的边界框，但我们可以使用本章的更简单的基于标签的质量控制指标。与一次捕获所有边界框的单个任务相比，我们可以期望更高的吞吐量和准确性，因为标注者一次专注于一个任务；如果我们按任务付费，预算会更简单，因为每个任务所需的时间变化会更小；如果只有一些标注者被信任执行最复杂的任务，任务分配给工作队伍也会更简单。
- en: The most complicated workflow I have seen had about 40 tasks. This workflow,
    for a computer vision task for autonomous vehicles, had several steps for each
    type of object that was being tracked in addition to semantic segmentation.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 我见过的最复杂的流程大约有40个任务。这个流程是为自动驾驶汽车的计算机视觉任务设计的，除了语义分割外，对每种被跟踪的对象都有几个步骤。
- en: Simpler tasks have some user experience trade-offs. Generally, people appreciate
    the efficiency, but the tasks feel more repetitive, which can lead to fatigue.
    Also, some people, especially in-house SMEs, might be offended that a complicated
    task that they performed in the past has been broken down into simpler tasks;
    they may interpret this situation as implying that they are not sophisticated
    enough to solve all the steps in one interface. We will return to the topic of
    user experience in chapter 11\. In these cases, you can clarify that the workflow
    choice was made due to limitations related to getting good training data for machine
    learning, not because of annotator expertise.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的任务有一些用户体验权衡。通常，人们欣赏效率，但任务感觉更重复，这可能导致疲劳。此外，有些人，尤其是内部行业专家，可能会因为过去执行过的复杂任务被分解成简单任务而感到冒犯；他们可能将这种情况解释为暗示他们不够复杂，无法在一个界面中解决所有步骤。我们将在第11章回到用户体验的主题。在这些情况下，你可以明确指出，工作流程的选择是由于获取良好的机器学习训练数据的限制，而不是因为标注者的专业知识。
- en: 8.6 Further reading
  id: totrans-273
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.6 进一步阅读
- en: 'Quality control for annotation is a fast-changing field, and many of the problems
    we face are unsolved. A good high-level overview is “Truth Is a Lie: Crowd Truth
    and the Seven Myths of Human Annotation,” by Lora Aroyo and Chris Welty ([http://mng.bz/NYq7](http://mng.bz/NYq7)).'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 标注的质量控制是一个快速变化的领域，我们面临的问题中有许多尚未解决。一篇很好的高级概述是Lora Aroyo和Chris Welty所著的《真理是谎言：众包真理与人类标注的七个神话》（[http://mng.bz/NYq7](http://mng.bz/NYq7)）。
- en: 'For a recent overview specific to the problems related to agreement, I recommend
    “Let’s Agree to Disagree: Fixing Agreement Measures for Crowdsourcing,” by Alessandro
    Checco, Kevin Roitero, Eddy Maddalena, Stefano Mizzaro, and Gianluca Demartini
    ([http://mng.bz/DRqa](http://mng.bz/DRqa)).'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 对于与一致性相关问题的近期概述，我推荐Alessandro Checco、Kevin Roitero、Eddy Maddalena、Stefano Mizzaro和Gianluca
    Demartini所著的《让我们同意不同意：修复众包的一致性度量》（[http://mng.bz/DRqa](http://mng.bz/DRqa)）。
- en: Klaus Krippendorff has published Krippendorff’s alpha in several papers and
    books since it was developed in the 1970s. I recommend “Computing Krippendorff’s
    Alpha-Reliability,” which was most recently updated in 2011, but note that it
    calculates in terms of disagreement, not agreement, as in this book ([http://mng.bz/l1lB](http://mng.bz/l1lB)).
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 自从1970年代开发以来，Klaus Krippendorff已经在多篇文章和书籍中发表了Krippendorff的alpha系数。我推荐《计算Krippendorff的Alpha可靠性》，这是最近在2011年更新的，但请注意，它是以不一致性而不是一致性来计算的，正如这本书中所述（[http://mng.bz/l1lB](http://mng.bz/l1lB)）。
- en: 'A good recent paper about workflows that back off to experts, with advice about
    how annotators can explain their decision process effectively to experts, is “Revolt:
    Collaborative Crowdsourcing for Labeling Machine Learning Datasets,” by Joseph
    Chee Chang, Saleema Amershi, and Ece Semiha Kamar ([http://mng.bz/BRqr](http://mng.bz/BRqr)).'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '一篇关于退回到专家的工作流程的好论文，其中包含关于标注者如何有效地向专家解释他们的决策过程的建议，是Joseph Chee Chang、Saleema
    Amershi和Ece Semiha Kamar合著的“Revolt: Collaborative Crowdsourcing for Labeling Machine
    Learning Datasets”（[http://mng.bz/BRqr](http://mng.bz/BRqr)）。'
- en: For a good recent study of annotator bias, see “Are We Modeling the Task or
    the Annotator? An Investigation of Annotator Bias in Natural Language Understanding
    Datasets,” by Mor Geva, Yoav Goldberg, and Jonathan Berant ([http://mng.bz/d4Kv](http://mng.bz/d4Kv)).
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 想要了解标注者偏差的近期良好研究，请参阅Mor Geva、Yoav Goldberg和Jonathan Berant合著的“Are We Modeling
    the Task or the Annotator? An Investigation of Annotator Bias in Natural Language
    Understanding Datasets”（[http://mng.bz/d4Kv](http://mng.bz/d4Kv)）。
- en: 'For a paper showing how diversity among annotators improves accuracy but lowers
    agreement, see “Broad Twitter Corpus: A Diverse Named Entity Recognition Resource,”
    by Leon Derczynski, Kalina Bontcheva, and Ian Roberts ([http://mng.bz/ry4e](http://mng.bz/ry4e)).'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '想要了解标注者多样性如何提高准确性但降低一致性的论文，请参阅Leon Derczynski、Kalina Bontcheva和Ian Roberts合著的“Broad
    Twitter Corpus: A Diverse Named Entity Recognition Resource”（[http://mng.bz/ry4e](http://mng.bz/ry4e)）。'
- en: Although not free, *Handbook of Linguistic Annotation* edited by Nancy Ide and
    James Pustejovsky, is a comprehensive book that covers a lot of NLP tasks and
    has a good diversity of use cases. If you don’t want to purchase the book, consider
    emailing the authors of the chapters that are interesting to you; they might share
    their contributions.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然不是免费的，但由Nancy Ide和James Pustejovsky编辑的《Handbook of Linguistic Annotation》是一本涵盖了许多NLP任务且用例多样化的综合书籍。如果你不想购买这本书，可以考虑给你感兴趣的章节的作者发邮件；他们可能会分享他们的贡献。
- en: Summary
  id: totrans-281
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Ground truth examples are tasks that have known answers. By creating ground
    truth examples for the dataset, you can evaluate the accuracy of annotators, create
    guidelines for those annotators, and better calibrate other quality control techniques.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真实示例是具有已知答案的任务。通过为数据集创建真实示例，你可以评估标注者的准确性，为这些标注者制定指南，并更好地校准其他质量控制技术。
- en: You have many ways to calculate agreement in a dataset, including overall agreement,
    agreement between annotators, agreement between labels, and agreement at task
    level. Understanding each type of agreement will help you calculate the accuracy
    of your training and evaluation data and better manage your annotators.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你有多种方法在数据集中计算一致性，包括总体一致性、标注者间一致性、标签间一致性和任务级别的一致性。理解每种类型的一致性将帮助你计算训练和评估数据的准确性，并更好地管理你的标注者。
- en: For any evaluation metric, you should calculate an expected result that would
    occur by random chance as a baseline. This approach allows you to normalize your
    accuracy/agreement metric to a score adjusted for random chance, which makes the
    score more easily comparable across different tasks.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于任何评估指标，你应该计算一个随机机会下预期发生的结果作为基线。这种方法允许你将你的准确性/一致性指标标准化为考虑随机机会调整的分数，这使得分数在不同任务之间更容易比较。
- en: You will get the best results when using both ground truth data and interannotator
    agreement, because ground truth agreement allows you to better calibrate your
    agreement metrics, and agreement metrics can be applied to more annotations than
    is practical with ground truth alone.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当使用真实数据和标注者间一致性时，你会得到最佳结果，因为真实数据的一致性允许你更好地校准你的一致性指标，并且一致性指标可以应用于比仅使用真实数据更实际的更多标注。
- en: You can aggregate multiple annotations to create a single label for each task.
    This approach allows you to create the training data for your machine learning
    models and calculate the likelihood that each label is correct.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以将多个标注聚合起来，为每个任务创建一个单独的标签。这种方法允许你创建机器学习模型的训练数据，并计算每个标签正确的可能性。
- en: Quality control by expert review is one common method of resolving disagreements
    between annotators. Because experts tend to be rare and/or expensive, they can
    focus mostly on the tough edge cases and the cases that will become part of the
    guidelines for other annotators.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专家审查的质量控制是解决标注者之间分歧的一种常见方法。由于专家通常很少见且/或昂贵，他们可以主要关注困难边缘案例和将成为其他标注者指南一部分的案例。
- en: Multistep workflows allow you to break an annotation task into simpler tasks
    that flow into one another. This approach can create annotations faster and more
    accurately and allow easier-to-implement quality control strategies.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多步骤工作流程允许您将注释任务分解成一系列相互衔接的简单任务。这种方法可以更快、更准确地创建注释，并允许实施更易于操作的质量控制策略。
