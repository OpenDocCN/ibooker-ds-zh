- en: 9 Face-following camera
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 9 面部跟随相机
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Using the OpenCV library to detect faces in images
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用OpenCV库在图像中检测面部
- en: Measuring and optimizing face detection performance
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测量和优化面部检测性能
- en: Performing face detection in live videos
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在实时视频中执行面部检测
- en: Using servo motors to make a face-following camera
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用伺服电机制作面部跟随相机
- en: This chapter will first show how to use the OpenCV library to detect faces in
    images. Then, we will extend this functionality to detecting faces in a live video
    stream and measure and optimize our face detection process. Once we have a fast
    face detection mechanism in place, we will create an application to perform face
    detection in a live video stream. The last part of the chapter includes creating
    an application that can detect face movements and move the camera with motors
    in the direction of the detected face. Face detection is a demanding computer
    vision activity using machine learning to detect faces.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将首先展示如何使用OpenCV库在图像中检测面部。然后，我们将扩展这一功能以检测实时视频流中的面部，并测量和优化我们的面部检测过程。一旦我们建立了快速的面部检测机制，我们将创建一个应用程序在实时视频流中执行面部检测。本章的最后部分包括创建一个可以检测面部运动并使用电机将相机移动到检测到的面部方向的应用程序。面部检测是一个要求较高的计算机视觉活动，使用机器学习来检测面部。
- en: Machine learning plays an important role in the field of artificial intelligence,
    and it has many applications in robotics. In this chapter, we will create a robot
    that uses motors to move its camera based on the face it sees through image input
    data received from the camera. This is a powerful technique that can be extended
    to many robots that can automatically react and take action based on events detected
    in the environment. There are many autonomous robot systems created by taking
    sensor inputs robots are receiving, and they employ machine learning to decide
    what actions the robots should take to achieve their goals. These range from food
    delivery to construction, with robots preforming complex tasks such as bricklaying.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习在人工智能领域发挥着重要作用，并在机器人学中有许多应用。在本章中，我们将创建一个机器人，它根据从相机接收到的图像输入数据中的面部来使用电机移动其相机。这是一种强大的技术，可以扩展到许多可以自动对环境中的事件做出反应并采取行动的机器人。有许多自主机器人系统是通过获取机器人接收的传感器输入来创建的，它们使用机器学习来决定机器人应该采取哪些行动来实现其目标。这些包括从食物配送到建筑，机器人执行诸如砌砖等复杂任务。
- en: 9.1 Hardware stack
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.1 硬件栈
- en: Figure 9.1 shows the hardware stack, with the specific components used in this
    chapter highlighted. The robot will use a servo motor to move the attached camera
    in the direction of a detected face. Depending on whether the detected face is
    on the left or the right side of the camera, the servo will move the motor in
    the direction of the face. The initial applications in the chapter will focus
    on using the camera hardware to perform face detection, and later, the related
    servo movements will be added to the robot functionality.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1显示了硬件栈，本章中使用的特定组件被突出显示。机器人将使用伺服电机将连接的相机移动到检测到的面部方向。根据检测到的面部是在相机的左侧还是右侧，伺服电机将移动电机以面向面部。本章的初始应用将专注于使用相机硬件执行面部检测，稍后，相关的伺服运动将被添加到机器人功能中。
- en: '![](../Images/CH09_F01_Alsabbagh.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH09_F01_Alsabbagh.png)'
- en: 'Figure 9.1 Hardware stack: servo motors will be used to move the camera toward
    a detected face.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1 硬件栈：将使用伺服电机将相机移动到检测到的面部。
- en: 9.2 Software stack
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.2 软件栈
- en: Details of the specific software used in this chapter are described in figure
    9.2\. We start the chapter by creating the `detect_face` application that will
    perform face detection using the OpenCV library on a single image. Then, we use
    the `measure_face` script and the `statistics` and `time` modules to measure the
    performance of our face detection process. Once we apply some performance enhancements,
    we will create the `face` library that can perform fast face detection, thus making
    the `live_face` application possible. The `live_face` application performs face
    detection in a live video stream. The chapter ends with the `follow` application
    that moves the servo motors to follow face movements. We will use the Linux video
    subsystem and camera hardware for the face detection. The `crickit` library will
    be used to control the servo motors.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中使用的特定软件的详细信息在图 9.2 中描述。我们通过创建 `detect_face` 应用程序开始本章，该应用程序将使用 OpenCV 库在单个图像上执行人脸检测。然后，我们使用
    `measure_face` 脚本和 `statistics` 以及 `time` 模块来测量人脸检测过程的性能。一旦我们应用了一些性能提升，我们将创建 `face`
    库，它可以执行快速的人脸检测，从而使 `live_face` 应用程序成为可能。`live_face` 应用程序在实时视频流中执行人脸检测。本章以 `follow`
    应用程序结束，该应用程序通过移动伺服电机来跟踪人脸运动。我们将使用 Linux 视频子系统和摄像头硬件进行人脸检测。`crickit` 库将用于控制伺服电机。
- en: '![](../Images/CH09_F02_Alsabbagh.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH09_F02_Alsabbagh.png)'
- en: 'Figure 9.2 Software stack: the OpenCV library will be used to perform face
    detection.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.2 软件堆栈：OpenCV 库将用于执行人脸检测。
- en: 9.3 Detecting faces in an image
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.3 在图像中检测人脸
- en: 'The first step is to perform face detection on a single image. We need to create
    a Python application that meets the following requirements:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是在单个图像上执行人脸检测。我们需要创建一个满足以下要求的 Python 应用程序：
- en: The OpenCV computer vision library should be used to detect the location of
    a face in an image.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenCV 计算机视觉库应用于检测图像中的人脸位置。
- en: The application should be able to draw a rectangle around the detected face
    and place a marker on its center.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序应能够围绕检测到的人脸绘制矩形并在其中心放置标记。
- en: The `x,y` coordinates of the center of the face should be calculated and returned.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应计算并返回人脸中心的 `x,y` 坐标。
- en: The final requirement of calculating the center of the face will be very helpful
    later in the chapter, as we will use it to decide in which direction to move the
    servo motor.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 计算人脸中心的最终要求将在本章的后续部分非常有用，因为我们将会用它来决定伺服电机移动的方向。
- en: 9.3.1 Exploring face detection
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.1 探索人脸检测
- en: The OpenCV documentation ([https://docs.opencv.org/4.x/](https://docs.opencv.org/4.x/))
    is an excellent source that provides good tutorials on common topics such as face
    detection. Under the Python tutorials section, it mentions that face detection
    is covered by the `objdetect` module. Specifically, the tutorial on the `objdetect`
    cascade classifier gives a detailed explanation of both theory and face detection
    application in OpenCV.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV 文档（[https://docs.opencv.org/4.x/](https://docs.opencv.org/4.x/））是一个极好的资源，提供了关于人脸检测等常见主题的良好教程。在
    Python 教程部分，它提到人脸检测由 `objdetect` 模块涵盖。具体来说，关于 `objdetect` 级联分类器的教程详细解释了理论以及 OpenCV
    中的人脸检测应用。
- en: OpenCV performs face detection using the Haar feature-based cascade classifiers.
    This approach uses machine learning to train a cascade function from a large set
    of positive and negative images of faces. The positive images contain faces, and
    the negative images have no faces in them. Once the function is trained, we can
    then use it to detect faces in any image we provide.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV 使用基于 Haar 特征的级联分类器进行人脸检测。这种方法使用机器学习从大量正负人脸图像中训练级联函数。正图像包含人脸，而负图像中没有人脸。一旦函数被训练，我们就可以使用它来检测我们提供的任何图像中的人脸。
- en: 'Pretrained models are shipped as part of the OpenCV library and can be used
    directly. These models are XML files that can be found in the data directory of
    the OpenCV installation. We can start working with these models and performing
    face detection in the read–evaluate–print loop (REPL). The first step is to import
    the `cv2` package:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练模型作为 OpenCV 库的一部分提供，可以直接使用。这些模型是可以在 OpenCV 安装的数据目录中找到的 XML 文件。我们可以开始使用这些模型，并在读取-评估-打印循环（REPL）中执行人脸检测。第一步是导入
    `cv2` 包：
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To locate the path of the OpenCV installation, we can inspect the `__path__`
    attribute:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 要定位 OpenCV 安装路径，我们可以检查 `__path__` 属性：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The `__path__` attribute provides a list of locations for the `cv2` package.
    The first item in the list is what we are interested in. We can save it in the
    `CV2_DIR` variable for further use:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '`__path__`属性提供了`cv2`包的位置列表。列表中的第一个项目是我们感兴趣的。我们可以将其保存到`CV2_DIR`变量中，以供进一步使用：'
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now we can calculate the path of the model XML file for face detection and
    save it in a variable called `CLASSIFIER_PATH`:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以计算用于人脸检测的模型XML文件的路径，并将其保存到名为`CLASSIFIER_PATH`的变量中：
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We can now create a classifier from the model file using the `CascadeClassifier`
    function. Once created, we save the classifier in a variable called `face_classifier`:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用`CascadeClassifier`函数从模型文件创建一个分类器。创建后，我们将分类器保存到名为`face_classifier`的变量中：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This classifier can be used to detect faces in images. Let’s take the classifier
    for a spin and start detecting faces. Take a photo of a face with the camera,
    and save the image as `photo.jpg` in the same directory as the REPL session. We
    can open this image using the `imread` function:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这个分类器可以用于在图像中检测人脸。让我们来试一试这个分类器，开始检测人脸。用相机拍摄一张人脸照片，并将图像保存为`photo.jpg`，与REPL会话所在的目录相同。我们可以使用`imread`函数打开这张图像：
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As expected, when we check the `shape` attribute of the image, we can see that
    the resolution of the image is 640 by 480 px with the three color components for
    each pixel. Figure 9.3 shows the image we are using in this REPL session:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期，当我们检查图像的`shape`属性时，我们可以看到图像的分辨率为640 x 480像素，每个像素有三个颜色分量。图9.3显示了我们在本REPL会话中使用的图像：
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/CH09_F03_Alsabbagh.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH09_F03_Alsabbagh.png)'
- en: 'Figure 9.3 Image of face: an image of a face is taken with the Raspberry Pi
    camera.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.3 人脸图像：使用树莓派相机拍摄的人脸图像。
- en: 'Our classifier will check the pixel intensities in different regions of the
    image. To do this, you want the image to be represented as a grayscale image instead
    of color. We can convert our color image to grayscale by calling `cvtColor`:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的分类器将检查图像不同区域中的像素强度。为此，你希望图像以灰度图像的形式表示，而不是彩色。我们可以通过调用`cvtColor`将我们的彩色图像转换为灰度图像：
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: If we inspect the `shape` attribute of our new `gray` image, we can see that
    it no longer has the three color components for each pixel. Instead, it has a
    single value for pixel intensity ranging from `0` to `255`, indicating a value
    from `0` for black, then higher values for gray, all the way to white at `255`.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们检查新`gray`图像的`shape`属性，我们可以看到它不再具有每个像素的三个颜色分量。相反，它有一个表示像素强度的单一值，范围从`0`到`255`，表示从`0`的黑色，然后是灰度的更高值，一直到`255`的白色。
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The second operation we will perform on the image before face detection is
    histogram equalization. This operation improves the contrast in an image, which
    in turn improves the accuracy of our face detection. We save the prepared image
    into a variable called `clean`. Figure 9.4 shows what the resulting image will
    look like after we have applied histogram equalization:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在人脸检测之前，我们将在图像上执行的第二个操作是直方图均衡化。这个操作提高了图像的对比度，从而提高了人脸检测的准确性。我们将准备好的图像保存到名为`clean`的变量中。图9.4显示了应用直方图均衡化后结果的图像。
- en: '[PRE9]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/CH09_F04_Alsabbagh.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH09_F04_Alsabbagh.png)'
- en: 'Figure 9.4 Equalized histogram: the contrast of the image is improved after
    histogram equalization.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.4 均衡直方图：直方图均衡化后图像的对比度得到改善。
- en: 'We can now call the `detectMultiScale` method on our classifier that will perform
    face detection on our image and return the results as a list of detected faces:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以在我们的分类器上调用`detectMultiScale`方法，该方法将在我们的图像上执行人脸检测，并将检测结果作为检测到的人脸列表返回：
- en: '[PRE10]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'When we inspect the length of `faces`, we can see that a single face was successfully
    detected in the image:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们检查`faces`的长度时，我们可以看到图像中成功检测到了一个单独的人脸：
- en: '[PRE11]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Inspecting `faces` shows that for each detected face, a set of values is provided
    relating to that detected face. Each set of values relates to a matching rectangle:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 检查`faces`显示，对于每个检测到的人脸，都提供了一组与该检测到的人脸相关的值。每组值与一个匹配的矩形相关：
- en: '[PRE12]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We can save the rectangle values for the first detected face into variables
    indicating the top left coordinates `x, y` of the rectangle, as well as the variables
    `w,` `h` for the width and height of the rectangle:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将第一个检测到的人脸的矩形值保存到变量中，表示矩形的左上角坐标`x, y`，以及表示矩形宽度和高度的变量`w,` `h`：
- en: '[PRE13]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We can see the top-left corner of the matching face is located at coordinates
    `(215, 105):`
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到匹配人脸的左上角位于坐标`(215, 105)`：
- en: '[PRE14]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We now have enough to slap together our first face detection application. Let’s
    take what we have learned and bring it all together into a script to detect faces
    in an image.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经有了足够的东西来构建我们的第一个面部检测应用程序。让我们将所学的一切整合到一个脚本中，以便在图像中检测面部。
- en: 'Going deeper: Machine learning with OpenCV'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 深入学习：使用OpenCV进行机器学习
- en: The OpenCV documentation has a comprehensive Machine Learning Overview ([https://docs.opencv.org/4.x/dc/dd6/ml_intro.html](https://docs.opencv.org/4.x/dc/dd6/ml_intro.html))
    that is a great launching point to delve deeper into the topic of machine learning
    in OpenCV.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV文档有一个全面的机器学习概述([https://docs.opencv.org/4.x/dc/dd6/ml_intro.html](https://docs.opencv.org/4.x/dc/dd6/ml_intro.html))，这是一个深入了解OpenCV中机器学习主题的绝佳起点。
- en: At the heart of machine learning are algorithms that use training data to build
    and train models that can then make predictions based on that data. Once these
    trained models are in place, we can feed them new data that has not been seen
    before by the algorithms, and they can make predictions based on the data. In
    this chapter, we used a model that was trained on a set of face images to detect
    the presence and locations of faces in new images.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的核心是使用训练数据构建和训练模型，这些模型可以基于该数据做出预测。一旦这些训练模型就位，我们可以向它们提供算法之前未见过的新的数据，它们可以根据数据做出预测。在本章中，我们使用了一个在一系列面部图像上训练的模型来检测新图像中面部存在和位置。
- en: Another computer vision application is performing OCR (optical character recognition)
    on hand-written digits. The OpenCV project has samples of 5,000 handwritten digits
    that can be used as training data to train our models. The k-nearest neighbors
    algorithm can be used to train our models and then use them to recognize the digits
    in images. There is an excellent example of this in the Python tutorials of the
    OpenCV documentation under the Machine Learning section.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个计算机视觉应用是对手写数字执行OCR（光学字符识别）。OpenCV项目有5,000个手写数字的样本，可以用作训练数据来训练我们的模型。k最近邻算法可以用来训练我们的模型，然后使用它们来识别图像中的数字。在OpenCV文档的Python教程的机器学习部分有一个关于此的极好示例。
- en: 9.3.2 Marking detected faces
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.2 标记检测到的面部
- en: 'We will create a script to perform face detection on an image and then draw
    a rectangle around the matching face. We will also calculate the center of the
    matching rectangle and place a marker at the center point. Once we complete the
    detection and shape drawing, we will display the final image in our graphical
    application. The first step will be to import the `cv2` library:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一个脚本，用于在图像上执行面部检测，并在匹配的面部周围绘制矩形。我们还将计算匹配矩形的中心，并在中心点放置一个标记。一旦我们完成检测和形状绘制，我们将在我们的图形应用程序中显示最终图像。第一步将是导入`cv2`库：
- en: '[PRE15]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The value for the color blue is saved in the variable `BLUE`, and the location
    of the `cv2` library is saved in `CV2_DIR`. We can now set our `CLASSIFIER_PATH`
    by using `CV2_DIR`. Our face classifier is then created and saved in `face_classifier`:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 蓝色的值保存在变量`BLUE`中，`cv2`库的位置保存在`CV2_DIR`中。现在我们可以使用`CV2_DIR`设置我们的`CLASSIFIER_PATH`。然后我们的面部分类器在`face_classifier`中创建并保存：
- en: '[PRE16]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The `prep_face` function will prepare an image for face detection by converting
    it to grayscale and applying histogram equalization. The prepared image is then
    returned:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '`prep_face`函数将通过将其转换为灰度并应用直方图均衡化来准备图像以进行面部检测。然后返回准备好的图像：'
- en: '[PRE17]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We will then define `get_center` to calculate the center coordinates of a rectangle.
    We can use it to calculate the center of a detected face. The function receives
    the standard values relating to a rectangle and then returns the center point
    as an `x,y` coordinate pair:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将定义`get_center`来计算矩形的中心坐标。我们可以用它来计算检测到的面部的中心。该函数接收与矩形相关的标准值，然后返回一个`x,y`坐标对作为中心点：
- en: '[PRE18]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The `detect_face` function receives an image and returns the center coordinates
    of a matching face. It first calls `prep_face` to prepare the image for face detection,
    and then `detectMultiScale` is called to detect faces in the image. If a face
    is found, we save the rectangle values of the first matching face into the variables
    `x,` `y,` `w,` `h`. Then, we calculate the center of the face and save this value
    in `center`. The `rectangle` function is used to draw a rectangle around the face,
    and `drawMarker` is used to place a marker at the center of the face. Finally,
    the coordinates of the center of the face are returned:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '`detect_face` 函数接收一个图像并返回匹配面部的中心坐标。它首先调用 `prep_face` 函数来准备图像以便面部检测，然后调用 `detectMultiScale`
    函数在图像中检测面部。如果找到面部，我们将第一个匹配面部的矩形值保存到变量 `x`、`y`、`w`、`h` 中。然后，我们计算面部的中心并保存此值到 `center`。使用
    `rectangle` 函数在面部周围绘制矩形，并使用 `drawMarker` 函数在面部中心放置标记。最后，返回面部中心的坐标：'
- en: '[PRE19]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The `main` function loads our face image into a variable called `frame`. Then,
    `detect_ face` is called to perform face detection, and the center of the face
    is saved in the `center` variable. These coordinates are printed out, and an image
    of the face is shown using `imshow`. The `waitKey` function is called to display
    the image until a key is pressed in the application:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`main` 函数将我们的面部图像加载到名为 `frame` 的变量中。然后调用 `detect_face` 函数执行面部检测，并将面部中心保存到 `center`
    变量中。这些坐标被打印出来，并使用 `imshow` 显示面部图像。调用 `waitKey` 函数显示图像，直到在应用程序中按下键：'
- en: '[PRE20]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The full script can be saved as `detect_face.py` on the Pi and then executed.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 完整脚本可以保存为 `detect_face.py` 在Pi上，然后执行。
- en: 'Listing 9.1 `detect_face.py`: Detecting a face and marking a matching face'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.1 `detect_face.py`：检测面部并标记匹配面部
- en: '[PRE21]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: When this script is run, it will perform face detection on the `photo.jpg` image
    and draw the matching rectangle and marker around the detected face. Figure 9.5
    shows what the application will look like once it has completed face detection
    and drawn shapes around the matching face.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 当此脚本运行时，它将在 `photo.jpg` 图像上执行面部检测，并在检测到的面部周围绘制匹配的矩形和标记。图9.5显示了应用程序完成面部检测并在匹配面部周围绘制形状后的样子。
- en: '![](../Images/CH09_F05_Alsabbagh.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH09_F05_Alsabbagh.png)'
- en: 'Figure 9.5 Face detection: rectangle and marker show the location of the detected
    face.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.5 面部检测：矩形和标记显示了检测到的面部位置。
- en: Now that we have the groundwork in place for face detection in images, we can
    move on to the exciting task of performing face detection in a live video stream.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经为图像中的面部检测打下了基础，我们可以继续进行在实时视频流中进行面部检测的激动人心的任务。
- en: 9.4 Detecting faces in live video
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.4 在实时视频中检测面部
- en: 'Detecting faces in live video follows a similar approach to detecting faces
    in a single image. The main difference is the more demanding performance requirements
    of doing face detection fast enough to keep up with a live video stream. We need
    to create a Python application that meets the following requirements:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在实时视频中检测面部的方法与在单个图像中检测面部的方法类似。主要区别在于，为了跟上实时视频流的速率，面部检测的性能要求更高。我们需要创建一个满足以下要求的Python应用程序：
- en: Face detection should be performed on each frame captured from the camera video
    stream.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应在从相机视频流捕获的每一帧上执行面部检测。
- en: Face detection should be fast enough to keep up with the camera frame rate.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 面部检测的速度应足够快，以跟上相机的帧率。
- en: The live video stream in the application should be displayed with any detected
    faces shown with a matching rectangle and marker.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在应用程序中，实时视频流应显示任何检测到的面部，使用匹配的矩形和标记显示。
- en: The first task at hand will be to measure the performance of our face detection
    to see whether it is executed fast enough to keep up with the rate of the images
    we will receive from the video stream.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的首要任务是衡量我们的面部检测性能，看看它是否执行得足够快，能够跟上我们从视频流中接收到的图像速率。
- en: 9.4.1 Measuring face detection performance
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.4.1 测量面部检测性能
- en: We know from the previous chapter that our camera will be capturing images at
    a rate of 30 frames per second. We need the face detection process to run faster
    than this frame rate so that it can keep up with the video stream. We will create
    a script to perform face detection multiple times and then report the average
    frame rate achieved for face detection.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 从前一章我们知道，我们的相机将以每秒30帧的速度捕获图像。我们需要面部检测过程运行得比这个帧率快，以便它能跟上视频流的速率。我们将创建一个脚本来执行多次面部检测，然后报告面部检测达到的平均帧率。
- en: 'The `cv2` library is imported to perform face detection. The `mean` function
    is imported to calculate the average frame rate. The `time` module will be used
    to measure the execution time of the face detection operation:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 导入`cv2`库以执行人脸检测。导入`mean`函数以计算平均帧率。将使用`time`模块来测量人脸检测操作的执行时间：
- en: '[PRE22]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The functions and process of face detection are identical to what was used
    in the `detect_face.py` script. We will use the `get_detect_timing` function to
    measure the execution time of face detection. This function records the start
    time and then makes a call to the `detect_face` function. At the end, it calculates
    the elapsed time in seconds and returns the value:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 人脸检测的功能和过程与`detect_face.py`脚本中使用的相同。我们将使用`get_detect_timing`函数来测量人脸检测的执行时间。这个函数记录开始时间，然后调用`detect_face`函数。最后，它计算经过的时间（以秒为单位）并返回该值：
- en: '[PRE23]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Our `main` function will, as before, open the `photo.jpg` image and save it
    in `frame`. Then we make an initial call to `detect_face` and print out the coordinates
    of the center of the matching face. Next, we make repeated calls to `get_detect_timing`
    to capture a sample of 10 execution times. We take the average of this sample
    and calculate and report the average frames per second achieved. During each face
    detection, we use `frame.copy()` to provide a clean copy of the frame on each
    face detection:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`main`函数将像以前一样打开`photo.jpg`图像，并将其保存到`frame`中。然后我们调用`detect_face`并打印出匹配人脸中心的坐标。接下来，我们重复调用`get_detect_timing`以捕获10次执行时间的样本。我们取这个样本的平均值，计算并报告平均每秒帧数。在每次人脸检测中，我们使用`frame.copy()`来提供每次人脸检测的干净副本：
- en: '[PRE24]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The full script can be saved as `measure_face.py` on the Pi and then executed.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 完整脚本可以保存为`measure_face.py`在Pi上，然后执行。
- en: 'Listing 9.2 `measure_face.py`: Measuring face detection performance'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.2 `measure_face.py`：测量人脸检测性能
- en: '[PRE25]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'When this script is run, it will perform face detection on the `photo.jpg`
    image. The coordinates of the center of the detected face are printed out in the
    terminal. Then, we take 10 samples of measuring the time required to detect a
    face. Based on the average of these samples, the frame rate is calculated and
    reported. We can see that the reported frame rate of 10.1 frames per second is
    well below the 30 frames per second that we need:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 当运行此脚本时，它将在`photo.jpg`图像上执行人脸检测。检测到的脸中心的坐标将在终端中打印出来。然后，我们测量检测人脸所需时间的10个样本。基于这些样本的平均值，计算并报告帧率。我们可以看到报告的帧率为每秒10.1帧，远低于我们需要的每秒30帧：
- en: '[PRE26]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Now that we have quantified our face detection performance, we can see that
    there is a performance problem, and we can get to work at improving the performance
    of our face detection process so that we can meet, and hopefully exceed, the 30
    frames per second requirement.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经量化了我们的人脸检测性能，我们可以看到存在性能问题，我们可以着手提高我们的人脸检测过程的性能，以便我们可以满足，并希望超过每秒30帧的要求。
- en: 9.4.2 Reducing the number of pixels to process
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.4.2 减少处理像素的数量
- en: Our face detection operation does not need a large image to accurately detect
    faces. If we call our face classifier with a smaller image, it will have less
    pixels to process and will return the results faster. So the strategy we will
    take is to perform the face detection on an image that has been resized to be
    much smaller and thus processed faster.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的人脸检测操作不需要大图像就能准确检测人脸。如果我们用较小的图像调用我们的面部分类器，它将处理更少的像素，并更快地返回结果。因此，我们将采取的策略是在一个被调整得小得多的图像上执行人脸检测，这样处理速度就会更快。
- en: We will resize the image to be 20% percent the size of the original image. We
    can find through experimentation that if this value is significantly smaller than
    10%, it will affect detection accuracy. We will see that setting the value at
    20% meets our performance needs and is within a safe range.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将图像调整到原始图像大小的20%。通过实验我们可以发现，如果这个值显著小于10%，它将影响检测精度。我们将看到将值设置为20%符合我们的性能需求，并且处于安全范围内。
- en: 'We can open a REPL session and do some calculations to get a sense of how much
    we have reduced the quantity of pixels in the image by doing this scaling. Our
    20% scaling is equivalent to reducing the width and height of the image by a factor
    of 5\. We can easily see this with the following calculation:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以打开一个REPL会话并做一些计算，以了解通过这种缩放我们减少了图像中像素数量的多少。我们的20%缩放相当于将图像的宽度和高度减少了5倍。我们可以通过以下计算轻松地看到这一点：
- en: '[PRE27]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The captured image has a width of `640` and a height of `480`. We can calculate
    the height and width of the scaled-down image with the following calculations:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 捕获的图像宽度为`640`，高度为`480`。我们可以通过以下计算来计算缩小后的图像的高度和宽度：
- en: '[PRE28]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We can see that the resized image will have a width of `128` and a height of
    `96`. We can now calculate the total number of pixels in the original and the
    resized image:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，调整大小后的图像宽度将为`128`，高度为`96`。现在我们可以计算原始图像和调整大小后的图像中的像素总数：
- en: '[PRE29]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now, we can take these two pixel counts and divide them to find out by what
    factor we have reduced the total number of pixels:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以将这两个像素计数相除，以找出我们减少了多少像素总数：
- en: '[PRE30]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We have reduced the total number of pixels to process by a 25x factor. This
    is a big reduction in data to process and should yield a big improvement in processing
    speed. Figure 9.6 shows the significant difference in image sizes when we place
    the two images side by side. We can cross-check this figure by squaring the reduction
    factor on the width and height:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过25倍的因素减少了需要处理的像素总数。这大大减少了需要处理的数据量，应该会显著提高处理速度。图9.6显示了将两个图像并排放置时图像尺寸的显著差异。我们可以通过将宽度和高度的缩放因子平方来交叉检查此图：
- en: '[PRE31]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: As expected, it produced the same result of a 25x reduction factor.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期，它产生了25倍的缩放因子。
- en: '![](../Images/CH09_F06_Alsabbagh.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH09_F06_Alsabbagh.png)'
- en: 'Figure 9.6 Image reduction: the original and reduced images are kept side by
    side for comparison.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.6 图像缩小：将原始图像和缩小后的图像并排放置以进行比较。
- en: We can take the smaller image and run it through our face detection script to
    inspect the results. Figure 9.7 shows that the image is clearly pixelated, but
    this doesn’t pose a problem for the face detection procedure.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将较小的图像通过我们的面部检测脚本运行来检查结果。图9.7显示该图像明显像素化，但这并不影响面部检测过程。
- en: '![](../Images/CH09_F07_Alsabbagh.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH09_F07_Alsabbagh.png)'
- en: 'Figure 9.7 Detection on smaller images: face detection is successful for images
    with smaller resolution.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.7 在较小图像上的检测：对于分辨率较低的图像，面部检测是成功的。
- en: Now that we have our initial calculations out of the way, we can move on to
    implement the new faster version of our application.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了初始计算，我们可以继续实现我们应用程序的新快速版本。
- en: 9.4.3 Optimizing face detection performance
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.4.3 优化面部检测性能
- en: 'This implementation will build on the previous one and mainly add the image
    reduction steps to gain a performance boost. First, we will import the `cv2` library
    to perform face detection:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 此实现将在前一个基础上构建，并主要添加图像缩小步骤以提高性能。首先，我们将导入`cv2`库以执行面部检测：
- en: '[PRE32]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The scaling factor is saved in the `DETECT_SCALE` variable:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放因子保存在`DETECT_SCALE`变量中：
- en: '[PRE33]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The `resize` function receives the image and the desired scale to resize the
    image and return the new smaller image. The new width and height of the image
    are calculated based on the provided `scale` and saved in `size`. The `cv2.resize`
    function is then called on the image. The OpenCV documentation ([https://docs.opencv.org/4.x](https://docs.opencv.org/4.x))
    on the resize function gives guidance to use the `INTER_AREA` interpolation when
    shrinking an image and `INTER_CUBIC` when enlarging it. We are shrinking the image,
    so we use `INTER_AREA`:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '`resize`函数接收图像和期望的缩放比例，以调整图像大小并返回新的较小图像。图像的新宽度和高度基于提供的`scale`计算，并保存在`size`中。然后对图像调用`cv2.resize`函数。OpenCV文档（[https://docs.opencv.org/4.x](https://docs.opencv.org/4.x)）中关于`resize`函数的说明提供了在缩小图像时使用`INTER_AREA`插值以及在放大图像时使用`INTER_CUBIC`插值的指导。我们正在缩小图像，因此我们使用`INTER_AREA`：'
- en: '[PRE34]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The `detect_face` function now has a performance enhancement. After `prep_face`
    is called, a call is made to `resize` to create a smaller image before face detection.
    Then, `detectMultiScale` is called using `small`. When the rectangle values are
    returned, we divide them by `DETECT_SCALE` so that they can be mapped again to
    the original full-resolution image. In this way, we can show details of the detected
    face on the full-sized original image but obtain a performance gain by doing face
    detection on a smaller image. The rest of the code remains the same:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '`detect_face`函数现在有了性能提升。在调用`prep_face`之后，在面部检测之前调用`resize`以创建一个较小的图像。然后使用`small`调用`detectMultiScale`。当返回矩形值时，我们将它们除以`DETECT_SCALE`，以便可以将它们再次映射到原始全分辨率图像上。这样，我们可以在全尺寸原始图像上显示检测到的面部细节，同时通过在较小的图像上进行面部检测来获得性能提升。其余的代码保持不变：'
- en: '[PRE35]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The library can be saved as `face.py` on the Pi to be imported by other applications.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 该库可以保存为`face.py`在Pi上，以便其他应用程序导入。
- en: 'Listing 9.3 `face.py`: Providing a fast face detection library'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.3 `face.py`：提供快速面部检测库
- en: '[PRE36]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'To see this library in action, we will create a new script that will import
    the library and make multiple calls to the face detection functions and measure
    their performance. We first import `cv2`, `mean`, and `time` as we have done before
    to open images, calculate averages, and measure execution times. We then import
    the `detect_face` function from our new `face` library:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看此库的实际效果，我们将创建一个新的脚本，该脚本将导入库并多次调用面部检测函数并测量其性能。我们首先导入`cv2`、`mean`和`time`，就像我们之前打开图像、计算平均值和测量执行时间一样。然后从我们的新`face`库中导入`detect_face`函数：
- en: '[PRE37]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: The rest of the application has the same functions as those created in the `measure
    _face.py` script to measure execution time and report the average frame rate achieved.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序的其余部分具有与在`measure_face.py`脚本中创建的相同的功能，用于测量执行时间并报告达到的平均帧率。
- en: The full script can be saved as `fast_face.py` on the Pi and then executed.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 完整脚本可以保存为`fast_face.py`在Pi上，然后执行。
- en: 'Listing 9.4 `fast_face.py`: Reporting performance of the fast face detection
    functions'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.4 `fast_face.py`：报告快速面部检测函数的性能
- en: '[PRE38]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'When this script is run, it will call our new faster face detection implementation.
    We can see from the results that a big performance gain has been achieved, as
    now we have reached a frame rate of 75.6 frames per second. This gives us a performance
    boost that is over seven times faster than the previous approach to face detection:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 当运行此脚本时，它将调用我们新的更快面部检测实现。我们可以从结果中看到，我们已经实现了很大的性能提升，现在我们已经达到了每秒75.6帧的帧率。这给我们带来了比之前面部检测方法快七倍以上的性能提升：
- en: '[PRE39]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: This frame rate is also way above the 30 frames per second target that we were
    hoping to achieve. We can now proceed to use this new improved approach to face
    detection in a live video stream.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这个帧率也远远超过了我们希望达到的每秒30帧的目标。现在我们可以继续使用这种新的改进方法在实时视频流中进行面部检测。
- en: 9.4.4 Showing detected faces in live video
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.4.4 在实时视频中显示检测到的面部
- en: 'In the following script, we will capture images from the camera video stream
    face detection and then show the detected faces in an application window. The
    `cv2` library is imported to capture images from the camera video stream. The
    `detect_face` function is imported to perform face detection:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下脚本中，我们将从摄像头视频流中捕获图像，然后在一个应用程序窗口中显示检测到的面部。导入`cv2`库以从摄像头视频流中捕获图像。导入`detect_face`函数以执行面部检测：
- en: '[PRE40]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'As we have done before, the key code for the Esc key is saved in `ESC_KEY`.
    It will be used to exit the graphical application by pressing the Esc key:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前所做的那样，Esc键的关键代码保存在`ESC_KEY`中。它将通过按下Esc键来退出图形应用程序：
- en: '[PRE41]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The `main` function will save a video capture object in the variable `cap`.
    We then check whether the capture device was opened correctly. We enter an event
    loop that we continue looping in until the Esc or Q key is pressed. In each loop
    iteration, we capture a frame from the video stream and call the `detect_face`
    function on the captured image. We then call `imshow` to show the captured image
    with any detected faces marked. When this loop is exited, we release the video
    capture device by calling the `cap.release` function:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '`main`函数将视频捕获对象保存到变量`cap`中。然后我们检查捕获设备是否正确打开。我们进入一个事件循环，直到按下Esc或Q键才退出循环。在每次循环迭代中，我们从视频流中捕获一帧，并在捕获的图像上调用`detect_face`函数。然后我们调用`imshow`来显示带有任何检测到的面部标记的捕获图像。当退出此循环时，通过调用`cap.release`函数释放视频捕获设备：'
- en: '[PRE42]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The full script can be saved as `live_face.py` on the Pi and then executed.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 完整脚本可以保存为`live_face.py`在Pi上，然后执行。
- en: 'Listing 9.5 `live_face.py`: Showing detected faces in a live video stream'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.5 `live_face.py`：在实时视频流中显示检测到的面部
- en: '[PRE43]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: When this script is run, it will continually capture images from the video stream.
    Each image is passed through our face detection functions. If a face is detected,
    a rectangle is drawn around the detected face with a marker placed at its center.
    The video stream with face detection is shown in the application window until
    the Esc key or Q key is pressed to exit the application.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 当运行此脚本时，它将不断从视频流中捕获图像。每个图像都通过我们的面部检测函数。如果检测到面部，则在检测到的面部周围绘制一个矩形，并在其中心放置一个标记。带有面部检测的视频流在应用程序窗口中显示，直到按下Esc键或Q键退出应用程序。
- en: '![](../Images/CH09_F08_Alsabbagh.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH09_F08_Alsabbagh.png)'
- en: 'Figure 9.8 Camera on Pan-Tilt Kit: the camera is mounted on the kit to enable
    camera movements.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.8 Pan-Tilt Kit上的相机：相机安装在该套件上，以实现相机移动。
- en: Figure 9.8 shows what the camera looks like once it is mounted on the Pan-Tilt
    Kit. The two servo motors give the camera the ability to be moved in different
    directions.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.8显示了相机安装到Pan-Tilt Kit上的样子。两个伺服电机使相机能够向不同方向移动。
- en: In the next section, we will use the servo motor to move the camera in the direction
    of the detected face.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将使用伺服电机将相机移动到检测到的人脸方向。
- en: 9.5 Creating a face-following robot
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.5 创建跟随人脸的机器人
- en: 'Now that we can detect faces fast enough to process live video, we can take
    our code to the next level and have the robot react to where you position your
    face. The robot will move the camera to follow your face. We need to create a
    Python application that meets the following requirements:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们能够快速检测人脸，足以处理实时视频，我们可以将我们的代码提升到下一个层次，并让机器人对你的面部位置做出反应。机器人将移动相机以跟随你的面部。我们需要创建一个满足以下要求的Python应用程序：
- en: It should be able to recognize whether a face is detected in the left, center,
    or right of frame.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它应该能够识别人脸是否在画面左侧、中心或右侧被检测到。
- en: When the face is detected in the left or right, the camera should move toward
    the face.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当在左侧或右侧检测到人脸时，相机应该朝人脸移动。
- en: In the application, a live video stream with detected faces marked and a grid
    showing the three zones (left, center, and right) should be displayed.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在应用程序中，应该显示带有检测到的人脸标记的实时视频流以及显示三个区域（左、中、右）的网格。
- en: '![](../Images/CH09_F09_Alsabbagh.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH09_F09_Alsabbagh.png)'
- en: 'Figure 9.9 Camera zones: the camera area is split into three detection zones.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.9 相机区域：相机区域被分成三个检测区域。
- en: Showing the three zones in the application will make the application more interactive,
    as people will be able to tell which zone their face has been detected in and
    where the camera will move.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用程序中显示这三个区域将使应用程序更具交互性，因为人们将能够告诉他们的面部被检测在哪个区域，以及相机将移动到哪个位置。
- en: 9.5.1 Zoning the face detection
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.5.1 人脸检测分区
- en: We can split up what the robot sees into three areas or zones. When a face is
    detected in the center zone, we don’t have to do anything because the camera is
    facing the person. If the face is detected in the left zone, then we will move
    the servo so that the camera places the face in the center zone. If the face is
    detected in the right zone, we will move the servo again but in the opposite direction.
    We will focus only on moving the camera left and right using the pan movements
    of the servo motor. Figure 9.9 shows the three zones for face detection.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将机器人看到的区域分成三个区域或区域。当在中心区域检测到人脸时，我们不需要做任何事情，因为相机正对着人。如果人脸在左区检测到，那么我们将移动伺服器，使相机将人脸放置在中心区域。如果人脸在右区检测到，我们将再次移动伺服器，但方向相反。我们将只关注使用伺服电机的摆动运动来左右移动相机。图9.9显示了人脸检测的三个区域。
- en: 'Now, let’s pop into a REPL session and see how we can split the camera viewing
    area into these three zones. First, we will import `cv2` for drawing on images
    and `numpy` for creating a new blank image:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们进入一个REPL会话，看看我们如何将相机观看区域分成这三个区域。首先，我们将导入`cv2`用于在图像上绘制和`numpy`用于创建一个新的空白图像：
- en: '[PRE44]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'We will save the width and height of our camera images into the variables `IMG_WIDTH`
    and `IMG_HEIGHT`. This will make our code more readable:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把相机图像的宽度和高度保存在变量`IMG_WIDTH`和`IMG_HEIGHT`中。这将使我们的代码更易于阅读：
- en: '[PRE45]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'We can get the center or halfway point of the width by dividing `IMG_WIDTH`
    by two:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将`IMG_WIDTH`除以二来得到宽度的中心或中点：
- en: '[PRE46]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Now, let’s take this center position and move left 50 px to get the position
    of the line between the left and center zones. We will save this value in a variable
    called `LEFT_X`:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将这个中心位置向左移动50像素，以获得左区和中心区之间的线条位置。我们将把这个值保存在一个名为`LEFT_X`的变量中：
- en: '[PRE47]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'By moving right 50 px from the center, we get the position of the line between
    the center and right zones. We save this value in `RIGHT_X`:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 从中心向右移动50像素，我们得到中心区和右区之间的线条位置。我们将这个值保存在`RIGHT_X`中：
- en: '[PRE48]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'We can save the value for the color green in a variable called `GREEN`:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将绿色的值保存在一个名为`GREEN`的变量中：
- en: '[PRE49]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Next, let’s create a blank color image with our desired dimensions:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们创建一个具有我们所需尺寸的空白彩色图像：
- en: '[PRE50]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'We can draw a grid showing the three zones by drawing a rectangle around the
    center zone:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过围绕中心区绘制一个矩形来绘制显示三个区域的网格：
- en: '[PRE51]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The last step will be to save what we have created so that we can see the image.
    We will use `imwrite` to save the image as the filename `zones.jpg`:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是将我们创建的内容保存下来，以便我们可以看到图像。我们将使用 `imwrite` 将图像保存为文件名 `zones.jpg`：
- en: '[PRE52]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Figure 9.10 shows what the image will look like once we have drawn the zone
    grid. The center zone is set to be narrower than the left and right zones. In
    this way, we can make the camera more sensitive to moving left and right when
    the face moves around the frame.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.10显示了在绘制区域网格后图像将呈现的样子。中心区域被设置为比左右区域窄。这样，当面部在框架周围移动时，我们可以使相机对左右移动更加敏感。
- en: '![](../Images/CH09_F10_Alsabbagh.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH09_F10_Alsabbagh.png)'
- en: 'Figure 9.10 Zone grid: the zone grid is drawn using the rectangle method.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.10 区域网格：区域网格是通过矩形方法绘制的。
- en: 9.5.2 Moving motors to follow faces
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.5.2 将电机移动以跟踪面部
- en: We can now have a go at tackling the script to follow the person’s face as they
    look at different zones within the camera’s viewing area. We can build on the
    experimentation we did in the previous section.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以尝试编写脚本以跟踪人在相机视场内查看不同区域时的面部。我们可以基于上一节所做的实验进行构建。
- en: 'We import the `cv2` library to capture images from the camera. The `detect_face`
    function is imported and will perform face detection as we have seen before. Finally,
    we use the `crickit` module to control the servo motor that has a camera attached
    to it:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们导入 `cv2` 库以从相机捕获图像。导入 `detect_face` 函数，它将执行与之前所见相同的面部检测。最后，我们使用 `crickit`
    模块来控制连接相机的伺服电机：
- en: '[PRE53]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Next, we define `ESC_KEY` and `GREEN` to store the key code for the Esc key
    and the value for the color green. The image height and width are defined in `IMG_WIDTH`
    and `IMG_HEIGHT`. We then calculate the values for `LEFT_X` and `RIGHT_X` to help
    keep track of the zone the face is detected in:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义 `ESC_KEY` 和 `GREEN` 以存储Esc键的键码和绿色值。图像的高度和宽度在 `IMG_WIDTH` 和 `IMG_HEIGHT`
    中定义。然后我们计算 `LEFT_X` 和 `RIGHT_X` 的值，以帮助跟踪检测到的面部所在的区域：
- en: '[PRE54]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'As we have done in chapter 8, we create a variable called `PAN` to keep track
    of values relating to our servo that performs the pan movement. Namely, we keep
    a reference to the servo object to the minimum, maximum, and starting angles of
    the servo. We also keep the actuation range setting in `range`. As done in the
    previous chapter, we store the value of the angle changes at each step in `ANGLE_STEP`.
    We use `MOVE` to map the left, center, and right zones to their associated servo
    movements:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在第8章中所做的那样，我们创建了一个名为 `PAN` 的变量来跟踪与执行水平移动的伺服电机相关的值。具体来说，我们保存了伺服电机的最小、最大和起始角度的引用。我们还在
    `range` 中保存了激活范围设置。正如前一章所做的那样，我们在 `ANGLE_STEP` 中存储了每一步的角度变化值。我们使用 `MOVE` 将左侧、中央和右侧区域映射到它们相关的伺服电机运动：
- en: '[PRE55]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The `get_zone` function will return the zone of the detected face based on
    the values of `LEFT_X` and `RIGHT_X`:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '`get_zone` 函数将根据 `LEFT_X` 和 `RIGHT_X` 的值返回检测到的面部的区域：'
- en: '[PRE56]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The `init_motors` function is used to initialize the servo motor’s starting
    position and actuation range:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '`init_motors` 函数用于初始化伺服电机的起始位置和激活范围：'
- en: '[PRE57]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'We will use the `move_motor` function to move the servo based on the position
    of the detected face. We first calculate the zone by calling `get_zone`. Then,
    we look up the angle change and save it in `change`. Next, we apply the new angle
    if a change is detected and if the new angle falls within our minimum and maximum
    angle range:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 `move_motor` 函数根据检测到的面部位置移动伺服电机。我们首先通过调用 `get_zone` 计算区域。然后，我们查找角度变化并将其保存到
    `change` 中。接下来，如果检测到变化且新角度在最小和最大角度范围内，我们应用新的角度：
- en: '[PRE58]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'When we create a new video capture object, we call `check_capture_device` to
    check the device. We check whether it was opened successfully and whether the
    width and height of images being captured by the device match our `IMG_WIDTH`
    and `IMG_HEIGHT` values:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们创建一个新的视频捕获对象时，我们调用 `check_capture_device` 来检查设备。我们检查它是否成功打开，以及捕获的图像的宽度和高度是否与我们的
    `IMG_WIDTH` 和 `IMG_HEIGHT` 值匹配：
- en: '[PRE59]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'The `main` function first calls `init_motors` to initialize the servo motors.
    Then we create a video capture device and check it by calling `check_capture_device`.
    We then enter an event loop that we only exit if either the Esc or the Q key is
    pressed. In each loop, we grab an image from the video stream and save it in `frame`.
    We then call `detect_face` to perform face detection and return us to the position
    of the center of the detected face. If a face was detected, we call `move_motor`
    with the `x` coordinate of the detected face. We then draw our zone grid onto
    the image by calling `cv2.rectangle` with the related dimensions. The last step
    of the loop is to show the latest video frame in the application by calling `imshow`.
    When we exit the loop, we call `cap.release` to release the video capture device:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '`main` 函数首先调用 `init_motors` 来初始化伺服电机。然后我们创建一个视频捕获设备，并通过调用 `check_capture_device`
    来检查它。接着我们进入一个事件循环，只有当按下 Esc 或 Q 键时才会退出。在每次循环中，我们从视频流中抓取一张图像并将其保存到 `frame` 中。然后我们调用
    `detect_face` 来执行人脸检测，并返回到检测到的人脸中心位置。如果检测到人脸，我们使用检测到的人脸的 `x` 坐标调用 `move_motor`。然后我们通过调用
    `cv2.rectangle` 并使用相关尺寸在图像上绘制我们的区域网格。循环的最后一步是通过调用 `imshow` 在应用程序中显示最新的视频帧。当我们退出循环时，我们调用
    `cap.release` 来释放视频捕获设备：'
- en: '[PRE60]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: The full script can be saved as `follow.py` on the Pi and then executed.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 整个脚本可以保存为 `follow.py` 在 Pi 上，然后执行。
- en: 'Listing 9.6 `follow.py`: Moving the camera to follow detected faces'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.6 `follow.py`：将摄像头移动到跟随检测到的人脸
- en: '[PRE61]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: When this script is run, you can look into the camera and see your face in the
    live camera feed with a border placed around your detected face. The center of
    the face is also marked on the live image with a crosshair. From this marker,
    we can tell which zone the face is in. If you move the face outside the center
    zone, the servo will automatically reposition the camera to put your face back
    in this zone. Figure 9.11 shows a face that has been detected and marked in the
    left zone, which then makes the servo motors move the cameras to place the face
    back in the center zone.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 当运行此脚本时，你可以对着摄像头看，在实时摄像头流中看到你的脸，并在检测到的人脸周围放置一个边界。人脸的中心也用十字线在实时图像上标记。从这个标记中，我们可以知道人脸位于哪个区域。如果你将人脸移出中心区域，伺服电机将自动重新定位摄像头，将你的脸放回这个区域。图
    9.11 显示了一个在左侧区域被检测并标记的人脸，然后伺服电机移动摄像头将人脸放回中心区域。
- en: '![](../Images/CH09_F11_Alsabbagh.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH09_F11_Alsabbagh.png)'
- en: 'Figure 9.11 Zoned face: the face is detected and marked in the left zone.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.11 区域人脸：人脸在左侧区域被检测并标记。
- en: This application gave us a chance to apply machine learning to our robotics
    project by using computer vision and face tracking. In the coming chapters, we
    will use other computer vision functionalities, such as QR code detection, to
    help our robot interact even further with its environment by using the camera
    as a way to see their environment.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用计算机视觉和面部跟踪，这个应用给了我们机会将机器学习应用到我们的机器人项目中。在接下来的章节中，我们将使用其他计算机视觉功能，如二维码检测，通过使用摄像头作为观察环境的方式，帮助我们的机器人与环境进行更深入的交互。
- en: 'Robots in the real world: Robotics vision processing'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 现实世界中的机器人：机器人视觉处理
- en: Robots can use computer vision to do feature detection to extract visual features
    such as corners and edges of objects. With this feature detection in place, robots
    can detect and classify objects they see in their environment.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 机器人可以使用计算机视觉进行特征检测，以提取诸如物体的角和边缘等视觉特征。有了这种特征检测，机器人可以检测和分类它们在环境中看到的物体。
- en: One application of this object interaction is creating robots that can pick
    and place objects in manufacturing and logistics. Using computer vision, they
    identify an object, grab it, and then move it from one location to another.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 这种对象交互的一个应用是创建可以在制造和物流中拾取和放置物体的机器人。使用计算机视觉，它们识别一个物体，抓取它，然后将其从一个位置移动到另一个位置。
- en: Inspection robots are another case that combines computer vision and robotics
    to create robots that can be used as part of the quality control process in manufacturing
    to perform fully automated inspections of manufactured products.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 检查机器人是另一种将计算机视觉和机器人技术结合在一起的情况，以创建可以用于制造过程中的质量控制流程的机器人，以执行制造产品的完全自动化检查。
- en: Summary
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: A fast face detection mechanism is required to perform face detection in a live
    video stream.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要一个快速的人脸检测机制来在实时视频流中执行人脸检测。
- en: Servo motors are used to move the attached camera in the direction of a detected
    face.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 伺服电机用于将连接的摄像头移动到检测到的人脸方向。
- en: Haar feature-based cascade classifiers are used in OpenCV to perform face detection.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Haar特征级联分类器在OpenCV中用于执行人脸检测。
- en: Histogram equalization improves the contrast of an image and helps to improve
    the accuracy of face detection.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 直方图均衡化可以改善图像的对比度，有助于提高人脸检测的准确性。
- en: Detected faces will have a matching rectangle and marker drawn around them.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 被检测到的人脸周围将绘制一个匹配的矩形和标记。
- en: The face detection must be able to handle a camera image rate of at least 30
    frames per second for live face recognition to work.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人脸检测必须能够处理至少每秒30帧的相机图像速率，以便实时人脸识别能够工作。
- en: Calling the face classifier with smaller images can make face detection faster.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用较小图像调用人脸分类器可以使人脸检测更快。
