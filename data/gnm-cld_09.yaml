- en: Chapter 8\. Automating Analysis Execution with Workflows
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 8 章。使用工作流自动化分析执行
- en: So far, we’ve been running individual commands manually in the terminal. However,
    the overwhelming majority of genomics work proper—the secondary analysis, in which
    we go from raw data to distilled information that we’ll then feed into downstream
    analysis to ultimately produce biological insight—involves running the same commands
    in the same order on all the data as it rolls off the sequencer. Look again at
    the GATK Best Practices workflows described in Chapters [6](ch06.xhtml#best_practices_for_germline_short_varia)
    and [7](ch07.xhtml#gatk_best_practices_for_somatic_variant); imagine how tedious
    it would be to do all that manually for every sample. Newcomers to the field often
    find it beneficial to run through the commands involved step by step on test data,
    to gain an appreciation of the key steps, their requirements, and their quirks—that’s
    why we walked you through all that in Chapters [6](ch06.xhtml#best_practices_for_germline_short_varia)
    and [7](ch07.xhtml#gatk_best_practices_for_somatic_variant)—but at the end of
    the day, you’re going to want to automate all of that as much as possible. Automation
    not only reduces the amount of tedious manual work you need to do, but also increases
    the throughput of your analysis and reduces the opportunity for human error.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直在终端手动运行单个命令。然而，大多数基因组学工作实际上—即从原始数据到我们将进一步用于下游分析以最终产生生物学见解的浓缩信息的次生分析—涉及按照相同的顺序在所有数据上运行相同的命令。再次看看第
    [6](ch06.xhtml#best_practices_for_germline_short_varia) 和 [7](ch07.xhtml#gatk_best_practices_for_somatic_variant)
    章描述的 GATK 最佳实践工作流程；想象一下为每个样本手动完成所有这些工作会有多么乏味。该领域的新手通常发现，逐步运行测试数据中涉及的命令有助于了解关键步骤、其要求及其特点—这就是为什么我们在第
    [6](ch06.xhtml#best_practices_for_germline_short_varia) 和 [7](ch07.xhtml#gatk_best_practices_for_somatic_variant)
    章中向您详细介绍了这些内容—但归根结底，您希望尽可能自动化所有这些过程。自动化不仅减少了您需要做的繁琐手动工作量，还提高了分析的吞吐量，并减少了人为错误的机会。
- en: In this chapter, we cover that shift from individual commands or one-off scripts
    to repeatable workflows. We show you how to use a workflow management system (*Cromwell*),
    and language, WDL, that we selected primarily for their portability. We walk you
    through writing your first example workflow, executing it, and interpreting Cromwell’s
    output. Then, we do the same thing with a couple of more realistic workflows that
    run GATK and use scatter-gather parallelism.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了从单个命令或一次性脚本转向可重复使用的工作流的转变。我们向您展示了如何使用工作流管理系统（*Cromwell*）和语言 WDL，这两者主要因其可移植性而被选择。我们将引导您编写第一个示例工作流，执行它，并解释
    Cromwell 的输出。然后，我们将使用几个更加现实的工作流再做同样的事情，运行 GATK 并使用散集-聚集并行处理。
- en: Introducing WDL and Cromwell
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 WDL 和 Cromwell
- en: You might remember that we introduced the concept of workflows in the technology
    primer ([Chapter 3](ch03.xhtml#computing_technology_basics_for_life_sc)). As we
    noted at the time, many tooling options are available for writing and running
    workflows, with a variety of features, strengths, and weaknesses. We can’t tell
    you the *best option overall*, because much of that determination would depend
    on your particular backgrounds and needs. For the purposes of this book, we’ve
    selected an option, the combination of Cromwell and WDL, that is most suitable
    for the breadth of audience and scope of needs that we are targeting.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能还记得，我们在技术概述中引入了工作流的概念（[第 3](ch03.xhtml#computing_technology_basics_for_life_sc)
    章）。当时我们指出，有许多工具选项可用于编写和运行工作流，具有各种功能、优势和劣势。我们不能告诉您*整体上最佳的选择*，因为很大程度上取决于您的特定背景和需求。出于本书的目的，我们选择了
    Cromwell 和 WDL 的组合，因为它最适合我们面向的广泛受众和需求范围。
- en: We already briefly introduced WDL at that time, as well, but let’s recap the
    main points given that it was half a book ago and a lot of water under the bridge.
    As just mentioned, its full name is *Workflow Description Language*, but it’s
    generally referred to as WDL (pronounced “widdle”) for short. It’s a DSL commonly
    used for genomics workflows that was originally developed at the Broad Institute
    and has since then evolved into a community-driven open source project under the
    auspices of a public group named [OpenWDL](https://openwdl.org). As a workflow
    language, it’s designed to be very accessible to bioinformatics newcomers who
    do not have any formal training in software programming while maximizing portability
    across different systems.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之前我们已经简要介绍了WDL，但考虑到这已经是半本书之前的事情，也经历了许多变故，让我们重新概述一下主要内容。正如刚才提到的，它的全名是*Workflow
    Description Language*，但通常简称为WDL（发音为“widdle”）。它是一种DSL，通常用于基因组工作流程，在Broad Institute最初开发，后来演变为由名为[OpenWDL](https://openwdl.org)的公共团体推动的社区驱动开源项目。作为工作流语言，它被设计成非常适合生物信息学新手，这些人没有软件编程的正式培训，同时最大限度地提高在不同系统间的可移植性。
- en: The workflow management system we’re going to use to actually *run* workflows
    written in WDL is Cromwell, an open source application, also developed at the
    Broad Institute. Cromwell is designed to be runnable in just about any modern
    Java-enabled computing environment, including popular HPC systems like Slurm and
    SGE, commercial clouds like GCP and AWS, and any laptop or desktop computer running
    on some flavor of Linux. This portability is a core feature of Cromwell, which
    is intended to facilitate running the same workflows at multiple institutions
    in order to maximize scientific collaboration and computational reproducibility
    in research. Another major portability-oriented feature of Cromwell is that it
    supports (but does not require) the use of containers for providing the code that
    you want to run within each component task of a given workflow. You’ll have the
    opportunity to try running both ways in the exercises in this chapter.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将用来实际*运行*WDL编写的工作流的工作流管理系统是Cromwell，这是一款在Broad Institute开发的开源应用程序。Cromwell设计为能够在几乎任何现代Java支持的计算环境中运行，包括像Slurm和SGE这样的流行HPC系统，商业云平台如GCP和AWS，以及运行某种Linux版本的任何笔记本电脑或台式电脑。这种可移植性是Cromwell的核心特性，旨在促进在多个机构运行相同工作流，以最大化科学研究中的协作和计算重现性。Cromwell另一个面向可移植性的主要特性是，它支持（但不需要）使用容器来提供您想要在给定工作流的每个组件任务中运行的代码。您将有机会在本章的练习中尝试两种运行方式。
- en: Finally, continuing in the spirit of collaboration and interoperability, Cromwell
    is also designed to support multiple workflow languages. Currently, it supports
    WDL as well as the CWL, another popular workflow language designed for portability
    and computational reproducibility.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在合作和互操作性精神的继续中，Cromwell还设计支持多种工作流语言。目前，它支持WDL以及CWL，另一种设计用于可移植性和计算可重现性的流行工作流语言。
- en: 'Cromwell offers two modes of operation: the one-shot run mode and the server
    mode. The *one-shot run mode* is a simple way of running Cromwell that involves
    a single command line: you give it a workflow and a file that lists workflow inputs,
    and it will start running, execute the workflow, and finally shut down when the
    workflow is done. This is convenient for running workflows episodically with minimal
    hassle, and it’s what we use in the exercises in this chapter. The *server mode*
    of operation involves setting up a persistent server that is always running, and
    submitting workflow execution requests to that server via a REST API (a type of
    programmatic interface).'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Cromwell提供两种操作模式：一次性运行模式和服务器模式。*一次性运行模式*是运行Cromwell的简单方法，涉及单个命令行：您提供一个工作流和一个列出工作流输入的文件，它将开始运行，执行工作流，并在工作流完成时关闭。这对于间断运行工作流非常方便，几乎没有麻烦，这也是我们在本章练习中使用的方式。*服务器模式*的操作涉及设置一个持久运行的服务器，并通过REST
    API（一种编程接口）向该服务器提交工作流执行请求。
- en: Starting the Cromwell server is quite easy. After it’s running, it offers functionality
    that is not available in the single-run mode, some of which we cover in [Chapter 11](ch11.xhtml#running_many_workflows_conveniently_in).
    However, managing its operation securely on an ongoing basis requires a specialized
    skill set that most individual researchers or small groups without dedicated support
    staff do not possess. In [Chapter 11](ch11.xhtml#running_many_workflows_conveniently_in),
    we introduce you to Terra, a managed system operated by the Broad Institute that
    provides access to a persistent Cromwell server through a GUI as well as an API.
    That will give you the opportunity to try out Cromwell in server mode without
    having to administer a server yourself.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 启动 Cromwell 服务器非常容易。一旦运行，它提供的功能在单次运行模式下是不可用的，其中一些我们在[第 11 章](ch11.xhtml#running_many_workflows_conveniently_in)中介绍。然而，要安全地管理其运行，需要具备专门的技能，这是大多数个人研究人员或没有专门支持人员的小团体所不具备的。在[第
    11 章](ch11.xhtml#running_many_workflows_conveniently_in)中，我们向您介绍 Terra，这是由 Broad
    Institute 操作的托管系统，通过 GUI 和 API 提供对持久 Cromwell 服务器的访问。这将使您有机会在服务器模式下尝试 Cromwell，而无需自己管理服务器。
- en: Note
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: We won’t cover Cromwell server administration in this book, so see the [Cromwell
    documentation](https://oreil.ly/8T7j8) if you’re interested in learning more.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会在本书中涵盖 Cromwell 服务器管理内容，如果您有兴趣了解更多信息，请参阅[Cromwell 文档](https://oreil.ly/8T7j8)。
- en: Whether you run it as a one-shot or in server mode, Cromwell has interesting
    features that aim to promote efficiency and scalability—but no one wants to read
    a laundry list of features in a book like this, so let’s move on to the exercises
    and we’ll bring up those key features as they become relevant along the way.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您将其作为一次性任务还是在服务器模式下运行，Cromwell 都具有旨在提高效率和可伸缩性的有趣功能，但没有人愿意在这本书中读取一长串功能清单，因此让我们转向练习，并在适当的时候提到这些关键功能。
- en: Installing and Setting Up Cromwell
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装和设置 Cromwell
- en: In this chapter, we examine and execute some workflows written in WDL to become
    acquainted with the basic structure of the language and learn how Cromwell manages
    inputs and outputs, logs, and so on. For continuity with the previous chapters,
    we run Cromwell on the GCP Compute Engine VM that we used earlier, in Chapters
    [4](ch04.xhtml#first_steps_in_the_cloud) and [5](ch05.xhtml#first_steps_with_gatk).
    However, we’re no longer running anything from within the GATK container. Instead,
    we install and run Cromwell directly in the VM environment.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将检查和执行一些用 WDL 编写的工作流程，以熟悉语言的基本结构，并了解 Cromwell 如何管理输入和输出、日志等。为了与前几章保持连贯性，我们在之前使用的
    GCP Compute Engine VM 上运行 Cromwell，即在[第 4 章](ch04.xhtml#first_steps_in_the_cloud)和[第
    5 章](ch05.xhtml#first_steps_with_gatk)中使用过的环境，不再从 GATK 容器内运行任何内容。相反，我们直接在 VM 环境中安装和运行
    Cromwell。
- en: You’ll need to run a few installation commands because Cromwell requires Java,
    which is not preinstalled on the VM we’re using. To do so, log back in to your
    VM via SSH, just as you did in earlier chapters. Remember that you can always
    find your list of VM instances in the GCP console by going directly to the [Compute
    Engine](https://oreil.ly/sGeug), or, in the menu of GCP services on the left side
    of the console, click Compute Engine, if you’ve forgotten the URL.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要运行几个安装命令，因为 Cromwell 需要 Java，而我们使用的虚拟机上没有预安装。为此，请通过 SSH 再次登录到您的虚拟机，就像在前几章中所做的那样。请记住，您始终可以在
    GCP 控制台中找到您的 VM 实例列表，直接访问[Compute Engine](https://oreil.ly/sGeug)，或者在控制台左侧的 GCP
    服务菜单中点击 Compute Engine，如果您忘记了 URL。
- en: 'In your VM, type `**java -version**` at the prompt. You should get the following
    output:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的虚拟机中，在提示符下键入 `**java -version**`。您应该会得到以下输出：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Cromwell requires Java version 8, so let’s install the `openjdk-8-jre-headless`
    option, which is a lightweight environment sufficient for our needs:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Cromwell 需要 Java 版本 8，因此让我们安装 `openjdk-8-jre-headless` 选项，这是一个轻量级环境，足以满足我们的需求：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This triggers the installation process, which should run to completion without
    error. You might see a few notifications but as long as you see that final `done`
    output, you should be fine. You can run the Java version check again to satisfy
    yourself that the installation was successful:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这将触发安装过程，应该可以顺利完成。您可能会看到一些通知，但只要看到最终的 `done` 输出，您就应该没问题。您可以再次运行 Java 版本检查以确保安装成功：
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'With Java installed, let’s set up Cromwell itself, which comes with a companion
    utility called `Womtool` that we use for syntax validation and creating input
    files. They are both distributed as compiled *.jar* files, and we’ve included
    a copy in the book bundle, so you don’t need to do anything fancy except point
    to where they are located. To keep our commands as short as possible, let’s set
    up an environment variable pointing to their location. Let’s call it *BIN* for
    binary, a term often used to refer to the compiled form of a program:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 安装了Java后，让我们设置Cromwell本身，它附带一个称为 `Womtool` 的伴侣实用程序，用于语法验证和创建输入文件。它们都作为编译后的 *.jar*
    文件分发，并且我们已经在书籍捆绑包中包含了一份副本，因此你不需要做任何复杂的操作，只需指向它们所在的位置即可。为了使我们的命令尽可能简洁，让我们设置一个指向它们位置的环境变量。我们称之为
    *BIN* 用来表示程序的编译形式：
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Let’s check that we can run Cromwell by asking for its `help` output, which
    presents a summary of the three commands you can give it: `server` and `submit`
    are part of the server mode we  discussed earlier, and `run` is the one-shot mode
    that we use shortly:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查一下是否可以运行Cromwell，通过请求它的 `help` 输出，这将呈现出你可以给它的三个命令的摘要：`server` 和 `submit`
    是我们之前讨论的服务器模式的一部分，而 `run` 是我们很快将使用的一次性模式：
- en: '[PRE4]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'It’s also worth doing the same thing for `Womtool`, to get a sense of the various
    utility commands available:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 `Womtool`，也值得做同样的事情，以了解各种可用的实用命令：
- en: '[PRE5]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Of the functions just listed, you’ll have the opportunity to use `inputs`, `validate`,
    and `graph` in this chapter.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在列出的功能中，你将有机会在本章中使用 `inputs`、`validate` 和 `graph`。
- en: 'Now let’s check that you have all the workflow files that we provide for this
    chapter. If you followed the setup instructions in [Chapter 4](ch04.xhtml#first_steps_in_the_cloud),
    you should have a code directory that you cloned from GitHub. Under *~/book/code*,
    you’ll see a directory called *workflows* that contains all of the code and related
    files that you’ll use in this chapter (aside from the data, which came from the
    bucket). You’re going to run commands from the home directory (instead of moving
    into a subdirectory as we did in earlier chapters), so to keep paths short in
    the various commands, let’s set up an environment variable to point to where the
    workflow files reside:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们检查一下，你是否已经拥有本章所提供的所有工作流文件。如果你按照[第4章](ch04.xhtml#first_steps_in_the_cloud)中的设置说明操作，你应该有一个从GitHub克隆的代码目录。在
    *~/book/code* 下，你会看到一个名为 *workflows* 的目录，其中包含本章中你将使用的所有代码和相关文件（除了来自存储桶的数据）。你将从主目录运行命令（而不是像在早期章节中那样进入子目录），因此为了在各种命令中保持路径简短，让我们设置一个环境变量，指向工作流文件的位置：
- en: '[PRE6]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Finally, let’s talk about text editors. In all but one of the exercises that
    follow, you’re simply going to view and run prewritten scripts that we provide,
    so for viewing you could just download or clone the files to your laptop and open
    them in your preferred text editor. In one exception, we suggest you modify a
    WDL to break it in order to see what Cromwell’s error messaging and handling behavior
    looks like, so you’ll need to actually edit the file. We show you how to do this
    using one of the shell’s built-in text editors, called `nano`, which is considered
    one of the most accessible for people who aren’t used to command-line text editors.
    You are of course welcome to use another shell editor like `vi` or `emacs` if
    you prefer; if so, it will be up to you to adapt the commands we provide accordingly.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们谈谈文本编辑器。在接下来的练习中，除了一个例外，你只需查看和运行我们提供的预写脚本，因此，你可以下载或克隆这些文件到你的笔记本电脑，并在你喜欢的文本编辑器中打开它们来进行查看。在一个例外情况下，我们建议你修改一个WDL文件以破坏它，以便查看Cromwell的错误消息和处理行为，因此你确实需要编辑这个文件。我们会展示如何使用一个称为
    `nano` 的内置shell文本编辑器来完成这个操作，这被认为是对不习惯使用命令行文本编辑器的人们最为可访问的选择。当然，如果你更喜欢使用 `vi` 或
    `emacs` 等其他shell编辑器，你可以自行根据我们提供的命令进行调整。
- en: Whatever you decide to use as a text editor, just make sure not to use a *word
    processor* like Microsoft Word or Google Docs. Those applications can introduce
    hidden characters and are therefore not appropriate for editing code files. With
    that all sorted out, let’s buckle up and tackle your very first WDL workflow.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你决定使用什么样的文本编辑器，请确保不要使用像Microsoft Word或Google Docs这样的*文字处理器*。这些应用程序可能会引入隐藏字符，因此不适合编辑代码文件。有了这些都明了，让我们扎紧安全带，开始处理你的第一个WDL工作流。
- en: 'Your First WDL: Hello World'
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你的第一个WDL：Hello World
- en: 'We begin with the simplest possible working example of a WDL script: the quintessential
    `HelloWorld`. If you’re not familiar with this, it’s a common trope in the documentation
    of programming languages; in a nutshell, the idea is to provide an introductory
    example with the minimum amount of code that produces the phrase `HelloWorld!`.
    We’re actually going to run through three basic WDL workflows to demonstrate this
    level of functionality, starting with the absolute minimum example, and then adding
    on just enough code to show core functionality that is technically not required
    yet needed for realistic use.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从WDL脚本中最简单可行的工作示例开始：典型的`HelloWorld`。如果你对此不熟悉，这在编程语言的文档中是一个常见的表达方式；简而言之，这个想法是提供一个最小代码量的介绍性示例，能够产生`HelloWorld!`这个短语。实际上，我们将运行三个基本的WDL工作流程来展示这种功能级别，首先是绝对最小的示例，然后添加足够的代码来展示核心功能，这些功能在技术上不是必需的，但在实际使用中是需要的。
- en: Learning Basic WDL Syntax Through a Minimalist Example
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过极简示例学习基本的WDL语法
- en: 'Let’s pull up the simplest example by loading the *hello-world.wdl* workflow
    file into the `nano` editor:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过将*hello-world.wdl*工作流文件加载到`nano`编辑器中来查看最简单的示例：
- en: '[PRE7]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: As noted earlier, `nano` is a basic editor. You can use the arrow keys on your
    keyboard to move through the file. To exit the editor, press Ctrl+X.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面提到的，`nano`是一个基本的编辑器。你可以使用键盘上的箭头键在文件中移动。要退出编辑器，请按Ctrl+X。
- en: 'This is what the minimalistic Hello World for WDL looks like:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是WDL中最简化的Hello World的样子：
- en: '[PRE8]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'First, let’s ignore everything except the one line that has the phrase `HelloWorld`
    in it, the one in which it’s in quotes. Do you recognize the command on that line?
    That’s right, it’s a simple `echo` command; you can run that line by itself right
    now in your terminal:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们忽略除了那一行中有`HelloWorld`短语的引号中的内容以外的一切。你认出那行命令了吗？没错，这是一个简单的`echo`命令；你现在可以在你的终端中运行这一行：
- en: '[PRE9]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: So that’s the command at the heart of our script that performs the desired action,
    and everything else is wrapping to make it runnable in scripted form through our
    workflow management system.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这就是我们的脚本核心中执行所需操作的命令，其他所有内容都是为了使其能够通过我们的工作流管理系统以脚本形式运行。
- en: 'Now let’s unpack that wrapping. At the highest level, we have just two distinct
    stanzas, or blocks of code: the one starting with `workflow HelloWorld`, and the
    one starting with `task WriteGreeting`, with several lines of code between the
    curly braces in each case (the original designer of WDL really liked curly braces;
    you’ll see a lot more of them). We can summarize them like this:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们详细解释这个包装。在最高级别上，我们有两个不同的段落或代码块：一个以`workflow HelloWorld`开头，另一个以`task WriteGreeting`开头，在每种情况下的大括号之间有几行代码（WDL的原始设计者非常喜欢大括号；你会看到更多这样的情况）。我们可以这样总结它们：
- en: '[PRE10]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This makes it really clear that our script is structured in two parts: the
    `workflow` block, which is where we call out the actions that we want the workflow
    to perform, and a `task` block, where we define the action details. Here we have
    only one task, which is not really typical given that most workflows consist of
    two or more tasks; we cover workflows with multiple tasks further in this section.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得我们的脚本结构变得非常清晰：`workflow`块中我们调用希望工作流程执行的动作，而`task`块中我们定义动作细节。这里我们只有一个任务，这在实际情况中并不典型，因为大多数工作流包含两个或更多任务；我们将在本节进一步讨论包含多个任务的工作流。
- en: 'Let’s take a closer look at how the action—that is, the command—is defined
    in the `WriteGreeting` task:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地看一下在`WriteGreeting`任务中如何定义行动（即命令）：
- en: '[PRE11]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'In the first line, we’re declaring that this is a task called `WriteGreeting`.
    Within the outermost curly braces, we can break the structure of the code into
    another two blocks of code: `command {...}` and `output {...}`. The `command`
    block is quite straightforward: it contains the `echo "Hello World"` command.
    So that’s pretty self-explanatory, right? In general, you can stick just about
    anything in there that you would run in your terminal shell, including pipes,
    multiline commands, and even blocks of “foreign” code like Python or R, provided
    that you wrap it in [heredoc syntax](https://oreil.ly/VK1F8). We provide examples
    of what that looks like in [Chapter 9](ch09.xhtml#deciphering_real_genomics_workflows).'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一行，我们声明这是一个名为`WriteGreeting`的任务。在最外层的花括号内部，我们可以将代码的结构分解为另外两个代码块：`command {...}`和`output
    {...}`。`command`块非常简单：它包含`echo "Hello World"`命令。所以这是相当容易理解的，对吧？一般来说，你可以在这里放置几乎任何你在终端shell中运行的内容，包括管道命令、多行命令，甚至像Python或R这样的“外来”代码块，只要你用[heredoc语法](https://oreil.ly/VK1F8)进行包装。我们在[第9章](ch09.xhtml#deciphering_real_genomics_workflows)中提供了这种语法的示例。
- en: Meanwhile the `output` block is perhaps a bit less obvious. The goal here is
    to define the output of the `command` block we plan to run. We’re declaring that
    we expect the output will be a `File`, which we choose to call `output_greeting`
    (this name can be anything you want, except one of the reserved keywords, which
    are defined in the WDL specification). Then, in the slightly tricky bit, we’re
    stating that the output content itself will be whatever is emitted to `stdout`.
    If you’re not that familiar with command-line terminology, `stdout` is short for
    *standard out*, and refers to the text output to the terminal window, meaning
    it’s what you see displayed in the terminal when you run a command. By default,
    this content is also saved to a text file in the execution directory (which we
    examine shortly), so here we’re saying that we designate that text file as the
    output of our command. It’s not a terribly realistic thing to do in a genomics
    workflow (although you might be surprised…we’ve seen stranger things), but then
    that’s what a Hello World is like!
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，`output`块可能稍显不明显。这里的目标是定义我们计划运行的`command`块的输出。我们声明我们期望的输出将是一个`File`，我们选择称为`output_greeting`（此名称可以是任何你想要的，除了WDL规范中定义的保留关键字之一）。然后，在稍微棘手的部分中，我们声明输出内容本身将是发到`stdout`的任何内容。如果你对命令行术语不是很熟悉，`stdout`是*standard
    out*的缩写，指的是输出到终端窗口的文本输出，也就是运行命令时在终端看到的内容。默认情况下，此内容也会保存到执行目录中的文本文件中（稍后我们会查看），因此这里我们表明我们指定该文本文件作为我们命令的输出。在基因组工作流程中这样做并不是一个非常现实的事情（尽管你可能会感到惊讶…我们见过更奇怪的事情），但这就是Hello
    World的典型案例！
- en: 'Anyway, that’s our `task` block explained away. Now, let’s look at the `workflow`
    block:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，这就是我们的`task`块的解释。现在，让我们来看看`workflow`块：
- en: '[PRE12]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Well, that’s pretty simple. First, we declare that our workflow is called `HelloWorld`,
    and then, within the braces, we make a `call` statement to invoke the `WriteGreeting`
    task. This means that when we actually run the workflow through Cromwell, it will
    attempt to execute the `WriteGreeting` task. Let’s try that out.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，这很简单。首先，我们声明我们的工作流程名称为`HelloWorld`，然后在花括号内部，我们使用`call`语句调用`WriteGreeting`任务。这意味着当我们通过Cromwell实际运行工作流程时，它将尝试执行`WriteGreeting`任务。让我们试试吧。
- en: Running a Simple WDL with Cromwell on Your Google VM
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在您的Google虚拟机上使用Cromwell运行一个简单的WDL
- en: 'Exit the `nano` editor by pressing Ctrl+X and return to the shell of your VM.
    You’re going to launch the *hello-world.wdl* workflow using the Cromwell *.jar*
    file that resides in the *~/book/bin* directory, which we aliased as `$BIN` during
    the setup part of this chapter. The command is straightforward Java:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 退出`nano`编辑器，按下Ctrl+X键返回到虚拟机的shell界面。你将使用位于*~/book/bin*目录下的Cromwell *.jar*文件来启动*hello-world.wdl*工作流程，在本章的设置部分，我们将其别名为`$BIN`。这个命令是一个简单的Java命令：
- en: '[PRE13]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This command invokes Java to run Cromwell using its one-off (run) workflow execution
    mode, which we contrasted with the persistent `server` mode earlier in this chapter.
    So it’s just going to start up, run the workflow we provided as an input to the
    `run` command, and shut down when that’s done. For the moment, there is nothing
    else involved because our workflow is entirely self-contained; we cover how to
    parameterize the workflow to accept input files next.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令调用Java来运行Cromwell，使用其一次性（运行）工作流执行模式，这与本章前面介绍的持续`server`模式形成对比。因此，它只会启动，运行我们提供给`run`命令的工作流，并在完成后关闭。目前为止，没有其他内容涉及，因为我们的工作流完全是自包含的；接下来我们将讨论如何将工作流参数化以接受输入文件。
- en: 'Go ahead and run that command. If you have everything set up correctly, you
    should now see Cromwell begin to spit out a lot of output to the terminal. We
    show the most relevant parts of the output here, but we’ve omitted some blocks
    (indicated by `[...]`) that are of no interest for our immediate purposes:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 继续运行该命令。如果您已正确设置一切，您现在应该看到Cromwell开始向终端输出大量信息。我们在这里展示了输出的最相关部分，但我们省略了一些不相关的块（由`[...]`表示）：
- en: '[PRE14]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'As you can see, Cromwell’s standard output is a tad…well, verbose. Cromwell
    has been designed primarily for use as part of a suite of interconnected services,
    which we discuss in [Chapter 11](ch11.xhtml#running_many_workflows_conveniently_in),
    where there is a dedicated interface for monitoring progress and output during
    routine use. The single-run mode is more commonly used for troubleshooting, so
    the development team has chosen to make the local execution mode very chatty to
    help with debugging. This can feel a bit overwhelming at first, but don’t worry:
    we’re here to show you how to decipher it all—or at least the parts that we care
    about.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，Cromwell的标准输出有点……嗯，冗长。Cromwell主要设计用于作为一组相互连接的服务的一部分使用，我们在[第11章](ch11.xhtml#running_many_workflows_conveniently_in)中讨论了这一点，在那里有一个专门的界面用于监视进度和输出。单次运行模式更常用于故障排除，因此开发团队选择使本地执行模式非常健谈，以帮助调试。这起初可能会让人感到有点不知所措，但别担心：我们在这里将向您展示如何解读这一切——或至少我们关心的部分。
- en: Interpreting the Important Parts of Cromwell’s Logging Output
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解释Cromwell日志输出的重要部分
- en: 'First, let’s check that the output of our workflow is what we expected. Find
    this set of lines in the terminal output:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们检查我们的工作流的输出是否符合预期。在终端输出中找到以下一组行：
- en: '[PRE15]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Without going into the details just yet, we see that this provides a list in
    JSON format of the output files that were produced; in this case, just the one
    file that captured the `stdout` of our one `echo "Hello World"` command. Cromwell
    gives us the fully qualified path, meaning it includes the directory structure
    above the working directory, which is really convenient because it allows us to
    use it in any command with a quick copy and paste. You can do that right now to
    look at the contents of the output file and verify that it contains what we expect:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 还没有详细讨论，但我们可以看到，这以JSON格式提供了生成的输出文件列表；在这种情况下，只有一个文件捕获了我们的一个`echo "Hello World"`命令的`stdout`。Cromwell为我们提供了完全限定的路径，这意味着它包括了工作目录上面的目录结构，这真的很方便，因为它允许我们在任何需要的命令中快速复制和粘贴使用。您现在可以这样做，查看输出文件的内容，并验证它是否包含我们期望的内容：
- en: Note
  id: totrans-65
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Keep in mind that in the command we show here, you need to replace the username
    and the execution directory hash. It might be easier to look for the equivalent
    line in your output than to customize our command.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，在我们展示的命令中，您需要替换用户名和执行目录哈希。查找您输出中相应的行可能比定制我们的命令更容易。
- en: '[PRE16]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: And there it is! So we know it worked.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样！所以我们知道它起作用了。
- en: 'Now let’s take a few minutes to walk through the information that Cromwell
    is giving us in all that log output to identify the most relevant nuggets:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们花几分钟时间逐步查看Cromwell在所有这些日志输出中提供给我们的信息，以识别最相关的要点：
- en: '[PRE17]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: = *I’m looking at this one workflow and assigning it this unique identifier.*
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: = *我正在查看这个工作流并为其分配一个独特的标识符。*
- en: 'Cromwell assigns a randomly generated unique identifier to every run of every
    workflow and creates a directory with that identifier, within which all of the
    intermediate and final files will be written. We go over the details of the output
    directory structure in a little bit. For now, all you really need to know is that
    this is designed to ensure that you will never overwrite the results of a previous
    run of the same workflow or experience collisions between different workflows
    that have the same name:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Cromwell为每个工作流运行的每个运行分配一个随机生成的唯一标识符，并在该标识符内创建一个目录，所有中间文件和最终文件都将写入其中。稍后我们将详细讨论输出目录结构的细节。现在，你真正需要知道的是，这旨在确保你永远不会覆盖相同工作流之前运行的结果，也不会在具有相同名称的不同工作流之间发生冲突：
- en: '[PRE18]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: = *I’m planning to send this to the local machine for execution (as opposed
    to a remote server).*
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: = *我计划将其发送到本地机器进行执行（而不是远程服务器）。*
- en: 'By default, Cromwell runs workflows directly on your local machine; for example,
    your laptop. As we mentioned earlier, you can configure it to send jobs to a remote
    server or cloud service, instead; that’s what in Cromwell lingo is called a *backend
    assignment* (not to be confused with diaper duty):'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Cromwell直接在您的本地机器上运行工作流；例如，您的笔记本电脑。正如我们之前提到的，您可以配置它将作业发送到远程服务器或云服务；这在
    Cromwell 的术语中称为*后端分配*（不要与换尿布搞混）：
- en: '[PRE19]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: = *I’m executing the `WriteGreeting` task call from the `HelloWorld` workflow
    now.*
  id: totrans-77
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: = *我现在执行`WriteGreeting`任务调用`HelloWorld`工作流。*
- en: 'Cromwell treats each task call in the workflow as a separate job to execute,
    and will give you individual updates about each one accordingly. If the workflow
    involves multiple task calls, Cromwell will organize them in a queue and send
    each out for execution when appropriate. We discuss some aspects of how that works
    a little later. With regard to the status reporting aspect, you can imagine that
    as soon as we move to running more complex workflows, getting these reports through
    the standard out is rather impractical. This is where frontend software that provides
    an interface to parse and organize all of this information can really come in
    handy; you’ll have an opportunity to experience that in [Chapter 11](ch11.xhtml#running_many_workflows_conveniently_in):'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: Cromwell将工作流中的每个任务调用视为单独的作业进行执行，并会相应地为每个作业提供更新。如果工作流涉及多个任务调用，Cromwell会将它们组织在队列中，并在适当时发送每个任务进行执行。我们稍后会讨论一些相关的工作原理。关于状态报告方面，可以想象，一旦我们开始运行更复杂的工作流，通过标准输出获取这些报告就显得不太实际。这就是提供界面以解析和组织所有这些信息的前端软件真正派上用场的地方；你将有机会在[第11章](ch11.xhtml#running_many_workflows_conveniently_in)中体验到这一点：
- en: '[PRE20]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: = *This is the actual command I’m running for this call.*
  id: totrans-80
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: = *这是我在此调用中实际运行的命令。*
- en: 'It’s not obvious from this particular call because we didn’t include any variables
    in our minimal Hello World example, but what Cromwell outputs here is the real
    command that will be executed. In the parameterized example that comes next, you
    can see that if we include a variable in the script, the log output will show
    the form of the command in which the variable has been replaced by the input value
    that we provide. This fully interpreted command also is output to the execution
    directory for the record:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的最小化 Hello World 示例中并未包含任何变量，因此从这个特定调用中并不明显，但 Cromwell 在此输出的是将要执行的真实命令。在接下来的参数化示例中，你可以看到，如果在脚本中包含变量，日志输出将显示命令的形式，其中变量已由我们提供的输入值替换。这个完全解释的命令也会输出到执行目录以备记录：
- en: '[PRE21]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: = *I’m done running this workflow. This is the full path to that output file(s)
    you wanted.*
  id: totrans-83
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: = *我已经完成了这个工作流的运行。这是你想要的输出文件的完整路径。*
- en: As noted earlier, this provides a list in JSON format of all the output files
    that were produced, identified by their full namespace. The namespace
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面所述，以 JSON 格式提供了生成的所有输出文件的完全命名空间列表。命名空间
- en: '[PRE22]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: tells us that we are looking at the `output_greeting` output by the call to
    the `WriteGreeting` task belonging to the `HelloWorld` workflow.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 告诉我们，我们正在查看`HelloWorld`工作流中属于`WriteGreeting`任务调用输出的`output_greeting`。
- en: 'The fully qualified path to the output file shows the entire directory structure;
    let’s unroll that and examine what each segment corresponds to:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 输出文件的完全限定路径显示整个目录结构；让我们展开来看看每个部分对应的内容：
- en: '[PRE23]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The important piece in this structure is the nesting of workflow/identifier/calls.
    As you’ll see in the next exercise, any runs of a workflow with the same name
    will be added under the *HelloWorld* workflow directory, in a new directory with
    another unique identifier.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结构中的重要部分是工作流/标识符/调用的嵌套。正如你将在下一个练习中看到的那样，任何以相同名称运行的工作流都将添加到*HelloWorld*工作流目录下，一个新的带有另一个唯一标识符的目录中。
- en: '[PRE24]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: = *Yo, everything worked!*
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: = *哟，一切都运行正常！*
- en: '[PRE25]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: = *I’m all done here. Buh-bye.*
  id: totrans-93
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: = *我在这里完成了。再见。*
- en: And that’s really all you need to care about at this point, concluding your
    first Cromwell workflow execution. Well done!
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 到此时，这就是你需要关心的全部内容，完成了你的第一个Cromwell工作流执行。做得好！
- en: Adding a Variable and Providing Inputs via JSON
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加变量并通过JSON提供输入
- en: 'OK, but running a completely self-contained WDL is unrealistic, so let’s look
    at how we add variables to bring in some external input that can change from run
    to run. In the `nano` editor, go ahead and open the *hello-world-var.wdl* from
    the code directory:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，但是运行一个完全独立的WDL是不现实的，所以让我们看看如何添加变量以引入一些可以从运行到运行改变的外部输入。在`nano`编辑器中，打开代码目录中的*hello-world-var.wdl*：
- en: '[PRE26]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'What’s different? The `workflow` block is exactly the same, but now there’s
    a bit more going on in the `WriteGreeting` `task` block:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 有什么不同？`workflow`块完全相同，但是`WriteGreeting` `task`块中现在有更多内容：
- en: '[PRE27]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The `Hello World` input to the `echo` command has been replaced by `${greeting}`,
    and we now have a new `input` block before the `command` block that contains the
    line `String greeting`. This line declares the variable called `greeting` and
    states that its value should be of type `String`; in other words, an alphanumeric
    sequence. This means that we have parameterized the greeting that will be echoed
    to the terminal; we’re going to be able to instruct Cromwell what to insert into
    the command on a run-by-run basis.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '`Hello World`输入到`echo`命令的`${greeting}`已被`${greeting}`替换，并且我们现在在`command`块之前有一个新的`input`块，其中包含`String
    greeting`这行。这行声明了名为`greeting`的变量，并说明其值应为`String`类型；换句话说，是一个字母数字序列。这意味着我们已经对将要回显到终端的问候语进行了参数化；我们将能够指示Cromwell在每次运行时将什么插入命令中。'
- en: 'This leads to the next question: how do we provide Cromwell with that value?
    We definitely don’t want to have to give it directly on the command line, because
    although this particular case is simple, in the future we might need to run workflows
    that expect dozens of values, many of them more complex than a simple `String`.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这引出了下一个问题：我们如何向Cromwell提供该值？我们绝对不希望直接在命令行上给出它，因为虽然这个特定案例很简单，但在将来，我们可能需要运行期望包含数十个值的工作流，其中许多比一个简单的`String`更复杂。
- en: 'Cromwell expects you to provide inputs in [JavaScript Object Notation](https://www.json.org)
    (JSON) text format. JSON has a key:value pair structure that allows us to assign
    a value to each variable. You can see an example of this in the *$WF/hello-world/hello-world.inputs.json*
    file that we provide:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: Cromwell期望您以[JavaScript对象表示法](https://www.json.org)（JSON）文本格式提供输入。JSON具有键值对结构，允许我们为每个变量分配一个值。您可以在我们提供的*$WF/hello-world/hello-world.inputs.json*文件中看到一个例子：
- en: '[PRE28]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: In this simple *inputs* JSON file, we have defined the `greeting` variable from
    our `HelloWorld` workflow by its fully qualified name, which includes the name
    of the workflow itself (`HelloWorld`) and then the name of the task (`WriteGreeting`)
    because we declared the variable at the task level and then the name of the variable
    itself.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简单的*inputs* JSON文件中，我们通过其完全限定名称定义了我们`HelloWorld`工作流中的`greeting`变量，该名称包括工作流本身的名称（`HelloWorld`），然后是任务的名称（`WriteGreeting`），因为我们在任务级别声明了变量，然后是变量本身的名称。
- en: 'To provide the *inputs* JSON file to Cromwell, simply add it by using the `-i`
    argument (short for `--input`) to your Cromwell command, as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 要将*inputs* JSON文件提供给Cromwell，只需通过使用`-i`参数（简写为`--input`）添加到您的Cromwell命令中，如下所示：
- en: '[PRE29]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Look for the output the same way you did earlier; you should see the message
    in the file output by the workflow match the text in the JSON file.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 以与您之前相同的方式查找输出；您应该看到由工作流输出的文件中的消息与JSON文件中的文本匹配。
- en: Cromwell enforces the use of fully qualified names at all levels, which makes
    it impossible to declare global variables. Although this might feel like a burdensome
    constraint, it is much safer than the alternative, because it means that you can
    have variables with the same name in different parts of a workflow without causing
    collisions. In simple workflows, it’s easy enough to keep track of variables and
    prevent such problems, but in more complex workflows with dozens of more variables,
    that can become quite difficult. That is especially the case when you use imports
    and subworkflows to facilitate code reuse, which we cover in [Chapter 9](ch09.xhtml#deciphering_real_genomics_workflows)
    (ooh, spoilers). Note that you can declare a variable at the workflow level (and
    use the input naming syntax *`WorkflowName.variable`* in the *inputs* JSON file),
    but you’ll need to pass it explicitly to any task calls in which you want to use
    it. You’ll see an example of this in action later in this chapter.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Cromwell在所有级别强制使用完全限定名称，这使得声明全局变量成为不可能。虽然这可能感觉像一种繁琐的约束，但比起另一种选择要安全得多，因为这意味着您可以在工作流的不同部分中使用相同名称的变量而不会造成冲突。在简单的工作流中，很容易跟踪变量并防止此类问题，但在具有数十个以上变量的更复杂的工作流中，这可能变得非常困难。特别是当您使用导入和子工作流来促进代码重用时，我们在[第9章](ch09.xhtml#deciphering_real_genomics_workflows)中详细介绍（哦，剧透）。请注意，您可以在工作流级别声明变量（并在*inputs*
    JSON文件中使用输入命名语法*`WorkflowName.variable`*），但必须明确地将其传递给任何您想使用它的任务调用。稍后在本章中，您将看到此操作的示例。
- en: Adding Another Task to Make It a Proper Workflow
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加另一个任务，使其成为一个适当的工作流程
- en: 'Real-world workflows usually have more than one task, and some of their tasks
    are dependent on the outputs of others. In the `nano` editor, open *hello-world-again.wdl*:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现实世界的工作流通常有多个任务，并且其中一些任务依赖于其他任务的输出。在`nano`编辑器中，打开*hello-world-again.wdl*：
- en: '[PRE30]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Here’s our third iteration attempt at a Hello World example, showing two tasks
    chained into a proper workflow:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们第三次尝试编写一个Hello World示例，展示了两个任务链接成一个正确的工作流：
- en: '[PRE31]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'You can see that the `workflow` block has quite a bit more going on now; it
    has an additional call statement pointing to a new task, `ReadItBackToMe`, and
    that call statement has some code in curly braces attached to it, which we’ll
    call the `input` block:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到`workflow`块现在有更多内容；它具有指向新任务`ReadItBackToMe`的附加调用语句，并且该调用语句附有一些代码，放在花括号中，我们将其称为`input`块：
- en: '[PRE32]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The `input` block allows us to pass values from the workflow level to a particular
    task call. In this case, we’re referencing the output of the `WriteGreeting` task
    and assigning it to a variable called `written_greeting` for use within the `ReadItBackToMe`
    call.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '`input`块允许我们从工作流级别传递值到特定任务调用。在这种情况下，我们引用`WriteGreeting`任务的输出，并将其分配给名为`written_greeting`的变量，以便在`ReadItBackToMe`调用中使用。'
- en: 'Let’s have a look at that new task definition:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看这个新任务定义：
- en: '[PRE33]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The `read_string()` bit is a function from the WDL standard library that reads
    in the contents of a text file and returns them in the form of a single string.
    So this task is meant to read in the contents of a file into a `String` variable
    and then use that variable to compose a new greeting and echo it to `stdout`.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '`read_string()`部分是WDL标准库中的一个函数，用于读取文本文件的内容并以单个字符串的形式返回。因此，此任务旨在将文件的内容读入`String`变量中，然后使用该变量来组成新的问候语并将其回显到`stdout`。'
- en: In light of that, the extra code attached to the `ReadItBackToMe` call statement
    makes perfect sense. We’re calling the `ReadItBackToMe` task and specifying that
    the input file we used to compose the new greeting should be the output of the
    call to the `Write​Greeting` task.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 有鉴于此，附加到`ReadItBackToMe`调用语句的额外代码显得非常合理。我们正在调用`ReadItBackToMe`任务，并指定我们用于编写新问候语的输入文件应该是调用`Write​Greeting`任务的输出。
- en: 'Finally, let’s look at the last block of code we haven’t examined in this new
    version of the workflow:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们看看在这个工作流程的新版本中我们尚未检查的最后一块代码：
- en: '[PRE34]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: This workflow has an `output` block defined at the workflow level in addition
    to the individual task-level `output` blocks. This workflow-level output definition
    is entirely optional when the workflow is intended to be run by itself; it’s more
    a matter of convention than function. By defining a workflow-level output, we
    communicate which of the outputs produced by the workflow we care about. That
    being said, you can use this output definition for functional purposes; for example,
    when the workflow is going to be used as a nested subworkflow and we need to pass
    its output to further calls. You’ll see that in action in [Chapter 9](ch09.xhtml#deciphering_real_genomics_workflows).
    For now, try running this workflow with the same input JSON as the previous workflow,
    then poke around the execution directories to see how the task directories relate
    to each other and where the outputs are located.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这个工作流在工作流级别定义了一个`output`块，除了各个任务级别的`output`块。当工作流是独立运行时，这个工作流级别的输出定义是完全可选的；这更多是一种惯例而不是功能。通过定义工作流级别的输出，我们传达了我们关心工作流产生的哪些输出。话虽如此，你可以利用这个输出定义进行功能性目的；例如，当工作流将被用作嵌套子工作流时，我们需要将其输出传递给进一步的调用。你将在[第9章](ch09.xhtml#deciphering_real_genomics_workflows)中看到这一点。现在，尝试使用与之前工作流相同的输入JSON运行此工作流，然后查看执行目录，看看任务目录之间的关系以及输出位于何处。
- en: 'Your First GATK Workflow: Hello HaplotypeCaller'
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你的第一个GATK工作流：Hello HaplotypeCaller
- en: 'Now that you have a firm grasp of basic WDL syntax, let’s turn to a more realistic
    set of examples: actual GATK pipelines! We begin with a very simple workflow in
    order to build your familiarity with the language gradually. We want a workflow
    that runs GATK `HaplotypeCaller` linearly (no parallelization) in GVCF mode on
    a single sample BAM file, as illustrated in [Figure 8-1](#concept_diagram_of_a_hypothetical_workf).'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经牢固掌握了基本的WDL语法，让我们转向更现实的一组示例：实际的GATK流水线！我们从一个非常简单的工作流开始，以逐渐建立你对语言的熟悉度。我们希望一个工作流在单个样本BAM文件上线性（无并行化）运行GATK
    `HaplotypeCaller`，以GVCF模式运行，如[图8-1](#concept_diagram_of_a_hypothetical_workf)所示。
- en: '![Concept diagram of a hypothetical workflow that runs HaplotypeCaller.](Images/gitc_0801.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![一个运行HaplotypeCaller的假设工作流的概念图。](Images/gitc_0801.png)'
- en: Figure 8-1\. A hypothetical workflow that runs HaplotypeCaller.
  id: totrans-127
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-1\. 一个运行HaplotypeCaller的假设工作流。
- en: The workflow should take the usual required files—the genome reference, input
    reads, and a file of intervals to analyze (technically optional as far as GATK
    is concerned, but here we made it required by the WDL)—and output a GVCF file
    named based on the input file.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流应该接受通常所需的文件——基因组参考、输入读取和要分析的区间文件（在GATK看来技术上是可选的，但在这里我们通过WDL将其设为必需）——并输出一个根据输入文件命名的GVCF文件。
- en: Exploring the WDL
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索WDL
- en: 'To illustrate all of that, we put together a WDL workflow that fulfills these
    requirements through a single task, `HaplotypeCallerGVCF`. Open it now in the
    `nano` editor:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明所有这些，我们组合了一个通过单个任务`HaplotypeCallerGVCF`实现这些要求的WDL工作流。现在在`nano`编辑器中打开它：
- en: '[PRE35]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Let’s walk through the main sections of the script, recalling the structure
    of our HelloWorld example:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐步浏览脚本的主要部分，回顾我们的HelloWorld示例的结构：
- en: '[PRE36]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Collapsing the task for clarity, you can see that it is indeed a single-task
    workflow, with only that single call and nothing else going on in the `workflow`
    block:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 为了清晰起见，将任务折叠起来，你会看到这确实是一个单任务工作流，只有一个单独的调用，`workflow`块中没有其他内容：
- en: '[PRE37]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'So let’s look at that `HaplotypeCallerGVCF` task in more detail, starting with
    the `command` block, because ultimately that’s where we’ll glean the most information
    about what the task actually does:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 所以让我们更详细地看一下`HaplotypeCallerGVCF`任务，从`command`块开始，因为最终我们将从中获取关于任务实际操作的大部分信息：
- en: '[PRE38]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: We see a classic GATK command that invokes `HaplotypeCaller` in GVCF mode. It
    uses placeholder variables for the expected input files as well as the output
    file. It also includes a placeholder variable for passing in Java options such
    as memory heap size, as described in [Chapter 5](ch05.xhtml#first_steps_with_gatk).
    So far, that’s pretty straightforward.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到一个经典的GATK命令，调用`HaplotypeCaller`以GVCF模式运行。它使用占位符变量来表示预期的输入文件以及输出文件。它还包括一个占位符变量，用于传递Java选项，例如内存堆大小，如[第5章](ch05.xhtml#first_steps_with_gatk)所述。到目前为止，这相当简单明了。
- en: 'Those variables should all be defined somewhere, so let’s look for them. Conventionally,
    we do this at the start of the task description, before the `command` block. This
    is what we see there:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些变量都应该在某个地方定义，所以让我们寻找它们。通常，在 `command` 块之前，在任务描述的开头进行这样的操作。这就是我们在那里看到的内容：
- en: '[PRE39]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Ignoring the `String docker_image` line for now, this shows that we declared
    all of the variables for the input files as well as the Java options, but we didn’t
    assign a value to them. So the task will expect to receive values for all of them
    at runtime. Not only that, but it will also expect values for all the accessory
    files we often take for granted: `refIndex`, `refDict`, and `inputBamIndex`, which
    refer to the indices and sequence dictionary. We don’t include those files in
    the command itself because GATK detects their presence automatically (as long
    as their names conform with their master file’s respective format conventions),
    but we do need to inform Cromwell that they exist so that it can make them available
    for execution at runtime.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 现在先忽略 `String docker_image` 行，这显示我们声明了所有输入文件的变量以及 Java 选项，但是我们没有为它们赋值。因此，任务在运行时将期望接收这些变量的值。不仅如此，它还将期望接收我们通常认为理所当然的所有辅助文件的值：`refIndex`、`refDict`
    和 `inputBamIndex`，它们指的是索引和序列字典。我们没有在命令本身中包含这些文件，因为 GATK 会自动检测它们的存在（只要它们的名称符合主文件的格式约定），但我们确实需要通知
    Cromwell 它们的存在，以便在运行时执行时使它们可用。
- en: 'There is one exception, though; for the output file, we see this line:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，有一个例外；对于输出文件，我们看到了这一行：
- en: '[PRE40]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The `basename(input_bam, ".bam")` piece is a convenience function from the WDL
    standard library that allows us to create a name for our output file based on
    the name of the input file. The `basename()` function takes the full path of the
    input file, strips off the part of the path that’s in front of the filename, and,
    optionally, strips off a given string from the end of the filename. In this case,
    we’re stripping off the expected *.bam* extension and then we’re using the `+
    ".g.vcf"` part of the line to add the new extension that will be appropriate for
    the output file.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '`basename(input_bam, ".bam")` 函数是 WDL 标准库中的一个便利函数，允许我们根据输入文件的名称创建输出文件的名称。 `basename()`
    函数接受输入文件的完整路径，剥离文件名前面的路径部分，并可选择剥离文件名末尾的特定字符串。在这种情况下，我们剥离了期望的 *.bam* 扩展名，然后使用行中的
    `+ ".g.vcf"` 部分添加新的扩展名，以便于输出文件。'
- en: 'Speaking of the output file, let’s now skip over to the task-level `output`
    block:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 谈到输出文件，现在让我们跳到任务级别的 `output` 块：
- en: '[PRE41]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: This is also straightforward; we’re stating that the command will produce an
    output file that we care about, giving it a name for handling it within the workflow,
    and providing the corresponding placeholder variable so that Cromwell can identify
    the correct file after the command has run to completion.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这也很直接；我们说明了命令将生成一个我们关心的输出文件，为了在工作流中处理它，给它命名，并提供相应的占位符变量，以便 Cromwell 在命令运行完成后能够识别正确的文件。
- en: 'Technically, that is all you need to have in the workflow and task definition
    if you’re planning to run this on a system with a local installation of the program
    that you want to run. However, in this chapter you’re working in your VM but outside
    the GATK container, and as a result, GATK is not available directly to your workflow.
    Fortunately, Cromwell is capable of utilizing Docker containers, so we just need
    to add a `runtime` block to the workflow in order to specify a container image:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术上讲，如果你计划在具有所需程序的本地安装系统上运行此流程，这就是工作流和任务定义中所需的全部内容。然而，在这一章节中，你是在 VM 中工作，但在
    GATK 容器外运行，因此 GATK 并不直接对你的工作流可用。幸运的是，Cromwell 能够利用 Docker 容器，因此我们只需要在工作流中添加一个
    `runtime` 块来指定一个容器映像：
- en: '[PRE42]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'That’s why we had that `String docker_image` line in our task variables: we’re
    also using a placeholder variable for the container image. When we fill out the
    input JSON in the next step, we’ll specify the `us.gcr.io/broad-gatk/gatk:4.1.3.0`
    image. Then, when we launch the workflow, Cromwell will spin up a new container
    from the image we specified and run GATK inside of it.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么在我们的任务变量中有 `String docker_image` 行的原因：我们还使用了一个容器映像的占位符变量。在下一步中填写输入 JSON
    时，我们将指定 `us.gcr.io/broad-gatk/gatk:4.1.3.0` 映像。然后，在启动工作流时，Cromwell 将从我们指定的映像中启动一个新的容器，并在其中运行
    GATK。
- en: 'Technically we could hardcode the image name here, using double quotes (e.g.,
    `docker: "us.gcr.io/broad-gatk/gatk:4.1.3.0"`) but we don’t recommend doing that
    unless you really want to peg a particular script to a particular version, which
    reduces flexibility significantly. Some people use the `latest` tag to make their
    workflows always run with the latest available version of the program, but we
    consider that to be a bad practice with more downsides than upsides because you
    never know what might change in the latest version and break your workflow.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '在技术上，我们可以在此处硬编码映像名称，使用双引号（例如，`docker: "us.gcr.io/broad-gatk/gatk:4.1.3.0"`），但我们不建议这样做，除非您确实希望将特定脚本固定到特定版本，这显著降低了灵活性。有些人使用`latest`标签使其工作流始终运行最新可用版本的程序，但我们认为这是一个不良实践，弊大于利，因为您永远不知道最新版本可能会发生什么变化并破坏您的工作流程。'
- en: Generating the Inputs JSON
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成输入的JSON
- en: 'Alright, we’ve gone through all of the code in the workflow; now we need to
    determine how we’re going to provide the inputs to the workflow when we run it.
    In [“Your First WDL: Hello World”](#your_first_wdl_hello_world), we were running
    an extremely simple workflow, first without any variable inputs and then with
    a single one. In the single-input case, we created a JSON file specifying that
    one input. Now we have eight inputs that we need to specify. We could proceed
    in the same way as before—create a JSON file and write in the name of every input
    expected by the `HaplotypeCallerGVCF` task—but there’s an easier way: we’re going
    to use the `Womtool inputs` command to create a template JSON.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '好了，我们已经过了工作流中的所有代码；现在我们需要确定在运行它时如何向工作流提供输入。在[“Your First WDL: Hello World”](#your_first_wdl_hello_world)中，我们运行了一个非常简单的工作流，首先没有任何变量输入，然后有一个输入。在单一输入情况下，我们创建了一个指定该输入的JSON文件。现在我们有八个输入需要指定。我们可以像以前一样继续操作——创建一个JSON文件并写入`HaplotypeCallerGVCF`任务期望的每个输入的名称，但有一种更简单的方法：我们将使用`Womtool
    inputs`命令创建一个模板JSON。'
- en: 'First, because we’re going to be writing files that we care about for the first
    time in the chapter, let’s make a *sandbox* directory to keep our outputs organized:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，因为我们将在本章中首次写入我们关心的文件，请让我们创建一个*sandbox*目录来保持我们的输出有序：
- en: '[PRE43]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Now, you can run the `Womtool` command that generates the *inputs* JSON template
    file:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以运行`Womtool`命令来生成*inputs* JSON模板文件：
- en: '[PRE44]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Because we specify an output file on the last line of this command (which is
    actually optional), the command writes its output to that file. If everything
    goes smoothly, you shouldn’t see any output in the terminal. Let’s look at the
    contents of the file that we just created:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 因为在此命令的最后一行指定了输出文件（实际上是可选的），所以命令会将其输出写入该文件。如果一切顺利，您在终端上不应该看到任何输出。让我们看看我们刚刚创建的文件的内容：
- en: '[PRE45]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'There you go: all of the inputs that the `HaplotypeCallerGVCF` task expects
    are listed appropriately, with a placeholder value stating their type, in JSON
    format (although they might be in a different order in yours). Now we just need
    to fill in the values; those are the paths to the relevant files for the first
    six, and the runtime parameters (container image and Java options) for the last
    two. In the spirit of laziness, we provide a filled-out version that uses the
    snippet data that we used in [Chapter 5](ch05.xhtml#first_steps_with_gatk), but
    you could also go through the exercise of filling in the *inputs* JSON with other
    inputs from the data bundle that you downloaded in [Chapter 4](ch04.xhtml#first_steps_in_the_cloud)
    if you like. This is what the prefilled JSON looks like (paths are relative to
    the home directory):'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是：所有`HaplotypeCallerGVCF`任务期望的输入都以适当的方式列出，其中包含占位符值指示它们的类型，以JSON格式显示（尽管在您的情况下可能顺序不同）。现在我们只需填写这些值；这些是前六个相关文件的路径以及最后两个的运行时参数（容器镜像和Java选项）。在懒惰的精神下，我们提供了一个填充版本，使用我们在[第5章](ch05.xhtml#first_steps_with_gatk)中使用的片段数据，但是如果愿意，您也可以从在[第4章](ch04.xhtml#first_steps_in_the_cloud)下载的数据包中的其他输入中填写*inputs*
    JSON。这是预填充JSON的样子（路径相对于主目录）：
- en: '[PRE47]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Notice that all of the values are shown in double quotes, but this is a bit
    of an artifact because these values are all of `String` type. For other types
    such as numbers, Booleans, and arrays, you should not use double quotes. Except,
    of course, for arrays of strings, for which you should use double quotes around
    the strings, though not around the array itself, `["like","this"]`.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，所有的值都用双引号显示，但这是一个技术性的问题，因为这些值都是`String`类型。对于其他类型，如数字、布尔值和数组，你不应该使用双引号。当然，对于字符串数组，你应该在字符串周围使用双引号，但不要在数组本身周围使用双引号，`["like","this"]`。
- en: Running the Workflow
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行工作流程
- en: 'To run the workflow, we’re going to use the same command-line syntax as earlier.
    Make sure to execute this in your home directory so that the relative paths in
    the *inputs* JSON file match the location of the data files:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行工作流程，我们将使用与之前相同的命令行语法。确保在你的主目录中执行此操作，以便*inputs* JSON文件中的相对路径与数据文件的位置匹配：
- en: '[PRE49]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'As mentioned earlier, Cromwell output is quite verbose. For this exercise,
    you’re looking for lines that look like these in the terminal output:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 正如之前提到的，Cromwell的输出非常冗长。在这个练习中，你要找的是终端输出中类似于以下示例的行：
- en: '[PRE50]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: The most exciting snippets here are `Status change from WaitingForReturnCode
    to Done` and `finished with status 'Succeeded'`, which together mean that your
    workflow is done running and that all commands that were run stated that they
    were successful.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这里最令人兴奋的片段是`Status change from WaitingForReturnCode to Done`和`finished with
    status 'Succeeded'`，它们一起意味着你的工作流已经运行完成，并且所有运行的命令都表示它们成功了。
- en: The other exciting part of the output is the path to the outputs. In the next
    section, we talk a bit about why they’re listed twice; for now, let’s just be
    happy that Cromwell tells us precisely where to find our output file so that we
    can easily peek into it. Of course, the output of this particular workflow is
    a GVCF file, so it’s not exactly pleasant to read through, but the point is that
    the file is there and its contents are what you expect to see.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 输出的另一个令人兴奋的部分是输出路径。在下一节中，我们会稍微讨论一下为什么它们会被列出两次；现在，让我们高兴地看到Cromwell精确告诉我们在哪里找到我们的输出文件，这样我们就可以轻松地查看它。当然，这个特定工作流的输出是一个GVCF文件，所以阅读起来并不是很愉快，但重要的是文件在那里，其内容正如你所期望的那样。
- en: 'We use the `head` utility for this purpose; keep in mind that you’ll need to
    substitute the execution directory hash in the file path shown in the following
    example (`9a6a9c97-7453-455c-8cd8-be8af8cb6f7c`) to the one displayed in your
    output:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用`head`实用程序来做这个目的；请记住，你需要将文件路径中显示的执行目录哈希（例如`9a6a9c97-7453-455c-8cd8-be8af8cb6f7c`）替换为你的输出中显示的哈希：
- en: '[PRE51]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: This run should complete quickly because we’re using an intervals list that
    spans only a short region. Most of the time spent here is Cromwell getting started
    and spinning up the container, whereas GATK `HaplotypeCaller` itself runs for
    only the briefest of moments. As with the Hello World example, you might feel
    that this is an awful lot of work for such a small workload, and you’d be right;
    it’s like swatting a fly with a bazooka. For toy examples, the overhead of getting
    Cromwell going dwarfs the analysis itself. It’s when we get into proper full-scale
    analyses that a workflow management system like Cromwell really shows its value,
    which you’ll experience in Chapters [10](ch10.xhtml#running_single_workflows_at_scale_with)
    and [11](ch11.xhtml#running_many_workflows_conveniently_in).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这次运行应该很快完成，因为我们使用的间隔列表仅跨越一个短区域。在这里花费的大部分时间是Cromwell启动和启动容器，而GATK的`HaplotypeCaller`本身仅运行了极短的时间。与Hello
    World示例一样，你可能会觉得为这样一个小工作量做这么多工作有点浪费，你是对的；这就像用火箭筒打苍蝇。对于玩具示例来说，启动Cromwell的开销使分析本身相形见绌。当我们进行适当的全面分析时，像Cromwell这样的工作流管理系统才能真正展示其价值，你将在第[10](ch10.xhtml#running_single_workflows_at_scale_with)章和第[11](ch11.xhtml#running_many_workflows_conveniently_in)章中体验到这一点。
- en: Breaking the Workflow to Test Syntax Validation and Error Messaging
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 中断工作流以测试语法验证和错误消息
- en: 'Hopefully, so far everything ran as expected for you, so you know what success
    looks like. But in reality, things occasionally go wrong, so now let’s look at
    what failure looks like. Specifically, we’re going to look at how Cromwell handles
    two common types of scripting error, WDL syntax and `command` block syntax errors,
    by introducing some errors in the WDL. First, let’s make a copy of the workflow
    file so that we can play freely:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 希望到目前为止一切都按预期进行，这样您就知道成功的样子。但实际上，事情偶尔会出错，所以现在让我们看看失败的情况。具体来说，我们将看看 Cromwell
    如何处理两种常见的脚本错误类型，即 WDL 语法和 `command` 块语法错误，通过在 WDL 中引入一些错误。首先，让我们复制工作流文件，以便可以自由玩耍：
- en: '[PRE52]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Now, in your preferred text editor, open the new file and introduce an error
    in the WDL syntax. For example, you could mangle one of the variable names, one
    of the reserved keywords, or delete a curly brace to mess with the block structure.
    Here, we’ll be a bit sadistic and delete the second parenthesis in the `basename()`
    function call. It’s the kind of small error that is fatal yet really easy to overlook.
    Let’s see what happens when we run this:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在您喜欢的文本编辑器中，打开新文件并在 WDL 语法中引入一个错误。例如，您可以弄乱一个变量名、一个保留关键字，或删除一个大括号来干扰块结构。在这里，我们会有点残忍，删除
    `basename()` 函数调用中的第二个括号。这种小错误通常是致命的，但很容易被忽视。让我们看看运行时会发生什么：
- en: '[PRE53]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'As expected, the workflow execution fails, and Cromwell serves us with some
    verbose error messaging:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，工作流执行失败，并且 Cromwell 提供了一些详细的错误消息：
- en: '[PRE54]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'There’s a lot in there that we don’t care about, such as the stack trace, which
    we’re not showing here. The really important piece is `Workflow input processing
    failed: ERROR: Unexpected symbol`. That is a dead giveaway that you have a syntax
    issue. Cromwell will try to give you more specifics indicating where the syntax
    error might lie; in this case, it’s pretty accurate—it expected but didn’t find
    the closing parenthesis (`rparen` for right parenthesis) on line 20—but be aware
    that sometimes it’s not as obvious.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '其中有许多我们不关心的内容，比如堆栈跟踪，这里我们没有展示。真正重要的部分是 `Workflow input processing failed: ERROR:
    Unexpected symbol`。这是一个明显的暗示，表明您有语法问题。Cromwell 尝试提供更具体的信息，指出语法错误可能位于哪里；在这种情况下，它相当准确——它期望但未找到第
    20 行的右括号 (`rparen`)，但请注意，有时情况并不那么明显。'
- en: 'When you’re actively developing a new workflow, you probably won’t want to
    have to launch the workflow through Cromwell each time you need to test the syntax
    of some new code. Good news: you can save time by using `Womtool`’s validate command
    instead. That’s what Cromwell actually runs under the hood, and it’s a very lightweight
    way to test your syntax. Try it now on your broken workflow:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 当您正在积极开发新的工作流时，您可能不想每次需要测试某些新代码的语法时都通过 Cromwell 启动工作流。好消息是：您可以通过使用 `Womtool`
    的 validate 命令来节省时间。这实际上是 Cromwell 在幕后运行的内容，这是一种非常轻量级的测试语法的方式。现在尝试在您的破碎工作流上运行它：
- en: '[PRE55]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: See? You get the important part of Cromwell’s output in a much shorter time
    frame—and you don’t even need to provide valid inputs to the workflow. As an additional
    exercise, try introducing other WDL syntax errors; for example, try deleting a
    variable declaration, changing a variable name in only one of its appearances,
    and misspelling a reserved keyword like `workflow`, `command`, or `outputs`. This
    will help you to recognize validation errors and interpret how they are reported
    by `Womtool`. In general, we heartily recommend using `Womtool validate` systematically
    on any new or updated WDLs (and yes, it works on CWL too).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 看到了吧？您在更短的时间内获得了 Cromwell 输出的重要部分，甚至不需要为工作流提供有效的输入。作为额外的练习，尝试引入其他 WDL 语法错误；例如，尝试删除变量声明，仅更改变量名称中的一个出现，以及拼写保留关键字如
    `workflow`、`command` 或 `outputs`。这将帮助您识别验证错误并解释它们如何被 `Womtool` 报告。总之，我们强烈建议在任何新的或更新的
    WDL（是的，它也适用于 CWL）上系统地使用 `Womtool validate`。
- en: 'That being said, it’s important to understand that `Womtool`’s WDL syntax validation
    will get you only so far: it can’t do anything about any other errors you might
    make that are outside its scope of expertise; for example, if you mess up the
    command syntax for the tool you want to run. To see what happens in that case,
    make another copy of the original workflow in your sandbox (call it *hc-break2.wdl*)
    and open it up to introduce an error in the GATK command this time; for example,
    by mangling the name of the tool, changing it to `HaploCaller`:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，重要的是要理解，`Womtool` 的 WDL 语法验证只能帮助你到这一步：它无法处理你可能在运行的工具命令语法上出错之外的任何其他错误；例如，如果你搞乱了你想要运行的工具的命令语法。要查看在这种情况下会发生什么，请在你的沙盒中再复制一份原始工作流（称为
    *hc-break2.wdl*），并打开它以在这次 GATK 命令中引入错误；例如，通过弄乱工具的名称，将其更改为 `HaploCaller`：
- en: '[PRE56]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'If you run `Womtool validate`, you’ll see this workflow sails right through
    validation; `Womtool` cheerfully reports `Success!` Yet if you actually run it
    through Cromwell, the workflow will most definitely fail:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行 `Womtool validate`，你会看到这个工作流程通过了验证；`Womtool` 愉快地报告说 `Success!` 然而，如果你真正通过
    Cromwell 运行它，这个工作流程肯定会失败：
- en: '[PRE57]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Scroll through the output to find the line showing the failure message:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 滚动输出以查找显示失败消息的行：
- en: '[PRE58]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: The log line that says `Job HelloHaplotypeCaller.HaplotypeCallerGVCF:NA:1 exited
    with return code 2` means that `HaplotypeCallerGVCF` was the task that failed
    and, specifically, that the command it was running reported an exit code of `2`.
    This typically indicates that the tool you were trying to run choked on something—a
    syntax issue, unsatisfied input requirements, formatting errors, insufficient
    memory, and so on.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 日志行中显示 `Job HelloHaplotypeCaller.HaplotypeCallerGVCF:NA:1 exited with return
    code 2` 意味着 `HaplotypeCallerGVCF` 是失败的任务，具体来说，它正在运行的命令报告了一个 `2` 的退出代码。这通常表示你尝试运行的工具在某些方面出了问题——可能是语法问题、未满足的输入要求、格式错误、内存不足等等。
- en: 'The error message goes on to point out that you can find out more by looking
    at the standard error (`stderr`) output produced by the command, and it helpfully
    includes the full file path so that you easily can peek inside it. It also includes
    the first few lines of the `stderr` log for convenience, which is sometimes enough
    if the tool’s error output was very brief. The `stderr` output produced by GATK
    is of the more verbose variety. So here we’ll need to check out the full `stderr`
    to find out what went wrong. Again, make sure to substitute the username and execution
    directory hash shown here (`dd77316f-7c18-4eb1-aa86-e307113c1668`) with the ones
    in your output:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 错误消息继续指出，你可以通过查看命令生成的标准错误 (`stderr`) 输出来了解更多信息，并且它贴心地包含了完整的文件路径，这样你可以轻松地查看其中内容。它还包括
    `stderr` 日志的前几行，这有时足够了，如果工具的错误输出非常简短的话。由 GATK 产生的 `stderr` 输出属于更详细的类型。因此，在这里我们需要检查完整的
    `stderr` 来找出问题所在。再次强调，请确保用你的输出中显示的用户名和执行目录哈希替换这里显示的（`dd77316f-7c18-4eb1-aa86-e307113c1668`）。
- en: '[PRE59]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Ah, look at that! We wrote the name of the tool wrong; who knew? Props to GATK
    for suggesting a correction, by the way; that’s new in GATK4.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 啊，看这个！我们把工具的名称写错了；谁知道呢？顺便说一句，感谢 GATK 建议更正；顺便说一句，这在 GATK4 中是新功能。
- en: Note
  id: totrans-196
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: All command-line tools output a *return code* when they finish running as a
    concise way to report their status. Depending on the tool, the return code can
    be more or less meaningful. Conventionally, a return code of 0 indicates success,
    and anything else is a failure. In some cases, a nonzero code can mean the run
    was successful; for example, the Picard tool `ValidateSamFile` reports nonzero
    codes when it ran successfully but found format validation errors in the files
    it examined.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 所有命令行工具在完成运行时都会输出一个 *返回码* 作为报告它们状态的简洁方式。根据工具的不同，返回码可能更或少有意义。传统上，返回码为 0 表示成功，而其他任何值表示失败。在某些情况下，非零返回码可能意味着运行成功；例如，Picard
    工具 `ValidateSamFile` 在检查的文件中发现格式验证错误时报告非零代码。
- en: Other things can go wrong that we haven’t covered here, such as if you have
    the wrong paths for input files, or if you forgot to wrap string inputs in double
    quotes in the inputs JSON. Again, we recommend that you experiment by making those
    errors on purpose, because it will help you learn to diagnose issues more quickly.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他可能出错的事情我们在这里没有涵盖，比如如果你为输入文件指定了错误的路径，或者如果你忘记在输入 JSON 中的字符串输入上加双引号。再次建议你故意制造这些错误来实验，因为这会帮助你更快速地诊断问题。
- en: Introducing Scatter-Gather Parallelism
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引入 Scatter-Gather 并行性
- en: We’re going to go over one more workflow example in this chapter to round out
    your first exposure to WDL and Cromwell, because we really want you to get a taste
    of the power of parallelization if you haven’t experienced that previously. So
    now we’re going to look at a workflow that parallelizes the operation of the `HaplotypeCaller`
    task we ran previously through a `scatter()` function and then merges the outputs
    of the parallel jobs in a subsequent step, as illustrated in [Figure 8-2](#concept_diagram_of_a_workflow_that_para).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将再介绍一个工作流示例，以补充你对 WDL 和 Cromwell 的第一次接触，因为我们真的希望你能尝试并行处理的强大之处，如果你之前没有经历过的话。所以现在我们将看一个工作流，它通过`scatter()`函数并行处理`HaplotypeCaller`任务的操作，然后在随后的步骤中合并并行作业的输出，如[图8-2](#concept_diagram_of_a_workflow_that_para)所示。
- en: '![Concept diagram of a workflow that parallelizes the execution of HaplotypeCaller.](Images/gitc_0802.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![并行执行HaplotypeCaller的工作流的概念图。](Images/gitc_0802.png)'
- en: Figure 8-2\. A workflow that parallelizes the execution of HaplotypeCaller.
  id: totrans-202
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-2\. 并行执行HaplotypeCaller的工作流。
- en: This workflow will expose you to the magic of scatter-gather parallelism, which
    is a staple of genomics workflows, especially in the cloud. It will also give
    you an opportunity to dig into the mechanics of stringing multiple tasks together
    based on their inputs and outputs in a bit more detail than we covered earlier.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这个工作流将让你接触到散集-聚集并行处理的魔力，这是基因组学工作流的重要组成部分，特别是在云端。它还将让你有机会更详细地了解如何根据输入和输出将多个任务串联在一起的机制，比我们之前讨论的更详细。
- en: Exploring the WDL
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索 WDL
- en: 'Here’s a full WDL that parallelizes the operation of `HaplotypeCallerGVCF`
    over subsets of intervals. In the `nano` editor, open it as usual:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个完整的 WDL，它将`HaplotypeCallerGVCF`的操作并行化处理在子区间上。在`nano`编辑器中，像往常一样打开它：
- en: '[PRE60]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Let’s walk through the main sections of the script, calling out what has changed
    compared to the linear implementation of this workflow:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐步走过脚本的主要部分，指出与这个工作流的线性实现相比有哪些变化：
- en: '[PRE61]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'The most obvious difference is that now a lot more is happening in the `workflow`
    block. The core of the action is this subset (collapsing the two `call` blocks
    for readability):'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 最明显的区别是现在`workflow`块中发生了更多的事情。这个动作的核心是这个子集（为了可读性将两个`call`块合并）：
- en: '[PRE62]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Previously, we were simply making one call to the `HaplotypeCallerGVCF` task,
    and that was it. Now, you see that the call to `HaplotypeCallerGVCF` is subordinated
    to a higher-level action, under this line, which opens a `scatter` block:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 以前，我们只是简单地调用了`HaplotypeCallerGVCF`任务，就是这样。现在，你会看到对`HaplotypeCallerGVCF`的调用被隶属于一个更高级别的操作，在这行下面，它打开了一个`scatter`块：
- en: '[PRE63]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'For such a short line, it does a lot of work: this is how we parallelize the
    execution of `HaplotypeCaller` over subsets of intervals, which are specified
    in the parentheses. The `calling_intervals` variable refers to a list of intervals,
    and the `HaplotypeCallerGVCF` task will be run as a separate invocation on each
    interval provided in that file. This might look a lot like a *for loop*, if you’re
    familiar with that scripting construct, and indeed it is similar in the sense
    that its purpose is to apply the same operation to each element in a list. However,
    the scatter is specifically designed to allow independent execution of each operation,
    whereas a for loop leads to linear execution in which each operation can be run
    only after the previous one (if any) has run to completion.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这么短的一行，它做了很多工作：这就是我们如何在指定的区间上并行执行`HaplotypeCaller`的过程，这些区间在括号中指定。`calling_intervals`变量指的是一个区间列表，`HaplotypeCallerGVCF`任务将在提供的文件中的每个区间上作为一个独立的调用运行。如果你熟悉脚本构造，这可能看起来很像一个*for循环*，实际上它确实类似，因为它的目的是对列表中的每个元素应用相同的操作。然而，scatter专门设计用于允许每个操作的独立执行，而for循环导致线性执行，其中每个操作只能在前一个操作（如果有的话）完成后才能运行。
- en: 'So now that you understand what the `scatter()` instruction does, let’s look
    into the `HaplotypeCallerGVCF` task itself, starting with how it’s being called:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了`scatter()`指令的作用，让我们来看看`HaplotypeCallerGVCF`任务本身，从它是如何被调用的开始：
- en: '[PRE64]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'In the previous version of the workflow, the call to the task was just that:
    the `call` keyword followed by the task name. In this version, the statement includes
    an `input` block that specifies values for some of the variables that are required
    by the task: the input BAM file and its index, the intervals file, and the name
    of the GVCF output file. Speaking of which, you’ll notice that the `basename`
    function call that we use to generate a name for the output is now happening within
    this `input` block instead of happening within the task. If you compare the task
    definitions for `HaplotypeCallerGVCF` between this version of the workflow and
    the previous one, that’s the only difference. Let’s make a mental note of that
    because it will come up again in a few minutes.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在工作流的先前版本中，对任务的调用只是这样：`call`关键字，然后是任务名称。在这个版本中，语句包括一个`input`块，指定了任务所需的一些变量的值：输入BAM文件及其索引，间隔文件，以及GVCF输出文件的名称。说到这一点，你会注意到我们用于生成输出名称的`basename`函数调用现在发生在这个`input`块内，而不是任务内部。如果你比较了本版本工作流中`HaplotypeCallerGVCF`任务的定义和之前版本的定义，那就是唯一的区别。让我们在几分钟后再次记住这一点。
- en: 'Now let’s talk about what follows the `scatter` block containing the `HaplotypeCallerGVCF`
    call: a call to a new task named `MergeVCFs`. To be clear, this call statement
    is *outside* of the `scatter` block, so it will be run only once:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们谈谈跟在包含`HaplotypeCallerGVCF`调用的`scatter`块后面的内容：对名为`MergeVCFs`的新任务的调用。明确一点，这个调用语句是*在*`scatter`块之外的，因此它只会运行一次：
- en: '[PRE65]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'You probably already have a pretty good idea of what this task is for based
    on its name, but let’s pretend it’s not that obvious and follow the logical path
    for deciphering the structure of the workflow. Peeking ahead into the `MergeVCFs`
    task definition, we see that the command it runs is a GATK command that invokes
    a tool called `MergeVcfs` (actually, a Picard tool bundled into GATK4). As input,
    it takes one or more VCF files (of which GVCFs are a subtype) and outputs a single
    merged file:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经根据其名称对这项任务有了一个相当好的想法，但我们假装这并不那么明显，按照逻辑路径来解密工作流程的结构。预览`MergeVCFs`任务定义，我们看到它运行的命令是一个调用名为`MergeVcfs`的工具（实际上是捆绑到GATK4中的Picard工具）。作为输入，它接受一个或多个VCF文件（其中GVCF是一个子类型），并输出一个合并后的单个文件：
- en: '[PRE66]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: We can infer this from the command arguments and the variable names, and confirm
    it by looking up the `MergeVcfs` tool documentation on the GATK website.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从命令参数和变量名推断出这一点，并通过查阅GATK网站上的`MergeVcfs`工具文档来确认。
- en: Note
  id: totrans-222
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'One novel point of WDL syntax to note here: the `-I ${sep='' -I'' vcfs}` formulation
    is how we deal with having a list of items of arbitrary length that we need to
    put into the command line with the same argument for each item. Given a list of
    files `[FileA, FileB, FileC]`, the preceding code would generate the following
    portion of the command line: `-I FileA -I FileB -I FileC`.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 这里要注意WDL语法的一个新点：`-I ${sep=' -I' vcfs}`的表达式是我们处理需要将列表中的项目放入命令行的相同参数的任意长度列表的方式。给定文件列表`[FileA,
    FileB, FileC]`，前述代码将生成命令行的以下部分：`-I FileA -I FileB -I FileC`。
- en: 'The `MergeVCFs` task definition also tells us that this task expects a list
    of files (technically expressed as `Array[*File*]`) as its main input. Let’s look
    at how the task is called in the `workflow` block:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '`MergeVCFs`任务定义还告诉我们，此任务期望一个文件列表（在技术上表示为`Array[*File*]`）作为其主要输入。让我们看看任务在`workflow`块中是如何调用的：'
- en: '[PRE67]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: This might feel familiar if you remember the `ReadItBackToMe` task in the `HelloWorld​Again`
    workflow. Much as we did then, we’re assigning the `vcfs` input variable by referencing
    the output of the `HaplotypeCallerGVCF` task. The difference is that in that case,
    we were passing a single-file output to a single-file input. In contrast, here
    we’re referencing the output of a task call that resides inside a `scatter` block.
    What does that even look like?
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还记得`HelloWorld​Again`工作流中的`ReadItBackToMe`任务，这可能会让你觉得很熟悉。就像我们当时所做的那样，我们通过引用`HaplotypeCallerGVCF`任务的输出来分配`vcfs`输入变量。不同之处在于，在那种情况下，我们将单个文件输出传递给单个文件输入。相反，在这里，我们引用了一个位于`scatter`块内的任务调用的输出。这到底是什么样子？
- en: Excellent question. By definition, each separate invocation of the task made
    within the `scatter` block generates its own separate output. The neat thing about
    the scatter construct is that those separate outputs are automatically collected
    into a list (technically an array) under the name of the output variable specified
    by the task. So here, although the output value of a single invocation of the
    `HaplotypeCallerGVCF` task, named `HaplotypeCallerGVCF.output_gvcf`, is a single
    GVCF file, the value of `HaplotypeCallerGVCF.output_gvcf` referenced in the `workflow`
    block is a list of the GVCF files generated within the `scatter` block. When we
    pass that reference to the next task call, we’re effectively providing the full
    list of files as an array.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 很好的问题。根据定义，`scatter`块内部对任务的每个单独调用生成其自己的单独输出。`scatter`结构的巧妙之处在于，这些单独的输出自动收集到一个列表（技术上是一个数组），名称为任务指定的输出变量。因此，在这里，虽然`HaplotypeCallerGVCF`任务的单个调用的输出值，即`HaplotypeCallerGVCF.output_gvcf`，是单个GVCF文件，但在`workflow`块中引用的`HaplotypeCallerGVCF.output_gvcf`的值是`scatter`块内生成的GVCF文件列表。当我们将该引用传递给下一个任务调用时，我们实际上是提供了作为数组的全部文件列表。
- en: Let’s finish this exploration by calling out a few more details. First, you
    might notice that we explicitly declare the output of the `MergeVCFs` call as
    the final output of the workflow in the workflow-level `output` block. This is
    technically not required, but it is good practice. Second, the variable declarations
    for the BAM file, its index, and the intervals file were all pushed up to the
    workflow level. In the case of the BAM file and its index, this move allows us
    to generate the names of the output files in the `input` blocks of both task calls,
    which among other advantages gives us more flexibility if we want to put our task
    definitions into a common library. For something like that, we want the tasks
    to be as generic as possible, and leave details like file-naming conventions up
    to the workflow implementations. As for the intervals file, we need to have it
    available at the workflow level in order to implement the `scatter` block.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过指出一些更多的细节来完成这次探索。首先，您可能注意到我们在工作流级别的`output`块中明确声明了`MergeVCFs`调用的输出作为工作流的最终输出。这在技术上并不是必需的，但这是一种良好的实践。其次，BAM文件、其索引和间隔文件的变量声明都被提升到了工作流的级别。对于BAM文件及其索引，这一举措允许我们在两个任务调用的`input`块中生成输出文件的名称，这样做除了其他优势外，如果我们想将任务定义放入公共库中，还可以给我们更多的灵活性。对于这样的情况，我们希望任务尽可能通用，并将诸如文件命名约定之类的细节留给工作流实现。至于间隔文件，我们需要在工作流级别上可用它，以便实现`scatter`块。
- en: Finally, you should now be able to generate the *inputs* JSON, fill it out based
    on the previous exercise, and run the workflow using the same setup as previously.
    We included a prefilled JSON if you want to save yourself the hassle of filling
    in file paths; just make sure to use the *.local.inputs.json* version rather than
    the *.gcs.inputs.json*, which we use in [Chapter 10](ch10.xhtml#running_single_workflows_at_scale_with).
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，现在您应该能够生成*inputs* JSON，根据之前的练习填写它，并使用与以前相同的设置运行工作流。我们提供了一个预填充的JSON，如果您不想填写文件路径，可以使用它；只需确保使用*.local.inputs.json*版本，而不是我们在[第10章](ch10.xhtml#running_single_workflows_at_scale_with)中使用的*.gcs.inputs.json*版本。
- en: 'Here’s the Cromwell command using the prefilled local inputs JSON. Make sure
    to execute this in your home directory so that the relative paths in the *inputs*
    JSON file match the location of the data files:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是使用预填充本地输入JSON的Cromwell命令。请确保在您的主目录中执行此命令，以便*inputs* JSON文件中的相对路径与数据文件的位置匹配。
- en: '[PRE68]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: When you run this command, you might notice the scatter jobs running in parallel
    on your VM. This is great because it means jobs will finish sooner. However, what
    happens if you’re trying to run five hundred scatter calls across a full genome?
    Running these all in parallel is going to cause problems; if it doesn’t outright
    crash, it will at least grind your VM to a halt as it swaps RAM to disk frantically.
    The good news is there are a couple solutions for this. First, you can control
    the level of parallelism allowed by the “local” backend for Cromwell, as described
    in the [online documentation](https://oreil.ly/8F4hp). Alternatively, you can
    use a different backend that is designed to handle this kind of situation gracefully.
    In [Chapter 10](ch10.xhtml#running_single_workflows_at_scale_with), we show you
    how to use  the Google backend to automatically send parallel jobs to multiple
    VMs.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 当您运行此命令时，您可能会注意到散布的作业在虚拟机上并行运行。这很好，因为它意味着作业将更快完成。但是，如果您尝试在整个基因组上运行五百个散布调用会发生什么呢？将所有这些并行运行将会引起问题；即使不会直接崩溃，它也会将您的虚拟机推向磁盘交换内存的边缘。好消息是有几种解决方案。首先，您可以通过“local”后端控制允许的并行性级别，如
    [在线文档](https://oreil.ly/8F4hp) 中所述。或者，您可以使用另一种专为优雅处理此类情况而设计的后端。在 [第 10 章](ch10.xhtml#running_single_workflows_at_scale_with)
    中，我们将向您展示如何使用 Google 后端自动将并行作业发送到多个虚拟机。
- en: Generating a Graph Diagram for Visualization
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成可视化的图形图表
- en: 'As a coda to this exercise, let’s learn to apply one more `Womtool` utility:
    the `graph` command.  The workflows we’ve looked at so far have been quite simple
    in terms of the number of steps and overall plumbing. In the next chapter (and
    out in the real world), you will encounter more complex workflows, for which it
    might be difficult to build a mental model based on the code alone. That’s where
    it can be incredibly helpful to be able to generate a visualization of the workflow.
    The `Womtool graph` command allows you to generate a graph file in *.dot* format
    and visualize it using generic graph visualization tools:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 作为此练习的结尾，让我们学习应用另一个 `Womtool` 实用程序：`graph` 命令。到目前为止，我们所看到的工作流在步骤数量和总体管道方面都相当简单。在下一章节（以及现实世界中），您将会遇到更复杂的工作流，单凭代码可能很难建立起一个心理模型。这时，能够生成工作流的可视化图形将非常有帮助。`Womtool
    graph` 命令允许您生成一个 *.dot* 格式的图形文件，并使用通用的图形可视化工具进行查看：
- en: '[PRE69]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'The *.dot* file is a plain-text file, so you can view it in the terminal; for
    example:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '*.dot* 文件是一个纯文本文件，因此您可以在终端中查看它；例如：'
- en: '[PRE70]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: However, that’s not terribly visual, so let’s load it into a graph viewer. There
    are many available options, including the very popular open source package [Graphviz](https://oreil.ly/FS_SR).
    You can either install the package on your local machine or use it through one
    of its [many online implementations](https://oreil.ly/WSMml). To do so, simply
    copy the contents of the *.dot* file into the text window of the visualizer app,
    and it will generate the graph diagram for you, as shown in [Figure 8-3](#visualizing_the_workflow_graph_in_an_on).
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 但是这并不直观，所以让我们将其加载到图形查看器中。有许多可用的选项，包括非常流行的开源软件包 [Graphviz](https://oreil.ly/FS_SR)。您可以在本地安装该软件包，也可以通过其
    [许多在线实现](https://oreil.ly/WSMml) 之一使用它。要这样做，只需将 *.dot* 文件的内容复制到可视化应用程序的文本窗口中，它将为您生成图形图表，如
    [图 8-3](#visualizing_the_workflow_graph_in_an_on) 所示。
- en: '![Visualizing the workflow graph in an online Graphviz application.](Images/gitc_0803.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![在在线 Graphviz 应用程序中可视化工作流图。](Images/gitc_0803.png)'
- en: Figure 8-3\. Visualizing the workflow graph in an online Graphviz application.
  id: totrans-240
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-3\. 在线 Graphviz 应用程序中可视化工作流图。
- en: When we visualize a workflow graph like this, we typically look at the ovals
    first, which represent calls to tasks in the workflow. Here you can see that the
    two task calls in our workflow are indeed present, `HaplotypeCallerGVCF` and `MergeVCFs`.
    The direction of the arrows connecting the ovals indicates the flow of execution,
    so in [Figure 8-3](#visualizing_the_workflow_graph_in_an_on), you can see that
    the output of `HaplotypeCallerGVCF` is going to be the input to `MergeVCFs`.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们像这样可视化工作流图时，通常首先查看表示工作流中任务调用的椭圆形。在这里，您可以看到我们工作流中的两个任务调用确实存在，`HaplotypeCallerGVCF`
    和 `MergeVCFs`。连接椭圆形的箭头方向表示执行流程，因此在 [图 8-3](#visualizing_the_workflow_graph_in_an_on)
    中，您可以看到 `HaplotypeCallerGVCF` 的输出将成为 `MergeVCFs` 的输入。
- en: Interestingly, the call to `HaplotypeCallerGVCF` is displayed with a box around
    it, which means it is under the control of a modifying function. The modifier
    function is represented as a hexagon, and here you can see the hexagon is labeled
    “scatter over String as interval.” That all makes sense because we just discussed
    how in this workflow the execution of the `HaplotypeCaller` task is scattered
    over a list of intervals.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，对`HaplotypeCallerGVCF`的调用显示为一个框，这意味着它受到一个修改函数的控制。修改函数以六边形表示，在这里您可以看到六边形标记为“在字符串作为间隔上分散”。这一切都说得通，因为我们刚刚讨论过在这个工作流中，`HaplotypeCaller`任务的执行是在一组间隔上分散的。
- en: In this case, the workflow was straightforward enough that the graph visualization
    didn’t really tell us anything we didn’t already know, but when we tackle more
    complex workflows in the next chapter, graph visualization is going to be a crucial
    part of our toolkit.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，工作流程相对简单，因此图形可视化并没有告诉我们任何我们之前不知道的内容，但是当我们在下一章中处理更复杂的工作流时，图形可视化将成为我们工具箱中至关重要的一部分。
- en: Note
  id: totrans-244
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: This concludes the exercises in this chapter, so don’t forget to stop your VM;
    otherwise, you’ll be paying just to have it idly ponder the futility of existence.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了本章的练习，所以不要忘记停止您的虚拟机；否则，您将仅仅为了它闲逛而支付费用。
- en: Wrap-Up and Next Steps
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结和下一步
- en: In this chapter, we looked at how to string individual commands into a simple
    Hello World workflow, and we executed it using Cromwell in one-shot run mode on
    the single VM that we had set up in [Chapter 4](ch04.xhtml#first_steps_in_the_cloud).
    We covered the basics of interpreting Cromwell’s terminal output and finding output
    files. We iterated on the original `Hello​World` workflow, adding variables and
    an additional task. Then, we moved on to examine more realistic workflows that
    run real GATK commands and use scatter-gather parallelism, though still at a fairly
    small scale. Along the way, we exercised key utilities for generating JSON templates,
    validating WDL syntax, testing error handling, and generating graph visualizations.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了如何将单个命令串联成一个简单的Hello World工作流，并在我们在[第四章](ch04.xhtml#first_steps_in_the_cloud)中设置的单个VM上使用Cromwell的一次性运行模式执行它。我们介绍了解释Cromwell终端输出和查找输出文件的基础知识。我们在原始的`Hello​World`工作流上进行了迭代，添加了变量和一个额外的任务。然后，我们继续研究了运行真实GATK命令并使用分散聚集并行性的更现实的工作流，尽管规模仍然相对较小。在此过程中，我们使用了一些关键的实用程序，如生成JSON模板、验证WDL语法、测试错误处理以及生成图形可视化。
- en: However, we only scratched the surface of WDL’s capabilities as a workflow language,
    so now it’s time to move on to some more sophisticated workflows. In [Chapter 9](ch09.xhtml#deciphering_real_genomics_workflows),
    we examine two mystery workflows and try to reverse engineer what they do, which
    will give you the opportunity to hone your detective skills and also learn some
    useful patterns that are used in real genomics analysis workflows.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们只是浅尝WDL作为工作流语言的能力，所以现在是时候转向一些更复杂的工作流了。在[第九章](ch09.xhtml#deciphering_real_genomics_workflows)，我们将研究两个神秘的工作流，并试图反向工程它们的功能，这将为您提供锻炼侦探技能的机会，同时学习一些在真实基因组分析工作流中使用的有用模式。
