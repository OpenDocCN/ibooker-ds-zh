- en: 15 Migrate
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 15迁移
- en: Antonio Gulli
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 安东尼奥·古利
- en: This chapter covers
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: The benefits of using Migrate for Anthos
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Migrate for Anthos的好处
- en: Recommended workloads for migration
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐迁移的工作负载
- en: Migrate for Anthos architecture
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Migrate for Anthos架构
- en: Using Migrate for Anthos to migrate a workload
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Migrate for Anthos迁移工作负载
- en: Best practices for Migrate for Anthos
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Migrate for Anthos的最佳实践
- en: Containers provide developers multiple advantages, including increased speed
    when deploying and provisioning workloads, higher resource utilization, portability,
    and cost efficiency compared to virtual machines (VMs).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 与虚拟机（VMs）相比，容器为开发者提供了多项优势，包括部署和配置工作负载时的速度加快、资源利用率更高、可移植性和成本效益，以及更高的效率。
- en: However, many customers have several thousands of applications written over
    multiple years running on VM infrastructure using heritage frameworks. For these
    customers, it would be too time consuming and expensive to rewrite their applications.
    Therefore, they need tools to modernize workloads and to provide the benefits
    of modern cloud native environments without incurring the cost of rewriting applications
    from scratch. The whole value proposition is to decrease customers’ time to market
    during transformation projects and to augment and optimize traditional workloads
    with modern cloud infrastructure and services.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，许多客户在过去的几年中在虚拟机基础设施上使用遗产框架编写了数千个应用程序。对于这些客户来说，重写他们的应用程序将耗费太多时间和金钱。因此，他们需要工具来现代化工作负载，并在不从头开始重写应用程序的情况下提供现代云原生环境的好处。整个价值主张是减少客户在转型项目中的上市时间，并通过现代云基础设施和服务增强和优化传统工作负载。
- en: Google believes that modernization doesn’t have to be all or nothing. Microservices
    architectures structure an application as a collection of services that are highly
    maintainable and testable, loosely coupled via APIs, and independently deployable.
    However, even if you don’t use a microservice architecture from the beginning,
    you can convert your applications into containers and still take advantage of
    many of the benefits typically obtained by cloud native applications. This is
    what we’ll see in this chapter.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Google认为，现代化不一定是全有或全无。微服务架构将应用程序结构化为一系列高度可维护和可测试的服务集合，通过API松散耦合，并可独立部署。然而，即使您最初没有使用微服务架构，您也可以将您的应用程序转换为容器，并仍然能够利用云原生应用程序通常获得的好处。这正是本章将要展示的内容。
- en: Migrate for Anthos (in short, M4A) is a tool that helps extract your legacy
    workloads from your VMs and transform them into containers, including all you
    need for execution—the runtime, system tools, libraries, code, configurations,
    and settings. Once your application is migrated, you can run it on Anthos, either
    on Google’s Kubernetes Engine (GKE), on-prem, or in other clouds. In this way,
    the management of infrastructure, hardware, and the OS/kernel are “abstracted
    away” and delegated to your cloud provider(s).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Migrate for Anthos（简称M4A）是一个工具，它帮助您从虚拟机中提取遗留工作负载，并将它们转换为容器，包括执行所需的所有内容——运行时、系统工具、库、代码、配置和设置。一旦您的应用程序迁移完成，您就可以在Anthos上运行它，无论是在Google的Kubernetes
    Engine（GKE）上、本地还是在其他云中。这样，基础设施、硬件和操作系统/内核的管理就被“抽象化”并委托给您的云提供商（们）。
- en: Furthermore, M4A generates the artifacts that enable you to switch to modern
    software development using CI/CD pipelines and shifting from package management
    to container-/image-based management. You can think about M4A as an accelerator
    to the ultimate goal of modernization, and this acceleration can happen at scale,
    with many legacy applications migrated together in bulk. M4A can let you operate
    thousands of legacy applications at scale by modernizing the underlying compute
    infrastructure, network, storage, and management.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，M4A生成使您能够切换到使用CI/CD管道的现代软件开发的艺术品，并从包管理转移到基于容器/镜像的管理。您可以将M4A视为现代化最终目标的加速器，这种加速可以在规模上发生，许多遗留应用程序可以一起大量迁移。M4A可以通过现代化底层计算基础设施、网络、存储和管理，以规模的方式让您操作数千个遗留应用程序。
- en: M4A supports both Linux and Windows migration to containers. Source environments
    can include either a GCP Compute Engine environment, a VMware vSphere environment,
    a Microsoft Azure VM environment, or an Amazon Elastic Compute Cloud (Amazon EC2)
    environment. All workloads are directly migrated with no need for access to the
    original source code, rewriting your workloads, or manually containerizing your
    workloads.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: M4A 支持将 Linux 和 Windows 迁移到容器。源环境可以包括 GCP 计算引擎环境、VMware vSphere 环境、Microsoft
    Azure 虚拟机环境或 Amazon 弹性计算云（Amazon EC2）环境。所有工作负载都直接迁移，无需访问原始源代码、重写工作负载或手动容器化工作负载。
- en: Most of the migration work is done automatically, and you can modify the generated
    migration plans to fine tune the desired modernization. While the migration process
    executes, the application can continue to run uninterrupted, and you can be up
    and running with the containerized app in minutes. If you want to go back to the
    initial state, you can roll back with no data lost. Migrated workload container
    images that are generated by M4A are automatically deployed into Google Container
    Registry (GCR) or other local repositories and can run in any environment without
    you having to install an M4A component on target workload clusters. Of course,
    the whole M4A process can be performed and monitored via the Google Cloud console
    UI.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 大部分迁移工作都是自动完成的，你可以修改生成的迁移计划以微调所需的现代化。在迁移过程执行期间，应用程序可以继续不间断地运行，你可以在几分钟内启动运行容器化应用程序。如果你想回到初始状态，你可以回滚而不会丢失数据。由
    M4A 生成的迁移工作负载容器镜像会自动部署到 Google 容器注册库（GCR）或其他本地存储库，并且可以在任何环境中运行，无需你在目标工作负载集群上安装
    M4A 组件。当然，整个 M4A 流程都可以通过 Google Cloud 控制台 UI 来执行和监控。
- en: Now that we have set up the context, let’s look at M4A’s benefits in detail.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经设置了上下文，让我们详细看看 M4A 的好处。
- en: 15.1 Migrate for Anthos benefits
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 15.1 迁移至 Anthos 的好处
- en: 'M4A allows us to unbundle more and more infrastructure from inside VMs and
    manage it with Kubernetes. This modernization unifies app management with modern
    IT skills. Indeed, in the numerous cases described in detail in this chapter,
    it is possible to promote legacy applications to first-class objects in a cloud
    native environment with no need to change or access the code. The unlocked improvements
    at scale follow:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: M4A 允许我们从虚拟机内部解包越来越多的基础设施，并用 Kubernetes 来管理它。这种现代化将应用程序管理与现代 IT 技能统一起来。确实，在本章详细描述的众多案例中，可以将遗留应用程序提升为云原生环境中的第一类对象，而无需更改或访问代码。规模化的解锁改进如下：
- en: Define the infrastructure with declarative APIs, dynamic scaling, self-healing,
    and programmatic rollout.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用声明性 API、动态扩展、自我修复和程序化部署来定义基础设施。
- en: Take advantage of improved workload density on the data center, allowing for
    better resource utilization.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用数据中心提高的工作负载密度，从而实现更好的资源利用率。
- en: Maintain the infrastructure metrics, business metrics, network policies, and
    project access control.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维护基础设施指标、业务指标、网络策略和项目访问控制。
- en: Integrate CI/CD pipelines and build systems.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成 CI/CD 管道和构建系统。
- en: 'M4A benefits are transparently gained in different areas: density, cost, security,
    infrastructure, automation, service management, and Day 2 operations. Let’s discuss
    each class in more detail.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: M4A 的好处在不同领域透明获得：密度、成本、安全性、基础设施、自动化、服务管理和第二天运营。让我们更详细地讨论每一类。
- en: 15.1.1 Density
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.1.1 密度
- en: 'VMs are abstracted from the underlying physical hardware. Whereas legacy bare
    metal servers can support only a single application, hypervisor[¹](#pgfId-1080678)
    virtualization allows the applications of multiple VMs to run on a single bare
    metal server, sharing the underlying resources. Bare metal use is described here:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟机从底层物理硬件中抽象出来。而传统的裸金属服务器只能支持单个应用程序，虚拟化管理程序[¹](#pgfId-1080678) 允许多个虚拟机的应用程序在单个裸金属服务器上运行，共享底层资源。裸金属的使用在此描述：
- en: Typically, bare metal utilization is at 5%-15%, and virtual machines can increase
    it up to 30%.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通常，裸金属利用率在 5%-15%，而虚拟机可以将利用率提高到 30%。
- en: Containers enhance workload density, because multiple containers are typically
    run on the same VM or bare metal server. In addition, the density is increased
    because things like OS/kernels, networking, and storage are abstracted away, as
    discussed earlier in the chapter.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器通过在同一个虚拟机或裸金属服务器上运行多个容器来提高工作负载密度。此外，由于操作系统/内核、网络和存储等抽象化，正如本章前面所讨论的，密度也增加了。
- en: The actual utilization gains will depend on several specific factors in your
    environment. Frequently, many organizations report significant gains as they move
    from physical servers, to VMs, to containers. For instance, the *Financial Times*
    content platform team reported an 80% reduction of server costs by adopting containers
    (see [http://mng.bz/mJ0P](http://mng.bz/mJ0P)).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 实际的利用率提升将取决于您环境中的一些特定因素。通常，许多组织在从物理服务器迁移到虚拟机，再到容器时，会报告显著的收益。例如，*《金融时报》*的内容平台团队报告说，通过采用容器，服务器成本降低了80%（见[http://mng.bz/mJ0P](http://mng.bz/mJ0P)）。
- en: 15.1.2 Cost
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.1.2 成本
- en: 'An increase in density results in immediate cost savings for infrastructure.
    As discussed earlier, density increase is a result of two facts: multiple containers
    can be packed on the same physical machine, and many software layers are abstracted
    away, which results in better usage of the available resources, requiring fewer
    servers, leading to an overall cost savings. Cost is a by-product of being able
    to elastically scale. If demand is low, then resources can be reduced, thus saving
    on the operating cost.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 密度的增加会导致基础设施成本立即降低。如前所述，密度的增加是由两个事实造成的：多个容器可以打包在同一台物理机器上，许多软件层被抽象化，这导致了对可用资源的更好利用，需要更少的服务器，从而实现总体成本节约。成本是能够弹性扩展的副产品。如果需求低，则可以减少资源，从而节省运营成本。
- en: Moreover, after migration, legacy applications are promoted to first-class citizens
    together with cloud native applications. As a side effect, you don’t need to maintain
    two working environments (both the legacy and the modern one), so, the unified
    management of workloads allows further cost reduction at scale.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，迁移后，遗留应用程序与云原生应用程序一起被提升为第一类公民。作为副作用，您不需要维护两个工作环境（既包括遗留的也包括现代的），因此，工作负载的统一管理允许在规模上进一步降低成本。
- en: If you want to know more about cost reduction, check the Google Cloud pricing
    calculator at [https://cloud.google.com/products/calculator](https://cloud.google.com/products/calculator)
    to estimate your monthly charges, including cluster management fees and worker
    node pricing for GKE.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想了解更多关于成本降低的信息，请查看Google Cloud定价计算器[https://cloud.google.com/products/calculator](https://cloud.google.com/products/calculator)，以估算您的月度费用，包括集群管理费和GKE的工作节点定价。
- en: 15.1.3 Infrastructure
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.1.3 基础设施
- en: After moving the application to containers, you can see the whole infrastructure
    as code, knowing how the applications, processes, and dependencies work together.
    Any change in infrastructure can be stored in a repository (in short, repo) with
    operations such as commit, push, pull, merging, and branching applied to any part
    of your infrastructure, including config files. Traditionally, maintaining an
    infrastructure is a considerable cost for enterprise. Moving to infrastructure
    as code allows teams to implement DevOps/SRE methodologies, which leads to further
    cost savings at scale due to enhanced agility and reliability.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 将应用程序迁移到容器后，您可以以代码的形式看到整个基础设施，了解应用程序、进程和依赖项是如何协同工作的。任何基础设施的变化都可以存储在仓库（简称repo）中，对基础设施的任何部分（包括配置文件）都可以应用操作，如提交、推送、拉取、合并和分支。传统上，维护基础设施是企业的一项重大成本。转向基础设施即代码允许团队实施DevOps/SRE方法，这由于提高了灵活性和可靠性，从而在规模上进一步节约成本。
- en: 15.1.4 Automation
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.1.4 自动化
- en: 'Managing virtual machines is an expensive, time-consuming, and error-prone
    process due to the need to patch and upgrade infrastructure either manually or
    with a plethora of third-party tools, which might increase the level of complexity.
    Anthos is an enabler for modernization and facilitates the move to containers
    for legacy workloads, which has an indirect effect on cost. For instance, on GKE
    for Anthos many operations are run automatically on the customer’s behalf, including
    the following:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 由于需要手动或使用大量第三方工具修补和升级基础设施，因此管理虚拟机是一个昂贵、耗时且容易出错的过程，这可能会增加复杂度。Anthos是现代化和促进将遗留工作负载迁移到容器的推动者，这对成本有间接影响。例如，在Anthos的GKE上，许多操作都是代表客户自动运行的，包括以下内容：
- en: '*Node autorepair*—Keeps the nodes in your Kubernetes cluster in a healthy,
    running state.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*节点自动修复*——保持您的Kubernetes集群中的节点处于健康、运行状态。'
- en: '*Node autoupgrade*—Keeps the nodes in your Kubernetes cluster up to date with
    the cluster master version when your master is updated on your behalf.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*节点自动升级*——当您的集群主版本更新时，保持您的Kubernetes集群中的节点与集群主版本保持最新。'
- en: '*Node autosecurity*—Security patches can be automatically deployed in a transparent
    way.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*节点自动安全*——安全补丁可以以透明的方式自动部署。'
- en: '*Node autoscale*—Dynamically scales your Kubernetes nodes up and down according
    to instantaneous load increase/decrease.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*节点自动扩展*—根据瞬时负载的增加/减少动态扩展您的Kubernetes节点。'
- en: '*Node autoprovisioning*—Automatically manages a set of Kubernetes node pools
    on the user’s behalf.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*节点自动配置*—代表用户自动管理一组Kubernetes节点池。'
- en: '*Progressive rollout/canary/A/B testing*—Programmatically rolls out applications
    on Kubernetes clusters, with rollbacks in case of problems.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*渐进式发布/金丝雀/A/B测试*—在Kubernetes集群上以编程方式部署应用程序，在出现问题时进行回滚。'
- en: As a rule of thumb, increasing the automation in your infrastructure will reduce
    the risk of accidental errors, enhance the reliability of the whole system, and
    reduce the cost.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 按照惯例，增加您基础设施中的自动化程度将降低意外错误的风险，提高整个系统的可靠性，并降低成本。
- en: 15.1.5 Security
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.1.5 安全
- en: 'Once you move into containers, several security operations are facilitated.
    On Anthos, these operations include the following:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦迁移到容器，就可以简化多个安全操作。在Anthos上，这些操作包括以下内容：
- en: '*Security-optimized node kernel and OS updates*—Anthos offers automatic operating
    system upgrades and kernel patches for the worker nodes, freeing you from the
    burden of maintaining the OS, which is a substantial cost if your server fleet
    is large. VMs must run a full guest operating system, even if they host only a
    single app. Instead, containers reduce operational cost because there is no need
    to run an OS.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*安全优化的节点内核和操作系统更新*—Anthos为工作节点提供自动操作系统升级和内核补丁，让您摆脱维护操作系统的负担，如果您的服务器群很大，这会是一笔巨大的成本。虚拟机必须运行完整的客户操作系统，即使它们只托管单个应用程序。相反，容器减少了运营成本，因为不需要运行操作系统。'
- en: '*Binary authorization and container analysis*—Anthos offers a deploy-time security
    control that ensures only trusted container images are deployed in your environment.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*二进制授权和容器分析*—Anthos提供部署时的安全控制，确保只有受信任的容器镜像被部署到您的环境中。'
- en: '*Zero-trust security model*—Anthos Service Mesh (ASM), covered in chapter 4,
    and the core capabilities of Kubernetes allow us to provide network isolation
    and TLS security without changing the application code.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*零信任安全模型*—在第4章中介绍的Anthos Service Mesh（ASM）和Kubernetes的核心功能使我们能够在不更改应用程序代码的情况下提供网络隔离和TLS安全。'
- en: '*Identity-based security model*—With ASM, you can get security insights, security
    policies, and policy-driven security. These cases are discussed in detail in chapter
    4.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基于身份的安全模型*—使用ASM，您可以获得安全见解、安全策略和政策驱动的安全。这些案例在第4章中详细讨论。'
- en: Transparently increasing security will reduce the risk of an incident and the
    associated high cost.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 透明地提高安全性将降低事件发生的风险及其相关的高昂成本。
- en: 15.1.6 Service management
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.1.6 服务管理
- en: 'After moving to the containers, you can use Anthos Service Mesh (see chapter
    4) to determine where your services are connected and get telemetry and visibility
    into your application without changing code. Some of the benefits transparently
    gained on Anthos follow:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移到容器后，您可以使用Anthos Service Mesh（见第4章）来确定您的服务连接在哪里，并在不更改代码的情况下获取应用程序的遥测和可见性。在Anthos上透明获得的以下好处：
- en: '*Encryption*—Applications can communicate with end-to-end encryption with no
    need for changing the code.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*加密*—应用程序可以无需更改代码即可使用端到端加密进行通信。'
- en: '*Integrated logging and monitoring*—You can get uniform metrics and traffic
    flow logs across your application.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*集成日志和监控*—您可以在应用程序中获得统一的指标和流量流日志。'
- en: '*Uniform observability*—You can observe service dependencies and understand
    the critical customer journey and how they affect your service-level agreement
    (SLA[²](#pgfId-1080741)) from end to end. You do this by setting up service-level
    objectives (SLOs[³](#pgfId-1080746)) on your applications.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*统一可观察性*—您可以从端到端观察服务依赖关系，了解关键客户旅程及其如何影响您的服务级别协议（SLA[²](#pgfId-1080741)）。您通过在应用程序上设置服务级别目标（SLO[³](#pgfId-1080746)）来完成此操作。'
- en: '*Operational agility*—You can dynamically migrate traffic and perform circuit
    breaking,[⁴](#pgfId-1080751) retries within your environment, canaries,[⁵](#pgfId-1080754)
    and A/B testing. Taking a canary as an example, you can move, based on a weighting,
    a certain amount of traffic from one service to a newer version of that service.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*操作敏捷性*—您可以在环境中动态迁移流量和执行断路器，[⁴](#pgfId-1080751) 重试，金丝雀[⁵](#pgfId-1080754)，以及A/B测试。以金丝雀为例，您可以根据权重，将一定量的流量从一个服务移动到该服务的较新版本。'
- en: '*Bridging*—You can use service meshes to bridge traffic between on-prem and
    multiple clouds.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*桥接*—您可以使用服务网格在本地和多个云之间桥接流量。'
- en: In general, adopting a service mesh will enhance your understanding of your
    infrastructure, which might become quite complex over time.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，采用服务网格将增强您对基础设施的理解，随着时间的推移，这可能变得相当复杂。
- en: 15.1.7 Day 2 operations
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.1.7 第二天运营
- en: 'Anthos relieves the burden of Day 2 operations. Once your application is migrated,
    you can benefit from many Google Cloud Platform (GCP) capabilities, such as the
    following:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Anthos减轻了第二天运营的负担。一旦您的应用程序迁移完成，您就可以享受许多Google Cloud Platform (GCP)的能力，例如以下内容：
- en: '*Cloud Logging and Cloud Monitoring*—Cloud Logging allows you to store, search,
    analyze, monitor, and alert on log data and events from Google Cloud, whereas
    Cloud Monitoring provides visibility into the performance, uptime, and overall
    health of cloud-powered applications. After migration, both services are available
    via configuration change only.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*云日志和云监控*—云日志允许您存储、搜索、分析、监控和警报来自Google Cloud的日志数据和事件，而云监控提供了对云应用程序性能、正常运行时间和整体健康状况的可见性。迁移后，这两个服务仅通过配置更改即可使用。'
- en: '*Unified policy and integrated resource management*—Anthos offers a declarative
    desired-state management via Anthos Config Management, which is covered in chapter
    11\. *Declarative* means that the user defines only the desired end state, leaving
    Anthos the definition of optimized steps to implement the changes. Anthos Config
    Management allows you to automate and standardize security policies and best practices
    across all your environments with advanced tagging strategies and selector policies.
    As users, you will have a single UI for defining unified policy creation and enforcement
    (chapter 13).'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*统一策略和集成资源管理*—Anthos通过Anthos Config Management提供声明式期望状态管理，这在第11章中有详细说明。*声明式*意味着用户仅定义所需的最终状态，而Anthos负责定义实现更改的优化步骤。Anthos
    Config Management允许您通过高级标记策略和选择策略，在所有环境中自动化和标准化安全策略和最佳实践。作为用户，您将有一个单一的UI来定义统一策略的创建和执行（第13章）。'
- en: '*Cloud Build to implement Day 2 maintenance procedures*—Cloud Build offers
    control over defining custom workflows for building, testing, and deploying across
    multiple environments and multiple languages.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用Cloud Build实现第二天维护程序*—Cloud Build提供了定义跨多个环境和多种语言的构建、测试和部署的定制工作流的控制。'
- en: '*CI/CD pipelines*—Anthos integrates CI/CD pipelines for enhancing the agility
    of your environment. This allows you to have smaller code changes, faster turnaround
    on feature changes, shorter release cycles, and quicker fault isolation.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*CI/CD流水线*—Anthos集成了CI/CD流水线，以增强您环境的敏捷性。这使得您能够进行更小的代码更改，更快地完成功能更改，缩短发布周期，并更快地进行故障隔离。'
- en: '*GCP Marketplace*—Anthos is integrated within GCP Marketplace, including a
    Service Catalog for deploying new applications with a single click. This is covered
    in detail in chapter 14.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*GCP Marketplace*—Anthos集成在GCP Marketplace中，包括服务目录，可以一键部署新应用程序。这将在第14章中详细说明。'
- en: One of the most important benefits of M4A is that legacy applications are promoted
    to first-class objects with the same benefits in terms of Day 2 operations as
    those typically expected in a cloud native environment.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: M4A最重要的好处之一是，传统应用程序被提升为第一类对象，在第二天运营方面的好处与在云原生环境中通常期望的相同。
- en: In this section, we have discussed the benefits of using Migrate for Anthos
    to modernize VM workloads in place and containerize your application automatically
    with no need to rewrite it. As discussed, containerized applications increase
    agility and efficiency because they require less management time compared to VMs.
    In addition, they offer an increase of infrastructure density and a related reduction
    in cost. Finally, containerized applications can benefit from the service mesh
    in terms of observability, Day 2 operation streamlining, and uniform policy management
    and enforcement across environments.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论了使用Migrate for Anthos来现代化现有VM工作负载并自动容器化您的应用程序（无需重写）的好处。正如所讨论的，容器化应用程序由于比VM需要更少的管理时间，因此可以提高灵活性和效率。此外，它们提供了更高的基础设施密度和相关的成本降低。最后，容器化应用程序可以从服务网格中受益，包括可观察性、第二天运营流程简化以及跨环境的统一策略管理和执行。
- en: In the next section, we will take a deep dive into what workloads are best suited
    for migration.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将深入探讨哪些工作负载最适合迁移。
- en: 15.2 Recommended workloads for migration
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 15.2 推荐的迁移工作负载
- en: 'Modernizing applications for the cloud can be difficult. Complex apps are often
    multitiered and typically have multiple dependencies. Data has gravity, and migration
    might depend on large volumes of data, either in files or in databases. Legacy
    applications might have been written in outdated code with legacy frameworks,
    and in many situations, the code itself might not be available for recompiling
    in a modern environment. In this section, we discuss the following types of applications
    that are particularly suitable for automatic migration:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 将应用程序现代化以适应云可能很困难。复杂的应用程序通常是多层的，并且通常具有多个依赖项。数据具有重力，迁移可能依赖于大量数据，无论是文件还是数据库。遗留应用程序可能是在过时的代码和遗留框架中编写的，并且在许多情况下，代码本身可能无法在现代环境中重新编译。在本节中，我们讨论以下类型的应用程序，这些应用程序特别适合自动迁移：
- en: '*Stateless web frontend*—A suitable class consists of stateless applications
    such as web servers and similar applications serving customer traffic. Containers
    are generally more lightweight than virtual machines, and it is, consequently,
    easier to scale them up and down according to various load situations.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*无状态Web前端*—一个合适的类别包括无状态应用程序，如Web服务器和类似的应用程序，它们服务于客户流量。容器通常比虚拟机更轻量级，因此根据各种负载情况上下扩展它们更容易。'
- en: '*Multi-VM, multitier stacks, and business logic middleware*—In this class are
    multitier web service stacks such as LAMP (Linux, Apache, MySQL, PHP/Perl/Python)
    or WordPress, because they can be broken down into multiple independent containers.
    Also in this class are J2EE Middleware such as Java Tomcat and other COTS (commercial
    off-the-shelf) apps. In M4A jargon, we typically say that the sweet-spot application
    categories include multitier web-based enterprise applications.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*多虚拟机、多层堆栈和业务逻辑中间件*—在这个类别中包括多层Web服务堆栈，如LAMP（Linux、Apache、MySQL、PHP/Perl/Python）或WordPress，因为它们可以被分解成多个独立的容器。此外，还包括Java
    Tomcat和其他COTS（现成商业）应用程序。在M4A术语中，我们通常说，最佳应用类别包括多层Web企业应用程序。'
- en: '*Medium to large-sized databases*—Databases such as MySQL, Postgres, and Redis
    are supported; the data layer can be typically separated from the compute layer,
    and containers can, therefore, help to manage lightweight computation.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*中等至大型数据库*—支持如MySQL、Postgres和Redis等数据库；数据层通常可以与计算层分离，因此容器可以帮助管理轻量级计算。'
- en: '*Low duty cycle and bursty workloads*—Containers are the preferred solution
    in any situation where intermittent rises and decreases in compute activity occur
    because they are more lightweight than virtual machines. So, M4A should be considered
    any time we need to rapidly set up Dev/Test environments, training environments,
    or labs.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*低负载周期和突发工作负载*—在任何计算活动间歇性上升和下降的情况下，容器都是首选解决方案，因为它们比虚拟机更轻量级。因此，在需要快速设置Dev/Test环境、培训环境或实验室时，应考虑M4A。'
- en: 'Overall, we can say that *ideal migration candidates* include the following:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，我们可以这样说，*理想的迁移候选者*包括以下内容：
- en: Workloads where modernization through a complete rewrite is either impossible
    or too expensive
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过完整重写进行现代化改造要么不可能，要么成本过高的工作负载
- en: Workloads with unknown dependencies that could break something if touched
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有未知依赖项的工作负载，如果被触及可能会破坏某些内容
- en: Workloads that are maintained but not actively developed
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然得到维护但不是积极开发的工作负载
- en: Workloads that aren’t maintained anymore
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已不再维护的工作负载
- en: Workloads without source code access
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有源代码访问的工作负载
- en: Sometimes it might be difficult to have automatic migration. This is true if
    dependencies exist on specific kernel drivers or specific hardware, or if software
    licenses need to be tied to certain hardware or virtual machines. Another relevant
    case is VM-based workloads that require the whole Kubernetes node capacity, including
    high-performance and high-memory databases (such as SAP HANA). Except for these
    specific cases, all the other workloads should be considered for a migration from
    VMs to containers.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 有时可能很难实现自动迁移。如果存在对特定内核驱动程序或特定硬件的依赖，或者如果软件许可证需要绑定到某些硬件或虚拟机，则情况如此。另一个相关的情况是，基于虚拟机的工作负载需要整个Kubernetes节点容量，包括高性能和高内存数据库（如SAP
    HANA）。除了这些特定情况外，所有其他工作负载都应考虑从虚拟机迁移到容器。
- en: In this section, we have rapidly reviewed relevant workloads suitable for migration.
    In the next few paragraphs, we will discuss the migration architecture and some
    real examples of migration.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们快速回顾了适合迁移的相关工作负载。在接下来的几段中，我们将讨论迁移架构和一些迁移的实例。
- en: 15.3 M4A architecture
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 15.3 M4A 架构
- en: In this section, we will discuss a typical migration workflow and how a virtual
    machine is transformed into several different containers. Once the migration is
    finished, the generated artifacts can run anywhere. In the case of failure, tools
    report detailed motivations for debugging and inspection.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论一个典型的迁移工作流程以及虚拟机如何转换为几个不同的容器。迁移完成后，生成的工件可以在任何地方运行。在出现故障的情况下，工具会报告详细的调试和检查动机。
- en: Note You no longer need to install the migration components on target clusters.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：您不再需要在目标集群上安装迁移组件。
- en: 15.3.1 Migration workflow
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.3.1 迁移工作流程
- en: 'Migration consists of three phases: the setup, actual migration, and optimization
    (see figure 15.1). Let’s take a closer look at each step.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移包括三个阶段：设置、实际迁移和优化（见图 15.1）。让我们更详细地看看每个步骤。
- en: '![15-01](../../OEBPS/Images/15-01.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![15-01](../../OEBPS/Images/15-01.png)'
- en: Figure 15.1 Setup and Migrate for Anthos
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.1 Anthos 的设置和迁移
- en: During the setup phase, a processing cluster is created, and the migration sources
    are defined. Among the supported migration sources we have VMware, AWS EC2, Azure
    VM, GCE VM, bare metal, and local VMware. As of version 1.9 of Anthos Migrate,
    the operating systems supported for migrations are RHEL, CentOS, SUSE, Ubuntu,
    Debian, and Windows. The list is always expanding, however, and it is good to
    check online for the latest list (see [http://mng.bz/51Gz](http://mng.bz/51Gz)).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置阶段，会创建一个处理集群，并定义迁移源。在支持的迁移源中，包括 VMware、AWS EC2、Azure VM、GCE VM、裸金属和本地 VMware。截至
    Anthos Migrate 1.9 版本，支持的迁移操作系统有 RHEL、CentOS、SUSE、Ubuntu、Debian 和 Windows。列表始终在扩展，因此建议在线查看最新列表（见
    [http://mng.bz/51Gz](http://mng.bz/51Gz)）。
- en: During the setup phase, we need to set up the cloud landing zone, considering
    identity, network configuration, security, and billing. Several tools can help
    make an infrastructure as code task more automatic, including Cloud Foundation
    Toolkit ([https://cloud.google.com/foundation-toolkit](https://cloud.google.com/foundation-toolkit))
    and Terraform ([https://www.terraform.io/](https://www.terraform.io/)). These
    templates can be used off the shelf to rapidly build a repeatable, enterprise-ready
    foundation, depending on your specific needs. Furthermore, during setup, you need
    to discover the workloads that you want to migrate. The desired workloads can
    be identified either manually or via discovery tools such as StratoZone ([https://www.stratozone.com/](https://www.stratozone.com/);
    now acquired by Google), modelizeIT ([https://www.modelizeit.com/](https://www.modelizeit.com/)),
    Cloudamize ([https://www.cloudamize.com/en/home/](https://www.cloudamize.com/en/home/)),
    or CloudPhysics ([https://www.cloudphysics.com/](https://www.cloudphysics.com/)).
    Since version 1.5 of M4A, native discovery tools are included, which will be covered
    in the next section.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置阶段，我们需要设置云着陆区，考虑到身份、网络配置、安全和计费。一些工具可以帮助使基础设施即代码任务更加自动化，包括 Cloud Foundation
    Toolkit ([https://cloud.google.com/foundation-toolkit](https://cloud.google.com/foundation-toolkit))
    和 Terraform ([https://www.terraform.io/](https://www.terraform.io/))。这些模板可以直接使用，以快速构建一个可重复、企业级的基础设施，具体取决于您的特定需求。此外，在设置过程中，您需要发现您想要迁移的工作负载。期望的工作负载可以通过手动方式或通过发现工具如
    StratoZone ([https://www.stratozone.com/](https://www.stratozone.com/); 现已被 Google
    收购)、modelizeIT ([https://www.modelizeit.com/](https://www.modelizeit.com/))、Cloudamize
    ([https://www.cloudamize.com/en/home/](https://www.cloudamize.com/en/home/)) 或
    CloudPhysics ([https://www.cloudphysics.com/](https://www.cloudphysics.com/))
    来识别。自 M4A 1.5 版本以来，已包含原生发现工具，将在下一节中介绍。
- en: During the migration phase, M4A is run and new container images are automatically
    generated, together with a Dockerfile, data volumes, and new YAML files for deployment.
    We will see the details in the next sections, where we will cover both the command-line
    interface (CLI) and graphical user interface (GUI) processes. Once these artifacts
    are automatically generated, you can test them on GKE/Anthos or in another cloud,
    and if everything looks good, you can deploy them to GKE/Anthos. It’s also important
    to note that data is automatically moved and synchronized as part of the migration
    process.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在迁移阶段，运行 M4A 并自动生成新的容器镜像，包括 Dockerfile、数据卷和新的 YAML 部署文件。我们将在下一节中看到这些细节，其中我们将涵盖命令行界面（CLI）和图形用户界面（GUI）过程。一旦这些工件自动生成，您就可以在
    GKE/Anthos 或其他云中进行测试，如果一切看起来都很好，您可以将它们部署到 GKE/Anthos。值得注意的是，数据作为迁移过程的一部分自动移动和同步。
- en: Anthos supports live migrations, which means that applications can be migrated
    to modern environments without any interruptions. Behind the scenes, M4A creates
    a snapshot for the source VM, and this source VM is left running and operational
    with no need for downtime. In the meantime, all the storage operations are done
    on that snapshot of the VM. All workloads are directly migrated without requiring
    the original source code.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Anthos 支持实时迁移，这意味着应用程序可以在没有任何中断的情况下迁移到现代环境。在幕后，M4A 为源虚拟机创建了一个快照，并且这个源虚拟机被留下运行和操作，无需停机。与此同时，所有存储操作都在该虚拟机快照上进行。所有工作负载都直接迁移，无需原始源代码。
- en: During the optimization phase, deployed artifacts can be integrated with CI/CD
    platforms such as Cloud Build, GitHub, Jenkins ([https://www.jenkins.io/](https://www.jenkins.io/)),
    Spinnaker ([https://spinnaker.io/](https://spinnaker.io/)), GitLab CI/CD ([https://docs.gitlab.com/ee/ci/](https://docs.gitlab.com/ee/ci/)),
    and others according to your specific preferences (see chapter 12).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在优化阶段，部署的艺术品可以根据您的特定偏好与 CI/CD 平台集成，例如 Cloud Build、GitHub、Jenkins ([https://www.jenkins.io/](https://www.jenkins.io/))、Spinnaker
    ([https://spinnaker.io/](https://spinnaker.io/))、GitLab CI/CD ([https://docs.gitlab.com/ee/ci/](https://docs.gitlab.com/ee/ci/))
    等（参见第 12 章）。
- en: 15.3.2 From virtual machines to containers
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.3.2 从虚拟机到容器
- en: A typical VM consists of multiple layers (see figure 15.2, left side). At the
    top are the applications run by users, together with cron jobs, config files,
    and user data. Just below are multiple services, including services running in
    the user space and SysV or Systemd[⁶](#pgfId-1080838) service. Then, a logging
    and monitoring layer sits on the top of the OS kernel and OS drivers. At the very
    bottom is the virtual hardware, including networking, storage with logical volumes
    on various filesystems, CPUs, and memory.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的虚拟机由多个层组成（参见图 15.2 左侧）。在最上面是用户运行的应用程序，以及 cron 作业、配置文件和用户数据。紧接着是多个服务，包括在用户空间运行的服务和
    SysV 或 Systemd[⁶](#pgfId-1080838) 服务。然后，一个日志和监控层位于操作系统内核和操作系统驱动程序之上。在最底层是虚拟硬件，包括网络、具有各种文件系统上的逻辑卷的存储、CPU
    和内存。
- en: '![15-02](../../OEBPS/Images/15-02.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![15-02](../../OEBPS/Images/15-02.png)'
- en: 'Figure 15.2 Anthos Migrate: From virtual machines to containers'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.2 Anthos Migrate：从虚拟机到容器
- en: 'For each application, M4A produces CI/CD artifacts in the form of a Docker
    Image, a Dockerfile, and deployment YAML files, including the applications, the
    user services, and the persistent volumes (see figure 15.2, right side). In particular,
    storage is refactored into a Kubernetes-supported persistent volume. Common functions
    such as networking, logging and monitoring, and OS kernel and drivers are abstracted
    away and delegated to Kubernetes management. A persistent volume is mounted using
    the Migrate for Anthos Container Storage Interface (CSI) driver (see appendix
    D). Then data is streamed directly from the source VM filesystem. Internally,
    Migrate also takes care of generating command-line input and Customer Resource
    Definitions (CRD[⁷](#pgfId-1080848)). Logically, the migration produces two layers
    in the containerized image: the first layer is the captured user-mode system,
    whereas the second layer is the runtime environment for migration, together with
    all the necessary CRDs. However, after migration, you don’t need to maintain the
    second layer and the generated artifacts can run on any Kubernetes-conformant
    distribution.[⁸](#pgfId-1080853)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个应用程序，M4A 以 Docker 镜像、Dockerfile 和部署 YAML 文件的形式生成 CI/CD 艺术品，包括应用程序、用户服务和持久卷（参见图
    15.2 右侧）。特别是，存储被重构为 Kubernetes 支持的持久卷。常见的功能，如网络、日志和监控，以及操作系统内核和驱动程序都被抽象化并委托给 Kubernetes
    管理。持久卷是通过 Migrate for Anthos 容器存储接口（CSI）驱动程序挂载的（参见附录 D）。然后数据直接从源虚拟机文件系统流式传输。内部，Migrate
    还负责生成命令行输入和客户资源定义（CRD[⁷](#pgfId-1080848)）。从逻辑上讲，迁移在容器化镜像中产生两层：第一层是捕获的用户模式系统，而第二层是迁移的运行环境，包括所有必要的
    CRDs。然而，迁移后，您不需要维护第二层，生成的艺术品可以在任何符合 Kubernetes 的发行版上运行。[⁸](#pgfId-1080853)
- en: VM-related files and components that are not essential for the application in
    the Kubernetes environment are explicitly left out. In fact, this exclusion implies
    benefits. As discussed, containers allow higher density and cost reduction due
    to their lightweight nature when compared to virtual machines. The application
    life cycle stays within the system container. Once ported, applications can run
    on either any Anthos environment (on-prem, on GCP, etc.) or any Kubernetes-conformant
    distribution independently of M4A deployment.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 环境中对于应用程序非必要的 VM 相关文件和组件被明确排除。实际上，这种排除意味着好处。正如讨论的那样，与虚拟机相比，容器由于其轻量级特性，可以实现更高的密度和成本降低。应用程序生命周期保持在系统容器内。一旦迁移，应用程序可以在任何
    Anthos 环境中运行（本地、GCP 等），或者独立于 M4A 部署在符合 Kubernetes 标准的任何发行版上。
- en: 15.3.3 A look at the Windows environment
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.3.3 查看Windows环境
- en: Version 1.4+ of Migrate for Anthos supports the migration of workloads from
    Windows servers to GKE/Windows. Like Linux environments, the goal is to automate
    the replatforming of the workload and then integrate it with a more modern cloud
    environment. At the end of 2021, all the Windows server platforms from Windows
    Server 2008r2 to Windows Server 2019 are available as targets. Currently, only
    GCE is supported as a source for Windows applications modernization, with direct
    support for on-prem VMware, AWS, and Azure planned for the next version. However,
    you can use Migrate for Compute Engine (sometime referred to as Migrate to Virtual
    Machines[⁹](#pgfId-1080866)) to migrate or clone a Windows VM from other sources
    into Compute Engine and then migrate the resulting VM into a container. The good
    news is that a migrated Windows VM does not have to be configured to run on Compute
    Engine.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: Migrate for Anthos 的 1.4+ 版本支持将工作负载从 Windows 服务器迁移到 GKE/Windows。与 Linux 环境一样，目标是自动化工作负载的重构，并将其集成到一个更现代的云环境中。到
    2021 年底，从 Windows Server 2008r2 到 Windows Server 2019 的所有 Windows 服务器平台都可作为目标。目前，仅支持
    GCE 作为 Windows 应用程序现代化的源，计划在下一个版本中直接支持本地 VMware、AWS 和 Azure。然而，您可以使用 Migrate for
    Compute Engine（有时称为 Migrate to Virtual Machines[⁹](#pgfId-1080866)）将来自其他源的 Windows
    VM 迁移或克隆到 Compute Engine，然后将生成的 VM 迁移到容器中。好消息是迁移后的 Windows VM 不必配置为在 Compute Engine
    上运行。
- en: Behind the scenes, the migration works by extracting the ASP.NET application
    and the IIS configuration and applying them on top of the official Windows 2019
    server image. M4A for Windows works well with applications developed with IIS
    7+, ASP.NET, especially with web and business logic middleware. Sweet spots for
    migration are stateless tiers of Windows web applications, application servers,
    and web frontends.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在幕后，迁移是通过提取 ASP.NET 应用程序和 IIS 配置，并将它们应用于官方 Windows 2019 服务器镜像上实现的。M4A for Windows
    与使用 IIS 7+、ASP.NET 开发的应用程序兼容良好，尤其是与 Web 和业务逻辑中间件。迁移的理想对象是无状态的 Windows Web 应用程序层、应用服务器和
    Web 前端。
- en: 15.3.4 A complete view of the modernization journey
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.3.4 现代化旅程的全面视图
- en: Now that we have discussed the modernization journey with both Linux and Windows
    workloads, we provide a comprehensive view, which also includes mainframes (see
    figure 15.3).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经讨论了 Linux 和 Windows 工作负载的现代化旅程，我们提供了一个全面的视图，这还包括大型机（见图 15.3）。
- en: '![15-03](../../OEBPS/Images/15-03.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![15-03](../../OEBPS/Images/15-03.png)'
- en: Figure 15.3 A complete modernization journey
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.3 完整的现代化旅程
- en: If the source application is a modern app, then it is containerized, integrated
    with CI/CD, and can run on Anthos where integration with the whole ecosystem can
    facilitate further refactoring into a microservice environment. If the source
    application is a traditional monolithic application in either Linux or Windows,
    then we can use M4A to containerize it.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如果源应用程序是现代应用程序，则它会被容器化，集成 CI/CD，并可以在 Anthos 上运行，与整个生态系统的集成可以促进进一步重构为微服务环境。如果源应用程序是
    Linux 或 Windows 上的传统单体应用程序，则我们可以使用 M4A 来容器化它。
- en: If the source application is a Linux/Window application with particular needs
    either for specific drivers or legacy support, then it is still possible to directly
    migrate the VM to GCP either in bare metal (BMS; [https://cloud.google.com/bare-metal](https://cloud.google.com/bare-metal))
    or in GCVE (Google Cloud VMware Engine; [https://cloud.google.com/vmware-engine](https://cloud.google.com/vmware-engine))
    and manually refactor the application into microservices later.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如果源应用程序是具有特定需求的Linux/Windows应用程序，无论是特定驱动程序还是遗留支持，那么仍然可以直接将虚拟机迁移到GCP，无论是在裸金属（BMS；[https://cloud.google.com/bare-metal](https://cloud.google.com/bare-metal)）还是在GCVE（Google
    Cloud VMware Engine；[https://cloud.google.com/vmware-engine](https://cloud.google.com/vmware-engine)），之后手动将应用程序重构为微服务。
- en: 15.4 Real-world scenarios
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 15.4 现实场景
- en: In this section, we will review real examples of migration with M4A. First,
    we’ll introduce the migration fit assessment tool ([http://mng.bz/v1VM](http://mng.bz/v1VM)).
    Then, we’ll provide a hands-on session on how to migrate for both Linux and Windows.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将回顾使用M4A的迁移实例。首先，我们将介绍迁移匹配评估工具([http://mng.bz/v1VM](http://mng.bz/v1VM))。然后，我们将提供关于如何迁移Linux和Windows的实战演练。
- en: 15.4.1 Using the fit assessment tool
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.4.1 使用匹配评估工具
- en: In this section, we present a self-service fit assessment tool used to determine
    the workload’s suitability for migration to a container. The tool consists of
    a utility called mfit, a standalone Linux CLI tool used to drive the assessment
    process along with dedicated Linux and Windows data-collection scripts that are
    invoked either automatically by mfit or manually, depending on the scenario.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了一个自助匹配评估工具，用于确定工作负载迁移到容器的适用性。该工具包括一个名为mfit的实用程序，这是一个独立的Linux CLI工具，用于驱动评估过程，以及专用的Linux和Windows数据收集脚本，这些脚本可以由mfit自动调用或根据场景手动调用。
- en: The fit assessment tool generates a report presenting pre-VM assessment results
    including both a score for the VM’s suitability for migration to a container and
    recommendations on resolving various obstacles. Table 15.1 provides a summary
    of possible fit scores.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 匹配评估工具生成一份报告，展示预虚拟机评估结果，包括虚拟机迁移到容器的适用性分数以及解决各种障碍的建议。表15.1提供了可能的匹配分数的摘要。
- en: Table 15.1 Fit scores produced by the fit assessment tool
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 表15.1 匹配评估工具生成的匹配分数
- en: '| Fit score | Description |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 匹配分数 | 描述 |'
- en: '| Score 0 | Excellent fit |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 分数 0 | 优秀匹配 |'
- en: '| Score 1 | Good fit with some findings that might require attention |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 分数 1 | 匹配良好，但有一些可能需要关注的发现 |'
- en: '| Score 2 | Requires minimal effort before migrating |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 分数 2 | 迁移前需要最小努力 |'
- en: '| Score 3 | Requires moderate effort before migrating |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 分数 3 | 迁移前需要适度努力 |'
- en: '| Score 4 | Requires major effort before migrating |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 分数 4 | 迁移前需要大量努力 |'
- en: '| Score 5 | No fit |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 分数 5 | 不匹配 |'
- en: '| Score 6 | Insufficient data collected to assess the VM |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 分数 6 | 收集的数据不足以评估虚拟机 |'
- en: Fit assessment process
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 匹配评估过程
- en: 'The fit assessment process consists of three distinct phases: discovery, assessment,
    and reporting. Each of the phases is detailed next:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 匹配评估过程包括三个不同的阶段：发现、评估和报告。接下来将详细介绍每个阶段：
- en: '*Discovery*—Gather data about the VMs and store it in a local lightweight database
    for use in the next phases (located in the ~/.mfit folder by default). The two
    types of data discovery methods follow:'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*发现*—收集有关虚拟机数据并将其存储在本地轻量级数据库中，用于下一阶段（默认位于~/.mfit文件夹）。以下两种数据发现方法：'
- en: (Optional) *VM/inventory-level discovery*—Use the mfit tool to pull inventory
    and configuration about VMs in one or more vCenters using the vSphere API. Future
    versions of the fit assessment tool will support pulling inventory from public
    clouds such as GCP, AWS, and Azure. This method is optional, and fit assessment
    can be performed without it, albeit somewhat less thoroughly.
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: （可选）*虚拟机/库存级别发现*—使用mfit工具通过vSphere API从一个或多个vCenters拉取虚拟机的库存和配置信息。fit评估工具的后续版本将支持从公共云（如GCP、AWS和Azure）拉取库存。此方法为可选，即使没有它，也可以执行匹配评估，尽管可能不够彻底。
- en: '*Guest-level data collection*—Consists of running a data-collection script
    inside the VM to be assessed. The fit assessment tool provides a Bash script for
    Linux VMs and a PowerShell script for Windows VMs. Each script gathers data about
    the OS configuration and about running services, processes, installed packages,
    and so on and produces a single archive file to be imported into the database
    by the mfit *t*ool and used later in the assessment phase. The process of running
    the collection script and importing the data can be either manual or automated,
    using the mfit *tool in the following scenarios:*'
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*虚拟机级别数据收集*—包括在要评估的虚拟机内部运行数据收集脚本。fit 评估工具为 Linux 虚拟机提供 Bash 脚本，为 Windows 虚拟机提供
    PowerShell 脚本。每个脚本都会收集有关操作系统配置以及正在运行的服务、进程、已安装的软件包等信息，并生成一个单独的存档文件，该文件将被 mfit
    *工具导入数据库，并在后续的评估阶段使用。运行收集脚本和导入数据的过程可以是手动或自动的，以下场景中使用 mfit *工具：*'
- en: '*Linux only*—Run collection script and collect results via SSH.'
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*仅限 Linux*—运行收集脚本并通过 SSH 收集结果。'
- en: '*Linux and Windows on vSphere*—Run collection script and collect results using
    the vSphere API.'
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*vSphere 上的 Linux 和 Windows*—运行收集脚本并使用 vSphere API 收集结果。'
- en: '*Assessment*—Use the mfit tool to analyze the collected data and apply a set
    of fit assessment rules[^(10)](#pgfId-1080954) for each VM assessed.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*评估*—使用 mfit 工具分析收集的数据，并为每个评估的虚拟机应用一套 fit 评估规则[^(10)](#pgfId-1080954)。'
- en: '*Reporting*—Use the mfit tool to produce a report to present the assessment
    outcomes in either CSV, HTML, or JSON format. The latter can then be displayed
    in Google’s cloud console ([http://mng.bz/ydVq](http://mng.bz/ydVq)).'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*报告*—使用 mfit 工具生成报告，以 CSV、HTML 或 JSON 格式呈现评估结果。然后可以在 Google 的云控制台（[http://mng.bz/ydVq](http://mng.bz/ydVq)）中显示。'
- en: Now that you know how the tool will discover and report the workloads, we can
    move on to how to use the tool so you can start your migration journey.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经知道了工具如何发现和报告工作负载，我们可以继续介绍如何使用该工具，以便你可以开始你的迁移之旅。
- en: Basic tool usage instructions
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 基本工具使用说明
- en: A basic overview for using the fit assessment tool follows. Full documentation
    is available at [http://mng.bz/41YV](http://mng.bz/41YV).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是使用 fit 评估工具的基本概述。完整文档可在 [http://mng.bz/41YV](http://mng.bz/41YV) 查找。
- en: Note that appending --help to each mfit command will show detailed command usage,
    including all possible flags and subcommands.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，将 --help 添加到每个 mfit 命令将显示详细的命令使用说明，包括所有可能的标志和子命令。
- en: Installation
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 安装
- en: 'At the time of writing, you can download the mfit tool (version 1.9) on your
    workstation used for driving the fit assessment with the following commands:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，你可以使用以下命令在你的工作站上下载 mfit 工具（版本 1.9），该工作站用于驱动 fit 评估：
- en: '[PRE0]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Inventory discovery
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 库存发现
- en: 'Run the following command to perform discovery of all VMs in a vCenter:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 运行以下命令以在 vCenter 中发现所有虚拟机：
- en: '[PRE1]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note If your Virtual Center is using a certificate that is not trusted by the
    machine you are running mfit on, you can add the -i option to ignore SSL errors.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：如果你的虚拟中心正在使用一个在运行 mfit 的机器上不受信任的证书，你可以添加 -i 选项来忽略 SSL 错误。
- en: 'You will be prompted to enter the vCenter password, and once executed, you
    will see a summary of the discovery process:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 你将被提示输入 vCenter 密码，一旦执行，你将看到发现过程的摘要：
- en: '[PRE2]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You may be wondering what actually happened because the output is limited from
    the discovery process, telling you only that the prechecks have passed and the
    tool discovered 27 virtual machines. This is just the initial collection step,
    and once everything is collected, you can assess and create a report of the VMs
    using the mfit tool, which we will cover after the manual collection process is
    explained.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想知道实际上发生了什么，因为发现过程的输出有限，只告诉你预检查已通过，工具发现了 27 个虚拟机。这只是初始收集步骤，一旦收集完毕，你可以使用 mfit
    工具评估和创建虚拟机的报告，我们将在手动收集过程解释之后介绍。
- en: Manual guest-level data collection
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 手动虚拟机级别数据收集
- en: 'At the time of writing, you can download the Linux collection script on the
    VM that you want to evaluate for migration using these commands:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，你可以使用以下命令在要评估迁移的虚拟机上下载 Linux 收集脚本：
- en: '[PRE3]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Run the collection script like this:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下方式运行收集脚本：
- en: '[PRE4]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The script will generate a TAR file named m4a-collect-<MACHINE NAME>-<TIMESTAMP>.tar
    in the current directory.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本将在当前目录下生成一个名为 m4a-collect-<MACHINE NAME>-<TIMESTAMP>.tar 的 TAR 文件。
- en: 'For Windows users, at the time of writing, you can download the Windows collection
    script on the VM that you want to evaluate for migration from the following URL:
    [http://mng.bz/X5E6](http://mng.bz/X5E6).'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Windows用户，在撰写本文时，您可以从以下URL下载要评估迁移的虚拟机上的Windows收集脚本：[http://mng.bz/X5E6](http://mng.bz/X5E6)。
- en: 'Run the collection script as follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下方式运行收集脚本：
- en: '[PRE5]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The script will generate a TAR or ZIP file (depending on OS version) named m4a-collect-<MACHINE
    NAME>-<TIMESTAMP>.tar/zip in the current directory.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本将在当前目录中生成一个名为m4a-collect-<MACHINE NAME>-<TIMESTAMP>.tar/zip的TAR或ZIP文件（取决于操作系统版本）。
- en: Import the collected data file
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 导入收集的数据文件
- en: 'After running the collection script on the assessed VM, download it to the
    workstation where mfit was installed by any means. Then, import it into mfit’s
    local database:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估虚拟机上运行收集脚本后，通过任何方式将其下载到安装了mfit的工作站。然后，将其导入到mfit的本地数据库中：
- en: '[PRE6]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Automatic guest-level data collection
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 自动客户端级别数据收集
- en: mfit contains the guest-collection script embedded in it and can automatically
    run it and retrieve the results in the following scenarios.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: mfit包含嵌入的客户端收集脚本，可以在以下场景中自动运行它并检索结果。
- en: VMware tools
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: VMware工具
- en: 'If the assessed VM is running on vSphere and has VMware tools installed, mfit
    can use vSphere APIs to automate the execution of the collection script (the one
    suited for the VM’s OS type) and the retrieval of the results. To run guest-level
    collection via VMware tools, run the following command:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 如果评估的虚拟机运行在vSphere上并且已安装VMware工具，mfit可以使用vSphere API来自动执行收集脚本（适用于虚拟机操作系统类型的脚本）和检索结果。要通过VMware工具运行客户端级别收集，请运行以下命令：
- en: '[PRE7]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: You will be prompted to enter both the vCenter and VM/OS passwords.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 您将被提示输入vCenter和VM/OS密码。
- en: SSH
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: SSH
- en: 'If the Linux machine running mfit has SSH access to the assessed VM, mfit can
    use that to automate the execution of the collection script and the retrieval
    of the results. To run guest-level collection via SSH using the SSH key of the
    current local user (located in ~/.ssh), run the following command:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 如果运行mfit的Linux机器可以访问评估的虚拟机SSH，mfit可以使用它来自动执行收集脚本和检索结果。要使用当前本地用户的SSH密钥（位于 ~/.ssh）通过SSH运行客户端级别收集，请运行以下命令：
- en: '[PRE8]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To run guest-level collection via SSH with additional authentication options,
    run the following command:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用附加的身份验证选项通过SSH运行客户端级别收集，请运行以下命令：
- en: '[PRE9]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: For additional options for running guest-level collection via SSH, consult the
    official documentation or run ./mfit discover ssh -help.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 若要获取通过SSH运行客户端级别收集的附加选项，请参阅官方文档或运行 ./mfit discover ssh -help。
- en: Assessment
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 评估
- en: 'To examine the discovered VMs and collected data, run the following command:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查发现的虚拟机和收集的数据，请运行以下命令：
- en: '[PRE10]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'To perform assessment on this data, run the following command:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 要对此数据进行评估，请运行以下命令：
- en: '[PRE11]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This will create an assessment result and store it in mfit’s local database
    for use when generating reports.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个评估结果并将其存储在mfit的本地数据库中，以便在生成报告时使用。
- en: Report generation
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 报告生成
- en: 'Once assessment has been performed, we are ready to generate a report. To generate
    a standalone HTML report, run the following command:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成评估，我们就可以生成报告。要生成独立的HTML报告，请运行以下命令：
- en: '[PRE12]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'To generate a JSON report, run the following command:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 要生成JSON报告，请运行以下命令：
- en: '[PRE13]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The report can then be displayed on Google’s cloud console: [http://mng.bz/Q8zj](http://mng.bz/Q8zj).'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，可以在Google云控制台中显示报告：[http://mng.bz/Q8zj](http://mng.bz/Q8zj)。
- en: In this section, we discussed the fit assessment tool used to determine a workload’s
    suitability for migration to a container. Once the assessment is made and the
    workloads suitable for migration are chosen, we can start the migration process
    itself. That’s the topic of the next section.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论了用于确定工作负载是否适合迁移到容器的fit评估工具。一旦完成评估并选择了适合迁移的工作负载，我们就可以开始迁移过程本身。这就是下一节的主题。
- en: 15.4.2 Basic migration example
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.4.2 基本迁移示例
- en: In this basic example, we will use the CLI to set up a Compute Engine virtual
    machine on GCE and then use M4A to migrate the VM to a GKE cluster. Note that
    we need to create another Kubernetes “processing cluster” used with the intent
    of driving the migration process itself. The processing cluster will do the work
    of pulling the application from the VM and generating all the artifacts as containers.
    Let’s start.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个基本示例中，我们将使用命令行界面（CLI）在GCE上设置一个Compute Engine虚拟机，然后使用M4A将其迁移到GKE集群。请注意，我们需要创建另一个用于驱动迁移过程的Kubernetes“处理集群”。处理集群将负责从虚拟机中拉取应用程序并生成所有容器化的工件。让我们开始吧。
- en: 'First, we create a source VM. In this basic example, the VM will host an Apache
    web server. The VM can be created with the following command:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建一个源虚拟机。在这个基本示例中，虚拟机将托管 Apache 网络服务器。可以使用以下命令创建虚拟机：
- en: '[PRE14]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Then, let’s make sure that the VM is accessible from internet with the next
    command:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，让我们确保使用以下命令从互联网上可以访问虚拟机：
- en: '[PRE15]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now we can now log in to the VM just configured using the GUI (see figure 15.4)
    and install Apache:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用 GUI（见图 15.4）登录到刚刚配置的虚拟机并安装 Apache：
- en: '[PRE16]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![15-04](../../OEBPS/Images/15-04.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![15-04](../../OEBPS/Images/15-04.png)'
- en: Figure 15.4 Connecting the migration cluster
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.4 连接迁移集群
- en: 'Now we have a source virtual machine with an Apache web server running. The
    next step is to create the Kubernetes processing cluster:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个运行 Apache 网络服务器的源虚拟机。下一步是创建 Kubernetes 处理集群：
- en: '[PRE17]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Next, let’s make sure that we give the processing cluster the correct processing
    rights. We need to create a specific service account for M4A, add a policy binding
    with storage.admin rights, create a JSON key to access the processing cluster,
    and get the credentials for the processing cluster. We can do this with the following
    four commands. Note that named-tome-295414 is the name of my project and you should
    change it to match yours:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们确保我们给处理集群正确的处理权限。我们需要为 M4A 创建一个特定的服务帐户，添加具有存储管理员权限的策略绑定，创建一个 JSON 密钥以访问处理集群，并获取处理集群的凭证。我们可以使用以下四个命令来完成此操作。请注意，named-tome-295414
    是我的项目名称，您应该将其更改为与您的匹配：
- en: '[PRE18]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Once we have the credentials, we can log in to the processing cluster and install
    M4A. Let’s do that with the following command. Note that m4a-install.json is the
    JSON key we have just created:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了凭证，我们就可以登录到处理集群并安装 M4A。让我们使用以下命令来完成此操作。请注意，m4a-install.json 是我们刚刚创建的 JSON
    密钥：
- en: '[PRE19]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We can use migctl to check whether the deployment is successful:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 migctl 检查部署是否成功：
- en: '[PRE20]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'After that, we can set up the source for migration, together with a specific
    service account, m4a-ce-src, the compute.viewer and compute.storageAdmin policy
    bindings required during the migration process, and the creation of a JSON key
    m4a-ce-src.json:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们可以设置迁移源，包括特定的服务帐户 m4a-ce-src，迁移过程中所需的 compute.viewer 和 compute.storageAdmin
    策略绑定，以及创建 JSON 密钥 m4a-ce-src.json：
- en: '[PRE21]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Once we have created the credentials for the source, we can proceed to set
    up the source with the following command. Note that ce stands for Google Compute
    Engine (GCE):'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们为源创建了凭证，我们可以使用以下命令来设置源。请注意，ce 代表 Google Compute Engine (GCE)：
- en: '[PRE22]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'After creating a migration source, we can now create a migration plan to containerize
    our VM:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建迁移源之后，我们现在可以创建一个迁移计划来容器化我们的虚拟机：
- en: '[PRE23]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'If you want to look at the migration plan (e.g., to modify it), you can use
    the following command:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想查看迁移计划（例如，修改它），可以使用以下命令：
- en: '[PRE24]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'You can then start the actual migration:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您就可以开始实际的迁移了：
- en: '[PRE25]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'As result, you should see something like this:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 结果，您应该看到如下内容：
- en: '[PRE26]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Once the migration starts, you can check the progress with the following command.
    Note that the flag -v gives a verbose dump of the status, which is useful if something
    goes wrong:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦迁移开始，您可以使用以下命令检查进度。请注意，标志 -v 会提供详细的输出状态，这在出现问题时很有用：
- en: '[PRE27]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'When the migration is concluded, you will see something similar to the output
    shown here:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移完成后，您将看到类似于此处所示输出的内容：
- en: '[PRE28]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The next step is to get the generated artifacts:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是获取生成的工件：
- en: '[PRE29]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Once the generation has completed, you should see something like this:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦生成完成，您应该看到如下内容：
- en: '[PRE30]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'To access the migrated workload, we need to expose the Pods using a Service.
    Modifying the generated deployment_spec.yaml to add a Service of type LoadBalancer
    will enable us to reach the workload on port 80:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问迁移的工作负载，我们需要使用服务暴露 Pods。修改生成的 deployment_spec.yaml 以添加一个类型为 LoadBalancer
    的服务将使我们能够通过端口 80 访问工作负载：
- en: '[PRE31]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We can now deploy the artifacts on our Kubernetes cluster like this:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以像这样在我们的 Kubernetes 集群上部署工件：
- en: '[PRE32]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'It might be useful to check that everything went well:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 检查一切是否顺利可能是有用的：
- en: '[PRE33]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'As a result, you should see something like this:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 结果，您应该看到如下内容：
- en: '[PRE34]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: In this case, the external IP address is 35.232.24.49\. Now we can open a browser
    and check that everything is OK (see figure 15.5).
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，外部 IP 地址是 35.232.24.49。现在我们可以打开浏览器并检查一切是否正常（见图 15.5）。
- en: '![15-05](../../OEBPS/Images/15-05.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![15-05](../../OEBPS/Images/15-05.png)'
- en: Figure 15.5 Accessing the web server migrated from VM to containers
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.5 访问从虚拟机迁移到容器的网络服务器
- en: 'Congratulations! You have successfully migrated a virtual machine running on
    GCE into a container running on GKE using the CLI. If you want to see another
    example of basic migration, we suggest you consider the hands-on lab, “Migrate
    to Containers: Qwik Start,” available at [http://mng.bz/X5jp](http://mng.bz/X5jp).'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！您已成功使用CLI将运行在GCE上的虚拟机迁移到运行在GKE上的容器。如果您想看到另一个基本迁移的示例，我们建议您考虑在[http://mng.bz/X5jp](http://mng.bz/X5jp)提供的“迁移到容器：快速入门”动手实验室。
- en: Now that you know how to execute a migration using the CLI, we will move on
    to the next section where we will use the Cloud console UI to perform a migration.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经知道如何使用CLI执行迁移，我们将进入下一节，我们将使用Cloud console UI来执行迁移。
- en: 15.4.3 Google Cloud console UI migration example
  id: totrans-235
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.4.3 Google Cloud控制台UI迁移示例
- en: In this section, we use M4A to migrate an application running as a virtual machine
    on Google Compute Engine to GKE. When using the console UI, Google Cloud clusters
    are the only supported environment, not Anthos on AWS or VMware. The GKE processing
    clusters can be in the cloud or on-prem. The migration will be run through the
    graphical user interface (GUI) available via the Google Cloud console. Note that
    the migration process is consistent between the CLI and the GUI.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们使用M4A将运行在Google Compute Engine上的虚拟机中的应用程序迁移到GKE。当使用控制台UI时，Google Cloud集群是唯一支持的环境，不是AWS或VMware上的Anthos。GKE处理集群可以在云中或本地。迁移将通过Google
    Cloud控制台的可用图形用户界面（GUI）运行。请注意，迁移过程在CLI和GUI之间是一致的。
- en: A GKE cluster will be used as a “processing cluster” to control the migration.
    The artifacts generated during the process will be stored on Google Cloud Storage
    (GCS), and the final container images are pushed to Google Container Registry.
    Under the hood, this is identical to the CLI-driven migration.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 将使用GKE集群作为“处理集群”来控制迁移。在迁移过程中生成的工件将存储在Google Cloud Storage（GCS）上，最终的容器镜像将推送到Google
    Container Registry。在底层，这与CLI驱动的迁移相同。
- en: The first step is to access Anthos Migrate from the console (see figure 15.6)
    at [http://mng.bz/Mlpn](http://mng.bz/Mlpn).
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是访问控制台中的Anthos迁移（见图15.6），网址为[http://mng.bz/Mlpn](http://mng.bz/Mlpn)。
- en: '![15-06](../../OEBPS/Images/15-06.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![15-06](../../OEBPS/Images/15-06.png)'
- en: Figure 15.6 Accessing Anthos Migrate to containers
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.6 访问Anthos迁移到容器
- en: For the sake of simplicity, we will deploy a VM from Marketplace with a Tomcat
    server preinstalled. Then, we will migrate Tomcat from the VM to a container.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化，我们将从Marketplace部署一个预装Tomcat服务器的VM。然后，我们将从VM迁移Tomcat到容器。
- en: Let’s start by accessing the Google Click to Deploy repository with Tomcat (see
    figure 15.7). The URL is [https://console.cloud.google.com/marketplace/details/click-to-deploy-images/tomcat](https://console.cloud.google.com/marketplace/details/click-to-deploy-images/tomcat).
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从访问带有Tomcat的Google Click to Deploy仓库开始（见图15.7）。URL是[https://console.cloud.google.com/marketplace/details/click-to-deploy-images/tomcat](https://console.cloud.google.com/marketplace/details/click-to-deploy-images/tomcat)。
- en: '![15-07](../../OEBPS/Images/15-07.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![15-07](../../OEBPS/Images/15-07.png)'
- en: Figure 15.7 Deploying a Tomcat application to VMs
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.7 将Tomcat应用程序部署到虚拟机
- en: Then, let’s select the zone where we want to deploy (see figure 15.8).
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，让我们选择我们想要部署的区域（见图15.8）。
- en: '![15-08](../../OEBPS/Images/15-08.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![15-08](../../OEBPS/Images/15-08.png)'
- en: Figure 15.8 Deployed Tomcat application
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.8 部署的Tomcat应用程序
- en: Once the VM with the Tomcat server is deployed, you can access the website from
    an external IP, as shown in figure 15.9.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦部署了带有Tomcat服务器的VM，您可以从外部IP访问网站，如图15.9所示。
- en: '![15-09](../../OEBPS/Images/15-09.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![15-09](../../OEBPS/Images/15-09.png)'
- en: Figure 15.9 Tomcat solution deployed with Google Click to Deploy
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.9 使用Google Click to Deploy部署的Tomcat解决方案
- en: In this deployment, the IP address is http://35.238.48.196/, so if you access
    the website, you should see the output shown in figure 15.10.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在此部署中，IP地址是http://35.238.48.196/，因此如果您访问网站，您应该看到图15.10中显示的输出。
- en: '![15-10](../../OEBPS/Images/15-10.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![15-10](../../OEBPS/Images/15-10.png)'
- en: Figure 15.10 Accessing Tomcat with a web browser
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.10 使用网络浏览器访问Tomcat
- en: The next step is to start the proper migration process. First, create a “processing
    cluster,” a cluster that will be used to control the migration of our source VM.
    You can perform this task by accessing the Migrate to Containers menu on Anthos
    and selecting the Add Processing Cluster option (see figure 15.11).
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是启动适当的迁移过程。首先，创建一个“处理集群”，这是一个将用于控制我们源虚拟机迁移的集群。您可以通过访问Anthos上的“迁移到容器”菜单并选择添加处理集群选项来完成此任务（见图15.11）。
- en: '![15-11](../../OEBPS/Images/15-11.png)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![15-11](../../OEBPS/Images/15-11.png)'
- en: Figure 15.11 Starting the migration process
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.11 开始迁移过程
- en: It is convenient to follow the suggestion provided in the GUI and create a new
    cluster dedicated to processing (see figure 15.12).
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 按照GUI提供的建议创建一个专门用于处理的新集群是很方便的（见图15.12）。
- en: '![15-12](../../OEBPS/Images/15-12.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![15-12](../../OEBPS/Images/15-12.png)'
- en: Figure 15.12 Choosing a name for the processing cluster
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.12 为处理集群选择名称
- en: Once the cluster is ready, you should be able to see it via the Google Cloud
    console in the GKE section (see figure 15.13).
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦集群准备就绪，你应该能够在GKE部分中的Google Cloud控制台中看到它（见图15.13）。
- en: '![15-13](../../OEBPS/Images/15-13.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![15-13](../../OEBPS/Images/15-13.png)'
- en: Figure 15.13 The processing cluster is ready for use.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.13 处理集群已准备好使用。
- en: Then, you can select the cluster (see figure 15.14) and select whether the target
    is Linux or Windows.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以选择集群（见图15.14）并选择目标是否为Linux或Windows。
- en: '![15-14](../../OEBPS/Images/15-14.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![15-14](../../OEBPS/Images/15-14.png)'
- en: Figure 15.14 Selecting the processing cluster
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.14 选择处理集群
- en: At this point, we need to make sure that the processing cluster has the proper
    processing rights. To this extent, the GUI suggests running a number of commands
    in the cloud shell. You just need to click Run in Cloud Shell, as shown in figure
    15.15.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们需要确保处理集群具有适当的处理权限。为此，GUI建议在云壳中运行一系列命令。你只需像图15.15所示点击运行云壳即可。
- en: '![15-15](../../OEBPS/Images/15-15.png)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![15-15](../../OEBPS/Images/15-15.png)'
- en: Figure 15.15 Using the UI to run the setup required by M4A
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.15 使用UI运行M4A所需的设置
- en: Let’s see the required steps in detail. First, we need to enable the Google
    Cloud APIs. Then, we need to create a service account for storing the migration
    artifacts in the Container Registry and Cloud Storage. Then, we need to add the
    permissions to access the Container Registry and Cloud Storage. Finally, we need
    to create and export a new key to a file required by M4A to use the service account.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细看看所需的步骤。首先，我们需要启用Google Cloud API。然后，我们需要在容器注册库和云存储中创建一个服务帐户来存储迁移工件。然后，我们需要添加访问容器注册库和云存储的权限。最后，我们需要创建并导出一个新密钥到M4A使用服务帐户所需的文件。
- en: Once these steps are done, we can migrate to containers. Again, the GUI makes
    this step very intuitive. The last step is to check with migctl doctor that the
    deployment status is correct (see figure 15.16).
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些步骤后，我们可以迁移到容器。同样，GUI使这一步骤非常直观。最后一步是使用migctl doctor检查部署状态是否正确（见图15.16）。
- en: '![15-16](../../OEBPS/Images/15-16.png)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
  zh: '![15-16](../../OEBPS/Images/15-16.png)'
- en: Figure 15.16 Correct deployment of M4A
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.16 M4A的正确部署
- en: Once the processing cluster is configured, select a migration source from where
    the VM will be pulled (see figure 15.17).
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦配置了处理集群，请选择一个迁移源，从该源拉取虚拟机（见图15.17）。
- en: '![15-17](../../OEBPS/Images/15-17.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![15-17](../../OEBPS/Images/15-17.png)'
- en: Figure 15.17 Adding a migration source
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.17 添加迁移源
- en: Currently, you can pull from GCE (see figure 15.18). (You can also use Migrate
    for Compute Engine [[http://mng.bz/eJav](http://mng.bz/eJav)] to import local
    vSphere environments, AWS, and Azure to GCE.)
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，你可以从GCE拉取（见图15.18）。（你还可以使用Migrate for Compute Engine [[http://mng.bz/eJav](http://mng.bz/eJav)]将本地vSphere环境、AWS和Azure导入GCE。）
- en: '![15-18](../../OEBPS/Images/15-18.png)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![15-18](../../OEBPS/Images/15-18.png)'
- en: Figure 15.18 Adding a migration source
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.18 添加迁移源
- en: Once you have chosen a name, you can select the project in which the source
    VMs are placed (see figure 15.19).
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你选择了名称，你可以选择放置源虚拟机的项目（见图15.19）。
- en: '![15-19](../../OEBPS/Images/15-19.png)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![15-19](../../OEBPS/Images/15-19.png)'
- en: Figure 15.19 Selecting the project in which the source VMs are placed
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.19 选择放置源虚拟机的项目
- en: Now that the processing cluster and the migration source have been created,
    we can start the migration (see figure 15\. 20).
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 现在处理集群和迁移源已经创建，我们可以开始迁移（见图15.20）。
- en: '![15-20](../../OEBPS/Images/15-20.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![15-20](../../OEBPS/Images/15-20.png)'
- en: Figure 15.20 Starting a migration process
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.20 开始迁移过程
- en: The migration requires a name, a source, a VM OS type, the VM ID, and the migration
    intent. Let’s specify these via the GUI, as shown in figure 15.21.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移需要一个名称、一个源、一个虚拟机操作系统类型、虚拟机ID和迁移意图。让我们通过GUI指定这些，如图15.21所示。
- en: '![15-21](../../OEBPS/Images/15-21.png)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![15-21](../../OEBPS/Images/15-21.png)'
- en: Figure 15.21 Specifying the migration name, the migration source, the VM OS
    type, the VM ID, and the migration intent.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.21 指定迁移名称、迁移源、虚拟机操作系统类型、虚拟机ID和迁移意图。
- en: Then, M4A will start generating the migration plan (see figure 15.22).
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，M4A将开始生成迁移计划（见图15.22）。
- en: '![15-22](../../OEBPS/Images/15-22.png)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![15-22](../../OEBPS/Images/15-22.png)'
- en: Figure 15.22 Generating the migration plan
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.22 生成迁移计划
- en: 'During the migration, we can check the progress with the following command,
    which will produce a detailed debug log:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在迁移过程中，我们可以使用以下命令检查进度，该命令将生成详细的调试日志：
- en: '[PRE35]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Once the migration plan is generated (see figure 15.23), you can inspect the
    results with the GUI.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦生成迁移计划（见图15.23），您可以使用GUI检查结果。
- en: '![15-23](../../OEBPS/Images/15-23.png)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![15-23](../../OEBPS/Images/15-23.png)'
- en: Figure 15.23 An overview of the migration plan generated by M4A
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.23 M4A生成的迁移计划概述
- en: In particular, the Options menu allows you to edit the generated migration plan,
    as shown in figure 15.24.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是选项菜单允许您编辑生成的迁移计划，如图15.24所示。
- en: '![15-24](../../OEBPS/Images/15-24.png)'
  id: totrans-297
  prefs: []
  type: TYPE_IMG
  zh: '![15-24](../../OEBPS/Images/15-24.png)'
- en: Figure 15.24 Reviewing and editing the generated migration plan
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.24 审查和编辑生成的迁移计划
- en: Let’s look at what has been generated by editing the migration plan, as shown
    in figure 15.25.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看通过编辑迁移计划生成的结果，如图15.25所示。
- en: '![15-25](../../OEBPS/Images/15-25.png)'
  id: totrans-300
  prefs: []
  type: TYPE_IMG
  zh: '![15-25](../../OEBPS/Images/15-25.png)'
- en: Figure 15.25 Editing the generated migration plan
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.25 编辑生成的迁移计划
- en: Normally, you don’t need to change the migration plan. However, being able to
    is useful if you either need to strip out unneeded VM components or need to add
    some additional configuration. After checking and, if necessary, editing the migration
    plan, you can start generating the artifacts (see figure 15.26).
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，您不需要更改迁移计划。然而，如果您需要移除不必要的VM组件或需要添加一些额外的配置，那么能够这样做是有用的。在检查并必要时编辑迁移计划后，您可以开始生成工件（见图15.26）。
- en: '![15-26](../../OEBPS/Images/15-26.png)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![15-26](../../OEBPS/Images/15-26.png)'
- en: Figure 15.26 Generating artifacts with the edited migration plan
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.26 使用编辑后的迁移计划生成工件
- en: Once the migration plans are generated, you can inspect them by accessing the
    Artifacts tab from the Google Cloud console. This includes the Dockerfile, the
    container image for deployment (that can be directly deployed), the container
    image base layer (the nonrunnable image layers), the Deployment spec YAML, the
    migration plan YAML, and the artifact links YAML (see figure 15.27).
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦生成迁移计划，您可以通过访问Google Cloud控制台中的工件选项卡来检查它们。这包括Dockerfile、部署容器镜像（可以直接部署）、容器镜像基础层（不可运行的镜像层）、部署规范YAML、迁移计划YAML以及工件链接YAML（见图15.27）。
- en: '![15-27](../../OEBPS/Images/15-27.png)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![15-27](../../OEBPS/Images/15-27.png)'
- en: Figure 15.27 Generated migration artifacts
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.27 生成的迁移工件
- en: The generated artifacts are stored in GCS with separate buckets for base and
    image layers (see figure 15.28).
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的工件存储在GCS中，基础层和镜像层分别使用不同的存储桶（见图15.28）。
- en: '![15-28](../../OEBPS/Images/15-28.png)'
  id: totrans-309
  prefs: []
  type: TYPE_IMG
  zh: '![15-28](../../OEBPS/Images/15-28.png)'
- en: Figure 15.28 Artifacts stored in GCS
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.28 存储在GCS中的工件
- en: Let’s look now at the system image with the Dockerfile, the Deployment spec,
    the manifest and the migration YAML (see figure 15.29).
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看带有Dockerfile、部署规范、清单和迁移YAML的系统镜像（见图15.29）。
- en: '![15-29](../../OEBPS/Images/15-29.png)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![15-29](../../OEBPS/Images/15-29.png)'
- en: Figure 15.29 Dockerfile, Deployment spec, manifest, and migration files
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.29 Dockerfile、部署规范、清单和迁移文件
- en: In addition, images generated for migration are automatically pushed to the
    Google Container Registry, and you can browse them via the console, as shown in
    figure 15.30.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，为迁移生成的镜像会自动推送到Google Container Registry，您可以通过控制台浏览它们，如图15.30所示。
- en: '![15-30](../../OEBPS/Images/15-30.png)'
  id: totrans-315
  prefs: []
  type: TYPE_IMG
  zh: '![15-30](../../OEBPS/Images/15-30.png)'
- en: Figure 15.30 Images generated for migration and pushed to the GCR
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.30 用于迁移并推送到GCR的镜像
- en: 'All the generated artifacts can be downloaded via the CLI as follows:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 所有生成的工件都可以通过以下命令从CLI下载：
- en: '[PRE36]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'These artifacts include the following:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工件包括以下内容：
- en: '*deployment_spec.yaml*—Configures your workload'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*deployment_spec.yaml*—配置您的负载'
- en: '*Dockerfile*—Used to build the image for your migrated VM'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Dockerfile*—用于构建迁移VM的镜像'
- en: '*migration.yaml*—A copy of the migration plan'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*migration.yaml*—迁移计划的副本'
- en: An overview of Dockerfile
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: Dockerfile概述
- en: 'In this section, we take a deep look at the Dockerfile generated by M4A. You
    can edit the file to customize your image, for instance, either for installing
    new packages or for installing an upgraded version of the M4A runtime. The file
    contains the original container repository for runtime, the image containing data
    captured from the source VM, and the initial entry point. A typical M4A Dockerfile
    follows:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将深入探讨M4A生成的Dockerfile。您可以编辑文件来自定义镜像，例如，用于安装新包或安装M4A运行时的升级版本。该文件包含运行时的原始容器仓库、包含从源虚拟机捕获的数据的镜像以及初始入口点。一个典型的M4A
    Dockerfile如下：
- en: '[PRE37]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: We will see more details on the M4A-generated Dockerfile later in this chapter
    when we discuss the postmigration integration with CI/CD pipelines. In the next
    section, we will discuss the details of the deployment_spec.yaml file.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章讨论迁移后与CI/CD管道集成时，我们将在本章后面看到M4A生成的Dockerfile的更多细节。在下一节中，我们将讨论deployment_spec.yaml文件的详细信息。
- en: An overview of deployment_spec.yaml
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: deployment_spec.yaml概述
- en: 'In this section, we will discuss the deployment_spec.yaml generated by M4A.
    First, let’s define some terminology we will use later:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论M4A生成的deployment_spec.yaml。首先，让我们定义一些我们稍后将要使用的术语：
- en: '*Stateless*—An application is stateless when the server does not store any
    state about the client session. In other words, there is no stored knowledge of
    or reference to past transactions.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*无状态*—当服务器不存储有关客户端会话的任何状态时，应用是无状态的。换句话说，没有对过去事务的存储知识或引用。'
- en: '*Stateful*—An application is stateful when the server stores data about the
    client session. In other words, the current transaction may be affected by what
    happened during previous transactions. For this reason, a stateful application
    needs to use the same servers each time a request from a user is processed.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*有状态*—当服务器存储有关客户端会话的数据时，应用是有状态的。换句话说，当前事务可能会受到之前事务发生的影响。因此，有状态的应用需要在每次处理用户请求时使用相同的服务器。'
- en: 'With this context in mind, let’s consider deployment_spec.yaml. This file will
    be different according to the intent flag selected in the UI, as described next:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个背景下，让我们考虑deployment_spec.yaml。这个文件将根据UI中选择的意图标志而有所不同，如下所述：
- en: '*Intent: Image*—The YAML defines a stateless application with identical Pods[^(11)](#pgfId-1081384)
    managed as a service. Different parts of the YAML follow:'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*意图：镜像*—YAML定义了一个无状态应用，具有相同的Pods作为服务管理。[^(11)](#pgfId-1081384) YAML的不同部分如下：'
- en: '*Deployment*—The set of identical Pods deployed from the image generated from
    your migrated VM. They are stored in GCR.'
  id: totrans-333
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*部署*—从您迁移的虚拟机生成的镜像中部署的一组相同的Pods。它们存储在GCR中。'
- en: '*Service*—Groups Pods in your deployment into a single resource accessible
    from a stable IP address. By default, a single cluster internal IP is reachable
    only from within the cluster with no load balancing. The Kubernetes endpoints
    controller will modify the DNS configuration to return records (addresses) that
    point to the Pods, which are labeled with "<app>": "<app-name>"where the name
    of the app is inferred from the migctl migration create my-migration command.
    Note that Pods will be visible only within the cluster by default, so, it might
    be appropriate to expose Pods outside of your cluster. We will see an example
    later in the chapter.'
  id: totrans-334
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*服务*—将您的部署中的Pods组合成一个单一的资源，可以从稳定的IP地址访问。默认情况下，单个集群内部IP只能在集群内部访问，没有负载均衡。Kubernetes端点控制器将修改DNS配置以返回指向Pods的记录（地址），这些Pods被标记为"<app>":
    "<app-name>"，其中应用名称是从migctl迁移创建my-migration命令中推断出来的。请注意，默认情况下，Pods只能在集群内部可见，因此，可能需要将Pods暴露在集群之外。我们将在本章后面看到一个示例。'
- en: '*Logging configuration*—Configures logging to Cloud Logging by listing many
    of the most common log files.'
  id: totrans-335
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*日志配置*—通过列出许多最常见的日志文件来配置将日志记录到云日志。'
- en: '*Intent: ImageAndData*—The YAML defines a stateful application with different
    Pods associated with persistent volumes. Different parts of the YAML follow:'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*意图：镜像和数据*—YAML定义了一个具有与持久卷相关联的不同Pods的有状态应用。YAML的不同部分如下：'
- en: '*StatefulSet*—The set of Pods deployed from the image generated from your migrated
    VM. They are stored in GCR.'
  id: totrans-337
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*StatefulSet*—从您迁移的虚拟机生成的镜像中部署的一组Pods。它们存储在GCR中。'
- en: '*Service*—Similar to the Service defined in the Image section.'
  id: totrans-338
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*服务*—类似于在镜像部分定义的服务。'
- en: '*PersistentVolume*—Used to manage the durable storage.'
  id: totrans-339
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*持久卷*—用于管理持久存储。'
- en: '*PersistentVolumeClaim*—Represents a request for and claim to the PersistentVolume
    resource (such as specific size and access mode).'
  id: totrans-340
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*持久卷声明*—表示对持久卷资源（如特定大小和访问模式）的请求和声明。'
- en: '*Logging configuration*—Similar to what was defined for stateless.'
  id: totrans-341
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*日志配置*—类似于为无状态定义的内容。'
- en: '*Intent: Data*—Different parts of the YAML follow:'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*意图：数据*—YAML的不同部分如下：'
- en: '*PersistentVolume*—Similar to what was defined for stateful.'
  id: totrans-343
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*持久卷*—类似于为有状态定义的内容。'
- en: '*PersistentVolumeClaim*—Similar to what was defined for stateful.'
  id: totrans-344
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*持久卷声明*—类似于为有状态定义的内容。'
- en: A typical M4A deployment_spec.yaml is shown in the next listing.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个列表显示了典型的M4A deployment_spec.yaml。
- en: Listing 15.1 The deployment_spec.yaml generated by M4A
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 列表15.1 M4A生成的deployment_spec.yaml
- en: '[PRE38]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Deploying the container generated by M4A
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 部署由M4A生成的容器
- en: 'In this section, the steps needed to deploy the container generated by M4A
    are discussed. Deploying the deployment_spec.yaml is very easy:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，讨论了部署由M4A生成的容器的步骤。部署deployment_spec.yaml非常简单：
- en: '[PRE39]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'As a result, you should see something like this:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你应该看到类似这样的内容：
- en: '[PRE40]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'If you want, you can check the status of the deployed Pods:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想，你可以检查已部署Pods的状态：
- en: '[PRE41]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'You should see something like this:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到类似这样的内容：
- en: '[PRE42]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'By default, the container is deployed with no load balancing and a single-cluster
    internal IP, which is reachable only from within the cluster. The Kubernetes endpoints
    controller will modify the DNS configuration to return addresses that point to
    the Pods, which are labeled with "app": "tomcat-vm-gulli-vm". Of course, you can
    change the deployment and add a Service of type LoadBalancer. Let’s do that by
    adding the following to the deployment spec:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: '默认情况下，容器以无负载均衡和单个集群内部IP的方式部署，只能从集群内部访问。Kubernetes端点控制器将修改DNS配置，以返回指向标记为"app":
    "tomcat-vm-gulli-vm"的Pods的地址。当然，你可以更改部署并添加一个类型为LoadBalancer的服务。让我们通过在部署规范中添加以下内容来实现这一点：'
- en: '[PRE43]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Then, let’s check that the Service is indeed accessible:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，让我们检查服务是否确实可访问：
- en: '[PRE44]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Figure 15.31 shows what happens when we try to access the Service from the internet.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.31显示了当我们尝试从互联网访问服务时发生的情况。
- en: '![15-31](../../OEBPS/Images/15-31.png)'
  id: totrans-362
  prefs: []
  type: TYPE_IMG
  zh: '![15-31](../../OEBPS/Images/15-31.png)'
- en: Figure 15.31 Accessing the Tomcat container after migration with M4A
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.31 使用M4A迁移后访问Tomcat容器
- en: Congratulations! You now have a routable container holding the full Tomcat installation
    previously available in a VM! The migration happened automatically, with no need
    to either recompile or access the original source code.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你现在拥有一个可路由的容器，它包含了之前在虚拟机中可用的完整Tomcat安装！迁移是自动发生的，无需重新编译或访问原始源代码。
- en: 'Before concluding, here’s a hint about the GUI: if you need to edit multiple
    files, it might be convenient to use the built-in editor, which is based on Eclipse.
    The editor is a quick and easy way to review and change all the files generated
    by M4A (see figure 15.32).'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 在结论之前，这里有一个关于GUI的提示：如果你需要编辑多个文件，使用基于Eclipse的内置编辑器可能很方便。编辑器是快速轻松地审查和更改M4A生成的所有文件的一种方式（见图15.32）。
- en: '![15-32](../../OEBPS/Images/15-32.png)'
  id: totrans-366
  prefs: []
  type: TYPE_IMG
  zh: '![15-32](../../OEBPS/Images/15-32.png)'
- en: Figure 15.32 The built-in editor used to manipulate migration configuration
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.32 用于操作迁移配置的内置编辑器
- en: 'One note before concluding: in addition to Google Container Registry and Google
    Cloud Storage for data repositories, M4A version 1.6 and higher supports additional
    repositories including ECR, S3, and Docker registries. In the next section, we
    are going to talk about Windows migration.'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 在结论之前的一个注意事项：除了Google Container Registry和Google Cloud Storage用于数据存储库之外，M4A 1.6及以上版本支持包括ECR、S3和Docker注册表在内的其他存储库。在下一节中，我们将讨论Windows迁移。
- en: 15.4.4 Windows migration
  id: totrans-369
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.4.4 Windows迁移
- en: In this section, we discuss how to migrate Windows VMs to GKE. Please note that
    Windows migration supports Compute Engine as a source. However, as discussed earlier,
    it is possible to migrate a Windows VM from other sources into Compute Engine
    using Migrate for Compute Engine (sometime referred as Migrate to Virtual Machines;
    see [http://mng.bz/pdj8](http://mng.bz/pdj8)). The resulting VM can be then migrated
    to GKE. Unsurprisingly, Windows migration is similar to that for Linux. Indeed,
    behind the scenes, M4A uses a unified M4A CLI utility named migctl. Let’s see
    a quick example using the CLI interface.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论如何将 Windows 虚拟机迁移到 GKE。请注意，Windows 迁移支持将计算引擎作为源。然而，如前所述，您可以使用计算引擎迁移（有时称为迁移到虚拟机；见[http://mng.bz/pdj8](http://mng.bz/pdj8)）将来自其他源的
    Windows 虚拟机迁移到计算引擎。然后，可以将生成的虚拟机迁移到 GKE。不出所料，Windows 迁移与 Linux 迁移类似。实际上，在幕后，M4A
    使用一个名为 migctl 的统一 M4A CLI 工具。让我们通过 CLI 接口快速看一下示例。
- en: 'First, similarly to Linux, you can use migctl with the following statement
    for adding a migration source:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，与 Linux 类似，您可以使用以下语句使用 migctl 添加迁移源：
- en: '[PRE45]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Remember that my-ce-src is the name of the source, my-project is the name of
    the project, and m4a-ce-src.json is the name of the JSON key file obtained after
    creating a service account for using Compute Engine as a migration source. Then
    you can create a migration with the following command
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，my-ce-src 是源名称，my-project 是项目名称，m4a-ce-src.json 是创建用于作为迁移源使用计算引擎的服务账户后获得的
    JSON 键文件名称。然后，您可以使用以下命令创建迁移
- en: '[PRE46]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'where my-migration is the name of the migration and vm-id is the name of the
    Compute Engine instance, as shown in the Google Cloud console. The migration plan
    just created can be retrieved with the following command:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 my-migration 是迁移的名称，vm-id 是计算引擎实例的名称，如 Google Cloud Console 中所示。可以使用以下命令检索刚刚创建的迁移计划：
- en: '[PRE47]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'If needed, you can customize the migration plan by editing the file my-migration.yaml.
    When editing is completed, you can then upload the edited migration plan with
    the following command:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，您可以通过编辑文件 my-migration.yaml 来自定义迁移计划。编辑完成后，您可以使用以下命令上传编辑后的迁移计划：
- en: '[PRE48]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The next step is to execute the migration and generate artifacts:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是执行迁移并生成工件：
- en: '[PRE49]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'During the migration, you can monitor the status:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 在迁移过程中，您可以监控状态：
- en: '[PRE50]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'When the migration concludes you can access the artifacts:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移完成后，您可以访问工件：
- en: '[PRE51]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'As a results, you should see something like this:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 结果，您应该看到类似以下内容：
- en: '[PRE52]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Hence you can get the artifacts with the following command:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，您可以使用以下命令获取工件：
- en: '[PRE53]'
  id: totrans-388
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The next step is to use the artifacts to build a Docker image. We can use Windows
    PowerShell to expand the artifacts.zip:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是使用工件构建 Docker 镜像。我们可以使用 Windows PowerShell 展开artifacts.zip：
- en: '[PRE54]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Then log in to the Container Registry:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 然后登录到容器注册表：
- en: '[PRE55]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The next step is to build the container using the next code snippet:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是使用以下代码片段构建容器：
- en: '[PRE56]'
  id: totrans-394
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'When you generate artifacts for Windows workloads, the artifacts are copied
    into a Cloud Storage bucket as an intermediate location that you can download.
    This file contains a Dockerfile, the deployment_spec.yaml file, and several directories
    from the source, which you then use to build the Windows container. Once the build
    is completed, the container image will be placed in the Container Registry, and
    the image can be deployed to a GKE cluster. Note that the Google Cloud console
    for Anthos has included Windows workload support since M4A v1.5\. The experience
    is identical to the one already discussed for Linux. If you want to see another
    example of Windows migration, consider the hands-on lab “Migrate for Anthos: Windows”
    available at [http://mng.bz/yd7y](http://mng.bz/yd7y).'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: '当您为 Windows 工作负载生成工件时，工件将被复制到云存储桶中作为中间位置，您可以从中下载。此文件包含 Dockerfile、deployment_spec.yaml
    文件以及来自源的一些目录，您可以使用这些目录构建 Windows 容器。构建完成后，容器镜像将被放置在容器注册表中，并且可以部署到 GKE 集群。请注意，自
    M4A v1.5 版本起，Google Cloud Console for Anthos 已包含对 Windows 工作负载的支持。体验与之前讨论的 Linux
    相同。如果您想看另一个 Windows 迁移的示例，请考虑在[http://mng.bz/yd7y](http://mng.bz/yd7y)可用的“Migrate
    for Anthos: Windows”动手实验室。'
- en: 15.4.5 Migration from other clouds
  id: totrans-396
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.4.5 从其他云迁移
- en: As of November 2021, migration from other clouds is based on a two-step approach.
    First, virtual machines are migrated (technically, they are converted into GCE
    instances). Then, the migrated virtual machines are containerized.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 截至 2021 年 11 月，从其他云迁移基于两步方法。首先，虚拟机被迁移（技术上，它们被转换为 GCE 实例）。然后，迁移的虚拟机被容器化。
- en: M4A uses the product Migrate for Compute Engine (M4CE) (sometime referred as
    Migrate to Virtual Machines; [https://cloud.google.com/migrate/compute-engine](https://cloud.google.com/migrate/compute-engine))
    to stream virtual machines located on other clouds or on-prem, moving them onto
    GCE instances. Migrate for Compute Engine can be installed via the marketplace
    ([http://mng.bz/Mlao](http://mng.bz/Mlao)) and allows the migration of thousands
    of applications across multiple data centers and clouds from source platforms
    such as VMware, Microsoft Azure, and Amazon EC2.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: M4A 使用 Migrate for Compute Engine (M4CE)（有时称为迁移到虚拟机；[https://cloud.google.com/migrate/compute-engine](https://cloud.google.com/migrate/compute-engine)）产品，将位于其他云或本地云上的虚拟机流式传输到
    GCE 实例。Migrate for Compute Engine 可以通过市场([http://mng.bz/Mlao](http://mng.bz/Mlao))安装，并允许从源平台（如
    VMware、Microsoft Azure 和 Amazon EC2）迁移数千个应用程序到多个数据中心和云。
- en: To use M4CE, you need to set up a site-to-site VPN connection and firewall rules
    to enable communication between the VPC in which the manager is positioned and
    the VPC of the source VM on the other cloud. The interested reader may find the
    online firewall documentation at [https://cloud.google.com/vpc/docs/firewalls](https://cloud.google.com/vpc/docs/firewalls)
    useful. Dynamic routing based on the BGP protocol ([http://mng.bz/zmVB](http://mng.bz/zmVB))
    can be set up via GCP Cloud Router ([http://mng.bz/0ygN](http://mng.bz/0ygN))
    working on either Cloud VPN ([http://mng.bz/aMro](http://mng.bz/aMro)) or dedicated
    high-speed Cloud Interconnect ([http://mng.bz/Klgj](http://mng.bz/Klgj)). Cloud
    Interconnect extends your on-prem network to Google’s network through a highly
    available, low-latency connection.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 M4CE，您需要设置站点到站点的 VPN 连接和防火墙规则，以启用位于管理器所在 VPC 和位于另一云的源虚拟机 VPC 之间的通信。感兴趣的读者可能会发现[https://cloud.google.com/vpc/docs/firewalls](https://cloud.google.com/vpc/docs/firewalls)上的在线防火墙文档很有用。可以通过
    GCP Cloud Router ([http://mng.bz/0ygN](http://mng.bz/0ygN)) 在 Cloud VPN ([http://mng.bz/aMro](http://mng.bz/aMro))
    或专用高速 Cloud Interconnect ([http://mng.bz/Klgj](http://mng.bz/Klgj)) 上设置基于 BGP
    协议的动态路由([http://mng.bz/zmVB](http://mng.bz/zmVB))。Cloud Interconnect 通过一个高可用、低延迟的连接将您的本地网络扩展到
    Google 的网络。
- en: 'In addition, thousands of virtual machines can be migrated in batches by aggregating
    them in waves according to their logical role. M4CE allows us to define runbooks
    to decide which VM should be migrated and in what order. A simulated testing phase
    can be planned before the effective migration. The main components of M4CE follow:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，可以根据它们的逻辑角色将成千上万的虚拟机分批迁移，通过波次聚合它们。M4CE 允许我们定义运行手册来决定哪些虚拟机应该迁移以及迁移的顺序。在有效迁移之前可以计划一个模拟测试阶段。M4CE
    的主要组件如下：
- en: '*A migration manager*—Used to orchestrate migration. The manager runs on a
    separate Google Compute Engine VM and offers a migration console to manage and
    monitor all the system components. Note that the manager might require specific
    permissions to handle specific actions, such as turning on and off a VM. These
    permissions can be defined with policies.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*迁移管理器*—用于编排迁移。管理器在单独的 Google Compute Engine 虚拟机上运行，并提供一个迁移控制台来管理和监控所有系统组件。请注意，管理器可能需要特定的权限来处理特定的操作，例如开启和关闭虚拟机。这些权限可以通过策略来定义。'
- en: '*A Cloud Extension*—Used to handle storage migrating from the source platform.
    An extension is a conduit for VM storage between the migration source and destination.
    These extensions run on separate Compute Engine VMs and serve data to migrated
    workloads during the migration process itself. Note that extensions work with
    a dual-node active/passive configuration for high availability; each node serves
    workloads and, at the same time, provides backup for the other node.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*云扩展*—用于处理从源平台迁移的存储。扩展是迁移源和目标之间虚拟机存储的通道。这些扩展在单独的 Compute Engine 虚拟机上运行，并在迁移过程中本身为迁移的工作负载提供服务。请注意，扩展使用双节点主动/被动配置进行高可用性；每个节点提供服务，同时为另一个节点提供备份。'
- en: 'Different components are then deployed on source platforms, as described here:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 然后根据以下描述，在源平台上部署不同的组件：
- en: '*On vSphere*—A backend component serves runtime data from VMware to extensions
    on Google Cloud. Data is then used by the VMs on Compute Engine. In addition,
    a vCenter plug-in connects vSphere to the migration manager and orchestrates the
    migration on vCenter.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在 vSphere 上*—后端组件从 VMware 向 Google Cloud 的扩展提供运行时数据。然后，数据由 Compute Engine
    上的虚拟机使用。此外，vCenter 插件将 vSphere 连接到迁移管理器，并在 vCenter 上编排迁移。'
- en: '*On Amazon EC2 and Azure*—An importer is deployed at runtime and serves runtime
    data from the source to extensions on Google Cloud. Data is then used by the VMs
    on Compute Engine.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在Amazon EC2和Azure上*—在运行时部署导入器，并将源数据从Google Cloud上的扩展服务中提供。然后，数据由Compute Engine上的虚拟机使用。'
- en: Since Migrate 1.9, you can also deploy containers to GKE Autopilot clusters
    and Cloud Run, but that topic is outside the subject of this book.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 自Migrate 1.9以来，您还可以将容器部署到GKE Autopilot集群和Cloud Run，但这个主题超出了本书的主题范围。
- en: In this section, we have briefly introduced M4CE, which M4A uses to move VMs
    between clouds and on-prem. Migration can happen in minutes, while data migrates
    transparently in the background. The interested reader can learn more online at
    [http://mng.bz/GRXv](http://mng.bz/GRXv). In addition, more helpful information
    on how to migrate an EC2 instance from AWS to Compute Engine on Google Cloud is
    available at [http://mng.bz/gJ2x](http://mng.bz/gJ2x). The next section is about
    several Google best practices adopted for M4A.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们简要介绍了M4CE，这是M4A用来在云和本地之间移动虚拟机的方法。迁移可以在几分钟内完成，而数据则在后台透明迁移。感兴趣的读者可以在[http://mng.bz/GRXv](http://mng.bz/GRXv)上了解更多信息。此外，有关如何将EC2实例从AWS迁移到Google
    Cloud上的Compute Engine的更多有用信息可在[http://mng.bz/gJ2x](http://mng.bz/gJ2x)找到。下一节将介绍为M4A采用的一些Google最佳实践。
- en: '15.5 Advanced topic: M4A best practices'
  id: totrans-408
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 15.5 高级主题：M4A最佳实践
- en: 'In this section, we discuss some best practices for M4A. The idea is to provide
    guidance on real-time scenarios frequently encountered by customers. This section
    is rather advanced and assumes that you are very familiar with Kubernetes environments.
    Different details of Kubernetes are discussed in detail. Let’s start with the
    following:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论了M4A的一些最佳实践。目的是为顾客经常遇到的实时场景提供指导。本节相当高级，并假设您非常熟悉Kubernetes环境。详细讨论了Kubernetes的不同细节。让我们从以下内容开始：
- en: '*VM hostnames*—One convenient pattern is to transform VM hostnames into Kubernetes
    service names (see [http://mng.bz/WAQa](http://mng.bz/WAQa)). Note that service
    names are a set of Pod endpoints grouped into a single resource. So, retaining
    this naming convention helps with consistency.'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*虚拟机主机名*—一个方便的模式是将虚拟机主机名转换为Kubernetes服务名称（见[http://mng.bz/WAQa](http://mng.bz/WAQa)）。请注意，服务名称是一组Pod端点，它们被组合成一个单一的资源。因此，保留这种命名约定有助于保持一致性。'
- en: '*Multiple apps/services per VM*—If multiple applications or services exist
    per VM, it might be convenient to define a Kubernetes Service for each of them.
    Again, this naming convention helps with consistency.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*每个虚拟机多个应用/服务*—如果每个虚拟机存在多个应用程序或服务，为它们中的每一个定义一个Kubernetes服务可能很方便。同样，这种命名约定有助于保持一致性。'
- en: '*Host file customizations*—If your VMs use specific customization on the host
    file for DNS resolution, then it is recommended to use the Kubernetes Pod spec
    hostAliases ([http://mng.bz/81qz](http://mng.bz/81qz)). Adding entries to a Pod’s
    /etc/hosts file provides a Pod-level override of hostname resolution. Moreover,
    it helps to replicate multiple application environments, such as production, staging,
    and testing.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*主机文件自定义*—如果您的虚拟机在主机文件上使用特定的自定义以进行DNS解析，那么建议使用Kubernetes Pod规范中的hostAliases（[http://mng.bz/81qz](http://mng.bz/81qz)）。向Pod的/etc/hosts文件中添加条目提供了对主机名解析的Pod级别覆盖。此外，它有助于复制多个应用程序环境，如生产、预发布和测试。'
- en: '*Multi-VM stacks*—If you have a multi-VM-stacks environment, then it might
    be convenient to place codependent Pods in the same Kubernetes namespace and use
    short DNS names. In addition, you should use Kubernetes’ NetworkPolicy to restrict
    access between frontend and backend Pods. This organization would help keep your
    environment organized, safer, and more effective.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*多虚拟机堆栈*—如果您有一个多虚拟机堆栈环境，那么将相互依赖的Pod放置在同一个Kubernetes命名空间中并使用简短DNS名称可能很方便。此外，您应该使用Kubernetes的NetworkPolicy来限制前端Pod和后端Pod之间的访问。这种组织有助于保持您的环境有序、更安全、更有效。'
- en: '*Referring to external services*—If your applications use external services,
    it is worth considering using the Kubernetes ExternalName Service without a selector
    ([http://mng.bz/Elqd](http://mng.bz/Elqd)), a best practice in Kubernetes to abstract
    external backends.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*引用外部服务*—如果您的应用程序使用外部服务，考虑使用Kubernetes ExternalName Service而不使用选择器（[http://mng.bz/Elqd](http://mng.bz/Elqd)）是一个Kubernetes的最佳实践，用于抽象外部后端。'
- en: '*NFS file share*—Currently, M4A does not automatically migrate NFS mounts.
    Therefore, you need to manually define NFS persistent volume directives and add
    them to the generated Pod YAML. The interested reader can find more information
    on mounting external volumes online ([http://mng.bz/Nmqn](http://mng.bz/Nmqn)).'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*NFS文件共享*—目前，M4A不会自动迁移NFS挂载。因此，您需要手动定义NFS持久卷指令并将它们添加到生成的Pod YAML中。感兴趣的读者可以在网上找到有关挂载外部卷的更多信息([http://mng.bz/Nmqn](http://mng.bz/Nmqn))。'
- en: '*Unneeded services*—Migration is a consolidation moment. Therefore, it is appropriate
    to double-check all the services running on your virtual machine and disable those
    that are not needed on containers. Migrate for Anthos will automatically disable
    unnecessary hardware or environment-specific services and a predefined set of
    additional services running on VMs. See a detailed list of different services
    automatically disabled at [http://mng.bz/DZqR](http://mng.bz/DZqR).'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*不必要的服务*—迁移是一个整合时刻。因此，检查您虚拟机上运行的所有服务并禁用不需要在容器上运行的服务是合适的。Migrate for Anthos将自动禁用不必要的硬件或特定于环境的服务和在VM上运行的一组预定义的附加服务。有关自动禁用的不同服务的详细列表，请参阅[http://mng.bz/DZqR](http://mng.bz/DZqR)。'
- en: '*Environmental variables*—If your application requires an environment variable,
    it is a good practice to move definitions to the Kubernetes Pod YAML, ensuring
    you follow the best practice of having all your infrastructure as code.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*环境变量*—如果您的应用程序需要环境变量，将定义移动到Kubernetes Pod YAML中是一个好习惯，以确保您遵循将所有基础设施作为代码的最佳实践。'
- en: '*Scripts using Cloud instance metadata*—If your scripts look up metadata, it
    is worth replacing this lookup with either Kubernetes ConfigMap ([http://mng .bz/lJl2](http://mng.bz/lJl2))
    or, again, using the env variables defined in your Kubernetes Pod YAML definition.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用Cloud实例元数据的脚本*—如果您的脚本查找元数据，将此查找替换为Kubernetes ConfigMap ([http://mng.bz/lJl2](http://mng.bz/lJl2))或再次使用在您的Kubernetes
    Pod YAML定义中定义的env变量是值得的。'
- en: '*Application logs*—You can have logs generated by workload containers migrated
    with M4A and written to Cloud Logging. By default, M4A considers entries written
    to stdout of init, the parent of all Linux processes, and contents from /var/log/syslog.
    Adopting this strategy will enhance the level of automation in your environment
    and the observability of your applications.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*应用程序日志*—您可以使用M4A将工作负载容器生成的日志迁移并写入Cloud Logging。默认情况下，M4A会将写入init（所有Linux进程的父进程）的stdout的条目以及来自/var/log/syslog的内容视为条目。采用此策略将提高您环境中自动化的程度和应用程序的可观察性。'
- en: '*GKE Ingress controller*—If you migrate to GKE, it might be convenient to use
    GKE network ingress control for controlling the network traffic accessing workloads.
    Doing so will eliminate the need for changing your application with additional
    routing rules, VPNs, filters, or VLANs. For instance, if you migrate a three-tiered
    application, you might want to split it into multiple containers. The frontend
    service is accessed via a GKE Google load balancer ([http://mng.bz/Blq1](http://mng.bz/Blq1))
    for load scalability. In addition, you might want to define network policies for
    enforcing access to the application service only by the frontend Pods and not
    from the external world. Similarly, you might want to define policies to access
    the database layer from the application layer only. These choices would increase
    the security of your environment.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*GKE入口控制器*—如果您迁移到GKE，使用GKE网络入口控制器来控制访问工作负载的网络流量可能很方便。这样做将消除更改应用程序以添加额外路由规则、VPN、过滤器或VLAN的需求。例如，如果您迁移一个三层应用程序，您可能希望将其拆分为多个容器。前端服务通过GKE
    Google负载均衡器([http://mng.bz/Blq1](http://mng.bz/Blq1))进行访问，以实现负载可伸缩性。此外，您可能还想定义网络策略，以确保只有前端Pod可以访问应用程序服务，而外部世界不能访问。同样，您可能还想定义策略，以确保应用程序层只能访问数据库层。这些选择将提高您环境中安全性。'
- en: '*Linux-specific runlevel 3*—In a Linux environment, certain services are configured
    to start by default only at runlevel 5\. Currently, M4A reaches runlevel 3 only.
    VMs migrated into GKE with M4A will be booted in the container at Linux runlevel
    3\. Consequently, certain services should be configured to start automatically
    at runlevel 3\. These might include X11, XDM, and the GUI used for VNC.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Linux特定的运行级别3*—在Linux环境中，某些服务被配置为默认只在运行级别5时启动。目前，M4A只能达到运行级别3。使用M4A迁移到GKE的VM将在Linux运行级别3下启动。因此，某些服务应该被配置为在运行级别3时自动启动。这些可能包括X11、XDM和用于VNC的GUI。'
- en: In this advanced section, we have discussed several best practices that you
    can adopt for fine-tuning environments migrated with M4A. In the next section,
    we will discuss how to upgrade images postmigration.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 在本高级章节中，我们讨论了您可以采用的一些最佳实践，以微调使用 M4A 迁移的环境。在下一节中，我们将讨论迁移后如何升级镜像。
- en: 15.6 Postmigration integration with CI/CD pipelines
  id: totrans-423
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 15.6 迁移后与 CI/CD 管道的集成
- en: Artifacts generated with M4A can be used for Day 2 operations, such as software
    updates, configuration changes, security patches, and additional operations with
    files. You can easily integrate these artifacts with a CI/CD typical pipeline
    consisting of source, build, test, and deploy (see figure 15.33).
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 M4A 生成的工件可用于第二天的操作，例如软件更新、配置更改、安全补丁以及与文件的附加操作。您可以将这些工件轻松集成到典型的 CI/CD 管道中，该管道包括源代码、构建、测试和部署（见图
    15.33）。
- en: '![15-33](../../OEBPS/Images/15-33.png)'
  id: totrans-425
  prefs: []
  type: TYPE_IMG
  zh: '![15-33](../../OEBPS/Images/15-33.png)'
- en: Figure 15.33 Typical CI/CD development phases
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.33 典型的 CI/CD 开发阶段
- en: Artifacts are generated with multistage builds so they can be incrementally
    maintained without incurring the risk of inflating the generated container image.
    Figure 15.34 shows an example of integration of M4A with CI/CD pipelines.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 通过多阶段构建生成的工件可以逐步维护，而不会增加生成容器镜像的风险。图 15.34 展示了 M4A 与 CI/CD 管道的集成示例。
- en: '![15-34](../../OEBPS/Images/15-34.png)'
  id: totrans-428
  prefs: []
  type: TYPE_IMG
  zh: '![15-34](../../OEBPS/Images/15-34.png)'
- en: Figure 15.34 Integration of M4A with CI/CD pipelines
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.34 M4A 与 CI/CD 管道的集成
- en: A typical Docker artifact is composed of two parts (see figure 15.35). The first
    part is the M4A runtime, and the second part is the nonrunnable base representing
    the capture system image layer from the migrated VM.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的 Docker 工件由两部分组成（见图 15.35）。第一部分是 M4A 运行时，第二部分是不可运行的基镜像，代表从迁移的虚拟机中捕获的系统镜像层。
- en: '![15-35](../../OEBPS/Images/15-35.png)'
  id: totrans-431
  prefs: []
  type: TYPE_IMG
  zh: '![15-35](../../OEBPS/Images/15-35.png)'
- en: Figure 15.35 A typical Dockerfile generated by M4A, useful for CI/CD pipelines
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.35 M4A 生成的典型 Dockerfile，适用于 CI/CD 管道
- en: 'If you need to update the M4A runtime, you can simply replace the first FROM
    directive as appropriate from the Dockerfile. For instance, suppose that you need
    to support M4A 1.8.1\. You can achieve with the following new directive, which
    replaces the current one:'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要更新 M4A 运行时，您可以直接从 Dockerfile 中替换第一个 FROM 指令。例如，假设您需要支持 M4A 1.8.1。您可以使用以下新指令来实现，这将替换当前的指令：
- en: '[PRE57]'
  id: totrans-434
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: If you need to update your application, you can change the second Docker FROM
    directive. In detail, you typically download the generated Dockerfile from your
    container registry (such as GCS), edit the Dockerfile to apply your desired changes,
    build a new layered image, and update the existing deployment with a rolling update.
    As discussed, this image-layered approach is very suitable for a CI/CD-based (see
    chapter 12) deployment environment where DevOps and site reliability engineering
    (SRE) methodologies are the key.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要更新您的应用程序，您可以更改第二个 Docker FROM 指令。具体来说，您通常从容器注册库（如 GCS）下载生成的 Dockerfile，编辑
    Dockerfile 以应用您希望进行的更改，构建一个新的分层镜像，并通过滚动更新来更新现有的部署。如前所述，这种基于镜像层的方法非常适合基于 CI/CD（见第
    12 章）的部署环境，其中 DevOps 和站点可靠性工程（SRE）方法是关键。
- en: In this section, we have discussed how to integrate with CI/CD pipelines for
    increasing your organizational agility. In the next section, we will discuss how
    to integrate with service meshes.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论了如何集成 CI/CD 管道以增加您的组织敏捷性。在下一节中，我们将讨论如何与服务网格集成。
- en: 15.7 Postmigration integration with ASM
  id: totrans-437
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 15.7 迁移后与 ASM 的集成
- en: Earlier in this chapter, we discussed the benefits of using a service mesh—transparent
    gains in terms of communication, policy management, observability, and agility.
    The key observation is that the adoption of Anthos Service Mesh (see chapter 4)
    is another step toward the adoption of SRE and DevOps methodologies.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章前面，我们讨论了使用服务网格的好处——在通信、策略管理、可观察性和敏捷性方面的透明收益。关键观察结果是采用 Anthos Service Mesh（见第
    4 章）是采用 SRE 和 DevOps 方法论的另一步。
- en: For instance, ASM makes it possible to check the service status together with
    key metrics for our applications such as error, latency, and request rates; visualize
    the topology; check the estimated cost; and define service-level indicators (see
    figure 15.36).
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，ASM 使得我们可以检查应用程序的关键指标（如错误、延迟和请求速率）的服务状态；可视化拓扑；检查估计成本；并定义服务级别指标（见图 15.36）。
- en: '![15-36](../../OEBPS/Images/15-36.png)'
  id: totrans-440
  prefs: []
  type: TYPE_IMG
  zh: '![15-36](../../OEBPS/Images/15-36.png)'
- en: Figure 15.36 Using ASM for inspecting an application after migration
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.36 使用 ASM 检查迁移后的应用程序
- en: Once again, it is important to point out that these gains are free with no need
    to change any code in your migrated application. Once it is containerized, your
    application becomes a first-class cloud native application, which can be managed
    with modern cloud native methodologies and significant cost savings. You can arguably
    add your legacy VM into the mesh by using WorkloadEntry. The point is more that
    you gain all the benefits of being on Kubernetes (portability, scalability, etc.),
    as well as the Service Mesh encapsulating all the services within a cluster, without
    having to extend beyond the cluster perimeter.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这些收益是免费的，无需更改迁移应用程序中的任何代码。一旦容器化，您的应用程序就变成了第一类云原生应用程序，可以使用现代云原生方法进行管理，并实现显著的成本节约。您可以通过使用
    WorkloadEntry 将您的遗留虚拟机添加到网格中。关键是您获得了在 Kubernetes 上（可移植性、可扩展性等）的所有好处，以及封装集群内所有服务的服务网格，而无需扩展到集群边界之外。
- en: Summary
  id: totrans-443
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Moving to cloud-based applications offers the benefit of having a modern container-based
    environment using infrastructure in a more efficient way than traditional virtual
    machines. Gains are in terms of reduced costs, improved portability, scalability,
    resiliency, simplified developer experience, and reduced time to market.
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迁移到基于云的应用程序提供了使用比传统虚拟机更有效的方式使用基础设施的现代基于容器的环境的优势。收益包括降低成本、提高可移植性、可扩展性、弹性、简化开发者体验以及缩短上市时间。
- en: You can use Migrate for Anthos to have a fully automated transformation, with
    no need for the original source code.
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以使用 Migrate for Anthos 进行完全自动化的转换，无需原始源代码。
- en: The best workload candidates for migration include stateless web frontend, multi-VM,
    multitiered stacks, business logic middleware, medium- to large-sized databases,
    and low duty-cycle and bursty workloads. We have reviewed the components that
    make up the Migrate for Anthos architecture together with real-world migration
    scenarios.
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最佳迁移工作负载候选者包括无状态 Web 前端、多虚拟机、多层堆栈、业务逻辑中间件、中到大型数据库以及低负载周期和突发工作负载。我们已经一起审查了构成
    Migrate for Anthos 架构的组件以及实际的迁移场景。
- en: We have learned some common best practices for migration using Migrate for Anthos
    including postmigration integration with CI/CD pipelines and with Anthos Service
    Mesh.
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们已经学习了使用 Migrate for Anthos 进行迁移的一些常见最佳实践，包括与 CI/CD 管道以及与 Anthos Service Mesh
    的迁移后集成。
- en: '* * *'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: ^(1.)A hypervisor is software, firmware, or hardware that creates and runs virtual
    machines.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: (1.) 虚拟机管理程序是创建和运行虚拟机的软件、固件或硬件。
- en: ^(2.)The SLA is the agreement that specifies what service is to be provided,
    how it is supported, times, locations, costs, performance, and responsibilities
    of the parties involved.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: (2.) SLA 是指定应提供什么服务、如何支持、时间、地点、成本、性能以及相关方责任的协议。
- en: ^(3.)SLOs are specific measurable metrics of an SLA such as availability, throughput,
    frequency, response time, or quality.
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: (3.) SLO 是 SLA 的具体可衡量指标，例如可用性、吞吐量、频率、响应时间或质量。
- en: ^(4.)Circuit breakers are a design pattern used in modern software development
    to detect failures and to prevent a failure from constantly reappearing, during
    maintenance, external failures, or unforeseen problems.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: (4.) 断路器是一种在现代软件开发中用于检测故障并防止故障在维护期间、外部故障或意外问题中不断出现的模式。
- en: ^(5.)Canary deployments are a pattern for rolling out releases to a subset of
    users or servers. The idea is to first deploy the change to a small subset of
    servers/users, test it, and then roll the change out to the remaining servers/users.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: (5.) 金丝雀部署是一种将发布部署到用户或服务器子集的模式。想法是首先将更改部署到一小部分服务器/用户，测试它，然后将其部署到剩余的服务器/用户。
- en: ^(6.)Two common Unix service layers; see [https://fossbytes.com/systemd-vs-sys-v-vs-upstart/](https://fossbytes.com/systemd-vs-sys-v-vs-upstart/).
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: (6.) 两个常见的 Unix 服务层；请参阅 [https://fossbytes.com/systemd-vs-sys-v-vs-upstart/](https://fossbytes.com/systemd-vs-sys-v-vs-upstart/)。
- en: ^(7.)CRD is an extension of the Kubernetes API, which is not necessarily available
    in a default Kubernetess installation. CRD is a standard mechanism to customize
    Kubernetes in a modular way. See [http://mng.bz/61zy](http://mng.bz/61zy).
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: (7.) CRD 是 Kubernetes API 的扩展，这并不一定在默认的 Kubernetes 安装中可用。CRD 是一种标准机制，以模块化方式自定义
    Kubernetes。请参阅 [http://mng.bz/61zy](http://mng.bz/61zy)。
- en: ^(8.)As of 2023, there are 90 certified Kubernetes-conformant distributions.
    See [http://mng.bz/oJ9M](http://mng.bz/oJ9M).
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: (8.)截至2023年，共有90个经过认证的Kubernetes兼容发行版。参见 [http://mng.bz/oJ9M](http://mng.bz/oJ9M)。
- en: ^(9.)See [https://cloud.google.com/migrate/compute-engine](https://cloud.google.com/migrate/compute-engine).
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: (9.)参见 [https://cloud.google.com/migrate/compute-engine](https://cloud.google.com/migrate/compute-engine)。
- en: ^(10.)For a list of fit assessment rules see [http://mng.bz/v1VM](http://mng.bz/v1VM).
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: (10.)有关拟合评估规则的列表，请参阅 [http://mng.bz/v1VM](http://mng.bz/v1VM)。
- en: ^(11.)A Pod encapsulates one or more applications and is the smallest unit of
    execution in Kubernetes.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: (11.)Pod封装了一个或多个应用程序，是Kubernetes中最小的执行单元。
