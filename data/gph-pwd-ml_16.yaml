- en: 12 Knowledge graphs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 12 知识图谱
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Introducing knowledge graphs and their use
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍知识图谱及其应用
- en: Extracting entities and relationships from text to create a knowledge graph
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从文本中提取实体和关系以创建知识图谱
- en: 'Using postprocessing techniques on top of knowledge graphs: semantic networks'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在知识图谱之上使用后处理技术：语义网络
- en: Extracting topics automatically
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动提取主题
- en: 'In this chapter, we’ll continue the work started in chapter 11: decomposing
    a text into a set of meaningful information and storing it in a graph. Here, we
    have a clear goal in mind: building a knowledge graph.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将继续第11章开始的工作：将文本分解成一组有意义的 信息并将其存储在图中。在这里，我们有一个明确的目标：构建知识图谱。
- en: In this way we will complete the journey we started 11 chapters ago, of managing
    and processing data by using graphs as a core technology and mental model. Knowledge
    graphs represent the summit of what has been discussed throughout the entire book.
    In previous chapters, you learned how to store and process user-item interaction
    data for providing recommendations in different shapes and forms, how to deal
    with transactional data and social networks to fight fraud, and more. Now we will
    dig deeper into how to extract knowledge from unstructured data.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们将完成11章前开始的旅程，即通过使用图作为核心技术和心理模型来管理和处理数据。知识图谱代表了整本书讨论内容的顶峰。在前面的章节中，你学习了如何存储和处理用户-项目交互数据以提供不同形式和形状的推荐，如何处理交易数据和社会网络以打击欺诈，等等。现在，我们将深入探讨如何从非结构化数据中提取知识。
- en: This chapter is a bit longer than the others and quite dense. You’ll need to
    read it as a whole to understand not only how to build a knowledge graph out of
    textual data, but also how to use it for building advanced services. Through diagrams
    and concrete examples, I’ve tried to make the chapter easier to read and understand;
    please look at them carefully as you read to be sure that you grasp the key concepts.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章比其他章节要长一些，内容也相当密集。你需要通读全文，才能理解不仅如何从文本数据中构建知识图谱，而且如何利用它来构建高级服务。通过图表和具体示例，我试图使本章更容易阅读和理解；请在阅读时仔细查看它们，以确保你掌握了关键概念。
- en: '12.1 Knowledge graphs: Introduction'
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.1 知识图谱：简介
- en: In chapter 3, I introduced the concept of using knowledge to transform data
    into insights and wisdom, using the series of images in figure 12.1\. As you can
    see, the process is all about connecting information, and a graph is the ideal
    representation.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在第3章中，我介绍了利用知识将数据转化为洞察和智慧的概念，使用图12.1中的系列图像。正如你所见，整个过程都是关于连接信息，而图是理想的表示方式。
- en: '![CH12_F01_Negro](../Images/CH12_F01_Negro.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F01_Negro](../Images/CH12_F01_Negro.png)'
- en: Figure 12.1 Illustration by David Somerville, based on the original by Hugh
    McLeod
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.1 由David Somerville绘制，基于Hugh McLeod的原始作品
- en: Knowledge graphs solve, in an unbeatable way, the recurring problem in machine
    learning of knowledge representation (think about all the times I’ve spoken about
    knowledge representation in this book!) and provide the best tool for knowledge
    reasoning, such as drawing inferences from the data represented.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱以一种无与伦比的方式解决了机器学习中知识表示的反复问题（想想我在本书中所有关于知识表示的讨论！），并为知识推理提供了最佳工具，例如从表示的数据中得出推论。
- en: Knowledge graphs came into the limelight when Google announced, in a seminal
    blog post[¹](#pgfId-1007711) from 2012, that its knowledge graph would enable
    users to search for *things, not strings*. Previously, the post explained, when
    a user searched for “Taj Mahal,” this string was split into two parts (words)
    of equal importance, and the search engine tried to match them both with all the
    documents it had. But the reality in such a case is that the user isn’t searching
    for two separate words but for a concrete “thing,” be it the beautiful monument
    in Agra, an Indian restaurant, or the Grammy Award-winning musician. Celebrities,
    cities, geographical features, events, movies—these are the kinds of results users
    want to get when they are searching for specific objects. Getting back information
    that is really relevant to the query dramatically changes the user experience
    during search.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 当谷歌在2012年一篇开创性的博客文章[¹](#pgfId-1007711)中宣布其知识图谱将使用户能够搜索“事物，而不是字符串”时，知识图谱进入了公众视野。该文章解释说，当用户搜索“Taj
    Mahal”时，这个字符串被分成两个同等重要的部分（单词），搜索引擎试图将它们与所有文档匹配。但实际情况是，用户并不是在搜索两个独立的单词，而是在搜索一个具体的“事物”，无论是位于阿格拉的美丽纪念碑、一家印度餐厅，还是获得格莱美奖的音乐家。名人、城市、地理特征、事件、电影——这些都是用户在搜索特定对象时希望得到的结果类型。返回与查询真正相关的信息，极大地改变了搜索过程中的用户体验。
- en: Google applied this approach to its core business, web search. Among other features,
    the most noticeable one from the user’s perspective is that in addition to a ranked
    list of web pages resulting from the keyword (string-based) search, Google also
    shows a structured knowledge card on the right—a small box containing summarized
    information about entities that might correspond to the search term (figure 12.2).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌将这种方法应用于其核心业务——网络搜索。从用户的角度来看，最引人注目的功能之一是除了由关键词（基于字符串）搜索产生的按排名排列的网页列表之外，谷歌还显示了一个结构化的知识卡片——一个包含关于可能与搜索词相对应的实体（如图12.2）的总结信息的盒子。
- en: '![CH12_F02_Negro](../Images/CH12_F02_Negro.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F02_Negro](../Images/CH12_F02_Negro.png)'
- en: Figure 12.2 The current results for the string “taj mahal”. Notice the box on
    the right.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.2 当前对于字符串“taj mahal”的结果。注意右边的盒子。
- en: 'Search was the beginning. A few years after Google’s blog post, knowledge graphs
    started entering the field of information retrieval in general: databases, the
    Semantic Web, artificial intelligence (AI), social media, and enterprise information
    systems [Gomez-Perez et al., 2017]. Over the years, various initiatives have extended
    and developed the initial concepts introduced by Google. Additional features,
    new ideas and insights, and a range of applications have been introduced, and
    as a result, the concept of the knowledge graph has grown much broader, with new
    methods and technologies.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索只是开始。在谷歌发布博客文章后的几年里，知识图谱开始进入信息检索领域：数据库、语义网、人工智能（AI）、社交媒体和企业信息系统 [Gomez-Perez
    et al., 2017]。多年来，各种倡议扩展和发展了谷歌最初引入的概念。引入了额外的功能、新的想法和见解，以及一系列应用，因此，知识图谱的概念已经变得非常广泛，包括新的方法和技术。
- en: 'But what is a knowledge graph? What makes a normal graph a knowledge graph?
    There is no gold standard, universally accepted definition, but my favorite is
    the one given by Gomez-Perez et al.: “A knowledge graph consists of a set of interconnected
    typed entities and their attributes.”'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 但什么是知识图谱？什么使一个普通图成为知识图谱？没有黄金标准，普遍接受的定义，但我最喜欢的是Gomez-Perez等人给出的定义：“知识图谱由一组相互连接的具有类型的实体及其属性组成。”
- en: According to this definition, the basic unit of a knowledge graph is the representation
    of an entity, such as a person, organization, or location (such as the Taj Mahal
    example), or perhaps a sporting event or a book or movie (as in the case of a
    recommendation engine). Each entity might have various attributes. For a person,
    those attributes would include name, address, birth date, and so on. Entities
    are connected by relations. A person *works for* a company, for example, and a
    user likes a page or follows another user. Relations can also be used to bridge
    two separate knowledge graphs.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这个定义，知识图谱的基本单元是实体的表示，例如人、组织或地点（如泰姬陵的例子），或者可能是体育赛事、书籍或电影（如在推荐引擎的情况下）。每个实体可能有各种属性。对于人来说，这些属性可能包括姓名、地址、出生日期等。实体通过关系相互连接。例如，一个人可能“为”一家公司工作，或者用户喜欢一个页面或关注另一个用户。关系也可以用来连接两个不同的知识图谱。
- en: Compared with other knowledge-oriented information systems, knowledge graphs
    are distinguished by their particular combination of
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他以知识为导向的信息系统相比，知识图谱的特点在于其独特的组合
- en: Knowledge representation structures and reasoning, such as languages, schemas,
    standard vocabularies, and hierarchies among concepts
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 知识表示结构和推理，例如语言、模式、标准词汇表以及概念之间的层次结构
- en: Information management processes (how information is ingested and transformed
    into a knowledge graph)
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信息管理流程（信息如何被摄取并转换为知识图谱）
- en: Accessing and processing patterns, such as querying mechanisms, search algorithms,
    and pre- and postprocessing techniques
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问和处理模式，例如查询机制、搜索算法以及预处理和后处理技术
- en: As we have done throughout this book, we will use a label property graph (LPG)
    to represent a knowledge graph—a break with usual practice, because knowledge
    graphs generally are represented with a Resource Description Framework (RDF) data
    model. RDF is a W3C standard for data exchange on the web, designed as a language
    for representing information about web resources, such as the title, author, and
    modification date of a web page or copyright and licensing information about a
    web document. But by generalizing the concept of a web resource, we can also use
    RDF to represent information about other things, such as items available from
    an online shop or a user’s preferences for information delivery [RDF Working Group,
    2004].
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在整本书中所做的那样，我们将使用标签属性图（LPG）来表示知识图谱——这与常规做法不同，因为知识图谱通常使用资源描述框架（RDF）数据模型来表示。RDF是W3C的互联网数据交换标准，设计为一种表示关于网络资源信息（如网页的标题、作者和修改日期，或关于网络文档的版权和许可信息）的语言。但通过泛化网络资源的概念，我们也可以使用RDF来表示关于其他事物（如在线商店可用的商品或用户对信息传递的偏好）的信息
    [RDF工作组，2004]。
- en: The underlying structure of any expression in RDF is a collection of triples,
    each consisting of a subject, a predicate, and an object. Each triple can be represented
    as a node-arc-node link, also called an *RDF graph*, in which the *subject* is
    a resource (a node in the graph), the *predicate* is the arc (a relationship),
    and the *object* is another node or a literal value. Figure 12.3 shows what this
    structure looks like.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: RDF中任何表达式的底层结构是一组三元组，每个三元组由一个主语、一个谓语和一个宾语组成。每个三元组可以表示为一个节点-弧-节点链接，也称为*RDF图*，其中*主语*是一个资源（图中的一个节点），*谓语*是弧（一个关系），*宾语*是另一个节点或一个字面值。图12.3显示了这种结构的外观。
- en: '![CH12_F03_Negro](../Images/CH12_F03_Negro.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F03_Negro](../Images/CH12_F03_Negro.png)'
- en: Figure 12.3 Simple RDF graph
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.3 简单的RDF图
- en: RDF is intended for situations in which the information it encodes needs to
    be processed by applications, rather than being displayed only to people. It provides
    a common framework for expressing this information so that it can be exchanged
    between applications without loss of meaning. This framework makes it a bit more
    verbose and less readable by humans than an LPG, which is designed to store complex
    graphs by using relationships and nodes with their properties in a compact way.
    Take a look at the example in figure 12.4, from a blog post[²](#pgfId-1007726)
    by Jesús Barrasa.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: RDF旨在处理其编码的信息需要由应用程序处理的情况，而不是仅向人们展示。它提供了一个通用的框架来表示此类信息，以便在没有意义损失的情况下在应用程序之间交换。这个框架使得它比LPG（通过使用具有属性的关系和节点以紧凑的方式存储复杂图而设计的）更冗长，对人类来说可读性较差。请参考图12.4中的示例，这是耶稣·巴拉斯在一篇博客文章[²](#pgfId-1007726)中的内容。
- en: '![CH12_F04_Negro](../Images/CH12_F04_Negro.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F04_Negro](../Images/CH12_F04_Negro.png)'
- en: Figure 12.4 LPG versus RDF graph
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.4 LPG与RDF图对比
- en: LPGs are more flexible and powerful than RDF graphs for representing knowledge
    graphs. It’s worth pointing out that this chapter focuses on how to build and
    access a knowledge graph created out of textual data. Building knowledge graphs
    from structured data is definitely a simpler task, and it’s what we have done
    already in multiple scenarios covered so far.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: LPG在表示知识图谱方面比RDF图更灵活、更强大。值得注意的是，本章重点介绍如何构建和访问由文本数据创建的知识图谱。从结构化数据构建知识图谱绝对是一个更简单的任务，这是我们已经在之前多个场景中完成过的。
- en: When a knowledge graph is obtained from the text, using techniques that we will
    explore in this chapter, it is postprocessed or enriched to extract insights and
    wisdom. Figure 12.5 illustrates the whole process, which we will work through
    in this chapter.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当从文本中获取知识图谱时，使用本章将要探讨的技术，它会被后处理或增强以提取洞察和智慧。图12.5展示了整个过程，我们将在本章中详细探讨。
- en: '![CH12_F05_Negro](../Images/CH12_F05_Negro.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F05_Negro](../Images/CH12_F05_Negro.png)'
- en: Figure 12.5 Mental map of the whole process
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.5 整个过程的心智地图
- en: 'The techniques for extracting structures out of text will be extended with
    the recognition of the key entities and the relationships among them. These techniques
    are critical for the creation of a knowledge graph. Because the same entities
    and relationships tend to recur in the documents belonging to a domain-specific
    corpus, it’s important to infer a generic model that represents this information,
    abstracting from the instances appearing in the text. This model is known as an
    *inferred knowledge graph*. The result of this process represents the knowledge
    base that can be used in multiple advanced machine learning techniques or, more
    generally, AI applications. One of the most common approaches for representing
    the knowledge base is via a *semantic network*: a set of concepts and predefined
    connections among them.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 从文本中提取结构的技术将通过识别关键实体及其之间的关系得到扩展。这些技术对于知识图谱的创建至关重要。因为相同的实体和关系往往在特定领域语料库的文档中反复出现，因此推断一个代表这种信息的通用模型非常重要，该模型从文本中出现的实例中抽象出来。这个模型被称为**推断知识图谱**。此过程的结果代表了一个知识库，它可以用于多种高级机器学习技术，或者更普遍地说，用于AI应用。表示知识库最常见的方法之一是通过**语义网络**：一组概念及其之间预定义的连接。
- en: '12.2 Knowledge graph building: Entities'
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.2 知识图谱构建：实体
- en: A key element for building a knowledge graph out of textual data is recognizing
    entities in the text. Suppose that you have a set of documents (from Wikipedia,
    for example), and you are tasked with finding the names of the people or other
    entities relevant to your domain in those documents, such as locations, organizations,
    and so on. When this information is extracted, you have to make it easily accessible
    via a graph for further exploration.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 从文本数据构建知识图谱的一个关键元素是识别文本中的实体。假设你有一组文档（例如来自维基百科），你被要求在这些文档中找到与你领域相关的人或其他实体的名称，如地点、组织等。当提取此信息时，你必须通过图使其易于访问，以便进一步探索。
- en: 'The task of *named entity recognition (NER**)* involves finding each mention
    of a named entity (NE) in the text and labeling its type [Grishman and Sundheim,
    1996]. What constitutes an NE type depends on the domain; people, places, and
    organizations are common, but NEs can include a variety of other structures, such
    as street addresses, times, chemical formulas, mathematical formulas, gene names,
    names of celestial bodies, products, and brands—in short, whatever is relevant
    to your application. In generic terms, we can define an NE as anything that can
    be referred to with a proper name that is relevant to the domain of analysis we
    are considering. If you are processing electronic medical records for some healthcare
    use case, for example, you may want to recognize patients, diseases, treatments,
    medicines, hospitals, and so on. As the previous examples suggest, many named
    entities have an extralinguistic structure, which means that they’re composed
    according to rules that differ from general language rules. The term is also commonly
    extended to include things that aren’t entities per se: numerical values (such
    as prices), dates, times, currencies, and so on. Each NE is related to a specific
    type that specifies its class, such as PERSON, DATE, NUMBER, or LOCATION. The
    domain is critical because the same entity can be related to different types based
    on the domain.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 命名实体识别（NER）的任务涉及在文本中找到每个命名实体（NE）的提及并标记其类型[Grishman and Sundheim, 1996]。NE类型的构成取决于领域；人物、地点和组织是常见的，但NE可以包括各种其他结构，例如街道地址、时间、化学公式、数学公式、基因名称、天体名称、产品以及品牌——简而言之，任何与您应用相关的信息。用通用术语来说，我们可以将NE定义为任何可以用适当名称指代且与我们要考虑的分析领域相关的东西。例如，如果您正在处理用于某些医疗用例的电子病历，您可能希望识别患者、疾病、治疗方法、药物、医院等等。正如前面的例子所暗示的，许多命名实体具有超语言结构，这意味着它们是根据与通用语言规则不同的规则组成的。这个术语也通常被扩展到包括不是实体本身的东西：数值（如价格）、日期、时间、货币等等。每个NE都与一个特定类型相关联，该类型指定了其类别，例如PERSON、DATE、NUMBER或LOCATION。领域至关重要，因为同一个实体可以根据领域与不同的类型相关联。
- en: 'When all the NEs in a text have been extracted, they can be linked in sets
    corresponding to real-world entities, allowing us to infer, for example, that
    mentions of “United Airlines” and “United” refer to the same company [Jurafsky
    and Martin, 2019]. Suppose that you have the following document:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个文本中的所有命名实体（NE）都被提取出来后，它们可以与对应于现实世界实体的集合相链接，这使我们能够推断，例如，“United Airlines”和“United”的提及指的是同一家公司[Jurafsky
    and Martin, 2019]。假设您有以下文档：
- en: '*Marie Curie, wife of Pierre Curie, received the Nobel Prize in Chemistry in
    1911\. She had previously been awarded the Nobel Prize in Physics in 1903.*'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**Marie Curie，Pierre Curie的妻子，于1911年获得了诺贝尔化学奖。她之前在1903年获得了诺贝尔物理学奖**。'
- en: The set of entities to extract would vary according to the relevant entities
    for your analysis goals, but supposing that we are interested in all the entities,
    a proper NE recognition result should be able to recognize and classify the names
    “Marie Curie” and “Pierre Curie” as person names, the names “Nobel Prize in Chemistry”
    and “Nobel Prize in Physics” as prize names, and “1911” and “1903” as dates. This
    task is straightforward for humans but not so simple for machines. You can try
    it by using an NE visualizer like the open source displaCy.[³](#pgfId-1007741)
    If you paste in the previous text and select all the entity labels, you’ll get
    a result like figure 12.6.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 需要提取的实体集合将根据您分析目标的相关实体而变化，但假设我们对所有实体都感兴趣，一个合适的命名实体识别（NE）结果应该能够识别并将“Marie Curie”和“Pierre
    Curie”识别为人物名称，将“Nobel Prize in Chemistry”和“Nobel Prize in Physics”识别为奖项名称，以及将“1911”和“1903”识别为日期。这项任务对人类来说很简单，但对机器来说并不那么简单。您可以通过使用像开源displaCy这样的NE可视化器来尝试它。[³](#pgfId-1007741)
    如果您粘贴前面的文本并选择所有实体标签，您将得到类似于图12.6的结果。
- en: '![CH12_F06_Negro](../Images/CH12_F06_Negro.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F06_Negro](../Images/CH12_F06_Negro.png)'
- en: Figure 12.6 The results from the displaCy NE visualizer with our sample text
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.6 displaCy NE可视化器对我们样本文本的结果
- en: Interestingly, without any tuning, the service was able to recognize all the
    entities in the sentences (although the prizes are classified as “works of art”).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，无需任何调整，该服务就能识别句子中的所有实体（尽管奖项被分类为“艺术品”）。
- en: Adding the NER task to the graph model is straightforward. As shown in figure
    12.7, the best solution is to add new nodes with the label NamedEntity that contain
    the entities extracted from the document. These nodes are linked to any related
    TagOccurrence nodes (“Marie Curie,” for example, is a single name composed of
    two TagOccurrence nodes, “Marie” and “Curie”). The NamedEntity nodes are created
    for each occurrence of the entities in the text, so “Marie Curie” can appear more
    than one time as different nodes. Later in this section, we will see how to link
    them to a common node that represents the specific entity that represents “Marie
    Curie” as a Person.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 将 NER 任务添加到图模型中很简单。如图 12.7 所示，最佳解决方案是添加带有标签 NamedEntity 的新节点，其中包含从文档中提取的实体。这些节点链接到任何相关的
    TagOccurrence 节点（例如，“Marie Curie”是一个由两个 TagOccurrence 节点“Marie”和“Curie”组成的单个名称）。为文本中实体的每个出现创建
    NamedEntity 节点，因此“Marie Curie”可以以不同的节点出现多次。在本节稍后，我们将看到如何将它们链接到一个表示“Marie Curie”作为人的特定实体的公共节点。
- en: '![CH12_F07_Negro](../Images/CH12_F07_Negro.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F07_Negro](../Images/CH12_F07_Negro.png)'
- en: Figure 12.7 Our schema extended with NER
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.7 带有 NER 的扩展模式
- en: Extending our data model from chapter 11 for storing the results of an NER task
    in a graph is quite simple. The following listing contains the changes required
    to extract NEs from the text and store them. The full code is in ch12/04_spacy_ner_schema.py
    and ch12/text_processors.py files.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 从第 11 章扩展我们的数据模型以在图中存储 NER 任务的输出相当简单。以下列表包含从文本中提取 NE 并存储所需的更改。完整代码位于 ch12/04_spacy_ner_schema.py
    和 ch12/text_processors.py 文件中。
- en: Listing 12.1 Adding the NER task to the model
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.1 将 NER 任务添加到模型中
- en: '[PRE0]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Adds the new step to extract and store the named entities
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 添加新的步骤以提取和存储命名实体
- en: ❷ The function takes the result of the NLP process and extracts the named entities.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 该函数接收 NLP 处理的结果并提取命名实体。
- en: ❸ The function stores the entities in the graph.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 函数将实体存储在图中。
- en: ❹ The query loops over the entities, and for each, it creates a new node and
    links it to the tags composing the NE.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 查询遍历实体，并为每个实体创建一个新节点，并将其链接到组成 NE 的标签。
- en: As you can see, the changes required are minimal, both in terms of the pipeline
    and the code for saving the result of the NER task. spaCy has its own models for
    basic NEs, and these models are what we used in this code, but it also offers
    the opportunity to train new NER models by passing samples of annotated sentences.
    Refer to the spaCy documentation[⁴](#pgfId-1007756) to see how.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，所需的更改在管道和保存 NER 任务结果的代码方面都很小。spaCy 有自己的基本 NE 模型，这是我们在这段代码中使用过的，但它还提供了通过传递标注句子样本来训练新的
    NER 模型的机会。请参阅 spaCy 文档[⁴](#pgfId-1007756) 了解详情。
- en: In written and spoken language, if a person, a location, or some other relevant
    entity is mentioned several times, later mentions often won’t repeat the full
    name. Thus, in the example given earlier, we might see instead an abbreviated
    name (“Mme. Curie”), a pronoun (“she”), or a descriptive phrase (“the noted scientist”).
    The problem at this point is how to identify such relationships and extract them
    from plain text.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在书面和口语语言中，如果提到一个人、一个地点或其他相关实体多次，后续提及通常不会重复完整的名称。因此，在前面给出的例子中，我们可能会看到缩写名称（“Mme.
    Curie”）、代词（“她”）或描述性短语（“著名的科学家”）。此时的问题是如何识别这些关系并将它们从普通文本中提取出来。
- en: 'We can develop our scenario further by adding another requirement. Suppose
    that you would like to improve your access patterns by also considering all the
    mentions of named entities. As a concrete example, in the following text we would
    like to connect “she” with “Marie Curie”:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过添加另一个要求来进一步开发我们的场景。假设您想通过考虑所有命名实体的提及来改进您的访问模式。作为一个具体的例子，在以下文本中，我们希望将“她”与“Marie
    Curie”连接起来：
- en: '*Marie Curie received the Nobel Prize in Physics in 1903\. She became the first
    woman to win the prize and the first person—man or woman—to win the award twice.*'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '*玛丽·居里在 1903 年获得了诺贝尔物理学奖。她成为了第一个获奖的女性，也是第一个两次获奖的人—无论是男性还是女性。*'
- en: 'In natural language processing (NLP), this task is accomplished by *co-reference
    resolution*, which is defined as the problem of identifying relationships between
    entity references in a text, whether they are represented by nouns or pronouns
    [Mihalcea and Radev, 2011]. Resolving pronoun references involves a combination
    of constraints and preferences: the antecedent must match the pronoun (in number,
    gender, and so on), and as antecedents, we prefer subjects over objects, words
    that are closer to the pronoun in the text, and words that can plausibly appear
    in the context of the pronoun [Grishman, 2015]. Typical algorithms for co-reference
    resolution attempt to identify chains of references by using rule-based systems,
    although the final criteria are based on gathering statistics over a large number
    of texts from the corpus or using machine learning classifiers.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在自然语言处理（NLP）中，这个任务是通过*共指消解*来完成的，它被定义为识别文本中实体引用之间关系的问题，无论它们是否由名词或代词表示[Mihalcea
    和 Radev, 2011]。解决代词引用涉及约束和偏好的组合：先行词必须与代词匹配（在数量、性别等方面），并且作为先行词，我们更倾向于主语而不是宾语，文本中离代词更近的词，以及可能在代词语境中出现的词[Grishman,
    2015]。典型的共指消解算法试图通过使用基于规则的系统来识别引用链，尽管最终标准是基于对语料库中大量文本的统计或使用机器学习分类器。
- en: Linking general co-referential noun phrases is a more difficult task. Some easy
    cases use the same noun several times, but most examples require some knowledge
    of the world, based on observing what phrases have been used elsewhere to refer
    to a specific entity. This approach allows us to resolve a phrase like “the noted
    Polish scientist” to “Marie Curie,” or “the prize” to “the Nobel Prize.”
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 链接一般的共指名词短语是一个更困难的任务。一些简单的情况使用相同的名词多次，但大多数例子需要一些世界知识，基于观察在其他地方用来指代特定实体的短语。这种方法允许我们将“著名的波兰科学家”解析为“玛丽·居里”，或将“奖项”解析为“诺贝尔奖”。
- en: Proposed graph-based approaches to co-reference resolution [Nicolae and Nicolae,
    2006; Ng, 2009] use a graph-cut algorithm to approximate the correct assignment
    of references to entities in a text, but these methods are outside the scope of
    this book because the NLP libraries used in our codebase have their own implementations
    for co-reference implementation. The focus here is on how to model the results
    of such a task and get the most out of it.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 提出的基于图的方法用于共指消解[Nicolae 和 Nicolae, 2006; Ng, 2009]使用图割算法来近似文本中实体引用的正确分配，但这些方法超出了本书的范围，因为我们在代码库中使用的
    NLP 库有自己的共指实现。这里的重点是讨论如何建模此类任务的结果并充分利用它。
- en: Consider our sample text. Figure 12.8 shows the result obtained by using the
    Stanford CoreNLP test service mentioned in chapter 11.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑我们的示例文本。图12.8显示了使用第11章中提到的斯坦福 CoreNLP 测试服务获得的结果。
- en: '![CH12_F08_Negro](../Images/CH12_F08_Negro.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F08_Negro](../Images/CH12_F08_Negro.png)'
- en: Figure 12.8 Co-reference results
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.8 共指结果
- en: We can represent these connections in our graph model by linking pronouns and
    other references to the real entities they are referring to. Figure 12.9 shows
    our model extended to include co-reference resolution. As usual, graphs provide
    the flexibility necessary to adapt the model to new needs with minimum effort
    while keeping the previous access patterns working effectively.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将代词和其他引用链接到它们所指向的真实实体来在我们的图模型中表示这些连接。图12.9显示了扩展到包括共指消解的模型。通常，图提供了必要的灵活性，以最小的努力适应新的需求，同时保持先前的访问模式有效运行。
- en: '![CH12_F09_Negro](../Images/CH12_F09_Negro.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F09_Negro](../Images/CH12_F09_Negro.png)'
- en: Figure 12.9 Graph model with co-reference resolution
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.9 带有共指消解的图模型
- en: The extended graph model connects NamedEntity nodes by using the MENTIONS relationship.
    The changes in the code for storing the new co-references are shown in the following
    listing. The full code is in ch12/05_spacy_coref_schema.py and in ch12/text_ processors.py.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展的图模型通过使用 MENTIONS 关系连接命名实体节点。以下列表显示了存储新共指的代码更改。完整代码位于 ch12/05_spacy_coref_schema.py
    和 ch12/text_processors.py。
- en: Listing 12.2 Extracting co-references
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.2 提取共指
- en: '[PRE1]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ Adds a new co-ref element in spaCy’s NLP pipeline, a neural network implementation
    of co-reference resolution (see [https://github.com/huggingface/neuralcoref](https://github.com/huggingface/neuralcoref)).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在 spaCy 的 NLP 管道中添加一个新的共指元素，这是一个共指消解的神经网络实现（见[https://github.com/huggingface/neuralcoref](https://github.com/huggingface/neuralcoref)）。
- en: ❷ Extracts the co-references and stores them in the graph
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 提取共指并将它们存储在图中
- en: ❸ Loops over the co-references found in the document and creates the dictionary
    for storing them in the graph
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 在文档中找到的共指上进行循环，并为在图中存储它们创建字典
- en: ❹ The query connects the named entities via MENTIONS.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 查询通过MENTIONS将命名实体连接起来。
- en: The co-reference relationships are useful for connecting all the mentions of
    the key NEs to the sources, even when their canonical names are not used.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 共指关系对于将所有关键NE的提及与来源连接起来很有用，即使它们的规范名称没有被使用。
- en: NEs and co-references play an important role in knowledge graph building. Both
    are first-class objects that represent occurrences in the text of relevant entities
    and their mutual relationships. But to improve the quality of the graph in terms
    of the knowledge we are able to extract from it, it is necessary to abstract from
    these occurrences in the text and identify the key entities that are referred
    to multiple times in the text. Natural language understanding systems (and humans)
    interpret linguistic expressions with respect to a *discourse model* [Karttunen,
    1969]—a mental model that the system constructs incrementally as it processes
    text from a corpus (or, in the case of a human hearer, from a dialogue), which
    contains representations of the entities referred to in the text, as well as properties
    of the entities and relations among them [Jurafsky and Martin, 2019]. We say that
    two mentions co-refer if they are associated with the same entity.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: NEs和共指在知识图谱构建中扮演着重要角色。它们都是一等对象，代表文本中相关实体及其相互关系的发生。但为了提高从图中提取知识的质量，有必要从这些文本发生中抽象出来，并识别出在文本中被多次提及的关键实体。自然语言理解系统（以及人类）根据*话语模型*
    [Karttunen, 1969]来解释语言表达——这是一个系统在处理语料库（或人类听者的情况，来自对话）中的文本时逐步构建的心理模型，其中包含文本中提及的实体的表示，以及实体的属性和它们之间的关系
    [Jurafsky and Martin, 2019]。我们说如果两个提及与同一实体相关联，则它们是共指的。
- en: The idea of the discourse model can be applied in the knowledge graph use case
    to simplify and improve access to the knowledge it embodies. As figure 12.10 shows,
    we can build a complement to the knowledge graph—the inferred knowledge graph
    mentioned in this chapter’s introduction—that contains unique representations
    of the entities referred to in the processed text, as well as their properties
    and the connections among them.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 话语模型的概念可以应用于知识图谱用例中，以简化并改进对其所体现知识的访问。如图12.10所示，我们可以构建知识图谱的补充——本章引言中提到的推断知识图谱——它包含处理文本中提及的实体的唯一表示，以及它们的属性和它们之间的关系。
- en: '![CH12_F10_Negro](../Images/CH12_F10_Negro.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F10_Negro](../Images/CH12_F10_Negro.png)'
- en: Figure 12.10 Knowledge graph with the inferred knowledge
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.10 包含推断知识的知识图谱
- en: Whereas the main body of the knowledge graph contains the decomposition of the
    text in the corpus and, eventually, the structured data reorganized in the graph
    model, this second part—connected to the first—distills key elements and relationships
    to provide answers to different questions and supports multiple services, eliminating
    the need to navigate the entire graph. This *inferred knowledge graph* contains
    an easy-to-share knowledge representation that is not directly connected to the
    specific instances (the documents) from which this knowledge is distilled.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然知识图谱的主体包含语料库中文本的分解，并最终在图模型中重新组织为结构化数据，但这一部分——与第一部分相连——提炼了关键元素和关系，以回答不同的问题并支持多种服务，消除了导航整个图的需要。这个*推断知识图谱*包含一个易于共享的知识表示，它不直接连接到从中提取此知识的特定实例（文档）。
- en: The following listing shows how this inference is applied after the co-reference
    resolution task to build the second part of the knowledge graph incrementally.
    The function is in ch12/text_processors.py called from ch12/06_spacy_entity_relationship_
    extraction.py.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的列表显示了在共指消解任务之后如何应用此推断来逐步构建知识图谱的第二部分。该函数在ch12/text_processors.py中调用，来自ch12/06_spacy_entity_relationship_extraction.py。
- en: Listing 12.3 Creating the inferred knowledge graph
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.3 创建推断知识图谱
- en: '[PRE2]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ The new step for extracting the inferred graph from the previous created graph
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从先前创建的图中提取推断图的步骤
- en: ❷ The first query creates entities out of the main named entities.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 第一个查询从主要命名实体创建实体。
- en: ❸ The second query creates connections to the main entities by using the co-reference
    connections available in the graph using MENTIONS.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 第二个查询通过使用图中可用的共指连接通过MENTIONS创建到主要实体的连接。
- en: With the code in listing 12.3, we have all the code necessary to extract the
    named entities and co-references in a text and to create this second layer of
    the knowledge graph. At this point, by using the code available in ch12/07_process_larger_corpus.py,
    you can import and process the MASC corpus we used in chapter 11 and start getting
    more insights out of it.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 使用列表12.3中的代码，我们有了从文本中提取命名实体和共指的所有必要代码，以及创建知识图谱的第二层。在此阶段，通过使用ch12/07_process_larger_corpus.py中可用的代码，您可以导入并处理第11章中使用的MASC语料库，并开始从中获得更多见解。
- en: Exercises
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 练习
- en: 'With the graph database we’ve created, perform the following operations via
    queries:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们创建的图数据库，可以通过查询执行以下操作：
- en: Find the distinct types of named entities created.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 找出创建的命名实体的不同类型。
- en: Count the occurrences of each type, order them in descending order, and take
    the first three.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算每种类型的出现次数，按降序排列，并取前三个。
- en: Count the occurrences of the Organization entities in the inferred knowledge
    graph. How many are there? There should be fewer because the system should aggregate
    them when creating the inferred graph.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算推断知识图谱中组织实体的出现次数。应该更少，因为系统在创建推断图时应将它们聚合。
- en: '12.3 Knowledge graph building: Relationships'
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.3 知识图谱构建：关系
- en: When the entities have been recognized, the next logical step is discerning
    relationships among the detected entities, which dramatically improves the quality
    of the knowledge graph in terms of the insights you can extract from it and the
    available access patterns. This step is key in creating a meaningful graph from
    a text because it allows you to create the connections between the entities and
    navigate them properly. The types of queries you can execute and, hence, the types
    of questions it can answer will increase significantly.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 当实体被识别后，下一步是辨别检测到的实体之间的关系，这在很大程度上提高了知识图谱的质量，包括您可以从中提取的见解和可用的访问模式。这一步在从文本创建有意义的图谱中至关重要，因为它允许您在实体之间建立联系并正确导航。您可以执行的查询类型以及因此可以回答的问题类型将显著增加。
- en: To decompose the text better and make it more understandable by machines and
    humans, suppose that you would like to identify relationships between the extracted
    entities that highlight connections among them—such as relationships between a
    prize and who it has been awarded to, or a company and who works for it.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地分解文本并使其更易于机器和人类理解，假设您想识别提取实体之间的关系，以突出它们之间的联系——例如，奖项与其获得者之间的关系，或公司与为其工作的人之间的关系。
- en: Answering questions such as the most probable diagnosis is based on the symptoms
    a patient has, or who has won a Nobel Prize in Physics requires you to identify
    not only specific entities, but also the connections among them. Different techniques
    exist for performing this task; some are more complex than others, and some require
    supervision (labeling sample relationships to create a training set). The earliest,
    still-common algorithm for relation extraction is based on lexicosyntactic patterns.
    It involves mapping some of the aforementioned syntactic relationships among tokens
    or specific sequences of tags into a set of relevant (for the use case) relations
    between key named entities.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 回答诸如根据患者症状最可能的诊断或谁获得了物理学诺贝尔奖等问题，需要您不仅识别特定实体，还要识别它们之间的关系。存在不同的技术来完成这项任务；有些比其他技术更复杂，有些需要监督（标记样本关系以创建训练集）。最早且至今仍常用的关系抽取算法基于词汇句法模式。它涉及将一些上述标记或特定标签序列之间的句法关系映射到一组与关键命名实体相关的（对于用例）关系。
- en: 'This task may seem to be a complex one, and in some circumstances, it is, but
    having a graph model helps a lot. A rough, simple approximation can be obtained
    by a set of semantic analysis rules, each of which maps a subgraph of the syntactic
    graph (such as a portion of the graph containing the syntactic relationships that
    relate key entities), anchored by some of the entity mentions, into a database
    relation applied to the corresponding entities. Consider, as a concrete example,
    the following sentence:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这个任务可能看起来很复杂，在某些情况下确实如此，但拥有图模型有很大帮助。可以通过一组语义分析规则获得一个粗略的简单近似，每个规则将句法图的子图（例如包含与关键实体相关句法关系的图的一部分）映射到数据库关系，这些关系应用于相应的实体。以下是一个具体的例子：
- en: '*Marie Curie received the Nobel Prize in Physics in 1903.*'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '*玛丽·居里在1903年获得了物理学诺贝尔奖*。'
- en: The syntactic analysis determines that “received” has the subject “Marie Curie”
    and the object “the Nobel Prize.” These dependencies can be visualized easily
    with the following code.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 句法分析确定“received”的主语是“玛丽·居里”，宾语是“诺贝尔物理学奖”。这些依存关系可以用以下代码轻松可视化。
- en: Listing 12.4 Visualizing dependencies
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.4 可视化依存关系
- en: '[PRE3]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Annotates a simple sentence
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 注释一个简单句子
- en: ❷ This option allows us to merge, for example, “Marie Curie” into a single entity
    in the visualization.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 此选项允许我们将“玛丽·居里”等合并为可视化中的单个实体。
- en: ❸ Creates a server instance that will allow us to visualize the result
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 创建一个服务器实例，这将允许我们可视化结果
- en: The result will look like figure 12.11.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 结果将类似于图12.11。
- en: '![CH12_F11_Negro](../Images/CH12_F11_Negro.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F11_Negro](../Images/CH12_F11_Negro.png)'
- en: Figure 12.11 Syntactic dependencies visualized with spaCy
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.11 使用spaCy可视化的句法依存关系
- en: A possible pattern would map this syntactic structure into the semantic predicate
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 一个可能的模式将把这个句法结构映射到语义谓词
- en: '[PRE4]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here, “receive” (considered in the lemmatized version) is an English verb, whereas
    RECEIVE_PRIZE is a relationship type (a semantic relation). Expressing these types
    of patterns is straightforward with a proper graph-based query language like Cypher.
    As an exercise, we will derive the graph we have. The sentence processed by the
    code we have produces the results shown in figure 12.12.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，“receive”（在词形还原版本中考虑）是一个英语动词，而RECEIVE_PRIZE是一个关系类型（一个语义关系）。使用像Cypher这样的适当基于图的查询语言表达这些类型的模式是直接的。作为一个练习，我们将推导出我们拥有的图。我们拥有的代码处理的句子产生了图12.12中所示的结果。
- en: '![CH12_F12_Negro](../Images/CH12_F12_Negro.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F12_Negro](../Images/CH12_F12_Negro.png)'
- en: Figure 12.12 Resulting graph after processing the sentence “Marie Curie received
    the Nobel Prize in Physics in 1903”
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.12 处理句子“玛丽·居里在1903年获得了诺贝尔物理学奖”后的结果图
- en: The task of finding all the subgraphs respecting the pattern we are looking
    for can be performed with the following query.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下查询可以执行寻找所有符合我们寻找模式的子图的任务。
- en: Listing 12.5 Search for subgraphs respecting the pattern we are looking for
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.5 搜索符合我们寻找模式的子图
- en: '[PRE5]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The result in our knowledge graph will look like figure 12.13.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知识图谱中的结果将类似于图12.13。
- en: '![CH12_F13_Negro](../Images/CH12_F13_Negro.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F13_Negro](../Images/CH12_F13_Negro.png)'
- en: Figure 12.13 The result of listing 12.5
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.13 列表12.5的结果
- en: Note that the pattern must specify the semantic types of the subject and object—that
    is, the entity type, such as Person as the subject and Prize as the object. (In
    our example, the type is “work of art”; having a better NER model would help.)
    But “receive” conveys many relations, and we don’t want instances of “receive”
    involving other types of arguments to be translated into the RECEIVE_PRIZE relationship.
    On the other side, large numbers of alternative patterns are needed to capture
    the wide range of expressions that could be used to convey this information, such
    as
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，模式必须指定主语和宾语的语义类型——即实体类型，例如以Person作为主语，Prize作为宾语。（在我们的例子中，类型是“艺术品”；拥有更好的NER模型会有所帮助。）但是，“receive”传达了许多关系，我们不希望涉及其他类型参数的“receive”实例被翻译成RECEIVE_PRIZE关系。另一方面，需要大量的替代模式来捕捉传达此类信息的广泛表达方式，例如
- en: '[PRE6]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Note that in the latter example, the recipient appears as the indirect object
    (“The Committee awarded the prize to Marie Curie.”). If we didn’t include a syntactic
    regularization step to convert passive sentences to active ones, we would also
    require a pattern for the passive form (“The prize was awarded to Marie Curie.”):'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在后一个例子中，获奖者作为间接宾语出现（“委员会将奖项授予玛丽·居里。”）。如果我们没有包括将被动句转换为主动句的句法正则化步骤，我们还需要一个被动形式的模式（“奖项被授予玛丽·居里。”）：
- en: '[PRE7]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: When these relationships have been extracted, they have to be stored in the
    graph model we designed. Figure 12.14 shows the changes to the schema required
    to add this new information.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 当这些关系被提取出来后，它们必须存储在我们设计的图模型中。图12.14显示了添加新信息所需的模式更改。
- en: '![CH12_F14_Negro](../Images/CH12_F14_Negro.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F14_Negro](../Images/CH12_F14_Negro.png)'
- en: Figure 12.14 Extended model with the relationships
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.14 带有关系的扩展模型
- en: The following listing shows the changes that are needed to gather the syntactic
    relationships, convert them to relationships of interest, and store them in our
    graph model. The full code is in ch12/06_spacy_entity_relationship_extraction.py
    and in ch12/text_processors.py.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表展示了为了收集句法关系、将它们转换为感兴趣的关系并存储到我们的图模型中所需的更改。完整的代码位于 ch12/06_spacy_entity_relationship_extraction.py
    和 ch12/text_processors.py 中。
- en: Listing 12.6 Extracting relationships from typed dependencies
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.6 从类型依存关系提取关系
- en: '[PRE8]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ An example of the possible rules that can be defined
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 可能定义的可能规则示例
- en: ❷ The new step for extracting relationships from the existing graph based on
    the rules defined
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 基于定义的规则从现有图中提取关系的步骤
- en: ❸ The query goes through the graph, navigating NEs and the relationships among
    the participants’ tags, and extracts the desired relationships.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 查询通过图进行，导航 NE 和参与者标签之间的关系，并提取所需的关系。
- en: 'As the code shows, the rules for converting semantic relationships to the relationships
    of interest must be listed, but enumerating these patterns poses a dual problem:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如代码所示，将语义关系转换为感兴趣的关系的规则必须列出，但列举这些模式提出了双重问题：
- en: There are many ways in which semantic relationships can be expressed, making
    it difficult to get good coverage by listing the patterns individually.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语义关系可以通过多种方式表达，这使得单独列出模式难以获得良好的覆盖率。
- en: Such rules might not capture all the distinctions required for a particular
    predicate in different domains. If we want to collect documents about military
    attacks, for example, we probably want to include instances of “strike” and “hit”
    in texts about conflicts, but not in sports stories. We might also want to require
    some arguments and make others optional.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些规则可能无法捕捉到特定领域特定谓词所需的所有区别。例如，如果我们想收集关于军事攻击的文档，我们可能希望在关于冲突的文本中包括“strike”和“hit”的实例，但不包括在体育故事中。我们还可能要求某些论点是必需的，而其他论点则是可选的。
- en: To get around these problems, other mechanisms may be used. Most of these approaches
    are supervised, which means that they require human support to learn. The most
    common approach is based on classifiers that determine the type of relationship
    (or lack of relationship) between NEs. It can be implemented by using different
    machine learning or deep learning algorithms, but what should the input to such
    a classifier be?
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些问题，可以使用其他机制。其中大部分方法都是监督式的，这意味着它们需要人类支持来学习。最常见的方法是基于分类器，它确定 NE 之间关系（或无关系）的类型。这可以通过使用不同的机器学习或深度学习算法来实现，但这样的分类器应该输入什么？
- en: Training the classifier requires a corpus annotated with entities and relations.
    First, we mark the entities in each document; then, for each pair of entities
    in a sentence, we either record the type of relation connecting them or note that
    they aren’t connected by a relation. The former are positive training instances,
    and the latter are negative training instances. After we’ve trained the classifier,
    we can extract the relationships in a new test document by applying it to all
    pairs of entity mentions that appear in the same sentence [Grishman, 2015]. Although
    it is effective, this approach has a big disadvantage related to the amount of
    data required during the training process.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 训练分类器需要一个标注了实体和关系的语料库。首先，我们在每个文档中标记实体；然后，对于句子中每一对实体，我们记录连接它们的关系的类型，或者记录它们之间没有关系。前者是正训练实例，后者是负训练实例。在训练了分类器之后，我们可以通过将其应用于同一句子中出现的所有实体提及对来提取新测试文档中的关系
    [Grishman, 2015]。尽管这种方法有效，但它有一个与训练过程中所需数据量相关的重大缺点。
- en: 'A third approach combines the pattern-based approach with the supervised approach,
    using pattern-based as a bootstrapping process: the relationships are inferred
    automatically from the patterns, which are used to train the classifier.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 第三种方法结合了基于模式的方法和监督方法，使用基于模式的方法作为引导过程：关系自动从模式中推断出来，这些模式用于训练分类器。
- en: Regardless of the approach you use for extracting the relationships, when they
    are stored as connections between the NEs in the knowledge graph representing
    the text, it is possible to project these relationships onto the inferred knowledge
    graph discussed earlier. In this case, the relationships should connect entities.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您使用哪种方法来提取关系，当它们作为表示文本的知识图中 NE（命名实体）之间的连接存储时，可以将这些关系投影到之前讨论的推断知识图上。在这种情况下，关系应连接实体。
- en: 'In the definition of the model, it’s important to bear in mind that it is necessary
    to trace back why that relationship has been created. An issue is that in most
    graph databases available today, including Neo4j, relationships can connect only
    two nodes. But in this case, we would like to connect many more, to point back
    to the source of the relationship. This problem has two solutions:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型的定义中，重要的是要记住，有必要追溯为什么创建了那种关系。一个问题是在今天大多数可用的图数据库中，包括Neo4j，关系只能连接两个节点。但在这个情况下，我们希望连接更多，以追溯到关系的源头。这个问题有两个解决方案：
- en: Add some information in the relationship as properties that will allow us to
    trace back to the origin of the connection between two entities, such as a list
    of IDs representing the NEs connected.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在关系中添加一些信息作为属性，这将使我们能够追溯两个实体之间连接的起源，例如表示连接的NEs的ID列表。
- en: Add nodes that represent the relationships. We can’t connect to relationships,
    but these Relationship nodes will materialize the connections between entities,
    and we will be able to connect them to other nodes.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加表示关系的节点。我们无法连接到关系，但这些关系节点将实体之间的连接具体化，我们将能够将它们连接到其他节点。
- en: The first option is less verbose in terms of number of nodes but much more complex
    to navigate, which is why the proposed schema (figure 12.15) follows the second
    approach.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种方案在节点数量方面不那么冗长，但导航起来要复杂得多，这就是为什么提出的模式（图12.15）遵循第二种方法。
- en: '![CH12_F15_Negro](../Images/CH12_F15_Negro.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F15_Negro](../Images/CH12_F15_Negro.png)'
- en: Figure 12.15 Extended inferred schema to include the relationships
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.15 扩展的推断模式以包括关系
- en: The creation of an inferred knowledge graph has a great impact on the navigability
    of your graph and the types of access patterns it supports. Suppose that you’ve
    processed a large corpus of texts like the one in our example with Marie Curie,
    and you would like to know who has won a Nobel Prize in Physics.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 推断知识图的创建对图的可导航性和它支持的访问模式类型有很大影响。假设你已经处理了一个像我们例子中关于居里夫人的大量文本语料库，并且你想知道谁获得了诺贝尔物理学奖。
- en: The following listing shows how to extend the code we already have for extracting
    entities from the text to infer relationships among entities in the inferred knowledge
    graph. The full code is in ch12/text_processors.py called from ch12/ 06_spacy_entity_
    relationship_extraction.py.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表显示了如何扩展我们已有的代码，从文本中提取实体，并在推断的知识图中推断实体之间的关系。完整的代码在ch12/text_processors.py中，从ch12/06_spacy_entity_relationship_extraction.py中调用。
- en: Listing 12.7 Extracting relationships and storing them in the inferred knowledge
    graph
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.7 从推断知识图中提取关系并将其存储
- en: '[PRE9]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ The new step for extracting the relationships of the inferred knowledge graph
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 提取推断知识图关系的新的步骤
- en: ❷ The query extracts the list of relationships created in previous steps and
    creates the evidence and the relationships in the inferred knowledge graph.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 查询提取在先前步骤中创建的关系列表，并在推断的知识图中创建证据和关系。
- en: At this point, after the text is processed and stored as described, the query
    needed to get the desired result will look like the following.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在此阶段，文本经过处理并按描述存储后，获取所需结果的查询将看起来如下。
- en: Listing 12.8 Getting the winners of the Nobel Prize in Physics
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.8 获取诺贝尔物理学奖获得者
- en: '[PRE10]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: From the rel node, it is possible also to find all the text that makes this
    relationship evident.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 从rel节点，也可以找到所有使这种关系显而易见的文本。
- en: The knowledge graph we have built represents the original content available
    in the corpus processed in a way that makes possible multiple types of searches
    and permits different access patterns and question answering. Most of these operations
    are impossible when we use the texts in their original format. Identifying NEs
    and the relationships among them enables queries that are not possible otherwise,
    and the inferred knowledge graph creates a second layer in which the distilled
    knowledge is easier to navigate. The graph is an abstraction that represents the
    key concepts in a text.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建的知识图以使原始内容在处理过的语料库中可用，并使多种类型的搜索和不同的访问模式及问答成为可能。当我们使用原始格式的文本时，大多数这些操作都是不可能的。识别NEs及其之间的关系使得查询成为可能，否则这些查询是不可能的，推断知识图创建了一个第二层，其中提炼的知识更容易导航。图是一个抽象，它代表了文本中的关键概念。
- en: 12.4 Semantic networks
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.4 语义网络
- en: The knowledge graph we’ve built so far contains a lot of information that has
    been extracted from the text and converted to knowledge that is ready to be used.
    Specifically, the inferred knowledge graph represents the distilled knowledge
    that has been extracted while more and more texts have been processed. At this
    point, it is relevant to investigate how concretely this knowledge graph can be
    used to deliver new advanced services to end users.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们迄今为止构建的知识图谱包含大量从文本中提取并转换为可用于使用的知识的信息。具体来说，推断出的知识图谱代表了在处理越来越多的文本时提取的浓缩知识。在此阶段，研究如何具体地使用这个知识图谱为最终用户提供新的高级服务是相关的。
- en: A knowledge graph is a representation of a knowledge base on top of which several
    types of automated reasoning and interesting features can be built. Knowledge
    representation and reasoning is a branch of symbolic AI that aims to design computer
    systems that are capable of reasoning (similar to humans) based on a machine-interpretable
    representation of the domain of interest. In this computational model, symbols
    serve as surrogates for physical objects, events, relationships, and other domain
    artifacts [Sowa, 2000].
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱是在知识库之上构建的表示，其上可以构建多种类型的自动化推理和有趣的功能。知识表示和推理是符号人工智能的一个分支，旨在设计能够基于感兴趣领域的机器可解释表示进行推理（类似于人类）的计算机系统。在这个计算模型中，符号作为物理对象、事件、关系和其他领域实体的替身
    [Sowa, 2000]。
- en: One of the most common ways to represent such knowledge bases is to use *semantic
    networks*—graphs whose nodes represent concepts and whose arcs represent relations
    between those concepts. Semantic networks provide a structural representation
    of statements about a domain of interest, or “a means to abstract from natural
    language, representing the knowledge that is captured in text in a form more suitable
    for computation” [Grimm et al., 2007].
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 表示此类知识库最常见的方法之一是使用*语义网络*——节点代表概念，弧代表这些概念之间关系的图。语义网络提供了关于感兴趣领域陈述的结构表示，或者“一种从自然语言中抽象出来的方法，以更适合计算的形式表示文本中捕获的知识”
    [Grimm et al., 2007]。
- en: Typically, concepts are chosen to represent the meaning of nouns in such a text,
    and relations are mapped to verb phrases. Let’s consider a concrete example we
    used earlier. The sentence
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，概念被选择来表示此类文本中名词的意义，关系被映射到动词短语。让我们考虑我们之前使用的一个具体例子。句子
- en: '*Marie Curie, the famous scientist, received the Nobel Prize in Physics in
    1903.*'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '*玛丽·居里，这位著名的科学家，在1903年获得了诺贝尔物理学奖。*'
- en: should generate the semantic network shown in figure 12.16.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 应生成图12.16所示的语义网络。
- en: '![CH12_F16_Negro](../Images/CH12_F16_Negro.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F16_Negro](../Images/CH12_F16_Negro.png)'
- en: Figure 12.16 A simple semantic network
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.16 一个简单的语义网络
- en: This structure is exactly the one created for the inferred knowledge graph.
    The only difference is that we materialized the relationships for keeping track
    of the sources, which is necessary if we want to know why such relationships are
    created. So the inferred knowledge graph is a semantic network—a simplified version
    of one because in our schema, we materialize the relationships to keep track of
    the source of each inferred relationship.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结构正是为推断出的知识图谱所创建的。唯一的区别是我们将关系实体化以跟踪来源，这在想要知道为什么创建这些关系时是必要的。因此，推断出的知识图谱是一个语义网络——因为在我们模式中，我们将关系实体化以跟踪每个推断关系的来源，这是一个简化的版本。
- en: For that reason, in our mental map we consider extracting the semantic network
    from the inferred knowledge graph as a specific process (as shown in figure 12.17),
    removing all the overhead related to the mapping of relationships to the source
    and keeping only the concepts and relationships that are relevant, such as by
    considering how often they appear in the original corpus.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在我们的心智图中，我们将从推断出的知识图谱中提取语义网络视为一个特定的过程（如图12.17所示），移除所有与关系映射到来源相关的开销，仅保留相关的概念和关系，例如通过考虑它们在原始语料库中出现的频率。
- en: '![CH12_F17_Negro](../Images/CH12_F17_Negro.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F17_Negro](../Images/CH12_F17_Negro.png)'
- en: 'Figure 12.17 Mental map: extracting the semantic network'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.17 心智图：提取语义网络
- en: The content of a semantic network depends on the concepts and relationships
    that are relevant to the domain of interest and to the specific service the application
    should deliver at the end. In our case, the semantic network is the inferred knowledge
    graph extracted from the current big graph. During this process of extraction,
    it’s possible to simplify the graph a bit, such as by removing the Relationship
    nodes and replacing them with proper relationships.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 语义网络的内容取决于与感兴趣领域和应用程序应提供的特定服务相关的概念和关系。在我们的案例中，语义网络是从当前的大图中提取的推断知识图谱。在这个过程中，可以稍微简化一下图，例如通过删除关系节点并用适当的关系来替换它们。
- en: Sometimes, using the corpus you have is not enough to build a proper semantic
    network that can fulfill all your needs. Luckily, publicly available generic semantic
    networks exist. One of the most widely used is ConceptNet 5,[⁵](#pgfId-1007771)
    described by its creators as “a knowledge representation project, providing a
    large semantic graph that describes general human knowledge and how it is expressed
    in natural language” [Speer and Havasi, 2013]. The knowledge represented in the
    graph is collected from a variety of sources, including expert-created resources,
    crowdsourcing, and games. The aim of ConceptNet is to improve natural language
    applications by enabling them to better understand the meanings behind the words
    people use [Speer et al., 2017]. Figure 12.18, from the website, shows how it
    works.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，使用你拥有的语料库不足以构建一个能够满足所有需求的有效语义网络。幸运的是，存在可公开获取的通用语义网络。其中最广泛使用的是ConceptNet
    5[⁵](#pgfId-1007771)，其创造者将其描述为“一个知识表示项目，提供了一个大型语义图，描述了普遍的人类知识和它在自然语言中的表达方式” [Speer
    and Havasi, 2013]。图中表示的知识来自各种来源，包括专家创建的资源、众包和游戏。ConceptNet的目标是通过使它们能够更好地理解人们使用词语背后的含义来改善自然语言应用[Speer
    et al., 2017]。图12.18，来自网站，展示了它是如何工作的。
- en: '![CH12_F18_Negro](../Images/CH12_F18_Negro.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F18_Negro](../Images/CH12_F18_Negro.png)'
- en: Figure 12.18 ConceptNet 5 as described on its website
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.18 ConceptNet 5 如其在网站上的描述
- en: The ConceptNet 5 API is quite straightforward to use. If you would like to know
    more about Marie Curie, for example, you can call the URL
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: ConceptNet 5 API的使用非常简单。例如，如果你想了解更多关于玛丽·居里的信息，你可以调用以下URL
- en: '[PRE11]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'and get the following answer:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 并得到以下答案：
- en: '[PRE12]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This answer tells you immediately that Marie Curie’s other name is Marya Sklodowoska.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 这个答案立即告诉你玛丽·居里的另一个名字是玛丽亚·斯克洛多夫斯卡。
- en: 'It’s interesting to look at ConceptNet at this point in the chapter for a few
    reasons:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章的这个点上研究ConceptNet有几个原因：
- en: 'It’s created in exactly the same way described in the text, which validates
    our path so far. As you can see from the schema in figure 12.18, it integrates
    all the key concepts: the knowledge graph, the semantic network, AI, NLP, and
    so on.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是以与文本中描述的完全相同的方式创建的，这验证了我们迄今为止的路径。如图12.18中的架构所示，它集成了所有关键概念：知识图谱、语义网络、人工智能、自然语言处理等等。
- en: If you don’t have enough information in your corpus to build a proper knowledge
    graph, and the domain you are referring to is a common one, you can use ConceptNet
    to fill the gaps. If you are processing news articles from online sources, and
    you get only the names of cities in the text, such as “Los Angeles,” you can query
    ConceptNet to find the states where the cities are located (in this case, “California”).[⁶](#pgfId-1007786)
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你没有足够的信息在你的语料库中构建一个适当的知识图谱，而你参考的领域是一个常见的领域，你可以使用ConceptNet来填补空白。如果你正在处理来自在线来源的新闻文章，并且你只得到文本中的城市名称，例如“洛杉矶”，你可以查询ConceptNet来找到这些城市所在的州（在这种情况下，“加利福尼亚”）。[⁶](#pgfId-1007786)
- en: 'I love it. It’s such a good resource for understanding text and extending a
    knowledge graph that I use it often, in many projects. It’s simple and free to
    use, and quite fast: for the best speeds you can download it or, better, import
    it in a Neo4j instance.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我喜欢它。这是一个理解文本和扩展知识图谱的好资源，我在很多项目中经常使用它。它简单易用，免费，而且相当快：为了获得最佳速度，你可以下载它，或者更好的是，将其导入Neo4j实例中。
- en: Figure 12.19, from the paper by Speer and Havasi [2013] introducing the latest
    iteration of ConceptNet, describes the main relationships available and how they
    connect different components in the text. It clearly shows that the approach is
    similar to what it is proposed in this book. In this figure, *NP* stands for *noun
    phrase*, *VP* for *verb phrase*, and *AP* for *adjectival phrase*.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.19，来自Speer和Havasi [2013]的论文，介绍了ConceptNet的最新迭代，描述了主要关系及其如何连接文本中的不同组件。它清楚地表明，这种方法与本书中提出的方法相似。在此图中，*NP*代表*名词短语*，*VP*代表*动词短语*，*AP*代表*形容词短语*。
- en: '![CH12_F19_Negro_Covert_to_table](../Images/CH12_F19_Negro_Covert_to_table.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F19_Negro_Covert_to_table](../Images/CH12_F19_Negro_Covert_to_table.png)'
- en: Figure 12.19 Table from Speer and Havasi [2013] showing which key relationships
    are available in ConceptNet 5
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.19 来自Speer和Havasi [2013]的表格，展示了ConceptNet 5中哪些关键关系是可用的
- en: Accessing ConceptNet 5 via Python is quite simple, as shown in the following
    listing. You can use the requests library to get the content.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 通过Python访问ConceptNet 5非常简单，如下面的列表所示。你可以使用requests库来获取内容。
- en: Listing 12.9 Accessing ConceptNet from Python
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.9 通过Python访问ConceptNet
- en: '[PRE13]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Exercises
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 练习
- en: Play a bit with the code in listing 12.9 to see different ways to process the
    results. The example given here is only a suggestion.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表12.9中的代码上稍作实验，以查看不同的处理结果。这里给出的示例只是一个建议。
- en: 12.5 Unsupervised keyword extraction
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.5 无监督关键词提取
- en: NER is not the only way to recognize key elements in a text. Any text has certain
    words and phrases—not always related to NEs—that are more important than others
    because they express key concepts related to the content of the entire document,
    paragraph, or sentence. These words and phrases are generally referred to as *keywords*,
    and they provide enormous support in dealing with a big corpus.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 命名实体识别（NER）并不是识别文本中关键元素的唯一方法。任何文本都有一些特定的单词和短语——并不总是与命名实体（NEs）相关——它们比其他单词和短语更重要，因为它们表达了与整个文档、段落或句子内容相关的关键概念。这些单词和短语通常被称为*关键词*，它们在处理大型语料库时提供了巨大的支持。
- en: Companies of any size have to manage and access huge amounts of data to provide
    advanced services for their end users or to handle their internal processes. The
    bulk of this data is usually stored in the form of text. The ability to process
    and analyze this enormous source of knowledge represents a competitive advantage,
    but often, even providing simple and effective access to it is a complex task
    due to the unstructured nature of the textual data and the size of the problem.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 任何规模的公司都必须管理和访问大量数据，以向最终用户提供高级服务或处理其内部流程。这些数据的大部分通常以文本的形式存储。处理和分析这一巨大知识来源的能力代表了一种竞争优势，但通常，由于文本数据的非结构化性质和问题规模，即使提供简单有效的访问也是一个复杂任务。
- en: Suppose that you would like to provide effective access to a large corpus of
    documents (emails, web pages, articles, and so on) by identifying the main concepts,
    organizing indexes, and providing an adequate visualization. *Keyword extraction*—the
    process of identifying and selecting the words and small phrases that best describe
    a document—is vital to this task. In addition to constituting useful entries for
    building indexes for a corpus, the keywords you extract can be used to classify
    text and in some cases can serve as a simple summary for a given document. A system
    for automatic identification of important terms in text can be used for several
    purposes, such as
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你希望通过识别主要概念、组织索引和提供适当的可视化来有效地访问大量文档（电子邮件、网页、文章等）。*关键词提取*——识别和选择最能描述文档的单词和小短语的过程——对于这项任务至关重要。除了构成构建语料库索引的有用条目外，你提取的关键词还可以用于对文本进行分类，在某些情况下还可以作为给定文档的简单摘要。用于自动识别文本中重要术语的系统可用于多种目的，例如
- en: Identifying named entities that a trained NER model is not capable of recognizing
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别训练好的NER模型无法识别的命名实体
- en: Creating domain-specific dictionaries (in this case, also using the extracted
    NEs)
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建特定领域的词典（在这种情况下，也使用提取的NEs）
- en: Extending the inferred knowledge graph with frequent and recurring keywords
    and connections with the entities
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过频繁和重复的关键词以及与实体的连接扩展推断出的知识图谱
- en: Creating indexes and using the key terms to boost results when the user is looking
    for some specific keywords
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建索引并使用关键术语在用户查找特定关键词时提升结果
- en: Keywords play an important role in the process of building a knowledge graph,
    improving the quality (in terms of knowledge and access patterns) of the final
    result. So how do you get them? When you use unsupervised techniques, such as
    the one discussed in this section, the task of keyword extraction doesn’t even
    require human support!
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 关键词在构建知识图谱的过程中起着重要作用，提高了最终结果的质量（从知识和访问模式的角度来看）。那么，如何获取它们呢？当使用本节讨论的无监督技术时，关键词提取的任务甚至不需要人工支持！
- en: 'This section describes a method for keyword extraction[7](#pgfId-1007802) that
    uses a graph model representing the relationships between tags or concepts in
    the documents. The solution starts from a graph-based unsupervised technique called
    TextRank. Thereafter, the quality of extracted keywords is greatly improved by
    using a typed dependency graph and other tricks that are used to filter out meaningless
    phrases, or to extend keywords with adjectives and nouns to describe the text
    better. It is worth noting that although the proposed approach is unsupervised,
    the final results are comparable in quality to those achieved with supervised
    approaches. This algorithm is preferred in this book for a few reasons:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 本节描述了一种用于关键词提取[7](#pgfId-1007802)的方法，该方法使用一个表示文档中标签或概念之间关系的图模型。解决方案从基于图的无监督技术TextRank开始。此后，通过使用类型依赖图和其他技巧（用于过滤掉无意义的短语，或用形容词和名词扩展关键词以更好地描述文本）大大提高了提取关键词的质量。值得注意的是，尽管提出的方法是无监督的，但最终结果的质量与监督方法达到的质量相当。本书中偏好使用此算法有几个原因：
- en: It is purely based on graph techniques and algorithms that we’ve discussed already,
    such as PageRank.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它完全基于我们之前讨论过的图技术和算法，例如PageRank。
- en: It uses syntactic dependencies that we analyzed in detail in chapter 11.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它使用了我们在第11章中详细分析的句法依赖关系。
- en: The quality of the results is excellent, even when compared with supervised
    algorithms.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果的质量非常出色，即使与监督算法相比也是如此。
- en: The TextRank algorithm, introduced by Mihalcea and Tarau [2004], is a relatively
    simple unsupervised method of text summarization that is directly applicable to
    the topic-extraction task. Its objective is to retrieve keywords and construct
    key phrases that are most descriptive of a given document by building a graph
    of word co-occurrences and ranking the importance of individual words by using
    the PageRank algorithm. Figure 12.20 shows how this co-occurrence graph is created.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: Mihalcea和Tarau于2004年提出的TextRank算法是一种相对简单的无监督文本摘要方法，它可以直接应用于主题提取任务。其目标是通过对单词共现构建图并使用PageRank算法对单个单词的重要性进行排序，检索关键词并构建最能描述给定文档的关键短语。图12.20显示了这种共现图是如何创建的。
- en: '![CH12_F20_Negro](../Images/CH12_F20_Negro.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F20_Negro](../Images/CH12_F20_Negro.png)'
- en: 'Figure 12.20 The key concept in TextRank: converting the text to a co-occurrence
    graph'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.20 TextRank的关键概念：将文本转换为共现图
- en: The structure of the algorithm presented by Mihalcea and Tarau is summarized
    in figure 12.21.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: Mihalcea和Tarau提出的算法结构总结在图12.21中。
- en: '![CH12_F21_Negro](../Images/CH12_F21_Negro.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F21_Negro](../Images/CH12_F21_Negro.png)'
- en: Figure 12.21 The key steps of the TextRank algorithm
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.21 TextRank算法的关键步骤
- en: 'The key steps of the algorithms are as follows:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的关键步骤如下：
- en: Preselect relevant words from the NLP annotated text. Each document is tokenized
    and annotated. These processed words are basic lexical units, or tags. A configurable
    stop-word list and a syntactic filter are applied to refine the selection to the
    most relevant lexical units. The syntactic filter selects only nouns and adjectives,
    following Mihalcea and Tarau’s observation that even human annotators tend to
    use nouns rather than verb phrases to summarize documents.
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从NLP标注文本中预选相关词汇。每个文档都被分词并标注。这些处理过的词汇是基本的词汇单位，或称为标签。应用一个可配置的停用词列表和句法过滤器来细化选择，以获得最相关的词汇单位。句法过滤器仅选择名词和形容词，遵循Mihalcea和Tarau的观察，即即使是人工标注者也倾向于使用名词而不是动词短语来总结文档。
- en: '*Create a graph of tag co-occurrences*. Filtered tags are ordered based on
    their positions in the document, and co-occurrence relationships are built between
    adjacent tags, following the natural word flow in the text. This step introduces
    the relations between syntactic elements of the document into the graph. By default,
    only tags that appear next to each other can have a co-occurrence relationship.
    In the sentence “Pieter eats fish,” no co-occurrence edge is created because “eats”
    is a verb that didn’t pass the syntactic filter. But if the size of the co-occurrence
    window is changed from the default of 2 to 3, “Pieter” and “fish” will become
    connected. Finally, each co-occurrence edge is assigned a weight property indicating
    the number of times the two tags co-occurred within the given document. The graph
    obtained at this point looks like figure 12.20.'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*创建标签共现的图*。过滤后的标签根据它们在文档中的位置排序，并在相邻标签之间建立共现关系，遵循文本中的自然词流。这一步将文档的句法元素之间的关系引入到图中。默认情况下，只有相邻出现的标签才能有共现关系。在句子“Pieter
    eats fish”中，没有创建共现边，因为“eats”是一个没有通过句法过滤的动词。但如果将共现窗口的大小从默认的2改为3，则“Pieter”和“fish”将连接起来。最后，每个共现边都分配一个权重属性，表示两个标签在给定文档中共现的次数。此时得到的图看起来像图12.20。'
- en: '*Run undirected weighted PageRank*. The undirected PageRank algorithm is run
    on weighted co-occurrence relationships to rate nodes (tags) based on their importance
    in the graph. Experiments with unweighted PageRank show that weights are useful
    for bringing forward important keywords.'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*运行无向加权PageRank*。在加权共现关系上运行无向PageRank算法，根据节点（标签）在图中的重要性对它们进行评分。无加权PageRank的实验表明，权重对于将重要关键词提前是有用的。'
- en: '*Save the top one-third of tags as keywords and identify key phrases*. The
    tags are ordered based on the PageRank ratings; then the top third (configurable)
    are taken as final keywords. If some of these selected tags are adjacent, they
    are collapsed into a key phrase.'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*将前三分之一的标签保存为关键词并识别关键短语*。标签根据PageRank评分排序；然后取前三分之一（可配置）作为最终关键词。如果这些选定的标签中的一些是相邻的，它们将被合并成一个关键短语。'
- en: At the end of this process, the identified keywords and key phrases are saved
    to the graph database via a DESCRIBES relationship between a Keyword node and
    the AnnotatedText node. The resulting graph will look like figure 12.22.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个过程结束时，通过关键词节点和AnnotatedText节点之间的DESCRIBES关系，将识别出的关键词和关键短语保存到图数据库中。得到的图将类似于图12.22。
- en: '![CH12_F22_Negro](../Images/CH12_F22_Negro.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F22_Negro](../Images/CH12_F22_Negro.png)'
- en: Figure 12.22 The graph model extended with keywords
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.22 带有关键词扩展的图模型
- en: Starting from the last version of the code that includes all the algorithms
    and techniques described so far, the following listing shows how to add this new
    algorithm to our growing project. The full code is in ch12/text_processors.py
    and ch12/ 08_spacy_ textrank_extraction.py.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 从包含迄今为止描述的所有算法和技术的新版本代码开始，以下列表显示了如何将这个新算法添加到我们不断增长的项目中。完整代码位于ch12/text_processors.py和ch12/08_spacy_textrank_extraction.py。
- en: Listing 12.10 TextRank applied
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.10 应用TextRank
- en: '[PRE14]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ❶ Adds the new step for extracting keywords
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 添加提取关键词的新步骤
- en: ❷ The function processes the annotated document, identifies the keywords, and
    stores them.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 该函数处理注释文档，识别关键词并将它们存储起来。
- en: ❸ Loops over the keywords found in the document, called chunks
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 在文档中找到的关键词循环，称为块
- en: ❹ Filters overlapping keywords and takes the longest one
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 过滤重叠的关键词并取最长的那个
- en: ❺ Creates new Keyword nodes and connects them to the document via DESCRIBES
    relationships
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 创建新的关键词节点并将它们通过DESCRIBES关系连接到文档
- en: The preceding code uses an existing plugin for spaCy, called pytextrank,[⁸](#pgfId-1007817)
    that implements the TextRank algorithm properly. For this sentence,
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码使用了spaCy的一个现有插件，名为pytextrank，[⁸](#pgfId-1007817)，它正确地实现了TextRank算法。对于这个句子，
- en: '*The Committee awarded the Nobel Prize in Physics to Marie Curie.*'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '*委员会将诺贝尔物理学奖授予玛丽·居里*。'
- en: 'it returns the following list of keywords (the numbers in parentheses are the
    rank assigned by the TextRank algorithm):'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 它返回以下关键词列表（括号中的数字是TextRank算法分配的排名）：
- en: The Committee (0.15)
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 委员会（0.15）
- en: Marie Curie (0.20)
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 玛丽·居里（0.20）
- en: The Nobel Prize in Physics (0.14)
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 诺贝尔物理学奖（0.14）
- en: Not bad, especially considering that we’re working with a single sentence. TextRank
    performs better on longer documents because it can consider how often specific
    words recur.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 还不错，尤其是考虑到我们只处理一个句子。TextRank在较长的文档上表现更好，因为它可以考虑到特定单词出现的频率。
- en: The initial results obtained with TextRank are quite promising, but the quality
    can be improved by using more insights about the text. At GraphAware, we have
    also implemented a TextRank algorithm, available in our open source NLP plugin
    for Neo4j.[⁹](#pgfId-1007832) The basic algorithm has been modified to take advantage
    of the typed dependency graph provided by Stanford CoreNLP.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 使用TextRank获得的初始结果相当有希望，但可以通过使用更多关于文本的见解来提高质量。在GraphAware，我们还实现了一个TextRank算法，可在我们的开源NLP插件Neo4j中使用。[⁹](#pgfId-1007832)
    基本算法已被修改，以利用Stanford CoreNLP提供的类型化依赖关系图。
- en: 'To improve the quality of automatic keyword extraction, the extended algorithm
    considers the typed dependencies *amod* and *nn*. An adjectival modifier (*amod*)
    of an NP is any adjectival phrase that serves to modify the meaning of the NP:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高自动关键词提取的质量，扩展算法考虑了类型化的依赖关系*amod*和*nn*。一个名词短语（NP）的形容词修饰语（*amod*）是指任何用于修饰NP意义的形容词短语：
- en: '[PRE15]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'A noun compound modifier (*nn*) of an NP is any noun that serves to modify
    the head noun:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 一个名词复合修饰语（*nn*）是指任何用于修饰中心名词的名词：
- en: '[PRE16]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'These typed dependencies can be used to improve the results of the TextRank
    algorithm. Consider a concrete example. The following key phrase has been extracted
    by TextRank by using the standard approach:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 这些类型化的依赖关系可以用来改进TextRank算法的结果。考虑一个具体的例子。以下关键短语是通过使用标准方法由TextRank提取的：
- en: '[PRE17]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Clearly, this phrase means nothing because both words are adjectives; a noun
    is missing. In this case, the noun is *equipment*. This omission might have happened
    because the noun was ranked below the threshold of one-third of the top words
    in the documents considered, and during the merge, such words were ignored. As
    a result, documents discussing the same topic—“*personal protective equipment”*—were
    not assigned any common key phrase.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，这个短语没有意义，因为两个词都是形容词；缺少一个名词。在这种情况下，名词是*装备*。这种遗漏可能是因为该名词在考虑的文档中的排名低于三分之一的最顶部单词的阈值，并且在合并过程中，这些单词被忽略。因此，讨论相同主题——“*个人防护装备*”——的文档没有被分配任何共同的关键短语。
- en: 'In this case, amod dependencies can help. In the text “personal protective
    equipment,” there are amod dependencies among the three words:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，amod依赖关系可以帮助。在文本“个人防护装备”中，三个词之间存在amod依赖关系：
- en: '[PRE18]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Specifying these dependencies means that during the merge phase we also have
    to take “equipment” because it is connected to words that appear in the top third
    of the results. Typed dependencies can be used not only to complete existing key
    phrases with missing tags, but also to remove key phrases that have no mutual
    relationships of type COMPOUND or amod. Therefore, the improved TextRank algorithm
    introduces two new principles:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 指定这些依赖关系意味着在合并阶段我们还需要考虑“装备”，因为它与出现在结果顶部三分之一的单词相关联。类型化依赖关系不仅可以用以补充缺少标签的现有关键短语，还可以删除没有COMPOUND或amod类型相互关系的短语。因此，改进的TextRank算法引入了两个新的原则：
- en: All tags in a key phrase candidate must be related through COMPOUND or amod
    dependency.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关键短语候选中的所有标签都必须通过COMPOUND或amod依赖关系相关联。
- en: If a neighboring tag was not ranked highly enough to be included in a key phrase
    by the original TextRank but is connected to one or more top-scoring words by
    COMPOUND or amod typed dependencies, that tag is added.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果一个相邻的标签由于排名不够高而没有被原始TextRank算法包含在关键短语中，但它通过COMPOUND或amod类型的依赖关系与一个或多个得分最高的词相关联，那么这个标签将被添加。
- en: The latter principle takes care of handling the previously mentioned shortcomings
    and also adds a higher level of detail.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 后者原则负责处理之前提到的缺点，并增加了更高的细节级别。
- en: With these small changes (and a few others not mentioned here, such as postfiltering
    based on tag part of speech or considering NEs and so on), the results obtained
    resemble the key phrases that many human annotators would use to describe given
    documents.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些小的变化（以及这里未提及的几个其他变化，例如基于标签词性的后过滤或考虑NEs等），得到的结果类似于许多人类标注者用来描述给定文档的关键短语。
- en: Thanks to its high accuracy, keyword extraction supports different types of
    analysis that can reveal a great deal of information about the corpus. The keywords
    extracted can be used in different ways to discover new insights about the documents
    in the corpus, including providing an index or even a summary of the contents
    of the documents.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其高精度，关键词提取支持不同类型的分析，可以揭示关于语料库的大量信息。提取的关键词可以用不同的方式来发现关于语料库中文档的新见解，包括提供索引或甚至文档内容的摘要。
- en: To prove this concept, let’s try working with the Wikipedia movie plots dataset.[^(10)](#pgfId-1007847)
    This dataset contains descriptions of 34,886 movies from around the world, including
    summaries of their plots. You can use the code available in ch12/08_spacy_textrank_
    extraction.py to import the full dataset. The dataset is large, so it will take
    some time to process it and store the results. Then you can obtain a list of the
    most frequent keywords with the following query.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 为了证明这一概念，让我们尝试使用维基百科电影情节数据集。[^(10)](#pgfId-1007847) 该数据集包含来自世界各地的34,886部电影描述，包括它们情节的摘要。您可以使用ch12/08_spacy_textrank_
    extraction.py中的代码导入完整的数据集。由于数据集很大，处理和存储结果将需要一些时间。然后，您可以使用以下查询获取最频繁的关键词列表。
- en: Listing 12.11 Get the list of the 100 most frequent keywords
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.11 获取100个最频繁关键词的列表
- en: '[PRE19]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The results are shown in figure 12.23.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如图12.23所示。
- en: '![CH12_F23_Negro](../Images/CH12_F23_Negro.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F23_Negro](../Images/CH12_F23_Negro.png)'
- en: Figure 12.23 Results of executing listing 12.11 on the database
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.23 执行列表12.11在数据库上的结果
- en: 'With even this simple query that considers the number of occurrences of keywords
    in the corpus, we can extract a lot of information about the content of our dataset:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是考虑语料库中关键词出现次数的这样一个简单查询，我们也能从数据集的内容中提取出大量信息：
- en: '*The* dominant topic is “love,” which appears as a keyword in a lot of plot
    summaries. This fact might reflect both the dominance of romance as a theme and
    users’ enthusiasm about the films they’re describing.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*主要*主题是“love”，这在许多情节摘要中作为关键词出现。这一事实可能反映了浪漫作为主题的统治地位以及用户对所描述电影的热情。'
- en: '*The terms “film”* and “*story”* appear quite often, which is to be expected
    because they are commonly used in describing the plot of a movie.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*“film”* 和 “*story*” 这些术语出现得相当频繁，这是可以预料的，因为它们在描述电影情节时被广泛使用。'
- en: The next-most-common keyword is “*police*,” suggesting that movies about crime
    are quite common.
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二常见的关键词是“*police*”，这表明关于犯罪的电影相当常见。
- en: Another interesting observation is that “man” appears to be much more common
    as a key component of the plot; “*woman”* is much lower in the ranking.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一个有趣的观察是，“man”似乎作为情节的关键组成部分出现得更为频繁；“*woman*”在排名中则要低得多。
- en: This simple example gives you an idea of how much information it is possible
    to extract about a corpus by considering only the keywords. In section 12.5.1,
    we’ll develop this idea further, but first consider the following exercise.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单的例子让您了解，仅通过考虑关键词，就可以从语料库中提取出多少信息。在12.5.1节中，我们将进一步发展这一想法，但首先考虑以下练习。
- en: Exercise
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 练习
- en: Play with the dataset, using not only the keywords, but also the NEs extracted
    from the text. Perform the same query by using NamedEntity instead of Keyword
    nodes. (Note that this change is not the only one you have to make in the query.)
    What observations can you make about the data?
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据集上玩耍，不仅使用关键词，还要使用从文本中提取的NE（命名实体）。通过使用NamedEntity节点而不是Keyword节点执行相同的查询。（注意，这并不是您在查询中必须做出的唯一更改。）您可以从数据中得出哪些观察？
- en: 12.5.1 Keyword co-occurrence graph
  id: totrans-263
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.5.1 关键词共现图
- en: Keywords provide a lot of knowledge in themselves, but we can extend their value
    further by considering them in combination. Keywords can be connected via relationships
    by considering the documents in which they occur together. This approach generates
    a co-occurrence graph of keywords (in which we have only nodes of type Keyword
    and the connections among them).
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 关键词本身提供了大量的知识，但通过考虑它们的组合，我们可以进一步扩展它们的价值。通过考虑它们共同出现的文档，关键词可以通过关系连接起来。这种方法生成了一个关键词共现图（其中我们只有关键词类型的节点以及它们之间的连接）。
- en: The concept of a co-occurrence graph has been used as a technique for graph
    construction in other scenarios (specifically, in the recommendation chapters).
    The resulting graph is full of information that can be used to analyze the original
    graph itself. In the case we are considering—keywords—this graph will look like
    figure 12.24.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 共现图的概念已被用作在其他场景中（特别是推荐章节）构建图的技巧。生成的图充满了可用于分析原始图本身的信息。在我们考虑的情况中——关键词——这个图将看起来像图12.24。
- en: '![CH12_F24_Negro](../Images/CH12_F24_Negro.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F24_Negro](../Images/CH12_F24_Negro.png)'
- en: Figure 12.24 Keyword co-occurrence graph
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.24 关键词共现图
- en: Such a graph can be obtained by running a specific query on the original graph.
    Once again, graphs and the available plugins and libraries allow you to avoid
    writing code for recurring tasks. In the following example, we are using the APOC
    library for Neo4j that we have already used extensively.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在原始图上运行特定查询可以获得这样的图。再次强调，图以及可用的插件和库允许你避免为重复性任务编写代码。在以下示例中，我们使用的是已经广泛使用的APOC库。
- en: Listing 12.12 Creating the co-occurrence graph
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.12 创建共现图
- en: '[PRE20]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: ❶ Depending on the size of the graph, this operation could take a long time.
    For this reason, I used apoc.periodic.submit, because it allows you to submit
    the following query as a background job. You can check the status by using “CALL
    apoc.periodic.list()”.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 根据图的大小，此操作可能需要很长时间。因此，我使用了apoc.periodic.submit，因为它允许你将以下查询作为后台作业提交。你可以通过使用“CALL
    apoc.periodic.list()”来检查状态。
- en: In this query, note the combination of the submit procedure, which causes the
    query to execute in the background, disconnected from the browser request, and
    the iterate procedure, which allows you to commit the results periodically and
    avoid having a single big transaction. You can check the status of the background
    job by using call apoc.periodic.list.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个查询中，请注意提交过程和迭代过程的组合，这导致查询在后台执行，与浏览器请求断开连接，并且允许你定期提交结果以避免单个大事务。你可以通过使用“CALL
    apoc.periodic.list”来检查后台作业的状态。
- en: Note also that we are filtering out the irrelevant keywords (those that appear
    fewer than 5 times, as specified by WHERE keyWeight > 5) and that we are considering
    the connections only if the pairs of keywords appear together at least 10 times
    (WHERE weight > 10). This approach allows us to create a proper co-occurrence
    graph in which the relevant information is even more evident.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们正在过滤掉不相关的关键词（那些出现次数少于5次的关键词，如WHERE keyWeight > 5所指定的）并且只有当关键词对至少一起出现10次时（WHERE
    weight > 10）我们才考虑这些连接。这种方法使我们能够创建一个合适的共现图，其中相关信息更加明显。
- en: Exercise
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 练习
- en: When the query has completed, explore the resulting knowledge graph by checking
    how the keywords are connected. You’ll notice that the graph is much denser.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 当查询完成后，通过检查关键词的连接来探索结果知识图。你会注意到图要密集得多。
- en: 12.5.2 Clustering keywords and topic identification
  id: totrans-276
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.5.2 关键词聚类和主题识别
- en: The co-occurrence graph contains a lot of new information that can be used to
    extract knowledge from text. The goal in our case is to extract insights from
    the processed texts (the plot summaries). We’ve already used keyword frequency
    to get some insights about the content of our dataset, but with the keyword co-occurrence
    graph, we’ll be better able to recognize the topics in the documents. Figure 12.25
    provides an overview of the steps necessary to get the list of topics.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 共现图包含大量可用于从文本中提取知识的新信息。在我们的案例中，目标是提取处理过的文本（情节摘要）的见解。我们已经使用关键词频率来获取关于我们数据集内容的一些见解，但通过关键词共现图，我们将能够更好地识别文档中的主题。图12.25提供了获取主题列表所需步骤的概述。
- en: '![CH12_F25_Negro](../Images/CH12_F25_Negro.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F25_Negro](../Images/CH12_F25_Negro.png)'
- en: Figure 12.25 Steps for extracting topics by using keyword extraction and community
    detection
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.25 使用关键词提取和社区检测提取主题的步骤
- en: The co-occurrence graph connects keywords that appear together in the same graph,
    so it is capable of aggregating multiple keywords into groups that represent the
    same types of movies. At least, we would like to prove that idea. The filters
    we used to create the co-occurrence graph (relevant keywords and relevant connections)
    are helpful in this phase because they do a good job of isolating the keywords
    in the co-occurrence graph.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 共现图连接了在同一图中一起出现的关键词，因此它能够将多个关键词聚合到代表相同类型电影的组中。至少，我们希望证明这个想法。我们用于创建共现图的过滤器（相关关键词和相关连接）在这个阶段是有帮助的，因为它们很好地隔离了共现图中的关键词。
- en: 'In chapter 10, I introduced a mechanism for identifying communities of people
    in a social network: the Louvain algorithm. The algorithm showed a high level
    of accuracy in identifying clusters, as well as high speed. Such an approach can
    also be applied to the co-occurrence graph to see what keyword clusters are the
    most relevant.'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 在第10章中，我介绍了一种识别社交网络中人群社区的方法：Louvain算法。该算法在识别聚类方面表现出高度的准确性以及高速率。这种方法也可以应用于共现图，以查看哪些关键词聚类是最相关的。
- en: 'In this case, to simplify the query for running the Louvain algorithm, we split
    the operation in two. The first query creates a sort of virtual graph in which
    we specify only the part of the graph that we are interested in: the co-occurrence
    graph. (Remember that we do have the full knowledge graph!) In this way, we can
    specify where we would like to perform the community detection algorithm, ignoring
    all the rest.'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，为了简化运行Louvain算法的查询，我们将操作分为两部分。第一个查询创建了一个虚拟图，我们只指定我们感兴趣的图的部分：共现图。（记住，我们确实拥有完整的知识图谱！）这样，我们可以指定在哪里执行社区检测算法，忽略所有其他部分。
- en: Listing 12.13 Creating a virtual graph in the knowledge graph
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.13 在知识图谱中创建虚拟图
- en: '[PRE21]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: With the virtual graph in hand, representing only the co-occurrence graph, it
    is possible to run the Louvain algorithm with the following simple query.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有表示仅包含共现图的虚拟图后，可以使用以下简单查询运行Louvain算法。
- en: Listing 12.14 Revealing communities by using Louvain
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.14 通过Louvain揭示社区
- en: '[PRE22]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This query should be quite fast because, as discussed in chapter 10, this algorithm
    is amazingly performant, and the Neo4j implementation is highly optimized. The
    community assigned to each keyword is saved as the community property in the related
    node; it contains the identifier of the community. At the end of this process,
    it is possible to explore the results by using the following query.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在第10章中讨论过，这个算法性能惊人，Neo4j实现高度优化，因此这个查询应该相当快。每个关键词分配的社区作为相关节点中的社区属性保存；它包含社区的标识符。在这个过程结束时，可以使用以下查询来探索结果。
- en: Listing 12.15 Getting the communities and the top 25 keywords for each community
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.15 获取社区和每个社区的顶级25个关键词
- en: '[PRE23]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The query first gets the list of keywords ordered by community (identified by
    the community identifier, communityId) and by frequency, then groups by community
    identifier, and takes only the top 25 keywords for each (the most relevant due
    to their frequency). The size of the community is used to order the final results,
    which are shown in figure 12.26\. They might surprise you!
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 查询首先根据社区（由社区标识符，communityId）和频率对关键词进行排序，然后按社区标识符分组，并只取每个社区的顶级25个关键词（由于它们的频率而最相关）。社区的大小用于对最终结果进行排序，这些结果在图12.26中显示。它们可能会让你感到惊讶！
- en: '![CH12_F26_Negro](../Images/CH12_F26_Negro.png)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![CH12_F26_Negro](../Images/CH12_F26_Negro.png)'
- en: Figure 12.26 Results of the community detection algorithm applied on the co-occurrence
    graph
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.26 应用在共现图上的社区检测算法的结果
- en: 'This example is only an extract, but it shows clearly the quality of the results.
    In each cluster, it’s easy to recognize the topic: movies about the world wars,
    sci-fi movies, sports-related movies, medieval movies, and finally Tom and Jerry
    movies.'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子只是一个摘录，但它清楚地展示了结果的质量。在每一个簇中，很容易识别主题：关于世界大战的电影、科幻电影、与体育相关的电影、中世纪电影，最后是汤姆和杰瑞电影。
- en: Exercise
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 练习
- en: Run listing 12.15, and explore the full list of results. Are you able to recognize
    the topics for all the results?
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 运行列表12.15，并探索完整的结果列表。你能否识别所有结果的主题？
- en: 12.6 Advantages of the graph approach
  id: totrans-297
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.6 图方法的优势
- en: The solution proposed in this chapter—the knowledge graph—cannot exist outside
    the context of a graph model, so we can’t really talk about the advantages of
    the graph approach over other available approaches. But as you have seen, representing
    data and information in the form of a graph empowers a range of solutions and
    services by making it easy to explore the knowledge hidden in the data. This approach
    is the best way to deliver AI solutions.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 本章提出的解决方案——知识图谱——不能存在于图模型之外，因此我们实际上无法谈论图方法相对于其他可用方法的优点。但是，正如你所看到的，以图的形式表示数据和信息通过使探索数据中隐藏的知识变得容易，从而赋予了一系列解决方案和服务。这种方法是提供AI解决方案的最佳方式。
- en: Specifically, a knowledge graph is a natural way to represent data in textual
    format, which is typically thought of as unstructured and hence hard to process.
    When the data is stored in such a way, the amount of knowledge that can be extracted
    and the types of analyses that can be performed on that data are endless.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，知识图谱是表示文本格式数据的自然方式，通常被认为是非结构化的，因此难以处理。当数据以这种方式存储时，可以从中提取的知识量和可以对数据进行的分析类型是无限的。
- en: We have seen how simple it is to navigate among the relationships extracted
    or through the mentions, how to create hierarchies of concepts in a semantic network,
    and how to use automatic keyword extraction in the co-occurrence graph to extract
    topics from the movie plots in our dataset. The same concepts would hold for any
    other type of corpus.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到如何在提取的关系或提及之间导航是多么简单，如何在语义网络中创建概念层次，以及如何使用共现图中的自动关键词提取从我们的数据集中的电影情节中提取主题。这些概念同样适用于任何其他类型的语料库。
- en: Summary
  id: totrans-301
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter is the last in the book; its aim is to show how what has been presented
    in this book finds its apotheosis in the knowledge graph. In this case, graphs
    are not a possible solution but the driving force, allowing information structuring,
    access patterns, and types of analysis and operations that would not otherwise
    be feasible.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 本章是本书的最后一章；其目的是展示本书中提出的内容如何在知识图谱中达到顶峰。在这种情况下，图不是可能的解决方案，而是驱动力，它允许信息结构化、访问模式以及类型分析和操作，这些在其他情况下是不可行的。
- en: Structured and unstructured data and information can coexist in this powerful
    knowledge representation, which can be used to feed more advanced services into
    your machine learning project than would be possible otherwise. The semantic network
    opens a whole range of new possibilities.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化和非结构化数据和信息可以共存于这种强大的知识表示中，这可以用来为你的机器学习项目提供比其他情况下更多的先进服务。语义网络开辟了一整系列新的可能性。
- en: In this chapter, you learned
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了
- en: How to extract NEs from a text and store them properly in a graph model
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何从文本中提取命名实体（NEs）并将其适当地存储在图模型中
- en: How to extract relationships between the NEs and model them in a graph
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何从命名实体（NEs）中提取关系并在图中对其进行建模
- en: 'How to infer key entities and relationships from different instances in the
    text and create a powerful knowledge representation: a semantic network'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何从文本的不同实例中推断关键实体和关系，并创建一个强大的知识表示：语义网络
- en: How to extract keywords from text in an unsupervised manner using a graph-based
    algorithm and store them in the knowledge graph you’ve created
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用基于图的算法以无监督的方式从文本中提取关键词并将它们存储在你创建的知识图谱中
- en: How to create a co-occurrence graph of keywords and process it
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何创建关键词共现图并对其进行处理
- en: How to identify key topics in a corpus by using only graph-powered techniques
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何仅使用图技术识别语料库中的关键主题
- en: I’d like to close by saying that this book is not the end of your journey—only
    the beginning of a new one. Now you have access to the main conceptual tools you
    need to use graphs properly in many contexts. This book cannot possibly answer
    all the questions you might have about graphs, of course, but I hope it has equipped
    you with the mental schemas necessary to approach machine learning projects from
    a different perspective.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 我想以这样的说法结束：这本书不是你旅程的终点——只是新旅程的开始。现在你有了在许多情况下正确使用图的主要概念工具。当然，这本书不可能回答你关于图可能有的所有问题，但我希望它已经为你提供了必要的心理模式，以便从不同的角度接近机器学习项目。
- en: References
  id: totrans-312
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[Gomez-Perez et al., 2017] Gomez-Perez, Jose Manuel, Jeff Z. Pan, Guido Vetere,
    and Honghan Wu. “Enterprise Knowledge Graph: An Introduction.” In *Exploiting
    Linked Data and Knowledge Graphs in Large Organisations*. Switzerland: Springer,
    2017: 1-14.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '[Gomez-Perez et al., 2017] Gomez-Perez, Jose Manuel, Jeff Z. Pan, Guido Vetere,
    和 Honghan Wu. “企业知识图谱：简介.” 在 *Exploiting Linked Data and Knowledge Graphs in Large
    Organisations* 中. 瑞士：Springer, 2017: 1-14.'
- en: '[Grishman, 2015] Grishman, Ralph. “Information Extraction.” *IEEE Intelligent
    Systems* 30:5 (2015): 8-15.'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '[Grishman, 2015] Grishman, Ralph. “信息提取.” *IEEE Intelligent Systems* 30:5 (2015):
    8-15.'
- en: '[Grishman and Sundheim, 1996] Grishman, Ralph, and Beth Sundheim. “Message
    Understanding Conference - 6: A Brief History.” *Proceedings of the 16th International
    Conference on Computational Linguistics* (1996): 466-471.'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '[Grishman and Sundheim, 1996] Grishman, Ralph, 和 Beth Sundheim. “消息理解会议 - 6：简史.”
    *第16届国际计算语言学会议论文集* (1996): 466-471.'
- en: '[Grimm et al., 2007] Grimm, Stephan, Pascal Hitzler, and Andreas Abecker. “Knowledge
    Representation and Ontologies.” In *Semantic Web Services: Concepts, Technology
    and Applications*. Berlin, Heidelberg: Springer, 2007: 51-106.'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '[Grimm et al., 2007] Grimm, Stephan, Pascal Hitzler, 和 Andreas Abecker. “知识表示和本体.”
    在 *Semantic Web Services: Concepts, Technology and Applications* 中. 柏林，海德堡：Springer,
    2007: 51-106.'
- en: '[Jurafsky and Martin, 2019] Jurafsky, Dan, and James H. Martin. *Speech and
    Language Processing: An Introduction to Natural Language Processing, Computational
    Linguistics, and Speech Recognition*. Upper Saddle River, NJ: Prentice Hall, 2019
    (3rd ed. draft, available at [https://web.stanford.edu/~jurafsky/slp3](https://web.stanford.edu/~jurafsky/slp3/)).'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '[Jurafsky 和 Martin，2019] Jurafsky, Dan, 和 James H. Martin. *语音和语言处理：自然语言处理、计算语言学和语音识别导论*.
    新泽西州上萨德尔河：Prentice Hall，2019（第3版草案，可在 [https://web.stanford.edu/~jurafsky/slp3](https://web.stanford.edu/~jurafsky/slp3/)
    获取）.'
- en: '[Karttunen, 1969] Karttunen, Lauri. “Discourse Referents.” *Proceedings of
    the 1969 Conference on Computational Linguistics* (1969): 1-38.'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '[Karttunen，1969] Karttunen, Lauri. “话语指称.” *第1969年计算语言学会议论文集* (1969): 1-38.'
- en: '[Mihalcea and Radev, 2011] Mihalcea, Rada, and Dragomir Radev. *Graph-Based
    Natural Language Processing and Information Retrieval*. New York: Cambridge University
    Press, 2011.'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '[Mihalcea 和 Radev，2011] Mihalcea, Rada, 和 Dragomir Radev. *基于图的自然语言处理和信息检索*.
    纽约：剑桥大学出版社，2011.'
- en: '[Mihalcea and Tarau, 2004] Mihalcea, Rada, and Paul Tarau. 2004, July. “TextRank:
    Bringing Order into Texts.” *Proceedings of the Conference on Empirical Methods
    in Natural Language Processing* (2004): 404-411.'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '[Mihalcea 和 Tarau，2004] Mihalcea, Rada, 和 Paul Tarau. 2004年7月. “TextRank: 将秩序带入文本.”
    *自然语言处理实证方法会议论文集* (2004): 404-411.'
- en: '[Ng, 2009] Ng, Vincent. 2009\. “Graph-Cut-Based Anaphoricity Determination
    for Co-Reference Resolution.” *Proceedings of Human Language Technologies: Conference
    of the North American Chapter of the Association of Computational Linguistics*
    (2009): 575-583.'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ng，2009] Ng, Vincent. 2009. “基于图割的共指消解指代性确定.” *人语言技术会议：北美计算语言学协会分会会议* (2009):
    575-583.'
- en: '[Nicolae and Nicolae, 2006] Nicolae, Cristina, and Gabriel Nicolae. “BESTCUT:
    A Graph Algorithm for Co-Reference Resolution.” *Proceedings of the 2006 Conference
    on Empirical Methods in Natural Language Processing* (2006): 275-283.'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '[Nicolae 和 Nicolae，2006] Nicolae, Cristina, 和 Gabriel Nicolae. “BESTCUT: 用于共指消解的图算法.”
    *第2006年自然语言处理实证方法会议论文集* (2006): 275-283.'
- en: '[RDF Working Group, 2004] “RDF Primer: W3C Recommendation 10 February 2004.”
    [https://www.w3.org/TR/rdf-primer](https://www.w3.org/TR/rdf-primer/).'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '[RDF 工作组，2004] “RDF 入门：W3C 建议书，2004年2月10日.” [https://www.w3.org/TR/rdf-primer](https://www.w3.org/TR/rdf-primer/).'
- en: '[Sowa, 2000] Sowa, John F. *Knowledge Representation: Logical, Philosophical,
    and Computational Foundations*. Pacific Grove, CA: Brooks Cole, 2000.'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '[Sowa，2000] Sowa, John F. *知识表示：逻辑、哲学和计算基础*. 加利福尼亚州太平洋 Grove: Brooks Cole,
    2000.'
- en: '[Speer and Havasi, 2013] Speer, Robyn, and Catherine Havasi. “ConceptNet 5:
    A Large Semantic Network for Relational Knowledge.” In *The People’s Web Meets
    NLP: Collaboratively Constructed Language Resources*, edited by Iryna Gurevych
    and Jungi Kim. Berlin, Heidelberg: Springer, 2013: 161-176.'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '[Speer 和 Havasi，2013] Speer, Robyn, 和 Catherine Havasi. “ConceptNet 5: 一个大型语义关系知识网络.”
    见 Iryna Gurevych 和 Jungi Kim 编著的 *人民的网络与自然语言处理：协作构建的语言资源*. 柏林，海德堡：Springer，2013:
    161-176.'
- en: '[Speer et al., 2017] Speer, Robyn, Joshua Chin, and Catherine Havasi. “ConceptNet
    5.5: An Open Multilingual Graph of General Knowledge.” *Proceedings of the 31st
    AAAI Conference on Artificial Intelligence* (2017): 4444-4451.'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: '[Speer 等人，2017] Speer, Robyn, Joshua Chin, 和 Catherine Havasi. “ConceptNet
    5.5: 一个开放的多语言通用知识图.” *第31届AAAI人工智能会议论文集* (2017): 4444-4451.'
- en: '* * *'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: ^(1.)[http://mng.bz/gxDE](https://shortener.manning.com/gxDE).
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: ^（1.）[http://mng.bz/gxDE](https://shortener.manning.com/gxDE).
- en: ^(2.)[http://mng.bz/eMjv](https://shortener.manning.com/eMjv).
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: ^（2.）[http://mng.bz/eMjv](https://shortener.manning.com/eMjv).
- en: ^(3.)[https://explosion.ai/demos/displacy-ent](https://explosion.ai/demos/displacy-ent).
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: ^（3.）[https://explosion.ai/demos/displacy-ent](https://explosion.ai/demos/displacy-ent).
- en: ^(4.)[https://spacy.io/usage](https://spacy.io/usage).
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: ^（4.）[https://spacy.io/usage](https://spacy.io/usage).
- en: ^(5.)[http://conceptnet.io](http://conceptnet.io).
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: ^（5.）[http://conceptnet.io](http://conceptnet.io).
- en: ^(6.)For this example, the query to use is [http://api.conceptnet.io/query?start=/c/en/los_angeles&rel=/r/PartOf](http://api.conceptnet.io/query?start=/c/en/los_angeles&rel=/r/PartOf).
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: ^（6.）在此示例中，要使用的查询是 [http://api.conceptnet.io/query?start=/c/en/los_angeles&rel=/r/PartOf](http://api.conceptnet.io/query?start=/c/en/los_angeles&rel=/r/PartOf).
- en: ^(7.)[http://mng.bz/pJD8](https://shortener.manning.com/pJD8).
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: ^（7.）[http://mng.bz/pJD8](https://shortener.manning.com/pJD8).
- en: ^(8.)[https://github.com/DerwenAI/pytextrank](https://github.com/DerwenAI/pytextrank).
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: ^（8.）[https://github.com/DerwenAI/pytextrank](https://github.com/DerwenAI/pytextrank).
- en: ^(9.)[https://github.com/graphaware/neo4j-nlp](https://github.com/graphaware/neo4j-nlp).
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: ^（9.）[https://github.com/graphaware/neo4j-nlp](https://github.com/graphaware/neo4j-nlp).
- en: ^(10.)[http://mng.bz/O1jR](https://shortener.manning.com/O1jR).
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: ^（10.）[http://mng.bz/O1jR](https://shortener.manning.com/O1jR).
