- en: Chapter 8\. Data Validation in Pipelines
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 8 章。管道中的数据验证
- en: Even in the best designed data pipeline, something is bound to go wrong. Many
    issues can be avoided, or at least mitigated, with good design of processes, orchestration,
    and infrastructure. To ensure the quality of and validity of the data itself,
    however, you’ll need to invest in data validation. It’s best to assume that untested
    data is not safe to use in analytics. This chapter discusses the principles of
    data validation throughout the steps of an ELT pipeline.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在设计最佳的数据管道中，某些事情也可能出错。通过良好的流程、编排和基础设施设计，可以避免或至少减轻许多问题。然而，要确保数据本身的质量和有效性，你需要投入数据验证。最好假设未经测试的数据在分析中使用时并不安全。本章讨论了在
    ELT 管道的各个步骤中进行数据验证的原则。
- en: Validate Early, Validate Often
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 早期验证，频繁验证
- en: Though well intentioned, some data teams leave data validation to the end of
    a pipeline and implement some kind of validation during transformation or even
    after all transformations are complete. In this design, they are working with
    the idea that the data analysts (who typically own the transform logic) are best
    suited to make sense of the data and determine if there are any quality issues.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有良好的意图，某些数据团队将数据验证留到管道末端，并在转换期间甚至在所有转换完成后实施某种验证。在这种设计中，他们认为数据分析师（通常拥有变换逻辑）最适合理解数据并确定是否存在任何质量问题。
- en: 'In such a design, the data engineers focus on moving data from one system to
    another, orchestrating pipelines, and maintaining the data infrastructure. Although
    that’s the role of a data engineer, there’s one thing missing: by ignoring the
    content of the data flowing through each step in the pipeline, they are putting
    trust in the owners of the source systems they ingest from, their own ingestion
    processes, and the analysts who transform the data. As efficient as such separation
    of responsibilities sounds, it’s likely to end with low data quality and an inefficient
    debugging process when quality issues are uncovered.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种设计中，数据工程师专注于将数据从一个系统移动到另一个系统，编排管道，并维护数据基础设施。尽管这是数据工程师的角色，但缺少一点：通过忽略流经管道中每个步骤的数据内容，他们将信任从中摄取的源系统所有者、自己的摄取过程以及转换数据的分析师。尽管这种责任分离听起来效率很高，但当发现质量问题时，调试过程可能效率低下。
- en: Finding a data quality issue at the end of a pipeline and having to trace it
    back to the beginning is a worst-case scenario. By validating at each step in
    a pipeline, you are more likely to find the root cause in the current step rather
    than a previous one.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在管道末端发现数据质量问题并追溯到起始点是最糟糕的情况。通过在管道的每个步骤进行验证，你更有可能在当前步骤找到根本原因，而不是之前的步骤。
- en: Though data engineers can’t be expected to have enough context to perform validation
    for every dataset, they can take the lead by writing noncontextual validation
    checks as well as providing the infrastructure and templates to enable those team
    members and stakeholders closer to each step in the pipeline to perform more specific
    validation.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管不能期望数据工程师具备足够的上下文来为每个数据集执行验证，但他们可以通过编写非上下文验证检查并提供基础设施和模板来引导那些接近管道每个步骤的团队成员和利益相关者执行更具体的验证。
- en: Source System Data Quality
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 源系统数据质量
- en: 'Given the large number of source systems that are ingested into a typical data
    warehouse, it’s likely that invalid data will make its way into the warehouse
    during data ingestion at some point. Though it may seem that invalid data of some
    sort would be found by the source system owner before it could be ingested, it’s
    often not the case for several reasons:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于将大量源系统摄取到典型数据仓库中，很可能在数据摄取过程中某个时刻会将无效数据引入到仓库中。尽管可能会认为在摄取之前，源系统所有者会发现某种形式的无效数据，但通常情况并非如此，原因有几个：
- en: Invalid data may not impact the functioning of the source system itself
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 无效数据可能不会影响源系统本身的功能。
- en: The logic of the source system application may work around issues such as duplicate/ambiguous
    records in a table by deduplicating at the application layer, or fill in NULL
    date values with a default in the application itself.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 源系统应用的逻辑可能会通过应用层对表中的重复/模糊记录进行去重复，或在应用本身中用默认值填充 NULL 日期值。
- en: The source system may function just fine when records are orphaned
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 源系统中的记录孤立时可能正常运行。
- en: For example, a `Customer` record might be deleted, but the `Order` records related
    to the customer may remain. Though the application might just ignore such `Order`
    records, this situation will certainly have an impact on the analysis of the data.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，可能会删除`Customer`记录，但与该客户相关的`Order`记录可能仍然存在。尽管应用程序可能会忽略这些`Order`记录，但这种情况肯定会影响数据分析。
- en: A bug that has not yet been found or fixed may actually exist in the source
    system
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在源系统中可能存在尚未发现或修复的错误
- en: I’ve encountered multiple instances in my career where a critical issue in a
    source system was identified by the data team!
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的职业生涯中，我遇到过多次数据团队识别源系统中关键问题的情况！
- en: Note
  id: totrans-15
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Regardless of the reason, the bottom line is that a data engineer should never
    assume that the data they are ingesting is free of quality issues, even if the
    resulting data loaded into the warehouse perfectly matches its source.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 无论原因如何，关键是数据工程师不应假设他们摄取的数据没有质量问题，即使加载到仓库中的数据完全匹配其来源。
- en: Data Ingestion Risks
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据摄取风险
- en: 'In addition to quality issues in the source system, there’s the possibility
    of the data ingestion process itself resulting in a data quality problem. Here
    are some common examples:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 除了源系统中的质量问题外，数据摄取过程本身可能导致数据质量问题。以下是一些常见例子：
- en: A system outage or timeout in the extract or load step of an ingestion
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 摄取中提取或加载步骤中的系统停机或超时
- en: Though at times such a situation will throw a hard error and halt the pipeline,
    in others a “silent” failure will result in a partially extracted or loaded dataset.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有时这种情况会引发严重错误并停止管道，但在其他情况下，“静默”故障将导致部分提取或加载数据集。
- en: A logical error in an incremental ingestion
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 增量摄取中的逻辑错误
- en: Recall from Chapters [4](ch04.xhtml#ch04) and [5](ch05.xhtml#ch05) the pattern
    for an incremental extract. The timestamp of the most recent record from a table
    in the data warehouse is read, and any records with a more recent timestamp in
    the source system are then extracted so they an be loaded into the warehouse.
    A logical error as simple as using a “greater than or equals” operator rather
    than a “greater than” in a SQL statement can result in duplicate records being
    ingested. There are numerous other possibilities such as inconsistencies in time
    zones across systems.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 从第 [4](ch04.xhtml#ch04) 章和第 [5](ch05.xhtml#ch05) 章回想起增量提取的模式。从数据仓库中读取表中最新记录的时间戳，然后提取源系统中时间戳更晚的任何记录，以便加载到数据仓库中。在
    SQL 语句中简单地使用“大于或等于”运算符而不是“大于”可能导致重复记录被加载。还有许多其他可能性，比如系统之间的时区不一致。
- en: Parsing issues in an extracted file
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 提取文件中的解析问题
- en: As you’ll recall from Chapters [4](ch04.xhtml#ch04) and [5](ch05.xhtml#ch05),
    it’s typical for data to be extracted from a source system, stored in a flat file
    such as a CSV, and then loaded from that file into a data warehouse. When data
    is translated from a source system into a flat file, there are times when it includes
    special characters or other character encoding that is unexpected. Depending on
    how the data engineer and the data warehouse loading mechanism handle such cases,
    it’s possible for records to be discarded or the data contained in the newly loaded
    records to be malformed.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如你在第 [4](ch04.xhtml#ch04) 章和第 [5](ch05.xhtml#ch05) 章中所述，从源系统中提取数据，存储在诸如 CSV
    这样的平面文件中，然后从该文件加载到数据仓库中是很典型的。当数据从源系统转换为平面文件时，有时会包含特殊字符或其他意外的字符编码。根据数据工程师和数据仓库加载机制处理这些情况的方式，可能会导致记录被丢弃或新加载的记录中的数据格式错误。
- en: Note
  id: totrans-25
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Like the assumption that source systems will present valid data, the assumption
    that a data ingestion “simply” extracts and loads data is a poor one.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 与假设源系统将呈现有效数据一样，假设数据摄取“仅仅”提取和加载数据是不合适的。
- en: Enabling Data Analyst Validation
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启用数据分析师验证
- en: When it comes to validating the data that’s been loaded into a data warehouse
    and the data that’s been transformed into data models, a data analyst is usually
    the best equipped to own validation. They are the ones who understand the business
    context of the raw data as well as in each data model (see [Chapter 6](ch06.xhtml#ch06)).
    However, it’s up to data engineers to provide analysts with the tools they need
    to define and execute data validation throughout a data pipeline. Of course, for
    less contextual validations such as row counts and duplicate records, data engineers
    should take part in validation early in the pipeline.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在验证已加载到数据仓库中的数据以及转换为数据模型的数据方面，数据分析师通常是最适合拥有验证权利的人。他们是了解原始数据和每个数据模型业务背景的人（见[第6章](ch06.xhtml#ch06)）。然而，数据工程师的任务是为分析师提供他们在数据管道中定义和执行数据验证所需的工具。当然，对于像行数统计和重复记录等较少上下文的验证，数据工程师应该在管道的早期参与验证过程中。
- en: The next section introduces a simplified framework that can be used by analysts
    and data engineers to implement data validation checks in a pipeline. The final
    section notes a few open source and commercial frameworks that can be used for
    the same purpose. Whatever tool you choose, it’s important to empower engineers
    and analysts with a reliable method of writing and executing validation tests
    while introducing as little friction as possible. Though everyone on a data team
    tends to agree that valid data is important, if the bar to implement validation
    is high, you’ll find that it will take a backseat to new development and other
    priorities.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的部分介绍了一个简化的框架，可以供分析师和数据工程师在管道中实现数据验证检查。最后一节提到了一些开源和商业框架，可以用于相同的目的。无论你选择哪种工具，重要的是为工程师和分析师提供一种可靠的方法来编写和执行验证测试，同时尽量减少摩擦。虽然数据团队中的每个人通常都同意有效的数据很重要，但如果实施验证的门槛很高，你会发现它会被新开发和其他优先事项所拖后腿。
- en: A Simple Validation Framework
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个简单的验证框架
- en: In this section, I define a fully functional data validation framework written
    in Python and designed to execute SQL-based data validation checks. Like other
    samples in this book, it’s highly simplified and lacks many features you’d expect
    in a production environment. In other words, it’s not intended to handle all of
    your data validation needs. However, my goal is for it to introduce the key concepts
    of such a framework while also sharing something that can be extended and improved
    to fit your infrastructure.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分中，我定义了一个完全功能的数据验证框架，用Python编写，旨在执行基于SQL的数据验证检查。像本书中的其他示例一样，它是高度简化的，并且缺少生产环境中所期望的许多功能。换句话说，它并不打算处理所有的数据验证需求。然而，我的目标是介绍这种框架的关键概念，同时分享一些可以扩展和改进以适应你的基础设施的东西。
- en: This simple version of the framework supports limited capabilities as far as
    what kind of outcomes can be checked in a validation test and how tests can be
    executed in bulk, but not much more. I note some possible additions to extend
    the framework later in this section if you want to use it as a starting point.
    Even if you choose to use an off-the-shelf framework, I believe there is value
    in understanding the concepts involved in this highly simplified approach.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简化版本的框架支持有限的功能，可以检查验证测试中可以检查的结果类型以及如何批量执行测试，但没有更多功能。如果你想将其用作起点，我在本节中还提到了一些可能的扩展来扩展该框架。即使你选择使用现成的框架，我相信理解这种高度简化方法所涉及的概念也是有价值的。
- en: Validator Framework Code
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 验证器框架代码
- en: The general concept of this framework is a Python script that executes a pair
    of SQL scripts and compares the two based on a comparison operator. The combination
    of each script and the outcome is considered a *validation test*, and the test
    is said to pass or fail depending on how the result of the executed scripts compares
    to the expected outcome. For example, one script might count the number of rows
    in a table for a given day, the second counts the number of rows from the previous
    day, and a comparison operator of `>=` checks to see if the current day has more
    rows than the previous did. If so, it passes; if not, it fails.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这个框架的总体概念是一个Python脚本，它执行一对SQL脚本，并根据比较运算符进行比较。每个脚本的组合和结果被视为一个*验证测试*，测试结果根据执行脚本的结果与预期结果的比较而定，可以通过或失败。例如，一个脚本可能会计算给定日期表中的行数，第二个脚本计算前一天的行数，比较运算符`>=`则检查当前日期的行数是否比前一天多。如果是，则测试通过；否则，测试失败。
- en: Note that one of the SQL scripts can also return a static value such as an integer.
    As you can see in the examples in [“Validation Test Examples”](#validation-test-exs),
    that approach is used to check for duplicated rows in a table. Though simple,
    this framework can handle a wide range of validation logic.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，SQL脚本中的一个也可以返回静态值，如整数。正如您在[“验证测试示例”](#validation-test-exs)中所看到的那样，该方法用于检查表中的重复行。虽然简单，但此框架可以处理广泛的验证逻辑。
- en: Using command-line arguments, you can tell the validator to execute a specific
    pair of scripts as well as the operator to use for comparison. It then executes
    and returns a pass/fail code. The return value can be used to trigger various
    actions in an Airflow DAG, as shown later in this section, or consumed by any
    other process that executes the validator.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 使用命令行参数，您可以告诉验证器执行特定的脚本对以及用于比较的运算符。然后，它执行并返回一个通过/失败代码。返回值可以用于触发Airflow DAG中的各种操作，如本节稍后所示，或被任何其他执行验证器的过程所消耗。
- en: '[Example 8-1](#ex_0801) shows the code for the validator. This version is set
    to execute tests against an Amazon Redshift data warehouse using the `psycopg2`
    Python library. It also uses the same *pipeline.conf* configuration file from
    Chapters [4](ch04.xhtml#ch04) and [5](ch05.xhtml#ch05) to access the credentials
    to the warehouse. You can easily modify this script to access a Snowflake data
    warehouse per the samples in [Chapter 5](ch05.xhtml#ch05), or another data warehouse
    of your choice. The only difference will be the library you use to connect and
    execute queries. You’ll also need to make sure that your Python environment is
    set up properly and a virtual environment is activated. See [“Setting Up Your
    Python Environment”](ch04.xhtml#setup-python-enviro) for more information.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 8-1](#ex_0801)显示了验证器的代码。此版本设置为使用`psycopg2` Python库执行针对Amazon Redshift数据仓库的测试。它还使用了第[4](ch04.xhtml#ch04)章和第[5](ch05.xhtml#ch05)章中相同的*pipeline.conf*配置文件来访问仓库的凭据。您可以轻松地修改此脚本以访问Snowflake数据仓库，如[第 5](ch05.xhtml#ch05)章中的示例，或其他您选择的数据仓库。唯一的区别将是您用于连接和执行查询的库。您还需要确保您的Python环境设置正确，并激活虚拟环境。有关更多信息，请参阅[“设置您的Python环境”](ch04.xhtml#setup-python-enviro)。'
- en: Example 8-1\. validator.py
  id: totrans-38
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-1\. validator.py
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The following subsections describe the structure of the validation tests that
    this framework is designed to run and how to run a test from the command line
    as well as an Airflow DAG. In the next section, I’ll share some sample validation
    tests based on common types of tests.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的小节描述了此框架设计用于运行的验证测试的结构以及如何从命令行运行测试以及Airflow DAG。在下一节中，我将基于常见的测试类型分享一些示例验证测试。
- en: Structure of a Validation Test
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 验证测试的结构
- en: 'As briefly described in the previous subsection, a validation test in this
    framework consists of three things:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面的小节中简要描述的那样，此框架中的验证测试由三个部分组成：
- en: A SQL file that runs a script that results in a single numeric value
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行脚本并返回单个数值的SQL文件
- en: A second SQL file that runs a script that results in a single numeric value
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个运行脚本并返回单个数值的SQL文件
- en: A “comparison operator” that is used to compare the two values returned from
    the SQL scripts
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个“比较运算符”，用于比较从SQL脚本返回的两个值
- en: Let’s look at a simple example that checks to make sure that two tables have
    the same number of rows. In [Example 8-2](#ex_0802), the SQL script counts the
    number of rows in a table named `Orders`, while in [Example 8-3](#ex_0803), the
    SQL script gets the same count from another table named `Orders_Full`.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个简单的例子，检查两个表的行数是否相同。在[示例 8-2](#ex_0802)中，SQL脚本计算名为`Orders`的表中的行数，而在[示例 8-3](#ex_0803)中，SQL脚本从另一个名为`Orders_Full`的表中获取相同的计数。
- en: Example 8-2\. order_count.sql
  id: totrans-47
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-2\. order_count.sql
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Example 8-3\. order_full_count.sql
  id: totrans-49
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-3\. order_full_count.sql
- en: '[PRE2]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'You can use the following SQL to create and populate the `Orders` and `Orders_Full`
    tables used in examples throughout this chapter:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下SQL创建和填充本章中使用的`Orders`和`Orders_Full`表：
- en: '[PRE3]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The last piece of a validation test is the comparison operator to be used to
    compare the two values. In the code sample from [Example 8-1](#ex_0801), you can
    see the options available for comparison operators, but here they are with their
    associated logical symbols in parentheses for reference:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个验证测试的部分是要用来比较两个值的比较运算符。在来自[示例 8-1](#ex_0801)的代码示例中，您可以看到可用于比较运算符的选项，但这里它们带有其关联的逻辑符号（括号内）以供参考：
- en: '`equals`'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`equals`'
- en: '`greater_equals`'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`greater_equals`'
- en: '`greater`'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`greater`'
- en: '`less_equals`'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`less_equals`'
- en: '`less`'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`less`'
- en: '`not_equal`'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`not_equal`'
- en: Next we’ll look at how to run a test and make sense of the result.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们将看看如何运行测试并理解结果。
- en: Running a Validation Test
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行验证测试
- en: 'Using the example of the validation test from the previous subsection, the
    test can be executed on the command line as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 使用前一小节中验证测试的示例，可以在命令行上执行如下：
- en: '[PRE4]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'If the row counts of both the `Orders` and `Orders_Full` tables are the same,
    the output will look like this:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`Orders`表和`Orders_Full`表的行数相同，则输出如下：
- en: '[PRE5]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: What you don’t see on the command line is the *Exit Status Code*, which in this
    case is `0` but will be `-1` in the case of a test failure. You can consume this
    value programmatically, however. The next section shows how to do so in an Airflow
    DAG. You may also want to consider doing something like sending a Slack message
    or email when a test fails. I’ll discuss some options for doing that later in
    [“Extending the Framework”](#extending-frmwk).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在命令行上看不到的是*退出状态码*，在本例中为`0`，但在测试失败时将为`-1`。但您可以在程序中消耗此值。下一节将展示如何在Airflow DAG中执行此操作。您可能还希望考虑在测试失败时执行像发送Slack消息或电子邮件之类的操作。稍后在[“扩展框架”](#extending-frmwk)中将讨论一些选项。
- en: Usage in an Airflow DAG
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Airflow DAG中的使用
- en: As you learned in [Chapter 7](ch07.xhtml#ch07), an Airflow task can execute
    a Python script using a `BashOperator`. Consider the `elt_pipeline_sample` DAG
    from [Example 7-2](ch07.xhtml#ex_0702). After the `Orders` table is ingested (after
    both the extract and load tasks), I will add another task to run the validation
    test example I just shared to check the row count of the `Orders` table against
    some fictional table named `Orders_Full`. For the sake of this example, assume
    that for some reason we want to make sure that the row count in `Orders` is the
    same as `Orders_Full`, and if it’s not, to fail the task and stop further execution
    of downstream tasks in the DAG.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在[第7章](ch07.xhtml#ch07)中学到的，Airflow任务可以使用`BashOperator`执行Python脚本。考虑从[示例7-2](ch07.xhtml#ex_0702)中的`elt_pipeline_sample`
    DAG开始。在`Orders`表被摄取之后（提取和加载任务完成之后），我将添加另一个任务来运行我刚分享的验证测试示例，以检查`Orders`表的行数与名为`Orders_Full`的虚构表格的行数是否相同。出于本例考虑，假设出于某种原因我们希望确保`Orders`中的行数与`Orders_Full`相同，并且如果不是，则任务失败，并停止DAG中下游任务的进一步执行。
- en: 'First, add the following task to the `elt_pipeline_sample.py` DAG definition:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，将以下任务添加到`elt_pipeline_sample.py` DAG定义中：
- en: '[PRE6]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Next, redefine the dependency order of the DAG in the same file to the following
    code. This ensures that after the `load_orders_task`, the validation task runs,
    followed by the `revenue_model_task` once both the validation is completed (and
    passed) and the `load_customers_task` has completed successfully:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在同一文件中重新定义DAG的依赖顺序为以下代码。这确保在`load_orders_task`之后，验证任务运行，在验证完成（并通过）以及`load_customers_task`成功完成后，`revenue_model_task`任务运行：
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[Figure 8-1](#fig_0801) shows the updated graph view of the DAG.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[图8-1](#fig_0801)显示了DAG的更新图形视图。'
- en: '![dppr 0801](Images/dppr_0801.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![dppr 0801](Images/dppr_0801.png)'
- en: Figure 8-1\. Graph view of the sample ELT DAG with a validation test included.
  id: totrans-75
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-1\. 带有验证测试的示例ELT DAG的图形视图。
- en: 'When `check_order_rowcount_task` is executed, the following Bash command is
    run per the task definition:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 当执行`check_order_rowcount_task`时，根据任务定义运行以下Bash命令：
- en: '[PRE8]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: You’ll recognize the execution of the validator with the command-line arguments
    from earlier in this section. What’s new is the `set -e;` prior to the rest of
    the command. This tells Bash to stop execution of the script on an error, which
    is defined by a nonzero exit status code. As you’ll recall, if the validation
    test fails, it returns an exit status of -1\. If that happens, the Airflow task
    will fail, and no downstream tasks will execute (`revenue_model_task` in this
    case).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 您会注意到使用了先前在本节中讨论过的命令行参数执行验证器。新的部分是在其余命令之前加上了`set -e;`。这告诉Bash在错误时停止脚本的执行，错误由非零退出状态码定义。如您所记得的，如果验证测试失败，它将返回退出状态-1。如果发生这种情况，Airflow任务将失败，并且不会执行下游任务（本例中的`revenue_model_task`）。
- en: It’s not always necessary to halt the further execution of a DAG when a validation
    tests fails. In that case, you shouldn’t include the `set -e` portion of the Bash
    command set on the Airflow task or modify the validator to handle warnings and
    hard errors differently. Next, I’ll discuss when to do so and when to simply send
    some kind of notification instead.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 当验证测试失败时，并不总是需要停止DAG的进一步执行。在这种情况下，不应将Bash命令集中的`set -e`部分包含在Airflow任务中，或者修改验证器以不同方式处理警告和严重错误。接下来，我将讨论何时这样做，何时只需发送某种通知。
- en: When to Halt a Pipeline, When to Warn and Continue
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时停止管道，何时警告并继续
- en: There are times, such as in the previous example, when halting a pipeline is
    necessary when a data validation tests fails. In that example, if the record count
    in the `Orders` table is incorrect, perhaps by refreshing the data model in the
    final task, business users will see incorrect sales figures. If that’s important
    to avoid, then halting the DAG so that the issue can be addressed is the right
    approach. When that’s done, the data model still has data in it from the previous
    successful run of the DAG. In general, stale data is better than incorrect data!
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，比如在前面的例子中，当数据验证测试失败时，停止管道是必要的。在那个例子中，如果`Orders`表中的记录计数不正确，可能是由于在最后一个任务中刷新数据模型，业务用户将看到不正确的销售数据。如果避免这种情况很重要，那么停止DAG以便解决问题是正确的方法。完成这些操作后，数据模型仍然包含前一个成功运行DAG的数据。总的来说，旧数据比不正确的数据更好！
- en: However, there are other times when the failure of a validation test is less
    critical and more informational. For example, perhaps the number of orders in
    the table increased by 3% since the previous run a day ago, while the average
    daily increase over the previous 30 days was 1%. You may catch such an increase
    with a basic statistical test as I show in the next section. Is it an issue worth
    halting for? The answer is that it depends on your circumstances and appetite
    for risk, but you can rely on multiple tests to get at that answer.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，还有其他时候，验证测试失败并不那么关键，更多的是提供信息。例如，也许表中的订单数量自昨天的上一个运行增加了3%，而过去30天的平均每日增长率是1%。你可以通过下一节中我展示的基本统计测试来捕捉这样的增长。这是否值得停止呢？答案取决于你的情况和对风险的接受程度，但你可以依靠多个测试来得出答案。
- en: For example, if you were to also run a test to check for duplicate rows in the
    `Orders` table and it passed, then you know that the issue isn’t some kind of
    duplication. Perhaps the company just had an incredible day of sales because of
    a promotion. You can also adjust your test to take into account seasonality. Perhaps
    it’s the holiday season and yesterday was Black Friday. Instead of comparing the
    growth in records to the past 30 days, you should have compared it to the same
    period the previous year, with or without an additional factor for growth in the
    business year over year.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你还运行了一个测试来检查`Orders`表中是否有重复行，并且测试通过了，那么你就知道问题不是重复的。也许公司因为促销活动而销售额惊人增长。你也可以调整你的测试以考虑季节性因素。也许现在是假期季节，昨天是黑色星期五。与其将记录的增长与过去30天相比较，不如与去年同期相比较，无论业务年度增长是否增加都可以考虑。
- en: In the end, the decision whether to throw an error and halt a pipeline versus
    sending an alert to a Slack channel should be based on the context of the business
    and use case of the data. However, it points to the need for both data engineers
    and analysts being empowered to contribute validation tests to a pipeline. Although
    a data engineer may check for a row count discrepancy, they may not have the business
    context to think of creating a test to check for a seasonality factor in growth
    of a row count in the `Orders` table.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，是选择抛出错误并停止管道，还是发送警报到Slack频道的决定，应该基于业务的背景和数据的用例。然而，这也指出了数据工程师和分析师都有必要贡献验证测试到管道的需求。虽然数据工程师可能会检查行计数差异，但他们可能没有业务背景去考虑创建一个测试来检查`Orders`表中行计数的季节性增长因素。
- en: What if you want to just warn instead of halt the pipeline? You’ll need to make
    a few modifications either to the DAG in the previous example or to the validation
    framework itself. Airflow has a number of options for error handling that you
    can learn about in the official Airflow documentation. In the following section
    on some possible extensions to the validation framework, I suggest some ways you
    can handle less critical failures in the framework itself. Either option is fine;
    it’s up to you where you want the logic to live.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你只想警告而不是停止管道，你需要在前面例子中的DAG或验证框架本身中进行一些修改。Airflow在错误处理方面有许多选项，你可以在官方Airflow文档中了解。在接下来关于验证框架的一些可能扩展的部分中，我建议一些处理框架中较不关键失败的方法。任何一个选项都可以；你可以选择在哪里设置逻辑。
- en: Extending the Framework
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 扩展框架
- en: As I noted earlier in the chapter, the sample data validation framework from
    [Example 8-1](#ex_0801) is lacking many features that you’ll want to consider
    for a production deployment. If you decide to use this framework as a starting
    point rather than considering an open source or commercial option, there are a
    number of improvements you may want to consider.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我在本章前面提到的，从[示例 8-1](#ex_0801)中的样本数据验证框架中，缺少了许多你可能希望考虑用于生产部署的功能。如果你决定将这个框架作为起点，而不是考虑开源或商业选项，你可能会考虑一些改进措施。
- en: A common need in a validation framework is to send a notification to a Slack
    channel or email when a test fails. I’ll provide an example of how to do so for
    a Slack channel, but there are numerous examples on the Web for sending email
    and notifications to other messaging services in Python.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在验证框架中的常见需求是，在测试失败时向Slack频道或电子邮件发送通知。我将提供一个示例，演示如何为Slack频道执行此操作，但在Python中发送电子邮件和其他消息服务的通知的示例也有很多。
- en: First, you’ll need to create an *incoming webhook* for the Slack channel you
    want to send to. An incoming webhook is a URL that is unique to the channel that
    you can post data to in order for it to show up as a message in that channel.
    You can follow the instructions in the [Slack documentation](https://oreil.ly/L4sYZ)
    to learn how to create one.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要为要发送的Slack频道创建一个*incoming webhook*。入站Webhook是一个唯一的URL，你可以向其发送数据，以便它显示为该频道中的消息。你可以按照[Slack文档](https://oreil.ly/L4sYZ)中的说明创建它。
- en: Once you have a webhook, you can add the following function shown in [Example 8-4](#ex_0804)
    to `validator.py`. You can pass information about a validation test to it. The
    information sent to the webhook is then published in the Slack channel.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了Webhook，你可以将以下函数添加到`validator.py`中，如[示例 8-4](#ex_0804)所示。你可以向其传递有关验证测试的信息。发送到Webhook的信息随后会在Slack频道中发布。
- en: Example 8-4\. A function to send Slack messages
  id: totrans-91
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-4\. 发送Slack消息的函数
- en: '[PRE9]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Now all you need to do is make a call to the function right before *validation.py*
    exits. [Example 8-5](#ex_0805) shows the final lines of the updated script.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在*validation.py*退出之前，你只需要调用该函数。[示例 8-5](#ex_0805)展示了更新脚本的最后几行。
- en: Example 8-5\. Send a Slack message when a test fails
  id: totrans-94
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-5\. 在测试失败时发送Slack消息
- en: '[PRE10]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Of course, there is some room for improvement in the formatting of the Slack
    messages that the function sends, but for now it’s enough to get the job done.
    Note that I included the `test_result` parameter in the `send_slack_notification`
    function. It’s set up to handle notifications of passed tests as well as failed
    ones. Though I don’t use it this way in the example, you may want to do so.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，Slack消息的格式还有改进的空间，这个函数发送的消息，现在已经足够完成工作。请注意，我在`send_slack_notification`函数中包含了`test_result`参数。它被设置为处理通过测试和未通过测试的通知。尽管在示例中我没有这样使用它，但你可能希望这样做。
- en: As noted in the previous subsection, sometimes a Slack message is sufficient,
    and the result of a failed test should not result in the pipeline coming to a
    halt. Though you can make use of the DAG configuration to handle such a case,
    you can also improve the validation framework by adding another command-line parameter
    to define severity.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一小节所述，有时候一个Slack消息就足够了，测试失败的结果不应导致流水线停止。尽管你可以利用DAG配置来处理这种情况，但也可以通过添加另一个命令行参数来定义严重性，从而改进验证框架。
- en: '[Example 8-6](#ex_0806) shows an updated `__main__` block of `validator.py`
    with handing for severity. When the script is executed with a severity level of
    `halt`, then a failed test results in an exit code of -1\. When the severity level
    is set to `warn`, then a failed test results in an exit code of 0, just as it
    does when a test passes. In both cases, a failed message leads to a Slack message
    being sent to your desired channel.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 8-6](#ex_0806) 展示了带有严重性处理的`validator.py`中更新后的`__main__`块。当脚本以`halt`严重性级别执行时，失败的测试会导致退出码为-1。当严重性级别设置为`warn`时，失败的测试结果会导致退出码为0，就像测试通过时一样。在两种情况下，失败消息都会导致在你指定的频道发送Slack消息。'
- en: Example 8-6\. Add handling for multiple severity levels of test failure
  id: totrans-99
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-6\. 添加多种严重性级别的测试失败处理
- en: '[PRE11]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: There are countless other ways to extend this framework, two of which follow.
    I’m sure you’ll think of some others as well!
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 有无数其他方法可以扩展这个框架，其中两种如下。我相信你也会想到其他一些方法！
- en: Exception handing through the application
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序中的异常处理
- en: Though I left it out for sake of space in this book, catching and handling exceptions
    for things like invalid command-line arguments and SQL errors in the test scripts
    are a must in production.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我在本书中为了节省空间而没有详细介绍，但在生产中，必须捕获和处理异常，如无效的命令行参数和SQL错误。
- en: The ability to run a number of tests with a single execution of validator.py
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 使用validator.py的单个执行能运行多个测试的能力
- en: Consider storing your tests in a config file and grouping them by table, DAG,
    or in another way that fits your development pattern. Then you can execute all
    tests that match a specific point in a pipeline with a single command rather than
    one for each test you’ve defined.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑将您的测试存储在配置文件中，并按表、DAG或其他适合您的开发模式的方式进行分组。然后，您可以通过单个命令执行与管道中特定点匹配的所有测试，而不是为您定义的每个测试执行一个命令。
- en: Validation Test Examples
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 验证测试示例
- en: 'The preceding section defined a simple validation framework and the concept
    behind how it works. As a reminder, a validation test consists of the following:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的部分定义了一个简单的验证框架及其工作原理。作为提醒，验证测试包括以下内容：
- en: A SQL file that runs a script that results in a single numeric value
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行脚本并得到一个单一的数字值的SQL文件
- en: A second SQL file that runs a script that results in a single numeric value
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行脚本并得到一个单一的数字值的第二个SQL文件
- en: A “comparison operator” that is used to compare the two values returned from
    the SQL scripts
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于比较从SQL脚本返回的两个值的“比较运算符”
- en: 'Assuming you added to enhancements from Examples [8-4](#ex_0804), [8-5](#ex_0805),
    and [8-6](#ex_0806) to the `validator.py` code in [Example 8-1](#ex_0801), you
    can execute a test on the command line as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您已将示例[8-4](#ex_0804)、[8-5](#ex_0805)和[8-6](#ex_0806)的增强功能添加到[Example 8-1](#ex_0801)中的`validator.py`代码中，您可以在命令行上执行测试如下：
- en: '[PRE12]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In this section, I’ll define some sample tests that I find useful in validating
    data in a pipeline. These are by no means all of the tests that you’ll need to
    run, but they do cover some common points to get you started and inspire a wider
    range of tests. Each subsection includes the source for the two SQL files that
    make up the test as well as the command-line commands and arguments to execute
    the tests.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我将定义一些我认为在验证管道中的数据时很有用的样本测试。这些并不是你需要运行的所有测试，但它们确实涵盖了一些常见点，可以帮助你开始并激发更广泛的测试。每个子节包括组成测试的两个SQL文件的源代码，以及执行测试所需的命令行命令和参数。
- en: Duplicate Records After Ingestion
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在摄取后重复记录
- en: Checking for duplicate records is a simple, common test. The only thing you’ll
    need to consider is what defines a “duplicate” in the table you’re checking. Is
    it based on a single ID value? An ID as well as a second column? In this example,
    I’ll check to make sure that there are not two records in the `Orders` table with
    the same `OrderId`. To check for duplicates based on additional columns, you can
    simply add those columns to the `SELECT` and `GROUP BY` in the first query.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 检查重复记录是一个简单而常见的测试。唯一需要考虑的是，你需要在检查的表中定义什么是“重复”。是基于单个ID值？还是基于ID以及第二列？在这个例子中，我将检查确保`Orders`表中没有两条具有相同`OrderId`的记录。要基于其他列检查重复项，只需将这些列添加到第一个查询的`SELECT`和`GROUP
    BY`中即可。
- en: Note that the second query returns a static value of 0\. That’s because I expect
    no duplicates and want to compare the count of duplicates to zero. If they match,
    the test passes.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 注意第二个查询返回了一个固定值0。这是因为我预期没有重复项，并希望将重复项的计数与零进行比较。如果它们匹配，则测试通过。
- en: Example 8-7\. order_dup.sql
  id: totrans-117
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-7\. order_dup.sql
- en: '[PRE13]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Example 8-8\. order_dup_zero.sql
  id: totrans-119
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-8\. order_dup_zero.sql
- en: '[PRE14]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'To run the test, use this:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行测试，请使用以下命令：
- en: '[PRE15]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Unexpected Change in Row Count After Ingestion
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摄取后行数意外变化
- en: When you expect the number of records from a recent ingestion to be somewhat
    constant, you can use a statistical check to see if the latest ingestion loaded
    more or fewer records than history would suggest.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 当您期望最近摄取的记录数量相对稳定时，您可以使用统计检查来查看最新的摄取是否加载比历史记录建议的更多或更少的记录。
- en: In this example, I assume that data is ingested daily and will look to see if
    the number of records in the `Orders` table loaded most recently (yesterday) is
    within a range I’m comfortable with. You can do the same for hourly, weekly, or
    any other interval, as long as it’s constant.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我假设数据每天摄取，并且会查看最近加载（昨天）`Orders`表中记录的数量是否在我可以接受的范围内。只要间隔是固定的，你可以对每小时、每周或任何其他间隔执行相同操作。
- en: I’ll use a standard deviation calculation and look to see if yesterday’s row
    count is within a 90% confidence level based on the entire history of the `Orders`
    table. In other words, is the value (number of rows) within a 90% confidence interval
    in either direction (can be up to 5% off in either direction) of what’s expected,
    based on history?
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我将使用标准差计算并查看昨天的行数是否在`Orders`表的整个历史记录的90%置信水平内。换句话说，基于历史，值（行数）是否在90%置信区间内的任一方向（每个方向最多可以偏离5%）？
- en: In statistics, this is considered a *two-tailed test* because we are looking
    under both sides of a normal distribution curve. You can use a z-score calculator
    to determine what score to use for a two-tailed test with a confidence interval
    of 90% to determine a z-score of 1.645\. In other words, we’re looking for a difference
    in either direction, too high or too low, based on a set threshold.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学中，这被视为*双尾检验*，因为我们在正态分布曲线的两侧查找。你可以使用z-score计算器确定在置信水平为90%的双尾检验中使用的分数，以确定z-score为1.645\.
    换句话说，我们正在寻找根据设置的阈值在任一方向上的差异，无论是太高还是太低。
- en: I’ll use that z-score in the test to see if the count of order records from
    yesterday passes or fails a test. In the validation test, I’ll return the absolute
    value of the z-score for yesterday’s row count and then compare it to a z-score
    of 1.645 in the second SQL script.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我将在测试中使用该z-score来查看昨天订单记录的计数是否通过测试。在验证测试中，我将返回昨天行数的z-score的绝对值，然后将其与第二个SQL脚本中的z-score
    1.645进行比较。
- en: Because you need a good deal of sample data in the `Orders` tables, I provide
    two versions of the first SQL script in the validation test. The first ([Example 8-9](#ex_0809))
    is the “real” code used to go through the `Orders` table, get row counts by day,
    and then calculate the z-score for the previous day.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 因为你需要在`Orders`表中有大量样本数据，我提供了验证测试中第一个SQL脚本的两个版本。第一个([示例 8-9](#ex_0809)) 是用于遍历`Orders`表、获取每天行数，并计算前一天z-score的“真实”代码。
- en: However, you may want to instead use some sample data to experiment with this
    kind of test. I provide an alternate version to populate a table called `orders_by_day`
    and then execute the latter section of [Example 8-9](#ex_0809) to calculate the
    z-score for the last day of the sample set (*2020-10-05*). [Example 8-11](#ex_0811)
    shows the alternate version.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，你可能想要使用一些样本数据来进行这种测试的实验。我提供了一个备用版本，以填充名为`orders_by_day`的表，然后执行[示例 8-9](#ex_0809)的后半部分来计算样本集的最后一天（*2020-10-05*）的z-score。[示例 8-11](#ex_0811)
    显示了备用版本。
- en: Example 8-9\. order_yesterday_zscore.sql
  id: totrans-131
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-9\. order_yesterday_zscore.sql
- en: '[PRE16]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[Example 8-10](#ex_0810) simply returns the value to check against.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 8-10](#ex_0810) 简单返回要检查的值。'
- en: Example 8-10\. zscore_90_twosided.sql
  id: totrans-134
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-10\. zscore_90_twosided.sql
- en: '[PRE17]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'To run the test, use this:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 若要运行测试，请使用以下方法：
- en: '[PRE18]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Note
  id: totrans-138
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If the `Orders` table contains a high volume of data, it’s worth creating the
    `orders_by_day` dataset as a table in a transform task (just as the data model
    examples in [Chapter 6](ch06.xhtml#ch06)) rather than as a CTE in the validation
    script. Because the number of orders by day should not change in the past, you
    can create an incremental data model and append rows for each subsequent day as
    new data arrives in the `Orders` table.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`Orders`表包含大量数据，创建`orders_by_day`数据集作为转换任务中的表（就像[第6章](ch06.xhtml#ch06)中的数据模型示例一样），而不是作为验证脚本中的CTE，是值得的。因为按天计算的订单数量在过去不应该发生变化，你可以创建一个增量数据模型，并在每个后续的天数中追加行，以表明`Orders`表中新数据的到达。
- en: 'Here is the alternative version, with a hard-coded date to check along with
    the sample data required to run it. With this version, you can adjust the `order_count`
    values and run the test to get different z-scores in and out of the desired range:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这是另一版本，带有一个硬编码的日期进行检查以及运行它所需的样本数据。通过这个版本，你可以调整`order_count`的值并运行测试，以获得不同的z-score在期望范围内和之外：
- en: '[PRE19]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Example 8-11\. order_sample_zscore.sql
  id: totrans-142
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-11\. order_sample_zscore.sql
- en: '[PRE20]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'To run the test, use this:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 若要运行测试，请使用以下方法：
- en: '[PRE21]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Metric Value Fluctuations
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指标值波动
- en: As noted earlier in this chapter, validating data at each step of the pipeline
    is critical. The previous two examples checked for the validity of data after
    ingestion. This example checks to make sure nothing went wrong after data was
    modeled in the transform step of a pipeline.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 正如本章前面所述，在管道的每个步骤中验证数据至关重要。前两个示例在摄入后验证了数据的有效性。此示例检查在数据在管道的转换步骤中建模后是否出现问题。
- en: In the data modeling examples from [Chapter 6](ch06.xhtml#ch06), multiple source
    tables are joined together, and logic that determines how to aggregate values
    is implemented. There’s no shortage of things that can go wrong, including invalid
    join logic that results in rows being duplicated or dropped. Even if the source
    data passed validation earlier in a pipeline, it’s always good practice to run
    validation on the data models that are built at the end of a pipeline.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在来自[第六章](ch06.xhtml#ch06)的数据建模示例中，多个源表被连接在一起，并实现了确定如何聚合值的逻辑。有很多问题可能会发生，包括导致行重复或删除的无效连接逻辑。即使源数据在管道的早期阶段已通过验证，也始终要对在管道末端构建的数据模型进行验证是个好习惯。
- en: 'There are three things you can check on:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以检查三件事情：
- en: Ensuring a metric is within certain lower and upper bounds
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保度量在某些下限和上限之间
- en: Checking row count growth (or reduction) in the data model
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查数据模型中行数的增长（或减少）
- en: Checking to see if there is unexpected fluctuation in the value of a particular
    metric
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查特定指标的值是否出现意外波动
- en: By now you probably have a good idea of how to implement such tests, but I will
    provide one final example for checking fluctuation in a metric value. The logic
    is nearly identical to that of the last section where I shared how to use a two-sided
    test to check the change in row count of a given source table. This time, however,
    instead of checking a row count value, I’m looking to see if the total revenue
    from orders placed on a given day is out of historical norms.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，您可能已经对如何实施这些测试有了一个很好的想法，但我将提供最后一个示例来检查指标值的波动。逻辑与我上一节分享的用于检查给定源表行数变化的逻辑几乎相同。不过，这一次，我不是检查行数值，而是查看特定日期订单总收入是否超出历史规范。
- en: Like the prior section’s example of looking for row count changes, I provide
    both a “real” example of how to do this on raw data ([Example 8-12](#ex_0812))
    as well as one with sample, aggregate data ([Example 8-14](#ex_0814)). To run
    [Example 8-12](#ex_0812), you’ll need quite a bit of data in the `Orders` table.
    This code makes sense for a true implementation. However, you might find [Example 8-14](#ex_0814)
    easier to experiment with for the sake of learning.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 就像前一节查找行数变化的示例一样，我提供了在原始数据上如何做到这一点（[示例 8-12](#ex_0812)）以及在样本聚合数据上的一个“真实”示例（[示例 8-14](#ex_0814)）。要运行[示例 8-12](#ex_0812)，您需要在`Orders`表中有相当多的数据。这段代码对于真正的实现是有意义的。但是，您可能会发现[示例 8-14](#ex_0814)更容易用于学习目的。
- en: Example 8-12\. revenue_yesterday_zscore.sql
  id: totrans-155
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-12\. revenue_yesterday_zscore.sql
- en: '[PRE22]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[Example 8-13](#ex_0813) simply returns the value to check against.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 8-13](#ex_0813)简单地返回要检查的值。'
- en: Example 8-13\. zscore_90_twosided.sql
  id: totrans-158
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-13\. zscore_90_twosided.sql
- en: '[PRE23]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Use this to run the test:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个来运行测试：
- en: '[PRE24]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Here is the sample data for [Example 8-14](#ex_0814), which as previously noted
    is a simplified version of [Example 8-12](#ex_0812) but for your own experimentation:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这是[示例 8-14](#ex_0814)的示例数据，正如前面提到的，这是[示例 8-12](#ex_0812)的简化版本，但用于您自己的实验：
- en: '[PRE25]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Example 8-14\. revenue_sample_zscore.sql
  id: totrans-164
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-14\. revenue_sample_zscore.sql
- en: '[PRE26]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'To run the test, use this:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行测试，请使用这个：
- en: '[PRE27]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Of course, you’ll want to consider adjusting this test to fit your business
    case.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，您会希望考虑调整此测试以适应您的业务案例。
- en: Is looking at order revenue by day too “noisy”? Is your order volume low enough
    that you need to look at weekly or monthly aggregates instead? If so, you can
    modify [Example 8-12](#ex_0812) to aggregate by week or month instead of day.
    [Example 8-15](#ex_0815) shows a monthly version of the same check. It compares
    the previous month versus the 11 prior to it.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 每天查看订单收入是否太“嘈杂”？您的订单量是否足够低，需要查看每周或每月的聚合数据？如果是这样，您可以修改[示例 8-12](#ex_0812)以按周或月进行聚合，而不是按天。[示例 8-15](#ex_0815)展示了相同检查的月度版本。它比较了上个月与之前11个月的差异。
- en: Note that this example checks the total revenue for the previous month from
    the current date. This is the type of validation you’d run when you “close” a
    month, which is usually on the first day of the next month. For example, this
    is a validation you might run on October 1 to check to make sure that revenue
    from September is within your expected range based on past history.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，此示例检查从当前日期到上个月的总收入。这是在“关闭”一个月时运行的验证类型，通常是在下个月的第一天。例如，这是您可能在10月1日运行的验证，以确保根据过去的历史，9月份的收入是否在您预期的范围内。
- en: Example 8-15\. revenue_lastmonth_zscore.sql
  id: totrans-171
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-15\. revenue_lastmonth_zscore.sql
- en: '[PRE28]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: There are a number of other variations of such a validation test. What level
    of date granularity, what date periods you want to compare, and even the z-score
    are things you’ll need to analyze and tweak based on your own data.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他类型的验证测试变体。你需要根据自己的数据分析和调整日期粒度的级别、你想要比较的日期周期，甚至是 z 分数。
- en: Commercial and Open Source Data Validation Frameworks
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 商业和开源数据验证框架
- en: Throughout this section, I’ve used a sample Python-based validation framework.
    As previously noted, though it’s simple, it can easily be extended to become a
    full-featured, production-ready application for all kinds of data validation needs.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我使用了一个基于 Python 的示例验证框架。正如之前提到的，尽管它很简单，但可以轻松扩展为一个功能齐全、可投入生产的应用程序，用于各种数据验证需求。
- en: That said, just like data ingestion, data modeling, and data orchestration tools,
    there is a build-versus-buy decision to make when it comes to what you use for
    data validation. In fact, previous build-versus-buy decisions often play into
    what a data team decides to use for data validation at different points in a pipeline.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 说到数据验证，就像数据摄入、数据建模和数据编排工具一样，当涉及到数据验证时，你需要做出一个自建还是购买的决策。实际上，之前的自建与购买决策通常会影响数据团队在管道不同阶段选择用于数据验证的工具。
- en: For instance, some data ingestion tools include features to check for row count
    changes, unexpected values in columns, and more. Some data transformation frameworks,
    such as [dbt](https://www.getdbt.com), include data validation and testing functionally.
    If you’ve already invested in such tools, check to see what options are available.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一些数据摄入工具包括功能来检查行数变化、列中的意外值等。一些数据转换框架，如[dbt](https://www.getdbt.com)，包括数据验证和测试功能。如果你已经投资了这类工具，看看有哪些可用选项。
- en: Finally, there are open source frameworks for data validation. The number of
    such frameworks is vast, and I suggest looking for one that fits your ecosystem.
    For example, if you’re building a machine learning pipeline and use TensorFlow,
    you might consider [TensorFlow Data Validation](https://oreil.ly/EJHDl). For more
    general validation, Yahoo’s [Validator](https://oreil.ly/XMdGY) is an open source
    option.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，有一些开源框架可用于数据验证。这类框架的数量庞大，我建议找一个适合你生态系统的框架。例如，如果你正在构建一个机器学习管道并使用 TensorFlow，你可以考虑使用[TensorFlow数据验证](https://oreil.ly/EJHDl)。对于更通用的验证，Yahoo的[验证器](https://oreil.ly/XMdGY)是一个开源选择。
