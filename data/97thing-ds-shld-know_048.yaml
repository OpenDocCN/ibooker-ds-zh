- en: Chapter 44\. Probability—the Law That Governs Analytical Ethics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第44章。概率——统治分析伦理的法则
- en: Thomas Casey
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 托马斯·凯西
- en: '![](Images/Thomas_Casey.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/Thomas_Casey.png)'
- en: Executive Director, Teradata
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Teradata 执行董事
- en: For years, analytics helped us better understand our world and supported our
    decision making. With the advent of more advanced analytics techniques, we have
    evolved to a point where nonhumans can autonomously make decisions on our behalf.
    Much is written about concepts like “machine learning” and “deep learning” as
    techniques that can drive incredible outcomes. At the end of the day, however,
    you cannot drive any decisions using these techniques without first understanding
    probability and its ethical implications for analytically driven decisions.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 多年来，分析帮助我们更好地理解我们的世界，并支持我们的决策。随着更先进的分析技术的出现，我们已经发展到非人类可以代表我们做出决策的地步。很多文章讨论了像“机器学习”和“深度学习”这样的概念，作为可以推动令人难以置信结果的技术。然而，无论如何，如果你不先理解概率及其对分析驱动决策的伦理影响，你无法使用这些技术来做出任何决定。
- en: When Probability and Ethics Collide
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 当概率和伦理相冲突时
- en: If you asked an algorithm whether you should play the lottery, the answer would
    undoubtedly be “no.” It is statistically impossible (based on probability and
    confidence level) that you will win, and therefore playing is not worth the practical
    risk. The truth is that even though this decision is appropriate for nearly everyone,
    given the sheer number of people that play the lottery, someone will eventually
    win. Making this mistake seems minor in this context (unless you missed out on
    your millions). What if, however, a decision that was made by an algorithm prohibited
    you from boarding a plane? What if it misdiagnosed cancer? What if an autonomous
    vehicle decided to veer right and hit your child because it “predicted” there
    was a more significant risk in going left? None of these decisions can be certain,
    and some acceptable level of risk is applied to each based on the likelihood or
    probability of being right—and the model will not experience a moment of regret
    if it made the wrong decision.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你问一个算法是否应该玩彩票，答案肯定是“不”。基于概率和置信水平，你赢得彩票的可能性是统计上不可能的，因此玩彩票并不值得冒这种实际风险。事实上，尽管这个决定对几乎所有人来说都是合适的，但是由于玩彩票的人数众多，总有人最终会赢得。在这种情况下犯错似乎是微不足道的（除非你错过了百万美元）。然而，如果一个由算法做出的决定阻止你登机怎么办？如果它误诊了癌症？如果自动驾驶车辆决定向右转而撞击你的孩子，因为它“预测”左转存在更大的风险？这些决策都无法确定，每一个都会根据可能性或正确性应用某种可接受的风险水平——如果模型做出错误的决定，它也不会感到后悔。
- en: How Humans Try to Interject Ethics into Algorithms
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人类如何试图在算法中注入伦理
- en: 'The marriage of people and machines to augment decisions has a lot of merit.
    The issue is that each time people try to apply ethical standards to a model,
    they inherently interject (for good or bad) some level of bias. Examples include:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 人类和机器的婚姻用于增强决策有很大的优点。问题在于每次人们试图将伦理标准应用于模型时，他们固有地（无论好坏）注入了一定程度的偏见。例如：
- en: Injecting the “right” bias
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 注入“正确”的偏见
- en: Companies like Google and Facebook have faced significant backlash in studies
    showing that their algorithms have made recommendations that favor some information
    providers over others. Whether or not there were nefarious or explicit biases
    intended, these companies continue to tweak their algorithms to demonstrate that
    their results better reflect the perceptions of what someone thinks they should
    represent.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 像谷歌和Facebook这样的公司在研究中面临了显著的反对意见，显示他们的算法推荐了一些信息提供者而不是其他人。无论是否有恶意或明确的偏见意图，这些公司继续调整他们的算法，以展示他们的结果更好地反映了某些人认为它们应该代表的看法。
- en: Dumbing down the model
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 简化模型
- en: Deep learning has risen to fame in the past few years as a technique used in
    many high-profile applications (image recognition, speech translation, advanced
    game play, etc.). The downside of deep learning is that it is difficult, if not
    impossible, to determine why a particular outcome is reached. In some instances,
    companies and other agencies are forced to resort to simpler and less effective
    (some may even say dumber) techniques just so they can explain the rationale behind
    the decision.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 近几年来，深度学习作为一种在许多知名应用中使用的技术（如图像识别、语音翻译、高级游戏玩法等）声名鹊起。深度学习的缺点在于很难，如果不是不可能，确定达成某个特定结果的原因。在某些情况下，公司和其他机构被迫转向更简单和不那么有效的（有些人甚至会说愚蠢的）技术，只是为了能够解释决策背后的理由。
- en: Overriding the decision
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 覆盖决定
- en: There are many instances in which the ability to override an algorithm makes
    sense. In other instances, though, overriding an algorithm gives us a false sense
    of security. For instance, some autonomous car services have addressed bad press
    (due to major accidents) by having an employee sit in the front seat and do nothing,
    though they are presumably ready to grab the wheel if they must. Although this
    might give us a feeling of control, one could argue that injecting humans in this
    way is spurious at best and counterproductive or even dangerous at worst.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 存在许多情况下，覆盖算法的能力是有意义的。然而，在其他情况下，覆盖算法会给我们一种虚假的安全感。例如，一些自动驾驶汽车服务因重大事故而遭受负面新闻，于是让一名员工坐在前排不做任何事情，虽然他们可能随时准备抓住方向盘。虽然这可能给我们一种控制感，但有人可能会认为以这种方式注入人类是毫无意义的，最好的情况下是无益的，最坏的情况下甚至是危险的。
- en: The Ethical Implications of Nonhuman Decision Making
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 非人类决策的伦理影响
- en: 'The march toward having more autonomous decisions made on our behalf is inevitable.
    Nevertheless, there undoubtedly will be situations in which a decision is statistically
    reasonable...but it will be wrong. If you recommend the wrong movie to watch,
    that is not catastrophic. If, however, an algorithm is making a life-or-death
    decision thousands or millions of times, the model will be wrong on occasion.
    Perhaps the benefits far outweigh the potential for errors, and perhaps the algorithm
    is infinitely better than a human at making that decision. Nevertheless, for someone
    who is impacted by an emotional outcome made by an unemotional decision maker,
    this will undoubtedly be insufficient solace. So in the future, as we think about
    the ethical implications of handing over complex decisions to unemotional algorithms
    that base their decisions on the laws of probability, we need to ask ourselves:
    are we sure?'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 向更多自主决策的方向前进是不可避免的。然而，毫无疑问地，会有一些情况下，一个决策在统计上是合理的……但它会是错误的。如果你推荐了一部错误的电影观看，那并不是灾难性的。然而，如果一个算法在数千或数百万次生死决策中偶尔出错，那将是问题的。也许好处远远超过错误的可能性，也许算法在做出决策方面比人类要好得多。然而，对于受到非情感决策者情感结果影响的人来说，这显然是不够安慰的。因此，在未来，当我们考虑将复杂决策交给基于概率法则做出决策的无情算法的伦理影响时，我们需要问自己：我们确定吗？
