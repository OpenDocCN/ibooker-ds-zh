- en: 5 Understanding churn and behavior with metrics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 通过指标理解客户流失和行为
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Showing how churn relates to metrics using cohort analysis
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用群体分析展示客户流失与指标之间的关系
- en: Summarizing the range of customer behaviors with dataset statistics
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用数据集统计来总结客户行为的范围
- en: Converting metrics from their normal scale to scores
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将指标从其正常尺度转换为分数
- en: Removing invalid observations from a cohort analysis
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从群体分析中移除无效观察
- en: Defining customer segments based on metrics and churn
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据指标和客户流失定义客户细分
- en: If you need to use statistics to understand your experiment, then you ought
    to have done a better experiment.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要使用统计学来理解你的实验，那么你应该已经做了更好的实验。
- en: —Ernest Rutherford, Nobel Prize in Chemistry, 1908, known as “The Father of
    Nuclear Physics” for his discovery of radioactive decay
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: —欧内斯特·卢瑟福，1908年诺贝尔化学奖获得者，以其发现放射性衰变而被称为“核物理之父”
- en: 'It’s time to do what you came here for: understand why your customers are churning
    and what keeps them engaged. Although it took a while, the dataset you learned
    to create in chapters 3 and 4 is the foundation for what comes next. You might
    expect that now I’m going to dive into some serious statistics or machine learning
    to do the analysis. Instead, I want to call your attention to the quote at the
    top of the page, which is my favorite saying by a scientist.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候做你来的目的了：理解为什么你的客户会流失以及是什么让他们保持活跃。尽管花了些时间，但你在第3章和第4章学到的数据集是接下来工作的基础。你可能期望我现在会深入一些严肃的统计学或机器学习来进行分析。然而，我想将你的注意力引到页面顶部的引言，这是我最喜欢的科学家的名言。
- en: The quote suggests that something is wrong if you are using statistics to analyze
    an experiment. In the age of big data and data science, that might sound like
    heresy. But I invite you to hold your judgment and consider what Rutherford was
    getting at. For one thing, he was a physicist at a time when electrical laboratory
    equipment was assembled by the scientists. If you had a lot of noise in your experimental
    apparatus, you could use statistics to deal with it by averaging results over
    many experiments, but maybe you should have spent more time setting up an experiment
    with less-noisy equipment. For a twenty-first-century data analyst, that can mean
    that you should spend a lot of time cleaning your data to get better results,
    which is completely correct. But does it justify maligning statistics?
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这句话暗示，如果你使用统计学来分析实验，那么可能存在某些问题。在大数据和数据科学的时代，这可能会听起来像是异端。但我邀请你保持你的判断，并考虑卢瑟福想要表达的意思。首先，他是在一个科学家组装电学实验室设备的时代当物理学家。如果你的实验装置中有很多噪声，你可以通过在许多实验中平均结果来使用统计学来处理它，但也许你应该花更多的时间设置一个使用更少噪声设备的实验。对于一个21世纪的数据分析师来说，这意味着你应该花很多时间清理数据以获得更好的结果，这是完全正确的。但这能证明诋毁统计学的合理性吗？
- en: Maybe I’m reading too much into Rutherford’s advice, but I think there is a
    deeper level to it. It might also mean that if an experiment shows a result that
    is not obviously a confirmation of the hypothesis, don’t bother with statistics
    to see whether you can make the result look better. Instead, come up with a better
    hypothesis—one that will really explain the thing you are trying to understand.
    To achieve that goal, you should design experiments to search for explanations
    that strongly drive the result, not second-order influences. If such a hypothesis
    is correct, the qualitative results of an experiment can be read from a single
    look at a plot of the results.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 也许我过分解读了卢瑟福的建议，但我想这其中有更深层次的意义。这也可能意味着，如果一个实验的结果并不是明显地证实了假设，那么你不必费心用统计学来查看是否可以使结果看起来更好。相反，提出一个更好的假设——一个真正能解释你所试图理解的事情的假设。为了达到这个目标，你应该设计实验来寻找强烈驱动结果的解释，而不是二级影响。如果这样的假设是正确的，实验的定性结果可以从结果图的一瞥中读取。
- en: 'It turns out that the most important results for churn analysis and subscriber
    engagement are usually this way: you will know it when you see it, and you will
    not need statistics. It’s also important that this property of churn will make
    it easy to communicate to the nontechnical businesspeople in your organization.
    In the context of churn analysis and behavioral metrics, look for metrics that
    show a strong relationship to churn, and if you don’t find them, keep looking.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，对于客户流失分析和用户参与度来说，最重要的结果通常是这样的：当你看到它时，你就会知道，而且你不需要统计。此外，这个客户流失的特性将使得与组织中非技术性的商业人士沟通变得容易。在客户流失分析和行为度量指标的情况下，寻找与客户流失有强烈关系的度量，如果你找不到，就继续寻找。
- en: TAKEAWAY You are looking for behavioral metrics that show a strong relationship
    to churn. When you find one, you will know it when you see the results, without
    using statistics.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**要点**你正在寻找与客户流失有强烈关系的行为度量。当你找到它时，你会看到结果，而不需要使用统计。'
- en: That said, in the third part of this book, I teach statistical and machine-learning
    methods for churn. It’s not that I think there is no place for statistics and
    machine learning; the question is emphasis. Also, I won’t use statistics and machine
    learning yet, but I didn’t say there won’t be math; I teach a small amount of
    necessary math in this chapter and the chapters that follow.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，本书的第三部分，我将教授用于客户流失的统计和机器学习方法。这并不是我认为统计和机器学习没有用武之地；问题在于侧重点。此外，我目前不会使用统计和机器学习，但我没有说不会用到数学；我在本章和随后的章节中会教授一些必要的数学知识。
- en: In terms of the overall themes of the book, the topics of this chapter are highlighted
    in figure 5.1\. This chapter assumes that you measured churn rates with the techniques
    in chapter 2, made behavioral metrics with the techniques in chapter 3, and created
    a dataset in chapter 4\. This chapter is where everything starts to come together!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 从本书的整体主题来看，本章的主题在图5.1中被突出显示。本章假设你已经使用第2章的技术测量了客户流失率，使用第3章的技术创建了行为度量，并在第4章中创建了一个数据集。本章是所有内容开始整合的地方！
- en: '![](../Images/5-01.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/5-01.png)'
- en: Figure 5.1 This chapter’s place in the process of fighting churn with data
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1本章在用数据对抗客户流失的过程中的位置
- en: 'Here’s how this chapter is organized:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何组织本章的：
- en: Section 5.1 teaches you a technique that I call metric cohorts, which allows
    you to investigate the real impact of behaviors that may be related to churn.
    I demonstrate this technique with examples from case studies to show what typical
    results look like.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第5.1节介绍了我认为的度量群体技术，它允许你调查可能与客户流失相关的行为的影响。我通过案例研究中的例子来演示这一技术，以展示典型的结果是什么样的。
- en: In section 5.2, I show you how to see the big picture of your customer behaviors
    by summarizing all the behavior in the dataset. What you find in the dataset summary
    is useful for refining your cohort analyses.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第5.2节中，我向你展示如何通过总结数据集中的所有行为来看到客户行为的整体图景。你在数据集摘要中找到的内容对于完善你的群体分析是有用的。
- en: Section 5.3 teaches another supporting technique called scoring, which is a
    way to transform customer metrics to improve the quality of analysis. There are
    no statistics, but the section includes a few equations.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第5.3节教授另一种辅助技术，称为评分，这是一种将客户度量转换为提高分析质量的方法。这里没有统计，但该节包含了一些方程式。
- en: In section 5.4, I discuss when and how to remove invalid or unwanted data that
    makes cohort analyses harder to interpret.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第5.4节中，我讨论了何时以及如何删除使群体分析难以解释的无效或不希望的数据。
- en: Section 5.5 goes over how to use cohort analysis to define customer segments.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第5.5节介绍了如何使用群体分析来定义客户细分。
- en: 5.1 Metric cohort analysis
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 度量群体分析
- en: Cohort analysis is a method of analyzing how churn (and other behaviors) depends
    on the value of behavioral and subscription metrics, like those taught in chapter
    3.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 群体分析是一种分析客户流失（以及其他行为）如何依赖于行为和订阅度量值的方法，就像第3章所教授的那样。
- en: 'DEFINITION The following definitions apply throughout the chapter:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义**以下定义适用于本章：'
- en: A cohort is a group of individuals that are similar (in the specific sense that
    all those individuals have a particular metric within a relatively small range).
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 群体是一组具有相似性（在特定意义上，所有这些个体在相对较小的范围内都有一个特定的度量）的个人。
- en: A metric cohort is a cohort of customers defined by having similar values on
    a metric.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 度量群体是由在某个度量上具有相似值的客户群体定义的。
- en: A cohort analysis is a comparison of different cohorts on some other measurement
    (not the one used to define the cohorts)—possibly another metric.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 群体分析是对不同群体在其他测量标准（不是用于定义群体的那个）上的比较——可能是另一个指标。
- en: A churn cohort analysis is a comparison of churn rates in different metric cohorts.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流失率群体分析是对不同指标群体流失率的比较。
- en: I generally use the term cohort analysis for brevity, but it’s implied that
    these analyses are metric cohort analyses of churn unless specified otherwise.
    You will see a lot of cohort analyses in the rest of the book, so I am going to
    take the time to introduce the concept before looking at Python code that does
    the calculation and plots the results. After you’ve learned the concept and the
    code, I illustrate the results in some real case studies.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我通常使用“群体分析”这个术语来简化，但除非明确说明，否则这些分析都是基于流失的指标群体分析。你将在本书的其余部分看到很多群体分析，因此我将在查看用于计算和绘制结果的Python代码之前，花时间介绍这个概念。在你学习了概念和代码之后，我将通过一些实际案例研究来展示结果。
- en: 5.1.1 The idea behind cohort analysis
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.1 群体分析背后的理念
- en: Probably the most basic hypothesis of any churn investigation is that people
    who are using the product a lot are less likely to churn than people who are using
    the product a little or not at all. A cohort analysis of churn that uses common
    product behaviors to form the cohorts serves as a test of that hypothesis. Figure
    5.2 illustrates the idea. If it is true that active customers churn less than
    inactive ones, a group of active customers should have a lower churn rate than
    a group of inactive customers. You can check this hypothesis by dividing the customers
    into cohorts based on their level of activity and then measure the churn rate
    in each group. If an activity is related to lower churn, you should find that
    the churn rate on the most active group is the lowest, a less active group has
    a higher churn rate, and the least active group has the highest churn rate. Figure
    5.2 illustrates this ideal scenario for three groups.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 可能任何流失调查的最基本假设是，使用产品较多的用户比使用产品较少或根本不使用的用户更不可能流失。使用常见的产品行为来形成群体的流失群体分析是对该假设的测试。图5.2展示了这个想法。如果活跃客户比不活跃客户流失率低，那么活跃客户群体应该比不活跃客户群体有更低的流失率。你可以通过根据客户的活跃程度将客户分为群体，然后测量每个群体的流失率来检验这个假设。如果一个活动与较低的流失率相关，你应该发现最活跃群体的流失率最低，较不活跃群体的流失率较高，而最不活跃群体的流失率最高。图5.2展示了这个理想场景的三组。
- en: TAKEAWAY If customers who use a product less churn more, a group of relatively
    inactive customers should have a higher churn rate than a group of relatively
    active customers.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**要点** 如果使用产品较少的客户流失率较低，那么相对不活跃的客户群体应该比相对活跃的客户群体有更高的流失率。'
- en: 'An important point to note is that finding relatively higher and lower churn
    rates in the less and more active groups is more realistic than expecting that
    all active customers don’t churn and all inactive customers do churn. Churn involves
    a lot of apparent randomness: sometimes, your best customers quit and your worst
    stay for reasons that only they will ever know. Comparing churn rates (which are
    averages) of groups makes sense, but you cannot expect all customers to show exactly
    the same churn behavior.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的一个重要观点是，在较不活跃和较活跃的群体中找到相对较高的和较低的流失率比期望所有活跃客户都不流失，所有不活跃客户都流失更现实。流失涉及很多明显的随机性：有时，你的最佳客户会离开，而最差的客户会留下，原因只有他们自己知道。比较群体的流失率（平均值）是有意义的，但你不能期望所有客户都表现出完全相同的流失行为。
- en: '![](../Images/5-02.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5-02.png)'
- en: Figure 5.2 The concept of metric cohorts
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2 指标群体的概念
- en: 'Next, consider how a cohort analysis is going to work in practice, given the
    dataset that you created in chapter 4\. When you finished that chapter, you created
    a dataset, which is one big table of data, and on each row, you have one observation
    of a customer on a particular date, including several metrics and whether the
    customer churned or renewed on that date. The process of making a metric cohort
    analysis on a single metric, illustrated in figure 5.3, is as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，考虑在实际情况中，如何进行群体分析，考虑到你在第4章中创建的数据集。当你完成那一章时，你创建了一个数据集，这是一个包含大量数据的大表格，每一行代表一个特定日期上客户的观察结果，包括多个指标以及客户在该日期是否流失或续订。在单个指标上进行的指标群体分析过程，如图5.3所示，如下进行：
- en: Start from a complete dataset that contains observations of customers, including
    the metric of interest and whether the customers churn. Some customers can be
    considered more than once if they renew. The data most likely starts sorted by
    date and by account ID, assuming that it was created by means of the process described
    in chapter 4.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从一个包含客户观察数据的完整数据集开始，这些数据包括感兴趣的指标以及客户是否流失。如果客户续订，某些客户可能被考虑多次。假设数据是通过第4章中描述的过程创建的，数据最有可能按日期和账户ID排序。
- en: Using the metric and the variable representing churn or nonchurn, sort those
    observations by the metric. The identity of the accounts and the observation date
    are ignored for the rest of the cohort analysis.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用指标和表示流失或非流失的变量，按指标对这些观察结果进行排序。在队列分析的其余部分，账户的身份和观察日期被忽略。
- en: Group the observations into the cohorts by dividing the observations into a
    preselected number of equal-size groups. In a real cohort analysis, you typically
    use 10 cohorts, so each cohort contains 10% of the data. (In the simple example
    shown in figures 5.1 and 5.2, only three cohorts are used.) Note that you do not
    decide in advance where the boundaries of the cohorts ought to be; the boundaries
    between cohorts are a result of the analysis.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将观察结果按预选的等大小组分组到队列中。在实际的队列分析中，通常使用10个队列，因此每个队列包含10%的数据。（在图5.1和图5.2所示的简单示例中，只使用了三个队列。）请注意，您事先并不决定队列的边界在哪里；队列之间的边界是分析的结果。
- en: 'For each cohort, make two calculations:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个队列，进行两个计算：
- en: The average value of the metric for all observations in the cohort
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 队列中所有观察结果的指标平均值
- en: The percentage of churns in the cohort observations
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 队列观察中流失的百分比
- en: Plot the average metric values and churn rates with the average metric on the
    x-axis and the churn rate on the y-axis.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在x轴上用平均指标值，在y轴上用流失率绘制平均指标值和流失率图。
- en: '![](../Images/5-03.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/5-03.png)'
- en: Figure 5.3 Metric cohort analysis example
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3 指标队列分析示例
- en: 'It might surprise you that the identity of the customers and the date of the
    observation don’t matter for the cohort analysis. Because our dataset is normally
    formed with multiple observations of most customers, the same customer generally
    appears many times in your cohorts. Sometimes, a customer appears more than once
    in one cohort; at other times, the same customer appears in different cohorts.
    Though this situation may be confusing, it makes sense: you are investigating
    the hypothesis that the behavior represented by the metric is related to churn,
    not that the identity of the customer or the timing of the observation is related
    to churn.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 可能会令您惊讶的是，客户身份和观察日期在队列分析中并不重要。因为我们的数据集通常包含大多数客户的多个观察结果，所以同一个客户通常会在您的队列中出现多次。有时，一个客户在一个队列中会出现多次；在其他时候，同一个客户出现在不同的队列中。尽管这种情况可能令人困惑，但这是有道理的：您正在研究这样一个假设，即指标所代表的行为与流失有关，而不是客户身份或观察时间与流失有关。
- en: That said, you may not want to explain this detail to your business colleagues,
    because it can lead to confusion. As discussed in more detail in the sidebar “Analyzing
    how cohorts change over time” (section 5.1.4), you can test whether both the behavior
    and the timing of the observation matter, but for now, we continue to explore
    whether the behavior alone is relevant.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，您可能不想向您的业务同事解释这个细节，因为它可能会导致混淆。如侧边栏“分析队列随时间的变化”中更详细地讨论的那样（第5.1.4节），您可以测试观察的行为和时间是否都重要，但到目前为止，我们继续探索行为本身是否相关。
- en: TAKEAWAY Metric cohorts are groups of observations of a customer metric and
    churn; they are not the same as groups of customers, because one customer can
    be observed multiple times.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**要点** 指标队列是客户指标和流失的观察结果组；它们不同于客户组，因为一个客户可以被观察多次。'
- en: WARNING It is important to understand that one customer can appear multiple
    times in a cohort analysis, but you probably should not explain this fact to your
    business colleagues, because they might find it confusing.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**警告** 理解一个客户可以在队列分析中出现多次是很重要的，但您可能不应该向您的业务同事解释这个事实，因为他们可能会觉得困惑。'
- en: 5.1.2 Cohort analysis with Python
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.2 使用Python进行队列分析
- en: 'Figure 5.4 shows a cohort analysis on the simulated dataset that was performed
    and plotted with Python. The metric is posts per month and is plotted on the x-axis:
    the cohort averages for the metric range are from near 0 to more than 175\. The
    churn rates are plotted against the y-axis and range from around 0.02 to 0.12\.
    The churn rate decreases dramatically over the cohorts, so behavior has the expected
    relationship to churn for the simulated social network.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4显示了使用 Python 执行并绘制的模拟数据集的队列分析。度量是每月帖子数，绘制在x轴上：该度量值的队列平均值范围从接近0到超过175。流失率绘制在y轴上，范围从大约0.02到0.12。流失率在队列中急剧下降，因此行为与模拟社交网络的流失率有预期的关系。
- en: The pattern shown by the simulated data in figure 5.4 is extremely common in
    real churn case studies. Churn falls rapidly as you move up the bottom cohorts,
    but the fall in churn rate decelerates and can even level out in the top cohorts.
    This pattern makes it easy to identify the metric’s healthy level. For posts per
    month in the simulation, above 25 is healthy because at that point, further increases
    don’t have observable effects on the churn rate.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4中模拟数据所显示的图案在真实的流失案例研究中极为常见。随着向上移动到底层队列，流失率迅速下降，但流失率的下降速度减慢，甚至可能在顶层队列中趋于平稳。这种模式使得很容易识别度量的健康水平。对于模拟中的每月帖子数，超过25是健康的，因为在此点之后，进一步的增加对流失率没有可观察的影响。
- en: 'I will show you real case studies in section 5.1.3, but first, let’s look at
    the code to perform cohort analysis. Listing 5.1 shows a Python function that
    performs a single metric cohort analysis using Pandas `DataFrame`s. The function
    has the following inputs:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我将在5.1.3节中展示真实的案例研究，但首先，让我们看看执行队列分析的代码。列表5.1显示了一个使用 Pandas `DataFrame` 执行单个度量队列分析的
    Python 函数。该函数具有以下输入：
- en: '`data_set_path`—A path to a dataset saved in a file, given by a string variable'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_set_path` — 一个字符串变量给出的数据集文件路径'
- en: '`metric_to_plot`—The name of a metric to make the cohort plot, given by a string
    variable'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metric_to_plot` — 要创建队列图的度量名称，由一个字符串变量给出'
- en: '`ncohort`—The number of cohorts to use, given by an integer variable'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ncohort` — 要使用的队列数量，由一个整型变量给出'
- en: '![](../Images/5-04.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图5-04](../Images/5-04.png)'
- en: Figure 5.4 Cohort analysis of posts per month for the simulated customer dataset
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4 每月帖子数模拟客户数据集的队列分析
- en: 'Given these inputs, the following are the main steps you use to create a cohort
    plot:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 给定这些输入，您创建队列图的主要步骤如下：
- en: Load the dataset into a Pandas `DataFrame` object, and set the `DataFrame` index.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集加载到 Pandas `DataFrame` 对象中，并设置 `DataFrame` 索引。
- en: Use the `DataFrame` member function `qcut` to divide the observations into cohorts.
    This function returns a series. The series length is the same as the number of
    observations, and the series values are integers representing the group assignments.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `DataFrame` 成员函数 `qcut` 将观测值划分为队列。此函数返回一个序列。序列长度与观测值的数量相同，序列值是表示分组分配的整数。
- en: Calculate the average metric and the average churn rate, using the `DataFrame`
    function `groupby` and passing the `qcut` result (the series of group identifiers)
    as the parameter.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `DataFrame` 函数 `groupby` 和传递 `qcut` 结果（组标识符的序列）作为参数，计算平均度量值和平均流失率。
- en: Make a new `DataFrame` from the averages and churn rates.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从平均值和流失率中创建一个新的 `DataFrame`。
- en: Plot the result, using `matplotlib.pyplot`, and add the appropriate labeling
    before saving.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `matplotlib.pyplot` 绘制结果，并在保存之前添加适当的标签。
- en: 'Note that this procedure has one important difference from the solution to
    the example problem in section 5.1.1: rather than sorting the data, forming the
    cohorts, and calculating the averages by using your logic, the code relies on
    Pandas `DataFrame.qcut` and `DataFrame.groupby` functions. `qcut` is short for
    quantile-based discretization, which is a technical term for the kind of cohort
    groups that we are making, drawing explicitly on the notion of a quantile.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，此过程与5.1.1节中示例问题的解决方案有一个重要区别：而不是通过排序数据、形成队列和使用您的逻辑计算平均值，代码依赖于 Pandas `DataFrame.qcut`
    和 `DataFrame.groupby` 函数。`qcut` 是基于分位数离散化的缩写，这是我们所形成的队列组的术语，明确地基于分位数的概念。
- en: DEFINITION A quantile is a value that results as a dividing point when data
    is divided into equal groups, each containing the same fraction of the total number
    of observations. A decile is a quantile when the data is divided into 10 groups,
    with each of the groups containing 10% of the data. A percentile is a quantile
    when the data is divided into 100 groups, each containing 1% of the data.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 定义：分位数是当数据被分成相等的组时，作为分割点出现的一个值，每个组包含相同比例的总观测数。十分位数是当数据被分成 10 组时，每个组包含 10% 的数据。百分位数是当数据被分成
    100 组时，每个组包含 1% 的数据。
- en: The first decile is the value of the metric that divides the first 10% of the
    data from the second 10% of the data when the data is organized by the metric.
    The second decile is the value of the metric that divides the second 10% of the
    data from the third 10% of the data, and so on. In a mathematical context, discrete
    means separate (or not continuous). The groups are discrete in the sense that
    membership in them is all or nothing (not discreet in the sense of something secretive
    or hidden). The `qcut` function is named quantile-based discretization because
    the data is divided into discrete groups by the values of the quantiles.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个十分位数是将数据按指标组织时，将前 10% 的数据与后 10% 的数据分开的指标值。第二个十分位数是将第二个 10% 的数据与第三个 10% 的数据分开的指标值，依此类推。在数学语境中，离散意味着分开（或不连续）。这些组是离散的，因为它们的成员资格要么全部要么没有（不是指秘密或隐藏的离散）。`qcut`
    函数被称为基于分位数离散化，因为数据是根据分位数的值被分成离散组的。
- en: Listing 5.1 Metric cohorts in Python
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.1 Python 中的指标队列
- en: '[PRE0]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ① Checks the dataset path
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ① 检查数据集路径
- en: ② Loads the dataset into a Pandas DataFrame object and sets the index
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ② 将数据集加载到 Pandas DataFrame 对象中并设置索引
- en: ③ Groups into cohorts and returns a series of the group numbers
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 将数据分组并返回一系列的组编号
- en: ④ Calculates the means of the metric for the cohorts
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 计算队列指标的均值
- en: ⑤ Calculates the churn rates of the cohorts
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 计算队列的流失率
- en: ⑥ Opens a new figure
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 打开一个新的图形
- en: ⑦ Makes a new DataFrame from the cohorts
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ⑦ 从队列中创建一个新的 DataFrame
- en: ⑧ Plots the cohort churn rate vs. the cohort metric average
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ⑧ 绘制队列流失率与队列指标平均值的对比图
- en: ⑨ Adds axes labels
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ⑨ 添加坐标轴标签
- en: ⑩ Saves and closes the figure
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ⑩ 保存并关闭图形
- en: Writing your own algorithms vs. using off-the-shelf module functions
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 编写自己的算法与使用现成的模块函数
- en: If you are still in a computer science or programming class, you may think it’s
    cheating to use a function like `DataFrame``.qcut` to implement an algorithm,
    because normally, a computer science education is about writing your own algorithms.
    Or maybe you think that in a book like this one, it’s cheating to use such a function
    because books are supposed to teach you to write algorithms. In this context,
    however, using the Pandas algorithm is the best practice.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还在计算机科学或编程课程中，您可能会认为使用像 `DataFrame.qcut` 这样的函数来实现算法是作弊，因为通常，计算机科学教育是关于编写自己的算法。或者，您可能认为在这类书中使用这样的函数是作弊，因为书籍应该教会您编写算法。然而，在这种情况下，使用
    Pandas 算法是最佳实践。
- en: In case you haven’t noticed, there is plenty of work to do in analyzing churn
    without reinventing the wheel by writing an algorithm to divide data into groups.
    The same goes for calculating the average and churn rate by using the `DataFrame.groupby`
    function; there’s no reason to write your own logic when a standard module function
    does exactly what you need to do. I take this approach throughout the book, always
    trying to achieve goals by using algorithms that are part of a standard module.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还没有注意到，在分析流失率时，有很多工作要做，而且无需重新发明轮子，即通过编写将数据分组到组中的算法。同样，使用 `DataFrame.groupby`
    函数计算平均值和流失率也是如此；当标准模块函数正好满足您的需求时，就没有必要编写自己的逻辑。我在整本书中都采用这种方法，总是试图通过使用标准模块中的算法来实现目标。
- en: Given that the `DataFrame.qcut` and `DataFrame.groupby` functions perform the
    main steps in the algorithm, half of listing 5.1 is concerned with plotting the
    result. Because this listing is the first plotting code in this book, I want to
    briefly mention the importance of clearly labeling all plots and figures that
    you produce in your analysis.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 `DataFrame.qcut` 和 `DataFrame.groupby` 函数在算法中执行主要步骤，列表 5.1 的一半内容都关注于结果的绘制。因为这是本书中的第一个绘图代码，我想简要提及在分析中清楚地标注所有生成的图表和图形的重要性。
- en: WARNING Clearly label all plots produced by your analysis. The businesspeople
    with whom you share your analysis won’t be familiar with the details, and if you
    don’t label the results clearly, the plots will be difficult for them to follow.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 警告：清楚地标注您分析产生的所有图表。与您分享分析的商业人士可能不熟悉细节，如果您没有清楚地标注结果，他们可能难以理解这些图表。
- en: Labeling the results also helps you later, when you come back to your analysis
    and try to remember what the results mean, especially if you have a lot of events
    and metrics. You may have to sift through dozens or even hundreds of cohort plots,
    which will be impossible if you don’t build clear annotation into your process.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 标注结果也有助于您以后回顾分析时记住结果的意义，尤其是如果您有很多事件和指标。您可能需要筛选数十个甚至数百个群体图，如果您没有在过程中构建清晰的注释，这将是不可能的。
- en: If you haven’t done so already, run listing 5.1 to test it with your own data.
    Assuming that you have set up your environment (instructions are in the README
    file in this book’s GitHub repository at [https://github.com/carl24k/fight-churn](https://github.com/carl24k/fight-churn))
    and are using the Python wrapper program, run listing 5.1 with the command
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还没有这样做，请运行列表5.1以使用您自己的数据测试它。假设您已经设置了您的环境（说明在本书GitHub仓库中的README文件中，网址为[https://github.com/carl24k/fight-churn](https://github.com/carl24k/fight-churn)），并且正在使用Python包装程序，请使用以下命令运行列表5.1：
- en: '[PRE1]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The result should be a .png file with a cohort plot that looks like figure 5.4.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应该是一个看起来像图5.4的群体图（cohort plot）的.png文件。
- en: 5.1.3 Cohorts of product use
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.3 产品使用群体
- en: Figure 5.5 displays a first example of a cohort analysis from a real case study
    that shows churn in metric cohorts for Broadly’s customers. An important event
    for Broadly’s customers is the number of online reviews that are updated, so a
    metric is calculated for the number of reviews updated per month.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.5展示了从真实案例研究中得出的第一个群体分析示例，显示了Broadly客户的指标群体中的流失情况。对于Broadly的客户来说，一个重要的事件是更新的在线评论数量，因此计算了每月更新的评论数量作为指标。
- en: '![](../Images/5-05.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5-05.png)'
- en: Figure 5.5 Cohort analysis of churn for Broadly’s metric (reviews updated per
    month)
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.5 广泛的指标（每月更新的在线评论）的群体流失分析
- en: 'Because this figure illustrates the first real metric cohort churn case study
    in this book, I need to make an important point that holds true for all other
    studies in the book that are based on real companies (not simulations): figure
    5.5 does not show actual churn rates as percentages on the y-axis. Instead, the
    y-axis is unlabeled, and the churn rate is described as relative. The actual churn
    rates are omitted to protect the privacy and business interests of the companies
    in the case studies, but you can still see the significance of the difference
    in churn between cohorts because the bottom of the cohort plots is always fixed
    at zero churn. As a result, the distance of the points from the bottom of the
    chart shows the relative churn rates of the cohorts.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 因为这个图展示了本书中第一个真正的指标群体流失案例研究，所以我需要提出一个重要的观点，这个观点适用于本书中所有基于真实公司（而非模拟）的其他研究：图5.5并没有在y轴上显示实际的流失率百分比。相反，y轴没有标签，流失率被描述为相对的。实际的流失率被省略，以保护案例研究中公司的隐私和商业利益，但您仍然可以看到群体之间流失差异的重要性，因为群体图的底部始终固定在零流失。因此，点与图表底部之间的距离显示了群体的相对流失率。
- en: For Broadly’s metric, the churn rate is highest in the first cohort and declines
    over the first five cohorts; the churn rate in the top three cohorts (on the right
    side of the plot, with the highest metric values) is around half the churn rate
    in the bottom cohort. You can tell that the churn in the top cohort is around
    half the churn in the bottom cohort by noting that it is approximately half the
    distance to the bottom of the graph, using the equally spaced grid lines. (To
    be precise, the churn in the top cohort of figure 5.5 is a bit more than half
    the churn rate of the bottom cohort.) Another point worth noting in figure 5.5
    is that the reduction in churn rate occurs between the cohorts that have around
    zero review updates per month and those that have four review updates per month;
    after four review updates per month, there is no further reduction in churn rate.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Broadly的指标，流失率在第一个群体中最高，并在前五个群体中下降；顶部三个群体（图表右侧，具有最高指标值）的流失率大约是底部群体的半数。你可以通过注意到它大约是图表底部距离的一半，使用等间距的网格线，来判断顶部群体的流失率大约是底部群体的一半。（为了精确起见，图5.5顶部群体的流失率略高于底部群体的半数。）图5.5中另一个值得注意的点是，流失率的下降发生在每月大约零次评论更新和每月四次评论更新之间的群体之间；每月四次评论更新后，流失率没有进一步下降。
- en: '![](../Images/5-06.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/5-06.png)'
- en: Figure 5.6 Cohort analysis of churn for Klipfolio’s metric (dashboard edits
    per month)
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.6 Klipfolio指标（每月仪表盘编辑次数）的流失率群体分析
- en: Figure 5.6 shows another example of a metric cohort churn case study for Klipfolio.
    This figure shows a case study in metric cohort analysis, using the metric dashboard
    edits per month calculated on Klipfolio’s customers. As in figure 5.5, churn rates
    are shown on a relative scale, with the bottom of the plot fixed to zero churn.
    In this case, the churn rate of the top cohorts is a fraction of that of the bottom
    cohorts (about 10%).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.6展示了Klipfolio的另一个指标流失率案例研究。此图显示了使用Klipfolio客户计算的指标仪表盘每月编辑次数的指标群体分析案例。与图5.5类似，流失率以相对尺度显示，图表底部固定为零流失率。在这种情况下，顶部群体的流失率是底部群体的几分之一（大约10%）。
- en: Figure 5.7 shows another metric cohort churn example, using Versature’s metric
    for total local-call times per month. This figure depicts another fairly typical
    relationship between an important behavioral metric and churn. The cohorts with
    more than 2,500 total local-call times per month churn at around a third the rate
    of the bottom cohort, which makes practically no calls. The reduction in churn
    rate happens between zero and 2,500, after which the churn rate seems to increase
    slightly but not significantly.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.7展示了另一个使用Versature每月总本地通话时间指标的指标流失率示例。此图描绘了另一个重要行为指标与流失率之间相当典型的关系。每月总本地通话时间超过2,500次的群体，其流失率大约是底部群体的三分之一，而底部群体几乎不打电话。在零和2,500之间，流失率有所下降，之后流失率似乎略有上升但并不显著。
- en: '![](../Images/5-07.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/5-07.png)'
- en: Figure 5.7 Cohort analysis of churn for Versature’s metric local-call times
    per month
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.7 Versature每月本地通话时间指标的流失率群体分析
- en: Looking at the distribution of local calls (not churn rates) in figure 5.7,
    note that most of the cohorts are compressed on the left side of the graph in
    the low range. In fact, seven cohorts occupy a sixth of the figure (the region
    between 0 and 5,000 calls). This figure shows that the cohort with the most calls
    makes a lot more calls than the others, so even the second-highest cohort has
    less than a third as many calls on average. This example shows a skewed behavioral
    metric.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 观察图5.7中本地通话（而非流失率）的分布，请注意，大多数群体在图表左侧的低范围内被压缩。实际上，七个群体占据了图的一部分（0到5,000次通话之间的区域）。此图显示，通话次数最多的群体比其他群体通话次数多得多，因此即使是第二高的群体，平均通话次数也少于三分之一。这个例子展示了一个偏斜的行为指标。
- en: DEFINITION A skewed metric is one in which the top cohort contains values several
    times higher than those of the next-closest cohort. Typically, most of the lower
    cohorts have averages within a relatively small range.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 定义：一个偏斜的指标是指顶部群体包含的值比下一个最接近的群体高几倍。通常，大多数较低群体的平均值在一个相对较小的范围内。
- en: Skew is an important concept in metrics, as I’ll explain in section 5.2.1\.
    Skew can cause problems in your analysis, beginning with the fact that figure
    5.6 is a bit hard to read. Most of the space is taken up by the top two cohorts;
    the others are squeezed together. This arrangement is a natural result of skew
    in the distribution of metric values, because the top cohorts are many multiples
    above the rest. Skew causes another problem when you try to understand the relationships
    among metrics, as described in chapter 6\. For that reason, I teach the technique
    known as scoring metrics in section 5.3.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 偏斜在度量指标中是一个重要的概念，我将在5.2.1节中解释。偏斜可能会在分析中引起问题，首先就是5.6图有点难以阅读。大部分空间都被前两个队列占据了；其他的则挤在一起。这种安排是度量值分布偏斜的自然结果，因为顶级队列的数值远高于其他队列。当你尝试理解指标之间的关系时，偏斜也会引起另一个问题，正如第6章所述。因此，我在5.3节中介绍了称为评分指标的技术。
- en: 'I want to call your attention to one more feature of the cohort churn analyses
    in figures 5.5, 5.6, and 5.7: they all have the same overall shape, with the cohort
    churn rates falling rapidly in the first couple of cohorts; for higher cohorts,
    the churn rate is more or less constant. This result is common, and it’s the reason
    why the simulation shown in figure 5.4 was crafted to act that way.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我想提醒你注意5.5、5.6和5.7图中队列换率分析的另一个特点：它们都具有相同的整体形状，前几个队列的队列换率迅速下降；对于更高队列，换率大致保持恒定。这种结果是常见的，这也是为什么图5.4中显示的模拟被设计成那样的原因。
- en: 'The fact that churn rates fall with behavior and then level off is both useful
    and a problem. It’s useful because it’s easy to identify a healthy level for the
    metric: the level where churn rates stop declining. It’s a problem because after
    a certain point, that metric no longer helps you understand churn or segment customers
    based on churn risk. In terms of intervening to reduce churn, getting users to
    take more of certain actions doesn’t make a difference past a certain point. If
    you want to explain differences in the churn rate among customers with high values
    on those metrics and reduce churn among those customers, you need to do something
    else. In chapters 6 and 7, you learn techniques to create metrics in which the
    relationship to churn stays strong, even up to the top cohorts.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 换率随着行为减少然后趋于平稳，这既有用又是一个问题。它有用，因为很容易识别出该指标的健康发展水平：换率停止下降的水平。它是一个问题，因为到了某个点，该指标就不再帮助你理解换率或根据换率风险细分客户。在干预以减少换率方面，让用户采取更多特定行动在某个点之后就没有区别了。如果你想解释那些指标值较高的客户之间的换率差异并减少这些客户的换率，你需要做些其他事情。在第6章和第7章中，你将学习创建与换率保持强关系的指标的技术，即使是在顶级队列中也是如此。
- en: 5.1.4 Cohorts of account tenure
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.4 账户使用期限的队列
- en: Another common kind of cohort analysis looks at churn based on the length of
    time that customers have been customers—a period that I call account tenure. This
    form of cohort analysis is the most common, so if you have seen a cohort-based
    churn analysis, it was probably based on tenure.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种常见的队列分析类型是查看基于客户成为客户的时间长度的换率——我称之为账户使用期限。这种形式的队列分析是最常见的，所以如果你看到过基于队列的换率分析，它很可能是基于使用期限的。
- en: This type of cohort analysis is the same as metric cohort analysis except that
    it looks at account tenure instead of behavior. Also, you usually expect to find
    that customers who have been customers for a long time are less likely to churn
    and that newer customers are more likely to churn. A cohort analysis using account
    tenure serves as a test of that hypothesis. Because account tenure is calculated
    as an account metric, this type of cohort analysis is performed with exactly the
    same code that was used in the behavioral metric cohort analysis in section 5.1.3.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的队列分析与度量指标队列分析相同，只是它查看的是账户使用期限而不是行为。此外，你通常预期会发现，长期客户不太可能流失，而新客户更有可能流失。使用账户使用期限进行的队列分析是对该假设的检验。因为账户使用期限是作为账户指标计算的，所以这种类型的队列分析使用与5.1.3节中行为度量指标队列分析中使用的完全相同的代码进行。
- en: 'Figure 5.8 shows the result of a cohort analysis of account tenure for Klipfolio.
    The results are fairly typical:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.8显示了Klipfolio账户使用期限队列分析的结果。结果相当典型：
- en: Churn is lower for the newest customers (around a month average tenure) than
    for customers of longer duration.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新客户（平均使用期限约为一个月）的换率低于长期客户。
- en: Churn increases in the first half of the year and is about a third higher in
    the third cohort.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在年度前半段，churn 率上升，在第三队列中大约高出三分之一。
- en: Churn decreases for customers between a half-year and one year. But churn increases
    for customers at the end of the first year.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在半年至一年之间，客户的 churn 率下降。但在第一年结束时，客户的 churn 率上升。
- en: After the first year (cohorts with average tenure greater than 365 days), churn
    is lower and declines such that the cohort with the longest tenure (around four
    years) has about a third less churn as the newest cohort.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第一年（平均任期超过 365 天的队列）之后，churn 率较低，并且呈下降趋势，以至于任期最长的队列（大约四年）的 churn 率比最新队列低约三分之一。
- en: 'Though tenure-based cohort analysis is the most common form in the literature
    on churn, the analysis I demonstrated in figure 5.8 is a bit different. The most
    common way to define account tenure cohorts and perform this analysis is to group
    customers by the time that they sign up: month, quarter, or year. After that initial
    cohort assignment, the number of customers remaining in each cohort is tracked
    over time and used to derive the churn rates for each cohort at different points
    in time. By contrast, the method I demonstrate observes customers independently
    on a schedule determined by their own renewals and forms cohorts from all observations
    that have similar values on the tenure measurement.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然基于任期的队列分析在 churn 文献中是最常见的形式，但我图 5.8 中展示的分析略有不同。定义账户任期队列和执行此分析的最常见方式是按客户注册的时间分组：月份、季度或年份。在最初队列分配之后，每个队列中剩余客户的数量会随着时间的推移而跟踪，并用于推导出不同时间点的每个队列的
    churn 率。相比之下，我展示的方法是独立观察客户，观察的频率由他们自己的续订周期决定，并从所有在任期测量上具有相似值的观察中形成队列。
- en: '![](../Images/5-08.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5-08.png)'
- en: Figure 5.8 Cohort analysis of churn for Klipfolio’s account tenure metric
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.8 Klipfolio 账户任期 churn 队列分析
- en: One advantage of this approach is that the churn rate for more seasoned (longer-tenure)
    cohorts is estimated on a larger pool of customers, because the older cohorts
    combine customers who signed up at different times. A potential disadvantage is
    that this cohort analysis does not show how the churn rate in cohorts of a given
    tenure can change over time, because the tenure cohort analysis method blends
    observations of customers who signed up at different times.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的一个优点是，对于更成熟的（任期较长的）队列，churn 率是在更大的客户池中估计的，因为较老的队列结合了在不同时间注册的客户。一个潜在的缺点是，这种队列分析没有显示给定任期的队列
    churn 率如何随时间变化，因为任期队列分析方法是混合了在不同时间注册的客户的观察结果。
- en: Analyzing how cohorts change over time
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 分析队列随时间的变化
- en: Usually, there are no significant differences in churn rates for customers of
    the same tenure who signed up a few months apart. Any differences may be due to
    random variation or driven by seasonality. But if you wait a year or more, churn
    patterns might change considerably.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，对于在几个月内注册的相同任期的客户，churn 率没有显著差异。任何差异可能是由随机变化或季节性驱动的。但如果你等待一年或更长时间，churn 模式可能会发生相当大的变化。
- en: To check whether any relationship between churn and a metric has changed, I
    recommend using the methods in chapter 4 to create different datasets for different
    periods and then comparing the results on separate cohort analyses. You might
    create one dataset of only observations from the past year and another dataset
    from observations of the previous year, for example. (Using one-year periods for
    the datasets should control seasonality.) If you see significant differences between
    the cohort churn rates for the different datasets, the relationship between churn
    and tenure changed between those two years. You can use this approach when changes
    in your product or marketing strategy result in different customer behavior during
    different time periods. Create a dataset for each time period, and compare your
    cohort analyses from the different datasets. (See section 5.1.6 for discussion
    of the minimum number of observations needed.)
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查 churn 与某个指标之间的关系是否发生了变化，我建议使用第 4 章中的方法为不同时期创建不同的数据集，然后比较不同队列分析的结果。例如，您可以创建一个只包含过去一年观察结果的数据集，以及另一个来自前一年观察结果的数据集。（使用一年期的数据集应该可以控制季节性。）如果您在不同数据集的队列
    churn 率之间看到显著差异，那么 churn 与任期之间的关系在这两年之间发生了变化。当您的产品或营销策略的变化导致不同时间段内客户行为不同时，可以使用这种方法。为每个时间段创建一个数据集，并比较来自不同数据集的队列分析。（有关所需观察数的最小数量的讨论，请参阅第
    5.1.6 节。）
- en: 5.1.5 Cohort analysis of billing period
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.5 账单周期队列分析
- en: 'Metrics based on customer subscriptions can be analyzed with cohort analysis.
    Figure 5.9 shows an analysis of churn and subscription billing among Broadly customers
    with monthly or annual billing periods. The figure illustrates two cohorts because
    there are only two distinct values for the billing period, which appear in the
    plot as points at 1 and 12 because the billing period is measured in months. Broadly’s
    customers show a typical pattern: customers with annual billing churn at a significantly
    lower rate than customers with monthly billing.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 基于客户订阅的指标可以通过群体分析进行评估。图5.9展示了 Broadly 客户在每月或年度计费周期内的流失和订阅计费分析。该图展示了两个群体，因为计费周期只有两个不同的值，在图表中以1和12的点出现，因为计费周期是以月份来衡量的。Broadly
    的客户显示出典型的模式：年度计费的客户流失率显著低于每月计费的客户。
- en: '![](../Images/5-09.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![图5.9](../Images/5-09.png)'
- en: Figure 5.9 Cohort analysis of churn for Broadly's customers having monthly versus
    annual billing periods
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.9 Broadly 客户按月度和年度计费周期进行的流失群体分析
- en: The result in figure 5.9 is based on monthly churn rates, due to monthly observation.
    It may seem strange to analyze annual customers this way, however, because an
    annual customer has the opportunity to churn only once each year. Another possible
    approach is to do separate metric cohort analyses on annual and monthly customers
    and then observe the annual customers once a year. That technique can work if
    you have a lot of annual customers, but it is usually a problem, because you have
    far fewer observations of annual customers than of monthly customers. As a result,
    you may not have enough annual customer observations to make a separate behavioral
    analysis.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.9中的结果基于月度流失率，因为进行了月度观察。以这种方式分析年度客户可能看起来有些奇怪，然而，因为年度客户每年只有一次流失的机会。另一种可能的方法是对年度和月度客户进行单独的指标群体分析，然后每年观察一次年度客户。如果你有很多年度客户，这种技术可以工作，但通常是个问题，因为你对年度客户的观察远少于对月度客户的观察。因此，你可能没有足够的年度客户观察数据来进行单独的行为分析。
- en: 'To understand annual customer behavior, it’s better to combine annual and monthly
    customers. You might think it would be a good idea to observe the annual customers
    once a year and combine them in a single dataset with monthly customers (by changing
    the logic of dataset construction). But then the annual customers would appear
    to churn at a higher rate; by observing them once a year, you implicitly calculate
    an annual churn rate on their cohort. Imagine figure 5.9 showing that annual customers
    churn at a higher rate than monthly customers. If you observe annual billing customers
    once a year and want to compare them with monthly customers, you have to convert
    the monthly customer churn rate to annual, thereby showing the true relationship:
    monthly billing customers have a higher annual churn rate. The best choice is
    to observe mixed populations of monthly and annual customers with monthly observations.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解年度客户行为，最好是将年度和月度客户结合起来。你可能认为每年观察一次年度客户并将他们与月度客户合并到一个数据集中（通过改变数据集构建的逻辑）是个好主意。但这样年度客户似乎会有更高的流失率；通过每年观察一次，你隐含地计算了他们群体的年度流失率。想象一下图5.9显示年度客户的流失率高于月度客户。如果你每年观察一次年度计费客户并想与他们进行比较，你必须将月度客户的流失率转换为年度，从而显示真实的关系：月度计费客户的年度流失率更高。最佳选择是观察每月和年度客户的混合群体，并每月进行观察。
- en: 5.1.6 Minimum cohort size
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.6 最小群体大小
- en: An important issue in analyzing churn with cohorts is the number of observations
    made in each cohort. You need enough observations in each cohort that when you
    estimate the cohort churn rates, the estimates are likely to be accurate. Remember
    from the discussion in chapter 1 that churn is affected by a lot of random factors
    that are outside your knowledge and influence. When you estimate the churn rate
    in a cohort based on the metric, part of the result is due to the influence of
    the metric and part is due to all the other things. The idea is that you need
    a lot of observations to make all those “other things” cancel out and show the
    influence of the metric. How many is “a lot” depends, but a simple rule of thumb
    is that you should have 200 to 300 observations in each cohort, and preferably
    thousands.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用群体分析流失问题时，每个群体中观察到的数量是一个重要的问题。你需要每个群体中有足够的观察数据，这样当你估计群体的流失率时，估计结果更有可能是准确的。记得从第1章的讨论中，流失受到许多你不知道和影响的随机因素的影响。当你根据指标估计群体的流失率时，结果的一部分是由于指标的影响，另一部分是由于所有其他因素。想法是，你需要大量的观察数据来使所有那些“其他因素”相互抵消并显示出指标的影响。多少是“大量”取决于具体情况，但一个简单的经验法则是，你应该在每个群体中有200到300个观察数据，最好是几千个。
- en: TAKEAWAY Every cohort should have at least 200 to 300 observations, and preferably
    a few thousand.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '**要点**：每个群体至少应有200到300个观察数据，最好是几千个。'
- en: 'Note that I am talking about how many observations should be in each cohort,
    not how many customers. If you have 500 customers with monthly renewals, and you
    observe their behavior (metrics and churn) for six months, you will have around
    3,000 observations. If you form 10 cohorts, each cohort will have 300 observations,
    so you should be good. The problem with minimum cohort size comes up with annual
    renewals: if you have 500 customers with annual renewals, after an entire year,
    you have only 500 observations.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我在谈论每个群体中应该有多少观察数据，而不是有多少客户。如果你有500个客户，每月续订，并且你观察他们的行为（指标和流失）六个月，你将有大约3,000个观察数据。如果你形成10个群体，每个群体将有300个观察数据，那么你应该没问题。问题是，最小群体大小出现在年度续订时：如果你有500个客户，年度续订，一年后，你只有500个观察数据。
- en: If you have too few observations in each cohort, the first thing you should
    do is use fewer cohorts. Given the example of 500 observations, you could form
    three cohorts of 167, 167, and 166\. At least you’d have more than 100 observations
    in each cohort, if not the few hundred that you want. Then your cohorts would
    represent low, medium, and high levels of the metric you are analyzing.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你每个群体中的观察数据太少，你应该做的第一件事是使用更少的群体。以500个观察数据的例子来说，你可以形成三个群体，167个、167个和166个。至少你每个群体中会有超过100个观察数据，如果不是你想要的几百个。然后你的群体将代表你正在分析的指标的低、中、高三个水平。
- en: WARNING It is more important to have enough observations in a few cohorts than
    to have a lot of cohorts in a cohort analysis. Reduce the number of cohorts accordingly.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '**警告**：在群体分析中，有足够的观察数据在少数几个群体中比有大量群体更重要。相应地减少群体的数量。'
- en: If you still have fewer than 200 observations in each cohort, you are getting
    into a danger zone where the noise of random events can overwhelm the signal you
    are looking for in the metric-based cohorts. Around 100 observations might still
    work if your churn rate is relatively high—well in the double digits (greater
    than 20%). That is because if the churn rate is fairly high, the influence of
    random factors on the churn rate is likely to be relatively small. But when the
    churn rate is low (below 10%), random external factors are more likely to be significant
    in comparison with the influence of the metric. So if your churn rate is low,
    you need even more observations to cancel out the noise and reveal the trend.
    If your churn rate is low, you should not try to do an analysis until you have
    at least 200 observations per cohort, and preferably a lot more.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你每个群体中的观察数据仍然少于200个，你将进入一个危险区域，其中随机事件的噪声可能会压倒你在基于指标的群体中寻找的信号。如果你的流失率相对较高——两位数以上（大于20%），大约100个观察数据可能仍然有效。这是因为如果流失率相当高，随机因素对流失率的影响可能相对较小。但是，当流失率低（低于10%）时，与指标的影响相比，随机外部因素更有可能变得重要。所以如果你的流失率低，你需要更多的观察数据来抵消噪声并揭示趋势。如果你的流失率低，你不应该在每个群体至少有200个观察数据之前尝试进行分析，最好是更多。
- en: Another rule of thumb is to have at least 100 churns in an analysis. For example,
    if your churn rate is 5%, you should have a total of around 2,000 observations
    (because to end up with 100 churn observations from a 5% churn rate, you would
    have to have 100 / 0.05 = 2,000 observations). Usually, the lower limits on the
    number of observations and churns aren’t a problem; most companies focus initially
    on customer acquisition and think about churn only when they have been in operation
    for some time. But a variety of issues can limit the number of observations, such
    as having a short history of events in the data warehouse, and you should be aware
    of those limitations.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 另一条经验法则是分析中至少要有100个客户流失。例如，如果你的客户流失率是5%，你应该有大约2,000个观察值（因为要从5%的客户流失率中得到100个客户流失观察值，你需要有100
    / 0.05 = 2,000个观察值）。通常，观察值和客户流失的下限不是问题；大多数公司最初专注于客户获取，只有在运营一段时间后才会考虑客户流失。但是，各种问题可能会限制观察值的数量，例如数据仓库中事件的历史较短，你应该意识到这些限制。
- en: TAKEAWAY If you have fewer than 100 churns in your data, you should focus on
    acquiring new customers and understanding their views qualitatively with surveys
    and focus groups. It will be hard to understand churn from data with so few examples.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 吸收要点：如果你的数据中客户流失少于100例，你应该专注于获取新客户，并通过调查和焦点小组了解他们的观点。在如此少的例子中，从数据中理解客户流失将很困难。
- en: These rough guidelines are based more on practical experience than on rigorous
    statistics. Chapters 8 and 10 discuss some statistics you can use to come up with
    better answers to questions about sample size.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这些粗略的指南更多地基于实践经验，而不是严格的统计。第8章和第10章讨论了一些你可以用来更好地回答关于样本大小问题的统计方法。
- en: 5.1.7 Significant and insignificant cohort differences
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.7 显著和不显著的群体差异
- en: 'So far I have shown you only cases in which a customer metric is clearly related
    to churn. Inevitably, however, you will test some metrics with cohorts and find
    no significant result. Figure 5.10 shows one example for the cloud communication
    services provider Versature. In this case, the metric is the number of extension
    units that customers purchased. The churn rate does not have any clear trend:
    the bottom cohort has about the same churn rate as the top cohort, and the churn
    rates in the middle cohorts bounce around but never differ significantly from
    the average. This behavior is not related to churn.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我只展示了客户指标与客户流失明显相关的案例。然而，不可避免的是，你将测试一些指标，并发现没有显著的结果。图5.10显示了云通信服务提供商Versature的一个例子。在这种情况下，指标是客户购买的扩展单元数量。客户流失率没有明显的趋势：底部群体与顶部群体的客户流失率大致相同，中间群体的客户流失率上下波动，但从未显著偏离平均水平。这种行为与客户流失无关。
- en: '![](../Images/5-10.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/5-10.png)'
- en: Figure 5.10 Cohort analysis when the difference in churn is not significant
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.10 当客户流失差异不显著时的群体分析
- en: Other cases are less clear-cut but not obviously unrelated. In chapter 8, I
    go over using statistics to answer these questions more rigorously, but you can
    often make a reasoned judgment without statistics. If you’re trying to decide
    whether a metric is related to churn, the first question to ask is whether other
    metrics are much more obviously related to churn.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 其他情况不太明确，但并非明显无关。在第8章中，我将讨论如何更严格地使用统计方法来回答这些问题，但你通常可以在没有统计的情况下做出合理的判断。如果你试图决定一个指标是否与客户流失相关，首先要问的问题是是否有其他指标与客户流失有更明显的关系。
- en: TAKEAWAY If you are unsure whether a metric is related to churn, first ask whether
    other obvious metrics have strong relationships to churn. If so, focus on the
    latter metrics, try to use that knowledge in your retention tactics, and come
    back to questionable cases later.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 吸收要点：如果你不确定一个指标是否与客户流失相关，首先询问是否有其他明显的指标与客户流失有很强的关系。如果有，关注这些指标，尝试在保留策略中使用这些知识，稍后再处理有疑问的案例。
- en: 'The only cases to worry about are borderline cases:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一需要担心的是边缘案例：
- en: When you have few metrics that are strongly related to churn
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你只有少数与客户流失强相关的指标时
- en: When a particular metric was expected to relate to churn and a retention or
    engagement strategy has already been planned based on that expectation
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当一个特定的指标预期与客户流失相关，并且基于这种预期已经制定了保留或参与策略时
- en: In such cases, you should look at whether the change in churn rates is consistent
    across cohorts and whether the difference in the lowest and highest churn rate
    cohorts is significant. If churn generally goes from high to low (or low to high),
    and the difference between the highest and the lowest is a factor of at least
    1.5, it’s reasonable to think that you’ve found a potentially useful relationship
    to churn.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，你应该查看流失率的变化是否在队列之间一致，以及最低和最高流失率队列之间的差异是否显著。如果流失率通常从高到低（或从低到高）变化，并且最高和最低之间的差异至少是1.5倍，那么可以合理地认为你发现了一个可能对流失率有意义的关联。
- en: 'Finally, you should think about the business reasons for the relationship to
    churn:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你应该考虑与流失率相关的业务原因：
- en: Does the metric measure something that is closely related to the usefulness
    or customer enjoyment of the product?
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该度量衡是否衡量与产品的有用性或客户满意度密切相关的因素？
- en: Or is the metric peripheral to central features of the product?
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 或者，这些度量衡是否与产品的核心特性无关？
- en: If you strongly believe that the metric should be important, you can give your
    analysis the benefit of the doubt and recheck the result when you have more data.
    On the other hand, if the data doesn’t support a pet theory, don’t keep trying
    too long; that’s an example of being data driven.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你坚信这个度量衡应该很重要，你可以给你的分析留有疑问，并在你拥有更多数据时重新检查结果。另一方面，如果数据不支持一个宠爱的理论，不要尝试太久；这是一个数据驱动的例子。
- en: 'Finally, note that questions of significance are related to sample size, discussed
    in section 5.1.6: if you have a lot of samples, you are more likely to see a meaningful
    relationship. More advanced methods are used to look at these questions in chapters
    8 and 10.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，请注意，显著性问题与样本大小有关，这在第5.1.6节中讨论过：如果你有很多样本，你更有可能看到有意义的关系。更高级的方法在第8章和第10章中用于研究这些问题。
- en: 5.1.8 Metric cohorts with a majority of zero customer metrics
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.8 大多数客户度量衡为零的度量衡队列
- en: 'Another issue you might face in a cohort analysis is that you can have a lot
    of observations with no results for the metric of interest, even when you have
    plenty of observations overall. This situation can happen when an event is rare,
    even if you measure it over a long period (as described in chapter 3). Figure
    5.11 shows an example metric cohort analysis for Klipfolio. Most accounts have
    zero for the metric in question: the number of orientation switches per month
    that users make when viewing their dashboards. In this case, only three cohorts
    are formed by the Python function `DataFrame.qcut`, even though the parameter
    for the cohorts was set to 10.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在队列分析中，你可能会遇到的一个问题是，即使你有很多观察值，你仍然可能对感兴趣的度量衡没有结果。这种情况可能发生在事件很少发生时，即使你在很长的时间内进行了测量（如第3章所述）。图5.11显示了Klipfolio的一个示例度量衡队列分析。大多数账户在所讨论的度量衡上为零：用户查看仪表板时每月进行的导向切换次数。在这种情况下，只有三个队列是由Python函数`DataFrame.qcut`形成的，尽管队列的参数被设置为10。
- en: The cohort plot in figure 5.11 still shows a relationship with churn, but the
    plot does not look quite as expected. If you know the reason, you know that nothing
    is wrong, but you will have to explain to your business colleagues why there are
    only three cohorts. In section 5.4, I show you how to improve on this sort of
    analysis by removing unwanted observations.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.11中的队列图仍然显示出与流失率的关系，但图表看起来并不完全符合预期。如果你知道原因，你会知道没有问题，但你将不得不向你的业务同事解释为什么只有三个队列。在第5.4节中，我向你展示了如何通过去除不想要的观察值来改进这类分析。
- en: '![](../Images/5-11.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图5.11 队列分析中大多数观察值为零](../Images/5-11.png)'
- en: Figure 5.11 Cohort analysis with a majority of zero observations
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.11 大多数观察值为零的队列分析
- en: If an event is rare, and the metric has zero value for most customers, that
    metric is probably not going to have as significant a relationship to churn as
    a behavior in which more accounts participate. To some degree, you should ignore
    rare events and focus on the common ones. There could be exceptional cases, of
    course, if the behavior in question has an important relationship with churn for
    the few accounts involved. Another approach to handling rare behavior metrics
    is to combine them in behavioral groups, as detailed in chapter 6.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个事件很少发生，并且对于大多数客户来说该度量衡的值为零，那么这个度量衡与流失率的关系可能不如更多账户参与的行为那样显著。在某种程度上，你应该忽略罕见事件，专注于常见事件。当然，如果所讨论的行为与少数账户的流失率有重要关系，可能会有例外情况。处理罕见行为度量衡的另一种方法是，如第6章所述，将它们组合在行为组中。
- en: '5.1.9 Causality: Are the metrics causing churn?'
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.9 因果关系：这些度量衡是否导致了流失率？
- en: 'Now you know how to discover when behavioral metrics are related to churn,
    and you have a good sense of when those relationships are significant. But you
    may be wondering about causality (and if you aren’t, now is a good time to start).
    Causality raises these questions:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经知道如何发现行为指标与客户流失之间的关系，并且你对这些关系何时重要有了很好的感觉。但你可能想知道因果关系（如果你还没有，现在是开始的好时机）。因果关系提出了以下问题：
- en: If you see lower churn when a metric is high, do the event and behavior in question
    cause customer retention?
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你看到当指标值高时客户流失率降低，那么所讨论的事件和行为是否导致了客户留存？
- en: Does a low value for a metric (low counts of an event) cause a customer to churn?
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指标（事件发生的低频次）的值低是否会导致客户流失？
- en: Unfortunately, these questions have no simple answers. Advanced statistics can
    be used to analyze questions of causality, but those techniques are beyond the
    scope of this book. For that matter, I don’t recommend using advanced methods
    to understand causality for churn due to the need for a parsimonious, agile analysis
    (chapter 1).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这些问题没有简单的答案。高级统计学可以用来分析因果关系问题，但这些技术超出了本书的范围。就这一点而言，我不建议使用高级方法来理解客户流失的因果关系，因为这需要一种简约、敏捷的分析（第1章）。
- en: 'My approach to causality is as follows: customers churn or don’t churn because
    of the utility or enjoyment they get from using the product or service. Here,
    I mean utility in the economic sense of usefulness and subjective pleasure. If
    the event behind the metric is the act that provides utility to the customer,
    it is fair to say that the event is causing both retention and churn. If the event
    is not the one that provides utility but something that happens along the way,
    it’s fair to say that the event and the metric are associated with customer engagement
    and retention, but not the cause.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我对因果关系的处理方法如下：客户流失或不流失是因为他们从使用产品或服务中获得效用或享受。在这里，我指的是经济意义上的效用和主观愉悦。如果指标的背后的行为是向客户提供效用，那么可以说这个行为既导致了留存也导致了流失。如果事件不是提供效用的行为，而是在过程中发生的事情，那么可以说这个事件和指标与客户参与和留存相关，但不是原因。
- en: How do you know which event provides utility to the customer? You should rely
    on your knowledge of the product and common sense (and if you don’t know, try
    talking to some customers). That said, if you thought that an event provided utility
    to customers but find that it’s related only weakly to churn and retention, you
    may want to rethink your beliefs—another example of being data driven.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 你如何知道哪个事件为顾客提供了效用？你应该依靠你对产品的了解和常识（如果你不知道，可以尝试与一些客户交谈）。话虽如此，如果你认为某个事件为顾客提供了效用，但发现它与流失和留存只有微弱的关联，你可能需要重新考虑你的信念——这是数据驱动的另一个例子。
- en: TAKEAWAY You need to rely on your knowledge of the business to decide whether
    a metric related to churn is causing retention and churn or only associated with
    churn and retention. To cause churn, the event must be closely related to customers
    achieving usefulness from or enjoyment of the product.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: TAKEAWAY 您需要依靠对商业知识的了解来判断与客户流失相关的指标是导致留存和流失，还是仅与留存和流失相关联。要导致客户流失，事件必须与客户从产品中获得效用或享受紧密相关。
- en: The distinction between metrics and events that cause retention or churn and
    those that are associated with it does not make much difference in the analysis
    of churn-related data, but it does make a big difference in your strategies to
    drive retention. If you think an event or metric is associated with retention
    but not causing it, there is no point in trying to encourage your customers to
    take that specific action.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析客户流失相关数据时，区分导致留存或流失的指标和事件与相关联的指标和事件之间的区别并不太大，但在制定留存策略时，这种区别却很大。如果你认为某个事件或指标与留存相关，但不是导致留存的原因，那么尝试鼓励客户采取该特定行动是没有意义的。
- en: WARNING If you do not believe that an event is causing customer retention and
    churn, do not attempt to encourage customers to take that action, even if it is
    strongly associated with churn.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: WARNING 如果你不认为某个事件是导致客户留存和流失的原因，不要尝试鼓励客户采取该行动，即使它与流失有很强的关联。
- en: 5.2 Summarizing customer behavior
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 总结客户行为
- en: By now, you know a lot about how to perform metric cohort analyses of churn
    in relationship to your metrics. You’ve also seen a few issues that might cause
    results to be hard to interpret. One issue is that metrics can be skewed, which
    can make cohort analyses hard to read and hard to compare. Another problem that
    might come up is having a rare event with most of the account metrics resulting
    in zero. These problems are fairly typical and not necessarily wrong, but you
    can do things about them if they are extreme. First, to help diagnose these problems
    and make sure that you are not surprised when they occur, I am going to show you
    how to check these kinds of issues by making a summary of your dataset.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，您已经了解了如何根据您的指标执行流失的指标群体分析。您也看到了一些可能导致结果难以解释的问题。一个问题就是指标可能存在偏斜，这可能会使群体分析难以阅读和比较。另一个可能出现的问题是，大多数账户指标的结果为零的罕见事件。这些问题相当典型，并不一定错误，但如果它们非常极端，您可以采取一些措施。首先，为了帮助诊断这些问题并确保当它们发生时您不会感到惊讶，我将向您展示如何通过制作数据集的摘要来检查这类问题。
- en: A dataset summary helps you check for problems and is also a great way to get
    a sense of the overall range of behaviors exhibited by your customers. That understanding
    will help you plan your customer segments and interventions to increase engagement.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集摘要有助于您检查问题，也是了解您的客户展现出的整体行为范围的好方法。这种理解将帮助您规划客户细分和干预措施，以增加参与度。
- en: 5.2.1 Understanding the distribution of the metrics
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.1 理解指标的分布
- en: A summary of a dataset is a set of measurements of the contents of the dataset—a
    set of metrics on your metrics. The results in the dataset summary give you a
    good idea of the range and variety of your customers’ behaviors. It can also help
    you spot many problems in your data before you waste time doing an analysis.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的摘要是一组对数据集内容的测量——一组对您指标的指标。数据集摘要中的结果可以很好地说明您客户行为的范围和多样性。它还可以帮助您在花费时间进行分析之前发现数据中的许多问题。
- en: TIP You should calculate a set of summary statistics and resolve any data problems
    before you start cohort analysis of churn. I taught you cohort analysis first
    to show you why you want an initial summary.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士：在开始对流失进行群体分析之前，您应该计算一组摘要统计量并解决任何数据问题。我首先教您群体分析，是为了向您展示为什么您需要一个初步的摘要。
- en: The distribution of a metric is what statisticians and analysts use to describe
    these kinds of properties—things like the minimum, maximum, and typical values.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 指标的分布是统计学家和分析人员用来描述这类属性的工具——诸如最小值、最大值和典型值等。
- en: DEFINITION The distribution of a metric refers to the overall set of facts about
    what values a metric takes for customers. Understanding a distribution means knowing—at
    an appropriate level of detail—facts such as how many customers have the metric,
    what the typical values are, and what the minimum and maximum values are.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 定义：一个指标的分布是指关于一个指标对客户取值的整体事实集合。理解分布意味着在适当的细节水平上了解诸如有多少客户具有该指标、典型值是什么以及最小值和最大值是什么等事实。
- en: Figure 5.12 shows such a summary for the simulated social network dataset. Table
    5.1 at the end of this section briefly explains the summary statistics, which
    will be familiar to anyone who has already taken a statistics course. If you want
    more information, many texts and online resources provide in-depth explanation
    of these measures.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.12 展示了模拟社会网络数据集的此类摘要。本节末尾的表 5.1 简要解释了摘要统计量，这些统计量对于已经学习过统计学课程的人来说应该是熟悉的。如果您需要更多信息，许多文本和在线资源提供了对这些措施的深入解释。
- en: '![](../Images/5-12.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/5-12.png)'
- en: Figure 5.12 Examples of summary statistics from the social network simulation
    dataset
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.12 社会网络模拟数据集的摘要统计示例
- en: 'Following are some key points about the dataset summary in figure 5.12:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是关于图 5.12 中数据集摘要的一些关键点：
- en: Most metrics have nonzero values for nearly 100% of accounts except the unfriend_per_month
    metric, which shows values for only 25% of accounts.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 大多数指标在几乎所有账户中都有非零值，除了“每月取消好友”指标，它只显示 25% 的账户的值。
- en: Metrics event count means are usually in the hundreds, and the maximum event
    counts are in the thousands. The exceptions are unfriend and new friend, both
    of which are rarer.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指标事件计数通常在数百，最大事件计数在数千。例外的是“取消好友”和“新好友”，两者都较为罕见。
- en: Most metrics are skewed to varying degrees; events with higher counts have higher
    skews.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 大多数指标在程度上有偏斜；计数较高的事件有更高的偏斜。
- en: The statistics for the account_tenure metric show that all accounts have a measurement
    because the nonzero measurement (column 2) is 100%. The mean (average) is 61 days,
    and the skew of account tenure is 0.2, indicating that it is more or less evenly
    distributed around its mean.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 账户留存期的统计数据显示，所有账户都有一个测量值，因为非零测量值（第2列）为100%。平均值为61天，账户留存期的偏斜为0.2，表明它在其平均值周围分布得或多或少是均匀的。
- en: 'The table also shows statistics of churn in the dataset: 4.6% of the observations
    are churns.'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该表格还显示了数据集中的流失统计信息：4.6%的观测值是流失。
- en: Real churn case study data usually is similar in terms of the distribution and
    skew of metrics, but real company data typically has many more metrics, for which
    only a small fraction of accounts have nonzero values. (I deliberately put one
    in the simulation for you to learn from while still keeping the simulation parsimonious.)
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 真实的流失案例研究数据在指标的分布和偏斜方面通常相似，但真实公司的数据通常有更多的指标，其中只有一小部分账户具有非零值。（我故意在模拟中放入一个，以便你在保持模拟简洁的同时学习。）
- en: Table 5.1 Metric distribution summary statistics *(continued)*
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.1 指标分布汇总统计 *(续)*
- en: '| Summary statistic | Explanation |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| 汇总统计 | 说明 |'
- en: '| Percentage nonzero | The percentage of observations in the dataset in which
    the metric is not zero—an important check on how rare a behavior is. |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| 非零百分比 | 数据集中指标非零的观测值百分比——这是检查行为多么罕见的重要检查。|'
- en: '| Mean | The measure of a typical value for a metric (also known as average).
    It is calculated by summing the metric on all observations and dividing by the
    number of observations. |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| 平均值 | 指标典型值的度量（也称为平均值）。它是通过将所有观测值上的指标相加，然后除以观测值数量来计算的。|'
- en: '| Standard deviation | A measure of how varied the values of the metric are
    in the sense of whether all the values are relatively close to the typical value.
    A high standard deviation occurs when many values are far from a typical value.
    Sometimes, it is convenient to refer to a metric value by how many standard deviations
    the value is from the mean. If the mean is 20 and the standard deviation is 5,
    for example, a metric observation of 25 is said to be 1 standard deviation above
    the mean. In that case, 30 would be called 2 standard deviations above the mean,
    and so on. This terminology is useful because it conveys a sense of how a metric
    observation compares with typical values without requiring you to remember the
    typical value for every metric. |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| 标准差 | 一个度量指标值如何变化的量度，即所有值是否相对接近典型值。当许多值远离典型值时，会出现高标准差。有时，通过值与平均值的标准差来引用指标值是方便的。例如，如果平均值是20，标准差是5，那么一个指标观测值为25就被说成是高于平均值1个标准差。在这种情况下，30就被称为高于平均值2个标准差，依此类推。这种术语是有用的，因为它传达了指标观测值与典型值相比的感觉，而不需要你记住每个指标的典型值。|'
- en: '| Skew | A statistical measure of how symmetric or lopsided the distribution
    of the metric is. This kind of lopsidedness occurs in the cohort analyses earlier
    in this chapter. If the skew is zero, the low and high values are symmetrically
    distributed around the mean. If the skew is positive, there are more observations
    of the metric that are higher than the mean than observations that are smaller
    than the mean. If the skew is negative, the opposite is true: more observations
    are smaller than the mean than those that are greater than the mean. (You are
    not likely to see that result in typical behavioral metrics.) Generally, skews
    below 3 or 4 are not significant, but metrics with skews of 5 or greater are significantly
    skewed. |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| 偏斜 | 一个统计量度，用于衡量指标分布的对称性或倾斜程度。这种倾斜性在本章前面的群体分析中出现过。如果偏斜为零，则低值和高值对称地分布在平均值周围。如果偏斜为正，则高于平均值的指标观测值多于低于平均值的观测值。如果偏斜为负，则情况相反：低于平均值的观测值多于高于平均值的观测值。（在典型的行为指标中，你不太可能看到这种结果。）一般来说，偏斜低于3或4并不显著，但偏斜为5或更大的指标显著倾斜。|'
- en: '| Quantiles (1%, 5%, and so on) | Quantiles are the metric values required
    to find a fixed percent of the observations below that value. The 1% quantile,
    for example, is the metric value that 1% of observations have a value less than;
    the other 99% of observations have a value greater than the 1% quantile. The 5%
    quantile is the metric value that 5% of the observations are less than and 95%
    are greater than. This pattern continues for all the higher quantiles. Looking
    at the sequence of quantiles in the summary is a good way to get a sense of what
    percentage of customer values are in what range. If you see that the 25th percentile
    of logins is 20 and the 75th percentile of logins is 100, 50% of customers (75
    - 25 = 50) have between 20 and 100 logins. |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| 分位数（1%，5%，等等） | 分位数是找到低于该值的固定百分比的观测值所需的度量值。例如，1% 分位数是观测值中有1%的值小于该度量值的值；其他99%的观测值具有大于1%分位数的值。5%
    分位数是观测值中有5%小于该值，有95%大于该值的度量值。这种模式适用于所有更高的分位数。查看摘要中的分位数序列是了解客户值在什么范围内的百分比的好方法。如果你看到登录的25分位数是20，登录的75分位数是100，那么50%的客户（75
    - 25 = 50）的登录次数在20到100之间。|'
- en: '| Median (50% quantile) | Another measure of a typical value for a metric,
    like the mean. The median is the value that half of the observations are greater
    than and half are less than (same as the 50% quantile). The median is a better
    measure of the typical value of a metric than the mean when the data includes
    extreme outliers—when the metric has a high skew. Extreme outliers raise the mean
    but not the median, so the median always reflects a customer in the middle. |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| 中位数（50% 分位数） | 一个度量值的典型值的另一种度量，如平均值。中位数是观测值中一半大于一半小于的值（等同于50% 分位数）。当数据包含极端异常值时——当度量值有高偏斜时，中位数比平均值更能衡量度量的典型值。极端异常值会提高平均值但不会提高中位数，因此中位数总是反映中间的客户。|'
- en: '| Minimum and maximum | The lowest and highest values observed for any customer.
    |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| 最小值和最大值 | 观测到的任何客户的最低和最高值。|'
- en: Normal and fat-tailed distributions
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 正态和厚尾分布
- en: In the famous normal (bell curve) distribution, around two-thirds of all the
    values are within 1 standard deviation of the mean, and almost all the values
    are within 3 standard deviations of the mean. If the mean is 20, and the standard
    deviation is 5, 3 standard deviations means 3 *x* 5 = 15\. In that case, most
    of the observations have values between 5 and 35 (because 20 - 15 = 5, and 20
    + 15 = 35). For a normal distribution, it is extremely rare to have values that
    are 5 or more standard deviations from the mean.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在著名的正态（钟形曲线）分布中，大约三分之二的所有值都在平均值的一个标准差范围内，几乎所有值都在平均值的三个标准差范围内。如果平均值是20，标准差是5，那么三个标准差就是3
    * x * 5 = 15。在这种情况下，大多数观测值都在5到35之间（因为20 - 15 = 5，20 + 15 = 35）。对于正态分布，具有比平均值5个或更多标准差值的值极为罕见。
- en: But behavioral metrics typically have more outliers than a normal distribution,
    so those relationships probably won’t hold in your data. A distribution with more
    extreme outliers than the normal distribution is often called a fat-tailed distribution.
    The tails of the distribution are the extremes, and if the tails are fat, a lot
    of observations are extreme. For most of your own metrics, fewer than two-thirds
    of observations will be within 1 standard deviation of the mean, and more will
    be farther away; maybe a third of the observations will be within 1 standard deviation
    of the mean. Having behavioral metric values that are 5 to 10 standard deviations
    from the mean (or more) is common for most products.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 但行为度量通常比正态分布有更多的异常值，所以这些关系可能不会在你的数据中成立。比正态分布有更多极端异常值的分布通常被称为厚尾分布。分布的尾部是极端值，如果尾部很厚，那么就会有大量的极端观测值。对于你自己的大多数度量值，不到三分之二的观测值将位于平均值的一个标准差范围内，而更多的观测值将更远；可能只有三分之一的观测值将位于平均值的一个标准差范围内。对于大多数产品，行为度量值在平均值5到10个标准差（或更多）之外是很常见的。
- en: 5.2.2 Calculating dataset summary statistics in Python
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.2 在Python中计算数据集摘要统计量
- en: Taking a set of summary measurements on a dataset is a common task in data analysis,
    so Python’s Pandas module already provides a function to do it—`DataFrame .describe`.
    This function calculates a set of measurements for every column in the dataset.
    Recall that each column of the dataset contains the observation values for one
    metric. Calling the `describe` function produces a set of summary statistics for
    each metric.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据集上执行一系列摘要测量是数据分析中的常见任务，因此 Python 的 Pandas 模块已经提供了一个函数来完成这项任务——`DataFrame.describe`。此函数为数据集中的每一列计算一组测量值。回想一下，数据集的每一列都包含一个指标的观测值。调用
    `describe` 函数会产生每个指标的摘要统计量集合。
- en: 'Listing 5.2 shows a complete program that uses the Pandas function and adds
    a few fields to the summary, which I find useful for understanding customer behavior.
    The main steps in listing 5.2 are as follows:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.2 展示了一个完整的程序，它使用 Pandas 函数并添加了一些字段到摘要中，我认为这对于理解客户行为很有用。列表 5.2 中的主要步骤如下：
- en: Load the dataset into a Pandas `DataFrame`, given a path.
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在给定路径的情况下，将数据集加载到 Pandas `DataFrame` 中。
- en: Call the Pandas function `DataFrame.describe` to get a basic summary. The basic
    summary includes the mean, standard deviation, minimum and maximum, and 25th,
    50th, and 75th percentiles. The summary data is returned as another Pandas `DataFrame`.
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用 Pandas 函数 `DataFrame.describe` 以获取基本摘要。基本摘要包括平均值、标准差、最小值和最大值，以及第 25、50 和
    75 个百分位数。摘要数据作为另一个 Pandas `DataFrame` 返回。
- en: Calculate some additional statistics, and add them to the summary result. These
    additional statistics are
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算一些额外的统计量，并将它们添加到摘要结果中。这些额外的统计量包括
- en: The skew, calculated with the Pandas function `DataFrame.skew`
  id: totrans-206
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Pandas 函数 `DataFrame.skew` 计算偏度
- en: The 1st and 99th percentiles, calculated with the Pandas function `DataFrame.quantile`
  id: totrans-207
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Pandas 函数 `DataFrame.quantile` 计算第 1 和第 99 个百分位数
- en: 'The percentage of nonzero observations of each metric, which is calculated
    using a little trick: converting the column to a Boolean type and summing it gives
    the count of nonzero values; then dividing by the number of rows converts it to
    a percentage'
  id: totrans-208
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个指标的零观测值的百分比，这是通过一个小技巧计算的：将列转换为布尔类型并求和得到非零值的计数；然后除以行数将其转换为百分比
- en: The columns of the final results are reordered more logically.
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最终结果的列按更合理的顺序重新排序。
- en: The result is saved.
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结果被保存。
- en: Listing 5.2 will be used again later in this chapter, as some of these summary
    statistics are needed for further analysis of your dataset.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.2 将在本章的后面再次使用，因为这些摘要统计量对于进一步分析你的数据集是必需的。
- en: Listing 5.2 Statistics of a churn analysis dataset
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.2 展示了客户流失分析数据集的统计信息
- en: '[PRE2]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ① Checks the dataset path
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: ① 检查数据集路径
- en: ② Loads data into a Pandas DataFrame object and sets the index
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: ② 将数据加载到 Pandas DataFrame 对象中并设置索引
- en: ③ Converts the churn indicator to a float
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 将流失指标转换为浮点数
- en: ④ Provides a standard set of summary statistics
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 提供一组标准摘要统计量
- en: ⑤ The results are easier to read with the metrics in the rows.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 将指标放在行中，结果更容易阅读。
- en: ⑥ Measures the skew with a standard dataset function
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 使用标准数据集函数测量偏度
- en: ⑦ Uses the quantile function to measure the 1st percentile
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: ⑦ 使用分位数函数测量第 1 个百分位数
- en: ⑧ Uses the quantile function to measure the 99th percentile
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: ⑧ 使用分位数函数测量第 99 个百分位数
- en: ⑨ Calculates the fraction of values that are not equal to zero
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: ⑨ 计算非零值的比例
- en: ⑩ Reorders the columns
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ⑩ 重新排序列
- en: You should run listing 5.2 on the simulated dataset yourself. Assuming that
    you are using the Python wrapper program, change the parameters to
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该自己运行列表 5.2 上的模拟数据集。假设你正在使用 Python 包装程序，将参数更改为
- en: '[PRE3]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: A typical result of running listing 5.2 was presented in figure 5.12; your result
    may be somewhat different because the data is randomly simulated.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 运行列表 5.2 的典型结果如图 5.12 所示；你的结果可能有所不同，因为数据是随机模拟的。
- en: 5.2.3 Screening rare metrics
  id: totrans-227
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.3 筛选稀有指标
- en: After creating the dataset summary statistics, you should check what percentage
    of accounts have nonzero values on all of your metrics. At this point, you should
    have already picked longer observation windows for rare metrics, as described
    in chapter 3\. If you still have metrics in which only a small percentage of accounts
    has a nonzero value, then that’s probably the best you can do. If that’s the case,
    I recommend that you remove those metrics with fewer than around 5% nonzero values
    from your dataset and analysis. The precise cutoff depends on how many “good”
    metrics you have. If you have a lot of metrics in which most accounts have nonzero
    values, you should use a higher threshold—maybe 10%. On the other hand, if you
    have a lot of rare events and metrics with zero values, you may want to use a
    lower threshold for this kind of screening, such as 1%.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建数据集摘要统计信息后，你应该检查有多少账户在所有指标上都有非零值。在这个时候，你应该已经为描述在第3章中的罕见指标选择了更长的观察窗口。如果你仍然有一些指标，其中只有一小部分账户有非零值，那么这可能就是你能做到的最好了。如果是这样，我建议你从数据集和分析中删除那些少于大约5%非零值的指标。确切的截止点取决于你有多少“好的”指标。如果你有很多指标，其中大多数账户都有非零值，你应该使用更高的阈值——可能是10%。另一方面，如果你有很多罕见事件和零值的指标，你可能想为这种筛选使用较低的阈值，例如1%。
- en: 'You can make exceptions to this approach if you find that one of these rare
    metrics is strongly related to churn or if you know it is of particular interest
    to the business. The principle guiding this approach is parsimony: if a metric
    applies to only a small percentage of accounts, it is not likely to be useful,
    even if it has a strong relationship to churn and retention.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你发现这些罕见指标中的一个与流失有很强的相关性，或者你知道它对业务特别感兴趣，你可以对此方法做出例外。指导这一方法的原则是简约：如果一个指标只适用于一小部分账户，那么它可能不太有用，即使它与流失和保留有很强的关系。
- en: 5.2.4 Involving the business in data quality assurance
  id: totrans-230
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.4 将业务纳入数据质量保证
- en: A good time to involve the businesspeople in your organization in quality assurance
    is after you produce the dataset summary statistics. I recommend that you have
    one or more meetings with people who represent different parts of your business
    and review the summary statistics with them. You should do this before you show
    them the results of your cohort analyses. I taught you how to do the cohort analysis
    first so that you could do some real churn analysis before spending time on more
    data quality assurance, but you should do the quality assurance first and the
    churn analysis afterward.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成数据集摘要统计信息后，是让组织中的业务人员参与质量保证的好时机。我建议你与代表你业务不同部分的人进行一到多次会议，并与他们一起审查摘要统计信息。你应该在他们看到你的队列分析结果之前这样做。我首先教你如何进行队列分析，这样你就可以在花费时间进行更多数据质量保证之前做一些实际的流失分析，但你应该首先进行质量保证，然后进行流失分析。
- en: Such a review with the business stakeholders is a chance to confirm with people
    who should know it well that the data is of good quality. In particular, you want
    to ask the representatives of the business whether the distribution of metric
    values meets their expectations. Is the percentage of accounts with a metric lower
    than they expected or the maximum value higher than they expected? It is important
    to get this information before you share findings about churn with the business,
    because your findings may change if you have to make additional corrections or
    modifications in your dataset.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 与业务利益相关者的这种审查是一个机会，可以确认数据质量良好的人知道这一点。特别是，你想要询问业务代表，指标值的分布是否符合他们的预期。指标低于他们预期的账户百分比是否更高，或者最大值是否高于他们预期的？在将关于流失的发现与业务分享之前获取这些信息很重要，因为如果你的数据集需要额外的纠正或修改，你的发现可能会改变。
- en: WARNING Complete your quality assurance checks on the data, including review
    of the summary statistics with the business, before sharing cohort analysis results.
    You might lose credibility with the business if you share cohort analyses that
    you later need to retract due to data quality issues.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 警告：在分享队列分析结果之前，完成对数据的质量保证检查，包括与业务审查摘要统计信息。如果你分享的队列分析后来因数据质量问题需要撤回，你可能会失去业务的信任。
- en: 5.3 Scoring metrics
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 评分指标
- en: One problem we saw when we looked at the cohort analyses in section 5.1 was
    that for some of the metrics, most of the cohorts occupy only a small portion
    of the total range of the metric. In section 5.2, you learned that this type of
    distribution can be identified by looking at the skew statistic of the metrics
    as part of the dataset summary. In this section, you learn the technique of scoring
    metrics as a way to improve the interpretability of cohort analysis when your
    metric is highly skewed. In chapter 6, you learn that metric scores have other
    important uses, so this section is an introduction.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们查看5.1节中的队列分析时，我们发现一个问题，即对于某些指标，大多数队列仅占据指标总范围的很小一部分。在5.2节中，你了解到可以通过查看数据集摘要中的指标偏斜统计来识别这种类型的分布。在本节中，你将学习评分指标的技术，以便在您的指标高度偏斜时提高队列分析的可解释性。在第6章中，你将了解到指标分数还有其他重要的用途，因此本节是一个介绍。
- en: Scoring vs. normalizing the data
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 评分与数据归一化
- en: If you are trained in statistics or data science, you probably know the subject
    I’m calling scoring as the normalization or standardization of data. I have found
    that businesspeople find those terms intimidating and confusing. I have had better
    results referring to the whole process as scoring and the transformed data as
    scores rather than normalized data. Businesspeople seem to find these terms easier
    to relate to. For that reason, I describe the process in those terms rather than
    conventional statistical language.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你受过统计学或数据科学的训练，你可能知道我所说的评分就是数据的归一化或标准化。我发现商界人士觉得这些术语令人畏惧且令人困惑。我发现将整个过程称为评分，将转换后的数据称为分数而不是归一化数据，效果更好。商界人士似乎觉得这些术语更容易与之相关联。因此，我使用这些术语而不是传统的统计语言来描述这个过程。
- en: 5.3.1 The idea behind metric scores
  id: totrans-238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.1 指标分数背后的理念
- en: The idea behind metric scores is that it is a rescaled version of the metric
    you started with. In this context, rescaled means that the scores will be in a
    different range of numbers from the original metric.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 指标分数背后的理念是，它是你最初使用的指标的缩放版本。在这种情况下，缩放意味着分数将位于与原始指标不同的数字范围内。
- en: DEFINITION A metric score (or score, for short) is a rescaled version of a metric.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 指标分数（或简称分数）是指标的缩放版本。
- en: Rescaling also implies that a larger metric observation always converts to a
    larger score, and two customers with the same metric would end up with the same
    score. As a result, if the customers are ordered by metric value from greatest
    to least, and then the same customers are ordered by metric score, the order is
    exactly the same. The cohorts created from your metric will also be exactly the
    same as the cohorts based on the score. Figure 5.13 illustrates this process.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 重新缩放还意味着较大的指标观测值总是转换为较大的分数，并且具有相同指标的两位客户最终会得到相同的分数。因此，如果按指标值从大到小对客户进行排序，然后按指标分数对相同的客户进行排序，顺序将完全相同。从您的指标创建的队列也将与基于分数的队列完全相同。图5.13说明了这个过程。
- en: '![](../Images/5-13.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![图5.13](../Images/5-13.png)'
- en: Figure 5.13 Mapping metrics to a score
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.13 将指标映射到分数
- en: 'Scores have some characteristics that make them useful for further analysis
    of your metrics and churn. Here are a few of those characteristics:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 分数具有一些特性，使它们对进一步分析您的指标和流失率很有用。以下是一些这些特性的例子：
- en: Whereas metrics can take on any value, scores are always small numbers, positive
    and negative, but close to zero. Typical scores are -1, 0, or 1\. An extreme value
    for a score might be 3 or 5, so the typical range of a score is around -5 to 5,
    no matter what the original range of the metric was.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 而指标可以取任何值，但分数总是小数，可以是正数或负数，但接近于零。典型的分数是-1、0或1。一个分数的极端值可能是3或5，因此分数的典型范围大约在-5到5之间，无论原始指标的取值范围如何。
- en: If the metric is skewed, the score will not be as skewed. Equivalently, the
    metric can have many observations close to zero and a small number of much larger
    values, but the score values will be more evenly distributed across the entire
    range that the scores occupy (approximately -5 to 5).
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果指标是偏斜的，分数就不会那么偏斜。等价地，指标可以有许多接近零的观测值和少量很大的值，但分数值将在分数占据的整个范围内（大约-5到5）更加均匀地分布。
- en: The average score is always zero, no matter what the original average of the
    metric was. You can see at a glance whether a customer is average on the metric
    by looking at the score, even if you don’t know the average value of the metric.
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平均分数始终为零，无论原始指标的均值是多少。通过查看分数，你可以一眼看出客户在指标上的表现是否平均，即使你不知道指标的均值。
- en: The standard deviation of a metric score is always 1\. This property is useful
    because you also know how far from the average a given score is. A score of 1
    means the customer had an original metric that was 1 standard deviation above
    average, and a score of -1 means that the customer had an original metric that
    was 1 standard deviation below the average.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指标得分的标准差始终为1。这个特性很有用，因为你还可以知道给定得分与平均值的距离。得分为1表示客户的原始指标比平均值高一个标准差，得分为-1表示客户的原始指标比平均值低一个标准差。
- en: These properties make scores useful for looking at customer metrics and churn.
    You learn more useful properties of metric scores later in the book.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 这些特性使得得分对于查看客户指标和流失很有用。你将在本书的后面部分了解指标得分的更多有用特性。
- en: 5.3.2 The metric score algorithm
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.2 指标得分算法
- en: 'Now you’re going to look at the formula you use to calculate scores from metrics.
    You can use an algorithm to determine a score formula based on the data, not a
    single formula. Figure 5.14 illustrates this procedure and is summarized as follows:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你将查看用于从指标计算得分的公式。你可以使用算法根据数据确定一个得分公式，而不是一个单一的公式。图5.14说明了这个步骤，总结如下：
- en: Determine whether the metric is significantly skewed by checking the skew statistic
    (section 5.2). A typical threshold considers the skew to be significant when it
    is above 4, although you can adjust the threshold depending on your preference.
    Also, you must confirm that the minimum metric value (before any transformation)
    is zero. If the metric is not significantly skewed or has negative values, skip
    to step 4.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过检查偏斜统计量（第5.2节）来确定指标是否显著偏斜。一个典型的阈值认为当偏斜超过4时是显著的，尽管你可以根据你的偏好调整阈值。此外，你必须确认指标的最小值（在任何转换之前）为零。如果指标没有显著偏斜或具有负值，则跳到步骤4。
- en: Add 1 to the skewed customer metrics, so that a customer that has a zero event
    count now has 1, a customer with 1 now has 2, and so on.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将偏斜的客户指标加1，这样原来事件计数为零的客户现在有1，原来有1的客户现在有2，依此类推。
- en: Take the logarithm of all the skewed metrics. The natural logarithm (log base
    e) is normally used, but the base of the logarithm does not matter.
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对所有偏斜的指标取对数。通常使用自然对数（以e为底），但对数底数并不重要。
- en: Calculate the mean and the standard deviation of the metric values at this point
    in the process. If the metric was not skewed, these values are simply the original
    metrics. If the metric was skewed, use the logarithm of 1 plus the original customer
    metrics.
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算在此过程此点的指标值的平均值和标准差。如果指标没有偏斜，这些值就是原始指标。如果指标有偏斜，使用1加上原始客户指标的对数。
- en: Subtract the average from all values.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从所有值中减去平均值。
- en: Divide all the values by the standard deviation. The results are the scores.
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有值除以标准差。结果是得分。
- en: '![](../Images/5-14.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![图5.14](../Images/5-14.png)'
- en: Figure 5.14 Example scoring calculation
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.14 示例得分计算
- en: Taking the logarithm is a key step in making the data less skewed. A difference
    in order of magnitude between two numbers becomes a small difference in the resulting
    logarithms of those two numbers. But the logarithm can be taken only on positive
    numbers, which is why you check that the minimum is zero and then add 1\. (An
    approach for negative metrics is introduced in chapter 7.)
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 取对数是使数据不那么偏斜的关键步骤。两个数字之间的数量级差异在它们的结果对数中变成了小的差异。但只能对正数取对数，这就是为什么你需要检查最小值是否为零，然后加1。（关于负指标的解决方案在第7章中介绍。）
- en: 'Subtracting the average and dividing the metrics by the standard deviation
    makes the average of the final scores 0 and the standard deviation 1\. The derivation
    is covered in detail in textbooks on statistics, but you can understand it by
    noting the following:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 从平均值中减去并除以标准差可以使最终得分的平均值变为0，标准差变为1。这个推导在统计学教科书中有详细说明，但你可以通过注意以下内容来理解它：
- en: The average is calculated by summing all the metrics and dividing by the number
    of observations. If you subtract a specific number from every observation, the
    new average is reduced by the amount you subtracted. If you subtract the original
    average from every observation, the new average must be zero.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平均值是通过将所有指标相加然后除以观测数来计算的。如果你从每个观测值中减去一个特定的数，新的平均值将减少你减去的量。如果你从每个观测值中减去原始平均值，新的平均值必须是零。
- en: Suppose that the average is zero and the standard deviation is any number; then
    divide all the observations by the standard deviation. An observation that was
    originally equal to the standard deviation now has the value of 1 because it was
    the standard deviation; then it was divided by the same. In fact, after dividing
    by the original standard deviation, every observation is converted to a value
    that is the number of standard deviations the observation was from the average.
    This result is the same as the metric’s having a standard deviation of 1.
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设平均值为零，标准差为任何数；然后除以标准差。原本等于标准差的观测值现在值为 1，因为它就是标准差；然后它被除以相同的数。实际上，在除以原始标准差之后，每个观测值都被转换为一个值，这个值是观测值与平均值的距离的标准差数。这个结果与指标具有标准差为
    1 是相同的。
- en: 'Creating a score from an individual metric is the same as calculating the formula
    in equation 5.1:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 从单个指标创建分数与计算公式 5.1 中的公式相同：
- en: '![](../Images/5-14_E00.png)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/5-14_E00.png)'
- en: where
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: '| ![](../Images/5-14_E01.png) | Equation 5.1 |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| ![图片](../Images/5-14_E01.png) | 公式 5.1 |'
- en: In equation 5.1, *μm¢* indicates the mean of the distribution of *m ¢*, *σm¢*
    is the standard deviation of the distribution of *m ¢*, and *ln* is the natural
    logarithm function. If the metric is not skewed, use the original metric instead
    of *m ¢*.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在公式 5.1 中，*μm¢* 表示 *m ¢* 分布的均值，*σm¢* 是 *m ¢* 分布的标准差，*ln* 是自然对数函数。如果指标不是偏斜的，则使用原始指标代替
    *m ¢*。
- en: 5.3.3 Calculating metric scores in Python
  id: totrans-269
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.3 在 Python 中计算指标分数
- en: 'Listing 5.3 shows a Python function that implements the score calculation.
    Note that this function calculates the scores for all the metrics in a dataset,
    not just one. The function `metric_scores` in listing 5.3 has the following inputs:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.3 展示了一个实现分数计算的 Python 函数。请注意，此函数计算数据集中所有指标的分数，而不仅仅是单个指标。列表 5.3 中的 `metric_scores`
    函数有以下输入：
- en: '`data_set_path`—A path to a dataset saved in a file, given by a string variable'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_set_path`—一个字符串变量，指向保存文件中的数据集路径'
- en: '`skew_thresh`—The threshold for determining whether a metric should be considered
    to be skewed'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`skew_thresh`—确定一个指标是否应被视为偏斜的阈值'
- en: 'Given these inputs, the following are the main steps to take in calculating
    the scores:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 给定这些输入，计算分数的主要步骤如下：
- en: Load the dataset into a Pandas `DataFrame` object, set the `DataFrame` index,
    and make a copy. The scores are written to the copy.
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集加载到 Pandas `DataFrame` 对象中，设置 `DataFrame` 索引，并创建一个副本。分数将写入副本。
- en: Remove the churn indicator column because it will not be converted to a score;
    it will be reattached as is after the scores are calculated.
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除换行指示列，因为它不会被转换为分数；在分数计算后，它将按原样重新附加。
- en: Load the dataset stats file saved by listing 5.2.
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载由列表 5.2 保存的数据集统计文件。
- en: Using the summary stats, determine which columns are significantly skewed by
    comparing the skew statistics with the threshold.
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用汇总统计，通过比较偏斜统计量与阈值来确定哪些列显著偏斜。
- en: For each column that is significantly skewed, add 1, and take the logarithm.
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个显著偏斜的列，加 1，然后取对数。
- en: For all columns, subtract the averages, and divide by the standard deviation.
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于所有列，减去平均值，然后除以标准差。
- en: Reattach the churn indicator column. The resulting `DataFrame` will be saved.
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新附加换行指示列。生成的 `DataFrame` 将被保存。
- en: One thing to note about listing 5.3 is that it does not follow my advice from
    section 5.1 about using standard Python functions. This listing does not use a
    standard Python Pandas function to calculate scores; there is one, but listing
    5.3 doesn’t use it because the standard Pandas function does not include the option
    to take the logarithm for skewed variables.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 关于列表 5.3 需要注意的一点是，它没有遵循第 5.1 节中关于使用标准 Python 函数的建议。此列表没有使用标准的 Python Pandas
    函数来计算分数；虽然有一个，但列表 5.3 没有使用它，因为标准的 Pandas 函数不包括对偏斜变量取对数的选项。
- en: Listing 5.3 Calculating metric scores in Python
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.3 计算指标分数的 Python
- en: '[PRE4]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ① Checks the dataset path
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: ① 检查数据集路径
- en: ② Loads the dataset into a Pandas DataFrame object
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: ② 将数据集加载到 Pandas DataFrame 对象中
- en: ③ Works on a copy of the data to calculate the scores
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 在数据的副本上工作以计算分数
- en: ④ The churn column should not be converted to a score.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 换行列不应转换为分数。
- en: ⑤ Checks the summary statistics file
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 检查汇总统计文件
- en: ⑥ Loads the summary statistics
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 加载汇总统计
- en: ⑦ Drops the churn row from the summary statistics
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 从汇总统计中删除掉换行行
- en: ⑧ Makes a Boolean series for which columns are skewed
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: ⑧ 为偏斜的列创建一个布尔序列
- en: ⑨ Removes the entries for columns that were below the threshold
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: ⑨ 移除低于阈值的列的条目
- en: ⑩ Iterates over the skewed columns
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: ⑩ 遍历偏斜的列
- en: ⑪ Converts the skewed columns to the log of 1 plus the original
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: ⑪ 将偏斜的列转换为原始值的对数
- en: ⑫ Records the new mean and standard deviation
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: ⑫ 记录新的均值和标准差
- en: ⑬ Subtracts the mean and divides by the standard deviation
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: ⑬ 减去均值并除以标准差
- en: ⑭ Adds back the is_churn column from the original data
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: ⑭ 将原始数据集中的is_churn列添加回来
- en: ⑮ Saves the score version of the metrics
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: ⑮ 保存指标的分数版本
- en: If you are following the examples in the chapter, you should run listing 5.3
    on the simulated dataset yourself. Assuming that you are using the Python wrapper
    program, set the parameters to `—chapter` `5` `—listing` `3`. That action creates
    the file socialnet_ dataset_scores.csv in the output directory. The wrapper program
    that runs the listings prints the output directory.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在遵循本章中的示例，你应该自己运行列表5.3在模拟数据集上。假设你正在使用Python包装程序，将参数设置为`—chapter` `5` `—listing`
    `3`。这个操作将在输出目录中创建文件socialnet_dataset_scores.csv。运行列表的包装程序会打印输出目录。
- en: 'If you want to check how the scores dataset differs from the original, one
    option is to open it in a text editor or spreadsheet. You should be able to see
    that all the metrics are small numbers (close to zero) and both positive and negative.
    A better option is to rerun the dataset summary program (listing 5.2) on the new
    dataset. You can run a second version of the dataset summary listing by adding
    the argument `—version` `2` to the Python wrapper program, so run the wrapper
    program with these arguments:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要检查分数数据集与原始数据集的不同之处，一个选项是将其在文本编辑器或电子表格中打开。你应该能够看到所有指标都是小数（接近零），并且既有正数也有负数。更好的选项是重新运行数据集摘要程序（列表5.2）在新数据集上。你可以通过在Python包装程序中添加参数`—version`
    `2`来运行数据集摘要列表的第二版，因此使用以下参数运行包装程序：
- en: '[PRE5]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The wrapper program saves the result in a file called socialnet_dataset_scores_summary
    .csv. If you check the result file, all the metrics should be like the one shown
    in figure 5.15:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 包装程序将结果保存到名为socialnet_dataset_scores_summary.csv的文件中。如果你检查结果文件，所有指标都应该像图5.15中显示的那样：
- en: The mean is a small rounding error close to zero. In figure 5.15, the mean is
    -2.65E-16, which means 10 to the minus 16th power (an extremely small number).
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 均值是一个接近零的小舍入误差。在图5.15中，均值为-2.65E-16，这意味着10的负16次方（一个非常小的数）。
- en: The standard deviation is 1.
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准差为1。
- en: The minimum and maximum value are around -4 and 4, respectively.
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最小值和最大值分别约为-4和4。
- en: Although the original metric was heavily skewed (15.5 in figure 5.12), the score
    has practically no skew.
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管原始指标严重偏斜（图5.12中的15.5），但评分实际上没有偏斜。
- en: '![](../Images/5-15.png)'
  id: totrans-307
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/5-15.png)'
- en: Figure 5.15 Example of summary statistics of a metric in the dataset of scores
    for the simulated dataset
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.15 模拟数据集分数数据集中一个指标的摘要统计示例
- en: 5.3.4 Cohort analysis with scored metrics
  id: totrans-309
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.4 使用评分指标进行队列分析
- en: 'When you have created the dataset of scores from your original dataset, you
    do cohort analysis exactly the way that you learned in section 5.1, using the
    same code. If you look back to listing 5.1 (section 5.1.2), you will find that
    nowhere in the cohort analysis function does it matter whether the data is original
    metrics (on their natural scale) or the scored metrics on the transformed scale.
    Also remember that because converting metrics to scores preserves the order of
    customers by the metric, the cohorts you find with scores are the same: using
    scores for the cohort analysis changes only how the data is distributed on the
    horizontal axis of the cohort plot.'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 当你从原始数据集中创建了分数数据集后，你可以按照5.1节中学到的方法进行队列分析，使用相同的代码。如果你回顾一下5.1.2节中的列表5.1，你会发现队列分析函数中根本不在乎数据是原始指标（在其自然尺度上）还是转换尺度上的评分指标。还要记住，由于将指标转换为分数保留了按指标排序的客户顺序，因此使用分数进行队列分析只会改变数据在队列图水平轴上的分布方式。
- en: 'You should run your own cohort analysis on the score metrics from the social
    network simulation with the Python wrapper program. You can run a second version
    of the cohort plot (listing 5.1) with these arguments:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该使用Python包装程序对社交网络模拟的评分指标运行自己的队列分析。你可以使用以下参数运行队列图列表的第二版（列表5.1）：
- en: '[PRE6]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The result looks like figure 5.16, in which the horizontal axis is relabeled
    as a score ranging from -1.5 to 1.5 (cohort averages). The churn rate in each
    cohort is the same as shown in figure 5.4\. But after converting to scores, the
    cohort positions are more evenly spread across the figure. At the same time, the
    churn rate of every point in the scored metric cohort matches the churn rate from
    one of the original cohorts.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 结果看起来像图5.16，其中水平轴被重新标记为从-1.5到1.5（群组平均值）的分数。每个群组的流失率与图5.4中显示的相同。但是，在转换为分数后，群组的定位在图中分布得更均匀。同时，分数指标群组中每个点的流失率与原始群组中的一个的流失率相匹配。
- en: '![](../Images/5-16.png)'
  id: totrans-314
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5-16.png)'
- en: Figure 5.16 Cohort analysis on scored metric from a simulation
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.16从模拟中得到的分数指标群组分析
- en: Figure 5.17 shows an example comparing the cohort churn plot for one metric
    on both its natural scale and as a score for Broadly, a service that helps businesses
    manage their online presence. An important event for Broadly’s customers is adding
    new transactions, and a metric was calculated for the number of transactions added
    per month. The metric transactions added per month are highly skewed, having a
    statistic of 23\. As a result, when the cohort plot is made using the metric on
    its natural scale, all the cohorts except one lie in a horizontal range that is
    around one-eighth of the entire plot. The cohort average values lie between 0
    and 250, and the top cohort averages 2,300\. By contrast, the cohorts based on
    the metric scores are distributed more or less evenly between scores of -1.5 and
    2.0\. Also, it is clear now how the cohorts compare with the average, which is
    0\. The first three cohorts are below average, and most of the reduction in churn
    rates goes from the lowest cohort to cohorts near the average.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.17展示了比较Broadly（一个帮助企业管理其在线存在的服务）一个指标在其自然尺度上及其作为分数的群组流失率图的示例。对于Broadly的客户来说，一个重要的事件是添加新的交易，并计算了每月新增交易量的指标。每月新增交易量的指标高度倾斜，统计值为23。因此，当使用该指标的自然尺度制作群组图时，除了一个群组外，所有群组都位于整个图大约八分之一宽的水平范围内。群组平均值介于0到250之间，最高群组的平均值是2,300。相比之下，基于指标分数的群组在大约-1.5到2.0的分数之间分布得更加均匀。此外，现在很清楚群组与平均值的比较，这个平均值是0。前三组低于平均值，大部分的流失率降低都是从最低群组到接近平均值的群组。
- en: '![](../Images/5-17.png)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5-17.png)'
- en: Figure 5.17 Scored metric and churn example for Broadly's transactions added
    per month
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.17 Broadly每月新增交易量分数指标和流失率示例
- en: TAKEAWAY Cohort analysis with scored metric cohorts makes it easy to see how
    the cohorts relate to the average metric value, which is always the score equal
    to zero.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '**要点**：使用分数指标群组的群组分析使得很容易看到群组与平均指标值的关系，这个值总是等于零的分数。'
- en: 5.3.5 Cohort analysis of monthly recurring revenue
  id: totrans-320
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.5 每月经常性收入（MRR）的群组分析
- en: 'In chapter 3, you learned that monthly recurring revenue (MRR) should be calculated
    as a metric, but so far, we have not looked at any cohort analysis results for
    it. Now I will demonstrate a typical result for MRR cohort analysis, using the
    metric scores technique introduced in section 5.3.4\. I demonstrate a cohort analysis
    of MRR and churn that uses scores for two reasons:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在第三章中，你学习了每月经常性收入（MRR）应该作为一个指标来计算，但到目前为止，我们还没有查看过任何关于它的群组分析结果。现在我将演示MRR群组分析的典型结果，使用的是在第5.3.4节中介绍的指标分数技术。我演示MRR和流失率的群组分析使用分数有两个原因：
- en: MRR is typically highly skewed for business to business (B2B) products because
    the largest customers, which can be large corporations, typically pay prices many
    times higher than those paid by the smallest customers, which can be sole proprietorships.
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MRR对于企业对企业（B2B）产品通常高度倾斜，因为最大的客户，可能是大型企业，通常支付的价格比最小的客户，可能是单一业主企业，高出许多倍。
- en: Presenting this cohort analysis with scores maintains the confidentiality of
    the pricing information from the case study.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以分数形式呈现这一群组分析，可以保持案例研究中定价信息的保密性。
- en: Figure 5.18 shows the results of the scored MRR churn analysis. But before you
    look at the results, stop to think about what you expect the result to be. (Okay,
    some of you may remember the answer from chapter 1.) Will cohorts of higher-paying
    customers have churn rates that are
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.18显示了分数MRR流失率分析的结果。但在你查看结果之前，停下来思考一下你期望的结果是什么。（好吧，你们中的一些人可能还记得第一章中的答案。）支付更多费用的客户群组的流失率会是
- en: Higher than the churn rates of customers who pay less?
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高于支付较少的客户流失率吗？
- en: Lower than the churn rates of customers who pay less?
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低于支付较少的客户流失率吗？
- en: About the same as the churn rate of customers who pay less?
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大约与支付较少的客户的流失率相同吗？
- en: 'Figure 5.18 shows that the answer is B: cohorts of customers that pay more
    on average churn at a lower rate, although the trend is a little bit noisy. The
    higher-paying customers churn at a rate around one-third to one-half less than
    that of the lowest-paying cohorts.'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.18显示答案是B：平均支付更多的客户群体流失率较低，尽管趋势有点嘈杂。高支付客户群体的流失率大约比最低支付群体低三分之一到一半。
- en: '![](../Images/5-18.png)'
  id: totrans-329
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/5-18.png)'
- en: Figure 5.18 Scored MRR and churn example for Versature's MRR scores
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.18 Versature的MRR得分和客户流失率示例
- en: This result may surprise you. The usual thinking is that high prices make customers
    less satisfied, and as a result, they churn at a higher rate. The opposite is
    usually true, however. On average, customers who pay more usually churn at a lower
    rate, for multiple reasons. The first reason for lower churn among customers who
    pay more has to do with passive churn. Passive churn (also known as involuntary
    churn) occurs due to a failed payment when the customer has not indicated a choice
    to churn (hence the term passive). The most common scenario for passive churn
    is an expired payment card or insufficient available balance. Because customers
    who are paying more sign up at a higher plan level, they generally have more money
    and, thus, are less likely to have those kinds of problems. (To reduce passive
    churn, most companies retry credit cards multiple times until a transaction goes
    through, but this method of reducing churn is beyond the scope of this book.)
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果可能会让你感到惊讶。通常的想法是高价格会让客户不太满意，因此他们流失率更高。然而，情况通常相反。平均而言，支付更多的客户通常流失率较低，原因有很多。支付更多客户流失率较低的第一个原因是被动流失。被动流失（也称为非自愿流失）发生在客户没有表明流失意愿的情况下（因此得名被动）。被动流失最常见的情况是支付卡过期或可用余额不足。因为支付更多的客户通常在更高的计划级别注册，他们通常有更多的钱，因此不太可能遇到这些问题。（为了减少被动流失，大多数公司会多次尝试信用卡直到交易成功，但这种减少流失的方法超出了本书的范围。）
- en: 'There is a second and usually more important reason customers with higher MRR
    churn at a lower rate, especially for business products: business products are
    sold at higher prices to bigger customers, and bigger customers churn less for
    multiple reasons related to their size. Bigger companies have more employees,
    so when it comes to product use such as making calls or using software, bigger
    customers usually use more of the available services. Also, a big business customer
    invests more to set up a system, so it is less likely to walk away from the investment.
    You may be surprised to learn that the same pattern often holds for consumer products.
    Customers who sign up for more expensive plans tend to be more invested and use
    the product more, and as a result, they churn at a lower rate than customers who
    signed up for lower-cost plans.'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个通常更重要的原因是，MRR较高的客户流失率较低，尤其是在商业产品方面：商业产品以更高的价格卖给大客户，而大客户由于与规模相关的多个原因流失较少。大公司有更多的员工，所以在产品使用方面，如打电话或使用软件，大客户通常使用更多的可用服务。此外，大企业客户在建立系统时投入更多，因此不太可能放弃投资。你可能惊讶地发现，同样的模式通常也适用于消费产品。注册更昂贵计划的客户往往投入更多并更频繁地使用产品，因此他们的流失率比注册低成本计划的客户低。
- en: MRR is associated with lower churn, but it’s not the cause. If you see a relationship
    like this one, do not try to raise MRR to reduce churn. This understanding is
    intuitively unsatisfying, because paying too much for something ought to be a
    cause for churn, and getting a good deal ought to be a cause for retention. A
    better way to understand the relationship between what customers pay and churn
    is to use a different metric—one that reflects the value that customers receive
    rather than what they pay. These topics are among the main subjects of chapters
    6 and 7.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: MRR与较低的客户流失率相关，但并非原因。如果你看到这种关系，不要试图提高MRR来降低客户流失率。这种理解在直觉上是不令人满意的，因为为某物支付过多应该是导致客户流失的原因，而得到一个好的交易应该是导致客户保留的原因。更好地理解客户支付与客户流失之间关系的方法是使用不同的指标——该指标反映客户获得的价值而不是他们支付的价值。这些主题是第6章和第7章的主要主题之一。
- en: 5.4 Removing unwanted or invalid observations
  id: totrans-334
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4 移除不需要或不正确的观察值
- en: Another useful technique that should be part of your toolkit for cohort analyses
    is removing unwanted observations from a cohort analysis. Despite your best efforts
    to do quality assurance and clean your data, some observations may be invalid
    (bad data), or they may not be invalid but you don’t want them because they make
    your cohort analysis harder to understand. I’m going to show you two motivating
    case studies in which some observations are removed from a cohort analysis and
    a Python function that performs the removal.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种应该成为您群体分析工具包中的有用技术是从群体分析中移除不想要的观察结果。尽管您已经尽力进行质量保证和清理数据，但某些观察结果可能无效（坏数据），或者它们可能不是无效的，但您不希望它们存在，因为它们会使您的群体分析更难理解。我将向您展示两个激励性的案例研究，其中一些观察结果被从群体分析中移除，以及一个执行移除操作的
    Python 函数。
- en: 5.4.1 Removing nonpaying customers from churn analysis
  id: totrans-336
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.1 从流失分析中移除非付费客户
- en: One common scenario in which you may need to remove some observations from your
    analysis is when you have both paying and nonpaying customers. Customers who don’t
    have to pay may be on temporary free trials, or they may be in some special category
    of customers, like partners who have permanent free use of the product. You might
    have a similar situation when some customers pay a nominal amount that is much
    less than what usual customers pay. The problem with nonpaying (or low-paying)
    customers is that they tend not to churn because the product doesn’t cost them
    anything, but they don’t necessarily use the product much. So nonpaying customers
    don’t have the normal relationship between behavior and churn, and if you have
    more than a small number of nonpaying customers, they can ruin the results of
    your analysis.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能需要从分析中移除一些观察结果的一个常见场景是，您既有付费客户又有非付费客户。不需要付费的客户可能处于临时免费试用阶段，或者他们可能属于某些特殊客户类别，例如永久免费使用产品的合作伙伴。您可能也有类似的情况，即一些客户支付的费用远低于普通客户支付的费用。非付费（或低付费）客户的问题在于，由于产品对他们来说不花钱，他们往往不会流失，但他们不一定大量使用产品。因此，非付费客户与行为和流失之间的正常关系不存在，如果您有超过少量非付费客户，他们可能会破坏您分析的结果。
- en: Figure 5.19 demonstrates the impact of free customers by adding simulated nonpaying
    customers to Versature’s MRR and local-call observations, which are analyzed in
    section 5.3.5\. These nonpaying customers are not real; they are randomly generated
    observations with $0 MRR. The simulated nonpaying customers were assigned a local-call
    metric that was also randomly generated to be within the bottom two deciles of
    the real customers. Enough simulated nonpaying customers were added to make up
    15% of the total data. When the cohort plots are regenerated, as shown in figure
    5.19, they are significantly distorted by the presence of the nonpaying customers,
    and the relationships between the metrics and churn appear to be much less significant.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.19 通过向 Versature 的 MRR 和本地通话观察结果中添加模拟的非付费客户来展示免费客户的影响，这些观察结果在 5.3.5 节中进行分析。这些非付费客户不是真实的；它们是随机生成的观察结果，具有
    $0 MRR。模拟的非付费客户被分配了一个本地通话指标，这个指标也是随机生成的，位于真实客户的底部两个十分位。添加了足够的模拟非付费客户，以占总数据的 15%。当群体图重新生成时，如图
    5.19 所示，它们由于非付费客户的存在而严重扭曲，指标与流失之间的关系似乎不太显著。
- en: '![](../Images/5-19.png)'
  id: totrans-339
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.19](../Images/5-19.png)'
- en: Figure 5.19 Impact of $0 MRR (free) trials added to Versature subscription data
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.19 添加到 Versature 订阅数据中的 $0 MRR (免费) 测试的影响
- en: If you have customers who pay and some who do not, you should remove the nonpaying
    customers before trying to do cohort analysis or the other analyses described
    in later chapters. Ideally, you might be able to remove such customers when generating
    your observations (as described in chapter 4) by using some kind of SQL logic
    based on the plans the customers use. But that approach may be complicated by
    the presence of multiple subscriptions. A customer might have some $0 MRR subscriptions
    and others that have a cost attached, so to be sure a customer pays nothing, you
    must use the MRR metric calculated in chapter 3\. This example illustrates why
    it may be necessary to remove such customers after the dataset has been generated.
    The Python program in section 5.4.2 shows you how.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一些客户付款，而有些客户不付款，在尝试进行群体分析或后续章节中描述的其他分析之前，你应该移除不付款的客户。理想情况下，你可能在生成观测值时（如第4章所述）通过使用基于客户使用的计划的某种SQL逻辑来移除此类客户。但是，多个订阅的存在可能会使这种方法变得复杂。一个客户可能有某些$0
    MRR订阅，而其他订阅则附加了费用，因此为了确保客户没有支付任何费用，你必须使用第3章中计算的MRR指标。这个例子说明了为什么在生成数据集之后可能需要移除此类客户。5.4.2节中的Python程序展示了如何做到这一点。
- en: 5.4.2 Removing observations based on metric thresholds in Python
  id: totrans-342
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.2 基于Python中的指标阈值移除观测值
- en: One way to remove observations from a churn analysis is to define a minimum
    value for a metric, a maximum value for a metric, or both. Any observations in
    which the metric is below the minimum or above the maximum can be removed, and
    a new dataset that is a subset of the original is produced.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 从客户流失分析中移除观测值的一种方法是为一个指标定义一个最小值，为一个指标定义一个最大值，或者两者都定义。任何指标值低于最小值或高于最大值的观测值都可以被移除，从而生成一个新的数据集，它是原始数据集的子集。
- en: 'Listing 5.4 shows a Python function that performs these operations. The function
    `remove_invalid` has the following inputs:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.4展示了执行这些操作的Python函数。函数`remove_invalid`具有以下输入：
- en: '`data_set_path`—A path to a dataset saved in a file, given by a string variable.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_set_path`—一个字符串变量，指定保存数据集的文件路径。'
- en: '`min_valid`—A dictionary containing the minimum valid values of any metric
    to be screened. Entries are assumed to be key-value pairs, in which the key is
    the name of a metric (a string), and the value is the minimum to be applied for
    screening that metric. Any number of criteria can be specified in this way.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`min_valid`—一个包含任何要筛选的指标的最低有效值的字典。条目假定是键值对，其中键是指标的名称（一个字符串），值是应用于筛选该指标的最低值。可以通过这种方式指定任意数量的标准。'
- en: '`max_valid`—A dictionary containing the maximum valid values of any metric
    to be screened. Entries are assumed to be key-value pairs, in which the key is
    the name of a metric (a string), and the value is the maximum to be applied for
    screening that metric. Any number of criteria can be specified in this way.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_valid`—一个包含任何要筛选的指标的最高有效值的字典。条目假定是键值对，其中键是指标的名称（一个字符串），值是应用于筛选该指标的最高值。可以通过这种方式指定任意数量的标准。'
- en: '`save_path`—A path to a file in which the scores will be saved.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_path`—一个文件路径，用于保存分数。'
- en: 'Given these inputs, following are the main steps to take to create a new dataset
    with invalid observations removed:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 给定这些输入，以下是要创建一个新数据集的主要步骤，其中无效观测值已被移除：
- en: Load the dataset into a Pandas `DataFrame` object, set the `DataFrame` index,
    and make a copy. The cleaned data is written to a copy of the `DataFrame`.
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集加载到Pandas `DataFrame`对象中，设置`DataFrame`索引，并创建一个副本。清洗后的数据被写入`DataFrame`的副本中。
- en: For each metric specified in the `min_valid` dictionary parameter, remove those
    observations from the `DataFrame` where the value is below the minimum.
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于在`min_valid`字典参数中指定的每个指标，从`DataFrame`中移除那些值低于最小值的观测值。
- en: For each metric specified in the `max_valid` dictionary parameter, remove those
    observations from the `DataFrame` where the value is above the maximum.
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于在`max_valid`字典参数中指定的每个指标，从`DataFrame`中移除那些值高于最大值的观测值。
- en: Save the resulting `DataFrame` to a file.
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将结果`DataFrame`保存到文件中。
- en: An example of using this algorithm is presented in figure 5.19 earlier in this
    chapter. The left side of the figure was produced from a dataset cleaned by listing
    5.4; the right side of figure 5.19 was made from the original, unclean data.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章前面提到的图5.19中，展示了使用此算法的一个示例。图的左侧是由列表5.4清洗的数据集生成的；图5.19的右侧是由原始未清洗数据生成的。
- en: Listing 5.4 Removing invalid observations
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.4 移除无效观测值
- en: '[PRE7]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ① Checks the dataset path
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: ① 检查数据集路径
- en: ② Loads data into a Pandas DataFrame, setting the index
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: ② 将数据加载到 Pandas DataFrame 中，设置索引
- en: ③ Makes a copy of the original DataFrame
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 创建原始 DataFrame 的副本
- en: ④ Iterates over variables specified for cleaning with a minimum
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 对用于清理的变量进行迭代，以最小值结束
- en: ⑤ Confirms that this metric is in the DataFrame
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 确认该指标是否在 DataFrame 中
- en: ⑥ Removes rows in which the metric is less than the minimum
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 移除指标小于最小值的行
- en: ⑦ Iterates over variables specified for cleaning with a maximum
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: ⑦ 对用于清理的变量进行迭代，以最大值结束
- en: ⑧ Removes rows in which the metric is greater than the maximum
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: ⑧ 移除指标大于最大值的行
- en: ⑨ Saves the resulting DataFrame to a file
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: ⑨ 将生成的 DataFrame 保存到文件中
- en: The simulated dataset for this book doesn’t contain any free-trial users or
    other reasons to remove unwanted data, so there is no example on which to run
    listing 5.4.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 本书所用的模拟数据集不包含任何免费试用用户或其他需要移除的不必要数据，因此没有可以运行列表 5.4 的示例。
- en: 5.4.3 Removing zero measurements from rare metric analyses
  id: totrans-367
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.3 从罕见指标分析中移除零测量值
- en: Another situation in which you might want to remove observations from a cohort
    analysis occurs when a metric measures a rare event and, as a result, most customers
    have zeros on the metric. This situation is illustrated in section 5.1.7\. The
    function in listing 5.4 provides an easy way to see what the cohorts look like
    when you consider only those customers who have the event (and a nonzero value
    on the metric).
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一种情况下，你可能想要从群体分析中移除观测值，当指标衡量的是一个罕见事件时，结果大多数客户在该指标上为零。这种情况在第 5.1.7 节中有所说明。列表
    5.4 中的函数提供了一个简单的方法来查看当你只考虑有该事件（以及在指标上有非零值）的客户时，群体看起来像什么。
- en: Figure 5.20 shows the analysis of Klipfolio’s orientation switch event, both
    with and without customers with zero metric counts.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.20 显示了 Klipfolio 的方向切换事件的分析，包括有和没有零指标计数客户的情况。
- en: '![](../Images/5-20.png)'
  id: totrans-370
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5-20.png)'
- en: Figure 5.20 Cohorts of rare behaviors for Klipfolio
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.20 Klipfolio 稀有行为的群体
- en: The version without zero metric customers was created by running listing 5.4
    on the dataset to remove customers with zero on the metric and then saving it.
    Afterward, the cohort analysis was run using five bins because only around 25%
    of the observations remained.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 没有零指标客户的版本是通过在数据集上运行列表 5.4 来创建的，以移除在指标上为零的客户，然后保存。之后，由于只有大约 25% 的观测值剩余，因此使用了五个区间进行群体分析。
- en: '5.4.4 Disengaging behaviors: Metrics associated with increasing churn'
  id: totrans-373
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.4 解离行为：与增加流失率相关的指标
- en: So far, I have showed you cohort analyses of behaviors associated with reduced
    churn. You may wonder about behaviors associated with increased churn. I call
    these behaviors disengaging behaviors.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我已经向你展示了与减少流失率相关的行为的群体分析。你可能想知道与增加流失率相关的行为。我把这些行为称为解离行为。
- en: DEFINITION A disengaging behavior is a customer behavior that leads to an increased
    risk of churn the more often it is performed.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 定义：解离行为是一种客户行为，这种行为越频繁地发生，导致客户流失的风险就越高。
- en: I have not avoided disengaging behaviors to put a positive spin on the case
    studies. The fact is that disengaging behaviors are rare in churn case studies
    and often cannot be detected with simple count and average metrics like the ones
    you have learned so far. For one thing, it is the product creators’ jobs to make
    features that are engaging, so if the creators are doing their jobs, disengaging
    behaviors should be rare. Normally, customers who don’t even use the product have
    an even higher churn rate than the customers who perform the disengaging behavior.
    As a result, if disengaging behaviors exist, their relationship to churn is likely
    to be weak and can easily be missed.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 我没有避免解离行为来对案例研究进行积极解读。事实是，在流失案例研究中，解离行为很少见，并且通常无法用你迄今为止学到的简单计数和平均指标来检测。一方面，产品创造者的工作是创建吸引人的功能，因此如果创造者正在做他们的工作，解离行为应该是罕见的。通常，甚至没有使用产品的客户比执行解离行为的客户有更高的流失率。因此，如果存在解离行为，它们与流失率的关系可能很弱，并且很容易被忽视。
- en: TAKEAWAY Disengaging behaviors usually show a weak relationship with increasing
    churn—typically less than the reduction in churn that comes from using the product
    even a small amount.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 吸收：解离行为通常与增加的流失率显示出较弱的关系——通常小于使用产品即使是一小部分所带来的流失率减少。
- en: An example of a disengaging feature from Klipfolio, an SaaS product for business
    dashboards, is shown in figure 5.21\. The case study shows two versions of the
    cohort analysis. One version uses all customers, including those who don’t use
    the product or feature, and the other includes only customers who use the feature.
    If you include all customers, you might miss that the feature is disengaging.
    The most notable feature of the cohort analysis is that customers who don’t use
    the feature have the highest churn rate. It’s easy to miss the fact that customers
    who use the feature churn at a slightly higher rate the more often they use it.
    When customers who don’t use the feature are removed from the analysis, the increasing
    churn rate among users of the feature is clearer.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.21展示了Klipfolio（一个用于商业仪表板的SaaS产品）的一个不活跃功能的例子。案例研究显示了两种版本的群体分析。一种版本包括所有客户，包括那些不使用产品或功能的人，另一种版本只包括使用该功能的客户。如果你包括所有客户，你可能会错过该功能是不活跃的。群体分析最显著的特点是，不使用该功能的客户具有最高的流失率。很容易忽略使用该功能的客户流失率会随着使用频率的增加而略有上升。当不使用该功能的客户从分析中去除后，使用该功能的用户中流失率的上升变得更加明显。
- en: '![](../Images/5-21.png)'
  id: totrans-379
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/5-21.png)'
- en: Figure 5.21 Cohorts of a disengaging behavior for Klipfolio
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.21 Klipfolio不活跃行为的群体
- en: All things considered, the increasing churn among the disengaging feature users
    shown in figure 5.21 is small compared with the reduced churn associated with
    using the main product features shown in section 5.1\. This result is typical
    for disengaging behaviors measured with simple metrics. In chapter 7, you learn
    advanced techniques to create metrics that detect more significant disengaging
    behaviors.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到所有因素，图5.21中显示的不活跃功能用户的流失增加与第5.1节中展示的使用主要产品功能相关的流失减少相比是微不足道的。这种结果对于用简单指标测量的不活跃行为来说是典型的。在第7章中，你将学习创建检测更显著不活跃行为的先进技术。
- en: Your instinct probably is to think that disengaging behaviors must be bad, in
    the sense of experiences that customers do not like. But I have seen cases in
    which disengaging behaviors are good, such as when the behavior serves to complete
    the purpose of a product that gave the users exactly what they wanted. Disengaging
    behavior can also occur when the product has only one purpose for some users and
    that purpose can be completed. A common example is watching a popular video series.
    If there is only one popular series, people may churn when they have watched every
    episode. In that case, watching the best content leads to churn. Creators must
    make more equally desirable content to change this pattern. To reach that kind
    of conclusion, you need to use your business knowledge. Usually, people know when
    a feature or content is good without the churn analysis (but survey users if you’re
    not sure).
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 你的直觉可能认为不活跃行为一定是坏事，即客户不喜欢的那种体验。但我见过一些情况，其中不活跃行为是好的，例如当这种行为有助于完成产品目的，而用户正好得到了他们想要的东西时。当产品对某些用户只有一个目的并且该目的可以完成时，也可能发生不活跃行为。一个常见的例子是观看热门视频系列。如果只有一个热门系列，人们在看完了每一集后可能会流失。在这种情况下，观看最佳内容会导致流失。创作者必须制作更多同样受欢迎的内容来改变这种模式。为了得出这样的结论，你需要运用你的商业知识。通常，人们知道一个功能或内容是否好，无需流失分析（但如果你不确定，可以调查用户）。
- en: 5.5 Segmenting customers by using cohort analysis
  id: totrans-383
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.5 通过群体分析对客户进行分段
- en: Now you know how to understand customer behavior and churn using a cohort analysis.
    The next step in fighting churn is using what you’ve learned to segment your customers
    and plan interventions. You’re going to learn even more about your customers in
    chapters 6 and 7, but you don’t need to wait any longer to get started. As I mentioned
    in chapter 1, I’m not going to go into details about different types of customer
    interventions because they are specific to each company’s product and situation.
    But the data-based procedures for creating customer segments based on churn data
    are pretty much universal.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经知道了如何通过群体分析来理解客户行为和流失。在对抗流失的下一步，是利用你所学的知识来对客户进行分段并规划干预措施。在第6章和第7章中，你将更深入地了解你的客户，但你现在无需再等待就可以开始行动。正如我在第1章中提到的，我不会详细介绍不同类型的客户干预措施，因为它们针对的是每个公司的产品和环境。但是，基于流失数据创建客户分段的基于数据的程序几乎是通用的。
- en: 5.5.1 Segmenting process
  id: totrans-385
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5.1 分段过程
- en: 'Most of the companies I have worked with find segmenting to be pretty straightforward,
    so this explanation is brief. The main steps are as follows:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 我合作过的多数公司发现客户群体划分相当直接，因此这个解释比较简短。主要步骤如下：
- en: Use a current customer dataset (which you learned how to create at the end of
    chapter 4) to create segments. Do not use the historical dataset on which you
    did the cohort analyses.
  id: totrans-387
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用当前客户数据集（你可以在第4章末尾学习如何创建）来创建群体。不要使用你进行群体分析的原始数据集。
- en: Segmenting is usually performed on spreadsheets by the businesspeople who are
    going to make the customer interventions. In a large company, a business intelligence
    system might be used.
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 客户群体划分通常由将要进行客户干预的业务人员通过电子表格进行。在一个大型公司中，可能会使用商业智能系统。
- en: Define a segment of customers at risk of churn by choosing the metric level
    based on the result of your cohort analysis. Assuming that the metric is one in
    which higher values are associated with lower churn, the at-risk customers are
    those whose metric is below a level that you choose.
  id: totrans-389
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过根据你的群体分析结果选择指标水平，定义一个处于流失风险的客户群体。假设该指标是一个与较低流失率相关的较高值，那么处于风险中的客户是那些指标低于你选择的水平的客户。
- en: The resulting customer list can be loaded into another system, such as an email
    marketing tool or customer relationship management system, if necessary.
  id: totrans-390
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果需要，可以将生成的客户名单加载到另一个系统中，例如电子邮件营销工具或客户关系管理系统。
- en: This procedure is basic, but there are some nuances in setting the segment criteria.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 这个程序很简单，但在设置群体标准时有一些细微差别。
- en: 5.5.2 Choosing segment criteria
  id: totrans-392
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5.2 选择群体标准
- en: You can use a few strategies in setting a metric level to define a segment.
    One common approach is to set the metric level based on churn risk, such as picking
    all customers whose churn risk is above a certain level as suggested by the results
    of the cohort analysis. Suppose that your cohort analysis shows that customers
    who don’t use the product churn at a 20% rate, and at some level of a metric,
    the risk is reduced to 5%. To define a segment of at-risk customers, you choose
    the metric level at which churn risk is significantly higher than the lowest churn.
    You might choose the metric values with a churn rate of 10%, for example. Another
    strategy is to pick the level of the metric at which most of the churn reduction
    from increased usage has been achieved (assuming such a level exists, as detailed
    in section 5.1).
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用一些策略来设定一个指标水平，以定义一个客户群体。一种常见的方法是根据流失风险设定指标水平，例如，选择所有流失风险高于一定水平的客户，如根据群体分析结果所建议的。假设你的群体分析显示，不使用产品的客户流失率为20%，而在某个指标水平上，风险降低到5%。为了定义一个处于风险中的客户群体，你选择一个流失风险显著高于最低流失率的指标水平。例如，你可能选择流失率为10%的指标值。另一种策略是选择一个指标水平，在这个水平上，通过增加使用量所实现的流失减少量最大（假设存在这样的水平，详见第5.1节）。
- en: Many companies also have some kind of resource budget or other constraint on
    the number of customers they will work with for a particular intervention. An
    alternative way to define a segment is something like picking the 500 customers
    who have the lowest measure on some behavior. This approach makes sense when the
    number of customers at risk is greater than your resources, and you need to triage
    your efforts. To create such a segment, sort the current customer dataset according
    to the metric of interest and pick a predetermined number of customers from the
    bottom (or top) of the list.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 许多公司也对特定干预措施中将要处理的客户数量有一定的资源预算或其他限制。定义群体的另一种方法是选择在某种行为上度量最低的500名客户。当处于风险中的客户数量大于你的资源时，你需要对努力进行分级，这种方法是有意义的。为了创建这样的群体，根据感兴趣的指标对当前客户数据集进行排序，并从列表底部（或顶部）选择预定的客户数量。
- en: It is also common to use interventions (such as emails, calls, or training)
    to target the customers at some intermediate level of risk.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 使用干预措施（如电子邮件、电话或培训）来针对处于某些中间风险水平的客户也是常见的。
- en: TAKEAWAY You usually don’t intervene to reduce churn with the most disengaged
    customers.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: '**总结**：通常情况下，你不会对最不活跃的客户进行干预以减少客户流失。'
- en: The reasoning is that the highest-risk (lowest-use) customers can be so disengaged
    that intervention will have no effect and would be wasted. This consideration
    is most important when intervention has a cost associated with it or when you
    think that unwanted communication might disengage customers further.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 这种推理是，最高风险（最低使用）的客户可能会如此疏离，以至于干预措施将没有效果，将是浪费的。当干预措施与成本相关联或您认为不想要的沟通可能会进一步疏离客户时，这种考虑尤为重要。
- en: Summary
  id: totrans-398
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 汇总
- en: Cohort analysis compares the churn rates on groups of customer observations,
    with the groups based on measurements of a single metric.
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 队列分析比较基于单个指标测量的客户观察组的流失率。
- en: Metric cohort analysis usually shows that customers who use a product more churn
    less.
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指标队列分析通常显示，使用产品更多的客户流失较少。
- en: Each cohort should have at least 200 to 300 observations, and preferably thousands.
    If you don’t have a lot of observations for your customers, use fewer cohorts.
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个队列至少应有200到300个观察值，最好有数千个。如果您没有很多客户观察值，请使用较少的队列。
- en: Cohort analysis can be applied to subscription metrics such as tenure, MRR,
    and billing period.
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 队列分析可以应用于订阅指标，如服务期限、MRR和账单周期。
- en: A statistical summary of a dataset consists of a set of measures (such as the
    average, minimum, and maximum) taken for every metric in a dataset.
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集的统计摘要包括对数据集中每个指标所采取的一系列度量（如平均值、最小值和最大值）。
- en: A statistical summary of a dataset is a good quality assurance check on your
    data and can alert you to conditions for which you need to adjust your cohort
    analysis. You should check a set of summary statistics before you do your cohort
    analysis.
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集的统计摘要是对您数据质量保证的良好检查，并且可以提醒您需要调整队列分析的某些条件。在进行队列分析之前，您应该检查一组汇总统计量。
- en: You should discuss the dataset summary statistics with people in the business
    and correct any data issues before performing cohort analyses.
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在执行队列分析之前，您应该与业务人员讨论数据集的汇总统计量，并纠正任何数据问题。
- en: A metric is skewed when most of the observed values are within a small range
    but a relatively small number of observations are much larger.
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当大多数观察值都在一个较小的范围内，但相对较少的观察值却非常大时，指标就会偏斜。
- en: A score created from a metric is a rescaling of every metric observation so
    that the rescaled values lie on a small range close to zero. But the order of
    the observations according to the score is the same as the order according to
    the metric. (A larger metric value always maps to a higher score.)
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从指标创建的分数是对每个指标观察值的重新缩放，使得重新缩放后的值位于接近零的小范围内。但根据分数排序的观察值顺序与根据指标排序的顺序相同。（较大的指标值总是映射到较高的分数。）
- en: When a metric is skewed, a cohort analysis that uses the metric scores is easier
    to read than a cohort analysis that uses the untransformed metric.
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当一个指标偏斜时，使用该指标分数的队列分析比使用未转换的指标更容易阅读。
- en: If nonpaying users are mixed with paying customers, you should remove the nonpaying
    users before performing cohort analysis. Nonpaying users tend not to churn, regardless
    of how much they use the product, and therefore distort the relationships in cohort
    analyses.
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果非付费用户与付费客户混合在一起，您应该在执行队列分析之前移除非付费用户。非付费用户往往不会流失，无论他们使用产品的程度如何，因此会扭曲队列分析中的关系。
- en: For metrics based on rare events, you may want to remove the customers with
    zero metric values so that the cohorts reflect the differences between customers
    who have events.
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于基于罕见事件的指标，您可能希望移除具有零指标值的客户，以便队列反映具有事件的客户之间的差异。
- en: Disengaging behaviors are behaviors where customers who perform the behavior
    more have higher churn.
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 疏离行为是那些执行该行为越多的客户流失率越高的行为。
- en: Disengaging behaviors rarely show up in simple behavioral count metrics; often,
    you must remove nonusers from the cohort analysis to see the trend with cohort
    analysis on these behaviors.
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 疏离行为很少在简单的行为计数指标中显现；通常，您必须从队列分析中移除非用户，才能看到这些行为的队列分析趋势。
- en: You find segments of at-risk customers to target for interventions by choosing
    a minimum metric level based on the results of cohort analysis.
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过根据队列分析的结果选择最小指标水平，您可以找到有风险的客户细分，以进行干预。
