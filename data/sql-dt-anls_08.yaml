- en: Chapter 8\. Creating Complex Data Sets for Analysis
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第八章。为分析创建复杂数据集
- en: In Chapters [3](ch03.xhtml#time_series_analysis) through [7](ch07.xhtml#experiment_analysis),
    we looked at a number of ways in which SQL can be used to perform analysis on
    data in databases. In addition to these specific use cases, sometimes the goal
    of a query is to assemble a data set that is specific yet general-purpose enough
    that it can be used to perform a variety of further analyses. The destination
    might be a database table, a text file, or a business intelligence tool. The SQL
    that is needed might be simple, requiring only a few filters or aggregations.
    Often, however, the code or logic needed to achieve the desired data set can become
    very complex. Additionally, such code is likely to be updated over time, as stakeholders
    request additional data points or calculations. The organization, performance,
    and maintainability of your SQL code become critical in a way that isn’t the case
    for one-time analyses.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在第[3](ch03.xhtml#time_series_analysis)到第[7](ch07.xhtml#experiment_analysis)章中，我们讨论了使用
    SQL 进行数据库中数据分析的多种方法。除了这些具体用例之外，有时查询的目标是组装一个具体但通用的数据集，可以用来执行各种进一步的分析。目标可能是数据库表、文本文件或商业智能工具。所需的
    SQL 可能很简单，仅需要几个过滤器或聚合。然而，通常实现所需数据集的代码或逻辑可能非常复杂。此外，随着利益相关者请求额外的数据点或计算，此类代码可能会随时间更新。SQL
    代码的组织、性能和可维护性变得至关重要，而这对于一次性分析来说并非如此。
- en: In this chapter, I’ll discuss principles for organizing code so that it’s easier
    to share and update. Then I’ll discuss when to keep query logic in the SQL and
    when to consider moving to permanent tables via ETL (extract-transform-load) code.
    Next, I’ll explain the options for storing intermediate results—subqueries, temp
    tables, and common table expressions (CTEs)—and considerations for using them
    in your code. Finally, I’ll wrap up with a look at techniques for reducing data
    set size and ideas for handling data privacy and removing personally identifiable
    information (PII).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我将讨论组织代码的原则，以便更容易地共享和更新。然后我将讨论何时保留 SQL 中的查询逻辑，何时考虑通过 ETL（提取-转换-加载）代码转移到永久表。接下来，我将解释存储中间结果的选项——子查询、临时表和公共表达式（CTE）——以及在代码中使用它们的考虑因素。最后，我将介绍减小数据集大小的技术和处理数据隐私以及删除个人可识别信息（PII）的方法。
- en: When to Use SQL for Complex Data Sets
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 何时使用 SQL 处理复杂数据集
- en: Almost all data sets prepared for further analysis contain some logic. The logic
    can range from the relatively simple—such as how tables are *JOIN*ed together
    and how filters are placed in the *WHERE* clause—to complex calculations that
    aggregate, categorize, parse, or perform window functions over partitions of the
    data. When creating data sets for further analysis, choosing whether to keep the
    logic within the SQL query or to push it upstream to an ETL job or downstream
    to another tool is often as much art as science. Convenience, performance, and
    availability of help from engineers all factor into the decision. There is often
    no single right answer, but you will develop intuition and confidence the longer
    you work with SQL.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎所有为进一步分析准备的数据集都包含一些逻辑。逻辑的复杂程度可以从相对简单的情况——例如如何将表进行连接（*JOIN*）以及如何在 *WHERE* 子句中放置过滤器——到对数据的分区执行聚合、分类、解析或窗口函数的复杂计算。在为进一步分析创建数据集时，选择是保留
    SQL 查询中的逻辑，还是将其推到上游的 ETL 作业或下游的其他工具，通常既是艺术也是科学。便利性、性能以及工程师的帮助可用性都是决策的因素。通常并不存在单一正确答案，但是随着您与
    SQL 的工作时间越长，您会逐渐培养直觉和信心。
- en: Advantages of Using SQL
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 SQL 的优势
- en: SQL is a very flexible language. Hopefully I convinced you in the earlier chapters
    that a wide variety of data preparation and analysis tasks can be accomplished
    using SQL. This flexibility is the main advantage of using SQL when developing
    complex data sets.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: SQL 是一种非常灵活的语言。希望在前几章中我已经说服了你，SQL 可以完成各种数据准备和分析任务。在开发复杂数据集时，这种灵活性是使用 SQL 的主要优势。
- en: In the initial stages of working with a data set, you may execute many queries.
    Work often starts with several profiling queries to understand the data. This
    is followed by building up the query step-by-step, checking transformations and
    aggregations along the way to be sure that the results returned are correct. This
    may be interspersed with more profiling, when actual values turn out to differ
    from our expectations. Complex data sets may be built up by combining several
    subqueries that answer specific questions with *JOIN*s or *UNION*s. Running a
    query and examining the output is fast and allows for rapid iteration.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理数据集的初始阶段，您可能会执行许多查询。工作通常从几个分析查询开始，以了解数据。然后逐步构建查询，沿途检查转换和聚合，确保返回的结果正确。这可能会与更多的分析交替进行，当实际值与我们的预期不同时。复杂的数据集可以通过组合几个子查询来构建，这些子查询使用*JOIN*或*UNION*回答特定问题。运行查询并检查输出是快速的，允许快速迭代。
- en: Aside from relying on the quality and timeliness of the data in the tables,
    SQL has few dependencies. Queries are run on demand and don’t rely on a data engineer
    or a release process. Queries can often be embedded into business intelligence
    (BI) tools or into R or Python code by the analyst or data scientist, without
    requesting technical support. When a stakeholder needs another attribute or aggregation
    added to the output, changes can be made quickly.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 除了依赖表中数据的质量和及时性外，SQL 几乎没有依赖性。查询是按需运行的，不依赖于数据工程师或发布流程。分析师或数据科学家通常可以将查询嵌入到商业智能（BI）工具或
    R 或 Python 代码中，而无需请求技术支持。当利益相关者需要在输出中添加另一个属性或聚合时，可以快速进行更改。
- en: Keeping logic in the SQL code itself is ideal when working on a new analysis
    and when you expect the logic and result set to undergo changes frequently. Additionally,
    when the query is fast and data is returned to stakeholders quickly, there may
    never be a need to move the logic anywhere else.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行新分析并且预计逻辑和结果集经常发生变化时，将逻辑保留在SQL代码中是理想的。此外，当查询快速且数据快速返回给利益相关者时，可能永远不需要将逻辑移动到其他位置。
- en: When to Build into ETL Instead
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时应构建到ETL中
- en: There are times when moving logic into an ETL process is a better choice than
    keeping all of it in a SQL query, especially when working in an organization that
    has a data warehouse or data lake. The two main reasons to use ETL are performance
    and visibility.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，将逻辑移入ETL流程比保留在SQL查询中更好，尤其是在工作于具有数据仓库或数据湖的组织时。使用ETL的两个主要原因是性能和可见性。
- en: Performance of SQL queries depends on the complexity of the logic, the size
    of the tables queried, and the computational resources of the underlying database.
    Although many queries run fast, particularly on the newer databases and hardware,
    you will inevitably end up writing some queries that have complex calculations,
    involve *JOIN*s of large tables or Cartesian *JOIN*s, or otherwise cause query
    time to slow down to minutes or longer. An analyst or a data scientist may be
    willing to wait for a query to return. However, most consumers of data are used
    to websites’ rapid response times and will get frustrated if they have to wait
    more than a few seconds for data.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: SQL 查询的性能取决于逻辑的复杂性、查询的表的大小以及底层数据库的计算资源。尽管许多查询运行速度很快，特别是在更新的数据库和硬件上，但您可能最终会编写一些具有复杂计算、涉及大型表的*JOIN*或笛卡尔*JOIN*的查询，或者以分钟或更长时间运行的查询。分析师或数据科学家可能愿意等待查询返回。然而，大多数数据使用者习惯于网站快速响应时间，如果他们等待数据超过几秒钟，就会感到沮丧。
- en: ETL runs behind the scenes at scheduled times and writes the result to a table.
    Since it is behind the scenes, it can run for 30 seconds, five minutes, or an
    hour, and end users will not be affected. Schedules are often daily but can be
    set to shorter intervals. End users can query the resulting table directly, without
    need for *JOIN*s or other logic, and thus experience fast query times.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ETL在计划的时间背景下运行，并将结果写入表中。由于它在后台运行，可以运行30秒、五分钟或一个小时，而不会影响最终用户。计划通常是每天运行一次，但可以设置更短的间隔。最终用户可以直接查询生成的表，无需进行*JOIN*或其他逻辑，因此体验到快速的查询时间。
- en: A good example of when ETL is often a better choice than keeping all of the
    logic in a SQL query is the daily snapshot table. In many organizations, keeping
    a daily snapshot of customers, orders, or other entities is useful for answering
    analytical questions. For customers, we might want to calculate total orders or
    visits to date, current status in a sales pipeline, and other attributes that
    either change or accumulate. We’ve seen how to create daily series, including
    for days when an entity was not present, in the discussions of time series analysis
    in [Chapter 3](ch03.xhtml#time_series_analysis) and cohort analysis in [Chapter 4](ch04.xhtml#cohort_analysis).
    At the individual entity level, and over long time periods, such queries can become
    slow. Additionally, attributes such as current status may be overwritten in the
    source table, so capturing a daily snapshot may be the only way to preserve an
    accurate picture of history. Developing the ETL and storing daily snapshot results
    in a table are often worth the effort.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 当 ETL 比将所有逻辑保留在 SQL 查询中更好的一个典型例子是每日快照表。在许多组织中，保留客户、订单或其他实体的每日快照对于回答分析问题非常有用。对于客户，我们可能想要计算到目前为止的总订单或访问次数，销售管道中的当前状态以及其他可能变化或累积的属性。我们在[第三章](ch03.xhtml#time_series_analysis)关于时间序列分析和[第四章](ch04.xhtml#cohort_analysis)关于队列分析中已经看到如何创建每日系列，包括实体不存在的天数。在个体实体级别和长时间段内，这样的查询可能变得缓慢。此外，像当前状态这样的属性可能会在源表中被覆盖，因此捕获每日快照可能是保留准确历史图片的唯一方法。开发
    ETL 并将每日快照结果存储在表中通常是值得努力的。
- en: Visibility is a second reason to move logic into ETL. Often SQL queries exist
    on an individual’s computer or are buried within report code. It can be difficult
    for others to even find the logic embedded in the query, let alone understand
    and check it for mistakes. Moving logic into ETL and storing the ETL code in a
    repository such as GitHub makes it easier for others in an organization to find,
    check, and iterate on it. Most repositories used by development teams also store
    change history, an additional benefit that allows you to see when a particular
    line in a query was added or changed.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 将逻辑移到 ETL 的第二个原因是可见性。通常 SQL 查询存在于个人计算机上或者埋藏在报告代码中。其他人甚至找到查询中嵌入的逻辑，更别说理解和检查其中的错误是困难的。将逻辑移到
    ETL 并将 ETL 代码存储在像 GitHub 这样的代码库中，可以让组织中的其他人更容易找到、检查和迭代它。大多数开发团队使用的代码库还存储变更历史，这是一个额外的好处，可以看到特定查询中的哪一行是何时添加或更改的。
- en: There are good reasons to consider putting logic into ETL, but this approach
    also has its drawbacks. One is that fresh results are not available until the
    ETL job has run and refreshed the data, even if new data has arrived in the underlying
    table. This can be overcome by continuing to run SQL against the raw data for
    very new records but limiting it to a small time window so that the query runs
    quickly. This can optionally be combined with a query on the ETL table, using
    subqueries or *UNION*. Another drawback to placing logic in ETL is that it becomes
    harder to change. Updates or bug fixes often need to be handed to a data engineer
    and code tested, checked into the repository, and released into the production
    data warehouse. For this reason, I usually opt to wait until my SQL queries are
    past the period of rapid iteration, and the resulting data sets have been reviewed
    and are in use by the organization, before moving them into ETL. Of course, making
    code harder to change and enforcing code reviews are excellent ways to ensure
    consistency and data quality.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多理由考虑将逻辑放入 ETL，但这种方法也有其缺点。其中一个是直到 ETL 作业运行并刷新数据之前，新结果才可用，即使底层表中已经到达了新数据。这可以通过继续针对原始数据运行
    SQL 但限制到一个小时间窗口以确保查询快速来克服。这可以选择与 ETL 表上的查询结合使用，使用子查询或*UNION*。将逻辑放入 ETL 的另一个缺点是更难更改。更新或修复错误通常需要交给数据工程师，并进行代码测试、检入代码库并发布到生产数据仓库。因此，我通常选择等到我的
    SQL 查询经过快速迭代期，组织已经审查并在使用的数据集之后，再将其移到 ETL 中。当然，使代码更难更改并强制进行代码审查是确保一致性和数据质量的优秀方法。
- en: When to Put Logic in Other Tools
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时将逻辑放入其他工具
- en: SQL code and the query results output in your query editor are frequently only
    part of an analysis. Results are often embedded in reports, visualized into tables
    and graphs, or further manipulated in a range of tools, from spreadsheets and
    BI software to environments in which statistical or machine learning code is applied.
    In addition to choosing when to move logic upstream into ETL, we also have choices
    about when to move logic downstream into other tools. Both performance and specific
    use cases are key factors in the decision.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: SQL代码和查询结果在查询编辑器中经常只是分析的一部分。结果通常嵌入报告中，以表格和图形形式可视化，或在从电子表格和BI软件到应用统计或机器学习代码的各种工具中进一步处理。除了选择何时将逻辑上游移动到ETL中，我们还可以选择何时将逻辑下游移动到其他工具中。决策中关键因素是性能和具体用例。
- en: Each type of tool has performance strengths and limitations. Spreadsheets are
    very flexible but are not known for being able to handle large numbers of rows
    or complex calculations across many rows. Databases definitely have a performance
    advantage, so it’s often best to perform as much of the calculation as possible
    in the database and pass the smallest data set possible on to the spreadsheet.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 每种工具类型都有其性能优势和限制。电子表格非常灵活，但不擅长处理大量行或跨多行的复杂计算。数据库明显具有性能优势，因此通常最好尽可能多地在数据库中进行计算，并将尽可能小的数据集传递给电子表格。
- en: BI tools have a range of capabilities, so it’s important to understand both
    how the software handles calculations and how the data will be used. Some BI tools
    can *cache* data (keep a local copy) in an optimized format, speeding up calculations.
    Others issue a new query each time a field is added to or removed from a report
    and thus mainly leverage the computational power of the database. Certain calculations
    such as `count distinct` and `median` require detailed, entity-level data. If
    it’s not possible to anticipate all the variations on these calculations in advance,
    it may be necessary to pass a larger, more detailed data set than otherwise might
    be ideal. Additionally, if the goal is to create a data set that allows exploration
    and slicing in many different ways, more detail is usually better. Figuring out
    the best combination of SQL, ETL, and BI tool computation can take some iteration.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: BI工具具有各种功能，因此了解软件处理计算方式及数据使用方式至关重要。一些BI工具可以*缓存*数据（保留本地副本）以优化格式加速计算。其他工具每次向报告添加或移除字段时都会发出新的查询，因此主要利用数据库的计算能力。某些计算，如`count
    distinct`和`median`，需要详细的实体级数据。如果无法预见这些计算的所有变体，可能需要传递比理想情况下更大更详细的数据集。此外，如果目标是创建一个允许多种方式探索和切片的数据集，通常详细数据更好。找到SQL、ETL和BI工具计算的最佳组合可能需要一些迭代过程。
- en: When the goal is to perform statistical or machine learning analysis on the
    data set using a language such as R or Python, detailed data is usually better.
    Both of these languages can perform tasks that overlap with SQL, such as aggregation
    and text manipulation. It’s often best to perform as much of the calculation as
    possible in SQL, to leverage the computational power of the database, but no more.
    Flexibility to iterate is usually an important part of the modeling process. The
    choice of whether to perform calculations in SQL or another language may also
    depend on your familiarity and comfort level with each. Those who are very comfortable
    in SQL may prefer to do more calculations in the database, while those who are
    more proficient in R or Python may prefer to do more calculations there.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 当目标是使用R或Python等语言在数据集上执行统计或机器学习分析时，通常详细数据更好。这两种语言都可以执行与SQL重叠的任务，如聚合和文本处理。通常最好尽可能多地在SQL中执行计算，以利用数据库的计算能力，但不要过度使用。灵活性迭代通常是建模过程中的重要部分。在SQL或其他语言中执行计算的选择也可能取决于您对每种语言的熟悉程度和舒适度。那些在SQL中非常熟悉的人可能更倾向于在数据库中进行更多的计算，而那些在R或Python中更熟练的人可能更倾向于在那里进行更多的计算。
- en: Tip
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: 'Although there are few rules to deciding where to put logic, I will encourage
    you to follow one rule in particular: avoid manual steps. It’s easy enough to
    open a data set in a spreadsheet or text editor, make a small change, save, and
    move on. But when you need to iterate, or when new data arrives, it’s easy to
    forget that manual step or to perform it inconsistently. In my experience, there’s
    no such thing as a truly “one-off” request. Put logic into code somewhere, if
    at all possible.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管决定逻辑放置位置的规则不多，我会特别鼓励您遵循一个规则：避免手动步骤。在电子表格或文本编辑器中打开数据集，做出小改动，保存并继续操作足够简单。但是当您需要迭代或有新数据到达时，很容易忘记手动步骤或执行不一致。根据我的经验，没有真正的“一次性”请求。尽可能将逻辑放在某处的代码中。
- en: SQL is a great tool and is incredibly flexible. It also sits within the analysis
    workflow and within an ecosystem of tools. Deciding where to put calculations
    can take some trial and error as you iterate through what is feasible among SQL,
    ETL, and downstream tools. The more familiarity and experience you have with all
    the available options, the better you will be able to estimate trade-offs and
    continue to improve the performance and flexibility of your work.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: SQL 是一个强大的工具，非常灵活。它也坐落在分析工作流程和工具生态系统中。决定计算放置位置可能需要一些试验和错误，因为您在 SQL、ETL 和下游工具之间进行迭代时需要考虑可行性。您对所有可用选项越熟悉和经验越丰富，您就能更好地估计权衡和继续提高工作的性能和灵活性。
- en: Code Organization
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代码组织
- en: 'SQL has few formatting rules, which can lead to unruly queries. Query clauses
    must be in the correct order: *SELECT* is followed by *FROM*, and *GROUP BY* cannot
    precede *WHERE,* for example. A few keywords such as *SELECT* and *FROM* are *reserved*
    (i.e., they cannot be used as field names, table names, or aliases). However,
    unlike in some other languages, newlines, whitespace (other than the spaces that
    separate words), and capitalization are not important and are ignored by the database.
    Any of the example queries in this book could have been written on a single line,
    and with or without capital letters, except in quoted strings. As a result, the
    burden of code organization is on the person writing the query. Fortunately, we
    have some formal and informal tools for keeping code organized, from commenting
    to “cosmetic” formatting such as indentation and storage options for files of
    SQL code.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: SQL 的格式化规则较少，这可能导致查询混乱。查询子句必须按正确顺序排列：*SELECT* 之后是 *FROM*，*GROUP BY* 不能在 *WHERE*
    之前，例如。一些关键字如 *SELECT* 和 *FROM* 是 *保留字*（即不能用作字段名、表名或别名）。然而，与其他一些语言不同，数据库会忽略换行、空白（除了分隔单词的空格）和大小写。本书中的示例查询都可以写在一行上，并且可以有或没有大写字母，除非在引号字符串中。因此，代码组织的负担落在编写查询的人身上。幸运的是，我们有一些正式和非正式的工具来保持代码组织良好，从注释到“装饰性”格式化（如缩进和
    SQL 代码文件的存储选项）。
- en: Commenting
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 注释
- en: 'Most coding languages have a way to indicate that a block of text should be
    treated as a comment and ignored during execution. SQL has two options. The first
    is to use two dash marks, which turns everything on the line that follows into
    a comment:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数编码语言都有一种方法来指示将文本块视为注释并在执行过程中忽略它。SQL 有两种选择。第一种是使用两个短划线，这会将后续行中的所有内容转换为注释：
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The second option is to use the slash (/) and star (*) characters to start
    a comment block, which can extend over multiple lines, followed by a star and
    slash to end the comment block:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种选择是使用斜杠（/）和星号（*）字符开始一个注释块，该块可以跨多行，后面跟着星号和斜杠结束注释块：
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Many SQL editors adjust the visual style of code inside comments, by graying
    them out or otherwise changing the color, to make them easier to spot.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 许多 SQL 编辑器调整了代码内部注释的视觉样式，将其变灰或以其他方式改变颜色，以便更容易识别。
- en: Commenting code is a good practice, but admittedly it’s one that many people
    struggle to do on a regular basis. SQL is often written quickly, and especially
    during exploration or profiling exercises, we don’t expect to keep our code for
    the long term. Overly commented code can be just as difficult to read as code
    with no comments. And we all suffer from the idea that since we wrote the code,
    we will always be able to remember *why* we wrote the code. However, anyone who
    has inherited a long query written by a colleague or has stepped away from a query
    for a few months and then come back to update it will know that it can be frustrating
    and time consuming to decipher the code.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 注释代码是一个好习惯，但必须承认，许多人在日常生活中很难坚持做到这一点。SQL 通常是迅速编写的，特别是在探索或剖析练习中，我们不指望长期保留我们的代码。过度注释的代码与没有注释的代码一样难以阅读。我们都曾因为我们写了这段代码，所以我们将永远能记住写这段代码的原因的想法而受苦。然而，任何继承自同事写的长查询或离开查询几个月后再回来更新它的人都会知道，解释代码可能是令人沮丧和耗时的。
- en: 'To balance the burden and the benefit of commenting, I try to follow a few
    rules of thumb. First, add a comment anywhere that a value has a nonobvious meaning.
    Many source systems will encode values as integers, and their meaning is easy
    to forget. Leaving a note makes the meaning clear and makes the code easier to
    change if needed:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了平衡注释的负担和好处，我尝试遵循一些经验法则。首先，在任何值具有非明显含义的地方添加注释。许多源系统将值编码为整数，而它们的含义很容易被忘记。留下一条注释使含义清晰，并使代码更易于根据需要更改：
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Second, comment on any other nonobvious calculations or transformations. These
    can be anything that someone who hasn’t spent the time profiling the data set
    might not know, from data entry errors to the existence of outliers:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，对于任何其他非明显的计算或转换进行评论。这些可以是任何人未花时间对数据集进行剖析可能不知道的内容，从数据输入错误到异常值的存在：
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The third practice I try to follow around commenting is to leave notes when
    the query contains multiple subqueries. A quick line about what each subquery
    calculates makes it easy to skip to the relevant piece when coming back later
    to quality check or edit a longer query:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我尝试遵循的第三个关于注释的实践是在查询包含多个子查询时留下注释。关于每个子查询计算的简短说明使得以后在质量检查或编辑较长查询时轻松跳转到相关部分变得容易：
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Commenting well takes practice and some discipline, but it’s worth doing for
    most queries that are longer than a few lines. Commenting can also be used to
    add useful information to the overall query, such as purpose, author, date created,
    and so on. Be kind to your colleagues, and to your future self, by placing helpful
    comments in your code.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 良好的注释需要练习和一些纪律，但对于大部分长于几行的查询来说是值得的。注释还可以用于向整体查询添加有用的信息，例如目的、作者、创建日期等等。通过在代码中添加有帮助的注释，善待你的同事和未来的自己。
- en: Capitalization, Indentation, Parentheses, and Other Formatting Tricks
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大小写、缩进、括号和其他格式技巧
- en: Formatting, and consistent formatting especially, is a good way to keep SQL
    code organized and legible. Databases ignore capitalization and whitespace (spaces,
    tabs, and newlines) in SQL, so we can use these to our advantage to format code
    into more legible blocks. Parentheses can both control the order of execution,
    which we will discuss more later, and also visually group calculation elements.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 格式化，特别是一致的格式化，是保持 SQL 代码有条理和可读性的好方法。数据库在 SQL 中忽略大小写和空白（空格、制表符和换行），因此我们可以利用这些优势将代码格式化为更易读的块。括号不仅可以控制执行顺序（我们稍后会详细讨论），还可以在视觉上组合计算元素。
- en: 'Capitalized words stand out from the rest, as anyone who has received an email
    with an all-caps subject line can confirm. I like to use capitalization only for
    the main clauses: *SELECT*, *FROM*, *JOIN*, *WHERE*, and so on. Particularly in
    long or complex queries, being able to spot these quickly and thus to understand
    where the *SELECT* clause ends and the *FROM* clause begins saves me a lot of
    time.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 大写的词突出于其他内容之中，任何收到全大写主题邮件的人都可以确认这一点。我喜欢仅在主要从句中使用大写：*SELECT*、*FROM*、*JOIN*、*WHERE*
    等等。特别是在长或复杂的查询中，能够迅速识别这些内容，从而理解*SELECT*从句何时结束，*FROM*从句何时开始，节省了我大量时间。
- en: 'Whitespace is another key way to organize and make parts of the query easier
    to find, and to understand which parts logically go together. Any SQL query could
    be written on a single line in the editor, but in most cases this would lead to
    a lot of scrolling left and right through code. I like to start each clause (*SELECT*,
    *FROM*, etc.) on a new line, which, along with capitalization, helps me keep track
    of where each one starts and ends. Additionally, I find that putting aggregations
    on their own lines, as well as functions that take up some space, helps with organization.
    For CASE statements with more than two WHEN conditions, separating them onto multiple
    lines is also a good way to easily see and keep track of what is happening in
    the code. As an example, we can query the `type` and `mag` (magnitude), parse
    `place`, and then count the records in the `earthquakes` table, with some filtering
    in the *WHERE* clause:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 空白字符是组织查询部分并使其更易于找到的关键方法，以及理解哪些部分在逻辑上彼此配合。任何SQL查询都可以在编辑器中的单行上编写，但在大多数情况下，这会导致代码左右滚动。我喜欢在新的一行上开始每个子句（*SELECT*、*FROM*等），这与大写一起帮助我跟踪每个子句的开始和结束。此外，我发现将聚合函数放在自己的行上，以及占据一些空间的函数，有助于组织。对于有两个以上WHEN条件的CASE语句，将它们分开到多行上也是一种很好的方法，可以轻松地看到和跟踪代码中正在发生的事情。例如，我们可以查询`type`和`mag`（大小），解析`place`，然后计算`earthquakes`表中的记录，在*WHERE*子句中进行一些过滤：
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Indentation is another trick for keeping code visually organized. Adding spaces
    or tabs to line up the WHEN items within a CASE statement is one example. You’ve
    also seen subqueries indented in examples throughout the book. This makes subqueries
    visually stand apart, and when a query has multiple levels of nested subqueries,
    it makes it easier to see and understand the order in which they will be evaluated
    and which subqueries are peers in terms of level:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 缩进是保持代码视觉组织的另一个技巧。在CASE语句中添加空格或制表符以对齐其中的WHEN项目是一个例子。您还在整本书的示例中看到缩进的子查询。这使得子查询在视觉上显得独立，当一个查询有多级嵌套子查询时，它使得查看和理解将被评估的顺序以及哪些子查询在级别上是对等的更加容易：
- en: '[PRE6]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Any number of other formatting choices can be made, and the query will return
    the same results. Long-term SQL writers tend to have their own formatting preferences.
    However, clear and consistent formatting makes creating, maintaining, and sharing
    SQL code much easier.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 任意数量的其他格式选择都可以，查询将返回相同的结果。长期以来，SQL编写者倾向于有自己的格式偏好。但是，清晰和一致的格式使得创建、维护和分享SQL代码更加容易。
- en: Many SQL query editors provide some form of query formatting and coloration.
    Usually keywords are colored, making them easier to spot within a query. These
    visual clues make both developing and reviewing SQL queries much easier. If you’ve
    been writing SQL in a query editor all along, try opening a *.sql* file in a plain
    text editor to see the difference coloration makes. [Figure 8-1](#screenshot_of_keyword_coloration_in_the)
    shows an example of a SQL query editor, and the same code is shown in a plain
    text editor in [Figure 8-2](#the_same_code_as_plain_text_in_the_text) (please
    note that these may appear in grayscale in some versions of this book).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 许多SQL查询编辑器提供某种形式的查询格式化和着色。通常关键字会被着色，使其在查询中更易于识别。这些视觉线索使得开发和审查SQL查询都更加容易。如果你一直在查询编辑器中编写SQL，请尝试在纯文本编辑器中打开一个*.sql*文件，看看着色效果有多大的不同。[图 8-1](#screenshot_of_keyword_coloration_in_the)展示了一个SQL查询编辑器的示例，同样的代码在[图 8-2](#the_same_code_as_plain_text_in_the_text)中展示为纯文本编辑器中的样式（请注意，在本书的某些版本中可能为灰度显示）。
- en: '![](Images/sfda_0801.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/sfda_0801.png)'
- en: Figure 8-1\. Screenshot of keyword coloration in the SQL query editor DBVisualizer
  id: totrans-51
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-1\. SQL查询编辑器DBVisualizer中关键字着色的屏幕截图
- en: '![](Images/sfda_0802.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/sfda_0802.png)'
- en: Figure 8-2\. The same code as plain text in the text editor Atom
  id: totrans-53
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-2\. 同样的代码在文本编辑器Atom中的纯文本形式
- en: Formatting is optional from the database perspective, but it’s a good practice.
    Consistent use of spacing, capitalization, and other formatting options goes a
    long way toward keeping your code readable, therefore making it easier to share
    and maintain.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据库的角度来看，格式化是可选的，但这是一个好的实践。一致使用间距、大写和其他格式选项有助于保持代码的可读性，因此更容易分享和维护。
- en: Storing Code
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 存储代码
- en: After going to the trouble of commenting and formatting code, it’s a good idea
    to store it somewhere in case you need to use or reference it later.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行注释和格式化代码之后，将其存储在某个地方以备日后使用或参考是一个好主意。
- en: Many data analysts and scientists work with a SQL editor, often a desktop piece
    of software. SQL editors are useful because they usually include tools for browsing
    the database schema alongside a code window. They save files with a *.sql* extension,
    and these text files can be opened and changed in any text editor. Files can be
    saved in local directories or in cloud-based file storage services.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 许多数据分析师和科学家使用SQL编辑器，通常是桌面软件。SQL编辑器很有用，因为它们通常包含用于浏览数据库架构的工具，并且有一个代码窗口。它们将文件保存为.sql扩展名的文件，这些文本文件可以在任何文本编辑器中打开和修改。文件可以保存在本地目录或云端文件存储服务中。
- en: Since they are text, SQL code files are easy to store in change control repositories
    such as GitHub. Using a repository provides a nice backup option and makes for
    easy sharing with others. Repositories also track the change history of files,
    which is useful when you need to figure out when a particular change was made,
    or when the change history is required for regulatory reasons. The main drawback
    of GitHub and other tools is that they are usually not a required step in the
    analysis workflow. You need to remember to update your code periodically, and
    as with any manual step, it’s easy to forget to do it.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 由于它们是文本文件，SQL代码文件很容易存储在像GitHub这样的变更控制存储库中。使用存储库提供了一个不错的备份选项，并且便于与他人分享。存储库还会跟踪文件的变更历史，这在需要查找特定更改的时间或出于法规原因需要变更历史时非常有用。GitHub和其他工具的主要缺点是它们通常不是分析工作流程中的必需步骤。您需要记住定期更新您的代码，并且与任何手动步骤一样，很容易忘记执行更新。
- en: Organizing Computations
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 组织计算
- en: 'Two related problems we face when creating complex data sets are getting the
    logic right and getting good query performance. Logic must be correct, or the
    results will be meaningless. Query performance for analysis purposes, unlike for
    transactional systems, usually has a range of “good enough.” Queries that don’t
    return are problematic, but the difference between waiting 30 seconds and waiting
    a minute for results may not matter a great deal. With SQL, there is often more
    than one way to write a query that returns the correct results. We can use this
    to our advantage to both ensure correct logic and tune performance of long-running
    queries. There are three main ways to organize the calculation of intermediate
    results in SQL: the subquery, temp tables, and common table expressions (CTEs).
    Before we dive into them, we’ll review the order of evaluation in SQL. To wrap
    up the section, I’ll introduce `grouping sets`, which can replace the need to
    *UNION* queries together in certain cases.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 创建复杂数据集时，我们面临的两个相关问题是确保逻辑正确和获得良好的查询性能。逻辑必须正确，否则结果将毫无意义。对于分析目的的查询性能，与事务系统不同，通常有一个“足够好”的范围。无法返回查询的查询是有问题的，但等待30秒和等待一分钟的结果可能并不会有很大差别。在SQL中，通常有多种编写返回正确结果的查询的方法。我们可以利用这一点来确保逻辑正确并调整长时间运行查询的性能。在SQL中，有三种主要方法来组织中间结果的计算：子查询、临时表和公共表表达式（CTE）。在我们深入研究它们之前，我们将回顾SQL的评估顺序。为了结束这一部分，我将介绍`分组集`，它可以在某些情况下替代*联合*查询。
- en: Understanding Order of SQL Clause Evaluation
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解SQL子句评估顺序
- en: Databases translate SQL code into a set of operations that will be carried out
    in order to return the requested data. While understanding exactly how this happens
    isn’t necessary to be good at writing SQL for analysis, understanding the order
    in which the database will perform its operations is incredibly useful (and is
    sometimes necessary to debug unexpected results).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库将SQL代码翻译成一组操作，这些操作按顺序执行以返回请求的数据。虽然不必深入了解其工作原理就能写出分析用的SQL，但了解数据库执行操作的顺序非常有用（有时候还是必要的，以便调试出现的意外结果）。
- en: Tip
  id: totrans-63
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Many modern databases have sophisticated query optimizers that consider various
    parts of the query to come up with the most efficient plan for execution. Although
    they may consider parts of the query in a different order from that discussed
    here and therefore may need less query optimization from humans, they won’t calculate
    intermediate results in a different order from that discussed here.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 许多现代数据库都有复杂的查询优化器，可以考虑查询的各个部分，以制定最高效的执行计划。尽管它们可能会按照不同于此处讨论的顺序考虑查询的各个部分，因此可能需要较少的人为查询优化，但它们不会按照此处讨论的顺序计算中间结果。
- en: The general order of evaluation is shown in [Table 8-1](#sql_query_order_of_evaluation).
    SQL queries usually include only a subset of possible clauses, so actual evaluation
    includes only the steps relevant to the query.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: SQL查询评估的一般顺序显示在[表 8-1](#sql_query_order_of_evaluation)中。SQL查询通常仅包括可能的子句子集，因此实际评估包括与查询相关的步骤。
- en: Table 8-1\. SQL query order of evaluation
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8-1\. SQL查询评估顺序
- en: '| 1 | FROM including *JOIN*s and their *ON* clauses |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 包括*JOIN*及其*ON*子句的FROM |'
- en: '| 2 | WHERE |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 2 | WHERE |'
- en: '| 3 | GROUP BY including aggregations |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 包括聚合的GROUP BY |'
- en: '| 4 | HAVING |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| 4 | HAVING |'
- en: '| 5 | Window functions |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 窗口函数 |'
- en: '| 6 | SELECT |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 6 | SELECT |'
- en: '| 7 | DISTINCT |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 7 | DISTINCT |'
- en: '| 8 | UNION |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 8 | UNION |'
- en: '| 9 | ORDER BY |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 9 | ORDER BY |'
- en: '| 10 | LIMIT and OFFSET |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 10 | LIMIT和OFFSET |'
- en: First the tables in the *FROM* clause are evaluated, along with any *JOIN*s.
    If the *FROM* clause includes any subqueries, these are evaluated before proceeding
    to the rest of the steps. In a *JOIN*, the *ON* clause specifies how the tables
    are to be *JOIN*ed, which may also filter the result set.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，计算*FROM*子句中的表格，以及任何*JOIN*。如果*FROM*子句包含任何子查询，在继续下一步之前需要评估这些子查询。在*JOIN*中，*ON*子句指定了如何*JOIN*表格，这也可能过滤结果集。
- en: Tip
  id: totrans-78
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: '*FROM* is always evaluated first, with one exception: when the query doesn’t
    contain a *FROM* clause. In most databases, it’s possible to query using only
    a *SELECT* clause, as seen in some of the examples in this book. A *SELECT*-only
    query can return system information such as the date and database version. It
    can also apply mathematical, date, text, and other functions to constants. While
    there is admittedly little use for such queries in final analyses, they are handy
    for testing out functions or iterating over tricky calculations rapidly.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '*FROM*始终首先评估，除非查询不包含*FROM*子句的情况下。在大多数数据库中，可以仅使用*SELECT*子句进行查询，如本书中的某些示例所示。仅*SELECT*查询可以返回系统信息，如日期和数据库版本。它还可以对常量应用数学、日期、文本和其他函数。尽管在最终分析中很少使用这样的查询，但它们对于快速测试函数或迭代复杂计算非常方便。'
- en: Next, the *WHERE* clause is evaluated to determine which records should be included
    in further calculations. Note that *WHERE* falls early in the order of evaluation
    and so cannot include the results of calculations that happen in a later step.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，评估*WHERE*子句以确定应包含在进一步计算中的记录。请注意，*WHERE*在评估顺序中较早，因此不能包含稍后步骤中发生的计算结果。
- en: '*GROUP BY* is calculated next, including the related aggregations such as `count`,
    `sum`, and `avg`. As you might expect, *GROUP BY* will include only the values
    that exist in the *FROM* tables after any *JOIN*ing and filtering in the *WHERE*
    clause.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来计算*GROUP BY*，包括相关的聚合函数，如`count`、`sum`和`avg`。正如您所预期的那样，*GROUP BY*将仅包括在*FROM*表格中存在的值，这是在*JOIN*和*WHERE*子句中进行过滤后的结果。
- en: '*HAVING* is evaluated next. Since it follows *GROUP BY*, *HAVING* can perform
    filtering on aggregated values returned by *GROUP BY*. The only other way to filter
    by aggregated values is to place the query in a subquery and apply the filters
    in the main query. For example, we might want to find all the states that have
    at least one thousand terms in the `legislators_terms` table, and we’ll order
    by terms in descending order for good measure:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来评估*HAVING*。由于它跟在*GROUP BY*之后，*HAVING*可以对*GROUP BY*返回的聚合值进行过滤。通过将查询放置在子查询中并在主查询中应用过滤器，也可以通过聚合值进行过滤。例如，我们可能希望找到`legislators_terms`表中至少有一千个任期的所有州，并按照任期降序排列：
- en: '[PRE7]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Window functions, if used, are evaluated next. Interestingly, since aggregates
    have already been calculated at this point, they can be used in the window function
    definition. For example, in the `legislators` data set from [Chapter 4](ch04.xhtml#cohort_analysis),
    we could calculate both the terms served per state and the average terms across
    all states in a single query:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用窗口函数，则在此时评估。有趣的是，因为聚合已在此时计算，所以可以在窗口函数定义中使用它们。例如，在[第四章](ch04.xhtml#cohort_analysis)中的`legislators`数据集中，可以在单个查询中计算每个州的任期服务和所有州的平均任期：
- en: '[PRE8]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Aggregates can also be used in the *OVER* clause, as in the following query
    that ranks the states in descending order by the total number of terms:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合也可以在*OVER*子句中使用，如下面的查询所示，它按总任期数降序排列各州：
- en: '[PRE9]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: At this point, the *SELECT* clause is finally evaluated. This is a little counterintuitive
    since aggregations and window functions are typed in the *SELECT* section of the
    query. However, the database has already taken care of the calculations, and the
    results are then available for further manipulation or for display as is. For
    example, an aggregation can be placed within a CASE statement and have mathematical,
    date, or text functions applied if the result of the aggregation is one of those
    data types.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，*SELECT* 子句最终被评估。这有点反直觉，因为聚合和窗口函数在查询的*SELECT*部分中被输入。然而，数据库已经处理了计算，结果可以进一步操作或直接显示。例如，聚合可以放在一个CASE语句中，并且可以应用数学、日期或文本函数，如果聚合的结果是这些数据类型之一。
- en: Tip
  id: totrans-89
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: The aggregators `sum`, `count`, and `avg` return numeric values. However, `min`
    and `max` functions return the same data type as the input and use the inherent
    ordering of that data type. For example, `min` and `max` dates return the earliest
    and latest calendar dates, while `min` and `max` on text fields use alphabetical
    order to determine the result.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合函数`sum`、`count`和`avg`返回数值类型。然而，`min`和`max`函数返回与输入相同的数据类型，并使用该数据类型的固有排序。例如，日期的`min`和`max`返回最早和最晚的日历日期，而文本字段的`min`和`max`则使用字母顺序确定结果。
- en: Following *SELECT* is *DISTINCT*, if present in the query. This means that all
    the rows are calculated and then deduplication occurs.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在*SELECT*之后是*DISTINCT*，如果在查询中存在。这意味着所有行都被计算，然后进行去重。
- en: '*UNION* (or *UNION ALL*) is performed next. Up to this point, each query that
    makes up a *UNION* is evaluated independently. This stage is when the result sets
    are assembled together into one. This means that the queries can go about their
    calculations in very different ways or from different data sets. All *UNION* looks
    for is the same number of columns and for those columns to have compatible data
    types.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '*UNION*（或*UNION ALL*）接下来执行。到目前为止，组成*UNION*的每个查询都是独立评估的。这个阶段是将结果集合并到一起。这意味着查询可以以非常不同的方式或来自不同数据集进行计算。*UNION*只要求列的数量相同，并且这些列具有兼容的数据类型。'
- en: '*ORDER BY* is almost the last step in evaluation. This means that it can access
    any of the prior calculations to sort the result set. The only caveat is that
    if *DISTINCT* is used, *ORDER BY* cannot include any fields that are not returned
    in the *SELECT* clause. Otherwise, it is entirely possible to order a result set
    by a field that doesn’t otherwise appear in the query.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '*ORDER BY* 几乎是评估的最后一步。这意味着它可以访问之前任何计算结果来对结果集进行排序。唯一的注意事项是，如果使用了*DISTINCT*，*ORDER
    BY* 不能包含在*SELECT*子句中未返回的任何字段。否则，可以完全按照查询中未出现的字段对结果集进行排序。'
- en: '*LIMIT* and *OFFSET* are evaluated last in the query execution sequence. This
    ensures that the subset of results returned will have fully calculated results
    as specified by any of the other clauses that are in the query. This also means
    that *LIMIT* has somewhat limited use in controlling the amount of work the database
    does before the results are returned to you. This is perhaps most noticeable when
    a query contains a large *OFFSET* value. In order to *OFFSET* by, say, three million
    records, the database still needs to calculate the entire result set, figure out
    where the three millionth plus one record is, and then return the records specified
    by the *LIMIT*. This doesn’t mean *LIMIT* isn’t useful. Checking a few results
    can confirm calculations without overwhelming the network or your local machine
    with data. Also, using *LIMIT* as early in a query as possible, such as in a subquery,
    can still dramatically reduce the work required by the database as you develop
    a more complex query.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '*LIMIT* 和 *OFFSET* 在查询执行序列中最后评估。这确保返回的结果子集将完全按照查询中的任何其他子句指定的已计算结果。这也意味着*LIMIT*
    在控制数据库在返回结果之前所做的工作量方面有些限制。当查询包含大的*OFFSET*值时，这可能是最明显的。为了偏移，比如说三百万条记录，数据库仍然需要计算整个结果集，找出第三百万加一条记录的位置，然后返回*LIMIT*指定的记录。这并不意味着*LIMIT*没有用处。检查少量结果可以确认计算结果，而不会用数据压倒网络或本地机器。另外，在尽可能早地使用*LIMIT*，比如在子查询中，仍然可以显著减少数据库所需的工作量，特别是当您开发更复杂的查询时。'
- en: 'Now that we have a good understanding of the order in which databases evaluate
    queries and perform calculations, we’ll turn to some options for controlling these
    operations in the context of a larger, complex query: subqueries, temporary tables,
    and CTEs.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对数据库评估查询和执行计算的顺序有了很好的理解，我们将转向一些选项来控制这些操作在更大更复杂查询的上下文中的操作：子查询、临时表和CTE。
- en: Subqueries
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 子查询
- en: '*Subqueries* are usually the first way we learn how to control the order of
    evaluation in SQL, or to accomplish calculations that can’t be achieved in a single
    main query. They are versatile and can help organize long queries into smaller
    chunks with discrete purposes.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '*子查询*通常是我们学习如何控制 SQL 中评估顺序的第一种方式，或者完成单个主查询无法实现的计算的方法。它们非常灵活，可以帮助将长查询组织成具有明确目的的小块。'
- en: A subquery is enclosed in parentheses, a notation that should be familiar from
    mathematics, where parentheses also force evaluation of some part of an equation
    prior to the rest. Within the parentheses is a standalone query that is evaluated
    before the main outer query. Assuming the subquery is in the *FROM* clause, the
    result set can then be queried by the main code, just like any other table. We’ve
    already seen many examples with subqueries in this book.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 子查询用括号括起来，这种表示法在数学中应该很熟悉，其中括号还会强制在其余部分之前评估等式的某些部分。括号内是一个独立的查询，在主外部查询之前进行评估。假设子查询位于*FROM*子句中，则结果集可以像任何其他表一样由主代码查询。在本书中，我们已经看过许多带有子查询的示例。
- en: 'An exception to the standalone nature of a subquery is a special type called
    a *lateral subquery*, which can access results from previous items in the *FROM*
    clause. A comma and the keyword *LATERAL* are used instead of *JOIN*, and there
    is no *ON* clause. Instead, a prior query is used inside the subquery. As an example,
    imagine we wanted to analyze previous party membership for currently sitting legislators.
    We could find the first year they were a member of a different party, and check
    how common that is when grouped by their current party. In the first subquery,
    we find the currently sitting legislators. In the second, lateral subquery, we
    use the results from the first subquery to return the earliest `term_start` where
    the party is different from the current party:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 一个例外是一个特殊类型的子查询，称为*侧向子查询*，它可以访问*FROM*子句中先前项目的结果。使用逗号和关键字*LATERAL*代替*JOIN*，并且没有*ON*子句。相反，在子查询中使用先前的查询。例如，假设我们想要分析当前议员以前的党派成员资格。我们可以找到他们第一次加入其他党派的年份，并检查按当前党派分组时这种情况有多常见。在第一个子查询中，我们找到当前的议员。在第二个侧向子查询中，我们使用第一个子查询的结果返回最早的`term_start`，其中党派与当前党派不同：
- en: '[PRE10]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This turns out to be fairly uncommon. Only three current legislators have switched
    parties, and no party has had more switchers than other parties. There are other
    ways to return the same result—for example, by changing the query to a *JOIN*
    and moving the criteria in the *WHERE* clause of the second subquery to the *ON*
    clause:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况其实相当罕见。目前只有三名立法者改变了党派，而没有哪个党派有更多的党派变更者。有其他方法可以得到相同的结果，例如，通过将查询改为*JOIN*，并将第二个子查询中的条件移到*ON*子句中：
- en: '[PRE11]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: If the second table is very large, filtering by a value returned in a previous
    subquery can speed up execution. In my experience, use of *LATERAL* is less common,
    and therefore less well understood, than other syntax, so it’s good to reserve
    it for use cases that can’t be solved efficiently another way.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如果第二个表非常大，通过前一个子查询返回的值进行过滤可以加快执行速度。根据我的经验，使用*LATERAL*的情况较少，因此比其他语法理解得更少，所以最好将其保留用于无法通过其他方式有效解决的用例。
- en: 'Subqueries allow a lot of flexibility and control over the order of calculations.
    However, a complex series of calculations in the middle of a larger query can
    become difficult to understand and maintain. At other times, the performance of
    subqueries is too slow, or the query won’t return results at all. Fortunately,
    SQL has some additional options that may help in these situations: temporary tables
    and common table expressions.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 子查询在控制计算顺序和灵活性方面提供了很大的帮助。然而，在较大查询中复杂的一系列计算可能会变得难以理解和维护。在其他时候，子查询的性能太慢，或者查询根本无法返回结果。幸运的是，SQL
    还有一些额外的选项可以在这些情况下帮助：临时表和公共表达式。
- en: Temporary Tables
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 临时表
- en: 'A *temporary (temp) table* is created in a similar way to any other table in
    the database, but with a key difference: it persists only for the duration of
    the current session. Temp tables are useful when you are working with only a small
    part of a very large table, as small tables are much faster to query. They are
    also useful when you want to use an intermediate result in multiple queries. Since
    the temp table is a standalone table, it can be queried many times within the
    same session. Yet another time they are useful is when you are working in certain
    databases, such as Redshift or Vertica, that partition data across nodes. *INSERT*ing
    data into a temp table can align the partitioning to other tables that will be
    *JOIN*ed together in a subsequent query. There are two main drawbacks to temp
    tables. First, they require database privileges to write data, which may not be
    allowed for security reasons. Second, some BI tools, such as Tableau and Metabase,
    allow only a single SQL statement to create a data set,^([1](ch08.xhtml#ch01fn10))
    whereas a temp table requires at least two: the statement to *CREATE* and *INSERT*
    data into the temp table and the query using the temp table.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '*临时（temp）表*的创建方式与数据库中的任何其他表类似，但有一个关键区别：它仅在当前会话期间存在。当你只处理非常大表的一小部分时，临时表非常有用，因为小表查询速度要快得多。当你想在多个查询中使用中间结果时，它们也很有用。由于临时表是独立的，可以在同一会话中多次查询。另一个有用的场景是在某些数据库中工作，如Redshift或Vertica，这些数据库将数据分区到多个节点中。将数据插入临时表可以使分区与后续查询中将*JOIN*在一起的其他表对齐。临时表的主要缺点有两个。首先，它们需要数据库权限来写入数据，出于安全原因可能不允许。其次，一些BI工具，如Tableau和Metabase，仅允许单个SQL语句创建数据集，^([1](ch08.xhtml#ch01fn10))
    而临时表至少需要两个：*CREATE*语句和*INSERT*语句用于将数据插入临时表以及使用临时表的查询语句。'
- en: 'To create a temporary table, use the *CREATE* command, followed by the keyword
    TEMPORARY and the name you wish to give it. The table can then be defined and
    a second statement used to populate it, or you can use *CREATE as SELECT* to create
    and populate in one step. For example, you could create a temp table with the
    distinct states for which there have been legislators:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建临时表，请使用*CREATE*命令，后跟关键字TEMPORARY和您希望为其命名的名称。然后可以定义表并使用第二个语句将其填充，或者您可以使用*CREATE
    as SELECT*一步创建和填充。例如，您可以创建一个包含已有立法者的不同州的临时表：
- en: '[PRE12]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The first statement creates the table, while the second statement populates
    the temp table with values from a query. Note that by defining the table first,
    I need to specify the data type for all the columns (in this case `varchar` for
    the `state` column) and can optionally use other elements of table definition,
    such as setting a primary key. I like to prefix temp table names with “temp_”
    or “tmp_” to remind myself of the fact that I’m using a temp table in the main
    query, but this isn’t strictly necessary.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 第一条语句创建表，第二条语句从查询中填充临时表的值。请注意，通过首先定义表，我需要为所有列指定数据类型（在此示例中为`varchar`的`state`列），并且可以选择使用表定义的其他元素，如设置主键。我喜欢用“temp_”或“tmp_”作为临时表名称的前缀，以提醒自己我在主查询中使用了临时表，但这并非必须。
- en: 'The faster and easier way to generate a temp table is the *CREATE as SELECT*
    method:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 生成临时表的更快更简单的方法是*CREATE as SELECT*方法：
- en: '[PRE13]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In this case, the database automatically decides the data type based on the
    data returned by the *SELECT* statement, and no primary key is set. Unless you
    need fine-grained control for performance reasons, this second method will serve
    you well.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，数据库根据*SELECT*语句返回的数据自动决定数据类型，并且未设置主键。除非出于性能原因需要精细控制，否则第二种方法将为您提供良好的服务。
- en: Since temp tables are written to disk, if you need to repopulate them during
    a session, you will have to *DROP* and re-create the table or *TRUNCATE* the data.
    Disconnecting and reconnecting to the database also works.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 由于临时表被写入磁盘，如果需要在会话期间重新填充它们，则必须*DROP*并重新创建表，或*TRUNCATE*数据。断开并重新连接到数据库也可以起作用。
- en: Common Table Expressions
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 公共表达式（CTEs）
- en: CTEs are a relative newcomer to the SQL language, having been introduced into
    many of the major databases only during the early 2000s. I wrote SQL for years
    without them, making do with subqueries and temp tables. I have to say that since
    I became aware of them a few years ago, they have steadily grown on me.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: CTE（公共表达式）是SQL语言的一个相对新功能，在2000年代初引入了许多主要数据库。我多年来一直在使用SQL，没有使用它们，而是使用子查询和临时表。不得不说自从几年前意识到它们以来，它们已经在我心中稳步增长。
- en: You can think of a *common table expression* as being like a subquery lifted
    out and placed at the beginning of the query execution. It creates a temporary
    result set that can then be used anywhere in the subsequent query. A query can
    have multiple CTEs, and CTEs can use results from previous CTEs to perform additional
    calculations.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以将*公共表达式*视为从子查询中提取出来并放置在查询执行开始处。它创建一个临时结果集，随后可在后续查询中的任何位置使用。一个查询可以有多个CTEs，并且CTEs可以使用前面CTEs的结果进行额外计算。
- en: CTEs are particularly useful when the result will be used multiple times in
    the rest of the query. The alternative, defining the same subquery multiple times,
    is both slow (since the database needs to execute the same query several times)
    and error-prone. Forgetting to update the logic in each identical subquery introduces
    error into the final result. Since CTEs are part of a single query, they don’t
    require any special database permissions. They can also be a useful way to organize
    code into discrete chunks and avoid sprawling nested subqueries.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 当查询的结果在后续查询中多次使用时，CTEs特别有用。相比之下，多次定义相同的子查询既慢（因为数据库需要多次执行相同的查询），又容易出错。忘记更新每个相同子查询中的逻辑会导致最终结果错误。由于CTEs是单个查询的一部分，它们不需要任何特殊的数据库权限。它们还可以是将代码组织成离散块并避免杂乱嵌套子查询的有用方式。
- en: The main drawback of CTEs arises from the fact that they are defined at the
    beginning, separate from where they are used. This can make a query more difficult
    to decipher for others when the query is very long, as it’s necessary to scroll
    to the beginning to check the definition and then back to where the CTE is used
    to understand what is happening. Good use of comments can help with this. A second
    challenge is that CTEs make execution of sections of long queries more difficult.
    To check intermediate results in a longer query, it’s fairly easy to select and
    run just a subquery in a query development tool. If a CTE is involved, however,
    all of the surrounding code must be commented out first.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: CTE的主要缺点是它们在开头定义，与它们的使用位置分离。当查询非常长时，这可能会使其它人解读查询更加困难，因为需要滚动到开头检查定义，然后再返回到使用CTE的位置理解发生了什么。良好的注释使用可以帮助解决这个问题。第二个挑战是，CTEs使得在长查询中执行部分更加困难。在较长的查询中检查中间结果时，很容易在查询开发工具中选择并运行一个子查询。然而，如果涉及到CTE，必须首先注释掉周围的所有代码。
- en: 'To create a CTE, we use the *WITH* keyword at the beginning of the overall
    query, followed by a name for the CTE and then the query that makes it up enclosed
    in parentheses. For example, we could create a CTE that calculates the first term
    for each legislator and then use this result in further calculation, such as the
    cohort calculation introduced in [Chapter 4](ch04.xhtml#cohort_analysis):'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建CTE，我们在整个查询的开头使用*WITH*关键字，然后是CTE的名称，然后是用括号括起来的组成它的查询。例如，我们可以创建一个CTE，计算每位立法者的第一个术语，然后在进一步的计算中使用此结果，例如在[第四章](ch04.xhtml#cohort_analysis)介绍的队列分析中使用：
- en: '[PRE14]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The query result is exactly the same as that returned by the alternate query
    using subqueries seen in [Chapter 4](ch04.xhtml#cohort_analysis). Multiple CTEs
    can be used in the same query, separated by commas:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 查询结果与在[第四章](ch04.xhtml#cohort_analysis)中看到的使用子查询的替代查询返回的结果完全相同。可以在同一查询中使用多个CTE，用逗号分隔：
- en: '[PRE15]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: CTEs are a useful way to control the order of evaluation, improve performance
    in some instances, and organize your SQL code. They are easy to use once you are
    familiar with the syntax, and they are available in most major databases. There
    are often multiple ways to accomplish something in SQL, and although not required,
    CTEs add useful flexibility to your SQL skills toolbox.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 公共表达式（CTEs）是一种有用的控制评估顺序、在某些情况下提高性能并组织 SQL 代码的方式。一旦熟悉语法，它们易于使用，并且在大多数主要数据库中都可用。在
    SQL 中通常有多种实现方式，虽然不是必需的，但 CTEs 可以为您的 SQL 技能工具箱增添有用的灵活性。
- en: grouping sets
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分组集
- en: Although this next topic isn’t strictly about controlling the order of evaluation,
    it is a handy way to avoid *UNION*s and get the database to do all the work in
    a single query statement. Within the *GROUP BY* clause, special syntax is available
    in many major databases that includes `grouping sets`, `cube`, and `rollup` (though
    Redshift is an exception, and MySQL only has `rollup`). They are useful when the
    data set needs to contain subtotals for various combinations of attributes.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个下一个主题并不严格控制评估顺序，但它是避免*UNION*并让数据库在一个单独的查询语句中完成所有工作的一种便捷方法。在*GROUP BY*子句内，许多主要数据库都提供了特殊的语法，包括`grouping
    sets`、`cube`和`rollup`（尽管Redshift是一个例外，MySQL只有`rollup`）。当数据集需要包含各种属性组合的小计时，它们非常有用。
- en: For examples in this section, we’ll use a data set of video game sales that
    is [available on Kaggle](https://oreil.ly/qIxRX). It contains attributes for the
    name of each game as well as the platform, year, genre, and game publisher. Sales
    figures are provided for North America, the EU, Japan, Other (the rest of the
    world), and the global total. The table name is `videogame_sales`. [Figure 8-3](#sample_of_the_videogame_sales_table)
    shows a sample of the table.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 本节示例将使用一个视频游戏销售数据集，可以在[Kaggle上获得](https://oreil.ly/qIxRX)。它包含每款游戏的名称、平台、年份、流派和游戏发行商的属性。销售数据提供了北美、欧盟、日本、其他（世界其他地区）和全球总额。表名为`videogame_sales`。[图8-3](#sample_of_the_videogame_sales_table)展示了表格的示例。
- en: '![](Images/sfda_0803.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/sfda_0803.png)'
- en: Figure 8-3\. Sample of the `videogame_sales` table
  id: totrans-128
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-3\. `videogame_sales`表的示例
- en: 'So in the video game data set, for example, we might want to aggregate `global_sales`
    by platform, genre, and publisher as standalone aggregations (rather than only
    the combinations of the three fields that exist in the data) but output the results
    in one query set. This can be accomplished by *UNION*ing together three queries.
    Note that each query must contain at least placeholders for all three of the grouping
    fields:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在视频游戏数据集中，例如，我们可能希望按独立的平台、流派和发行商聚合`global_sales`（而不仅仅是数据中存在的三个字段的组合），但将结果输出为一个查询集。这可以通过*UNION*三个查询来实现。请注意，每个查询必须至少包含所有三个分组字段的占位符：
- en: '[PRE16]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This can be achieved in a more compact query using `grouping sets`. Within
    the *GROUP BY* clause, `grouping sets` is followed by the list of groupings to
    calculate. The previous query can be replaced by:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过使用`grouping sets`在更紧凑的查询中实现这一点。在*GROUP BY*子句内，`grouping sets`之后是要计算的分组列表。前述查询可以替换为：
- en: '[PRE17]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The items inside the `grouping sets` parentheses can include blanks as well
    as comma-separated lists of columns. As an example, we can calculate the global
    sales without any grouping, in addition to the groupings by `platform`, `genre`,
    and `publisher`, by including a list item that is just a pair of parentheses.
    We’ll also clean up the output by substituting “All” for the null items using
    `coalesce`:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '`grouping sets`括号内的项可以包括空白以及逗号分隔的列列表。例如，我们可以计算全球销售而不进行任何分组，此外还包括按`platform`、`genre`和`publisher`进行的分组，通过包含一个仅由一对括号组成的列表项，我们还可以通过`coalesce`替换“All”以清理输出：'
- en: '[PRE18]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'If we want to calculate all possible combinations of platform, genre, and publisher,
    such as the individual subtotals just calculated, plus all combinations of platform
    and genre, platform and publisher, and genre and publisher, we could specify all
    of these combinations in the `grouping sets`. Or we can use the handy `cube` syntax,
    which handles all of this for us:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想计算平台、流派和发行商的所有可能组合，例如刚刚计算的各个子总计，以及平台和流派、平台和发行商以及流派和发行商的所有组合，我们可以在`grouping
    sets`中指定所有这些组合。或者我们可以使用方便的`cube`语法，它可以为我们处理所有这些：
- en: '[PRE19]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'A third option is the function `rollup`, which returns a data set that has
    combinations determined by the ordering of fields in the parentheses, rather than
    all possible combinations. So the previous query with the following clause:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个选项是函数`rollup`，它返回的数据集由括号中字段的顺序决定其组合，而不是所有可能的组合。因此，前述查询加上以下子句：
- en: '[PRE20]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'returns aggregations for the combinations of:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 返回以下组合的聚合结果：
- en: '[PRE21]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'But the query does *not* return aggregations for the combinations of:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 但是该查询*不*返回以下组合的聚合结果：
- en: '[PRE22]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Although it is possible to create the same output using *UNION*, the `grouping
    sets`, `cube`, and `rollup` options are big space and time savers when aggregations
    at multiple levels are needed, because they result in fewer lines of code and
    fewer scans of the underlying database tables. I once created a query hundreds
    of lines long using *UNION*s to generate output for a dynamic website graphic
    that needed to have all possible combinations of filters precalculated. Quality
    checking it was an enormous chore, and updating it was even worse. Leveraging
    `grouping sets`, and CTEs for that matter, could have gone a long way toward making
    the code more compact and easy to write and maintain.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然可以使用*UNION*来生成相同的输出，但`grouping sets`、`cube`和`rollup`选项在需要多级聚合时是空间和时间的重要节省者，因为它们可以减少代码行数和底层数据库表的扫描次数。曾经我创建过一个数百行长的查询，使用*UNION*生成动态网站图形的输出，需要预先计算所有可能的过滤器组合。质量检查是一项巨大的工作，更新则更加糟糕。利用`grouping
    sets`以及CTE，可能会大大减少代码量，使得编写和维护更加简洁。
- en: Managing Data Set Size and Privacy Concerns
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理数据集大小和隐私问题
- en: 'After taking care to properly work out the logic in our SQL, organize our code,
    and make it efficient, we’re often faced with another challenge: the size of the
    result set. Data storage is ever cheaper, meaning that organizations are storing
    ever-larger data sets. Computational power is also always increasing, allowing
    us to crunch this data in the sophisticated ways we’ve seen in previous chapters.
    However, bottlenecks still occur, either in downstream systems such as BI tools
    or in the bandwidth available to pass large data sets between systems. Additionally,
    data privacy is a major concern that impacts how we handle sensitive data. For
    these reasons, in this section I’ll discuss some ways to limit the size of data
    sets, as well as considerations for data privacy.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理好SQL逻辑、组织代码并提高效率之后，我们通常面临另一个挑战：结果集的大小。数据存储变得越来越便宜，这意味着组织存储了越来越大的数据集。计算能力也在不断增强，使得我们可以以前几章看到的复杂方式处理这些数据。然而，仍然会出现瓶颈，可能是在下游系统如BI工具中，也可能是在传递大数据集之间可用带宽方面。此外，数据隐私是一个重要的关注点，影响我们如何处理敏感数据。因此，在本节中我将讨论一些限制数据集大小的方法，以及数据隐私的考虑事项。
- en: Sampling with %, mod
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用%、mod进行抽样
- en: One way to reduce the size of a result set is to use a sample of the source
    data. *Sampling* means taking only a subset of the data points or observations.
    This is appropriate when the data set is large enough and a subset is representative
    of the entire population. You can often sample website traffic and still retain
    most of the useful insights, for example. There are two choices to make when sampling.
    The first is the size of the sample that achieves the right balance between reducing
    the size of the data set and not losing too much critical detail. The sample might
    include 10%, 1%, or 0.1% of the data points, depending on the starting volume.
    The second choice is the entity on which to perform the sampling. We might sample
    1% of website *visits*, but if the goal of the analysis is to understand how users
    navigate the website, sampling 1% of website *visitors* would be a better choice
    in order to preserve all the data points for the users in the sample.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 减少结果集大小的一种方法是使用源数据的样本。*抽样*意味着仅使用数据点或观测的子集。当数据集足够大且子集代表整体人群时，这是合适的。例如，通常可以对网站流量进行抽样，并仍保留大部分有用的见解。在进行抽样时有两个选择。第一个选择是样本的大小，要在减少数据集大小和不丢失太多关键细节之间找到合适的平衡。样本可能包括数据点的10%、1%或0.1%，这取决于初始体积。第二个选择是执行抽样的实体。我们可以对网站*访问*进行1%的抽样，但如果分析的目标是了解用户如何浏览网站，则对网站*访客*进行1%的抽样会更好，以保留所有用户的数据点样本。
- en: 'The most common way to sample is to filter query results in the *WHERE* clause
    by applying a function to an entity-level identifier. Many ID fields are stored
    as integers. If this is the case, taking a modulo is a quick way to achieve the
    right result. The modulo is the whole number remainder when one number is divided
    by another. For example, 10 divided by 3 is equal to 3 with a remainder (modulo)
    of 1\. SQL has two equivalent ways to find the modulo—with the % sign and with
    the `mod` function:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的抽样方式是在*WHERE*子句中通过对实体级标识符应用函数来过滤查询结果。许多ID字段存储为整数。如果是这种情况，取模是实现正确结果的快速方式。取模是一个数除以另一个数时的整数余数。例如，10除以3等于3，余数（取模）为1。SQL有两种等效的方法来找到取模——用%符号和`mod`函数：
- en: '[PRE23]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Both return the same answer, 56, which is also the last two digits of the input
    value `123456`. To generate a 1% sample of the data set, place either syntax in
    the *WHERE* clause and set it equal to an integer—in this case, 7:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 两者返回相同的答案，即56，这也是输入值`123456`的最后两位数字。要生成数据集的1%样本，在*WHERE*子句中放置任一语法，并将其设置为一个整数——在本例中为7：
- en: '[PRE24]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: A mod of 100 creates a 1% sample, while a mod of 1,000 would create a 0.1% sample,
    and a mod of 10 would create a 10% sample. Although sampling in multiples of 10
    is common, it’s not required, and any integer will work.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 取模100生成1%样本，取模1,000生成0.1%样本，取模10生成10%样本。虽然按10的倍数抽样很常见，但不是必需的，任何整数都可以使用。
- en: 'Sampling from alphanumeric identifiers that include both letters and numbers
    isn’t as straightforward as sampling purely numeric identifiers. String-parsing
    functions can be used to isolate just the first or last few characters, and filters
    can be applied to them. For example, we can sample only identifiers ending in
    the letter “b” by parsing the last character from a string using the `right` function:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 从包含字母和数字的字母数字标识符中进行抽样并不像从纯数字标识符进行抽样那样直接。可以使用字符串解析函数来仅隔离前几个或最后几个字符，并对它们应用过滤器。例如，我们可以使用`right`函数从字符串中解析出最后一个字符，然后仅对以字母“b”结尾的标识符进行抽样：
- en: '[PRE25]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Assuming that any upper- or lowercase letter or number is a possible value,
    this will result in a sample of approximately 1.6% (1/62). To return a larger
    sample, adjust the filter to allow multiple values:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 假设任何大写或小写字母或数字都是可能的值，这将导致约1.6%（1/62）的样本。要返回更大的样本，请调整过滤器以允许多个值：
- en: '[PRE26]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'To create a smaller sample, include multiple characters:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建较小的样本，请包括多个字符：
- en: '[PRE27]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Tip
  id: totrans-159
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: When sampling, it’s worth validating that the function you use to generate a
    sample does create a random or close-to-random sampling of the data. In one of
    my previous roles, we discovered that certain types of users were more likely
    to have certain combinations of the last two digits in their user IDs. In this
    case, using the `mod` function to generate a 1% sample resulted in noticeable
    bias in the results. Alphanumeric identifiers in particular often have common
    patterns at the beginning or end of the string that data profiling can help identify.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 当进行抽样时，值得验证所使用的生成样本的函数是否确实创建了数据的随机或接近随机的抽样。在我之前的某个角色中，我们发现某些类型的用户更有可能在其用户ID的最后两位数字中具有特定的组合。在这种情况下，使用`mod`函数生成1%样本导致结果中明显的偏差。特别是字母数字标识符通常在字符串的开头或结尾有共同的模式，数据分析可以帮助识别这些模式。
- en: Sampling is an easy way to reduce data set size by orders of magnitude. It can
    both speed up calculations within SQL statements and allow the final result to
    be more compact, making it faster and easier to transfer to another tool or system.
    Sometimes the loss of detail from sampling isn’t acceptable, however, and other
    techniques are needed.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 抽样是通过数量级减少数据集大小的简单方法。它既可以加快SQL语句中的计算速度，又可以使最终结果更加紧凑，从而更快速、更容易地转移到另一个工具或系统中。然而，有时从抽样中丢失细节是不可接受的，因此需要其他技术。
- en: Reducing Dimensionality
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 减少维度
- en: The number of distinct combinations of attributes, or *dimensionality*, greatly
    impacts the number of records in a data set. To understand this, we can do a simple
    thought experiment. Imagine we have a field with 10 distinct values, and we `count`
    the number of records and *GROUP BY* that field. The query will return 10 results.
    Now add in a second field, also with 10 distinct values, `count` the number of
    records, and *GROUP BY* the two fields. The query will return 100 results. Add
    in a third field with 10 distinct values, and the query result grows to 1,000
    results. Even if not all the combinations of the three fields actually exist in
    the table queried, it’s clear that adding additional fields into a query can increase
    the size of the results dramatically.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 属性组合的不同组合数量，或者*维度*，极大地影响数据集中的记录数量。为了理解这一点，我们可以进行一个简单的思维实验。假设我们有一个包含10个不同值的字段，并且我们使用`count`函数统计记录数，并*按照*该字段进行*分组*。查询将返回10个结果。现在加入第二个字段，也有10个不同的值，统计记录数，并*按照*这两个字段*分组*。查询将返回100个结果。再加入第三个字段，每个字段有10个不同的值，查询结果将增长到1,000个结果。即使在查询的表中并非所有这三个字段的组合实际存在，很明显，向查询中添加额外的字段可以显著增加结果的大小。
- en: When performing analysis, we can often control the number of fields and filter
    the values included in order to end up with a manageable output. However, when
    preparing data sets for further analysis in other tools, the goal is often to
    provide flexibility and therefore to include many different attributes and calculations.
    To retain as much detail as possible while managing the overall size of the data,
    we can use one or more grouping techniques.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行分析时，我们通常可以控制字段的数量，并过滤包含的值，以便得到可管理的输出。然而，在准备数据集以在其他工具中进行进一步分析时，目标通常是提供灵活性，因此包含许多不同的属性和计算。为了尽可能保留详细信息同时管理数据的总体大小，我们可以使用一个或多个分组技术。
- en: Granularity of dates and times is often an obvious place to look to reduce the
    size of data. Talk to your stakeholders to determine whether daily data is needed,
    for example, or whether weekly or monthly aggregations would work just as well.
    Grouping data by month and day of week might be a solution to aggregating data
    while still providing visibility into patterns that differ on weekdays versus
    weekends. Restricting the length of time returned is always an option, but that
    can restrict exploration of longer-term trends. I have seen data teams provide
    one data set that aggregates to a monthly level and covers several years, while
    a companion data set includes the same attributes but with daily or even hourly
    data for a much shorter time window.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 日期和时间的细化程度通常是减少数据大小的明显方法之一。与利益相关者沟通，确定是否需要每日数据，例如，或者每周或每月汇总是否同样有效。按月份和星期几分组数据可能是在提供不同工作日与周末模式可见性的同时进行数据聚合的解决方案。限制返回时间长度始终是一种选择，但这可能会限制对长期趋势的探索。我曾看到数据团队提供一个将数据聚合到月度级别并覆盖多年的数据集，同时另一个数据集包含相同属性，但数据粒度为每日甚至每小时，时间窗口更短。
- en: Text fields are another place to check for possible space savings. Differences
    in spelling or capitalization can result in many more distinct values than are
    useful. Applying text functions discussed in [Chapter 5](ch05.xhtml#text_analysis),
    such as `lower`, `trim`, or `initcap`, standardizes values and usually makes data
    more useful for stakeholders as well. REPLACE or CASE statements can be used to
    make more nuanced adjustments, such as adjusting spelling or changing a name that
    has been updated to a new value.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 文本字段是另一个可能节省空间的检查位置。拼写或大小写的差异可能导致比实际有用的更多的不同值。应用在[第5章](ch05.xhtml#text_analysis)讨论过的文本函数，比如`lower`、`trim`或`initcap`，可以标准化值，通常使数据对利益相关者更有用。REPLACE或CASE语句可用于进行更微妙的调整，比如调整拼写或将更新为新值的名称更改。
- en: 'Sometimes only a few values out of a longer list are relevant for analysis,
    so retaining detail for those while grouping the rest together is effective. I
    have seen this frequently when working with geographic locations. There are close
    to two hundred countries in the world, but often only a handful have enough customers
    or other data points to make reporting on them individually worthwhile. The `legislators`
    data set used in [Chapter 4](ch04.xhtml#cohort_analysis) contains 59 values for
    state, which includes the 50 states plus US territories that have representatives.
    We might want to create a data set with detail for the five states with the largest
    populations (currently California, Texas, Florida, New York, and Pennsylvania),
    and then group the rest into an “other” category with a CASE statement:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，仅对较长列表中的少数值感兴趣进行分析，因此对于这些值保留详细信息，而将其余的值分组是有效的。在处理地理位置时，我经常看到这种情况。世界上有接近两百个国家，但通常只有少数几个国家有足够的客户或其他数据点，使得对它们进行单独报告具有价值。在[第四章](ch04.xhtml#cohort_analysis)中使用的`legislators`数据集包含59个州的值，其中包括50个州以及有代表的美国领土。我们可能希望创建一个数据集，其中详细列出人口最多的五个州（目前是加利福尼亚州、德克萨斯州、佛罗里达州、纽约州和宾夕法尼亚州），然后使用CASE语句将其余的州分组为“其他”：
- en: '[PRE28]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The query returns only 6 rows, down from 59, which represents a significant
    decrease. To make the list more dynamic, we can first rank the values in a subquery,
    in this case by the distinct `id_bioguide` (legislator ID) values, and then return
    the `state` value for the top 5 and “Other” for the rest:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 查询结果仅返回了6行，从59行减少到6行，这代表了显著的减少。为了使列表更加动态，我们可以首先在子查询中对值进行排名，例如按照不同的`id_bioguide`（议员ID）值进行排序，然后返回前5个值的`state`值和“其他”：
- en: '[PRE29]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Several of the states change in this second list. If we continue to update the
    data set with fresh data points, the dynamic query will ensure that the output
    always reflects the current top values.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二个列表中，有几个州发生了变化。如果我们继续使用新数据点更新数据集，动态查询将确保输出始终反映当前的顶级值。
- en: Dimensionality can also be reduced by transforming the data into flag values.
    Flags are usually binary (i.e., they have only two values). BOOLEAN TRUE and FALSE
    can be used to encode flags, as can 1 and 0, “Yes” and “No,” or any other pair
    of meaningful strings. Flags are useful when a threshold value is important, but
    detail beyond that is less interesting. For example, we might want to know whether
    or not a website visitor completed a purchase, but detail on the exact number
    of purchases is less important.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将数据转换为标志值，也可以减少维度。标志通常是二进制的（即只有两个值）。布尔值TRUE和FALSE可以用来编码标志，也可以使用1和0，“是”和“否”，或任何其他有意义的一对字符串。当阈值重要时，但超过此阈值的详细信息较不重要时，标志非常有用。例如，我们可能想知道网站访客是否完成了购买，但购买的确切数量则较不重要。
- en: 'In the `legislators` data set, there are 28 distinct numbers of terms served
    by the legislators. Instead of the exact value, however, we might want to include
    in our output only whether a legislator has served at least two terms, which we
    can do by turning the detailed values into a flag:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在`legislators`数据集中，议员任职的期数有28个不同的数字。然而，我们可能只想在输出中包含是否至少任职两届的信息，我们可以通过将详细值转换为标志来实现：
- en: '[PRE30]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: About twice as many legislators have served at least two terms as compared to
    those with only one term. When combined with other fields in a data set, this
    type of transformation can result in much smaller result sets.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 至少有两届任职的议员比只任职一届的议员多大约一倍。与数据集中的其他字段结合使用时，这种转换可以导致更小的结果集。
- en: Sometimes a simple true/false or presence/absence indicator is not quite enough
    to capture the needed nuance. In this case, numeric data can be transformed into
    several levels to maintain some additional detail. This is accomplished with a
    CASE statement, and the return value can be a number or string.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 有时简单的真/假或存在/缺失指示器并不能完全捕捉所需的细微差别。在这种情况下，可以将数值数据转换为几个级别，以保留一些额外的细节。这可以通过CASE语句完成，返回值可以是数字或字符串。
- en: 'We might want to include not only whether a legislator served a second term
    but also another indicator for those who served 10 or more terms:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能不仅想知道议员是否任职第二届，还想为那些任职10届或更多届的人提供另一个指标：
- en: '[PRE31]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Here we have reduced 28 distinct values down to 3, while retaining the notion
    of single-term legislators, those who were reelected, and the ones who are exceptionally
    good at staying in office. Such groupings or distinctions occur in many domains.
    As with all the transformations discussed here, it may take some trial and error
    to find the exact thresholds that are most meaningful for stakeholders. Finding
    the right balance of detail and aggregation can greatly decrease data set size
    and therefore often speeds delivery time and performance of the downstream application.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将28个不同的值减少到了3个，同时保留了单术语立法者、连任者和在任期间表现出色的概念。这样的分组或区分在许多领域中都存在。与这里讨论的所有转换一样，可能需要一些试验和错误来找到最有意义的阈值，以满足利益相关者的需求。找到详细信息和聚合之间的正确平衡可以大大减少数据集的大小，从而通常加快下游应用程序的交付时间和性能。
- en: PII and Data Privacy
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PII和数据隐私
- en: Data privacy is one of the most important issues facing data professionals today.
    Large data sets with many attributes allow for more robust analysis with detailed
    insights and recommendations. However, when the data set is about individuals,
    we need to be mindful of both the ethical and the regulatory dimensions of the
    data collected and used. Regulations around the privacy of patients, students,
    and financial services customers have existed for many years. Laws regulating
    the data privacy rights of consumers have also come into force in recent years.
    The General Data Protection Regulation (GDPR) passed by the EU is probably the
    most widely known. Other regulations include the California Consumer Privacy Act
    (CCPA), the Australian Privacy Principles, and Brazil’s General Data Protection
    Law (LGPD).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 数据隐私是当今数据专业人士面临的最重要问题之一。具有多个属性的大数据集可以进行更强大的分析，提供详细的洞见和建议。然而，当数据集涉及个人时，我们需要注意数据收集和使用的道德和法规维度。围绕病人、学生和金融服务客户的隐私的法规已经存在多年。近年来，关于消费者数据隐私权的法律也相继出台。欧盟通过的《通用数据保护条例》（GDPR）可能是最为人知晓的一部分。其他法规包括加州消费者隐私法案（CCPA）、澳大利亚隐私原则以及巴西的《通用数据保护法》（LGPD）。
- en: 'These and other regulations cover the handling, storage, and (in some cases)
    deletion of *personally identifiable information (PII)*. Some categories of PII
    are obvious: name, address, email, date of birth, and Social Security number.
    PII also includes health indicators such as heart rate, blood pressure, and medical
    diagnoses. Location information, such as GPS coordinates, is also considered PII,
    since a small number of GPS locations can uniquely identify an individual. For
    example, GPS readings at my house and at my children’s school could uniquely identify
    someone in my household. A third GPS point at my office could uniquely identify
    me. As a data practitioner, it’s worthwhile to become familiar with what these
    regulations cover and to discuss how they affect your work with the privacy lawyers
    at your organization, who will have the most up-to-date information.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 这些及其他法规涵盖了对个人身份信息（PII）的处理、存储以及（在某些情况下）删除。一些PII的类别是显而易见的：姓名、地址、电子邮件、出生日期和社会安全号码。PII还包括健康指标，如心率、血压和医疗诊断。位置信息，如GPS坐标，也被视为PII，因为少数GPS位置可以唯一标识一个人。例如，我家和我孩子学校的GPS读数可以唯一标识我的家庭中的某个人。办公室的第三个GPS点可以唯一标识我。作为数据从业者，熟悉这些法规涵盖的内容，并与组织中的隐私法律专家讨论它们对你工作的影响是值得的，他们将具有最新的信息。
- en: A best practice when analyzing data that includes PII is to avoid including
    the PII itself in the outputs. This can be accomplished by aggregating data, substituting
    values, or hashing values.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析中处理包含个人身份信息（PII）的最佳实践是避免在输出中包含PII本身。可以通过聚合数据、替换值或对值进行哈希处理来实现这一点。
- en: For most analyses, the goal is to find trends and patterns. Counting customers
    and averaging their behavior, rather than including individual detail in the output,
    is often the purpose. Aggregations generally remove PII; however, be aware that
    a combination of attributes that have a user count of 1 could potentially be tied
    back to an individual. These can be treated as outliers and removed from the result
    in order to maintain a higher degree of privacy.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数分析的目标是发现趋势和模式。通常情况下，计算客户数量和平均行为，而不是在输出中包含个人详细信息。聚合通常会删除PII；然而，需要注意的是，一组具有用户计数为1的属性可能会被追溯到个人。可以将这些视为异常值，并从结果中删除，以保持更高的隐私度。
- en: 'If individual data is needed for some reason—to be able to calculate distinct
    users in a downstream tool, for instance—we can replace problematic values with
    random alternate values that maintain uniqueness. The `row_number` window function
    can be used to assign a new value to each individual in a table:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 如果出于某种原因需要个体数据——例如能够在下游工具中计算不同用户数量——我们可以用随机替代值替换有问题的值，以保持唯一性。`row_number` 窗口函数可用于为表中的每个个体分配新值：
- en: '[PRE33]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The challenge in this case is to find a field to put in the *ORDER BY* that
    makes the ordering sufficiently random such that we can consider the resulting
    user identifier anonymized.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下的挑战是找到一个足以使排序足够随机的字段，以便我们可以考虑生成的用户标识符为匿名化。
- en: 'Hashing values is another option. Hashing takes an input value and uses an
    algorithm to create a new output value. A particular input value will always result
    in the same output, making this a good option for maintaining uniqueness while
    obscuring sensitive values. The `md5` function can be used to generate a hashed
    value:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是对值进行哈希处理。哈希处理采用输入值并使用算法创建新的输出值。特定输入值始终会产生相同的输出，这使得它成为在保持唯一性的同时模糊敏感值的良好选择。`md5`
    函数可用于生成哈希值：
- en: '[PRE34]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Warning
  id: totrans-191
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: The `md5` function hashes input values but does not encrypt them, and therefore
    it can be reversed to obtain the original value. For highly sensitive data, you
    should work with a database administrator to truly encrypt the data.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '`md5` 函数对输入值进行哈希处理，但不对其进行加密，因此可以通过逆向操作获取原始值。对于高度敏感的数据，应与数据库管理员合作，确实加密数据。'
- en: Avoiding PII in the output of your SQL queries is always the best option if
    possible, since you avoid proliferating it into other systems or files. Replacing
    or masking the values is a second-best option. You can also explore secure methods
    to share data, such as developing a secured data pipeline directly between a database
    and an email system to avoid writing email addresses out to files, for example.
    With care and partnership with technical and legal colleagues, it is possible
    to achieve high-quality analysis while also preserving individuals’ privacy.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 如果可能的话，避免在SQL查询的输出中包含PII始终是最佳选择，因为这样可以避免将其扩散到其他系统或文件中。替换或掩盖这些值是次佳选择。您还可以探索安全的数据共享方法，例如直接在数据库和电子邮件系统之间开发安全的数据管道，以避免将电子邮件地址写入文件中。通过与技术和法律同事的慎重合作，可以在保护个人隐私的同时实现高质量的分析。
- en: Conclusion
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Surrounding every analysis, there are a number of decisions to be made around
    organizing the code, managing complexity, optimizing query performance, and safeguarding
    privacy in the output. In this chapter, we’ve discussed a number of options and
    strategies and special SQL syntax that can help with these tasks. Try not to get
    overwhelmed by all of these options or to become concerned that, without mastery
    of these topics, you can’t be an efficient data analyst or data scientist. Not
    all of the techniques are required in every analysis, and there are often other
    ways to get the job done. The longer you spend analyzing data with SQL, the more
    likely you are to come across situations in which one or more of these techniques
    come in handy.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在每次分析周围，都需要做出许多关于组织代码、管理复杂性、优化查询性能和在输出中保护隐私的决策。在本章中，我们讨论了许多选项、策略和可以帮助完成这些任务的特殊SQL语法。尽量不要被所有这些选项所淹没，也不要因为没有掌握这些主题就认为自己不能成为高效的数据分析师或数据科学家。并非所有技术在每次分析中都是必需的，通常也有其他方法可以完成工作。您在使用SQL分析数据的时间越长，越有可能遇到适用一个或多个这些技术的情况。
- en: ^([1](ch08.xhtml#ch01fn10-marker)) Though in the case of Tableau, you can get
    around this with the Initial SQL option.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch08.xhtml#ch01fn10-marker)) 尽管在Tableau的情况下，可以通过初始SQL选项绕过此问题。
