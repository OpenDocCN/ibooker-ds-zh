- en: Chapter 14\. Data Exchange
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第14章 数据交换
- en: Data can be stored and exchanged in many different formats. Thus far, we’ve
    focused on plain-text delimited and fixed-width formats ([Chapter 8](ch08.html#ch-files)).
    In this chapter, we expand our horizons a bit and introduce a few other popular
    formats. While CSV, TSV, and FWF files are useful for organizing data into a dataframe,
    other file formats can save space or represent more complex data structures. *Binary*
    files (*binary* is a term for formats that aren’t plaintext) can be more economical
    than plain-text data sources. For example, in this chapter we introduce NetCDF,
    a popular binary format for exchanging large amounts of scientific data. Other
    plain-text formats like JSON and XML can organize data in ways that are more general
    and useful for complex data structures. Even HTML web pages, a close cousin to
    XML, often contain useful information that we can scrape and wrangle into shape
    for analysis.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可以以许多不同的格式存储和交换。到目前为止，我们专注于纯文本分隔和固定宽度格式（[第8章](ch08.html#ch-files)）。在本章中，我们稍微扩展了视野，并介绍了几种其他流行的格式。虽然CSV、TSV和FWF文件有助于将数据组织成数据框架，但其他文件格式可以节省空间或表示更复杂的数据结构。*二进制*文件（*binary*是指不是纯文本格式的格式）可能比纯文本数据源更经济。例如，在本章中，我们介绍了NetCDF，这是一种用于交换大量科学数据的流行二进制格式。其他像JSON和XML这样的纯文本格式可以以更通用和有用于复杂数据结构的方式组织数据。甚至HTML网页，作为XML的近亲，通常包含我们可以抓取并整理以进行分析的有用信息。
- en: In this chapter, we introduce these popular formats, describe a mental model
    for their organization, and provide examples. In addition to introducing these
    formats, we cover programmatic ways to acquire data online. Before the internet,
    data scientists had to physically move disk drives to share data with one another.
    Now we can freely retrieve datasets from computers across the world. We introduce
    HTTP, the primary communication protocol for the web, and REST, an architecture
    to transfer data. By learning a bit about these web technologies, we can take
    better advantage of the web as a data source.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了这些流行格式，描述了它们组织的心智模型，并提供了示例。除了介绍这些格式外，我们还涵盖了在线获取数据的程序化方法。在互联网出现之前，数据科学家必须亲自搬移硬盘驱动器才能与他人共享数据。现在，我们可以自由地从世界各地的计算机中检索数据集。我们介绍了HTTP，这是Web的主要通信协议，以及REST，一种数据传输的架构。通过了解一些关于这些Web技术的知识，我们可以更好地利用Web作为数据来源。
- en: Throughout this book, we have set an example of reproducible code for wrangling,
    exploring, and modeling with data. In this chapter, we address how to acquire
    data that are available online in a reproducible fashion.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本书始终为数据整理、探索和建模提供了可重复的代码示例。在本章中，我们将讨论如何以可重复的方式获取在线数据。
- en: We begin with a description of NetCDF, followed by JSON. Then, after an overview
    of web protocols for data exchange, we wrap up the chapter with an introduction
    to XML, HTML, and XPath, a tool for extracting content from these types of files.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先介绍NetCDF，然后是JSON。接着，在概述用于数据交换的Web协议之后，我们通过介绍XML、HTML和XPath，一个从这些类型文件中提取内容的工具，来结束本章。
- en: NetCDF Data
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: NetCDF数据
- en: The [Network Common Data Form (NetCDF)](https://oreil.ly/_qZGj) is a convenient
    and efficient format for storing array-oriented scientific data. A mental model
    for this format represents a variable by a multidimensional grid of values. The
    diagram in [Figure 14-1](#netcdf-diagram) shows the concept. A variable such as
    rainfall is recorded daily at places around the globe. We can imagine these rainfall
    values arranged in a cube with longitude running along one side of the cube, latitude
    along another, and date in the third dimension. Each cell in the cube holds the
    rainfall recorded for one day at a particular location. A NetCDF file also contains
    information, which we call *metadata*, about the dimensions of the cube. The same
    information would be organized quite differently in a dataframe, where we would
    need three features for latitude, longitude, and date for each rainfall measurement.
    This would mean repeating lots of data. With a NetCDF file, we don’t need to repeat
    the latitude and longitude values for each day, nor the dates for each location.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[网络通用数据格式（NetCDF）](https://oreil.ly/_qZGj)是存储面向数组的科学数据的方便高效的格式。该格式的心智模型通过多维值网格表示变量。[图 14-1](#netcdf-diagram)展示了这个概念。例如，降雨量每天在全球各地记录。我们可以想象这些降雨量值排列成一个立方体，其中经度沿着立方体的一边，纬度沿着另一边，日期沿着第三个维度。立方体中的每个单元格存储了特定位置每天记录的降雨量。NetCDF
    文件还包含我们称之为*元数据*的有关立方体尺寸的信息。在数据框中，同样的信息会以完全不同的方式组织，对于每次降雨测量，我们需要经度、纬度和日期三个特征。这将意味着重复大量数据。使用
    NetCDF 文件，我们不需要为每天重复经度和纬度值，也不需要为每个位置重复日期。'
- en: '![](assets/leds_1401.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_1401.png)'
- en: Figure 14-1\. This diagram represents a model for NetCDF data. The data are
    organized into a three-dimensional array that contains recordings of rainfall
    at locations in time (latitude, longitude, and time). The “X” marks one rainfall
    measurement for a specific location on a particular date.
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14-1\. 该图表代表了 NetCDF 数据的模型。数据组织成一个三维数组，其中包含了时间和位置（纬度、经度和时间）上的降雨记录。“X”标记了特定位置在特定日期的一个降雨测量。
- en: 'NetCDF has several other advantages, in addition to being more compact:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: NetCDF 除了更紧凑之外，还有其他几个优点：
- en: Scalable
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展的
- en: It provides efficient access to subsets of the data.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 它提供了对数据子集的高效访问。
- en: Appendable
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 可附加的
- en: You can easily add new data without redefining the structure.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以轻松地添加新数据而无需重新定义结构。
- en: Sharable
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 可共享
- en: It’s a common format that’s independent of the coding language and operating
    system.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 它是一种独立于编程语言和操作系统的常见格式。
- en: Self-describing
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 自描述的
- en: The source file contains both a description of the data’s organization and the
    data itself.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 源文件包含了数据组织的描述和数据本身。
- en: Community
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 社区
- en: The tools are made available by a community of users.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工具是由用户社区提供的。
- en: Note
  id: totrans-20
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The NetCDF format is an example of *binary* data—data that can’t directly be
    read into a text editor like `vim` or Visual Studio Code, unlike text formats
    like CSV. There are a multitude of other binary data formats, including SQLite
    databases (from [Chapter 7](ch07.html#ch-sql)), Feather, and Apache Arrow. Binary
    data formats provide flexibility in how datasets are stored, but they also typically
    need special tools to open and read them in.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: NetCDF 格式是*二进制*数据的一个例子 —— 这类数据不能像 CSV 这样的文本格式一样直接在文本编辑器如 `vim` 或 Visual Studio
    Code 中读取。还有许多其他二进制数据格式，包括 SQLite 数据库（来自[第 7 章](ch07.html#ch-sql)）、Feather 和 Apache
    Arrow。二进制数据格式提供了存储数据集的灵活性，但通常需要特殊工具来打开和读取。
- en: NetCDF variables are not limited to three dimensions. For example, elevation
    could be added to our earth science application so that we have recordings of,
    say, temperature, in time, latitude, longitude, and elevation. And dimensions
    need not correspond to physical dimensions. Climate scientists often run several
    models and store the model number in a dimension along with the model output.
    While NetCDF was originally developed for atmospheric scientists at the University
    Corporation for Atmospheric Research (UCAR), the format has gained popularity
    and is now used at thousands of educational, research, and government sites around
    the world. And the applications have expanded to other areas, such as astronomy
    and physics with the [Smithsonian/NASA Astrophysics Data System (ADS)](https://oreil.ly/kg9kV)
    and medical imaging with [Medical Image NetCDF (MINC)](https://oreil.ly/6t3gJ).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: NetCDF变量不仅限于三个维度。例如，我们可以添加海拔到我们的地球科学应用程序中，以便我们在时间、纬度、经度和海拔上记录温度等数据。维度不一定要对应物理维度。气候科学家经常运行几个模型，并将模型号存储在维度中以及模型输出。虽然NetCDF最初是为大气科学家设计的，由大气研究公司(UCAR)开发，但这种格式已经广受欢迎，并且现在在全球数千个教育、研究和政府网站上使用。应用程序已扩展到其他领域，如天文学和物理学，通过[史密森尼/
    NASA天体物理数据系统(ADS)](https://oreil.ly/kg9kV)，以及医学成像通过[医学图像NetCDF(MINC)](https://oreil.ly/6t3gJ)。
- en: 'NetCDF files have three basic components: dimensions, variables, and various
    sorts of metadata. The *variable* contains what we think of as the data, such
    as the rainfall recordings. Each variable has a name, storage type, and shape,
    meaning the number of dimensions. The *dimensions* component gives each dimension’s
    name and number of grid points. Additional information is provided by the *coordinates*—in
    particular, the points at which the measurements are made, such as for longitude,
    where these might be <math><mn>0.0</mn> <mo>,</mo> <mn>0.25</mn> <mo>,</mo> <mn>0.50</mn>
    <mo>,</mo> <mo>…</mo> <mo>,</mo> <mn>359.75</mn></math> . Other metadata include
    *attributes*. Attributes for a variable can hold ancillary information about the
    variables, and other attributes contain global information about the file, such
    as who published the dataset, their contact information, and permissions for using
    the data. This global information is critical to ensure reproducible results.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: NetCDF文件有三个基本组件：维度、变量和各种元数据。*变量*包含我们认为的数据，例如降水记录。每个变量都有名称、存储类型和形状，即维度的数量。*维度*组件给出每个维度的名称和网格点的数量。*坐标*提供了其他信息，特别是测量点的位置，例如经度，在这里这些可能是<math><mn>0.0</mn>
    <mo>,</mo> <mn>0.25</mn> <mo>,</mo> <mn>0.50</mn> <mo>,</mo> <mo>…</mo> <mo>,</mo>
    <mn>359.75</mn></math>。其他元数据包括*属性*。变量的属性可以包含有关变量的辅助信息，其他属性包含关于文件的全局信息，例如发布数据集的人员、其联系信息以及使用数据的权限。这些全局信息对确保可重复结果至关重要。
- en: The following example examines the components of a particular NetCDF file and
    demonstrates how to extract portions of data from variables.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例检查了特定NetCDF文件的组件，并演示了如何从变量中提取数据的部分。
- en: The [Climate Data Store](https://oreil.ly/NAhRW) provides a collection of datasets
    from various climate sectors and services. We visited their site and requested
    measurements of temperature and total precipitation for a two-week period in December
    2022\. Let’s walk through a brief examination of these data to get a sense of
    the organization of the components in the file, how to extract subsets, and how
    to make visualizations.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[气候数据存储](https://oreil.ly/NAhRW)提供了来自各种气候部门和服务的数据集合。我们访问了他们的网站，并请求了2022年12月两周的温度和总降水量的测量数据。让我们简要检查这些数据的组织结构，如何提取子集，并进行可视化。'
- en: 'The data are in the NetCDF file *CDS_ERA5_22-12.nc*. Let’s first figure out
    how large the file is:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 数据位于NetCDF文件*CDS_ERA5_22-12.nc*中。让我们首先弄清楚文件有多大：
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Despite having only three variables (total precipitation, rain rate, temperature)
    for two weeks, the file is two GiB in size! These climate sources often tend to
    be quite large.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管只有三个变量（总降水量、降雨率、温度）的两周数据，但文件的大小达到了2 GiB！这些气候数据通常会相当庞大。
- en: 'The `xarray` package is useful for working with array-like data and, in particular,
    NetCDF. We use its functionality to explore the components of our climate file.
    First we open the file:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '`xarray`包对处理类似数组的数据非常有用，尤其是NetCDF格式的数据。我们使用它的功能来探索我们气候文件的组件。首先我们打开文件：'
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now let’s check the dimensions component of the file:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们检查文件的维度组件：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'As in [Figure 14-1](#netcdf-diagram), our file has three dimensions: longitude,
    latitude, and time. The size of each dimension tells us that there are over 400,000
    cells of data values (1440 × 721 × 408). If these data were in a dataframe, then
    it would have 400,000 rows with latitude, longitude, and time columns in great
    repetition! Instead, we only need their values once, and the coordinates component
    gives them to us:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 就像在 [图 14-1](#netcdf-diagram) 中一样，我们的文件有三个维度：经度、纬度和时间。 每个维度的大小告诉我们有超过 400,000
    个数据值单元格（1440 × 721 × 408）。 如果这些数据在数据框中，则数据框将具有 400,000 行，其中包含大量重复的纬度、经度和时间列！ 相反，我们只需要它们的值一次，坐标组件就会给我们提供它们：
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Each variable in our file is three-dimensional. Actually, a variable doesn’t
    have to have all three dimensions, but in our example they do:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们文件中的每个变量都是三维的。 实际上，一个变量不一定要有所有三个维度，但在我们的示例中确实有：
- en: '[PRE7]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Metadata for a variable provides the units and a longer description, while
    metadata for the source gives us information such as when we retrieved the data:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 变量的元数据提供单位和较长的描述，而源的元数据则为我们提供诸如检索数据的时间等信息：
- en: '[PRE9]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: By keeping all of these pieces of information in the source file itself, we
    don’t risk losing it or having the description get out of sync with the data.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将所有这些信息保存在源文件中，我们不会冒丢失信息或使描述与数据不同步的风险。
- en: 'Like with `pandas`, `xarray` provides many different ways to select portions
    of the data to work with. We show two examples. First we focus on one specific
    location and examine the total precipitation in time with a line plot:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 就像使用 `pandas` 一样，`xarray` 提供了许多不同的方法来选择要处理的数据部分。 我们展示了两个例子。 首先，我们专注于一个特定的位置，并使用线性图来查看时间内的总降水量：
- en: '[PRE13]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](assets/leds_14in01.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_14in01.png)'
- en: 'Next we choose one date, December 31, 2022, at 1 p.m., and narrow down the
    latitude and longitude to the continental US to make a map of temperature:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们选择一个日期，2022年12月31日，下午1点，并将纬度和经度缩小到美国大陆范围内，以制作温度地图：
- en: '[PRE15]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Like `loc` for dataframes, `sel` returns a new `DataArray` whose data is determined
    by the index labels along the specified dimension, which for this example is the
    date. And like `np.where`, `xr.where` returns elements depending on the logical
    condition provided. We use `drop=True` to reduce the size of the dataset.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 就像对于数据框的 `loc` 一样，`sel` 返回一个新的 `DataArray`，其数据由沿指定维度的索引标签确定，对于本例来说，即日期。 而且就像
    `np.where` 一样，`xr.where` 根据提供的逻辑条件返回元素。 我们使用 `drop=True` 来减少数据集的大小。
- en: 'Let’s make a choropleth map of temperature, where color represents the temperature:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们制作一个温度色彩地图，其中颜色代表温度：
- en: '[PRE17]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![](assets/leds_14in02.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_14in02.png)'
- en: We can make out the shape of the US, the warm Caribbean, and the colder mountain
    ranges from this map.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 从这张地图中，我们可以看出美国的形状、温暖的加勒比海和更冷的山脉。
- en: 'We wrap up by closing the file:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过关闭文件来结束：
- en: '[PRE18]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This brief introduction to NetCDF is meant to touch on the basic concepts. Our
    main goal is to show that other kinds of data formats exist and can have advantages
    over plain-text read into a dataframe. For interested readers, NetCDF has a rich
    ecosystem of packages and functionality. For example, in addition to the `xarray`
    module, NetCDF files can be read with other Python modules like [`netCDF4`](https://oreil.ly/UlX_k)
    and [`gdal`](https://oreil.ly/fKeQh). The NetCDF community has also provided command-line
    tools for interacting with NetCDF data. And to make visualizations and maps, options
    include `matplotlib`, [`iris`](https://oreil.ly/ozNrI), which is built on top
    of `netCDF4`, and [`cartopy`](https://oreil.ly/9N7y7).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这个对 NetCDF 的简要介绍旨在介绍基本概念。 我们的主要目标是展示其他类型的数据格式存在，并且可以比纯文本读入数据框更具优势。 对于感兴趣的读者，NetCDF
    拥有丰富的软件包和功能。 例如，除了 `xarray` 模块之外，NetCDF 文件还可以使用其他 Python 模块（如 [`netCDF4`](https://oreil.ly/UlX_k)
    和 [`gdal`](https://oreil.ly/fKeQh)）进行读取。 NetCDF 社区还提供了与 NetCDF 数据交互的命令行工具。 制作可视化和地图的选项包括
    `matplotlib`、[`iris`](https://oreil.ly/ozNrI)（建立在 `netCDF4` 之上）和 [`cartopy`](https://oreil.ly/9N7y7)。
- en: Next we consider the JSON format, which offers more flexibility to represent
    hierarchical data than the CSV and FWF formats.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们考虑 JSON 格式，它比 CSV 和 FWF 格式更灵活，可以表示分层数据。
- en: JSON Data
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: JSON 数据
- en: JavaScript Object Notation (JSON) is a popular format for exchanging data on
    the web. This plain-text format has a simple and flexible syntax that aligns well
    with Python dictionaries, and it is easy for machines to parse and people to read.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: JavaScript 对象表示法（JSON）是在 web 上交换数据的流行格式。 这种纯文本格式具有简单灵活的语法，与 Python 字典非常匹配，易于机器解析和人类阅读。
- en: 'Briefly, JSON has two main structures, the object and the array:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，JSON有两种主要结构，对象和数组：
- en: Object
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 对象
- en: Like a Python `dict`, a JSON object is an unordered collection of name-value
    pairs. These pairs are contained in curly braces; each is formatted as `"name":value`,
    and separated by commas.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 像Python的`dict`一样，JSON对象是一个无序的名称-值对集合。这些对包含在大括号中；每个对都格式为`"name":value`，并用逗号分隔。
- en: Array
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 数组
- en: Like a Python `list`, a JSON array is an ordered collection of values contained
    in square brackets, where the values are unnamed and separated by commas.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 像Python的`list`一样，JSON数组是一个有序的值集合，包含在方括号中，其中值没有名称，并用逗号分隔。
- en: The values in an object and array can be of different types and can be nested.
    That is, an array can contain objects and vice versa. The primitive types are
    limited to string in double quotes, number in text representation, logical as
    true or false, and null.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 对象和数组中的值可以是不同类型的，并且可以嵌套。也就是说，数组可以包含对象，反之亦然。原始类型仅限于双引号中的字符串，文本表示中的数字，true或false作为逻辑，以及null。
- en: 'The following short JSON file demonstrates all of these syntactical features:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 以下简短的JSON文件演示了所有这些语法特性：
- en: '[PRE19]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Here we have an object that contains six name-value pairs. The values are heterogeneous;
    four are primitive values: string, number, logical, and null. The `status` value
    consists of an array of three (ordered) numbers, and `lender_dem` is an object
    with demographic information.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们有一个包含六个名称-值对的对象。值是异构的；其中四个是原始值：字符串，数字，逻辑和null。`status`值由三个（有序的）数字数组组成，而`lender_dem`是包含人口统计信息的对象。
- en: 'The built-in `json` package can be used to work with JSON files in Python.
    For example, we can load this small file into a Python dictionary:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 内置的`json`包可用于在Python中处理JSON文件。例如，我们可以将这个小文件加载到Python字典中：
- en: '[PRE20]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The dictionary matches the format of the Kiva file. This format doesn’t naturally
    translate to a dataframe. The `json_normalize` method can organize this semistructured
    JSON data into a flat table:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 字典与Kiva文件的格式相匹配。这种格式并不自然地转换为数据框。`json_normalize`方法可以将这种半结构化的JSON数据组织成一个平面表：
- en: '[PRE23]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '|   | lender_id | loan_count | status | sponsored | sponsor_name | lender_dem.sex
    | lender_dem.age |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '|   | lender_id | loan_count | status | sponsored | sponsor_name | lender_dem.sex
    | lender_dem.age |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| **0** | matt | 23 | [2, 1, 3] | False | None | m | 77 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| **0** | matt | 23 | [2, 1, 3] | False | None | m | 77 |'
- en: Notice how the third element in this one-row dataframe is a list, whereas the
    nested object was converted into two columns.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在这个单行数据框中，第三个元素是一个列表，而嵌套对象被转换为两列。
- en: There’s a tremendous amount of flexibility in how data can be structured in
    JSON, which means that if we want to create a dataframe from JSON content, we
    need to understand how the data are organized in the JSON file. We provide three
    structures that translate easily into a dataframe in the next example.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: JSON中数据结构的灵活性非常大，这意味着如果我们想要从JSON内容创建数据框，我们需要了解JSON文件中数据的组织方式。我们提供了三种结构，这些结构可以轻松地转换为数据框。
- en: The list of PurpleAir sites used in the case study in [Chapter 12](ch12.html#ch-pa)
    was JSON-formatted. In that chapter, we didn’t call attention to the format and
    simply read the file contents into a dictionary with the `json` library’s `load`
    method and then into a dataframe. Here, we have simplified that file while maintaining
    the general structure so that it’s easier to examine.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第12章](ch12.html#ch-pa)中使用的PurpleAir站点列表是JSON格式的。在那一章中，我们没有注意到格式，只是使用`json`库的`load`方法将文件内容读入字典，然后转换为数据框。在这里，我们简化了该文件，同时保持了一般结构，以便更容易进行检查。
- en: We begin with an examination of the original file, and then reorganize it into
    two other JSON structures that might also be used to represent a dataframe. With
    these examples we aim to show the flexibility of JSON. The diagrams in [Figure 14-2](#json-diagram)
    give representations of the three possibilities.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先检查原始文件，然后将其重新组织成另外两种可能用于表示数据框的JSON结构。通过这些示例，我们旨在展示JSON的灵活性。 [图14-2](#json-diagram)
    中的图表显示了这三种可能性的表示。
- en: '![](assets/leds_1402.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_1402.png)'
- en: Figure 14-2\. Three different approaches for a JSON-formatted file to store
    a dataframe.
  id: totrans-88
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图14-2\. JSON格式文件存储数据框的三种不同方法。
- en: 'The leftmost dataframe in the diagram shows an organization by rows. Each row
    is an object of named values where the name corresponds to the column name of
    the dataframe. Rows would then be collected in an array. This structure coincides
    with that of the original file. In the following code, we display the file contents:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图表中最左侧的数据框按行组织。每一行都是具有命名值的对象，其中名称对应于数据框的列名。然后将行收集到数组中。这种结构与原始文件的结构相吻合。在下面的代码中，我们显示文件内容：
- en: '[PRE24]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We see that the file consists of one object with two elements, named `Header`
    and `Data`. The `Data` element is an array with an element for each row in the
    dataframe, and as described earlier each element is an object. Let’s load the
    file into a dictionary and check its contents (see [Chapter 8](ch08.html#ch-files)
    for more on finding a pathname to a file and printing its contents):'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到文件包含一个对象，有两个元素，名为`Header`和`Data`。`Data`元素是一个数组，每一行数据框中都有一个元素，正如前面描述的，每个元素都是一个对象。让我们将文件加载到字典中并检查其内容（详见[第八章](ch08.html#ch-files)有关查找文件路径和打印内容的更多信息）：
- en: '[PRE25]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We can quickly convert the array of objects into a dataframe with the following
    call:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以快速将对象数组转换为数据框，只需进行以下调用：
- en: '[PRE28]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '|   | site | date | aqi |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '|   | 网站 | 日期 | 空气质量指数 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| **0** | 0014 | 02-27 | 30.0 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| **0** | 0014 | 02-27 | 30.0 |'
- en: '| **1** | 0014 | 02-24 | 17.0 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| **1** | 0014 | 02-24 | 17.0 |'
- en: '| **2** | 0014 | 02-21 | 60.0 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| **2** | 0014 | 02-21 | 60.0 |'
- en: '| **3** | 0014 | 01-15 | NaN |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| **3** | 0014 | 01-15 | NaN |'
- en: 'The middle diagram in [Figure 14-2](#json-diagram) takes a column approach
    to organizing the data. Here the columns are provided as arrays and collected
    into an object with names that match the column names. The following file demonstrates
    the concept:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图中的中间图表在[图 14-2](#json-diagram)中采用了列的方法来组织数据。这里列被提供为数组，并收集到一个对象中，名称与数据框的列名相匹配。以下文件展示了该概念：
- en: '[PRE29]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Since `pd.read_json()` expects this format, we can read the file into a dataframe
    directly without needing to first load it into a dictionary:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`pd.read_json()`期望这种格式，我们可以直接将文件读入数据框，而不需要先加载到字典中：
- en: '[PRE31]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '|   | site | date | aqi |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '|   | 网站 | 日期 | 空气质量指数 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| **0** | 14 | 02-27 | 30.0 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| **0** | 14 | 02-27 | 30.0 |'
- en: '| **1** | 14 | 02-24 | 17.0 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| **1** | 14 | 02-24 | 17.0 |'
- en: '| **2** | 14 | 02-21 | 60.0 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| **2** | 14 | 02-21 | 60.0 |'
- en: '| **3** | 14 | 01-15 | NaN |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| **3** | 14 | 01-15 | NaN |'
- en: 'Lastly, we organize the data into a structure that resembles a matrix (the
    diagram on the right in the figure) and separately provide the column names for
    the features. The data matrix is organized as an array of arrays:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将数据组织成类似矩阵的结构（图中右侧的图表），并分别为特征提供列名。数据矩阵被组织为一个数组的数组：
- en: '[PRE32]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We can provide `vars` and `data` to create the dataframe:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以提供`vars`和`data`来创建数据框：
- en: '[PRE33]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '|   | site | date | aqi |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '|   | 网站 | 日期 | 空气质量指数 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| **0** | 0014 | 02-27 | 30.0 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| **0** | 0014 | 02-27 | 30.0 |'
- en: '| **1** | 0014 | 02-24 | 17.0 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| **1** | 0014 | 02-24 | 17.0 |'
- en: '| **2** | 0014 | 02-21 | 60.0 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| **2** | 0014 | 02-21 | 60.0 |'
- en: '| **3** | 0014 | 01-15 | NaN |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| **3** | 0014 | 01-15 | NaN |'
- en: 'We’ve included these examples to show the versatility of JSON. The main takeaway
    is that JSON files can arrange data in different ways, so we typically need to
    examine the file before we can read the data into a dataframe successfully. JSON
    files are very common for data stored on the web: the examples in this section
    were files downloaded from the PurpleAir and Kiva websites. Although we downloaded
    the data manually in this section, we often want to download many datafiles at
    a time, or we want a reliable and reproducible record of the download. In the
    next section, we introduce HTTP, a protocol that will let us write programs to
    download data from the web automatically.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们包含这些示例是为了展示JSON的多功能性。主要的收获是JSON文件可以以不同的方式排列数据，因此我们通常需要在成功将数据读入数据框之前检查文件。JSON文件在存储在网络上的数据中非常常见：本节中的示例是从PurpleAir和Kiva网站下载的文件。尽管在本节中我们手动下载了数据，但我们经常希望一次下载多个数据文件，或者我们希望有一个可靠且可重现的下载记录。在下一节中，我们将介绍HTTP，这是一个协议，让我们能够编写程序自动从网络上下载数据。
- en: HTTP
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HTTP
- en: HTTP (HyperText Transfer Protocol) is an all-purpose infrastructure to access
    resources on the web. There are a tremendous number of datasets available to us
    on the internet, and with HTTP we can acquire these datasets.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP（超文本传输协议）是访问网络资源的通用基础设施。互联网上提供了大量的数据集，通过HTTP我们可以获取这些数据集。
- en: The internet allows computers to communicate with each other, and HTTP places
    a structure on the communication. HTTP is a simple *request-response* protocol,
    where a client submits a *request* to a server in a specially formatted text message,
    and the server sends a specially formatted text *response* back. The client might
    be a web browser or our Python session.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 互联网允许计算机彼此通信，而HTTP则对通信进行结构化。 HTTP是一种简单的*请求-响应*协议，其中客户端向服务器提交一个特殊格式的文本*请求*，服务器则返回一个特殊格式的文本*响应*。
    客户端可以是Web浏览器或我们的Python会话。
- en: 'An HTTP request has two parts: a header and an optional body. The header must
    follow a specific syntax. An example request to obtain the Wikipedia page shown
    in [Figure 14-3](#fig-wiki-1500) looks like the following:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP请求由两部分组成：头部和可选的正文。 头部必须遵循特定的语法。 请求获取在[图14-3](#fig-wiki-1500)中显示的维基百科页面的示例如下所示：
- en: '[PRE34]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The first line contains three pieces of information: it starts with the method
    of the request, which is `GET`; this is followed by the URL of the web page we
    want; and last is the protocol and version. Each of the three lines that follow
    give auxiliary information for the server. This information has the format `name:
    value`. Finally, a blank line marks the end of the header. Note that we’ve marked
    the blank line with `{blank_line}` in the preceding snippet; in the actual message,
    this is a blank line.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '第一行包含三个信息部分：以请求的方法开头，这是`GET`；其后是我们想要的网页的URL；最后是协议和版本。 接下来的三行每行提供服务器的辅助信息。 这些信息的格式为`名称:
    值`。 最后，空行标志着头部的结束。 请注意，在前面的片段中，我们用`{blank_line}`标记了空行；实际消息中，这是一个空行。'
- en: '![](assets/leds_1403.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_1403.png)'
- en: Figure 14-3\. Screenshot of the Wikipedia page with data on the world record
    for the 1,500-meter race
  id: totrans-132
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图14-3\. 维基百科页面截图，显示1500米赛跑的世界纪录数据
- en: 'The client’s computer sends this message over the internet to the Wikipedia
    server. The server processes the request and sends a response, which also consists
    of a header and body. The header for the response looks like this:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端的计算机通过互联网将此消息发送给维基百科服务器。 服务器处理请求并发送响应，响应也包括头部和正文。 响应的头部如下所示：
- en: '[PRE35]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The first line states that the request completed successfully; the status code
    is 200\. The next lines give additional information for the client. We shortened
    this header quite a bit to focus on just a few pieces of information that tell
    us the content of the body is HTML and uses UTF-8 encoding, and the content is
    153,912 characters long. Finally, the blank line at the end of the header tells
    the client that the server has finished sending header information, and the response
    body follows.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 第一行声明请求成功完成；状态代码为200。 接下来的行提供了客户端的额外信息。 我们大大缩短了这个头部，仅关注告诉我们正文内容为HTML，使用UTF-8编码，并且内容长度为153,912个字符的几个信息。
    最后，头部末尾的空行告诉客户端，服务器已经完成发送头部信息，响应正文随后而来。
- en: HTTP is used in almost every application that interacts with the internet. For
    example, if you visit this same Wikipedia page in your web browser, the browser
    makes the same basic HTTP request as the one just shown. When it receives the
    response, it displays the body in your browser’s window, which looks like the
    screenshot in [Figure 14-3](#fig-wiki-1500).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎每个与互联网交互的应用程序都使用HTTP。 例如，如果您在Web浏览器中访问相同的维基百科页面，浏览器会执行与刚刚显示的基本HTTP请求相同的操作。
    当它接收到响应时，它会在浏览器窗口中显示正文，该正文看起来像[图14-3](#fig-wiki-1500)中的屏幕截图。
- en: 'In practice, we do not write out full HTTP requests ourselves. Instead, we
    use tools like the `requests` Python library to construct requests for us. The
    following code constructs the HTTP request for the page in [Figure 14-3](#fig-wiki-1500)
    for us. We simply pass the URL to `requests.get`. The “get” in the name indicates
    the `GET` method is being used:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，我们不会手动编写完整的HTTP请求。 相反，我们使用诸如`requests` Python库之类的工具来为我们构建请求。 以下代码为我们构造了获取[图14-3](#fig-wiki-1500)页面的HTTP请求。
    我们只需将URL传递给`requests.get`。 名称中的“get”表示正在使用`GET`方法：
- en: '[PRE36]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We can check our request’s status to make sure the server completed it successfully:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以检查我们的请求状态，以确保服务器成功完成它：
- en: '[PRE38]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We can thoroughly examine the request and response through the object’s attributes.
    As an example, let’s take a look at the key-value pairs in the header in our request:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过对象的属性彻底检查请求和响应。 例如，让我们看一看我们请求的头部中的键值对：
- en: '[PRE40]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Although we did not specify any header information in our function call, `request.get`
    provided some basic information for us. If we need to send special header information,
    we can specify them in our call.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们在函数调用中没有指定任何头信息，但`request.get`为我们提供了一些基本信息。如果需要发送特殊的头信息，我们可以在调用中指定它们。
- en: 'Now let’s examine the header of the response we received from the server:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来查看从服务器收到的响应头：
- en: '[PRE42]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'As we saw earlier, there’s a lot of header information in the response. We
    just display the `date`, `content-type`, and `content-length`:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前看到的，响应中有大量的头信息。我们仅显示`date`、`content-type`和`content-length`：
- en: '[PRE44]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Finally, we display the first several hundred characters of the response body
    (the entire content is too long to display nicely here):'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们显示响应体的前几百个字符（整个内容过长，无法在此完整显示）：
- en: '[PRE46]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: We confirm that the response is an HTML document and that it contains the title
    `1500 metres world record progression - Wikipedia`. We have successfully retrieved
    the web page shown in [Figure 14-3](#fig-wiki-1500).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们确认响应是一个HTML文档，并且包含标题`1500 metres world record progression - Wikipedia`。我们已成功获取了[图14-3](#fig-wiki-1500)中显示的网页。
- en: Our HTTP request has been successful, and the server has returned a status code
    of `200`. There are hundreds of other HTTP status codes. Thankfully, they are
    grouped into categories to make them easier to remember (see [Table 14-1](#response-codes)).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的HTTP请求已成功，服务器返回了状态码`200`。还有数百种其他HTTP状态码。幸运的是，它们被分组到不同的类别中，以便记忆（见[表14-1](#response-codes)）。
- en: Table 14-1\. Response status codes
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 表14-1。响应状态码
- en: '| Code | Type | Description |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| Code | Type | Description |'
- en: '| --- | --- | --- |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 100s | Informational | More input is expected from the client or server (100
    Continue, 102 Processing, etc.). |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| 100s | 信息性 | 需要客户端或服务器进一步输入（100 Continue、102 Processing等）。 |'
- en: '| 200s | Success | The client’s request was successful (200 OK, 202 Accepted,
    etc.). |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| 200s | 成功 | 客户端请求成功（200 OK、202 Accepted等）。 |'
- en: '| 300s | The redirection | Requested URL is located elsewhere and may need
    further action from the user (300 Multiple Choices, 301 Moved Permanently, etc.).
    |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 300s | 重定向 | 请求的URL位于其他位置，可能需要用户进一步操作（300 Multiple Choices、301 Moved Permanently等）。
    |'
- en: '| 400s | Client error | A client-side error occurred (400 Bad Request, 403
    Forbidden, 404 Not Found, etc.). |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| 400s | 客户端错误 | 发生了客户端错误（400 Bad Request、403 Forbidden、404 Not Found等）。 |'
- en: '| 500s | Server error | A server-side error occurred or the server is incapable
    of performing the request (500 Internal Server Error, 503 Service Unavailable,
    etc.). |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| 500s | 服务器错误 | 发生了服务器端错误或服务器无法执行请求（500 Internal Server Error、503 Service
    Unavailable等）。 |'
- en: 'One common error code that might look familiar is 404, which tells us we have
    requested a resource that doesn’t exist. We send such a request here:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的错误代码可能看起来很熟悉，即404，表示我们请求的资源不存在。我们在这里发送这样的请求：
- en: '[PRE48]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The request we made to retrieve the web page was a `GET` HTTP request. There
    are four main HTTP request types: `GET`, `POST`, `PUT`, and `DELETE`. The two
    most commonly used methods are `GET` and `POST`. We just used `GET` to retrieve
    the web page:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发出的请求是用`GET` HTTP请求获取网页。有四种主要的HTTP请求类型：`GET`、`POST`、`PUT`和`DELETE`。最常用的两种方法是`GET`和`POST`。我们刚刚使用`GET`来获取网页：
- en: '[PRE50]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: The `POST` request is used to send specific information from the client to the
    server. In the next section, we use `POST` to retrieve data from Spotify.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '`POST`请求用于将特定信息从客户端发送到服务器。在下一节中，我们将使用`POST`来从Spotify获取数据。'
- en: REST
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: REST
- en: Web services are increasingly implementing the REST (REpresentational State
    Transfer) architecture for developers to access their data. These include social
    media platforms like Twitter and Instagram, music apps like Spotify, real estate
    apps like Zillow, scientific sources of data such as the Climate Data Store, government
    data at the World Bank, and many, many more. The basic idea behind REST is that
    every URL identifies a resource (data).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 网络服务越来越多地采用REST（表述性状态转移）架构，供开发人员访问其数据。这些包括像Twitter和Instagram这样的社交媒体平台，像Spotify这样的音乐应用，像Zillow这样的房地产应用，像气候数据存储这样的科学数据源，以及世界银行的政府数据等等。REST背后的基本思想是，每个URL标识一个资源（数据）。
- en: 'REST is *stateless*, meaning that the server does not remember the client from
    one request to the next. This aspect of REST has a few advantages: the server
    and the client can understand any message received without seeing previous messages,
    code can be changed on either the client or server side without impacting the
    operation of the service, and access is scalable, fast, modular, and independent.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: REST 是*无状态*的，意味着服务器不会在连续的请求中记住客户端的状态。REST 的这一方面具有一些优势：服务器和客户端可以理解任何收到的消息，不必查看先前的消息；可以在客户端或服务器端更改代码而不影响服务的操作；访问是可伸缩的、快速的、模块化的和独立的。
- en: In this section, we work through an example to retrieve data from Spotify.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将通过一个示例来从 Spotify 获取数据。
- en: Our example follows [Steven Morse’s blog post](https://oreil.ly/zI-5z), where
    we use both `POST` and `GET` methods in a series of requests to retrieve data
    on songs by [The Clash](https://www.theclash.com).
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的示例遵循[Steven Morse 的博客文章](https://oreil.ly/zI-5z)，我们在一系列请求中使用`POST`和`GET`方法来检索[The
    Clash](https://www.theclash.com)的歌曲数据。
- en: Note
  id: totrans-178
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In practice, we wouldn’t write `GET` and `POST` requests ourselves for Spotify.
    Instead, we’d use the [`spotipy`](https://oreil.ly/fPQX0) library, which has functions
    to interact with the [Spotify web API](https://oreil.ly/NH4ZO). That said, data
    scientists can often find themselves in the position of wanting to access data
    available via REST that doesn’t have a Python library available, so this section
    shows how to get data from a RESTful website like Spotify.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，我们不会自己为 Spotify 编写`GET`和`POST`请求。相反，我们会使用[`spotipy`](https://oreil.ly/fPQX0)库，该库具有与[Spotify
    web API](https://oreil.ly/NH4ZO)交互的功能。尽管如此，数据科学家通常会发现自己想要访问的数据只能通过 REST 获得，而没有
    Python 库可用。因此，本节展示了如何从类似 Spotify 的 RESTful 网站获取数据。
- en: Typically, a REST application provides documentation with examples on how to
    request its data. Spotify has extensive documentation geared to developers who
    want to build an app, but we can also access the service just to explore data.
    To do that, we need to register as a developer and get a client ID and secret.
    We then use these to identify us to Spotify in our HTTP requests.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，REST 应用程序会提供带有如何请求其数据的示例的文档。Spotify 提供了针对想要构建应用程序的开发者的广泛文档，但我们也可以仅仅用来探索数据访问服务。为此，我们需要注册开发者帐号并获取客户端
    ID 和密钥，然后在我们的 HTTP 请求中使用它们来识别自己给 Spotify。
- en: 'After we register, we can begin to request data. This process has two steps:
    authenticate and request resources.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 注册后，我们可以开始请求数据。此过程分两步：认证和请求资源。
- en: To authenticate, we issue a POST request, where we give the web service our
    client ID and secret. We provide these in the header of the request. In return,
    we receive a token from the server that authorizes us to make requests.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 要进行身份验证，我们发出一个 POST 请求，将我们的客户端 ID 和密钥提供给 Web 服务。我们在请求的标头中提供这些信息。作为回报，我们从服务器接收到一个授权我们进行请求的令牌。
- en: 'We begin the process and authenticate:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开始流程并进行身份验证：
- en: '[PRE52]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'We provided our ID and secret in key-value pairs in the header of our POST
    request. We can check the status of our request to see if it was successful:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 POST 请求的标头中以键值对的形式提供了我们的 ID 和密钥。我们可以检查请求的状态以查看是否成功：
- en: '[PRE54]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Now let’s check the type of content in the body of the response:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们检查响应体中的内容类型：
- en: '[PRE56]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The body of the response contains the token that we need in the next step to
    get the data. Since this information is JSON-formatted, we can check the keys
    and retrieve the token:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 响应体包含我们需要在下一步获取数据时使用的令牌。由于此信息格式为 JSON，我们可以检查键并检索令牌：
- en: '[PRE58]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Notice that we hid our ID and secret so that others reading this book can’t
    imitate us. This request won’t be successful without a valid ID and secret. For
    example, here we make up an ID and secret and try to authenticate:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们隐藏了我们的 ID 和密钥，以防其他人模仿我们。没有有效的 ID 和密钥，此请求将无法成功。例如，在这里，我们编造了一个 ID 和密钥并尝试进行身份验证：
- en: '[PRE61]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'We check the status of this “bad” request:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们检查此“坏”请求的状态：
- en: '[PRE62]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'According to [Table 14-1](#response-codes), a code of 400 means that we issued
    a bad request. For one more example, Spotify shuts us down if we take too much
    time making requests. We ran into this issue a couple of times when writing this
    section and received the following code, telling us our token had expired:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 根据[表 14-1](#response-codes)，400 码表示我们发出了一个错误请求。作为一个例子，如果我们花费太多时间进行请求，Spotify
    会关闭我们。在撰写本节时，我们遇到了这个问题几次，并收到了以下代码，告诉我们我们的令牌已过期：
- en: '[PRE64]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Now for the second step, let’s get some data.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 现在进行第二步，让我们获取一些数据。
- en: 'Requests for resources can be made via `GET` for Spotify. Other services may
    require POSTs. Requests must include the token we received from the web service
    when we authenticated, which we can use over and over. We pass the access token
    in the header of our `GET` request. We construct the name-value pairs as a dictionary:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 对 Spotify 的资源可以通过 `GET` 进行请求。其他服务可能需要 POST。请求必须包括我们从 web 服务认证时收到的令牌，我们可以一次又一次地使用。我们将访问令牌传递到我们的
    `GET` 请求的头部。我们将名称-值对构造为字典：
- en: '[PRE65]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: The developer API tells us that an artist’s albums are available at URLs that
    look like *https://api.spotify.com/v1/artists/3RGLhK1IP9jnYFH4BRFJBS/albums*,
    where the code between *artists/* and */albums* is an artist’s ID. This particular
    code is for The Clash. Information about the tracks on an album is available at
    a URL that looks like *https://api.spotify.com/v1/albums/49kzgMsxHU5CTeb2XmFHjo/tracks*,
    where the identifier here is for the album.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 开发者 API 告诉我们，艺术家的专辑可在类似于 *https://api.spotify.com/v1/artists/3RGLhK1IP9jnYFH4BRFJBS/albums*
    的 URL 上找到，其中 *artists/* 和 */albums* 之间的代码是艺术家的 ID。这个特定的代码是 The Clash 的。有关专辑上音轨的信息可在类似于
    *https://api.spotify.com/v1/albums/49kzgMsxHU5CTeb2XmFHjo/tracks* 的 URL 上找到，这里的标识符是专辑的。
- en: 'If we know the ID for an artist, we can retrieve the IDs for its albums, and
    in turn, we can get data about the tracks on the albums. Our first step was to
    get the ID for The Clash from Spotify’s site:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们知道艺术家的 ID，我们可以检索其专辑的 ID，进而可以获取关于专辑上音轨的数据。我们的第一步是从 Spotify 的网站获取 The Clash
    的 ID：
- en: '[PRE66]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Our first data request retrieves the group’s albums. We construct the URL using
    `artist_id` and pass our access token in the header:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一个数据请求检索了组的专辑。我们使用 `artist_id` 构建 URL，并在头部传递我们的访问令牌：
- en: '[PRE67]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '[PRE68]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Our request was successful. Now let’s check the `content-type` of the response
    body:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的请求成功了。现在让我们检查响应主体的`content-type`：
- en: '[PRE70]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '[PRE71]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'The resource returned is JSON, so we can load it into a Python dictionary:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 返回的资源是 JSON，因此我们可以将其加载到 Python 字典中：
- en: '[PRE72]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'After poking around a bit, we can find that album information is in the `items`
    element. The keys for the first album are:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 经过一番搜索，我们可以发现专辑信息在 `items` 元素中。第一个专辑的键是：
- en: '[PRE73]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '[PRE74]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Let’s print the album IDs, names, and release dates for a few albums:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们打印几个专辑的专辑 ID、名称和发行日期：
- en: '[PRE75]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '[PRE76]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'We see that some albums are remastered and others are live performances. Next,
    we cycle through the albums, pick up their IDs, and for each album we request
    information about the tracks:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到一些专辑是重新混音的，而另一些是现场演出。接下来，我们循环遍历专辑，获取它们的 ID，并为每个专辑请求有关音轨的信息：
- en: '[PRE77]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Over a dozen features are available to explore on the tracks. Let’s close the
    example with a plot of danceability and loudness of The Clash songs:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些音轨上有超过十几个功能可供探索。让我们以绘制 The Clash 歌曲的舞蹈性和响度为例结束本示例：
- en: '![](assets/leds_14in03.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_14in03.png)'
- en: This section covered REST APIs, which provide standardized approaches for programs
    to download data. The example shown here downloaded JSON data. At other times,
    the data from a REST request may be in an XML format. And sometimes a REST API
    isn’t available for the data we want, and we must extract the data from web pages
    themselves in HTML, a format similar to XML. We describe how to work with these
    formats next.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了 REST API，它提供了程序下载数据的标准化方法。这里展示的示例下载了 JSON 数据。其他时候，来自 REST 请求的数据可能是 XML
    格式的。有时我们想要的数据没有 REST API 可用，我们必须从 HTML 中提取数据，这是一种与 XML 类似的格式。接下来我们将描述如何处理这些格式。
- en: XML, HTML, and XPath
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: XML、HTML 和 XPath
- en: The eXtensible Markup Language (XML ) can represent all types of information,
    such as data sent to and from web services, including web pages, spreadsheets,
    visual displays like SVG, social network structures, word processing documents
    like Microsoft’s docx, databases, and much more. For a data scientist, knowing
    a little about XML can come in handy.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展标记语言（XML）可以表示各种类型的信息，例如发送到和从 Web 服务传送的数据，包括网页、电子表格、SVG 等可视显示、社交网络结构、像微软的
    docx 这样的文字处理文档、数据库等等。对于数据科学家来说，了解 XML 会有所帮助。
- en: Despite its name, XML is not a language. Rather, it is a very general structure
    we can use to define formats to represent and organize data. XML provides a basic
    structure and syntax for these “dialects” or vocabularies. If you read or compose
    HTML, you will recognize the format of XML.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管它的名称是 XML，但它不是一种语言。相反，它是一个非常通用的结构，我们可以用它来定义表示和组织数据的格式。XML 提供了这些“方言”或词汇表的基本结构和语法。如果你读过或撰写过
    HTML，你会认出 XML 的格式。
- en: The basic unit in XML is the *element*, which is also referred to as a *node*.
    An element has a name and may have attributes, child elements, and text.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: XML的基本单位是*元素*，也被称为*节点*。一个元素有一个名称，可以有属性、子元素和文本。
- en: 'The following annotated snippet of an XML plant catalog provides an example
    of these pieces (this content is adapted from [W3Schools](https://oreil.ly/qPa6s)):'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 下面标注的XML植物目录片段提供了这些部分的示例（此内容改编自[W3Schools](https://oreil.ly/qPa6s)）：
- en: '[PRE78]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: We added the indentation to this snippet of XML to make it easier to see the
    structure. It is not needed in the actual file.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为此XML片段添加了缩进以便更容易看到结构。实际文件中不需要缩进。
- en: 'XML documents are plain-text files with the following syntax rules:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: XML文档是纯文本文件，具有以下语法规则：
- en: Each element begins with a start tag, like `<plant>`, and closes with an end
    tag of the same name, like `</plant>`.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个元素都以开始标签开始，例如`<plant>`，并以相同名称的结束标签关闭，例如`</plant>`。
- en: XML elements can contain other XML elements.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XML元素可以包含其他XML元素。
- en: XML elements can be plain-text, like “Columbine” in `<common>Columbine</common>`.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XML元素可以是纯文本，例如`<common>Columbine</common>`中的“Columbine”。
- en: XML elements can have optional attributes. The element `<price curr=“CAD”>`
    has an attribute `curr` with value `"CAD"`.
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XML元素可以具有可选的属性。元素`<price curr=“CAD”>`具有属性`curr`，其值为`"CAD"`。
- en: In the special case when a node has no children, the end tag can be folded into
    the start tag. An example is `<availability date="0199"/>`.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特殊情况下，当节点没有子节点时，结束标签可以折叠到开始标签中。例如`<availability date="0199"/>`。
- en: 'We call an XML document well formed when it follows certain rules. The most
    important of these are:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 当它遵循特定规则时，我们称XML文档为良好格式的文档。其中最重要的规则是：
- en: One root node contains all of the other elements in the document.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个根节点包含文档中的所有其他元素。
- en: Elements nest properly; an open node closes around all of its children and no
    more.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元素正确嵌套；开放节点在其所有子节点周围关闭，不再多余。
- en: Tag names are case-sensitive.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标签名称区分大小写。
- en: Attribute values have a `name=“value”` format with single or double quotes.
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 属性值采用`name=“value”`格式，可以使用单引号或双引号。
- en: There are additional rules for a document to be well formed. These relate to
    whitespace, special characters, naming conventions, and repeated attributes.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 有关文档为良好格式的其他规则。这些与空白、特殊字符、命名约定和重复属性有关。
- en: The hierarchical nature of well-formed XML means it can be represented as a
    tree. [Figure 14-4](#fig-xml-tree) shows a tree representation of the plant catalog
    XML.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '**XML的分层结构**使其可以表示为树形结构。[图 14-4](#fig-xml-tree)展示了植物目录XML的树形表示。'
- en: '![](assets/leds_1404.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_1404.png)'
- en: Figure 14-4\. Hierarchy of an XML document; the lighter gray boxes represent
    text elements and, by design, these cannot have child nodes
  id: totrans-250
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14-4\. XML文档的层次结构；浅灰色框表示文本元素，按设计，这些元素不能有子节点。
- en: Like with JSON, an XML document is plaintext. We can read it with a plain-text
    viewer, and it’s easy for machines to read and create XML content. The extensible
    nature of XML allows content to be easily merged into higher-level container documents
    and easily exchanged with other applications. XML also supports binary data and
    arbitrary character sets.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 与JSON类似，XML文档是纯文本。我们可以用纯文本查看器来读取它，对于机器来说读取和创建XML内容也很容易。XML的可扩展性允许内容轻松合并到更高级别的容器文档中，并且可以轻松地与其他应用程序交换。XML还支持二进制数据和任意字符集。
- en: As mentioned already, HTML looks a lot like XML. That’s no accident, and indeed,
    XHTML is a subset of HTML that follows the rules of well-formed XML. Let’s return
    to our earlier example of the Wikipedia page that we retrieved from the internet
    and show how to used XML tools to create a dataframe from the contents of one
    of its tables.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，HTML看起来很像XML。这不是偶然的，事实上，XHTML是HTML的子集，遵循良好格式XML的规则。让我们回到之前从互联网上检索的维基百科页面的例子，并展示如何使用XML工具从其表格内容创建数据框架。
- en: 'Example: Scraping Race Times from Wikipedia'
  id: totrans-253
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例：从维基百科抓取赛时
- en: Earlier in this chapter, we used an HTTP request to retrieve the HTML page from
    Wikipedia shown in [Figure 14-3](#fig-wiki-1500). The contents of this page are
    in HTML, which is essentially an XML vocabulary. We can use the hierarchical structure
    of the page and XML tools to access data in one of the tables and wrangle it into
    a dataframe. In particular, we are interested in the second table in the page,
    a portion of which appears in the screenshot in [Figure 14-5](#fig-html-table).
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的早些时候，我们使用了一个 HTTP 请求从维基百科检索了 HTML 页面，如[图 14-3](#fig-wiki-1500)所示。这个页面的内容是
    HTML 格式的，本质上是 XML 词汇。我们可以利用页面的分层结构和 XML 工具来访问其中一个表格中的数据，并将其整理成数据框。特别是，我们对页面中的第二个表格感兴趣，其中的一部分显示在[图 14-5](#fig-html-table)的截图中。
- en: '![](assets/leds_1405.png)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_1405.png)'
- en: Figure 14-5\. Screenshot of the second table in a web page that contains the
    data we want to extract
  id: totrans-256
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14-5\. 网页中包含我们想要提取的数据的第二个表格的截图
- en: 'Before we work on this table, we provide a quick summary of the format for
    a basic HTML table. Here is the HTML for a table with a header and two rows of
    three columns:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们处理这个表格之前，我们先快速总结一下基本 HTML 表格的格式。这是一个带有表头和两行三列的表格的 HTML 格式：
- en: '[PRE79]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: Notice how the table is laid out in rows with `<tr>` elements, and each cell
    in a row is a `<td>` element that contains the text to be displayed in the table.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 注意表格是如何以`<tr>`元素为行布局的，每行中的每个单元格是包含在`<td>`元素中的文本，用于在表格中显示。
- en: 'Our first task is to create a tree structure from the content of the web page.
    To do this, we use the `lxml` library, which provides access to the C-library
    `libxml2` for handling XML content. Recall that `resp_1500` contains the response
    from our request, and the page is in the body of the response. We can parse the
    web page into a hierarchical structure with `fromstring` in the `lxml.html` module:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一个任务是从网页内容中创建一个树结构。为此，我们使用`lxml`库，它提供了访问 C 库`libxml2`来处理 XML 内容的功能。回想一下，`resp_1500`包含了我们请求的响应，页面位于响应体中。我们可以使用`lxml.html`模块中的`fromstring`方法将网页解析为一个分层结构：
- en: '[PRE80]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '[PRE81]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '[PRE82]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Now we can work with the document using its tree structure. We can find all
    the tables in the HTML document with the following search:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用文档的树结构来处理文档。我们可以通过以下搜索找到 HTML 文档中的所有表格：
- en: '[PRE83]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '[PRE84]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '[PRE85]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: '[PRE86]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: This search uses the XPath `//table` expression, which we soon describe, to
    search for all table nodes anywhere in the document.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这个搜索使用了 XPath `//table` 表达式，在文档中的任何位置搜索所有表格节点。
- en: 'We found six tables in the document. If we examine the web page, including
    looking at its HTML source via the browser, we can figure out that the second
    table in the document contains the IAF-era times. This is the table we want. The
    screenshot in [Figure 14-5](#fig-html-table) shows that the first column contains
    the race times, the third holds names, and the fourth has the dates of the races.
    We can extract each of these pieces of information in turn. We do this with the
    following XPath expressions:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在文档中找到了六个表格。如果我们检查网页，包括通过浏览器查看其 HTML 源代码，我们可以发现文档中的第二个表格包含 IAF 时代的时间。这是我们想要的表格。[图 14-5](#fig-html-table)中的截图显示，第一列包含比赛时间，第三列包含名称，第四列包含比赛日期。我们可以依次提取这些信息。我们使用以下
    XPath 表达式完成这些操作：
- en: '[PRE87]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '[PRE88]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '[PRE89]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'These return values behave like a list, but each value is an element of the
    tree. We can convert them to strings:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 这些返回值的行为类似于列表，但每个值都是树的元素。我们可以将它们转换为字符串：
- en: '[PRE90]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'For the times, we want to transform them into seconds. The function `get_sec`
    does this conversion. And we want to extract the race year from the date string:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 对于时间，我们希望将其转换为秒。函数`get_sec`可以完成这个转换。而我们希望从日期字符串中提取比赛年份：
- en: '[PRE91]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '[PRE92]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'We can create a dataframe and make a plot to show the progress in race times
    over the years:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建一个数据框并绘制图表，以展示比赛时间随年份的变化情况：
- en: '![](assets/leds_14in04.png)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_14in04.png)'
- en: As you may have noticed, extracting data from an HTML page relies on careful
    examination of the source to find where in the document the numbers that we’re
    after are. We relied heavily on the XPath tool to do the extraction. Its elegant
    language is quite powerful. We introduce it next.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能已经注意到的那样，从 HTML 页面中提取数据需要仔细检查源代码，找到我们需要的数字在文档中的位置。我们大量使用 XPath 工具进行提取。它的语言优雅而强大。我们接下来介绍它。
- en: XPath
  id: totrans-282
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: XPath
- en: When we work with XML documents, we typically want to extract data from them
    and bring it into a dataframe. XPath can help here. XPath can recursively traverse
    an XML tree to find elements. For example, we used the expression `//table` in
    the previous example to locate all table nodes in our web page.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们处理 XML 文档时，通常希望从中提取数据并将其带入数据框中。XPath 可以在这方面提供帮助。XPath 可以递归地遍历 XML 树以查找元素。例如，在前面的示例中，我们使用表达式
    `//table` 定位网页中所有表格节点。
- en: XPath expressions operate on the hierarchy of well-formed XML. They are succinct
    and similar in format to the way files are located in a hierarchy of directories
    in a computer filesystem. But they’re much more powerful. XPath is also similar
    to regular expressions in that we specify patterns to match content. Like with
    regular expressions, it takes experience to compose correct XPath expressions.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: XPath 表达式作用于良构 XML 的层次结构。它们简洁并且格式类似于计算机文件系统中目录层次结构中定位文件的方式。但它们更加强大。XPath 与正则表达式类似，我们指定要匹配内容的模式。与正则表达式一样，撰写正确的
    XPath 表达式需要经验。
- en: An XPath expression forms logical steps to identify and filter nodes in a tree.
    The result is a *node set* where each node occurs at most once. The node set also
    has an order that matches the order in which the nodes occur in the source; this
    can be quite handy.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: XPath 表达式形成逻辑步骤，用于识别和过滤树中的节点。结果是一个*节点集*，其中每个节点最多出现一次。节点集也具有与源中节点出现顺序匹配的顺序；这一点非常方便。
- en: 'Each XPath expression is made up of one or more *location steps*, separated
    by a “/”. Each location step has three parts—the *axis*, *node test*, and optional
    *predicate*:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 XPath 表达式由一个或多个*位置步骤*组成，用“/”分隔。每个位置步骤有三个部分——*轴*、*节点测试*和可选的*谓词*：
- en: The axis specifies the direction to look in, such as down, up, or across the
    tree. We exclusively use shortcuts for the axis. The default is to look down one
    step at children in the tree. `//` says to look down the tree as far as possible,
    and `..` indicates one step up to the parent.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 轴指定查找的方向，例如向下、向上或横向。我们专门使用轴的快捷方式。默认是向下一步查找树中的子节点。`//` 表示尽可能向下查找整个树，`..` 表示向上一步到父节点。
- en: The node test identifies the name or the type of node to look for. This is typically
    just a tag name or `text()` for text elements.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点测试标识要查找的节点的名称或类型。通常只是标签名或者对于文本元素是 `text()`。
- en: A predicate acts like a filter to further restrict the node set. This is given
    in square brackets, like `[2]`, which keeps the second node in the node set, and
    `[ @date ]`, which keeps all nodes with a date attribute.
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谓词像过滤器一样作用于进一步限制节点集。这些谓词以方括号表示，例如 `[2]`，保留节点集中的第二个节点，以及 `[ @date ]`，保留具有日期属性的所有节点。
- en: We can tack together location steps to create powerful search instructions.
    [Table 14-2](#xpath-examples) provides some examples that cover the most common
    expressions. Refer back to the tree in [Figure 14-4](#fig-xml-tree) to follow
    along.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将位置步骤连接在一起，以创建强大的搜索指令。[表 14-2](#xpath-examples) 提供了一些涵盖最常见表达式的示例。请参考 [图 14-4](#fig-xml-tree)
    中的树进行跟踪。
- en: Table 14-2\. XPath examples
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 表 14-2\. XPath 示例
- en: '| Expression | Result | Description |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| 表达式 | 结果 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| ‘//common’ | Two nodes | Look down the tree for any common nodes. |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| ‘//common’ | Two nodes | 在树中向下查找任何共同节点。'
- en: '| ‘/catalog/plant/common’ | Two nodes | Travel the specific path from the root
    node *catalog* to all plant nodes to all common nodes within the plant nodes.
    |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| ‘/catalog/plant/common’ | Two nodes | 从根节点 *catalog* 沿特定路径向所有植物节点遍历，并在植物节点中的所有共同节点中查找。'
- en: '| ‘//common/text()’ | Bloodroot, Columbine | Locate the text content of all
    common nodes. |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '| ‘//common/text()’ | Bloodroot, Columbine | 定位所有共同节点的文本内容。 |'
- en: '| ‘//plant[2]/price/text()’ | $9.37 | Locate plant nodes anywhere in the tree,
    then filter to take only the second. From this plant node, travel to its price
    child and locate its text. |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '| ‘//plant[2]/price/text()’ | $9.37 | 在树的任何位置定位植物节点，然后过滤并仅获取第二个节点。从此植物节点进入其价格子节点并定位其文本。
    |'
- en: '| ‘//@date’ | 0399, 0199 | Locate the attribute value of any attribute named
    “date” in the tree. |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '| ‘//@date’ | 0399, 0199 | 定位树中任何名为“date”的属性值。 |'
- en: '| ‘//price[@curr=“CAD”]/text()’ | $9.37 | The text content of any price node
    that has a currency attribute value of “CAD.” |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| ‘//price[@curr=“CAD”]/text()’ | $9.37 | 具有货币属性值“CAD”的任何价格节点的文本内容。 |'
- en: 'You can try out the XPath expressions in the table with the catalog file. We
    load the file into Python using the `etree` module. The `parse` method reads the
    file into an element tree:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在目录文件中的表中尝试XPath表达式。我们使用`etree`模块将文件加载到Python中。`parse`方法读取文件到一个元素树中。
- en: '[PRE93]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: The `lxml` library gives us access to XPath. Let’s try it out.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '`lxml`库让我们能够访问XPath。让我们试试吧。'
- en: 'This simple XPath expression locates all text content of any `<light>` node
    in the tree:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单的XPath表达式定位树中任何`<light>`节点的所有文本内容：
- en: '[PRE94]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: '[PRE95]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'Notice that two elements are returned. Although the text content is identical,
    we have two `<light>` nodes in our tree and so are given the text content of each.
    The following expression is a bit more challenging:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 注意返回了两个元素。虽然文本内容相同，但我们的树中有两个`<light>`节点，因此返回了每个节点的文本内容。以下表达式稍微有些复杂：
- en: '[PRE96]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: '[PRE97]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: The expression locates all `<price>` nodes in the tree, then filters them according
    to whether their `curr` attribute is `CAD`. Then, for the remaining nodes (there’s
    only one in this case), travel up one step in the tree to the parent node and
    then back down to any child “common” nodes and on to their text content. Quite
    the trip!
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 该表达式定位树中所有`<price>`节点，然后根据它们的`curr`属性是否为`CAD`进行过滤。然后，对剩余节点（在本例中只有一个）在树中向上移动一步至父节点，然后返回到任何子“common”节点，并获取其文本内容。非常复杂的过程！
- en: Next, we provide an example that uses an HTTP request to retrieve XML-formatted
    data, and XPath to wrangle the content into a dataframe.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们提供一个示例，使用HTTP请求检索XML格式的数据，并使用XPath将内容整理成数据框。
- en: 'Example: Accessing Exchange Rates from the ECB'
  id: totrans-311
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例：访问ECB的汇率
- en: 'The European Central Bank (ECB) makes exchange rates available online in XML
    format. Let’s begin by getting the most recent exchange rates from the ECB with
    an HTTP request:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 欧洲央行（ECB）提供了在线XML格式的汇率信息。让我们通过HTTP请求获取ECB的最新汇率：
- en: '[PRE98]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '[PRE99]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: '[PRE100]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: 'Again, we can use the `lxml` library to parse the text document we received
    from the ECB, but this time the contents are in a string returned from the ECB,
    not in a file:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，我们可以使用`lxml`库解析从ECB接收到的文本文档，但这次内容是从ECB返回的字符串，而不是文件：
- en: '[PRE101]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: 'In order to extract the data we want, we need to know how it is organized.
    Here is a snippet of the content:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提取我们想要的数据，我们需要了解它的组织方式。这是内容的一部分片段：
- en: '[PRE102]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: This document appears quite different in structure from the plant catalog. The
    snippet shows three levels of tags, all with the same name, and none have text
    content. All of the relevant information is contained in attribute values. Other
    new features are the `xmlns` in the root `<Envelope>` node, and the odd tag names,
    like `gesmes:​Enve⁠lope`. These have to do with namespaces.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 这份文档在结构上与植物目录有很大不同。代码片段展示了三个层次的标签，它们都有相同的名称，且没有文本内容。所有相关信息都包含在属性值中。根`<Envelope>`节点中有`xmlns`和`gesmes:Enve⁠lope`等奇怪的标签名，这些与命名空间有关。
- en: XML allows content creators to use their own vocabularies, called *namespaces*.
    The namespace gives the rules for a vocabulary, such as allowable tag names and
    attribute names, and restrictions on how nodes can be nested. And XML documents
    can merge vocabularies from different applications. To keep it all straight, information
    about the namespace(s) is provided in the document.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: XML允许内容创建者使用自己的词汇，称为*命名空间*。命名空间为词汇提供规则，例如允许的标签名和属性名，以及节点嵌套的限制。XML文档可以合并来自不同应用程序的词汇。为了保持一致，文档中提供了有关命名空间的信息。
- en: The root node in the ECB file is `<Envelope>`. The additional “gesmes:” in the
    tag name indicates that the tags belong to the gesmes vocabulary, which is an
    international standard for the exchange of time-series information. Another namespace
    is also in `<Envelope>`. It is the default namespace for the file because it doesn’t
    have a prefix, like “`gesmes:`”. Whenever a namespace is not provided in a tag
    name, the default is assumed.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: ECB文件的根节点是`<Envelope>`。标签名中的额外“gesmes:”表示这些标签属于gesmes词汇，这是一个用于时间序列信息交换的国际标准。`<Envelope>`中还有另一个命名空间。它是文件的默认命名空间，因为它没有像“`gesmes:`”那样的前缀。如果在标签名中未提供命名空间，则默认为此命名空间。
- en: 'The upshot of this is that we need to take into account these namespaces when
    we search for nodes. Let’s see how this works when we extract the dates. From
    the snippet, we see that the dates reside in “time” attributes. These `<Cube>`s
    are children of the top `<Cube>`. We can give a very specific XPath expression
    to step from the root to its `<Cube>` child node and on to the next level of `<Cube>`
    nodes:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们需要在搜索节点时考虑这些命名空间。让我们看看在提取日期时的运作方式。从片段中，我们看到日期存储在“time”属性中。这些 `<Cube>`
    是顶层 `<Cube>` 的子节点。我们可以给出一个非常具体的 XPath 表达式，从根节点步进到其 `<Cube>` 子节点，然后进入下一级的 `<Cube>`
    节点：
- en: '[PRE103]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: '[PRE104]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: The `.` in the expression is a shortcut to signify “from here,” and since we’re
    at the top of the tree, it’s equivalent to “from the root.” We specified the namespace
    in our expression as “`x:`”. Even though the `<Cube>` nodes are using the default
    namespace, we must specify it in our XPath expression. Fortunately, we can simply
    pass in the namespace as a parameter with our own label (“x” in this case) to
    keep our tag names short.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 表达式中的 `.` 是一个快捷方式，表示“从这里”，因为我们位于树的顶部，它相当于“从根节点”。我们在表达式中指定了命名空间为“`x:`”。尽管 `<Cube>`
    节点使用了默认命名空间，但我们必须在 XPath 表达式中指定它。幸运的是，我们可以简单地将命名空间作为参数传递，并用我们自己的标签（在这种情况下是“x”）来保持标记名称的简短性。
- en: 'Like with the HTML table, we can convert the date values into strings and from
    strings into timestamps:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 与 HTML 表格类似，我们可以将日期值转换为字符串，再从字符串转换为时间戳：
- en: '[PRE105]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: 'As for the exchange rates, they also appear in `<Cube>` nodes, but these have
    a “rate” attribute. For example, we can access all exchange rates for the British
    pound with the following XPath expression (we’re ignoring the namespace for the
    moment):'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 至于汇率，它们也出现在 `<Cube>` 节点中，但这些节点有一个“rate”属性。例如，我们可以使用以下 XPath 表达式访问所有英镑的汇率（目前我们忽略命名空间）：
- en: '`//Cube[@currency = "GBP"]/@rate`'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '`//Cube[@currency = "GBP"]/@rate`'
- en: This expression says look for all `<Cube>` nodes anywhere in the document, filter
    them according to whether the node has a currency attribute value of “GBP,” and
    return their rate attribute values.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 这个表达式表示在文档中的任何位置查找所有 `<Cube>` 节点，根据节点是否具有货币属性值“GBP”进行过滤，并返回它们的汇率属性值。
- en: 'Since we want to extract exchange rates for multiple currencies, we generalize
    this XPath expression. We also want to convert the exchange rates to a numeric
    storage type, and make them relative to the first day’s rate so that the different
    currencies are on the same scale, which makes them more amenable for plots:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们想要提取多种货币的汇率，我们对这个 XPath 表达式进行了泛化。我们还想将汇率转换为数字存储类型，并使它们相对于第一天的汇率，以便不同的货币处于相同的比例尺上，这样更适合绘图：
- en: '[PRE106]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: 'We wrap up this example with line plots of the exchange rates:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以汇率的折线图作为这个示例的结束。
- en: '![](assets/leds_14in05.png)'
  id: totrans-335
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_14in05.png)'
- en: Combining knowledge of JSON, HTTP, REST, and HTML gives us access to a vast
    variety of data available on the web. For example, in this section we wrote code
    to scrape data from a Wikipedia page. One key advantage of this approach is that
    we can likely rerun this code in a few months to automatically update the data
    and the plots. One key drawback is that our approach is tightly coupled to the
    structure of the web page—if someone updates the Wikipedia page and the table
    is no longer the second table on the page, our code will also need some edits
    in order to work. That said, having the skills needed to scrape data from the
    web opens the door to a wide range of data and enables all kinds of useful analyses.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 结合对 JSON、HTTP、REST 和 HTML 的知识，我们可以访问网上可用的大量数据。例如，在本节中，我们编写了从维基百科页面抓取数据的代码。这种方法的一个关键优势是我们可以在几个月后重新运行此代码，自动更新数据和图表。一个关键缺点是我们的方法与网页结构紧密耦合——如果有人更新了维基百科页面，而表格不再是页面上的第二个表格，我们的代码也需要一些修改才能工作。尽管如此，掌握从网页抓取数据的技能打开了广泛数据的大门，使各种有用的分析成为可能。
- en: Summary
  id: totrans-337
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: The internet abounds with data that are stored and exchanged in many different
    formats. In this chapter, our aim was to give you a taste of the variety of formats
    available and a basic understanding of how to acquire data from online sources
    and services. We also addressed the important goal of acquiring data in a reproducible
    fashion. Rather than copying and pasting from a web page or completing a form
    by hand, we demonstrated how to write code to acquire data. This code gives you
    a record of your workflow and of the data provenance.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 互联网上存储和交换的数据种类繁多。在本章中，我们的目标是让您领略到可用格式的多样性，并基本理解如何从在线来源和服务获取数据。我们还解决了以可重复的方式获取数据的重要目标。与其从网页复制粘贴或手工填写表单，我们演示了如何编写代码来获取数据。这些代码为您的工作流程和数据来源提供了记录。
- en: With each format introduced, we described a model for its structure. A basic
    understanding of a dataset’s organization helps you uncover issues with quality,
    mistakes in reading a source file, and how best to wrangle and analyze the data.
    In the longer run, as you continue to develop your data science skills, you will
    be exposed to other forms of data exchange, and we expect this approach of considering
    the organizational model and getting your hands dirty with some simple cases will
    serve you well.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 每种介绍的格式，我们都描述了其结构模型。对数据集组织的基本理解有助于您发现质量问题，读取源文件中的错误，以及最佳处理和分析数据的方法。从长远来看，随着您继续发展数据科学技能，您将接触到其他形式的数据交换，我们期待这种考虑组织模型并通过一些简单案例动手实践的方法能为您服务良好。
- en: We only touched the surface of web services. There are many other useful topics,
    like keeping connections to a server alive as you issue multiple requests or retrieve
    data in batches, using cookies, and making multiple connections. But understanding
    the basics presented here can get you a long way. For example, if you use a library
    to retrieve data from an API but run into an error, you can start looking at the
    HTTP requests to debug your code. And you will know what’s possible when a new
    web service comes online.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仅仅触及了网络服务的表面。还有许多其他有用的主题，比如在发出多个请求或批量检索数据时保持与服务器的连接活动，使用Cookie和进行多个连接。但是理解此处介绍的基础知识可以让您走得更远。例如，如果您使用一个库从API获取数据但遇到错误，可以查看HTTP请求来调试代码。当新的网络服务上线时，您也会知道可能性。
- en: Web etiquette is a topic that we must mention. If you plan to scrape data from
    a website, it’s a good idea to check that you have permission to do so. When we
    sign up to be a client for a web app, we typically check a box indicating our
    agreement to the terms of service.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 网络礼仪是我们必须提及的一个话题。如果您计划从网站抓取数据，最好检查您是否有权限这样做。当我们注册成为Web应用的客户时，通常会勾选同意服务条款的框。
- en: If you use a web service or scrape web pages, be careful not to overburden the
    site with your requests. If a site offers a version of the data in a format like
    CSV, JSON, or XML, it’s better to download and use these than to scrape from a
    web page. Likewise, if there is a Python library that provides structured access
    to a web app, use it rather than writing your own code. When you make requests,
    start small to test your code, and consider saving the results so that you don’t
    have to repeat requests unnecessarily.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用网络服务或抓取网页，请注意不要过度请求网站。如果网站提供了类似CSV、JSON或XML格式的数据版本，最好下载并使用这些数据，而不是从网页抓取。同样，如果有一个Python库提供对Web应用的结构化访问，请使用它而不是编写自己的代码。在发送请求时，先从小处开始测试您的代码，并考虑保存结果，以免不必要地重复请求。
- en: The aim of this chapter wasn’t to make you an expert in these specific data
    formats. Instead, we wanted to give you the confidence needed to learn more about
    a data format, to evaluate the pros and cons of different formats, and to participate
    in projects that might use formats that you haven’t seen before.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目标不是使您成为这些特定数据格式的专家。相反，我们希望为您提供学习更多关于数据格式所需的信心，评估不同格式的优缺点，并参与可能使用您之前未见过的格式的项目。
- en: Now that you have experience working with different data formats, we return
    to the topic of modeling that we introduced in [Chapter 4](ch04.html#ch-modeling),
    picking it back up in earnest.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经有了使用不同数据格式的经验，我们将回到我们在[第4章](ch04.html#ch-modeling)中引入的建模主题，认真地继续讨论。
