- en: 6 Relationships between customer behaviors
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6 客户行为之间的关系
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了
- en: Analyzing relationships between pairs of metrics
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析成对度量的关系
- en: Calculating matrices of correlation coefficients
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算相关系数矩阵
- en: Calculating averages of correlated metric scores
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算相关度量分数的平均值
- en: Segmenting customers using averages of metrics
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用度量平均值细分客户
- en: Discovering metric groups with clustering
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过聚类发现度量群组
- en: 'For most products and services, analyzing whether individual metrics are related
    to churn is the beginning but not the end of using your data to reduce churn.
    This chapter teaches you how to address a common problem: having an overabundance
    of data available for fighting churn. In the age of big data, some companies collect
    a lot about their customers. That should make it easier to fight churn with data,
    right? Not quite.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数产品和服务的分析，分析单个度量与流失率的相关性只是使用数据减少流失的开始，但不是结束。本章教你如何解决一个常见问题：拥有大量可用于对抗流失的数据。在大数据时代，一些公司收集了大量关于他们的客户信息。这应该使得使用数据对抗流失变得更容易，对吧？并不完全是这样。
- en: 'Many customer behaviors are closely related, so metrics based on those behaviors
    have similar relationships to churn. A cohort churn analysis on a typical company’s
    database of events and metrics probably won’t give you just a few cohort churn
    plots: you probably have dozens or more. This can actually cause more confusion
    than good. When behaviors measured by metrics are not the specific acts that give
    enjoyment or utility to the user, then the relationships to churn are just associations
    and not causal. When you have a lot of metrics that are associated with churn
    but not causal, you don’t have a good way to understand how they act together.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 许多客户行为密切相关，因此基于这些行为的度量具有相似的相关性。在典型公司的数据库事件和度量中进行的客户群体流失分析可能不会只给你几个客户群体流失图：你可能会有几十个或更多。这实际上可能比好的情况造成更多的困惑。当度量的行为不是给用户带来愉悦或效用具体行为时，那么与流失率的关系只是关联而不是因果关系。当你有很多与流失相关但不是因果关系的度量时，你没有一个很好的方法来理解它们是如何共同作用的。
- en: To fight churn effectively with your data, you need to do more than understand
    how individual customer behaviors are related to churn. You need to understand
    how customer behaviors are related to each other. When you do that instead of
    just looking at how single behaviors are related to churn, you can look at how
    groups of behaviors are related to churn. That way, you turn the problem of having
    too much data into an asset because groups of behaviors often show a clearer relationship
    to churn than do individual behaviors alone.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效地使用数据对抗流失，你需要做的不仅仅是理解单个客户行为与流失率的关系。你需要理解客户行为之间的关系。当你这样做而不是仅仅看单个行为与流失率的关系时，你可以看看行为群体与流失率的关系。这样，你将拥有过多数据的问题转变为一种资产，因为行为群体往往比单个行为更能清晰地显示出与流失率的关系。
- en: 'This chapter is organized as follows:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的组织结构如下：
- en: In section 6.1, the chapter starts with some case studies to demonstrate what
    it means for behaviors to be correlated and then teaches you how to calculate
    correlations in your own data with Python and with something called a correlation
    matrix, which is an important way of looking at correlations among a large number
    of metrics.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第6.1节中，本章从一些案例研究开始，展示行为相关性的含义，然后教你如何使用Python以及称为相关矩阵的东西来计算你自己的数据中的相关性，这是观察大量度量之间相关性的一种重要方式。
- en: In section 6.2, you’ll learn a technique for forming averages of the metric
    scores of correlated behaviors and then analyze churn using the average score.
    This is a key technique that you’ll use to reduce information overload from having
    too many metrics associated with churn.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第6.2节中，你将学习一种形成相关行为度量分数平均值的技术，然后使用平均分数来分析流失率。这是你将使用的关键技术，用于减少与流失相关的大量度量所引起的信息过载。
- en: Last, in section 6.3, you’ll learn a technique to automatically find groups
    of correlated metrics in a large dataset using an algorithm called a clustering
    algorithm. By mastering these techniques, you’ll be ready to handle big datasets
    with lots of correlated metrics and behaviors to be even more effective in your
    fight against churn.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，在第6.3节中，你将学习一种使用称为聚类算法的算法在大型数据集中自动找到相关度量组的技术。通过掌握这些技术，你将准备好处理具有大量相关度量和行为的庞大数据集，以便在对抗流失的斗争中更加有效。
- en: Grouping behaviors vs. dimension reduction
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 行为分组与维度缩减
- en: If you have formal training in data science or statistics, you’ll probably recognize
    that this chapter covers the idea and practice of dimension reduction and is a
    crash course in linear algebra. But because of the need to communicate the concepts
    to businesspeople, I refer to it as behavioral grouping, which describes the key
    result in plain English. If you are formally trained, you’ll also find that I
    stick to a basic and intuitive kind of dimension reduction, but I want to caution
    you against thinking of this as a “dumbed-down” approach. The approach taken is
    deliberately simple. But while it is not optimal in the usual statistical sense,
    it is optimized for explainability. It is also excellent for robustness and out-of-sample
    predictive performance in the face of messy data and a problem that never stops
    changing (churn is nonstationary). In my experience, extracting the maximum information
    from a dimension reduction with more complicated methods does not lead to better
    performance in churn prediction. For interested readers, this chapter ends with
    a sidebar comparing the results using the methods in this chapter with results
    obtained from standard dimension reduction using principal component analysis
    (PCA).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你接受过数据科学或统计学的正规培训，你可能会认识到这一章节涵盖了降维的概念和实践，并且是线性代数的一个快速课程。但是，由于需要将概念传达给商业人士，我将其称为行为分组，它用简单的英语描述了关键结果。如果你接受过正规培训，你也会发现我坚持使用一种基本且直观的降维方法，但我想要提醒你，不要将这种方法视为“简化”的方法。采取的方法是有意为之的简单。虽然它从通常的统计意义上来说不是最优的，但它优化了可解释性。它对于面对混乱的数据和不断变化的问题（流失是非平稳的）的鲁棒性和样本外预测性能也非常出色。根据我的经验，使用更复杂的方法从降维中提取最大信息并不会导致在流失预测中的性能更好。对于感兴趣的读者，这一章节以一个侧边栏结束，比较了本章中使用的方法与使用主成分分析（PCA）进行标准降维得到的结果。
- en: 6.1 Correlation between behaviors
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.1 行为之间的相关性
- en: If you have two customer behaviors that you think are related, start by objectively
    measuring how they are related. The most practical way to do this is by measuring
    correlation, which is the subject of this section. You will learn what correlation
    between customer behaviors means and see demonstrations in customer behavioral
    data with case studies. Then you’ll learn how to calculate and visualize correlations
    between pairs of metrics as well as between all the metrics in a dataset.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你认为有两种客户行为是相关的，首先从客观上测量它们是如何相关的。最实际的方法是通过测量相关性来完成，这是本节的主题。你将了解客户行为之间的相关性意味着什么，并将在案例研究中看到客户行为数据的演示。然后，你将学习如何计算和可视化成对指标之间的相关性，以及数据集中所有指标之间的相关性。
- en: 6.1.1 Correlation between pairs of metrics
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1.1 指标对之间的相关性
- en: Two metrics or behaviors are said to be correlated when a customer who has a
    high value on the first metric also has a high value on the second metric, and
    a different customer with a low value on the first metric also has a low value
    on the second. You can also describe correlation by saying that an increase in
    the first metric is associated with an increase in the second metric, in the sense
    that if a customer increased one behavior, they also tend to increase the other
    behavior (and the associated metrics).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个在第一个指标上有高值的客户也在第二个指标上有高值，而一个在第一个指标上有低值的客户也在第二个指标上有低值时，我们说这两个指标或行为是相关的。你也可以通过说第一个指标的增加与第二个指标的增加相关联来描述相关性，在这种意义上，如果一个客户增加了一种行为，他们也有可能增加另一种行为（以及相关的指标）。
- en: DEFINITION Correlation between a pair of metrics or behaviors is a measure of
    the consistency with which an increase (or decrease) in one metric or behavior
    is associated with an increase (or decrease) in the other.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 定义：一对指标或行为之间的相关性是衡量一个指标或行为增加（或减少）与另一个指标或行为增加（或减少）之间一致性的度量。
- en: That’s the idea of correlation. There is also a measurement of correlation called
    the correlation coefficient, which is also often simply called the correlation.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是相关性的概念。还有一种称为相关系数的相关性度量，通常也简单地称为相关性。
- en: 'DEFINITION The correlation coefficient is a measurement of correlation that
    can range from -1.0 to 1.0:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 定义：相关系数是衡量相关性的一个度量，其范围可以从-1.0到1.0：
- en: 1.0 correlation between two metrics means that an increase in one metric is
    always associated with the same increase in another metric.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1.0的相关性意味着一个指标的增加总是与另一个指标相同的增加相关联。
- en: Negative correlation means that the association is a decrease of one metric
    when the other metric increases.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 负相关意味着当一个指标增加时，另一个指标会减少。
- en: It is easiest to imagine 1.0 correlation when the increase is 1:1 (an increase
    of 1 in the first metric corresponds to an increase of 1 in the second metric),
    but it can also be any ratio (1:2, 2:1, and so forth) when the correlation is
    the same. That’s why the correlation depends on the consistency of the association
    between two metrics but not the exact magnitude of the ratio. Correlation can
    also be between two metrics with any measurement units or scale (logins, downloads,
    views, etc.).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当增加是1:1（第一个指标增加1对应第二个指标增加1）时，最容易想象1.0的相关性，但相关性相同的情况下，也可以是任何比例（1:2、2:1等等）。这就是为什么相关性取决于两个指标之间关联的一致性，而不是比例的精确大小。相关性也可以存在于任何测量单位或刻度的两个指标之间（登录、下载、查看等）。
- en: NOTE Consistency in the relationship means that a certain amount of increase
    in one metric results in a proportional amount of increase in the other as given
    by a specific ratio.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：关系的一致性意味着一个指标的一定程度的增加会导致另一个指标按特定比例成比例增加。
- en: Figure 6.1 shows example pairs of metrics with different degrees of correlation,
    taken from the case studies of companies introduced in earlier chapters. Scatterplots
    show the values of two different metrics by plotting each observation as a point
    with one metric on each axis. Each point in figure 6.1 represents two metrics
    from a single observation out of the dataset; the complete set of points is all
    the paired values from those two metrics.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1展示了不同相关程度的指标对示例，这些示例来自前面章节中介绍的公司案例研究。散点图通过在每个轴上绘制每个观察值作为一个点来显示两个不同指标的价值。图6.1中的每个点代表数据集中单个观察值中的两个指标；这些点的完整集合是这两个指标的所有成对值。
- en: '![](../Images/6-01.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6-01.png)'
- en: Figure 6.1 Case studies for Klipfolio, Broadly, and Versature that illustrate
    different levels of positive correlation
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1 Klipfolio、Broadly和Versature的案例研究，展示了不同程度的正相关
- en: Figure 6.1A shows highly correlated metrics with a correlation above 0.95 (0.98,
    to be exact). In practice, you’ll never see a 1.0 correlation between two metrics
    (unless you accidentally calculate the same metric twice), but you might see metrics
    that are highly correlated, like those shown in figure 6.1A. These are closely
    related metrics from Klipfolio’s dashboard editor. (Klipfolio, introduced in chapter
    1, is an SaaS product for business dashboards.)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1A显示了相关性超过0.95（确切地说为0.98）的高度相关指标。在实践中，你永远不会看到两个指标之间有1.0的相关性（除非你意外地计算了两次相同的指标），但你可能会看到像图6.1A中那样高度相关的指标。这些是Klipfolio仪表板编辑器中的紧密相关指标。（Klipfolio在第1章中介绍，是一种用于企业仪表板的SaaS产品。）
- en: When you plot a set of observations that are highly correlated, they are arranged
    in an almost diagonal line. At a 1.0 correlation, the points would be precisely
    on a diagonal line.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当你绘制一组高度相关的观察值时，它们会排列成几乎对角线的线。在1.0的相关性下，点将精确地位于对角线上。
- en: Correlation measurements higher than 0.7 are considered a high correlation.
    Figure 6.1B shows a pair of metrics from Broadly for the number of customers added
    and the number of asks presented, which have 0.88 correlation. (Broadly, introduced
    in chapter 1, helps businesses manage their online presence.) Another metric showing
    a moderately high degree of correlation (0.75) is shown in figure 6.1C, which
    is the metric scores for local calls and domestic calls from Versature. (Versature,
    introduced in chapter 1, provides cloud-based business communication solutions.)
    For metrics with a relatively high correlation, points in these scatterplots tend
    to lie in some kind of ellipse or oval that is at a diagonal orientation.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 超过0.7的相关性测量被认为是高度相关。图6.1B显示了Broadly中客户增加数和展示请求数这对指标，它们的相关性为0.88。（Broadly在第1章中介绍，帮助企业管理其在线存在。）图6.1C显示了Versature的本地通话和国内通话指标分数，这显示了中等程度的高度相关性（0.75）。（Versature在第1章中介绍，提供基于云的企业通信解决方案。）对于相对高度相关的指标，这些散点图中的点往往位于某种斜向的椭圆或椭圆形中。
- en: Correlation measurements in the range of around 0.3 to 0.7 are moderately correlated
    and are illustrated in figures 6.1D and 6.1E. Figure 6.1D is a moderate correlation
    of 0.57 and shows the same two metrics for local and domestic calls from Versature.
    In this case, the metrics are shown on their natural scale rather than as scores.
    Note that the metric scores are significantly more correlated than the underlying
    metric. This is often the case when metrics are skewed, as described in chapter
    5.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 大约在0.3到0.7范围内的相关性测量被认为是适度相关的，并在图6.1D和图6.1E中展示。图6.1D是0.57的适度相关性，展示了Versature的本地和国内通话的相同两个指标。在这种情况下，指标是在其自然尺度上显示的，而不是作为分数。请注意，指标分数与基础指标的相关性显著更高。正如第5章所述，当指标有偏斜时，这种情况经常发生。
- en: TAKEAWAY Metric scores are often more correlated than the underlying metrics
    on their natural scale, especially when the metrics are heavily skewed. This is
    another important reason for using metric scores in your analysis.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 吸收要点 指标分数通常比其自然尺度上的基础指标具有更高的相关性，尤其是在指标严重偏斜时。这是在分析中使用指标分数的另一个重要原因。
- en: 'Figure 6.1E shows two metrics for Klipfolio with weaker but still moderate
    correlation (0.31). These are the metric scores for the number of data sources
    and the number of Klips edited. In scatterplots for moderately correlated metrics,
    the points tend to lie closer to the diagonal than not, but there is much less
    structure. Figure 6.1F shows two metrics for Broadly that are even more weakly
    correlated (0.18). These are metrics for the number of transactions added and
    the number of customer promoters (customers who give positive reviews). Businesses
    with more transactions tend to have more promoters, but the relationship is weak,
    and there are many outliers: some observations are high in one metric but low
    in another, leading to points close to both axes.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1E展示了Klipfolio的两个具有较弱但仍然适中的相关性（0.31）的指标。这些是数据源数量和编辑的Klip数量指标。在适度相关的指标的散点图中，点倾向于靠近对角线，但结构较少。图6.1F展示了Broadly的两个具有更弱相关性（0.18）的指标。这些是添加交易数量和客户推广者（给出正面评价的客户）数量指标。交易数量更多的企业往往有更多的推广者，但关系较弱，并且有许多异常值：一些观察值在一个指标上很高，而在另一个指标上很低，导致点靠近两个轴。
- en: '![](../Images/6-02.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6-02.png)'
- en: Figure 6.2 Case studies for Klipfolio, Broadly, and Versature that illustrate
    zero correlation
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2 Klipfolio、Broadly和Versature的零相关性案例研究
- en: Figure 6.2 shows examples of metrics that have zero correlation or close to
    it; these are commonly called uncorrelated. Although scatterplots of metrics with
    a high correlation usually look similar, there is a lot more variety in metrics
    with low and near-zero correlations. Figure 6.2A shows two metrics from Broadly
    that have exactly 0.0 correlation. These metrics are for viewing the customer
    list and sending follow-up emails. In this case, there is no relationship, and
    the points tend to lie close to the origin (equally spaced with respect to both
    axes). Figure 6.2B shows Versature’s metric for local calls and account tenure.
    Account tenure is uniformly distributed across the x-axis up to the maximum, but
    there is no relationship with the number of local calls. Figure 6.2C shows an
    example from Klipfolio of near-zero correlation between the metrics for adding
    templates and switching orientations. The add template metric is rare, so most
    observations have values near zero on that axis, and there is no relationship
    to the other metric (orientation switches).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2展示了具有零相关性或接近零相关性的指标示例；这些通常被称为不相关。尽管具有高相关性的指标的散点图通常看起来很相似，但在低相关性和接近零相关性的指标中存在更多多样性。图6.2A展示了Broadly的两个具有精确0.0相关性的指标。这些指标用于查看客户列表和发送跟进邮件。在这种情况下，两者之间没有关系，点倾向于靠近原点（在两个轴上均匀分布）。图6.2B展示了Versature的本地通话和账户期限指标。账户期限在x轴上均匀分布到最大值，但与本地通话次数没有关系。图6.2C展示了Klipfolio的一个示例，其中添加模板和切换方向的指标之间存在接近零的相关性。添加模板的指标很少见，因此大多数观察值在该轴上的值接近零，并且与另一个指标（方向切换）没有关系。
- en: Figure 6.3 shows correlation patterns that you are unlikely to see in your data.
    No examples were available from case studies, so these were made from simulated
    data using the code on the book’s website ([www.manning.com/books/fighting-churn-with-data](http://www.manning.com/books/fighting-churn-with-data))
    and in this book’s GitHub repository ([https://github.com/carl24k/fight-churn/tree/
    master/data-generation](https://github.com/carl24k/fight-churn/tree/master/data-generation)).
    Figure 6.3A shows an example where two behavioral metrics both lie in a nonzero
    range with few outliers and no skew and yet still have no correlation. Scatterplots
    of such metrics have points that tend to lie in a sphere, and this is the classic
    example of uncorrelated metrics in a statistics textbook. But surprisingly, it
    is rare to see it in customer behaviors. Usually, when two customer metrics have
    few zeros and no extreme values, there is some degree of correlation.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.3 展示了你在数据中不太可能看到的相关性模式。案例研究中没有可用的示例，因此这些是通过在本书网站上提供的代码（[www.manning.com/books/fighting-churn-with-data](http://www.manning.com/books/fighting-churn-with-data)）和本书的
    GitHub 仓库（[https://github.com/carl24k/fight-churn/tree/master/data-generation](https://github.com/carl24k/fight-churn/tree/master/data-generation)）中使用的代码进行模拟数据生成的。图
    6.3A 展示了一个示例，其中两个行为指标都位于非零范围内，几乎没有异常值和偏斜，但仍然没有相关性。此类指标的散点图中的点倾向于位于球体中，这是统计学教科书中不相关指标的典型例子。但令人惊讶的是，在客户行为中很少看到这种情况。通常，当两个客户指标几乎没有零值和极端值时，它们之间会有某种程度的相关性。
- en: '![](../Images/6-03.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/6-03.png)'
- en: Figure 6.3 Simulations illustrating rare behavioral correlations from simulated
    data
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.3 展示了从模拟数据中得出的罕见行为相关性
- en: In the figure, 6.3B and 6.3C show examples of low and moderate negative correlations,
    respectively. Like positive correlations, the points in a scatterplot tend to
    lie in an ellipse, but in this case, the ellipse is at a diagonal orientation
    sloping down to the right rather than up to the left. This shows that an increase
    in one behavior is associated with a decrease in the other behavior.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在图中，6.3B 和 6.3C 分别展示了低度和中度的负相关性示例。与正相关类似，散点图中的点倾向于位于一个椭圆中，但在这个例子中，椭圆是斜向右下方倾斜的，而不是向左上方倾斜。这表明一种行为的增加与另一种行为的减少相关联。
- en: It’s rare that you’ll observe negative correlations between count metrics based
    on customer events because generally customers with more events do more of everything.
    That said, there are other types of more advanced behavioral metrics (see the
    next chapter) that can have negative correlations with other metrics in your dataset.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于客户事件的计数指标之间观察到负相关性是很少见的，因为通常拥有更多事件的客户会做更多的事情。话虽如此，还有其他类型的更高级的行为指标（参见下一章），这些指标可以与数据集中的其他指标有负相关性。
- en: 6.1.2 Investigating correlations with Python
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1.2 使用 Python 调查相关性
- en: Listing 6.1 shows a short Python program to create scatterplots and correlation
    measurements like the ones shown in the last section. The program assumes a dataset
    was created and saved using the code in chapter 4 (specifically listings 4.1,
    4.2, 4.4, and 4.5). Most of listing 6.1 handles the details of loading the dataset
    and making the scatterplot with annotations.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 6.1 展示了一个简短的 Python 程序，用于创建散点图和相关性测量，类似于上一节中展示的内容。该程序假设数据集是使用第 4 章中的代码（特别是列表
    4.1、4.2、4.4 和 4.5）创建并保存的。列表 6.1 的大部分内容处理了加载数据集和带有注释的散点图的细节。
- en: The correlation is calculated in a single call to the Pandas function `Series.corr`.
    If you want to know how the correlation coefficient was calculated, there are
    many resources online and in statistics textbooks (search for “Pearson” correlation
    coefficient, for example). The scatterplot is created with a call to the Matplotlib
    function `pyplot.scatter`. As in previous plot examples, it is important to provide
    detailed labeling and annotation of the plot, so your business colleagues know
    what they are looking at (and so you can remember what you plotted when you look
    at it sometime later).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 相关性是通过 Pandas 函数 `Series.corr` 的单个调用计算的。如果你想知道相关性系数是如何计算的，网上和统计学教科书中有许多资源（例如，搜索“皮尔逊相关性系数”）。散点图是通过调用
    Matplotlib 函数 `pyplot.scatter` 创建的。与之前的绘图示例一样，提供详细的标签和注释对于图表非常重要，这样你的商业同事就能知道他们在看什么（并且当你稍后再次查看时，你可以记住你绘制了什么）。
- en: '![](../Images/6-04.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/6-04.png)'
- en: Figure 6.4 Result of running listing 6.1 on the simulated metrics, showing scores
    for likes per month and posts per month
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.4 展示了在模拟指标上运行列表 6.1 的结果，显示了每月点赞数和每月发帖数的得分
- en: Figure 6.4 shows the result of running listing 6.1 on the default simulated
    dataset. You should try it out on a pair of metrics yourself. Assuming you have
    set up your environment (instructions in the README for the book in the GitHub
    repository at [https://github.com/carl24k/fight-churn](https://github.com/carl24k/fight-churn)),
    and you are using the Python wrapper program, run listing 6.1 with
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.4 显示了在默认模拟数据集上运行列表 6.1 的结果。你应该亲自尝试一对度量。假设你已经设置了你的环境（GitHub 仓库中书籍的 README
    中的说明，[https://github.com/carl24k/fight-churn](https://github.com/carl24k/fight-churn)），并且你正在使用
    Python 包装程序，使用以下命令运行列表 6.1：
- en: '[PRE0]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'That should give you a .png file with a scatterplot between the metrics post_per_month
    and like_per_month, which looks like figure 6.4\. You can also check the results
    on different pairs of metrics by running the alternative versions by adding the
    version arguments up to 16:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会给你一个包含度量 post_per_month 和 like_per_month 之间散点图的 .png 文件，其外观类似于图 6.4。你也可以通过运行带有版本参数的替代版本（最多到
    16）来检查不同度量对的结果：
- en: '[PRE1]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: That command generates the pair plots of posts per month as both scores and
    natural scale metrics. That’s just a small number out of all the possible pair
    plots from the dataset, but it will show you a little variety for possible correlation
    patterns and the difference it makes when the metrics are converted to scores.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令生成了每月帖子数作为得分和自然尺度度量的配对图。这只是从数据集中所有可能的配对图中的一小部分，但它将展示可能的关联模式的一些多样性，以及当度量转换为得分时产生的差异。
- en: Listing 6.1 Analyzing correlation in pairs of metrics
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 6.1 分析度量对的关联性
- en: '[PRE2]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ① Checks the dataset path
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ① 检查数据集路径
- en: ② Loads the dataset into a DataFrame
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ② 将数据集加载到 DataFrame 中
- en: ③ Selects the two metrics that will be analyzed
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 选择将要分析的度量
- en: ④ Calculates the correlation between two series
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 计算两个序列之间的相关性
- en: ⑤ Makes a scatterplot from two series
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 从两个序列制作散点图
- en: ⑥ Adds axis labels
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 添加轴标签
- en: ⑦ Prints the correlation measurement in the title
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ⑦ 在标题中打印相关测量值
- en: ⑧ Adjusts the layout to accommodate the labels and title
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ⑧ 调整布局以适应标签和标题
- en: ⑨ Saves the figure in .png format
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ⑨ 将图形保存为 .png 格式
- en: 6.1.3 Understanding correlations between sets of metrics with correlation matrices
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1.3 理解通过相关矩阵度量集之间的相关性
- en: Scatterplots are useful for understanding the relationships between pairs of
    metrics that you are interested in, but they are an inefficient way to investigate
    the correlations between the pairs in a large set of metrics. That’s because if
    you have a moderate number of metrics, there will be a much larger number of combinations
    (for the mathematically inclined, for N metrics, there are N × (N - 1) / 2 combinations,
    as illustrated later). You will learn a much more efficient way to look at a large
    number of correlations in a dataset next; this is called a correlation matrix.
    A matrix is a table (of data) where all of the entries are numbers, and a correlation
    matrix is a table of all the correlations in a dataset. That is, every entry in
    the correlation matrix is a correlation coefficient between two metrics.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 散点图对于理解你感兴趣的度量对之间的关系很有用，但它们是调查大量度量对之间相关性的低效方式。这是因为如果你有相当数量的度量，组合的数量会大得多（对于数学爱好者，对于
    N 个度量，有 N × (N - 1) / 2 种组合，如后面所示）。你将在下一节学习一种更有效的方法来查看数据集中的大量相关性；这被称为相关矩阵。矩阵是一个表格（数据），其中所有条目都是数字，相关矩阵是数据集中所有相关性的表格。也就是说，相关矩阵中的每个条目都是两个度量之间的相关系数。
- en: DEFINITION A correlation matrix is a table of all of the pairwise correlation
    coefficients between the metrics in a dataset.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 定义：相关矩阵是数据集中所有度量之间的成对相关系数的表格。
- en: Figure 6.5 shows an example of creating a correlation matrix from a simple dataset.
    The dataset was simulated to have five metrics, all counts per month of events
    (likes, reads, replies, sends, and writes) in a messaging application. The metrics
    are converted to scores because that can show more of a correlation. Each pair
    of metrics has its own relationship that can be investigated with a scatterplot
    and an individual correlation calculation. To display all of the correlations
    in a single matrix, the metrics are put on both the rows and the columns of a
    table (in the same order). The correlation between each pair is entered at the
    intersection of that pair of metrics in the table. That way, every correlation
    can be looked up in a single table.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.5 展示了从简单数据集中创建相关矩阵的示例。该数据集模拟了五个度量，即每月事件（点赞、阅读、回复、发送和撰写）的计数，在一个消息应用中。这些度量被转换为分数，因为这样可以显示更多的相关性。每一对度量都有自己的关系，可以通过散点图和单独的相关计算来研究。为了在一个单一矩阵中显示所有相关性，度量被放置在表格的行和列中（相同的顺序）。每一对度量之间的相关性被输入到表格中该对度量的交叉点上。这样，每个相关性都可以在单个表格中查找。
- en: '![](../Images/6-05.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6-05.png)'
- en: Figure 6.5 A correlation matrix (bottom) summarizes all pairwise correlations
    among the metrics in a dataset (top).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.5 一个相关矩阵（底部）总结了数据集中所有度量之间的成对相关性（顶部）。
- en: NOTE Correlation matrices are often color coded by value because it makes it
    easier to identify high and low correlations visually; a color-coded correlation
    matrix is often referred to as a heatmap.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：相关矩阵通常按值着色，因为这样可以更容易地通过视觉识别高和低相关性；着色相关矩阵通常被称为热图。
- en: The correlation matrices in this book are grayscale so they can be printed,
    but I recommend using full-color heatmaps in all other situations (both for your
    own analysis and for presentations to your colleagues).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的相关矩阵是灰度图，因此可以打印，但我建议在其他所有情况下（无论是自己的分析还是向同事展示）都使用全色热图。
- en: 'Because metrics are in the rows and the columns of the correlation matrix,
    there are two intersections in the matrix for every pair of metrics. These are
    in locations that are symmetrical with respect to a diagonal line drawn through
    the matrix from the top left to the bottom right. There are two options to deal
    with this redundancy: show every entry twice, or omit half the matrix. The most
    common approach is to show every entry twice; consequently, the correlation matrix
    is symmetrical across the diagonal. That can make it easier to find the correlation
    you are looking for because, whether you start from a row or a column, you find
    the entry just as fast either way. The alternative approach is to omit half of
    the matrix either above or below the diagonal. This leads to a cleaner look that
    is better for presentations. Also, every metric has an intersection with itself
    in the correlation matrix, and this lies on the diagonal of the matrix because
    the metrics are in the same order in the rows and columns.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 因为度量位于相关矩阵的行和列中，所以对于每一对度量，矩阵中都有两个交叉点。这些交叉点在从左上角到右下角穿过矩阵的对角线两侧是对称的。有两种处理这种冗余的方法：显示每个条目两次，或者省略一半的矩阵。最常见的方法是显示每个条目两次；因此，相关矩阵在对角线上是对称的。这可以更容易地找到你想要的关联，因为无论你从行还是从列开始，你都能以相同速度找到条目。另一种方法是省略对角线以上或以下的一半矩阵。这会导致更干净的外观，更适合演示。此外，每个度量在相关矩阵中都有一个与自身的交叉点，并且这个交叉点位于矩阵的对角线上，因为度量在行和列中的顺序是相同的。
- en: By definition, every metric has a correlation of 1.0 with itself. Although that
    information is useless, it is mathematically necessary for algorithms involving
    correlation matrices. But showing the diagonal 1.0s in a matrix can be distracting
    in a presentation, and therefore it can be omitted.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 根据定义，每个度量与其自身的相关性为1.0。尽管这个信息没有用，但对于涉及相关矩阵的算法来说在数学上是必要的。但在演示中显示矩阵中的对角线1.0可能会分散注意力，因此可以省略。
- en: 6.1.4 Case study correlation matrices
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1.4 案例研究相关矩阵
- en: Figure 6.6 shows a correlation matrix from Klipfolio’s case study as a heatmap.
    There are around 70 metrics, and they are ordered to show the relationships of
    high correlation between different types of metrics. Six groups of metrics are
    highly correlated. The single largest group comprises metrics for the most common
    ways to use the product. There are also five other smaller groups of metrics that
    relate to other aspects of the products, and some metrics are not strongly correlated
    to any other metrics. This structure is fairly typical, although there are not
    always so many well-defined groups. The technique to produce this order is shown
    later in listing 6.4.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.6展示了Klipfolio案例研究中的相关矩阵，以热图的形式呈现。大约有70个指标，它们被排序以显示不同类型指标之间高度相关的关联。有六个高度相关的指标组。最大的单个组包括使用产品最常见方式的指标。还有五个其他较小的指标组，它们与产品的其他方面相关，有些指标与任何其他指标的相关性不强。这种结构相当典型，尽管并不总是有这么多定义良好的组。产生这种顺序的技术将在列表6.4中展示。
- en: '![](../Images/6-06.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6-06.png)'
- en: Figure 6.6 Klipfolio’s metric correlations, ordered to show the relationships
    of high correlation
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.6 Klipfolio的指标相关性，按顺序显示高度相关的关联
- en: Figure 6.7 shows the correlation matrix from Klipfolio’s case study with the
    metrics organized alphabetically. These are the same metrics as in figure 6.6;
    only the order is different. The organized matrix in figure 6.6 shows much more
    structure than the alphabetized matrix in figure 6.7\. But something like figure
    6.7 is what you are more likely to see the first time you look at your correlations
    in a heatmap (listing 6.2). Alphabetic ordering of the metrics reveals a structure
    where metrics that start with the same word are usually related. Still, there
    are many exceptions, so the related groups are not as evident as in figure 6.6.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.7展示了Klipfolio案例研究中的相关矩阵，指标按字母顺序排列。这些指标与图6.6中的指标相同；只是顺序不同。图6.6中组织良好的矩阵比图6.7中按字母顺序排列的矩阵结构更明显。但像图6.7这样的结构是你第一次查看热图（列表6.2）时更有可能看到的。指标的字母顺序揭示了一个结构，其中以相同单词开头的指标通常相关。尽管如此，还有很多例外，因此相关组不像图6.6中那样明显。
- en: '![](../Images/6-07.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6-07.png)'
- en: Figure 6.7 Klipfolio’s correlation matrix showing alphabetically arranged metrics
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.7 Klipfolio的相关矩阵，显示按字母顺序排列的指标
- en: 6.1.5 Calculating correlation matrices in Python
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1.5 在Python中计算相关矩阵
- en: Listing 6.2 is a short Python program to create correlation matrices like those
    shown in figures 6.6 and 6.7\. The result of running listing 6.2 on the simulated
    dataset is illustrated in figure 6.8\. The program assumes that a dataset was
    created and saved using the code in chapter 4\. Recall that this dataset is a
    table with one observation of a customer on each row, and one metric in each column.
    Most of listing 6.1 handles the details of loading a dataset and saving the result.
    The formatting was done in a free spreadsheet, as described later.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.2是一个简短的Python程序，用于创建如图6.6和6.7所示的相关矩阵。在模拟数据集上运行列表6.2的结果如图6.8所示。该程序假设使用第4章中的代码创建并保存了一个数据集。回想一下，这个数据集是一个表格，每行有一个客户的观察结果，每列有一个指标。列表6.1的大部分内容处理加载数据集和保存结果的细节。格式化将在后面描述的免费电子表格中进行。
- en: '![](../Images/6-08.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6-08.png)'
- en: Figure 6.8 Result of running listing 6.2 on the simulated dataset
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.8 在模拟数据集上运行列表6.2的结果
- en: In listing 6.2, the correlation matrix is calculated with a call to the Pandas
    `Dataframe.corr` function. Note that listing 6.2 does not attempt to create a
    heatmap image like the examples in figures 6.6 and 6.7; the function stops after
    saving the correlation matrix data in a comma-separated (.csv) file. The reason
    for this is that it’s not practical to make a heatmap for a large number of metrics
    in Python. If there are more than 15 to 20 metrics, either the heatmap image must
    be enormous, or the metric names and correlation values are too small to read
    (see figures 6.6 and 6.7 for examples).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表6.2中，通过调用Pandas `Dataframe.corr`函数计算相关矩阵。请注意，列表6.2并不试图创建如图6.6和6.7中的示例那样的热图图像；该函数在将相关矩阵数据保存到逗号分隔的(.csv)文件后停止。这样做的原因是在Python中为大量指标制作热图并不实用。如果有超过15到20个指标，热图图像必须非常大，或者指标名称和相关性值太小而无法阅读（参见图6.6和6.7中的示例）。
- en: TIP It’s not practical to explore large correlation heatmaps in static images.
    You should definitely inspect the correlation heatmap closely, but it is usually
    easier to view it in a spreadsheet application. Fix the metric name row and column
    to make the matrix scrollable, and use conditional formatting to add the heatmap
    colors. For presentations, you can export various formatted versions.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: TIP 在静态图像中探索大型相关性热图并不实用。你绝对应该仔细检查相关性热图，但通常在电子表格应用程序中查看它更容易。固定指标名称的行和列，使矩阵可滚动，并使用条件格式化添加热图颜色。对于演示，你可以导出各种格式版本。
- en: Listing 6.2 Calculating the correlation matrix for a dataset in Python
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 6.2 在 Python 中计算数据集的相关矩阵
- en: '[PRE3]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ① Checks the path
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ① 检查路径
- en: ② Loads the dataset into a DataFrame and sets the index
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ② 将数据集加载到 DataFrame 中并设置索引
- en: ③ Sorts the columns alphabetically
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 按字母顺序排序列
- en: ④ Calculates the correlation matrix with the Dataframe.corr function
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 使用 Dataframe.corr 函数计算相关矩阵
- en: ⑤ Saves the correlation matrix in .csv format
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 以 .csv 格式保存相关矩阵
- en: You should run listing 6.2 and confirm that it gives you a similar result on
    your own dataset. If you are using the wrapper program to run the listings, by
    now you know that means changing the command-line parameters to `—chapter` `6`
    `—listing` `2`. The program saves the data in a .csv file (the location of which
    will be printed by the wrapper program).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该运行列表 6.2 并确认它在你自己的数据集上给出相似的结果。如果你正在使用包装程序来运行列表，到现在你应该知道这意味着将命令行参数更改为 `—chapter`
    `6` `—listing` `2`。程序将数据保存为 .csv 文件（其位置将由包装程序打印出来）。
- en: 6.2 Averaging groups of behavioral metrics
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.2 平均行为指标组
- en: Suppose that you have 5 or 10 customer behaviors where the metrics are moderately
    to highly correlated. What do you do? A foundational technique for handling highly
    correlated metrics is to average the scores of the correlated metrics together.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有 5 或 10 个客户行为，其中指标中度到高度相关。你该怎么办？处理高度相关指标的基础技术是将相关指标的得分平均在一起。
- en: 6.2.1 Why you average correlated metric scores
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.1 为什么你要平均相关指标得分
- en: 'Handling multiple correlated metrics individually in churn analysis and customer
    segmentation is problematic for two interrelated reasons:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在客户流失分析和客户细分中单独处理多个相关指标存在两个相互关联的问题：
- en: The churn relationships you observe in two different cohort analyses are not
    integrated in the sense that there is no way to understand how customers in different
    cohorts on different metrics relate to each other. What does it mean if a particular
    customer is in the third cohort on one metric and the sixth cohort on another
    in two related activities? Averaging them together is a way to handle this, as
    will be explained.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你在两个不同的群体分析中观察到的客户流失关系在整合意义上是没有的，因为无法理解不同群体在不同指标上的客户是如何相互关联的。如果一个特定客户在一个指标上位于第三个群体，而在另一个相关活动中位于第六个群体，这意味着什么？将它们平均在一起是一种处理方法，这将在下面解释。
- en: An information overload comes from looking at too many metrics. Remember that
    behavioral metrics usually do not measure something that is directly causal of
    churn or retention. It is more common that your behavioral metrics are only associated
    with churn. Given a large number of metrics associated with churn (but not causal),
    there is no way to know which metrics and events are most important.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信息过载来自于查看过多的指标。记住，行为指标通常不衡量直接导致客户流失或保留的东西。更常见的是，你的行为指标仅与客户流失相关。给定与客户流失相关的大量指标（但不是因果），无法知道哪些指标和事件最重要。
- en: After the correlated metric scores are averaged together, they are often easier
    to use in a churn cohort analysis for customer segmentation. As explained in the
    last chapter, averaging together many customers to form the cohorts shows the
    influence of a metric on churn by averaging away the individual circumstances
    that shape behavior. In the same way, averaging together groups of metrics further
    reduces random variation and makes the underlying relationship between churn and
    a set of behaviors clearer.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在将相关指标得分平均后，它们在客户细分中的客户流失分析中通常更容易使用。正如上一章所解释的，将许多客户合并成群体以形成群体，可以通过平均掉影响行为的个体情况来显示指标对客户流失的影响。同样，将一组指标的平均值进一步减少随机变化，使客户流失与一系列行为之间的基本关系更加清晰。
- en: What does it mean to average different metric scores together? Remember that
    different metrics usually mean completely different things, like logging in and
    editing a document or viewing a video and liking it. Does it even make sense to
    average logins and edits? Because there are probably going to be a lot more edits
    than logins, it would be unbalanced. And does it make sense to average views and
    likes of content? There are going to be a lot more views than likes, so it’s not
    clear such an average is meaningful. The problem is worse if different metrics
    have units like monetary values or time. Considering the telecommunications context,
    what would an average of total call duration and overage charges mean? Actually,
    this is no problem at all; this is another advantage of having converted the metrics
    to scores.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 将不同的指标分数平均在一起意味着什么？记住，不同的指标通常意味着完全不同的事物，比如登录和编辑文档或观看视频并点赞。将登录和编辑平均在一起有意义吗？因为可能编辑的次数会比登录的次数多，这会导致不平衡。将内容的观看和点赞平均在一起有意义吗？观看的次数可能会比点赞的次数多，所以这样的平均可能没有意义。如果不同的指标有货币价值或时间这样的单位，问题会更严重。在电信的背景下，总通话时长和超额费用的平均值意味着什么？实际上，这根本不是问题；这是将指标转换为分数的另一个优势。
- en: TAKEAWAY Because each metric score measures the position of the customer with
    respect to the average, it is okay to average together scores of different types
    of metrics.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**总结**：因为每个指标分数衡量的是客户相对于平均水平的地位，所以将不同类型指标的分数平均在一起是可以的。'
- en: 'It does not make sense to average together different types of metrics when
    those metrics refer to different things if you are using the original units. But
    it is okay with scores: the average score describes the overall area of activity
    that those different metrics relate to. If someone is above average in both logins
    and edits with an SaaS product, it’s fair to call them an above-average user overall.
    If someone is below average in views and likes on a streaming video product, it
    makes sense to consider them a below-average user overall. And if someone is below
    average in calls and above average in overage charges on a telecommunications
    product, if you average the scores, they are just an average user.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用原始单位时，如果这些指标指的是不同的事物，将不同类型的指标平均在一起是没有意义的。但使用分数时则没有问题：平均分数描述了这些不同指标所关联的整体活动区域。如果某人在使用SaaS产品的登录和编辑方面都高于平均水平，那么称他们为整体上高于平均水平的用户是公平的。如果某人在流媒体视频产品的观看和点赞方面低于平均水平，那么将他们视为整体上低于平均水平的用户是有意义的。如果某人在电信产品中的通话次数低于平均水平，而在超额费用方面高于平均水平，如果你平均这些分数，他们只是一个普通用户。
- en: In fact, an average score on a group of metrics is often more useful than the
    separate scores. That’s because different metrics provide different ways of looking
    at the same area of activity that can substitute for each other. If a customer
    does not use a particular product feature but instead uses a related one, the
    average picks it up either way. You would miss the activity for some customers
    if you relied on a single metric. If a customer is high on one metric and low
    on another, in one churn cohort they would be in a low-risk cohort, and in the
    other they would be in a high-risk cohort. By averaging the two together, you
    get a better picture of the overall activity.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，一组指标的平均分数通常比单独的分数更有用。这是因为不同的指标提供了不同的方式来观察同一活动区域，它们可以相互替代。如果一个客户没有使用某个特定的产品功能，而是使用了一个相关的功能，平均分数会捕捉到这两种情况。如果你只依赖单一指标，你可能会错过某些客户的某些活动。如果一个客户在一个指标上得分高而在另一个指标上得分低，在一个客户流失群体中他们可能属于低风险群体，而在另一个群体中则属于高风险群体。通过将这两个指标的平均值结合起来，你可以得到一个更全面的总体活动图景。
- en: 6.2.2 Averaging scores with a matrix of weights (loading matrix)
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.2 使用权重矩阵（加载矩阵）平均分数
- en: Averaging together groups of correlated metric scores is a straightforward concept,
    but the implementation is a bit tricky because you may be doing this for a lot
    of metrics and observations. You are going to use a technique where you encode
    the groups in a matrix of weights to keep track of which metrics are in which
    groups and the weights needed to form the averages. Recall that a matrix is just
    a table where all the entries are numbers. A weight in this context means the
    multiplicative factor, 1/n, is needed to turn a sum into an average. This matrix
    of weights is known as a loading matrix.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 将相关度量指标分组求平均值是一个简单的概念，但实现起来有点棘手，因为你可能要对许多指标和观测值进行此类操作。你将使用一种技术，在权重矩阵中编码组，以跟踪哪些指标属于哪些组以及形成平均值所需的权重。回想一下，矩阵只是一个所有条目都是数字的表格。在这个上下文中，权重意味着乘法因子，1/n，需要将总和转换为平均值。这个权重矩阵被称为加载矩阵。
- en: DEFINITION A loading matrix is a table of weights to apply to metrics in order
    to form averages.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 定义：加载矩阵是一个表格，用于应用权重到度量指标上，以便形成平均值。
- en: The loading matrix not only keeps track of the metrics in each group but also
    provides an efficient implementation of the averaging computation (more in the
    next section). I’m going to walk you through an example with just a small number
    of metrics. The technique might seem overly complex for a toy problem like the
    example, but it scales well to dozens or even hundreds of metrics and large datasets.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 加载矩阵不仅跟踪每个组中的度量指标，还提供了平均计算的高效实现（下一节将详细介绍）。我将通过一个只有少量度量指标的示例来引导你。对于像示例这样的玩具问题，这项技术可能看起来过于复杂，但它可以很好地扩展到数十个甚至数百个度量指标和大型数据集。
- en: '![](../Images/6-09.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/6-09.png)'
- en: Figure 6.9 The process of grouping related metrics into averages using a matrix
    of weights
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.9 使用权重矩阵将相关度量指标分组求平均的过程
- en: 'Figure 6.9 demonstrates the averaging technique for a small dataset with 10
    observations and 6 metrics, continuing the example from figure 6.5\. Here is how
    it works:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.9演示了对于具有10个观测值和6个度量指标的小数据集的平均值技术，继续图6.5的示例。以下是它是如何工作的：
- en: The metrics for login, read, and reply events are averaged into one group because
    they are highly correlated. The metrics for send and write are averaged into another
    group, and the metric for like is left alone. These decisions are driven by an
    inspection of the small correlation matrix. (Later in this chapter, you will learn
    how to automatically discover groups in datasets with large numbers of metrics.)
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录、阅读和回复事件的度量指标被合并到一个组中，因为它们高度相关。发送和写入的度量指标被合并到另一个组中，而点赞的度量指标则保持不变。这些决策是由检查小的相关矩阵驱动的。（在本章的后面部分，你将学习如何自动在具有大量度量指标的数据集中发现组。）
- en: A loading matrix is defined with a shape that is the number of metrics by the
    number of groups (three by five, for the example). Also in the example, the weight
    matrix is shown with the groups arranged on the rows and the metrics in the columns;
    in practice, it is usually stored the other way (metrics in the rows and groups
    in the columns), but see the next section for details.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载矩阵的定义形状是度量指标的数量乘以组的数量（例如，三乘以五）。在示例中，权重矩阵显示组按行排列，度量指标按列排列；在实践中，通常以另一种方式存储（度量指标按行排列，组按列排列），但下一节将详细介绍。
- en: 'Each row for a group contains weights to form an average from the appropriate
    metrics and zeros for the others. The weight to form an average is one divided
    by the number of metrics in the group:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个组的行都包含用于从适当的度量指标形成平均值的权重，以及其他组的零值。形成平均值的权重是组中度量指标数量的倒数：
- en: For the row corresponding to group 1, there are weights of 1/3 (0.33) in each
    of the three columns for login, read, and reply, and zeros in the others. To form
    group 1, the weight of 0.33 is applied to the scores for login, read, and reply
    events. For the other metrics, zeros are shown in their place, indicating these
    are not used in group 1.
  id: totrans-117
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于对应于第1组的行，登录、阅读和回复三个列中的权重均为1/3（0.33），其他列中的权重为零。为了形成第1组，将0.33的权重应用于登录、阅读和回复事件的得分。对于其他度量指标，其位置显示为零，表示这些指标在第1组中未使用。
- en: For the row corresponding to group 2, there are weights of 1/2 (0.5) in each
    of the two columns for write and send, and zeros in the other.
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于对应于第2组的行，写入和发送两个列中的权重为1/2（0.5），其他列中的权重为零。
- en: For the row corresponding to group 3, the likes, there is a 1 in the weight
    column for it.
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于对应于第3组（点赞）的行，权重列中有一个1。
- en: To calculate the group averages, the metrics for each account are multiplied
    by the weights for each group, and then the results are added together.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了计算组平均值，每个账户的指标乘以每个组的权重，然后将结果相加。
- en: The resulting sums are the averages for each group.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结果之和是每个组的平均值。
- en: 6.2.3 Case study for loading matrices
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.3 加载矩阵案例研究
- en: 'Figure 6.10 shows the loading matrix created for the simulated social network
    data. Two groups are created:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.10显示了为模拟社交网络数据创建的加载矩阵。创建了两个组：
- en: 'A metric group for ad views, likes, and posts: the three most common metrics'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 广告查看、点赞和帖子的指标组：最常见的三个指标
- en: A metric group for messages and replies
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消息和回复的指标组
- en: If you look at the correlation matrix in figure 6.8, you can easily convince
    yourself that the metrics in these groups are highly correlated to each other
    and to the others, less so. (The formal method for discovering groups automatically
    is coming later in the chapter.)
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看图6.8中的相关矩阵，你可以很容易地让自己相信这些组中的指标彼此之间以及与其他指标的相关性很高，而与其他指标的相关性较低。（自动发现组的正式方法将在本章后面介绍。）
- en: 'At this point, I must call your attention to one feature of figure 6.10 that
    you are not expecting: the weights groups in the real loading matrices are a bit
    higher than 1/N, where N is the number of metrics in the group.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我必须提醒你注意图6.10的一个你预料不到的特征：实际加载矩阵中的权重略高于1/N，其中N是该组中的指标数量。
- en: '![](../Images/6-10.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/6-10.png)'
- en: Figure 6.10 Loading matrix for the simulation case study
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.10 模拟案例研究的加载矩阵
- en: The loading matrix still forms an average from the correlated scores, but the
    weights are boosted slightly above 1/N. I did not mention this detail earlier
    because the meaning is the same, and the concept is clearer when explained with
    1/*N* weights. For three metric groups, the weights are 0.41 instead of 0.33;
    and for two metric groups, the weights are 0.62 instead of 0.5\. The detail of
    the reasoning is explained in section 6.3.3 (it has to do with adjusting the standard
    deviation of the combined score).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 加载矩阵仍然从相关分数中形成平均值，但权重略高于1/N。我之前没有提到这个细节，因为其含义相同，并且当用1/*N*权重解释时，概念更清晰。对于三个指标组，权重是0.41而不是0.33；对于两个指标组，权重是0.62而不是0.5。推理的细节在6.3.3节中解释（这与调整组合分数的标准差有关）。
- en: 'Figure 6.11 shows the real loading matrix created in Klipfolio’s case study.
    Now the matrix is shown with the metrics on the rows and the groups in the columns;
    this is the transposition of the view in figure 6.9\. (Figure 6.9 shows the loading
    matrix transposed so the weights would visually align with the columns of data
    for illustrative purposes.) The reason for arranging the metrics in the rows and
    the groups in the columns is clear from figure 6.11: there are typically many
    more metrics than groups, so it’s much easier to read this way. Arranging the
    metrics along the rows is also the correct orientation for implementation of the
    averaging calculation, which the next section shows.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.11显示了Klipfolio案例研究中创建的实际加载矩阵。现在矩阵以指标为行，组为列显示；这是图6.9中视图的转置。（图6.9展示了转置的加载矩阵，以便权重在视觉上与数据列对齐，用于说明目的。）将指标排列在行中，将组排列在列中的原因在图6.11中很清楚：通常指标比组多得多，因此这样阅读更容易。将指标沿行排列也是平均计算的正确方向，下一节将展示这一点。
- en: '![](../Images/6-11.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/6-11.png)'
- en: Figure 6.11 Loading matrix for Klipfolio’s case study
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.11 Klipfolio案例研究的加载矩阵
- en: 'In the figure, you can see that the average weights are also not exactly 1/*N*
    : the first group of metrics consists of 28 metrics, so each metric is assigned
    a weight of 0.041, but 1/28 = 0.0357\. There are five other groups consisting
    of fewer than 10 metrics each, which all receive weighted entries in the matrix
    that are a bit above 1/N. There are also a few dozen other metrics that were not
    highly correlated enough to be grouped; these are only partially shown in figure
    6.11.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在图中，你可以看到平均权重也不完全是1/*N*：第一个指标组包含28个指标，因此每个指标分配的权重为0.041，但1/28 = 0.0357。还有五个其他组，每个组包含不到10个指标，它们在矩阵中的加权条目略高于1/N。还有一些几十个其他指标，它们的相关性不足以被分组；这些在图6.11中只部分显示。
- en: 6.2.4 Applying a loading matrix in Python
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.4 在Python中应用加载矩阵
- en: 'Listing 6.3 shows the code that applies a loading matrix to a dataset to calculate
    the average scores. Most of this listing is the usual reading of the dataset and
    saving the results, and this time also reading in a loading matrix (created by
    listing 6.4). The heart of the listing is the following single line:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 6.3 展示了将加载矩阵应用于数据集以计算平均分数的代码。列表的大部分内容是常规的数据集读取和结果保存，这次还读取了一个加载矩阵（由列表 6.4
    创建）。列表的核心是以下这一行：
- en: '[PRE4]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: That line performs a matrix multiplication of the data by the loading matrix,
    which does the averaging calculation described in the last section.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 那一行执行了数据与加载矩阵的矩阵乘法，这完成了上一节中描述的平均计算。
- en: DEFINITION Matrix multiplication is an operation on two matrices that creates
    a result matrix. Each element in the first row of the result matrix is given by
    multiplying the first row of the first matrix by each column of the second matrix
    and then adding the results for each column; the second row of the result matrix
    is given by doing the same with the second row of the first matrix and all of
    the columns of the second matrix in turn, and so on.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 矩阵乘法是对两个矩阵进行操作以创建结果矩阵的过程。结果矩阵的第一行中的每个元素是通过将第一个矩阵的第一行与第二个矩阵的每一列相乘，然后对每一列的结果进行求和得到的；结果矩阵的第二行是通过将第一个矩阵的第二行与第二个矩阵的所有列依次相乘并求和得到的，依此类推。
- en: Note that for matrix multiplication to work, the number of columns in the first
    matrix has to equal the number of rows in the second matrix; this condition is
    met when the loading matrix has the metrics along the rows.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，为了使矩阵乘法生效，第一个矩阵的列数必须等于第二个矩阵的行数；当加载矩阵的行包含指标时，这个条件得到满足。
- en: Listing 6.3 Applying a loading matrix to a dataset in Python
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 6.3 在 Python 中将加载矩阵应用于数据集
- en: '[PRE5]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ① Listing 5.3 saved this score data.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: ① 列表 5.3 保存了这些分数数据。
- en: ② Reloads the file into a DataFrame and sets the index
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: ② 将文件重新加载到 DataFrame 中并设置索引
- en: ③ The churn indicator is removed for now; this returns a copy.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 现在移除了流失指示器；这返回了一个副本。
- en: ④ Reads a loading matrix from a file
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 从文件中读取加载矩阵
- en: ⑤ Converts the loading matrix to a NumPy array
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 将加载矩阵转换为 NumPy 数组
- en: ⑥ Rearranges data columns to the order of the loading matrix rows
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 将数据列重新排列为加载矩阵行的顺序
- en: ⑦ Uses matrix multiplication on ndarray to do the grouping
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ⑦ 使用 ndarray 上的矩阵乘法进行分组
- en: ⑧ Creates a DataFrame from the ndarray result
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ⑧ 从 ndarray 结果创建 DataFrame
- en: ⑨ Adds back the churn status column
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: ⑨ 添加回流失状态列
- en: ⑩ Saves the result
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: ⑩ 保存结果
- en: '![](../Images/6-12.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6-12.png)'
- en: Figure 6.12 Matrix multiplication is an operation that implements the averaging
    of scores by a loading matrix.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.12 矩阵乘法是通过加载矩阵实现分数平均的操作。
- en: 'Figure 6.12 illustrates the definition of matrix multiplication in terms of
    averaging scores. The definition may sound complicated, but it’s what you just
    learned in the last section:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.12 阐述了矩阵乘法定义的平均分数。这个定义可能听起来很复杂，但它正是你在上一节中学到的：
- en: The first average score for Account 1 is calculated by multiplying the Account
    1 row of the data by the first group of loading weights in the first column and
    summing it together.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 账户 1 的第一个平均分数是通过将数据中的账户 1 行与第一列的第一组加载权重相乘并求和得到的。
- en: The second average score for Account 1 is calculated by multiplying the Account
    1 row of the data by the second group of loading weights in the second column,
    and so on.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 账户 1 的第二个平均分数是通过将数据中的账户 1 行与第二列的第二组加载权重相乘得到的，依此类推。
- en: Matrix multiplication is a concise and efficient way to apply the loading weights
    to calculate averages in large datasets with any number of metrics and groups.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵乘法是将加载权重应用于计算大型数据集中任何数量指标和组的平均值的简洁且高效的方法。
- en: 'At this point, you probably want to run listing 6.3 on some data and check
    out the results, but you might be wondering where exactly you get the loading
    matrix from. You’re right to wonder, because I’m teaching you how to use a loading
    matrix first so you understand its purpose. The next section shows you how to
    create one from scratch. Be patient: you’ll see some case studies to further convince
    you of the usefulness of grouping metrics with loading matrices, and then in section
    6.3, you’ll learn how to run the code to make one. Then you can come back and
    run listing 6.3 using the loading matrix you created.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你可能想要在数据上运行列表6.3并查看结果，但你可能想知道加载矩阵是从哪里得到的。你确实应该这样想，因为我首先在教你如何使用加载矩阵，以便你理解其目的。下一节将向你展示如何从头创建一个加载矩阵。请耐心等待：你将看到一些案例研究，以进一步证明使用加载矩阵分组指标的有用性，然后在第6.3节中，你将学习如何运行代码来创建一个加载矩阵。然后你可以回来，使用你创建的加载矩阵运行列表6.3。
- en: 6.2.5 Churn cohort analysis on metric group average scores
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.5 指标组平均分数的客户流失群体分析
- en: 'Once you have grouped correlated metrics into average scores for the related
    behaviors, you can perform a churn analysis on the average group. No new code
    is needed to do so. The procedure is as follows:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦将相关指标分组为相关行为的平均分数，就可以对平均组进行客户流失分析。为此不需要编写新的代码。步骤如下：
- en: Use listing 6.3 and save the grouped scores in a new dataset file. It will have
    the same name as the original dataset except it now ends in `group_scores`.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用列表6.3并将分组分数保存到新的数据集文件中。它将具有与原始数据集相同的名称，但现在以`group_scores`结尾。
- en: Use listing 5.1 to create a cohort plot from the grouped dataset by substituting
    the new filename and the variable name `metric_group_1` for the first group, and
    so forth (see listing 6.3 for details).
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用列表5.1通过替换新文件名和变量名`metric_group_1`（对于第一组）以及依此类推（详情请见列表6.3）从分组数据集中创建一个客户群体图。
- en: Figure 6.13 illustrates the results of a churn cohort analysis for Klipfolio’s
    main group of metrics for viewing and editing dashboards. This is the first group
    that was illustrated in the correlation matrix of figure 6.6 and in the loading
    matrix of figure 6.11\. Churn cohort analysis was introduced in chapter 5, so
    I will just briefly summarize the main features. Each point represents the customers
    in a cohort defined by one decile in the scores. The vertical axis shows the churn
    rate in the cohort on a relative scale, and the bottom of the graph is fixed at
    zero. If a cohort is twice as far from the bottom of the plot as another, then
    it has twice the churn rate.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.13展示了Klipfolio主要指标组查看和编辑仪表板的结果。这是在图6.6的相关矩阵和图6.11的加载矩阵中首次展示的组。在第5章中介绍了客户流失群体分析，因此我将简要总结其主要特点。每个点代表一个由分数的十分之一定义的客户群体。垂直轴显示群体中的客户流失率，以相对比例表示，图表底部固定为零。如果一个群体距离图表底部的距离是另一个群体的两倍，那么它的流失率也是另一个群体的两倍。
- en: '![](../Images/6-13.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/6-13.png)'
- en: Figure 6.13 Cohort analysis of churn for Klipfolio’s primary metric group scores
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.13 Klipfolio主要指标组流失率客户群体分析
- en: 'Figure 6.13 shows that the average of the main group of metric scores for Klipfolio
    reveals a powerful relationship to churn: the cohort with the highest average
    scores has a churn rate that is less than one-tenth of the churn rate for the
    lower cohorts. Another nice property of this relationship is that the churn rate
    keeps declining, up to the highest cohorts. The average of this group of scores
    shows a stronger relationship to churn than the individual behaviors that were
    shown in the last chapter in figure 5.6.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.13显示，Klipfolio主要指标组的平均分数与客户流失之间存在强大的关联：平均分数最高的群体流失率低于较低群体流失率的十分之一。这种关系的另一个优点是流失率持续下降，直到最高群体。这个分数组的平均数与流失率的关系比上一章图5.6中展示的个别行为与流失率的关系更强。
- en: Figure 6.14 shows an example of a churn cohort analysis for the average of the
    main group of scores for Broadly. The main group of correlated metrics all relate
    to adding customers and transactions to the system, making requests to customers
    for reviews and recommendations, and the result of those requests. The cohort
    analysis based on this group of scores is another example of a strong relationship
    to churn. In this case, the top cohort has a churn rate around one-seventh the
    churn rate in the bottom cohorts.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.14 展示了针对 Broadly 主要指标组分数的平均值的流失客户分析示例。所有相关指标组都与向系统中添加客户和交易、请求客户进行评论和推荐以及这些请求的结果相关。基于此分数组的客户分析是另一个与流失有强烈关系的例子。在这种情况下，顶级客户组的流失率大约是底层客户组流失率的七分之一。
- en: '![](../Images/6-14.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/6-14.png)'
- en: Figure 6.14 Cohort analysis of churn for Broadly's primary metric group scores
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.14 广泛的指标组分数的流失客户分析
- en: Figures 6.13 and 6.14 both show that in real case studies, averages of groups
    of metric scores often show relationships to churn more effectively than individual
    metrics alone. Your own results might not show results that are this strong, but
    it is still preferable to analyze correlated metrics in groups. That’s because
    it avoids information overload from too many metrics.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.13 和 6.14 都表明，在实际案例研究中，指标分数组的平均值往往比单个指标更能有效地显示与流失的关系。你自己的结果可能不会显示如此强烈的结果，但仍然最好是分析相关度量的组。这是因为它避免了过多指标的信息过载。
- en: TAKEAWAY For correlated metrics, it is better to analyze churn in cohorts using
    the average score in place of individual metrics.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '**要点** 对于相关度量，最好使用平均分数而不是单个指标来分析流失客户。'
- en: 6.3 Discovering groups of correlated metrics
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.3 发现相关度量的组
- en: 'You now know how to average groups of metrics, but there’s one last thing:
    I did not explain how to find those groups of metrics in large datasets. For simple
    cases with just a few metrics, you can probably identify groups of metrics by
    looking at the correlation matrix. That’s the case for the small dataset used
    in the examples of figures 6.5 and 6.9\. But if you have a correlation matrix
    with dozens of metrics (or more), like the one from the case study (figure 6.7),
    it’s not as simple. Fortunately, there is a standard algorithm that will do it
    for you.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在知道如何计算指标组的平均值，但还有最后一件事：我没有解释如何在大型数据集中找到这些指标组。对于只有几个指标的简单情况，你可能可以通过查看相关矩阵来识别指标组。这就是图
    6.5 和 6.9 例子中使用的小数据集的情况。但是，如果你有一个包含数十个指标（或更多）的相关矩阵，如案例研究（图 6.7）中的那样，那就不会那么简单了。幸运的是，有一个标准算法可以为你完成这项工作。
- en: 6.3.1 Grouping metrics by clustering correlations
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.1 按聚类相关性分组度量
- en: The algorithm that you use to find groups of correlated metrics is called a
    clustering algorithm.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 你用来寻找相关度量组的方法被称为聚类算法。
- en: DEFINITION A clustering algorithm is an automatic procedure for grouping together
    similar items based on data.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** 聚类算法是基于数据自动将相似项目分组在一起的过程。'
- en: Technically, the procedure of the clustering algorithm is distinct from how
    similarity between items is measured. To group together metrics, you’ll use the
    correlation coefficient; the higher the correlation, the more similar the metrics.
    The clustering procedure you’ll use is called hierarchical clustering.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 技术上，聚类算法的流程与度量项目之间相似性的测量方法是不同的。为了将度量分组在一起，你会使用相关系数；相关系数越高，度量越相似。你将使用的聚类过程称为层次聚类。
- en: 'DEFINITION Hierarchical clustering is a greedy, agglomerative clustering algorithm:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** 层次聚类是一种贪婪的、聚合的聚类算法：'
- en: Agglomerative means the algorithm works by combining similar items in a bottom-up
    manner. Groups are formed starting from just two similar elements, and more elements
    are added to form larger groups of similar items as the algorithm progresses.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚合意味着算法通过自下而上的方式组合相似的项目。从仅两个相似元素开始形成组，随着算法的进行，更多元素被添加到形成更大的相似项目组。
- en: Greedy means that the algorithm works by picking the two elements that appear
    most similar, and after those two are grouped, the next most similar item is grouped
    at each stage.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 贪婪意味着算法通过选择最相似的两个元素来工作，在这两个元素被分组后，每个阶段都会将下一个最相似的项目分组。
- en: Hierarchical in this context refers to the fact that greedy agglomeration implies
    a structure or hierarchy between the items. There are the two most similar items,
    and after that, there is the next most similar, and so on.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这个上下文中，“分层”指的是贪婪聚合意味着项目之间存在结构或层次。有两个最相似的项目，然后是下一个最相似的项目，依此类推。
- en: 'Figure 6.15 illustrates hierarchical clustering, continuing the example of
    the small dataset that was shown in figures 6.5, 6.9, and 6.12\. The algorithm
    starts with the correlation matrix from figure 6.5 and finds the single highest
    correlation between any two metrics (figure 6.15.1). The two most correlated metrics
    form the first group: this is the 0.93 correlation between the metrics for reading
    and replying to messages.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.15展示了分层聚类，继续展示图6.5、6.9和6.12中所示的小数据集示例。算法从图6.5中的相关系数矩阵开始，找到任何两个指标之间的最高相关系数（图6.15.1）。两个最相关的指标形成一个分组：这是阅读和回复消息指标之间的0.93相关系数。
- en: The second step in the hierarchical clustering algorithm (figure 6.15.2) is
    to create a loading matrix that converts the original dataset into a new dataset
    where the two most correlated metrics are grouped, but all the other metrics remain
    separate. This loading matrix has one fewer column than there are metrics because
    there is just one group of metrics. The third step in the algorithm (not shown
    in figure 6.15) is to use the new loading matrix to create a new version of the
    dataset, following the procedure shown in the last section. The fourth step in
    the hierarchical clustering algorithm (figure 6.15.3) is to calculate the new
    correlation matrix for the data after the first two metrics are grouped.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 分层聚类算法的第二步（图6.15.2）是创建一个加载矩阵，将原始数据集转换为一个新的数据集，其中两个最相关的指标被分组，但所有其他指标仍然保持独立。这个加载矩阵比指标少一个列，因为只有一个指标分组。算法的第三步（图6.15中没有展示）是使用新的加载矩阵创建数据集的新版本，按照上一节中展示的程序进行。分层聚类算法的第四步（图6.15.3）是在前两个指标分组后计算数据的新相关系数矩阵。
- en: 'Having a new correlation matrix, the algorithm starts on a new iteration: find
    the next highest correlation. In the example, the next highest correlation is
    the 0.77 correlation between the metric for logins and the group metric for reading
    and replying, created in the last step (figure 6.15.3). The login metric is added
    to the first group in a new iteration of the loading matrix (figure 6.15.4), leading
    to a new version of the dataset and correlation matrix (figure 6.15.5), and so
    on.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有一个新的相关系数矩阵后，算法开始新的迭代：寻找下一个最高的相关系数。在示例中，下一个最高的相关系数是登录指标与上一步创建的阅读和回复分组指标的0.77相关系数（图6.15.3）。在加载矩阵的新迭代中，将登录指标添加到第一个分组（图6.15.4），从而得到新的数据集和相关系数矩阵版本（图6.15.5），依此类推。
- en: '![](../Images/6-15.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![图6.15](../Images/6-15.png)'
- en: Figure 6.15 Discovering metric groups by clustering correlations
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.15 通过聚类相关系数发现指标分组
- en: The algorithm stops when enough metrics have been grouped so that nothing is
    left that is moderately or highly correlated. The exact level of correlation at
    which the algorithm should stop trying to group things is a parameter that controls
    the level of grouping. Generally, you set the threshold at a moderate level of
    correlation. I typically set it in the range of 0.5 or 0.6 in the analyses that
    I do. I will provide more details about how to set this parameter in section 6.3.3\.
    For now, let’s look at how the example in figure 6.15 ends. After login, read,
    and reply are in one group, and write and send are in another group (figure 6.15.6),
    the remaining correlations (figure 6.15.7) are all between -.28 and .27; these
    are only weak correlations, so the algorithm stops. The result of the algorithm
    is to produce the loading matrix that was first shown in figure 6.9\. (Figure
    6.15.6 is a transposed and slightly reordered version of the loading matrix in
    figure 6.9.)
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 当足够多的指标被分组，以至于没有剩下任何中等或高度相关的指标时，算法停止。算法应该停止尝试分组的精确相关系数水平是一个控制分组水平的参数。通常，你将阈值设置在中等的相关系数水平。我在进行的分析中通常将其设置为0.5或0.6。我将在第6.3.3节中提供更多关于如何设置此参数的细节。现在，让我们看看图6.15中的示例是如何结束的。登录、阅读和回复在一个分组中，而写作和发送在另一个分组中（图6.15.6），剩余的相关系数（图6.15.7）都在-0.28和0.27之间；这些只是弱相关，因此算法停止。算法的结果是产生图6.9中首次展示的加载矩阵。（图6.15.6是图6.9中加载矩阵的转置和稍微重新排序的版本。）
- en: 'To review, here is the how the hierarchical clustering algorithm works at each
    step:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾一下，以下是层次聚类算法在每一步的工作方式：
- en: Identify the highest correlation.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 识别最高的相关性。
- en: Update the loading matrix to group together the two most correlated elements.
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新加载矩阵，将两个最相关的元素分组在一起。
- en: Create a new grouped dataset using the loading matrix on the original dataset
    of scores.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用原始分数数据集的加载矩阵创建一个新的分组数据集。
- en: Calculate a new correlation matrix.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算一个新的相关性矩阵。
- en: Repeat steps 1 through 4 until all of the remaining correlations are below a
    predetermined threshold.
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤1至4，直到所有剩余的相关性都低于一个预定的阈值。
- en: Efficiency of hierarchical clustering and correlation calculations for large
    datasets
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 大数据集的层次聚类和相关性计算的效率
- en: 'You might read in other references that hierarchical clustering is inefficient
    and not suited for big data. But there is a crucial difference here: the correlation
    matrix is not big data even when your data is big! The size that matters for the
    run time of hierarchical clustering is the number of metrics in your dataset,
    not the number of customers (observations). The number of metrics is reduced by
    one at every step, so the maximum number of iterations is the number of metrics.
    There is no problem using hierarchical clustering for larger datasets.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会在其他参考资料中读到层次聚类效率低下且不适合大数据。但这里有一个关键的区别：即使你的数据很大，相关性矩阵也不是大数据！影响层次聚类运行时间的大小是数据集中度量指标的数量，而不是客户（观察）的数量。每一步都会减少一个度量指标的数量，所以最大迭代次数是度量指标的数量。对于更大的数据集使用层次聚类没有问题。
- en: If you do have a lot of customers (a lot of observations), you’ll find that
    calculating the correlation matrix is actually the most expensive step. If your
    data is truly big, you should look at optimization or approximation of the correlation
    matrix calculation and don’t worry about the hierarchical clustering. As you’ll
    see in the next section, you really calculate the correlation matrix only once.
    My explanation of the algorithm presents it as if you recalculate the correlation
    matrix at each step, but in practice, the correlation matrix at each step can
    be deduced using the loading matrix (this detail is beyond the scope of this book).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你确实有很多客户（很多观察），你会发现计算相关性矩阵实际上是成本最高的步骤。如果你的数据真的很大，你应该考虑优化或近似相关性矩阵的计算，而不用担心层次聚类。正如你将在下一节中看到的，你实际上只计算一次相关性矩阵。我对算法的解释将其呈现为在每一步重新计算相关性矩阵，但在实践中，每一步的相关性矩阵可以通过加载矩阵推导出来（这个细节超出了本书的范围）。
- en: 6.3.2 Clustering correlations in Python
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.2 Python中的聚类相关性
- en: 'Now that you know how hierarchical clustering based on a correlation matrix
    works, you are ready to learn the Python code that implements it in practice.
    Listing 6.4 shows the program. Spoiler: the code uses prewritten open source package
    functions to implement the clustering. Listing 6.4 is mainly concerned with preparing
    the input to make it ready for the package functions and receiving the output
    from the package functions and turning those into the loading matrix that you
    need. The overall process is broken down into three steps that are separate functions
    in listing 6.4\. I explain each one in turn.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经知道了基于相关性矩阵的层次聚类是如何工作的，你就可以学习实现它的Python代码了。列表6.4展示了程序。剧透：代码使用了预写的开源包函数来实现聚类。列表6.4主要关注准备输入使其为包函数做好准备，并接收包函数的输出，将这些输出转换为所需的加载矩阵。整个过程被分解为三个步骤，这些步骤在列表6.4中是独立的函数。我将逐一解释它们。
- en: 'The actual clustering in listing 6.4 is in the function `find_correlation_clusters`.
    SciPy provides an implementation of hierarchical clustering in the package `scipy
    .cluster.hierarchy` with two functions: `linkage` and `fcluster`. The function
    `linkage` is the one that really does the work. It can work either on a raw dataset
    or on a precomputed measurement of the distance between points in a dataset, which
    is what happens in listing 6.4\. But the result of the `linkage` function is not
    actually the clusters; instead, the `linkage` function returns a description of
    the structure of the distance relationships between the data points, which is
    the hierarchy of distances referred to in the algorithm name.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.4中的实际聚类是在函数`find_correlation_clusters`中进行的。SciPy在`scipy.cluster.hierarchy`包中提供了一个层次聚类的实现，包含两个函数：`linkage`和`fcluster`。`linkage`函数是真正执行工作的函数。它可以在原始数据集上工作，也可以在数据集中点之间距离的预计算测量上工作，这就是列表6.4中发生的情况。但`linkage`函数的结果实际上不是聚类；相反，`linkage`函数返回数据点之间距离关系结构的描述，这就是算法名称中提到的距离层次。
- en: 'I am not going to explain the details of how the hierarchy is represented because
    there is another function that you can pass the result into to get the clusters
    you want: that is `fcluster`. The function `fcluster` takes the hierarchy description
    from `linkage` and a cutoff threshold to form clusters. In our case, this threshold
    is the correlation cutoff for what we consider to be highly correlated. The result
    of `fcluster` is an assigned cluster for each of the original items in the form
    of a `numpy` `Series`.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我不会解释层次表示的细节，因为还有一个函数可以将结果传递进去以获取你想要的聚类：那就是`fcluster`。`fcluster`函数接受来自`linkage`的层次描述和一个截止阈值来形成聚类。在我们的情况下，这个阈值是我们认为高度相关的相关截止值。`fcluster`的结果是以`numpy`
    `Series`形式为原始项目分配的聚类。
- en: Listing 6.4 Finding metric groups and creating a loading matrix in Python
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.4：在Python中查找指标分组和创建加载矩阵
- en: '[PRE6]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ① Imports SciPy functions that perform hierarchical clustering
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: ① 导入执行层次聚类的SciPy函数
- en: ② Clustering uses dissimilarity, so invert correlation matrix
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: ② 聚类使用不相似性，因此反转相关矩阵
- en: ③ The threshold parameter is also inverted.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 阈值参数也被反转。
- en: ④ Calculates the order of relative distances between metrics
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 计算指标之间相对距离的顺序
- en: ⑤ Determines the groups given the hierarchy and threshold
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 根据层次和阈值确定分组
- en: ⑥ Counts the number of elements in each cluster
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 计算每个聚类中元素的数量
- en: ⑦ Finds the order of the cluster’s number of members
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: ⑦ 找到聚类成员数的顺序
- en: ⑧ Makes a new series of the cluster labels in order
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: ⑧ 按顺序创建聚类标签的新序列
- en: ⑨ Makes a new count from the relabeled clusters
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: ⑨ 从重新标记的聚类中创建新的计数
- en: ⑩ Makes a DataFrame, listing the group for each of the metrics
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: ⑩ 创建一个DataFrame，列出每个指标的分组
- en: ⑪ Creates an empty (zero) matrix to hold the averaging weights
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: ⑪ 创建一个空的（零）矩阵来存储平均权重
- en: ⑫ Enters the weight for each metric in the loading matrix
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: ⑫ 在加载矩阵中输入每个指标的权重
- en: ⑬ Selects those columns in the loading matrix that are groups
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: ⑬ 选择加载矩阵中是分组的那些列
- en: ⑭ Uses equation 6.3 (section 6.3.3) to get the weights
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: ⑭ 使用方程6.3（第6.3.3节）获取权重
- en: ⑮ For non-grouped metrics, the weight is simply 1.0.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: ⑮ 对于未分组的指标，权重简单地是1.0。
- en: ⑯ Makes a Boolean series showing which columns are groups
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: ⑯ 创建一个布尔序列，显示哪些列是分组
- en: ⑰ Makes the names metric_group_n for the groups
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: ⑰ 为分组创建名称`metric_group_n`
- en: ⑱ Otherwise, the original metric name is entered in the list.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: ⑱ 否则，将原始指标名称输入列表中。
- en: ⑲ Makes a DataFrame from the weighted matrix
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: ⑲ 从加权矩阵创建DataFrame
- en: ⑳ Makes a name column from the DataFrame index column
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ⑳ 从DataFrame索引列创建名称列
- en: ㉑ Makes a list of the columns that sort the rows
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: ㉑ 创建一个列的列表，该列表按行排序
- en: ㉒ Sorts most of the columns in descending order
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: ㉒ 按降序排序大部分列
- en: ㉓ Sorts the name column in ascending order
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: ㉓ 按升序排序名称列
- en: ㉔ Sorts the loading matrix in order for interpretability
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: ㉔ 按顺序排序加载矩阵以进行可解释性
- en: ㉕ Drops the name column because it was used for sorting
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: ㉕ 删除名称列，因为它用于排序
- en: ㉖ Reloads the scores created by listing 5.3
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: ㉖ 重新加载列表5.3创建的分数
- en: ㉗ Makes a list of the original metric columns
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: ㉗ 创建原始指标列的列表
- en: ㉘ Calculates the group assignments
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: ㉘ 计算分组分配
- en: ㉙ Makes a column that lists the metrics in each group
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: ㉙ 创建一个列出每个组中指标的列
- en: ㉚ Saves the loading matrix
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: ㉚ 保存加载矩阵
- en: 'Getting your data into the cluster algorithm is not that hard. The most important
    detail is the fact that the `linkage` function is written to work on data in terms
    of dissimilarity, but so far we have thought about correlation, which is a measure
    of similarity. The solution is as follows: you take 1.0 minus the correlation,
    and what was a measure of similarity becomes a measure of dissimilarity. What
    does that mean? Consider: the highest correlation (the most similarity) was 1.0,
    which becomes 0.0 after being subtracted from 1.0\. That is now the least dissimilar
    two items can be. The most dissimilar in terms of correlation would be -1.0, but
    that becomes 2.0 when subtracted from 1.0 (1 - -1 = 1 + 1 = 2); that is now the
    most dissimilar. Both the correlation matrix and the correlation threshold are
    converted by (element-wise) subtraction from 1.0 before they are used in the SciPy
    functions `linkage` and `fcluster`. That’s all the preparation needed to run the
    clustering algorithm.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据输入到聚类算法中并不那么困难。最重要的细节是`linkage`函数是编写来处理基于差异性的数据的，但到目前为止，我们考虑的是相关性，这是一种相似性的度量。解决方案如下：你从1.0减去相关性，那么原本是相似性度量的指标现在变成了差异性度量。这意味着什么？考虑：最高的相关性（最大的相似性）是1.0，减去1.0后变成了0.0。现在这是两个项目之间最不相似的情况。从相关性角度来说最不相似的是-1.0，但减去1.0后变成了2.0（1
    - -1 = 1 + 1 = 2）；现在这是最不相似的情况。在用于SciPy函数`linkage`和`fcluster`之前，相关矩阵和相关阈值都通过逐元素减去1.0进行转换。这就是运行聚类算法所需的所有准备工作。
- en: 'Unfortunately, the result of the clustering algorithm is not exactly what you
    want. What you want is a loading matrix and in a particular order. It is easiest
    to interpret when the largest group comes first, and they are then ordered in
    descending size. The `fcluster` function returns the assigned clusters for the
    groups, but they are not in any particular order sizewise. There are two main
    parts to the postprocessing after calling `linkage` and `fcluster`: first comes
    sorting and relabeling the clusters, and after that, the creation of the loading
    matrix.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 很遗憾，聚类算法的结果并不完全符合你的期望。你想要的是一个加载矩阵，并且按照特定的顺序排列。当最大的组别排在最前面，并且按照大小顺序降序排列时，这最容易理解。`fcluster`函数返回了分配给各个组的聚类，但它们在大小上并没有任何特定的顺序。在调用`linkage`和`fcluster`之后，后处理有两个主要部分：首先是排序和重新标记聚类，然后是创建加载矩阵。
- en: 'The second function in listing 6.4, `relabel_clusters`, is the first step of
    postprocessing. To sort and relabel the clusters, a Python `set` is used to find
    the unique clusters, and a Python `Counter` is used to count the occurrences of
    each label in the result of `fcluster`. The `Counter` object also has a utility
    function to iterate through the elements in order from most common to least: that
    is the function `Counter.most_common`. After the relabeled cluster names are found,
    the result is saved in a new `Series` of labels. Two objects are created to represent
    the clusters for later: a two-column `DataFrame` that lists the original metrics
    and the groups they were placed in, and a new `Counter` object that counts the
    new labels.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.4中的第二个函数`relabel_clusters`是后处理的第一步。为了排序和重新标记聚类，使用Python的`set`来找到唯一的聚类，并使用Python的`Counter`来统计`fcluster`结果中每个标签的出现次数。`Counter`对象还有一个实用函数，可以按最常见到最不常见的顺序遍历元素：这就是函数`Counter.most_common`。在找到重新标记的聚类名称后，结果被保存在一个新的标签`Series`中。创建了两个对象来表示聚类以供后续使用：一个两列的`DataFrame`，列出了原始指标及其所在的组，以及一个新创建的`Counter`对象，用于统计新的标签。
- en: 'The third function in listing 6.4, `make_load_matrix`, is the final step. The
    loading matrix is initialized as an `ndarray` of zeros in the right size: the
    number of rows is the number of metrics, and the number of columns is the number
    of groups. The function `relabel_clusters` creates a `DataFrame` that lists each
    metric and its group. That is used to iterate over the metrics and fill in an
    appropriate entry under the right group in the loading matrix. That `ndarray`
    is turned into a `DataFrame` using the metric names as the index.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.4中的第三个函数`make_load_matrix`是最后一步。加载矩阵初始化为正确大小的零`ndarray`：行数是指标的数目，列数是组的数目。`relabel_clusters`函数创建了一个`DataFrame`，列出了每个指标及其组。这被用来遍历指标，并在加载矩阵中相应的组下填充适当的条目。这个`ndarray`被转换成一个`DataFrame`，使用指标名称作为索引。
- en: 'The weight for each entry in the loading matrix is calculated with 1.0 divided
    by the number of elements in the group: the number of elements in the group is
    `relabeled_count[row[1][0]]` in the code. `relabeled_count` is a counter object,
    and `row[1][0]` selects the appropriate element. But there is also another term
    in the denominator of the weight calculation, which is the square root of the
    correlation threshold used for clustering: `np.sqrt(corr)`. That extra term is
    what makes the weights a bit higher than 1/N, as I mentioned back when I first
    showed you the loading matrix in section 6.2.3\. I’ll explain the reasoning for
    that choice in the next section, after I finish explaining the algorithm.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 加载矩阵中每个条目的权重是通过将1.0除以组内元素的数量来计算的：代码中是`relabeled_count[row[1][0]]`中的组内元素数量。`relabeled_count`是一个计数器对象，`row[1][0]`选择适当的元素。但在权重计算的分子中还有一个额外的项，即用于聚类的相关阈值平方根：`np.sqrt(corr)`。正如我在6.2.3节首次向您展示加载矩阵时提到的，这个额外项使得权重略高于1/N。我将在解释完算法后，在下节解释这个选择的原因。
- en: 'The rest of the function `make_load_matrix` sorts the loading matrix in the
    order that makes it easiest to read: the largest group comes first and then the
    second largest, and so forth. Within each group, the metrics are sorted alphabetically
    by name. This is accomplished using Pandas `DataFrame.sort_values` with appropriate
    parameters. The function `sort_values` takes a list of columns to sort by and
    a list of Booleans for whether each column is in ascending or descending order.
    The name of the metrics is added as a column (it was previously the index), and
    all of the columns are used to sort. The columns for group weights come first
    and are sorted in descending order, while the column for the name comes last and
    is sorted in ascending order. Because the columns indicating group membership
    are in order from largest to smallest, this achieves the desired ordering of the
    loading matrix: grouped from largest to smallest and sorted alphabetically within
    each group. Also, the columns are labeled with a label (metric_goup_x, where *x*
    is the group number for the groups or just the metric name when a group is just
    a single metric).'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 函数`make_load_matrix`的其余部分按照使读取最简单的顺序对加载矩阵进行排序：最大的组首先，然后是第二大的，依此类推。在每个组内，指标按名称的字母顺序排序。这是通过使用Pandas的`DataFrame.sort_values`和适当的参数来实现的。`sort_values`函数接受一个要排序的列的列表和一个布尔值列表，表示每一列是升序还是降序。指标的名称被添加为一个列（之前是索引），并且所有列都被用于排序。组权重的列首先，并按降序排序，而名称的列最后，并按升序排序。因为表示组成员的列是从大到小排序的，这实现了加载矩阵的期望排序：从大到小分组，并在每个组内按字母顺序排序。此外，列被标记为一个标签（metric_goup_x，其中*x*是组的编号，或者当组只是一个单一指标时，就是指标名称）。
- en: 'The main function that runs all the steps together is at the end of listing
    6.4: `find_metric_groups`. This function loads a dataset and then calls the other
    steps in the algorithm. `find_metric_groups` returns the loading matrix as the
    result, and the default option is to save it to a .csv file. Note that the program
    outputs only a simple confirmation that it is running and where it saves the result.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 执行所有步骤的主要函数位于列表6.4的末尾：`find_metric_groups`。此函数加载一个数据集，然后调用算法中的其他步骤。`find_metric_groups`返回加载矩阵作为结果，默认选项是将它保存到.csv文件中。请注意，程序只输出一个简单的确认信息，表明它正在运行以及结果保存的位置。
- en: '![](../Images/6-16.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/6-16.png)'
- en: Figure 6.16 Result of running listing 6.4 on the default simulated dataset (a
    reproduction of figure 6.10)
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.16 运行列表6.4在默认模拟数据集上的结果（图6.10的再现）
- en: 'If you use the simulated data, then the resulting loading matrix should look
    like the one figure 6.16 when you open the file in a spreadsheet or text editor.
    There are two groups of metrics: one for the most common behaviors that are correlated
    to each other (which are posts, viewing ads, and likes) and a smaller group for
    reading and replying to messages. The metrics for account tenure, disliking, and
    unfriending are not correlated enough, so they don’t enter into any group. Note
    that the weights are not exactly the 1/*N* for a standard average, but these are
    modified using equation 6.3 (section 6.3.2) to make the averages work as scores
    themselves.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用模拟数据，那么打开文件在电子表格或文本编辑器中时，得到的加载矩阵应该看起来像图 6.16 中的那样。存在两组度量指标：一组是相互关联的最常见行为（包括发帖、查看广告和点赞），另一组是阅读和回复消息的小组。账户时长、不喜欢和取消好友关系的度量指标相关性不足，因此它们没有进入任何一组。请注意，权重不是标准的平均值的
    1/*N*，而是使用方程 6.3（第 6.3.2 节）进行修改，以使平均值本身作为分数。
- en: '![](../Images/6-17.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6-17.png)'
- en: Figure 6.17 Ordered correlation matrix for the simulated data
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.17 模拟数据的有序相关矩阵
- en: Now that you have a loading matrix, you can produce an ordered correlation matrix
    like figure 6.6\. For the simulated dataset, this result is shown in figure 6.17\.
    From the ordered correlation heatmap, you can see the higher correlations between
    the two groups and the lower correlations between other metrics. Figure 6.17 was
    created by running listing 6.5 and then formatting the resulting data in a spreadsheet.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你有了加载矩阵，你可以生成一个有序相关矩阵，如图 6.6 所示。对于模拟数据集，这个结果在图 6.17 中显示。从有序相关热图中，你可以看到两组之间的高相关性以及其他度量指标之间的低相关性。图
    6.17 是通过运行列表 6.5 并在电子表格中对结果数据进行格式化创建的。
- en: 'Listing 6.5 shows that the code to create the ordered matrix is almost exactly
    the same as that for creating a regular correlation matrix. The only difference
    is that you read in the loading matrix and reorder the dataset columns according
    to the order of the metrics in the loading matrix before calculating the correlation
    matrix. Reordering is a one liner because you already went to the trouble of ordering
    the loading matrix correctly by groups: just reuse that order.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 6.5 显示，创建有序矩阵的代码几乎与创建常规相关矩阵的代码完全相同。唯一的区别是，在计算相关矩阵之前，你读取加载矩阵并按加载矩阵中度量指标的顺序重新排序数据集列。重新排序是一行代码，因为你已经费心将加载矩阵正确地按组排序：只需重用那个顺序即可。
- en: Listing 6.5 Creating an ordered correlation matrix
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 6.5 创建有序相关矩阵
- en: '[PRE7]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ① Loads the saved scores
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: ① 加载保存的分数
- en: ② Reorders the dataset columns to the order of the loading matrix rows
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: ② 将数据集列重新排序为加载矩阵行的顺序
- en: ③ Calculates the correlation matrix
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 计算相关矩阵
- en: ④ Saves the result
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 保存结果
- en: 6.3.3 Loading matrix weights that make the average of scores a score
  id: totrans-254
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.3 加载使分数平均值为分数的矩阵权重
- en: 'There is one technical detail about loading matrices that I haven’t explained
    yet, and it has to do with exactly what weights you should use in the loading
    matrix. The upshot, mentioned in the last section, is that you don’t use weights
    in the loading matrix that are exactly 1/N. I said 1/*N* when I first taught you
    the idea of the loading matrix so you would learn the concept easily, and the
    concept doesn’t change: the loading matrix transformation still represents taking
    an average of the metric scores. But the weights need to be changed a bit.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 关于加载矩阵的一个技术细节我还没有解释，这与加载矩阵中应该使用的确切权重有关。上一节提到的要点是，你不需要在加载矩阵中使用精确的 1/N 权重。我第一次教你加载矩阵的概念时说
    1/*N*，是为了让你更容易地理解这个概念，而这个概念并没有改变：加载矩阵的转换仍然代表对度量指标分数取平均值。但权重需要稍作调整。
- en: 1/N is the correct weight to make an equally weighted average when all of the
    numbers in the average have the same scale or unit. But it’s a little different
    with scores because there is no natural unit. (Note that if you don’t like equations,
    this would be a fine time to skip to the next section, after you read the takeaway.)
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 1/N 是当平均中的所有数字具有相同的尺度或单位时，制作等权重的平均值的正确权重。但与分数不同，因为分数没有自然单位。（注意，如果你不喜欢方程，这将是跳到下一节的好时机，在你阅读了要点之后。）
- en: TAKEAWAY The weights in the loading matrix will be a bit higher than 1/N, but
    the meaning is still the same.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 要点：加载矩阵中的权重将略高于 1/N，但意义仍然是相同的。
- en: 'The problem with using 1/*N* weights to make an average of scores is that then
    the average of the metric scores is not a score anymore. What does that mean?
    A score was defined as a scaled version of a metric, and it has some particular
    properties: the average (mean) score is 0, and the standard deviation of the scores
    is 1\. These facts make the scores comparable.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 使用1/*N*权重来平均分数的问题在于，这样得到的指标分数的平均值就不再是分数了。这意味着什么？分数被定义为指标的缩放版本，并且具有一些特定的属性：平均（均值）分数是0，分数的标准差是1。这些事实使得分数具有可比性。
- en: The good news is that if you make an average of scores with any equal weights,
    the mean (average) of the scores will still be zero. But the bad news is that
    the standard deviation of the average of scores will not be 1, and instead, it
    will be less than 1.0\. How much less depends on how many metrics you average
    together and how correlated they are. But I’m going to teach a modification to
    the weights in the loading matrix that will make the average scores have (almost)
    the 1.0 standard deviation they are supposed to. That adjustment makes the average
    still a score regardless of how many metrics you are averaging together.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，如果你用任何等权重的平均分，这些分数的平均值（平均数）仍然会是零。但坏消息是，这些分数平均的标准差不会是1，而是小于1.0。具体小多少取决于你平均了多少个指标以及它们的相关性如何。但我会教你们如何修改加载矩阵中的权重，使得平均分数具有（几乎）应有的1.0标准差。这种调整使得平均数仍然是一个分数，无论你平均了多少个指标。
- en: 'First I need to remind you what a variance is: the variance is the standard
    deviation squared. When the standard deviation is 1, the variance is also 1 (because
    1 squared is 1). In what follows, I write σ for the standard deviation and σ 2
    for the variance; that’s the Greek letter sigma, and in math books, it is the
    usual letter for indicating standard deviation and variance. The thing about standard
    deviations is that when you sum metrics or other variables and each metric has
    its own standard deviation, the standard deviation of the sum doesn’t stay the
    same; they sum up scaled by the weight. The relationship is easier to understand
    in terms of the variance, which is why I reminded you what the variance is. I’ll
    show you how you get the variance for a sum of metrics that all have their own
    variance. Assuming you multiply each metric by a weight to form an average, the
    variance of a weighted sum of metrics is given in equation 6.1:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我需要提醒你们什么是方差：方差是标准差的平方。当标准差是1时，方差也是1（因为1的平方是1）。在接下来的内容中，我用σ表示标准差，用σ²表示方差；这是希腊字母sigma，在数学书中，它是表示标准差和方差的常用字母。关于标准差的一个特点是，当你对指标或其他变量求和时，每个指标都有自己的标准差，求和的标准差不会保持不变；它们会根据权重进行缩放求和。这个关系用方差来理解更容易，这就是为什么我要提醒你们什么是方差。我会展示如何得到具有各自方差的指标求和的方差。假设你通过乘以每个指标的权重来形成一个平均数，加权指标和的方差由方程6.1给出：
- en: '| σ ²(*wx*[1] + *wx*[2] + ... + *wx*[*N*]) = *Σ*[*ij*] *w*²*σ*[*i*] *σ*[*j*]
    *c*[*ij*] | Equation 6.1 |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| σ²(*wx*[1] + *wx*[2] + ... + *wx*[*N*]) = *Σ*[*ij*] *w*²*σ*[*i*] *σ*[*j*]
    *c*[*ij*] | 方程6.1 |'
- en: 'In equation 6.1, the notation *Σ*[*ij*] ... is shorthand for the sum of all
    the different elements’ index by the subscripts (in code, that’s like adding a
    sum in a doubly nested loop). What equation 6.1 says is that the variance of a
    sum of metrics is the sum of the pairwise products of all the standard deviations,
    multiplied by the pairwise correlation coefficients. That’s kind of complicated,
    and hopefully gives you an idea for why the standard deviation of a sum of metrics
    will be 1 only under certain conditions. Now I’ll show you what those conditions
    are. First, however, I’m going to make some simplifications:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在方程6.1中，符号*Σ*[*ij*] ... 是所有不同元素索引的求和的简写（在代码中，这就像在双层循环中添加求和一样）。方程6.1所说的就是，指标求和的方差是所有标准差成对乘积的求和，乘以成对的相关系数。这有点复杂，但希望这能让你明白为什么指标求和的标准差只有在某些条件下才会是1。现在，我将展示这些条件是什么。然而，首先，我将做一些简化：
- en: In our case, all the standard deviations are 1 because they are all scores,
    so the terms *σ*[*i/j*] drop out.
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在我们的情况下，所有标准差都是1，因为它们都是分数，所以项*σ*[*i/j*]消失。
- en: 'You don’t know exactly what all the correlations *c*[*ij*] between the metrics
    are, but you do know this: if you are grouping them together into an average,
    then they are highly correlated. They probably have individual correlations that
    are at least as high as your correlation threshold. So instead of using *c*[*ij*]
    , I approximate it with *c*[*thresh*] , the threshold used to form the clusters.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你不知道所有指标之间的相关性 *c*[*ij*] 究竟是什么，但你确实知道这一点：如果你将它们分组在一起取平均值，那么它们高度相关。它们可能具有至少与你的相关性阈值一样高的个体相关性。因此，而不是使用
    *c*[*ij*] ，我用 *c*[*thresh*] 来近似它，这是形成聚类的阈值。
- en: 'With those simplifications, equation 6.1 for the variance of the sum is given
    approximately in equation 6.2:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些简化，方差方程 6.1 大约在方程 6.2 中给出：
- en: '| σ²(*wx*[1] + *wx*[2] + ... + *wx*[*N*]) ≈ *N*² *w*² | Equation 6.2 |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| σ²(*wx*[1] + *wx*[2] + ... + *wx*[*N*]) ≈ *N*² *w*² | 方程 6.2 |'
- en: 'There are *N*² terms in the sum of pairwise correlations; that’s where the
    *N*² in equation 6.2 comes from. Equation 6.2 is an approximation because the
    correlations aren’t really *c*[*thresh*] (most notably the self-correlations for
    every metric are 1), but it’s close enough. The next step is to solve the equation
    for the weight w that makes the variance (and the standard deviation) equal to
    1\. The result is shown in equation 6.3:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在成对相关性的和中存在 *N*² 项；这就是方程 6.2 中的 *N*² 的来源。方程 6.2 是一个近似值，因为相关性实际上并不是 *c*[*thresh*]（最明显的是每个指标的自我相关性都是
    1），但它足够接近。下一步是解方程以找到使方差（以及标准差）等于 1 的权重 w。结果在方程 6.3 中给出：
- en: '| ![](../Images/6-17_E03.png)  | Equation 6.3 |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| ![图片 6-17_E03.png](../Images/6-17_E03.png) | 方程 6.3 |'
- en: 'After all the equations, there is a reasonably straightforward change: instead
    of using 1/*N* as the weights to make the averages in the loading matrix, you
    multiply 1/*N* by an extra factor, which is the square root of 1/ *c*[*thresh*]
    , the correlation threshold used in the clustering algorithm. Because the correlation
    threshold is less than one (typically around 0.5 or 0.6), 1 divided by it is greater
    than 1 (typically between 1 and 2), and the square root doesn’t change that. As
    a result, the weights you use to average scores will be a bit bigger than the
    usual 1/*N* in a standard average. It’s a technical detail, but keeping your average
    scores as scores by making this adjustment will make your analysis easier to interpret
    because the standard deviation of your metric scores will still be 1.'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有方程之后，有一个相当直接的变化：在加载矩阵中使平均值时，不再使用 1/*N* 作为权重，而是将 1/*N* 乘以一个额外的因子，这个因子是 1/
    *c*[*thresh*] 的平方根，这是聚类算法中使用的相关性阈值。因为相关性阈值小于 1（通常在 0.5 或 0.6 左右），所以它的倒数大于 1（通常在
    1 和 2 之间），平方根不会改变这一点。因此，你用来平均分数的权重将比标准平均中的 1/*N* 略大。这是一个技术细节，但通过这种调整保持你的平均分数作为分数，会使你的分析更容易解释，因为你的指标分数的标准差仍然为
    1。
- en: 6.3.4 Running the metric grouping and grouped cohort analysis listings
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.4 运行指标分组和分组队列分析列表
- en: Now that you have a loading matrix (produced by running listing 6.4), you can
    go back and run listing 6.3\. Listing 6.3 applies the loading matrix to the dataset
    of scores to create the grouped average scores. Note that running listing 6.3
    produces only a line of output showing it is running, and the real result will
    be a new .csv dataset (the result prints where it is saved). Figure 6.18 shows
    a small sample of the dataset saved from running listing 6.3\. Instead of metric
    names, the column headers show group numbers.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你有了加载矩阵（通过运行列表 6.4 生成），你可以返回并运行列表 6.3。列表 6.3 将加载矩阵应用于分数数据集以创建分组平均分数。请注意，运行列表
    6.3 只会产生一行输出，显示它在运行，而实际结果将是一个新的 .csv 数据集（结果打印出保存的位置）。图 6.18 显示了运行列表 6.3 保存的数据集的小样本。列标题显示的是组号，而不是指标名称。
- en: '![](../Images/6-18.png)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![图片 6-18.png](../Images/6-18.png)'
- en: Figure 6.18 Result of running listing 6.3 on the default simulated dataset
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.18 运行列表 6.3 的默认模拟数据集的结果
- en: With a dataset of grouped metrics, it’s also the time to try a cohort analysis
    (listing 5.1) using a grouped metric. This is the technique that was demonstrated
    in section 6.2.4\. To do this, there is another version of listing 5.1 that you
    can run by passing the arguments `—chapter` `5` `—listing` `1` `—version` `3`
    to the Python wrapper program. Figure 6.19 shows the result of running the cohort
    analysis on the main group of correlated metrics in the simulated data. The grouped
    metrics show a strong relationship with churn. (Because the dataset is randomly
    simulated, your result might not be exactly the same.)
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 当你有一个分组指标的数据集时，也是尝试使用分组指标进行队列分析（列表5.1）的时候了。这是在第6.2.4节中演示的技术。为此，你可以通过将`—chapter`
    `5` `—listing` `1` `—version` `3`参数传递给Python包装程序来运行列表5.1的另一个版本。图6.19显示了在模拟数据中的主要相关指标组上运行队列分析的结果。分组指标显示出与客户流失的强烈关系。（因为数据集是随机模拟的，你的结果可能不会完全相同。）
- en: '![](../Images/6-19.png)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
  zh: '![图6.19](../Images/6-19.png)'
- en: Figure 6.19 Result of running listing 5.1 on the first group of metrics generated
    by the default simulated dataset
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.19 运行列表5.1在默认模拟数据集生成的第一组指标上的结果
- en: 6.3.5 Picking the correlation threshold for clustering
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.5 选择聚类相关性阈值
- en: In explaining the clustering algorithm, I mentioned the threshold for clustering
    correlations; recall that this threshold determines when metrics should be grouped
    together or left apart. I did not explain in detail how to set this parameter
    because I wanted you to learn how the grouping is supposed to work before getting
    into the technical details. But the clustering threshold parameter is really crucial
    for the success of behavioral grouping. If you set this parameter at too low a
    value, then you can wind up with every metric grouped together in one big group,
    even when they are not all related to each other. And if you set the correlation
    threshold parameter at too high a value, then metrics that are strongly related
    still won’t get grouped, and you’ll end up with (almost) as many groups as you
    had metrics to begin with.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在解释聚类算法时，我提到了聚类相关性的阈值；回想一下，这个阈值决定了何时将指标分组在一起或分开。我没有详细解释如何设置这个参数，因为我想让你在学习技术细节之前先了解分组是如何工作的。但聚类阈值参数对于行为分组成功至关重要。如果你将此参数设置得太低，那么你可能会得到一个包含所有指标的大组，即使它们之间并不都相关。而且，如果你将相关性阈值参数设置得太高，那么强相关的指标仍然不会分组，你最终会得到（几乎）与最初指标数量一样多的组数。
- en: 'Unfortunately, there is no best value that works in every case, so you might
    have to experiment a bit. I also don’t advise any measure of the grouping to evaluate
    your choice. Rather, I advise you to understand the business (or learn about it
    from someone who does) and what the correlation matrix tells you about the business.
    Then ask yourself: do the metrics that are grouped together make sense? Would
    the grouping make more sense and/or be more useful if a few more metrics were
    grouped together or split apart?'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，没有一种适用于所有情况的最佳值，所以你可能需要做一些实验。我也不建议任何分组度量来评估你的选择。相反，我建议你了解业务（或者从了解业务的人那里了解）以及相关性矩阵告诉你关于业务的信息。然后问问自己：分组在一起的指标是否合理？如果将更多指标分组在一起或分开，分组是否更有意义和/或更有用？
- en: For example, suppose you know that some metrics relate to a product feature
    or content area normally used together. In that case, it’s reasonable to adjust
    the parameter a bit (if necessary) to break those out into their own group or
    to keep those from being split. (That’s an example of using your prior knowledge
    to guide the analysis.) On the other hand, if the correlation matrix is telling
    you some activities are highly correlated, but some of your business colleagues
    want you to split them to make more groups, it might be their own wishful thinking
    or office politics dictating that decision. Use your prior knowledge to help decide
    on close calls, but don’t ignore the results of your analysis!
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你知道一些指标通常与一个产品特性或内容区域相关联。在这种情况下，合理地调整参数（如果需要的话）将它们分成自己的组或防止它们被分开是有道理的。（这是一个使用你的先验知识来指导分析的一个例子。）另一方面，如果相关性矩阵告诉你某些活动高度相关，但你的某些商业同事希望你将它们分开以形成更多的组，这可能只是他们的一厢情愿的想法或办公室政治在影响决策。使用你的先验知识来帮助决定关键时刻，但不要忽视你分析的结果！
- en: 'Here are some rules of thumb that I use when setting the correlation levels
    in my own analyses:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置我自己的分析中的相关性水平时，以下是一些我常用的经验法则：
- en: You should usually end up with the correlation threshold parameter set at the
    level of a moderate or moderately high correlation in the range between 0.4 and
    0.7—never at very high or low correlation, meaning, don’t go above 0.8 or below
    0.3.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你通常应该将相关阈值参数设置在中等或较高相关性的水平，范围在0.4到0.7之间——永远不要设置在非常高的或很低的相关性，也就是说，不要超过0.8或低于0.3。
- en: 'It’s usually better to start out too low, with a threshold value of 0.5 or
    less, and have all (or most) of the metrics grouped together in one big group:'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通常最好从较低的水平开始，阈值值为0.5或更低，并将所有（或大多数）度量指标分组到一个大组中：
- en: If every metric has a high correlation (> 0.7) to at least a few of the other
    metrics, then you probably should group them all in one group. This might be the
    case for a small product that does not have a wide variety of features or content,
    or if the events you track do not vary widely.
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果每个度量指标都与其他至少几个度量指标有高相关性（> 0.7），那么你可能应该将它们全部分组到一个组中。这可能适用于没有广泛特征或内容的较小产品，或者如果你跟踪的事件变化不大。
- en: 'Use a simple binary search on the range of 0.5 to 0.7: if 0.5 looks too low,
    try 0.6 (halfway between 0.5 and 0.7). If 0.6 still seems too low, try 0.65 (halfway
    between 0.6 and 0.7); if 0.6 is too high, try 0.55, and so forth. You’ll quickly
    exhaust the plausible range and get a sense of where the best value lies.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在0.5到0.7的范围内使用简单的二分搜索：如果0.5看起来太低，尝试0.6（0.5和0.7之间的一半）。如果0.6仍然看起来太低，尝试0.65（0.6和0.7之间的一半）；如果0.6太高，尝试0.55，以此类推。你很快就会耗尽可能的范围，并感觉到最佳值所在的位置。
- en: Use a manual search, not an algorithm—I have never found a stopping criterion
    that works all the time. The search usually doesn’t take very long anyway.
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用手动搜索，而不是算法——我从未找到一种始终有效的停止标准。无论如何，搜索通常不会花费很长时间。
- en: 'Use color-coded correlation heatmaps and an aesthetic criteria (honestly):
    a pattern of squares on the diagonal looks well ordered (see figure 6.7), but
    if you go too far in either direction (too much or too little correlation), it
    breaks up the symmetry. Once you’ve done it a few times, this is pretty intuitive.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用彩色编码的相关热图和美学标准（真诚地）：对角线上的正方形图案看起来井然有序（见图6.7），但如果你在任何方向上走得太远（相关性过多或过少），就会破坏对称性。一旦你做了几次，这就会变得相当直观。
- en: The biggest challenge is that sometimes small changes in the correlation can
    have a highly disproportionate impact on the grouping. This means that a small
    change of 0.01 or 0.02 in the threshold occasionally has a big impact on how many
    groups there are, possibly changing from just 1 or 2 groups to 5 or 10.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大的挑战是，有时相关性的微小变化会对分组产生不成比例的影响。这意味着阈值在0.01或0.02的小幅度变化偶尔会对组数产生重大影响，可能从只有1或2组变为5或10组。
- en: In my own studies, I have written an alternative version of the grouping algorithm
    in listing 6.4, where the parameter is the number of blocks to produce. It uses
    an algorithmic search to return the grouping with the desired number of groups.
    This is a nice programming exercise that I leave for you to try; it is helpful
    if you have a hard time finding a correlation threshold due to irregular responses
    to small changes. But you can use this approach (choosing a number of blocks)
    only if you have already experimented enough to have a good idea of what to choose.
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在我的研究中，我编写了一个分组算法的替代版本，如列表6.4所示，其中参数是生成的块数。它使用算法搜索来返回具有所需组数的分组。这是一个很好的编程练习，我留给你们去尝试；如果你因为对微小变化的反应不规则而难以找到相关阈值，这将很有帮助。但只有在你已经足够实验，对选择什么有很好的想法时，你才能使用这种方法（选择块数）。
- en: In chapter 8, when we look at statistics, you’ll learn more about this subject.
    When you use statistical analysis, there can be some real problems if you group
    behaviors incorrectly by using too high a correlation threshold. But, for now,
    you know enough to do a good job on your own data.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在第8章中，当我们查看统计数据时，你会了解更多关于这个主题的内容。当你使用统计分析时，如果你使用过高的相关性阈值错误地分组行为，可能会出现一些真正的问题。但，到目前为止，你已经知道足够的信息来处理你自己的数据。
- en: 6.4 Explaining correlated metric groups to businesspeople
  id: totrans-291
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.4 向商业人士解释相关度量组
- en: 'This chapter demonstrated the following:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 本章展示了以下内容：
- en: The importance of understanding correlation between your metrics
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解你度量指标之间相关性的重要性
- en: How to discover groups of related metrics
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何发现相关度量指标组
- en: How to perform churn analysis on metric group average scores
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何对度量组平均分数进行客户流失分析
- en: 'This chapter got pretty technical, and you might have learned some new terms:
    correlation matrix, loading matrix, and clustering (not to mention the real monster,
    hierarchical agglomerative clustering!). Now let’s take a deep breath and think
    about how you are going to explain all this to your business colleagues. This
    isn’t an issue if you are reading this book for educational purposes only, but
    this is a very big issue if you are trying to apply these techniques in a business
    context.'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 本章相当技术性，你可能学到了一些新术语：相关性矩阵、加载矩阵和聚类（更不用说真正的怪物——层次聚类了！）。现在让我们深呼吸，思考如何向你的业务同事解释所有这些。如果你只是出于教育目的阅读这本书，这不是问题，但如果你试图在商业环境中应用这些技术，这是一个非常大的问题。
- en: The concepts in this chapter are not that hard to understand, but there are
    a lot of technical details and jargon. I recommend starting simply and making
    sure to explain each concept with actual data from your own company. You can leave
    out the details of how everything gets done and just communicate the final results.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的概念并不难理解，但有很多技术细节和术语。我建议从简单开始，并确保用你自己的公司实际数据解释每个概念。你可以省略完成所有事情的具体细节，只传达最终结果。
- en: TAKEAWAY Your job is to shield your business colleagues from as much of the
    jargon as possible. So do not try to impress them with technical terms! Rather,
    try to simplify things to a common language.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 吸收要点：你的任务是尽可能让业务同事远离术语。所以不要试图用术语让他们印象深刻！相反，尝试将事情简化为共同语言。
- en: 'Here is how I usually handle it when I present case study results to a business
    audience for the first time:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我通常在第一次向商业听众展示案例研究结果时的处理方式：
- en: Before you begin, ask the businesspeople how much statistics they know. You
    should adapt your explanations based on their level of knowledge. In what follows,
    I’ll explain how to go through the concepts, assuming an average group of business
    users who do not have any statistics training but also aren’t scared of statistics.
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在开始之前，询问业务人士他们了解多少统计学知识。你应该根据他们的知识水平调整你的解释。以下内容，我将假设一个平均的业务用户群体，他们没有接受过任何统计学培训，但也不害怕统计学。
- en: Teach (or remind) everyone what correlations are by showing them scatterplots
    (like the ones in figure 6.1) that you created from the business’s own data. It’s
    fine (and necessary) to use the term correlation with the business, but you should
    probably drop the term coefficient. Even nonmathematical people understand correlations
    easily when they know which product behaviors go together. Showing them scatterplots
    and the correlation number is giving them a nice new way to look at something
    they already know.
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过展示你从业务数据中创建的散点图（如图6.1所示）来教（或提醒）每个人什么是相关性。使用“相关性”这个词与业务人士交流是可以的（也是必要的），但你可能应该放弃“系数”这个词。即使是非数学人士，当他们知道哪些产品行为是一起发生的时，也容易理解相关性。向他们展示散点图和相关性数字，是在给他们提供一种全新的方式来看待他们已经知道的东西。
- en: Show the heatmap, organized (after you have formed the groups) and formatted
    more or less like the one in figure 6.5 (except use full color). I try to avoid
    the term matrix with businesspeople, so I usually just describe it as a correlation
    heatmap and not a correlation matrix. After they have learned about individual
    correlations, they usually understand the overall pattern shown by the heatmap
    too. Again, this is showing something they already know intuitively, so they like
    it (and heatmaps look cool!).
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 展示热图，组织（在你形成组之后）并且格式上与图6.5中的类似（除了使用全色）。我尽量避免在商人面前使用“矩阵”这个词，所以我通常只是将其描述为相关性热图，而不是相关性矩阵。在他们了解了单个相关性之后，他们通常也能理解热图所展示的整体模式。同样，这是展示他们已经直觉上知道的东西，所以他们喜欢（而且热图看起来很酷！）。
- en: 'Show them the metrics that form the groups, both by outlining them in the heatmap
    (see figure 6.5) and by giving them a list of what metrics are in each group.
    You need to explain that the groups are formed automatically and based on the
    data (they must understand you did not choose the groups). Do not attempt to explain
    the details of the algorithm. but you can mention it is a clustering algorithm
    if there are relatively technical people in the group:'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向他们展示形成这些组的指标，既可以通过在热图中概述它们（见图6.5），也可以通过给他们列出每个组中包含哪些指标。你需要解释这些组是自动形成的，并且基于数据（他们必须理解你并没有选择这些组）。不要试图解释算法的细节。但如果组里有一些相对技术性的人，你可以提到它是一个聚类算法：
- en: They might debate the grouping, and that’s healthy. If they challenge the grouping
    in a sensible way, you might want to try adjusting the threshold as described
    in section 6.3.4\. But make sure they realize that you cannot (or at least should
    not) manually choose the groups.
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 他们可能会对此进行辩论，这是有益的。如果他们以合理的方式挑战分组，你可能想尝试调整第6.3.4节中描述的阈值。但确保他们意识到你不能（或者至少不应该）手动选择组。
- en: Show them the behavioral cohort analysis that was done on the grouped metrics
    and how it compares to the cohort analysis on the individual metrics (just a selection
    of individual metrics, if there are a lot).
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向他们展示对分组指标进行的群体行为分析，以及它与对单个指标（如果有很多的话，则仅选择单个指标）的群体分析如何比较。
- en: 'That’s it! You’re done. In particular, you do not need to discuss the following
    terms or algorithms with businesspeople:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！你已经完成了。特别是，你不需要与商业人士讨论以下术语或算法：
- en: Matrix (either for the correlation matrix or the loading matrix)
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矩阵（无论是相关矩阵还是加载矩阵）
- en: Loading
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载
- en: Matrix multiplication
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矩阵乘法
- en: Clustering (or even worse, hierarchical agglomerative clustering)
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类（甚至更糟，层次聚类）
- en: Hierarchical clustering vs. principal component analysis
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 层次聚类与主成分分析比较
- en: If you studied statistics or data science, there is a good chance you learned
    a technique called principal component analysis (PCA). PCA is similar to hierarchical
    clustering (HC) in that it reduces the number of metrics in a dataset by multiplication
    with a loading matrix. But the loading matrix from PCA is derived using a different
    technique than HC. PCA has some nice properties that statisticians like, but it
    is beyond the scope of this book because it’s not very useful for churn, and the
    loadings it produces are too difficult to interpret for most people. However,
    the loadings produced by HC and PCA have a lot in common, which this figure illustrates.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你学习过统计学或数据科学，你很可能学过一种称为主成分分析（PCA）的技术。PCA与层次聚类（HC）相似，因为它通过乘以加载矩阵来减少数据集中指标的数量。但PCA的加载矩阵是通过与HC不同的技术推导出来的。PCA具有统计学家喜欢的某些良好属性，但由于它对客户流失不太有用，并且它产生的加载对于大多数人来说太难解释，所以它超出了本书的范围。然而，HC和PCA产生的加载有很多共同之处，如图所示。
- en: '![](../Images/6-20.png)'
  id: totrans-313
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/6-20.png)'
- en: Comparison of the loading matrices for hierarchical clustering (HC) and principal
    component analysis (PCA)
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 层次聚类（HC）和主成分分析（PCA）的加载矩阵比较
- en: This figure was created by calculating a PCA loading matrix and ordering the
    metrics in the same order as the HC groups. When run on the same data, the blocks
    discovered by HC are usually similar to clusters of high weights in the PCA loading
    matrix. You can see that the two algorithms are capturing some of the same underlying
    properties of the data. But the PCA loading matrix has both positive and negative
    weights, and every entry in the loading matrix is nonzero. Details of how to interpret
    a PCA loading matrix are beyond the scope of this book.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 此图是通过计算PCA加载矩阵并按与HC组相同的顺序排列指标创建的。当在相同的数据上运行时，HC发现的块通常与PCA加载矩阵中高权重的聚类相似。你可以看到，这两个算法正在捕捉数据的一些相同的基本属性。但是，PCA加载矩阵既有正权数也有负权数，加载矩阵中的每个条目都不为零。如何解释PCA加载矩阵的细节超出了本书的范围。
- en: (continued)
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: （继续）
- en: One important point to note is that because the PCA matrix has negative as well
    as positive weights, the resulting grouped metrics are not simply averages but
    also differences between the (scored) metrics. A difference between two subscriber
    metrics means a derived metric that is high when one metric is high and the other
    is low, in contrast to an average or total, which is high when both metrics are
    high. Differences between scored subscriber metrics are not very intuitive but
    can be important because they measure how much one behavior exceeds another. For
    example, if you had scored metrics for local calls and international calls on
    a telecommunications service, the difference would show whether a subscriber is
    more or less an international or local caller. Differences like that can be important
    for understanding engagement, but differences between scored metrics produced
    by loading matrices with negative entries are difficult to interpret. The next
    chapter teaches techniques to capture information about differences between behaviors
    in a way that is easily understandable by businesspeople and data people alike.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 一个需要注意的重要点是，由于PCA矩阵既有负权重也有正权重，因此得到的分组度量不仅仅是平均值，还包括（评分）度量之间的差异。两个订阅度量之间的差异意味着一个派生度量，当其中一个度量值高而另一个低时，该度量值高，而平均或总度量值在两个度量值都高时才高。评分订阅度量之间的差异不太直观，但可能很重要，因为它们衡量一个行为超过另一个行为多少。例如，如果你对一个电信服务中的本地通话和国际通话进行了评分度量，差异将显示订阅者是更多还是更少地进行国际或本地通话。这样的差异对于理解参与度可能很重要，但由具有负条目的载荷矩阵产生的评分度量之间的差异很难解释。下一章将教授捕捉行为之间差异信息的技术，以便商业人员和数据人员都能容易理解。
- en: Summary
  id: totrans-318
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Correlation in the positive sense refers to when a high value on one metric
    is consistently associated with a high value on another metric, or when an increase
    in one metric is consistently associated with an increase in another.
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正相关是指当一个度量值高时，总是与另一个度量值高相关联，或者当一个度量值增加时，总是与另一个度量值增加相关联。
- en: Negative correlation refers to when an increase in one metric is associated
    with a decrease in another. Negative correlation is rare in customer behavioral
    metrics on events.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 负相关是指当一个度量值增加时，与另一个度量值减少相关联。在事件客户行为度量中，负相关很少见。
- en: The correlation coefficient is a statistical measure of correlation that ranges
    between -1 and 1, where 1 means perfect positive correlation, and -1 means perfect
    negative correlation.
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相关系数是介于-1和1之间的相关性的统计度量，其中1表示完美的正相关，而-1表示完美的负相关。
- en: Correlation coefficients measure the consistency of the relationship between
    two metrics but are insensitive to the ratio implied by the relationship. Equivalently,
    the units or scale of the metrics is irrelevant to correlation.
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相关系数衡量两个度量值之间关系的一致性，但对关系所暗示的比率不敏感。等价地，度量的单位或刻度对相关性无关紧要。
- en: Pairwise metric scatterplots are a good way to visualize individual correlations
    in your data, but there can be too many pairs to look at them all.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成对度量散点图是可视化数据中单个相关性的好方法，但可能存在太多对需要查看。
- en: A correlation matrix is a table of all the pairwise correlation coefficients
    in a dataset and is an efficient way to explore a large number of correlations.
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相关系数矩阵是一个包含数据集中所有成对相关系数的表格，并且是探索大量相关性的有效方式。
- en: When metrics are highly correlated, you can improve a churn analysis by averaging
    together the scores of the correlated metrics.
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当度量值高度相关时，你可以通过平均相关度量的分数来提高客户流失分析。
- en: A loading matrix is a table of the weights used to average metrics. It is used
    in the calculation of the average scores.
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 载荷矩阵是一个用于平均度量的权重的表格。它在平均分数的计算中使用。
- en: Matrix multiplication of the loading matrix by the dataset is the operation
    that efficiently performs the averaging of grouped metrics.
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 载荷矩阵与数据集的矩阵乘法是执行分组度量平均的有效操作。
- en: After averaging metric scores together with a loading matrix, you can do behavioral
    cohort analysis of churn using the averaged scores. This often gives stronger
    results than the individual metrics.
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在使用载荷矩阵平均度量分数后，你可以使用平均分数进行客户流失的行为群体分析。这通常比单个度量给出更强的结果。
- en: Clustering means to group together related items based on some measure of similarity
    among their data.
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类是指根据数据中相关项之间的相似度度量将它们分组在一起。
- en: Hierarchical clustering is an algorithm that can be used to group together correlated
    metrics. The algorithm stops at a threshold in the correlation level so that all
    strongly correlated metrics become grouped.
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 层次聚类是一种可以将相关度量分组在一起的算法。该算法在相关性的阈值处停止，以便所有高度相关的度量都被分组在一起。
- en: After running hierarchical clustering, you use the result to create a loading
    matrix.
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行层次聚类后，您使用结果创建一个负载矩阵。
