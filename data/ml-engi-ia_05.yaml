- en: '5 Experimentation in action: Planning and researching an ML project'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 实验行动：规划和研究机器学习项目
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: The details of a project’s research phase
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 项目研究阶段的细节
- en: The process and methodology of conducting solution experimentation for a project
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对项目进行解决方案实验的过程和方法
- en: 'We spent the preceding two chapters focusing on the processes surrounding planning,
    scoping of work, and communication among a team working on an ML project. This
    chapter and the next two focus on the next most critical aspects of ML work as
    it pertains to data scientists: research, experimentation, prototyping, and MVP
    development.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前两章中专注于围绕机器学习项目规划、工作范围和团队沟通的过程。本章和接下来的两章将关注与数据科学家相关的机器学习工作的下一个最关键方面：研究、实验、原型设计和
    MVP 开发。
- en: Once a project’s requirements have been thoroughly captured from planning meetings
    (as much as can be realistically achieved) and the goal of the modeling solution
    has been defined, the next phase of creating an ML solution is to begin *experimentation
    and research*. These processes, conducted without an appropriate level of structure,
    can easily result in a cancelled project.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦从规划会议中彻底捕捉到项目的需求（尽可能实现的部分）并且定义了建模解决方案的目标，创建机器学习解决方案的下一阶段就是开始 *实验和研究*。如果没有适当的结构，这些过程很容易导致项目取消。
- en: Projects may be cancelled because of a seemingly endless experimentation phase,
    wherein no clear direction for finalizing an approach to a solution is decided
    on. Stalled projects may also be the result of poor predictive capabilities. Whether
    due to indecision or an inability to meet accuracy expectations, the prevention
    of stalled and cancelled projects that have data and algorithm issues starts in
    the experimentation phase.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 项目可能会因为看似无休止的实验阶段而被取消，在这个阶段中，对于最终确定解决方案的方法没有明确的方向。停滞的项目也可能是由于预测能力差造成的。无论是由于犹豫不决还是无法满足准确度期望，防止因数据和算法问题而停滞和取消的项目，始于实验阶段。
- en: No concrete rule set exists for estimating exactly how long an experimentation
    phase should last, because a myriad of complexities may arise from each unique
    project. However, the methodologies in this chapter guarantee a reduction in the
    amount of time to reach a favorable MVP state and a marked reduction in the amount
    of duplicate effort that a team would face were they to approach experimentation
    without such methods.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 没有具体的规则集可以用来精确估计实验阶段应该持续多长时间，因为每个独特项目都可能产生无数复杂情况。然而，本章中的方法确保了达到有利的 MVP 状态所需时间的减少，以及显著减少了团队在没有这些方法进行实验时可能面临的重复工作量的减少。
- en: This chapter covers the first phase of ML experimentation, as shown in figure
    5.1\. We will go through a proven method for setting up an effective experimentation
    environment, evaluating a dataset through the creation of reusable visualization
    functions, and conducting research and modeling approach validations in a controlled
    and efficient manner to help get to the MVP phase earlier with less rework.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖机器学习实验的第一阶段，如图 5.1 所示。我们将介绍一种经过验证的方法来设置有效的实验环境，通过创建可重用的可视化函数来评估数据集，并以受控和高效的方式进行研究和建模方法验证，以帮助更早地进入
    MVP 阶段，并减少返工。
- en: '![05-01](../Images/05-01.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![05-01](../Images/05-01.png)'
- en: Figure 5.1 The ML experimentation process
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1 机器学习实验过程
- en: We’ll see how to organize and plan appropriate research, set expectations and
    rules within the planning phase, properly analyze the scenario that we’ll be solving
    in this chapter to inform our model selection and experimentation, and finally,
    conduct our experiments and build useful utilities for the project at hand. All
    of these stages and processes are designed to maximize the opportunity to have
    an easier development period and to minimize not only the risk of creating technical
    debt from the start of the project, but also the risk of project abandonment.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将了解如何组织并规划适当的研究，在规划阶段设定期望和规则，正确分析本章中我们将要解决的场景，以指导我们的模型选择和实验，最后，进行实验并为当前项目构建有用的工具。所有这些阶段和过程都是为了最大限度地提高开发期更容易的机会，并最大限度地减少不仅从项目开始就产生技术债务的风险，而且还有项目放弃的风险。
- en: We spent the previous chapters working through the pre-experimentation phases
    of a recommendation engine for an e-commerce company. We’re going to use a much
    simpler example in these next few chapters in the interests of brevity. While
    this time-series modeling project is much simpler than many ML implementations,
    the aspects that we’re covering are generally universally applicable to all ML
    work; when they are not, I provide additional comments in sidebar discussions.
    As with all things in software development, a quality project starts with planning.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们一直在处理一家电子商务公司推荐引擎的预实验阶段。为了简洁起见，在接下来的几章中，我们将使用一个更简单的例子。虽然这个时间序列建模项目比许多机器学习实现都要简单，但我们所涉及的内容通常普遍适用于所有机器学习工作；当它们不适用时，我在侧边栏讨论中提供额外的注释。就像软件开发中的所有事情一样，一个高质量的项目始于规划。
- en: 5.1 Planning experiments
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 规划实验
- en: Let’s pretend for this chapter that we work for a company that is in the business
    of supplying peanuts (specifically, those individual-serving wrapped peanuts that
    are handed out on most major airlines throughout the world, coupled with a square
    napkin, a ridged plastic cup engineered to tip beverages into laps when a seatmate
    adjusts to a more comfortable position, and a twice-pasteurized can of carbonated
    beverage). The business unit in charge of logistics for the peanuts has requested
    a project to be developed that can forecast demand of these sad in-flight snacks
    because of the increased pressure that they are getting from airlines about the
    excessive quantities of bulk-shipped dry-roasted legumes that they continually
    have to throw away when their expiration dates strike.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们假设在这个章节中，我们为一家从事花生供应业务的公司工作（具体来说，是那些在世界上大多数主要航空公司发放的单独包装的花生，附带一张方形餐巾、一个设计成当邻座调整到更舒适的位置时会把饮料洒到腿上的凹槽塑料杯，以及一罐经过两次巴氏杀菌的碳酸饮料）。负责花生物流的业务单元要求开发一个项目，以预测这些悲伤的机上零食的需求量，因为航空公司对他们在保质期到期时不断丢弃的大量干烤豆类的大量运输施加了压力。
- en: The meetings have been conducted, the requirements have been gathered, and the
    ML team has internally discussed the project. The general consensus is that we’re
    looking at a simple demand forecast time-series prediction problem. But where
    do we start, now that we know the problem that we’re trying to solve? We also
    have two weeks to come up with a rough MVP to show that we have a proven approach
    to solving this problem. Best get to it.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 会议已经召开，需求已经收集，机器学习团队已经内部讨论了该项目。普遍共识是我们面对的是一个简单的需求预测时间序列预测问题。但现在我们知道了我们试图解决的问题是什么？我们还有两周的时间来提出一个粗略的最小可行产品（MVP），以证明我们有一个经过验证的解决方案。最好立即着手。
- en: '![05-02](../Images/05-02.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![05-02](../Images/05-02.png)'
- en: Figure 5.2 The ML experimentation planning phase road map
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.2 机器学习实验规划阶段路线图
- en: 'What we’re going to be getting to is illustrated in figure 5.2: the planning
    phase of ML experimentation. In this phase, a lot of things will be read, most
    will hopefully be retained in our heads, and many browser bookmarks will be created.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要讨论的内容如图 5.2 所示：机器学习实验规划阶段。在这个阶段，我们将阅读很多东西，希望大部分都能保存在我们的脑海中，并且会创建许多浏览器书签。
- en: 5.1.1 Perform basic research and planning
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.1 进行基本研究和规划
- en: The first thing that the team members are going to do, once they get back to
    their desks after the planning meeting, is look at the data available. Since we’re
    a peanut manufacturer, and not in any partnership with major airlines, we’re not
    going to get ticket sales forecasting data. We certainly don’t have time to build
    web scrapers to attempt to see flight capacity for each airport (nor would anyone
    want to do this who has ever attempted to build a scraper before). What we do
    have available, though, is historic passenger capacity that the airport transit
    authorities provide freely.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦团队成员在规划会议后回到他们的办公桌，他们要做的第一件事就是查看可用的数据。由于我们是花生制造商，并且没有与主要航空公司有任何合作，我们无法获得机票销售预测数据。我们当然没有时间构建网络爬虫来尝试查看每个机场的航班容量（也没有人愿意做这件事，因为之前尝试过构建爬虫的人都知道）。不过，我们确实有机场交通管理局免费提供的乘客容量历史数据。
- en: We know from figure 5.2 that one of the first actions that we should be doing
    to understand the nature of the data is to visualize it and run a few statistical
    analyses we have available. Most people would simply load the data into their
    local computer’s environment and begin working in a notebook.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 从图 5.2 我们知道，为了了解数据的性质，我们应该做的第一件事是可视化它并运行一些我们可用的统计分析。大多数人会简单地将数据加载到他们的本地计算机环境中，并在笔记本中开始工作。
- en: This is a recipe for disaster, though. A default Python environment that is
    running on the main operating system of your primary computer is anything but
    pristine. To minimize the amount of time wasted on struggling with a development
    environment (and help prepare for a smooth transition to the development phase
    later), we need to create a clean environment for our testing. For guidance on
    getting started with Docker and Anaconda to create a development environment for
    the code listings in this chapter and all subsequent chapters, see appendix B
    at the end of this book.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种灾难性的做法。在您的首选计算机的主要操作系统上运行的默认 Python 环境远非纯净。为了最小化在开发环境中挣扎所浪费的时间（并帮助为后续章节的开发阶段顺利过渡做准备），我们需要为我们的测试创建一个干净的环境。有关如何使用
    Docker 和 Anaconda 创建用于本章和所有后续章节代码列表的开发环境的指导，请参阅本书末尾的附录 B。
- en: Now that we have an isolated environment (with persistence of the notebook storage
    location on the container mapped to a local filesystem location), we can get the
    sample data into this location and create a new notebook for experimentation.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有一个隔离的环境（笔记本存储位置在容器中映射到本地文件系统位置），我们可以将样本数据放入此位置并创建一个新的笔记本进行实验。
- en: A quick visualization of the dataset
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的快速可视化
- en: 'The first thing that should be done before choosing an ML approach to solving
    the problem is the most trivial (but frequently overlooked) aspect of data science:
    getting to know your data. For the airport forecasting, let’s take a look at the
    data available to us. Listing 5.1 demonstrates a scripted approach to quickly
    visualize one of the time series (JFK domestic passengers) that needs to be forecasted.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择机器学习方法来解决该问题之前，应该做的第一件事是最简单（但经常被忽视）的数据科学方面：了解您的数据。对于机场预测，让我们看看我们可用的数据。列表
    5.1 展示了一种快速可视化需要预测的一个时间序列（JFK 国内乘客）的方法。
- en: NOTE To follow along exactly with this example, you can acquire this dataset
    by cloning a repo maintained by the Alan Turing Institute. Navigate to the local
    notebook directory that was synced in the steps outlined in appendix B and run
    through the command-line statement `git``clone``https://github.com/alan-turing-institute/TCPD.git`.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：要精确地跟随此示例，您可以通过克隆艾伦·图灵研究所维护的存储库来获取此数据集。导航到附录 B 中概述的步骤同步的本地笔记本目录，并运行命令行语句
    `git clone https://github.com/alan-turing-institute/TCPD.git`。
- en: Listing 5.1 Visualizing the data
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.1 可视化数据
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Makes a shallow copy of the DataFrame so we can use mutable modifications
    to it
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 对 DataFrame 进行浅拷贝，以便我们可以对其进行可变修改
- en: ❷ Converts the Month column to a datetime object so we can assemble the date
    from it. (Currently, it’s a string three-letter abbreviation of the month.)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将月份列转换为日期对象，以便我们可以从它组装日期。（目前，它是一个月份的三字母缩写字符串。）
- en: ❸ Adds a constant literal column so we can assemble a date column
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 添加一个常数列，以便我们可以组装日期列
- en: ❹ Assembles the date column for our row-based index for each airport
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 为每个机场组装基于行的索引的日期列
- en: ❺ Filters the DataFrame so we’re looking at only a single airport (in this case,
    JFK)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 过滤 DataFrame，以便我们只查看单个机场（在本例中为JFK）
- en: ❻ Sorts the DataFrame by date so the time series is ordered correctly for plotting
    (and future activities)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 按日期对 DataFrame 进行排序，以便正确地按顺序绘制时间序列（以及未来的活动）
- en: ❼ Sets the index of the filtered DataFrame to the date column
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 将过滤后的 DataFrame 的索引设置为日期列
- en: After executing listing 5.1 in the notebook read-eval-print loop (REPL), we’ll
    get a simple visualization of the time-series trend, showing the monthly passengers
    who have made domestic flights inside the United States from 1977 to 2015\. The
    matplotlib window is shown in figure 5.3.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在笔记本的读取-评估-打印循环（REPL）中执行列表 5.1 后，我们将得到一个简单的时间序列趋势可视化，显示 1977 年至 2015 年间在美国国内航班的月度乘客数量。matplotlib
    窗口如图 5.3 所示。
- en: '![05-03](../Images/05-03.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![05-03](../Images/05-03.png)'
- en: Figure 5.3 Basic default visualization of the raw data
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.3 原始数据的基本默认可视化
- en: 'Seeing this raw data displayed, we can start thinking through our plans for
    the experimentation phase. First, we come up with questions that should be answered
    to inform not only the research that we’ll need to do in order to understand our
    options for forecasting, but also the platform decisions (which are covered in
    depth in section 5.2). Here are our data observations and questions:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 看到这些原始数据展示出来，我们可以开始思考实验阶段的计划。首先，我们提出应该回答的问题，这些问题不仅将指导我们为了理解预测选项而需要进行的调查，还将指导平台决策（这在第5.2节中有深入讨论）。以下是我们的数据观察和问题：
- en: Latent factors are influencing the trend. The data doesn’t look stationary.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 潜在因素正在影响趋势。数据看起来不具有平稳性。
- en: The data seems to have a strong seasonality component.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据似乎有一个强烈的季节性成分。
- en: We have thousands of airports to model. We need to think about scaling the approach
    that we choose.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要为成千上万的机场建模。我们需要考虑选择的方法的可扩展性。
- en: What models are good for this use case?
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于这个用例，哪些模型是好的？
- en: We have two weeks to come up with a direction for approaching this. Can we get
    this done?
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们有两周的时间来制定这个问题的处理方向。我们能完成吗？
- en: Both the questions for this phase of data visualization and the answers can
    help create a more effective experimentation phase for the project. Jumping directly
    to creating the model and testing random ideas too early can create a great deal
    of wasted work that sets the delivery for an MVP back in terms of meeting the
    deadlines. It will always be an effective use of time to understand the nature
    of your dataset and uncover any hidden issues prior to researching potential solutions,
    as this phase can help reduce the amount of testing and additional research by
    culling options early.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据可视化阶段的问题和答案都可以帮助为项目创建一个更有效的实验阶段。过早地直接创建模型和测试随机想法可能会产生大量的浪费工作，从而推迟了MVP的交付，使其无法按时完成。在研究潜在解决方案之前，始终理解数据集的性质和揭示任何隐藏问题都是有效利用时间的方法，因为这个阶段可以帮助通过早期淘汰选项来减少测试和额外研究。
- en: Research phase
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 研究阶段
- en: Now that we know some of the concerns with the data—it’s highly seasonal, with
    trends influenced by latent factors that are wholly unknown to us—we can start
    researching. Let’s pretend for a moment that no one on the team has ever done
    time-series forecasting. Where, without the benefit of expert knowledge on the
    team, should research begin?
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经了解了一些数据的问题——它具有高度的季节性，趋势受到我们完全未知的潜在因素的影响——我们可以开始研究。让我们暂时假设团队中没有一个人做过时间序列预测。在没有团队专家知识的情况下，研究应该从哪里开始？
- en: Internet searches are a great place to start, but most search results show blog
    posts of people offering forecasting solutions that involve a great deal of hand-waving
    and glossing over of the complexities involved in building out a full solution.
    Whitepapers can be informative but generally don’t focus on the applications of
    the algorithms that they’re covering. Lastly, script examples from Getting Started
    guides for different APIs are wonderful for seeing the mechanics of the API signature
    but are intentionally simplistic to serve as nothing more than a basic starting
    point, as the name indicates.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 网络搜索是一个很好的起点，但大多数搜索结果都显示了人们提供的时间序列预测解决方案的博客文章，这些文章涉及大量的挥手和简化了构建完整解决方案所涉及的复杂性。白皮书可能是有信息的，但通常不关注他们所涵盖的算法的应用。最后，不同API入门指南中的脚本示例对于了解API签名的工作原理非常棒，但它们故意简化，仅作为基本起点的参考，正如其名称所示。
- en: So, what should we be looking at to figure out how to predict future months
    of passenger demand at airports? The short answer is books. Quite a few great
    ones exist on time-series forecasting. In-depth blogs can help as well, but they
    should be used exclusively as an initial approach to the problem at hand, rather
    than as a repository from which to directly copy code.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们应该关注哪些方面来弄清楚如何预测机场未来几个月的旅客需求？简短的答案是书籍。关于时间序列预测有很多优秀的书籍。深入的研究博客也有帮助，但它们应该仅作为解决手头问题的初始方法，而不是直接复制代码的代码库。
- en: Note The seminal work *Time Series Analysis* by G. E. P. Box and G. M. Jenkins
    (Holden-Day, 1970) is widely considered the foundation of all modern time-series
    forecasting models. The Box-Jenkins methodologies are the basis for nearly all
    forecasting implementations today.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：G. E. P. Box 和 G. M. Jenkins 所著的奠基性作品《时间序列分析》（Holden-Day，1970年）被广泛认为是所有现代时间序列预测模型的基础。Box-Jenkins
    方法是今天几乎所有预测实现的基础。
- en: 'After a bit of research into time-series forecasting, we find a few options
    that seem commonly used enough to warrant some effort in implementing a rough
    scripted approach. The short list that we decide to try out is as follows:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在对时间序列预测进行了一些研究之后，我们发现了一些似乎足够常用，值得努力实现粗略脚本方法的选项。我们决定尝试的简短列表如下：
- en: Linear regression (OLS, ridge, lasso, elastic net, and ensemble)
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性回归（OLS、岭回归、Lasso、弹性网络和集成）
- en: ARIMA (autoregressive integrated moving average)
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ARIMA（自回归积分移动平均）
- en: Exponential smoothing (Holt-Winters)
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指数平滑（Holt-Winters）
- en: VAR (vector autoregression)
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VAR（向量自回归）
- en: SARIMA (seasonal autoregressive integrated moving average)
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SARIMA（季节性自回归积分移动平均）
- en: With that list of things to test out, the next step is to figure out which packages
    have these algorithms and read through their API documentation. A good rule to
    live by in the ML world is to establish a healthy library and a team budget to
    continuously expand that library. Having a collection of in-depth guides in the
    form of technical books can help a great deal with new challenges that the team
    will face and ensure that the nuanced complexity of applications of ML can be
    done with the right information.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在有了要测试的这些列表之后，下一步是找出哪些包有这些算法，并阅读它们的 API 文档。在机器学习世界中，一个很好的生活规则是建立一个健康的库和团队预算，以持续扩展该库。拥有一系列深入的技术书籍可以帮助团队应对新的挑战，并确保机器学习应用的细微复杂性能够用正确的信息来完成。
- en: 5.1.2 Forget the blogs—read the API docs
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.2 忘掉博客——阅读 API 文档
- en: Project failure is almost guaranteed when a team—typically, a rather junior
    team—believes so thoroughly in the veracity of a blog post that it bases an entire
    project around the methodology (and sometimes the exact code) of that blog. While
    almost always well-intentioned, authors of short blog posts on ML topics are not
    able, because of the format of the medium, to cover in the depth necessary all
    the information required to be garnered for a real-world production ML solution.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个团队——通常是一个相当年轻的团队——如此坚信博客文章的真实性，以至于他们围绕该博客的方法（有时甚至是确切代码）构建整个项目时，项目失败几乎是必然的。虽然几乎总是出于好意，但关于机器学习主题的短博客作者由于媒体格式的限制，无法深入覆盖所有必要的信息，这些信息对于现实世界的生产级机器学习解决方案至关重要。
- en: Let’s look at what a blog post might have for our time-series problem. If we
    were to search for “time series forecasting example,” we’d likely find more than
    a few results. Forecasting, after all, has been around for quite some time. What
    we’ll likely find, though, are code snippets that are highly scripted, using the
    API defaults, and omit many of the finer details needed to make the exercise repeatable.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看博客文章可能为我们的时间序列问题提供什么。如果我们搜索“时间序列预测示例”，我们可能会找到很多结果。毕竟，预测已经存在很长时间了。我们可能会发现的是，代码片段高度脚本化，使用
    API 默认值，并省略了许多使练习可重复的更细微的细节。
- en: If you choose to follow along with the example (provided that it has convinced
    you of the approach), you’ll likely end up spending a few hours looking up API
    documentation and getting frustrated with something that the author made look
    simple, only to find out that they left out all the complex details in an effort
    to hit that magic 10-minute read that people of low attention spans are so hungry
    for. The following listing is an example snippet from a fictional blog on elastic
    net regression (scikit-learn example) for demonstration purposes.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你选择跟随此示例（假设它已经说服了你），你可能会花几个小时查找 API 文档，并对作者看起来简单的东西感到沮丧，结果发现他们为了达到那神奇的 10
    分钟阅读时间，省略了所有复杂的细节。以下是从一个虚构的弹性网络回归博客（scikit-learn 示例）中摘取的示例片段，用于演示目的。
- en: Listing 5.2 A blog example for elastic net from scikit-learn
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.2 来自 scikit-learn 的弹性网络博客示例
- en: '[PRE1]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ Uses the built-in datasets—a solid move for a reproducible demo
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用内置数据集——对于可重复的演示来说是一个稳健的举措
- en: ❷ Random sample split
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 随机样本分割
- en: ❸ Sure hope the defaults are OK . . .
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 希望默认值是好的……
- en: ❹ I guess we don’t need a reference to the fit model?
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 我想我们不需要对拟合模型进行引用？
- en: ❺ A single metric? Surely, we can do better than that. . . .
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 单个指标？当然，我们可以做得更好……
- en: 'What are the issues in using this code? Setting aside the atrocious formatting
    and wall of text, let’s enumerate the problems with using an example like this
    as a foundation for performing a time-series regression:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此代码有哪些问题？抛开糟糕的格式化和文本墙，让我们列举一下将此类示例作为进行时间序列回归基础的问题：
- en: It’s a demo. A fairly poor one at that. But it’s meant to be as *simple as possible*,
    showing the broad strokes of the APIs.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是一个演示。相当糟糕的一个。但它的目的是尽可能简单，展示API的大致轮廓。
- en: The train-test split uses random sampling. This will not bode well for predicting
    a time series. (Keep in mind that the blog is intended to show elastic net regression,
    not a time-series problem.)
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练-测试分割使用随机抽样。这不会对预测时间序列产生好结果。（请记住，博客的目的是展示弹性网络回归，而不是时间序列问题。）
- en: The model uses default hyperparameters. This is, for the purposes of a blog,
    entirely understandable for the sake of brevity, but doesn’t help out the reader
    much in knowing what they might need to change in order to make it applicable
    to their use case.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型使用默认的超参数。从博客的简洁性考虑，这是可以理解的，但这并不帮助读者了解他们可能需要更改什么才能将其应用于他们的用例。
- en: It is method chaining and printing to stdout in such a way that the objects
    are not usable for further processing
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是一种方法链和打印到标准输出的方式，使得对象无法用于进一步处理。
- en: Don’t get me wrong here. Blogs are good. They help teach new concepts and provide
    inspiration for alternate solutions for problems that you may be working on. The
    primary reason I always tell people to not rely on them too much is that they’re
    meant to be digestible, concise, and simple. To achieve those three goals, along
    with the overarching mission of maximum brevity, the finer details absolutely
    have to be omitted.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 请不要误解我的意思。博客是好的。它们有助于教授新概念，并为可能正在解决的问题提供替代解决方案的灵感。我总是告诉人们不要过度依赖它们的主要原因在于，它们旨在易于消化、简洁和简单。为了实现这三个目标，以及最大简洁性的总体目标，绝对必须省略细节。
- en: A note about blogs
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 关于博客的注意事项
- en: I don’t want to make it seem like I’m knocking them. They’re great. They provide
    a wonderful introduction to concepts and potential solutions that are absolutely
    invaluable. If you’re a blog writer, please, keep up the amazing work. It really
    does help out. If you’re a blog reader, just, you know, proceed with caution.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我不想让人觉得我在批评他们。他们很棒。他们提供了对概念和潜在解决方案的精彩介绍，这些内容绝对是无价的。如果你是博客作者，请继续保持出色的表现。这真的很有帮助。如果你是博客读者，请谨慎行事。
- en: Some truly great blog posts surrounding ML are on the internet. Unfortunately,
    these are drowned out by blogs filled with overly simplistic proofs-of-concept,
    broken code, or unintentionally horrific programming practices. If you’re using
    blogs as a primary point of basic research when starting a project, just keep
    in mind that basing your prototype directly off example code from a blog might
    be OK, but you will have to completely rewrite the solution when building an MVP.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 网上有关机器学习的真正优秀的博客文章有很多。不幸的是，这些文章被充斥着过于简化的概念证明、损坏的代码或无意中糟糕的编程实践的博客淹没。如果你在开始一个项目时将博客作为基本研究的主要来源，请记住，直接基于博客中的示例代码构建原型可能没问题，但在构建最小可行产品（MVP）时，你将不得不完全重写解决方案。
- en: My best advice, if using blogs as a primary reference tool, is to vet the ideas
    by quorum. Do you see multiple people writing about similar (but not identical)
    solutions using a particular approach? Then it’s probably a safe bet to test the
    approach on your data.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果将博客作为主要参考工具，我的最好建议是通过对多个观点进行审查。你是否看到多个人使用特定方法撰写关于类似（但不完全相同）的解决方案？那么，在您的数据上测试这种方法可能是一个安全的赌注。
- en: Do you see a particular solution that has the exact same code examples in multiple
    blogs? It’s likely this is a copy-paste job to get advertising revenue or some
    other nefarious ruse. The more blogs you look at, the more that you’ll be able
    to sniff bad code and poor implementation, and determine whether the author knows
    what they’re talking about and can be trusted.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否看到过在多个博客中存在完全相同的代码示例的特定解决方案？这很可能是为了获取广告收入或进行其他恶意行为而进行的复制粘贴工作。你查看的博客越多，你就能越容易嗅出糟糕的代码和糟糕的实现，并判断作者是否真的了解他们在谈论的内容，以及是否值得信赖。
- en: 'Just remember: the one thing that you never want to do is base your implementation
    directly off code copied from a blog post. Blogs are written for brevity and usually
    focused on covering only a narrow topic. This short-form writing does not lend
    itself to realistic examples of production code, and as such, should always be
    seen for what it actually is: a means of communicating a single topic in the shortest
    span of text and time possible.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 只需记住：你绝对不希望直接基于从博客文章中复制的代码来实现你的实现。博客是为了简洁而编写的，通常只关注覆盖一个狭窄的主题。这种短篇写作不适合生产代码的现实示例，因此它应该始终被视为它实际是的东西：以尽可能短的时间和文字跨度传达一个单一主题的手段。
- en: Instead of blindly trusting a blog post by basing the project around something
    that seems like it will work, you need to check and vet additional sources of
    information. These include academic papers, API tutorials, published books on
    the subject, and, most critically, an effective testing and validation phase of
    the team’s approach. Having a project cancelled because the copied (or copied
    in essence) work from a blogger’s informative post about something new that they’ve
    learned recently is not only detrimental to the business’s opinion of the DS team,
    but also potentially dangerous.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是盲目地相信基于似乎会起作用的项目的博客文章，你需要检查和核实额外的信息来源。这包括学术论文、API教程、关于该主题的出版书籍，以及，最重要的是，团队方法的测试和验证阶段。由于从博主关于他们最近学到的新东西的信息性帖子中复制的（或本质上复制的）工作导致项目取消，这不仅对业务对DS团队的看法有害，而且可能具有潜在的危险性。
- en: No, seriously, read the API docs
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 不，认真地说，阅读API文档
- en: Once we have the list of modeling approaches that we want to test, we should
    head over to the API documentation for the module that we’re using. If we do that
    for elastic net, as an example, we’ll find that the hyperparameters for this model
    have a few options that are pretty important to test and tune, as reflected in
    the following listing.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了想要测试的建模方法列表，我们应该前往我们使用的模块的API文档。以弹性网络为例，如果我们这样做，我们会发现这个模型的超参数有几个重要的选项需要测试和调整，如下所示。
- en: Listing 5.3 The full API signature for elastic net on scikit-learn
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.3 scikit-learn中弹性网络的完整API签名
- en: '[PRE2]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ The penalty applied to the l1 and l2 regularization
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 应用到l1和l2正则化的惩罚
- en: ❷ The elastic net mixing parameter (how much of ridge vs. lasso)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 弹性网络混合参数（岭回归与lasso的比例）
- en: ❸ Whether to fit the intercept (pretty important to know based on whether data
    centering is happening)
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 是否拟合截距（根据数据中心化是否发生，这是一个很重要的问题）
- en: ❹ Used only when fit_intercept is False. Performs normalization by subtracting
    the mean and dividing by l2-norm.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 仅当fit_intercept为False时使用。通过减去平均值并除以l2范数进行归一化。
- en: ❺ Either Boolean or an array of the feature shape as a gram matrix to speed
    up the calculations
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 要么是布尔值，要么是一个特征形状的数组，作为语法矩阵来加速计算
- en: ❻ The maximum number of iterations allowed for convergence
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 允许收敛的最大迭代次数
- en: ❼ Whether to copy the training set
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 是否复制训练集
- en: ❽ Optimization tolerance for whether to continue to attempt to converge on each
    iteration
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 每次迭代是否继续尝试收敛的优化容忍度
- en: ❾ Whether to reuse the solution of the previous iteration for initialization
    of the model fit
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ❾ 是否重用前一次迭代的解决方案来初始化模型拟合
- en: ❿ Whether the coefficients in the linear equation will be forced to be positive
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ❿ 线性方程中的系数是否将被强制为正值
- en: ⓫ Seed value if the selection type is “random”
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: ⓫ 如果选择类型是“随机”，则种子值
- en: ⓬ Selection type for coefficient selection (cyclic is default and loops over
    the feature vector, while random utilizes random coefficient selection for a different
    feature each iteration)
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ⓬ 系数选择的选取类型（循环是默认值，它遍历特征向量，而随机则在每个迭代中为不同的特征使用随机系数选择）
- en: For many ML algorithms, the options (hyperparameters) specified as defaults
    are occasionally good for some common data structures being passed into them.
    But it’s always best to verify what those options are and what they are used for,
    and identifying ones that should be tuned is an essential part of building an
    effective model. Many times, these options are specified simply as placeholders,
    with the API developer fully intending for the end user to override those values.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多机器学习算法，默认指定的选项（超参数）偶尔对某些常见的数据结构来说是好的。但始终最好验证这些选项是什么，以及它们被用于什么，并识别出应该调整的选项是构建有效模型的一个基本部分。很多时候，这些选项只是简单地作为占位符指定，API开发者完全希望最终用户覆盖这些值。
- en: TIP Like anything else in the world of DS, don’t assume anything. Assumption
    results in problems coming to haunt you later in your project work.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: TIP 就像DS世界中的任何其他事物一样，不要假设任何事情。假设会导致问题在项目后期工作中困扰你。
- en: Based on the list of models that the team has agreed to test out, everyone on
    the team should head off to familiarize themselves with the options available
    for the signatures of each model’s API. This is important to handle early so that
    when the results of each quick-and-dirty experiment are run, the maintainability
    and complexity of the model can be weighed in concert with the accuracy metrics
    that are typically the sole point of judgment.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 根据团队同意测试的模型列表，团队中的每个人都应该去熟悉每个模型API的签名选项。这很重要，以便在运行每个快速且粗略的实验结果时，可以同时权衡模型的可维护性和复杂性以及通常作为唯一判断点的准确性指标。
- en: No, really, you should read the docs
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 真的，你应该阅读文档
- en: I’ve always been a bit surprised when I see someone using a particular API,
    sometimes for a production use case, without having ever read the documentation
    surrounding that API (including myself, in hindsight). I’ve been surprised in
    the sense that most people would be surprised to see a cabin crew member step
    into the cockpit of an airplane and start flying the aircraft. Can they keep it
    aloft? Sure (well, hopefully). Do they know how the aircraft works and the dynamics
    of flight? Probably not. Let’s hope that the skies stay clear and blue.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 当我看到有人使用特定的API时，有时甚至用于生产用例，而从未阅读过围绕该API的文档（包括我自己，事后看来），我总是有点惊讶。我惊讶的原因是大多数人会惊讶地看到一名乘务员走进飞机驾驶舱并开始驾驶飞机。他们能保持飞机在空中吗？当然（希望如此）。他们知道飞机的工作原理和飞行动力学吗？可能不知道。让我们希望天空保持晴朗和蓝色。
- en: This isn’t to say that you should be reading every single developer API doc
    for each module you’re ever going to use. That’s untenable and a bit ridiculous.
    However, in the world of ML, where the number of available algorithms is seemingly
    endless (not to mention the inner workings of the code powering those algorithms
    are exceedingly complex and lengthy), it’s quite important to read the API docs
    from at least the main interface level.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是说你应该阅读你将要使用的每个模块的每一个开发者API文档。这是不可行的，而且有点荒谬。然而，在机器学习的世界里，可用的算法数量似乎无穷无尽（更不用说那些算法背后的代码的内部工作原理极其复杂且冗长），因此阅读至少主要接口级别的API文档非常重要。
- en: This means becoming familiar with the classes that you’re using, their signatures,
    and the methods that you’re using within those classes. There’s no need to reverse
    engineer the package. However, at the very least, you should become familiar with
    the doc string descriptions of the class, know which attributes to pass in or
    override, and understand the basic functionality of the methods that you’re going
    to be calling and interfacing with.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着要熟悉你正在使用的类，它们的签名，以及你在这些类中使用的方法。没有必要逆向工程包。然而，至少你应该熟悉类的文档字符串描述，知道哪些属性需要传递或覆盖，并理解你将要调用和与之交互的方法的基本功能。
- en: The implementation of most of these algorithms has nuances (particularly the
    higher-level meta-algorithms whose entire behavior is determined by configuration).
    Understanding which knobs need to be turned, how to turn them, and the implications
    of spinning those knobs can help reduce risk during testing. It will save you
    a lot of time and frustration, particularly once you move on to the full development
    of the solution, knowing which default values are placeholders and which are generally
    good values to leave as is.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数这些算法的实现都有细微差别（尤其是那些由配置决定整个行为的高级元算法）。了解需要调整哪些旋钮，如何调整它们，以及旋转这些旋钮的后果可以帮助在测试期间降低风险。这将节省你大量的时间和挫败感，尤其是当你转向解决方案的完整开发时，知道哪些默认值是占位符，哪些是一般情况下可以保留的值。
- en: We’ll discuss these concepts in greater detail later this book, but for now,
    you have an understanding of why all the settings are specified for the APIs throughout
    this MVP simulation in this chapter.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本书的后面部分更详细地讨论这些概念，但到目前为止，你应理解为什么在本章中这个MVP模拟的整个API中指定了所有设置。
- en: A critical function of API docs is in informing a user of the options available
    for controlling the behavior of the software (and in turn, for ML use cases, the
    algorithms’ learning patterns). Without understanding how to control the model’s
    learning behavior, we run the risk of building models that are unable to generalize
    well because of overfit, or are so fragile that even a slight change in the baseline
    variability of the feature inputs will make the solution absolutely useless to
    a business.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: API 文档的一个关键功能是向用户告知可用于控制软件行为（以及相应地，对于机器学习用例，算法的学习模式）的选项。如果不了解如何控制模型的学习行为，我们就有可能构建出无法很好地泛化的模型，因为过度拟合，或者模型过于脆弱，以至于特征输入的基线变异性的一点点变化都会使解决方案对业务完全无用。
- en: When a model becomes useless, performing worse than a manual human-centric solution,
    it’s usually abandoned by the business (even if it is still running in production
    by the ML team). Understanding how to tune and control the behavior of the model
    properly in the early stages of experimentation is critical, even though the act
    of fine-tuning it is not necessary during this phase.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个模型变得无用，表现不如手动的人为中心解决方案时，它通常会被业务放弃（即使它仍然由机器学习团队在生产环境中运行）。在实验的早期阶段，正确地调整和控制模型的行为至关重要，尽管在这个阶段进行微调的行为并不是必要的。
- en: Quick testing and rough estimates
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 快速测试和粗略估计
- en: Perhaps the only time in ML project work that extensive evaluation of appropriate
    hyperparameter tuning can be ignored is at this point. During the rapid evaluation
    period, we’re not particularly interested in seeing how well we can optimize a
    model’s fit to our data. Rather, we’re interested in measuring the general sensitivity
    of a group of disparate algorithms, trying to gauge how stable a particular approach
    will be later when we’re fine-tuning our models and maintaining them through drift
    situations.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习项目工作中，可能唯一一次可以忽略对适当超参数调整的广泛评估的时间点就是现在。在快速评估期间，我们并不特别关心我们如何优化模型与数据的拟合程度。相反，我们感兴趣的是测量一组不同算法的总体敏感性，试图评估在后期当我们微调模型并维护它们以应对漂移情况时，特定方法将有多稳定。
- en: The previous section covered why it’s important to know how to tune each model
    by reading through the API docs (and perhaps the source code as well). But for
    the rapid testing phase, it simply isn’t tenable to tune all of these (see the
    following sidebar on overbuilding). While going through the process of whittling
    down those nine possible implementations to something more manageable for MVP
    implementation and full testing, it can be helpful to just use most of the defaults
    and see what the results look like. It is also a useful practice, however, to
    either explicitly mark the instantiation blocks with the provided default conditions
    or to just leave a `TODO` in the code to make sure, when ready to move toward
    full tuning of a model for the MVP phase, that the API documentation is checked
    and the optional settings that are part of the API are validated and tested.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 前一节涵盖了为什么通过阅读 API 文档（以及可能还有源代码）了解如何调整每个模型很重要。但在快速测试阶段，调整所有这些（参见以下关于过度构建的边栏）根本不可行。在将这九种可能的实现削减为更适合
    MVP 实施和全面测试的更易管理的东西的过程中，仅仅使用大多数默认设置并查看结果可能是有帮助的。然而，明确标记实例化块以使用提供的默认条件，或者只是在代码中留下一个
    `TODO`，以确保在准备进入 MVP 阶段对模型进行全面调整时，检查 API 文档，并验证和测试 API 中的可选设置，这也是一个有用的实践。
- en: A note on overbuilding a rapid prototype test
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 关于过度构建快速原型测试的注意事项
- en: The focus in the early smoke test experimentation for candidate solutions should
    be on speed and not accuracy. Keep in mind that you work for a company, results
    are expected, and there are likely other projects to work on.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在对候选解决方案的早期烟雾测试实验中，重点应放在速度上，而不是准确性。记住，你是在为公司工作，预期会有结果，而且可能还有其他项目需要工作。
- en: I mentioned in previous chapters some of the dangers of overdeveloping a prototype
    (it makes it harder to decide what to choose for an MVP). Looking at the bigger
    picture, though, the more detrimental effect of unnecessary work is on the business.
    Every day that the team is working on proving out different solutions is a day
    that’s not available to work on the next project.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我提到了过度开发原型的一些危险（它使得决定选择什么用于最小可行产品变得更加困难）。然而，从更大的角度来看，不必要的劳动对业务的损害更为严重。团队每天都在努力证明不同的解决方案，而这些时间本可以用来工作在下一个项目上。
- en: Efficiency, objective selection based on common criteria, and moving to developing
    an MVP should always be the primary focus of prototyping. Nothing else. There
    will be time during the MVP phase to build out better accuracy, clever feature
    engineering, and creative approaches to the problem.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 效率、基于共同标准的客观选择，以及转向开发MVP始终应该是原型设计的首要关注点。没有其他事情。在MVP阶段，将有时间构建更好的准确性、巧妙的功能工程和解决问题的创造性方法。
- en: We’ll go through testing examples for our forecasting problem in the next chapter.
    For now, just know that for the initial round of exploratory work and evaluating
    solutions, the predictions don’t have to be perfect. Your time will be much better
    spent focusing your energy on culling the list of possibilities so that you have
    one or two candidate solutions, rather than spending an inordinate amount of time
    fine-tuning nine (or more) approaches.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一章中通过测试示例来介绍我们的预测问题。现在，只需知道，在初步的探索工作和评估解决方案阶段，预测不必完美。你将把更多的时间花在精简可能性列表上，以便你有一个或两个候选解决方案，而不是花大量时间微调九个（或更多）方法。
- en: 5.1.3 Draw straws for an internal hackathon
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.3 为内部黑客马拉松抽签
- en: Setting boundaries around testing is incredibly critical, particularly as a
    team grows in number and project complexity grows as the team matures in experience.
    In pursuit of efficiency (and the aforementioned critical *time* aspect of picking
    a direction for building an MVP), it can be absolutely detrimental to the success
    of a project if testing isn’t assigned to individuals or pair-programming teams.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试周围设定界限至关重要，尤其是在团队规模增长和项目复杂性随着团队经验的成熟而增长时。为了追求效率（以及选择构建MVP方向时上述关键的*时间*方面），如果没有将测试分配给个人或结对编程团队，这可能会对项目的成功造成绝对的损害。
- en: If everyone is left to just figure out the best solution, duplicated work and
    excessive effort will undoubtedly be placed on particular solutions. By focusing
    on a single approach, with consistent status updates on its progress, the team
    can minimize the chance of missing the delivery date for the MVP.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如果每个人都只负责找出最佳解决方案，无疑会重复工作并过度努力在某些解决方案上。通过专注于单一方法，并对其进展进行一致的状态更新，团队可以最小化错过MVP交付日期的风险。
- en: 'Now that we’ve come up with a list of potential solutions for our forecasting
    model, how do we go about testing them? Whether the team includes a single person
    or a dozen data scientists, the approach should be the same:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经为我们的预测模型想出了一系列可能的解决方案，我们该如何测试它们？无论团队中只有一个人还是十几名数据科学家，方法应该是相同的：
- en: Block off a set amount of time to do the testing. Giving an end-time deadline
    to this phase will impart a sense of urgency so that a decision can be made quickly
    on the efficacy of the solution.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为测试预留一定的时间。为这个阶段设定一个结束时间截止日期将传达一种紧迫感，以便可以快速决定解决方案的有效性。
- en: 'Set some rules, just as you would for a hackathon:'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 制定一些规则，就像为黑客马拉松做的那样：
- en: Everyone must use the same dataset.
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个人都必须使用相同的dataset。
- en: Everyone must use the same evaluation metrics.
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个人都必须使用相同的评估指标。
- en: Each evaluation needs to forecast over the same time period.
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每次评估都需要在相同的时间段内进行预测。
- en: Visualizations of the forecast, along with metrics, need to be provided.
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要提供预测的可视化以及指标。
- en: The experimentation code needs to be re-runnable from scratch.
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实验代码需要从头开始可重跑。
- en: Make sure that the language chosen is supportable by the team and that the platform
    it’s running on is available for the team to use if the business decides to move
    forward with the solution.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保所选语言得到团队的支持，并且如果业务决定继续推进解决方案，该平台对团队可用。
- en: 'If we set up the experimentation in this way, for this problem, we would likely
    have the following rules based on this dataset:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们以这种方式设置实验，针对这个问题，我们可能会基于这个dataset制定以下规则：
- en: One week of testing—starting on Thursday after the scrum meeting, the presentations
    are due on the following Thursday morning for review by the entire team.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试一周——从scrum会议后的星期四开始，演示文稿将在下一个星期四上午提交，以便整个团队进行审查。
- en: The data to be modeled is for JFK domestic passengers.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要建模的数据是针对JFK国内乘客的。
- en: 'The eval metrics will be as follows:'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估指标将如下：
- en: Mean absolute error (MAE)
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 均绝对误差 (MAE)
- en: Mean absolute percentage error (MAPE)
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 均方绝对百分比误差 (MAPE)
- en: Mean squared error (MSE)
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 均方误差 (MSE)
- en: Root mean square error (RMSE)
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根均方误差 (RMSE)
- en: R-squared
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: R-squared
- en: The forecast period for evaluation will be the last five years of the dataset.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估的预测期将是数据集的最后五年。
- en: Experimentation will be done in Jupyter notebooks running Python 3, utilizing
    the standard Anaconda build in a Docker container.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实验将在运行Python 3的Jupyter笔记本中完成，利用内置在Docker容器中的标准Anaconda构建。
- en: 'With the rules established, the team (if count(team) > 1 else you) can set
    about figuring out solutions. Before we get into looking at how that would be
    done in an efficient way, we have just one more thing to cover: standards.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在确立了规则之后，团队（如果团队计数大于1，则为“你”）可以着手寻找解决方案。在我们深入研究如何以高效的方式完成这项工作之前，我们还有最后一件事要讨论：标准。
- en: 5.1.4 Level the playing field
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.4 平衡竞争环境
- en: For our experimentation to be meaningful with these nine separate approaches,
    we need to ensure that we’re playing fairly. This means that we’re not only comparing
    using the same dataset, but also evaluating the test data against the predictions
    with the exact same error metrics. The core issue that we need to prevent is indecision
    and chaos among the team when measuring the effectiveness of a solution (which
    wastes time that, as we’ve mentioned before, we simply don’t have if we want to
    move to the MVP phase of the project).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使我们的实验这九种不同的方法具有意义，我们需要确保我们是在公平竞争。这意味着我们不仅使用相同的dataset进行比较，而且还将测试数据与预测值使用完全相同的误差指标进行评估。我们需要防止的核心问题是团队在衡量解决方案的有效性时出现犹豫不决和混乱（这浪费了时间，正如我们之前提到的，如果我们想进入项目的MVP阶段，我们根本就没有时间）。
- en: Since we’re looking at a time-series problem, we’re going to evaluate a regression
    problem. We know that, to do a true comparison, we need to control the data splits
    (which we will explore throughout the code examples in section 5.2), but we also
    need to agree on an evaluation metric that each model is going to record to do
    the comparison of goodness of fit of the prediction. Since we’re eventually going
    to need to build thousands of these models, and the raw prediction values are
    of wildly different orders of magnitude (just slightly more people fly through
    JFK and ATL than do through, say, Boise), the team members have agreed to use
    MAPE as the comparison metric. In a wise decision, though, they have also agreed
    to capture as many regression metrics as are applicable to a time-series regression
    problem, should they choose to switch to a different metric during tuning later
    for the per model optimizations.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们正在研究一个时间序列问题，我们将评估一个回归问题。我们知道，为了进行真正的比较，我们需要控制数据拆分（我们将在第5.2节中的代码示例中探讨这一点），但我们还需要就每个模型将要记录以进行预测拟合度比较的评估指标达成一致。由于我们最终需要构建数千个这样的模型，而原始预测值具有截然不同的数量级（例如，通过JFK和ATL机场飞行的人数略多于通过博伊西机场的人数），团队成员已同意使用MAPE作为比较指标。然而，在明智的决定中，他们还同意捕获尽可能多的适用于时间序列回归问题的回归指标，以便在后续的模型优化过程中，如果他们选择切换到不同的指标，可以进行相应的调整。
- en: For this reason, we’ll agree to collect metrics on MAPE, MAE, MSE, RMSE, explained
    variance, and R-squared. This way, we’ll have the flexibility to discuss the benefits
    of the different metrics as they relate to the data and to the project.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将同意收集MAPE、MAE、MSE、RMSE、解释方差和R平方的度量标准。这样，我们将能够根据数据和相关项目讨论不同指标的好处。
- en: The metric wars and how to solve them
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 度量战争及其解决方法
- en: A lot of opinions exist on the best metrics to use for different ML solutions.
    Innumerable hours have been wasted in ridiculous arguments over whether to use
    MSE or RMSE, whether an F1 score is appropriate versus area under ROC, and whether
    a normalization of MAE should be applied, turning it into MAPE.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 对于不同机器学习解决方案的最佳度量标准存在许多意见。无数小时被浪费在无意义的争论中，争论是否使用均方误差（MSE）或均方根误差（RMSE），F1分数是否比ROC曲线下的面积更合适，以及是否应该对平均绝对误差（MAE）进行归一化，将其转换为平均绝对百分比误差（MAPE）。
- en: There’s definitely a great argument to be made for selecting the appropriate
    metric for each use case. However, calculating errors is usually pretty cheap
    and fast. It doesn’t hurt to calculate all of the applicable ones and record them
    all. Obviously, don’t record categorical metrics for a regression problem (that
    would be incredibly ill-advised) or vice versa, but slapping down MAE, MSE, and
    R-squared calculations for a model to ensure that the benefits of each method
    can be utilized for determination can prove helpful.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 确定每个用例的适当指标确实是一个很好的论点。然而，计算误差通常既便宜又快。计算所有适用的指标并记录它们并不会有什么坏处。显然，不要为回归问题记录分类指标（那将是非常不明智的），反之亦然，但为模型提供MAE、MSE和R平方的计算以确保每种方法的利益可以被利用，这可能会很有帮助。
- en: It is likewise similarly invaluable to record them all in case, while building
    out a solution and tuning it, the team decides to utilize a different metric.
    Having each metric there from the beginning can give a historical reference for
    each run that was attempted without having to go back to rerun old experiments
    just to collect additional metrics (which is both costly and time-consuming).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，记录所有这些内容也是非常有价值的，以防在构建解决方案和调整过程中，团队决定使用不同的指标。从一开始就记录每个指标，可以为每个尝试运行的实验提供历史参考，而无需重新运行旧实验来收集额外的指标（这既昂贵又耗时）。
- en: The only notable exception to collecting all the metrics exists if the metric
    evaluation is so expensive (computationally) that the benefit that it provides
    outweighs the cost of calculating it. For instance, in chapter 4’s recommendation
    engine, a calculation for NDCG involves a window function over a large corpus
    of data (the implicit scoring data), which can take hours to execute on a relatively
    large Apache Spark cluster. Calculating these scores in a relational database
    management system (RDBMS) involves expensive Cartesian joins, which can take even
    longer. If the metric is not critical and takes periods of time to execute that
    don’t justify its collection, then it’s best not to waste time with it.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 收集所有指标的唯一明显例外是，如果指标评估（在计算上）非常昂贵，那么它提供的利益超过了计算它的成本。例如，在第4章的推荐引擎中，NDCG的计算涉及一个在大型数据集（隐式评分数据）上的窗口函数，这在相对较大的Apache
    Spark集群上可能需要数小时才能执行。在关系数据库管理系统（RDBMS）中计算这些分数涉及昂贵的笛卡尔积，这可能需要更长的时间。如果指标不是关键的，并且执行时间过长，不划算收集，那么最好不要浪费时间在它上面。
- en: 5.2 Performing experimental prep work
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 进行实验准备工作
- en: After the planning and research phase is completed by a team focused on building
    an ML solution to a business problem, the next phase, preparation for experimental
    testing, is one of the most oft-omitted activities in the DS community (speaking
    from personal experience here). Even with a solid plan of who is going to test
    what, an agreed-upon series of metrics, an evaluation of the dataset, and an agreed-upon
    methodology of how far into experimentation each team will be going, this preparatory
    phase, if ignored, will create more inefficiencies that can lead to a project
    being delayed. This preparatory phase is focused on doing a deep analysis of the
    datasets, creating common tools that the entire team can use in order to increase
    the speed at which they can evaluate their experimental attempts.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个专注于构建解决商业问题的机器学习解决方案的团队完成规划和研究阶段之后，接下来的阶段，即实验测试的准备阶段，是数据科学社区中最常被忽视的活动之一（这里从个人经验来说）。即使有一个明确的计划，确定谁将测试什么，达成一致的指标系列，对数据集进行评估，以及达成一致的实验深度方法论，如果这个准备阶段被忽视，将会产生更多的低效率，可能导致项目延迟。这个准备阶段专注于对数据集进行深入分析，创建整个团队都可以使用的通用工具，以便提高他们评估实验尝试的速度。
- en: At this point, we’ve decided on some models to try, set the ground rules for
    the experimentation phase, and selected our language (Python, mostly because of
    the statsmodels library) and our platform (Jupyter Notebook running on Docker
    containers so we don’t waste our time with library compatibility issues and can
    rapidly prototype tests and see visualizations directly). Before we start firing
    off a bunch of modeling tests, it’s important to understand the data as it relates
    to the problem at hand.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经决定尝试一些模型，为实验阶段设定了基本规则，并选择了我们的语言（主要是Python，因为statsmodels库）和我们的平台（在Docker容器上运行的Jupyter
    Notebook，这样我们就不必浪费时间在库兼容性问题上了，并且可以快速原型测试并直接查看可视化）。在我们开始发射大量建模测试之前，了解与当前问题相关的数据非常重要。
- en: For this forecasting project, that means going through a thorough analysis of
    stationarity tests, a decomposition of the trend, identification of severe outliers,
    and building basic visualization tooling that will aid in the rapid phases of
    model testing that the subteams will be doing. As shown in figure 5.4, we’ll cover
    each of these key stages of preparation work to ensure that each of our hacking
    teams will have an efficient development process and won’t be focused on creating
    nine different copies of the same way of plotting and scoring their results.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个预测项目，这意味着对平稳性测试进行彻底分析、分解趋势、识别严重异常值，并构建基本的可视化工具，这些工具将有助于子团队快速进行模型测试。如图 5.4
    所示，我们将涵盖这些准备工作的关键阶段，以确保我们的黑客团队将有一个高效的开发过程，并且不会专注于创建九种不同的绘图和评分结果的方式。
- en: '![05-04](../Images/05-04.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![05-04](../Images/05-04.png)'
- en: Figure 5.4 The analysis phase, focusing on evaluating the data to inform the
    prototyping work
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.4 分析阶段，专注于评估数据以指导原型设计工作
- en: This analysis pathing is highly dependent on the type of ML project being undertaken.
    For this time-series forecasting, these are a good set of items to accomplish
    prior to building prototype solutions to evaluate. Each step is fairly applicable
    to any supervised ML problem. For an NLP project, however, you would have slightly
    different actions to perform in this stage.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这种分析路径高度依赖于正在进行的 ML 项目的类型。对于这种时间序列预测，在构建原型解决方案以评估之前，完成这些项目是一个好主意。每一步都相当适用于任何监督式
    ML 问题。然而，对于 NLP 项目，在这个阶段你需要执行一些不同的操作。
- en: The point of showing these processes and the order in which they need to be
    done is to illustrate that a plan needs to be developed before working on model
    prototyping. Without one, the evaluation phase will be guaranteed to be long,
    arduous, chaotic, and likely inconclusive.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 展示这些过程及其执行顺序的目的是为了说明在开始模型原型设计工作之前，需要制定一个计划。没有计划，评估阶段肯定会是漫长、艰难、混乱的，并且可能不会有结论。
- en: 5.2.1 Performing data analysis
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.1 执行数据分析
- en: In the course of researching possible solutions, a lot of people seem to find
    trend visualizations pretty helpful. Not only does this activity prepare for baseline
    visualizations of the data to the broader business unit team that will be the
    consumers of the project solution, but it can help minimize unforeseen issues
    with the data that might be uncovered much later in the project; these issues
    could require a complete rework of the solution (and potentially a cancellation
    of the project if the rework is too expensive from a time and resources perspective).
    To marginalize the risk associated with finding out too late about a serious flaw
    in the data, we’re going to build a few analytics visualizations.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究可能的解决方案的过程中，很多人似乎发现趋势可视化非常有帮助。这项活动不仅为数据的基本可视化做准备，以便向将成为项目解决方案消费者的更广泛的业务单元团队展示，而且有助于最小化在项目后期可能发现的未预见的数据问题；这些问题可能需要完全重新设计解决方案（并且如果从时间和资源角度来看重新设计成本过高，可能还需要取消项目）。为了降低发现数据严重缺陷过晚的风险，我们将构建一些分析可视化。
- en: Based on the initial raw data visualization built in listing 5.1 (and shown
    in figure 5.3), we notice a great deal of noise in the dataset. Having a great
    deal of noise in a trend can certainly help visualize the general trend line,
    so let’s start by applying a smoothing function to the raw data trend for the
    domestic passengers at JFK. The script that we’re going to be executing is in
    the following listing, utilizing basic matplotlib visualizations.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 根据列表 5.1 中构建的初始原始数据可视化（如图 5.3 所示），我们注意到数据集中存在大量的噪声。趋势中的大量噪声当然有助于可视化总体趋势线，因此让我们首先对
    JKF 国内乘客的原始数据趋势应用平滑函数。我们将执行的脚本如下所示，使用了基本的 matplotlib 可视化。
- en: Listing 5.4 Moving average trend with two-sigma error
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.4 带有两倍标准差误差的移动平均趋势
- en: '[PRE3]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Generates a rolling average series based on a year’s period of smoothing
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 基于一年的平滑周期生成滚动平均系列
- en: ❷ Generates the standard deviation series on the same rolling time period as
    the smoothed rolling average
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在与平滑滚动平均相同的滚动时间周期内生成标准差系列
- en: ❸ Initializes the plot with the raw data (domestic passengers) and creates a
    label for the legend box
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 使用原始数据（国内乘客）初始化图表，并为图例框创建标签
- en: ❹ Applies the rolling average series to the plot
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 将滚动平均系列应用于图表
- en: ❺ Applies the rolling stddev series at two-sigma to the plot by adding and subtracting
    the values from the rolling average series
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 通过添加和减去滚动平均值系列中的值，将两倍标准差的滚动标准差系列应用于图表
- en: ❻ Puts a title to the plot so exported images from this are instantly identifiable
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 为图表添加标题，使得从该图表导出的图像可以立即识别
- en: ❼ Displays the plot in stdout
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 在标准输出中显示图表
- en: NOTE The code shown here and throughout section 5.2 is for rapid experimentation
    only. Section 5.22 covers more effective ways to write MVP code.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：这里和5.2节中展示的代码仅用于快速实验。5.22节涵盖了编写MVP代码的更有效方法。
- en: Running this code in our Jupyter notebook will generate the plot shown in figure
    5.5\. Note how the general trend of the data looks when smoothed and realize that
    a definite step function occurs around 2002\. Also note that the stddev varies
    widely during different time periods. After 2008, the variance becomes much broader
    than it had been historically.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的Jupyter笔记本中运行此代码将生成图5.5所示的图表。注意数据在平滑后的总体趋势，并意识到在2002年左右发生了一个明确的阶梯函数。此外，还要注意标准差在不同时间段内变化很大。在2008年之后，方差变得比历史上更宽。
- en: '![05-05](../Images/05-05.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![05-05](../Images/05-05.png)'
- en: Figure 5.5 Baseline smoothing and sigma fits from listing 5.4
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.5 从列表5.4中得到的基线平滑和sigma拟合
- en: The trend is OK, and somewhat useful for understanding the potential problems
    that might arise from building training and validation datasets that don’t reflect
    the trend change. (Specifically, we can see what might happen if we train up to
    the year 2000 and expect that a model will accurately predict from 2000 to 2015.)
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 趋势是好的，并且对于理解可能出现的潜在问题有一定的帮助，这些问题可能来自于构建不反映趋势变化的训练和验证数据集。（具体来说，我们可以看到如果我们训练到2000年并期望模型能够从2000年准确预测到2015年，可能会发生什么。）
- en: During the research and planning phase, however, we found a great many mentions
    of stationarity in time series and how certain model types can really struggle
    with predicting a nonstationary trend. We should take a look at what that is all
    about.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在研究和规划阶段，我们发现时间序列平稳性的提及非常多，以及某些模型类型在预测非平稳趋势时可能会遇到真正的困难。我们应该看看这是怎么回事。
- en: For this, we’re going to use an augmented Dickey-Fuller stationarity test, provided
    in the statsmodels module. This test will inform us of whether we need to provide
    stationarity adjustments to the time series for particular models that are incapable
    of handling nonstationary data. If the test comes back with a value indicating
    that the time series is stationary, essentially all models can use the raw data
    with no transformations applied to it. However, if the data is nonstationary,
    extra work will be required. The script to run this test for the JFK domestic
    passengers series is shown next.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 对于此，我们将使用statsmodels模块中提供的增强迪基-富勒平稳性测试。此测试将告诉我们是否需要为无法处理非平稳数据的特定模型提供平稳性调整。如果测试返回的值表明时间序列是平稳的，则几乎所有模型都可以使用未经变换的原始数据。然而，如果数据是非平稳的，则需要额外的工作。接下来将展示用于对JFK国内乘客系列运行此测试的脚本。
- en: Listing 5.5 Stationarity test for a time series
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.5 时间序列平稳性测试
- en: '[PRE4]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ❶ Instantiates the adfuller (augmented Dickey-Fuller test) and sets the autolag
    to automatically minimize the information criterion for lag count determination
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 实例化adfuller（增强迪基-富勒测试）并设置autolag以自动最小化滞后计数的信息准则
- en: ❷ Grabs the first elements of the test results
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 获取测试结果的第一部分
- en: ❸ Creates a Boolean yes/no stationarity test. (In practice, it’s best to compare
    the test statistic to the critical values to make a true determination of stationarity.)
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 创建一个布尔值是/否平稳性测试。（在实践中，最好将测试统计量与临界值进行比较，以做出真正的平稳性判断。）
- en: ❹ Generates an indexed series of the information
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 生成信息的索引序列
- en: ❺ Extracts the critical values from the test statistics
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 从测试统计量中提取临界值
- en: Upon running this code, we get the result in figure 5.6, printed to stdout.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码后，我们得到图5.6的结果，并打印到标准输出。
- en: '![05-06](../Images/05-06.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![05-06](../Images/05-06.png)'
- en: Figure 5.6 Results of the augmented Dickey-Fuller test for stationarity. This
    is what we will see by running the code in listing 5.5.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.6 增强迪基-富勒测试的平稳性结果。这就是我们在列表5.5中运行代码时将看到的内容。
- en: OK, so that’s cool. But what does all of that mean?
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，那很酷。但这意味着什么呢？
- en: The *test statistic* (always negative) is a measure of the adjacency a time
    series has to containing a unit root. (If multiple unit roots—for example, a number
    of differencing functions—must be applied to the time series to make it essentially
    flat, then the less stationary it is.) In non-math terms, if the test statistic
    is less than the critical values, the series will be determined as stationary.
    In this case, our test statistic value is much higher than the critical values,
    thus giving us a null-accepting p-value where we can quite confidently state,
    “This is not stationary” (H0 of the `adfuller` test is that the time series is
    *nonstationary*).
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '*检验统计量*（总是负数）是衡量时间序列包含单位根的邻近性的度量。（如果必须对时间序列应用多个单位根——例如，多个差分函数——以使其基本平坦，那么它就越不平稳。）用非数学术语来说，如果检验统计量小于临界值，则该序列将被确定为平稳。在这种情况下，我们的检验统计量值远高于临界值，因此给出了一个接受零假设的p值，我们可以相当自信地说，“这不是平稳的”（`adfuller`测试的零假设是时间序列是*非平稳的*）。'
- en: 'Note If you’re curious about the theory and math behind the test, I highly
    encourage you to search for the original research papers: “Efficient Tests for
    an Autoregressive Unit Root” by Graham Elliot et al. (1996) as well as the foundational
    unit root theory espoused in the journal publication “Distribution of the Estimators
    for Autoregressive Time Series with a Unit Root” by D. A. Dickey and W. A. Fuller
    (1979).'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：如果你对测试背后的理论和数学感兴趣，我强烈建议你搜索原始研究论文：“Efficient Tests for an Autoregressive Unit
    Root” by Graham Elliot et al. (1996) 以及在期刊出版物“Distribution of the Estimators for
    Autoregressive Time Series with a Unit Root” by D. A. Dickey and W. A. Fuller
    (1979) 中阐述的基础单位根理论。
- en: Other interesting data is also in there—specifically, the number of lags discovered.
    We can look at this value in an additional way, which can help us figure out settings
    that we should be using when we get to the modeling phase with ARIMA-based models.
    The number 13 seems a bit odd, considering that we’re looking at monthly data
    here. If we were to blindly just use that value as a seasonality (period) component
    in our models, we would probably get some pretty terrible results. We can validate
    this, though, by looking at some trend decompositions in figure 5.7.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 其中还有其他有趣的数据——特别是发现的滞后数。我们可以以另一种方式查看这个值，这有助于我们确定在用基于ARIMA模型进入建模阶段时应使用的设置。考虑到我们在这里查看的是月度数据，数字13似乎有点奇怪。如果我们盲目地只将这个值作为模型中的季节性（周期）成分，我们可能会得到一些相当糟糕的结果。然而，我们可以通过查看图5.7中的某些趋势分解来验证这一点。
- en: We’re going to see if we can effectively decompose the trend, seasonality, and
    residuals in the signal with the built-in functionality in statsmodels, helping
    to inform some of the settings that we will need to use in the modeling experiments.
    Thankfully, the authors of the package have built out not only the decomposition
    methods, but also a nice visualization that we can easily plot out, as shown in
    the following listing. Let’s see what happens if we use the lag count from the
    `adfuller` report for the seasonality period.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将尝试使用statsmodels内置功能有效地分解信号中的趋势、季节性和残差，以帮助告知我们在建模实验中需要使用的某些设置。幸运的是，该软件包的作者不仅构建了分解方法，还提供了一个很好的可视化，我们可以轻松地绘制出来，如下面的列表所示。让我们看看如果我们使用`adfuller`报告中的滞后计数作为季节性周期会发生什么。
- en: Listing 5.6 Trend decomposition for seasonality
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.6 季节性分解趋势
- en: '[PRE5]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ Performs the seasonal decomposition with the adfuller lag value of 13
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用adfuller滞后值13进行季节性分解
- en: ❷ Gets a reference to the plot for storing. (It will automatically display inline
    as well.)
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 获取用于存储的绘图引用。（它将自动以内联方式显示。）
- en: ❸ Saves the plot for later reference
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 保存绘图以供以后参考
- en: Figure 5.7 shows what that chart looks like when the code from listing 5.6 is
    executed.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.7显示了当执行列表5.6中的代码时该图表的形状。
- en: '![05-07](../Images/05-07.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![05-07](../Images/05-07.png)'
- en: 'Figure 5.7 The trend decomposition plot consisting of (from top to bottom):
    the raw data, the extracted trend, the seasonality component, and the residuals.
    This doesn’t seem to be right.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.7 趋势分解图，从上到下包括：原始数据、提取的趋势、季节性成分和残差。这似乎不太对。
- en: Not exactly the most compelling data, is it? The residuals (the bottom pane)
    seem to have a signal in there. A residual should be the unexplained noise that
    is left over after the general trend and the seasonality are extracted from the
    data. But here, it seems as though quite a bit of actual repeatable signal is
    still in there. Let’s try a different run of this, but specifying the period as
    12, as shown in figure 5.8.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是最引人注目的数据，对吧？残差（底部面板）似乎存在一个信号。残差应该是从数据中提取出一般趋势和季节性之后留下的未解释的噪声。但在这里，似乎还有相当多的实际可重复信号。让我们尝试不同的运行，但指定周期为12，如图5.8所示。
- en: '![05-08](../Images/05-08.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![05-08](../Images/05-08.png)'
- en: Figure 5.8 The trend decomposition plots with the period set to 12 instead of
    13\. That’s a bit better.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.8 将周期设置为12而不是13的趋势分解图。这要好一些。
- en: The evaluation in figure 5.8 with the period value of 12 looks significantly
    better than the earlier test of 13\. Our trend is nice and smooth, our seasonality
    looks well matched to the periodicity of the repeated pattern in the data, and
    the residuals are (mostly) random. We’ll remember this value when we do testing
    in chapter 6.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在图5.8中，使用12个周期的评估看起来明显比之前的13个周期的测试要好。我们的趋势很平滑，季节性看起来很好地匹配了数据中重复模式的周期性，残差（大部分）是随机的。当我们第6章进行测试时，我们会记住这个值。
- en: The importance of doing this prep work ahead of time is to *inform our testing*.
    It is to guide the testing in such a way that we can rapidly iterate on experiments
    from a position of knowledge about the data, thereby getting to answers about
    approaches and their applicability to this problem faster.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之前完成这项准备工作的重要性在于*为我们的测试提供信息*。这是以数据知识为依据指导测试，从而能够快速迭代实验。
- en: Keep in mind that we’re going to be evaluating nine approaches to forecasting
    during the testing phase. The faster we can determine which of those nine are
    the two most promising candidates, the faster we can ignore the other seven and,
    collectively as a team, make progress toward our deadline for an MVP for the business.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，在测试阶段，我们将评估九种预测方法。我们越快确定这九种中哪两种最有希望，我们就越快可以忽略其他七种，并且作为一个团队，我们可以更快地向我们的MVP截止日期迈进。
- en: How clean is our data?
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据有多干净？
- en: Data cleanliness issues are one of the prime reasons for an MVP extending much
    longer than was promised to a business. Identifying bad data points is crucial
    not only for the purposes of modeling training effectiveness, but also to help
    tell a story to the business about why certain outputs of the model might be less
    than accurate at times. Building a series of visualizations that can communicate
    the complexities of latent factors, data-quality issues, and other unforeseen
    elements that can affect the solution can serve as a powerful tool during discussions
    with the project’s business unit.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 数据清洁问题是一个重要原因，导致MVP的延期时间远超过对企业的承诺。识别不良数据点不仅对建模训练效果至关重要，而且有助于向企业讲述为什么模型的一些输出有时可能不够准确的原因。构建一系列可视化，可以传达潜在因素、数据质量问题和其他可能影响解决方案的不可预见元素，可以在与项目业务单元的讨论中作为强大的工具。
- en: One of the most important points that we’ll have to explain about the forecasting
    from this project is that it will not, and cannot, be an infallible system. Many
    unknowns remain in our dataset—elements of influence to the trend that are either
    too complex to track, too expensive to model, or nearly impossible to predict—that
    need to feed into the algorithm. For the case of univariate time-series models,
    nothing is going into the model other than the trending data itself. In the case
    of more complex implementations, such as windowed approaches and deep learning
    models like long short-term memory (LSTM) recurrent neural networks (RNNs), even
    though we can create vectors that contain much more information, we don’t always
    have the capability or the time to collate all of the features that could influence
    the trend.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将不得不解释的关于本项目预测的最重要的一点是，它将不会，也不能成为一个无误的系统。在我们的数据集中仍有许多未知因素——影响趋势的元素，这些元素要么过于复杂难以追踪，要么建模成本过高，或者几乎无法预测，这些都需要输入到算法中。对于单变量时间序列模型，模型中除了趋势数据本身外，没有其他任何东西。在更复杂的实现中，例如窗口方法和长短期记忆（LSTM）循环神经网络（RNNs）等深度学习模型，尽管我们可以创建包含更多信息的向量，但我们并不总是有能力或时间收集所有可能影响趋势的特征。
- en: To aid in having this conversation, we can take a look at a simple method of
    identifying outlier values that are dramatically different from what we would
    otherwise expect from a seasonally influenced trend. A relatively easy way to
    do this with series data is to use a differencing function on the sorted data.
    This can be accomplished as shown in the following listing.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助进行这次对话，我们可以看看一种简单的方法来识别与季节性影响趋势相比差异巨大的异常值。使用序列数据的一个相对简单的方法是在排序数据上使用差分函数。这可以通过以下列表中的示例实现。
- en: Listing 5.7 Time-series differencing functions and visualizations
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.7 时间序列差分函数和可视化
- en: '[PRE6]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ Gets the logarithm of the raw data to reduce the magnitude of difference for
    subsequent steps
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 获取原始数据的对数以减少后续步骤的差异幅度
- en: ❷ Gets a per-unit differencing of each position’s value compared to the lag
    specified. Here, we’re looking at the immediately preceding value.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 获取每个位置值相对于指定滞后值的单位差分。在这里，我们正在查看立即前一个值。
- en: ❸ Gets the differencing of the 12th preceding value (difference from last year,
    since our data is monthly)
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 获取前 12 个月值的差分（与去年的差异，因为我们的数据是按月计算的）
- en: ❹ Generates the plot structure so we can create a single image of these three
    separate plots
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 生成绘图结构，以便我们可以创建这三个单独绘图的单一图像
- en: ❺ Creates x-axis reference points that illustrate abnormality periods in the
    series data (to aid in explanations to business unit members who will ask questions
    about why predictions failed)
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 创建 x 轴参考点，以说明序列数据中的异常期（有助于向询问预测失败原因的业务单元成员进行解释）
- en: ❻ Always plot the raw data if generating graphics to share to the rest of the
    business. It will save you from having to craft horrifically complex slides later.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 如果要生成用于与业务其他部分共享的图形，始终绘制原始数据。这将让您免于以后制作复杂得令人难以置信的幻灯片。
- en: ❼ Plots the static boundaries we want to highlight about why unforeseen latent
    factors affected the trend
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 绘制我们想要突出显示的静态边界，说明不可预见潜在因素如何影响趋势
- en: ❽ Displaying the highlighted aberrations in data in multiple ways can help communicate
    the impact of latent factors more clearly.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 以多种方式显示数据中的突出异常，可以帮助更清楚地传达潜在因素的影响。
- en: ❾ Regardless of platform, visualization technology, or process, it’s a good
    habit to save all of our generated plots for later reference.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: ❾ 无论平台、可视化技术还是流程，保存我们生成的所有绘图以供以后参考都是一个好习惯。
- en: When we execute this, we get the plot shown in figure 5.9 (as well as an SVG
    image saved to our shared notebook directory).
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们执行此操作时，我们得到图 5.9 中所示的绘图（以及保存到我们共享笔记本目录中的 SVG 图像）。
- en: '![05-09](../Images/05-09.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![05-09](../Images/05-09.png)'
- en: Figure 5.9 Outlier analysis demonstration from listing 5.7
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.9 从列表 5.7 的异常值分析演示
- en: We now have some insight into what the data looks like. We’ve created demonstration
    plots and basic trend decompositions, and collected data about what these trends
    look like. The code has been a bit rough and reads like a script. If we don’t
    take a little time to make this code reusable through the use of utility functions,
    we will likely find that each time someone wants to generate such visualizations,
    they will be employing Chef Boyardee levels of copy-pasta throughout their code
    base.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在对数据的外观有了一些了解。我们创建了演示图和基本趋势分解，并收集了有关这些趋势外观的数据。代码有点粗糙，读起来像脚本。如果我们不花点时间通过使用实用函数使此代码可重用，我们可能会发现每次有人想要生成这样的可视化时，他们都会在代码库中大量复制粘贴。
- en: 5.2.2 Moving from script to reusable code
  id: totrans-225
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.2 从脚本到可重用代码的迁移
- en: Returning to the theme of timeliness, the urgency of making decisions about
    directions for the project can be lessened if we focus on employing reusable code.
    It not only makes for a cleaner code base (and fewer versions of the exact same
    thing being created by multiple people), but also helps standardize elements of
    the project in preparation for the MVP (and development) phases. Reducing confusion,
    speeding time to decision making, and creating less chaos in notebooks and scripts
    are all in an effort to maximize the chances of the business having enough faith
    in the project to continue development efforts on it.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 返回到及时性的主题，如果我们专注于使用可重用代码，那么对项目方向做出决策的紧迫性可以降低。这不仅使代码库更干净（并且减少了由多个人创建的完全相同的东西的版本），还有助于在
    MVP（和开发）阶段标准化项目的元素。减少混淆、加快决策时间、在笔记本和脚本中减少混乱，所有这些都是在努力最大化业务对项目有足够信心以继续开发工作的可能性。
- en: We’ve been doing an awful lot of scripting here with the trend analysis and
    the visualizations of our JFK domestic passenger data. That’s perfectly fine for
    doing a quick check on things and certainly understandable for the early stages
    of experimentation (we all do it, and anyone who says otherwise is a liar). However,
    when the team breaks off to work on modeling activities, it will be incredibly
    wasteful for everyone to be building their own visualizations, their own implementations
    of similar tests, and code that can be relatively easily rolled into standard
    functions. The last thing we (should) want is to have a disparate collection of
    notebooks that have multiple copies of the exact same code, just slightly modified,
    spread everywhere. While using the magical copy and paste commands might seem
    expedient, it ends up wreaking havoc on both productivity and sanity. The better
    thing to do is to create functions.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里进行了大量的脚本编写，用于趋势分析和我们的JFK国内乘客数据的可视化。这完全适合快速检查事物，对于实验的早期阶段来说也是完全可以理解的（我们都会这样做，任何说否则的人都是在撒谎）。然而，当团队分头进行建模活动时，每个人都构建自己的可视化、自己的类似测试的实现以及可以相对容易地合并到标准函数中的代码，这将是极其浪费的。我们（应该）最不希望看到的是，散布着多个笔记本，它们包含大量几乎完全相同的代码，只是略有修改。虽然使用神奇的复制和粘贴命令可能看起来很方便，但最终会对生产力和理智造成破坏。更好的做法是创建函数。
- en: I’m certainly not recommending, at this stage, to build a package-level project
    for these utility functions. That work will come later, in the actual development
    phase of the project, during the long and arduous road to production release.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我当然不建议在这个阶段为这些实用函数构建一个包级项目。这项工作将在项目的实际开发阶段进行，在漫长的生产发布之路上。
- en: For now, let’s take these useful and repeatable code snippets for manipulating
    the raw data, visualizing the trends, and extracting information from them into
    a standardized collection of basic functions. This work will save us dozens of
    hours, particularly when different implementations are going to be tested against
    other airports’ data. The absolutely last thing that we want to do is copy and
    paste a block of script in order to present a visualization and analysis, which
    will leave everyone wondering which methodology is the best, cause massive amounts
    of duplicated work, and generate code sprawl that will be untenable to maintain.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将这些有用的可重复代码片段，用于操作原始数据、可视化趋势和从中提取信息，整理成标准的基本函数集合。这项工作将为我们节省数十个小时，尤其是在将要测试针对其他机场数据的不同实现时。我们绝对不希望做的事情是复制和粘贴一大块脚本以展示可视化和分析，这会让每个人都想知道哪种方法最好，造成大量重复工作，并生成难以维护的代码蔓延。
- en: Let’s take a look at the dataset ingestion script from listing 5.1 and see what
    a function to acquire the data and format it correctly might look like. To make
    the ingestion function useful, we need to get a list of the airports included
    with this file, be able to apply filtering to get a single airport, and specify
    the time-series periodicity associated with the data. The following listing shows
    each of these functions.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看列表5.1中的数据集导入脚本，看看一个获取数据并正确格式化的函数可能是什么样子。为了使导入函数有用，我们需要获取包含在此文件中的机场列表，能够应用过滤以获取单个机场，并指定与数据相关的时间序列周期性。以下列表显示了这些函数中的每一个。
- en: Listing 5.8 Data ingestion and formatting functions
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.8 数据导入和格式化函数
- en: '[PRE7]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ Defines a static variable for the column that contains the key for the airports
    (to minimize string replacements within code, should this need to be changed)
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 定义一个静态变量，用于包含机场键的列（为了最小化代码中的字符串替换，如果需要更改的话）
- en: ❷ Function for setting the time-series frequency for the index of the DataFrame
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 为DataFrame索引设置时间序列频率的函数
- en: ❸ Primary data acquisition and formatting function
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 主要数据获取和格式化函数
- en: ❹ Sets a copy of the ingested data so it can be safely mutated
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 设置导入数据的副本，以便可以安全地修改
- en: ❺ Extracts the month from the string date value in the original data
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 从原始数据中的字符串日期值中提取月份
- en: ❻ Creates a day field (first day of the month) so the encoding to a date object
    can happen
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 创建一个日期字段（月份的第一天），以便将编码转换为日期对象
- en: ❼ Generates the date field in appropriate NumPy datetime format (required for
    time-series modeling)
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 生成适当的NumPy日期时间格式（对于时间序列建模是必需的）
- en: ❽ Sets the index of the DataFrame to the date column (useful for plotting and
    modeling)
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 将DataFrame的索引设置为日期列（对于绘图和建模很有用）
- en: ❾ Sets the properties of the index to the inferred frequency
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: ❾ 将索引的属性设置为推断出的频率
- en: ❿ Ensures that the DataFrame has been sorted by the date index to prevent issues
    with series extraction of data later
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: ❿ 确保DataFrame已经按日期索引排序，以防止以后数据序列提取时出现问题
- en: ⓫ Utility function for returning a list of all airports contained within the
    data
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: ⓫ 返回数据中包含的所有机场的列表的实用函数
- en: With these functions established, they can be used by each subteam that will
    be testing out solutions to the forecasting project throughout the experimental
    phase. With a little bit more work, these can all be modularized into a class
    later, during the development phase, to create a standardized and testable implementation
    for the production-grade final project (covered in chapters 9, 10, and 14). The
    usage of these can be as simple as the next listing.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些函数建立之后，它们可以被每个将在实验阶段测试预测项目解决方案的子团队使用。通过更多的工作，这些都可以在开发阶段模块化成一个类，以创建一个标准化的、可测试的生产级最终项目实现（在第9、10和14章中介绍）。这些的使用可以像下面的列表一样简单。
- en: Listing 5.9 Ingesting data by using a reusable function
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.9 通过可重复使用的函数摄取数据
- en: '[PRE8]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ Uses the function get_airport_data() to acquire the data as a date-indexed
    pandas DataFrame
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用函数get_airport_data()获取作为日期索引的pandas DataFrame的数据
- en: ❷ Applies the correct time periodicity to the date index on the DataFrame (MS
    is for “month start frequency”)
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将正确的周期性时间应用到DataFrame的日期索引上（MS代表“月起始频率”）
- en: Let’s look at one additional modification that we can do, focused on the outlier
    visualization script created in listing 5.7 and demonstrated in figure 5.9\. We’ll
    see how this script could be adapted to a one-line use that greatly simplifies
    the generation of these plots without having to make it fully generic (which would
    take a great deal of time and effort). Even though the function representation
    of this visualization logic is a bit more complex, and requires a few more lines
    of code, the end result will be worth it in no small part because we can generate
    plots with a single line of code.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们可以做的另一个修改，专注于在列表5.7中创建并在图5.9中展示的异常值可视化脚本。我们将看到这个脚本如何被改编成一行使用，这极大地简化了这些图表的生成，而无需使其完全通用（这将需要大量的时间和精力）。尽管这个可视化逻辑的函数表示稍微复杂一些，并且需要更多的代码行，但最终结果将是非常值得的，因为我们可以用一行代码生成图表。
- en: Listing 5.10 Reusable function for visualizing outlier data
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.10 可重复使用的可视化异常数据的函数
- en: '[PRE9]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ Functions generally don’t have quite this many arguments. The * tuple packing
    operator and the ** dictionary packing operator allow for passing multiple arguments.
    For this example, I name them explicitly to minimize confusion.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 函数通常不会有这么多参数。*元组打包运算符*和**字典打包运算符*允许传递多个参数。在这个例子中，我明确地命名它们以减少混淆。
- en: ❷ Uses string interpolation to build static references to dynamically created
    fields in the DataFrame
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用字符串插值来构建对DataFrame中动态创建的字段的静态引用
- en: ❸ Converts the passed-in date to something that will match up with the datetime
    index of the DataFrame. For this example, it’s OK to convert passed-in values.
    In general practice (particularly for libraries), the correct action is to raise
    an exception for invalid passed-in configurations (a validation that the value
    exists in the index could be one method to employ) so that the end user of the
    function doesn’t get an unexpected result.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将传入的日期转换为与DataFrame的日期索引匹配的东西。在这个例子中，转换传入的值是可以的。在一般实践中（尤其是对于库），正确的行动是对于无效的传入配置引发异常（验证值是否存在于索引中可能是一种方法）以确保函数的最终用户不会得到意外的结果。
- en: ❹ Creates a date differencing so we can get a uniform scaling based on the frequency
    of the time-series index of the DataFrame
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 创建一个基于DataFrame时间序列索引频率的统一缩放的时间差分
- en: ❺ Creates a maximum bound on the vertical lines being drawn that is based on
    the range of the data
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 创建一个基于数据范围的垂直线的最大界限
- en: ❻ Makes a deep copy (object replication in different memory address) for the
    series of mutations we will be doing to the data. This is a useful operation,
    particularly for ML, wherein we may want to change this so subsequent calls to
    this function won’t be mutating the source data, allowing us to loop or map/lambda
    over a collection that calls this data.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 对我们将要对数据进行的一系列突变创建一个深拷贝（在不同内存地址的对象复制）。这是一个有用的操作，尤其是在机器学习（ML）中，我们可能想要改变这一点，以便后续对这个函数的调用不会修改源数据，使我们能够对调用此数据的集合进行循环或map/lambda操作。
- en: ❼ Performs the same log and diff functions performed earlier in the scripted
    version, except these are parameterized by the interpolated names so that no hardcoding
    is required
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 执行与脚本版本中之前执行相同的日志和差异函数，但这些函数是通过插值名称参数化的，因此不需要硬编码
- en: ❽ These values could also be arguments to this function (the figsize value)
    in case you want the user to have flexibility in the size of the plots. For this
    example, we’re leaving them hardcoded.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 这些值也可以作为此函数（figsize 值）的参数，以便用户可以在绘图大小方面有灵活性。在这个例子中，我们保留它们为硬编码。
- en: ❾ All the code from here to the bottom is identical to our previous scripted
    version, with the exception that we’re using dynamic variables from the passed-in
    arguments to construct everything in a flexible manner.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: ❾ 从这里到下面的所有代码与之前的脚本版本完全相同，唯一的区别是我们正在使用传入参数的动态变量以灵活的方式构建一切。
- en: Interpolation is your friend
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 插值是你的朋友
- en: In the realm of ML, a lot of what we do involves passing around string references.
    It can get a bit tedious. The only thing that I’ve found to be more tedious than
    dealing with strings in configurations is manually overwriting those strings for
    different uses in code.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习领域，我们做的大部分工作都涉及到传递字符串引用。这可能会有些繁琐。我发现，处理配置中的字符串比手动覆盖代码中不同用途的字符串还要繁琐。
- en: '*Interpolation* is a remarkably powerful tool that, once you learn how to use
    it correctly, can save you no end of frustration and typo-induced failures. As
    great as it is, however, there are ways that people use it correctly, and then
    there are the “lazy” implementations.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '*插值* 是一个非常强大的工具，一旦你学会了如何正确使用它，就能避免无数因输入错误导致的挫败和失败。然而，尽管它非常出色，但人们正确使用它的方法与“懒惰”的实现方式大相径庭。'
- en: How do you do string building in a lazy fashion? By using the concatenation
    operator.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 你如何以懒惰的方式构建字符串？通过使用连接运算符。
- en: 'Let’s say we want to build one of those strings from listing 5.10, the title
    for `axes[1]`. In a lazy implementation of concatenation, we might do something
    like this:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想从列表 5.10 中构建一个字符串，即 `axes[1]` 的标题。在连接的懒惰实现中，我们可能会这样做：
- en: '[PRE10]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: While technically correct (it will assemble the string correctly), it’s ugly,
    hard to read, and incredibly error-prone. What if you forgot to put the leading
    and trailing spaces into the middle statically defined string? What if someone
    comes in later and needs to change that string? What if the title needs to be
    added onto to provide a dozen different strings? At a certain point, the code
    will start to look amateurish and impossible to read.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然技术上正确（它将正确组装字符串），但看起来很糟糕，难以阅读，并且极易出错。如果你忘记在静态定义的字符串中间添加前导和尾随空格怎么办？如果有人后来需要更改该字符串怎么办？如果需要添加标题以提供一打不同的字符串怎么办？在某个时候，代码将开始看起来很业余，难以阅读。
- en: Using the '`{}'.format()` syntax (bonus points for declaring variables and type
    formatting in there as well) will save you from annoying bugs and make your code
    look cleaner, which should be the end goal for maintainability’s sake. If you
    don’t like the format syntax, you can always use f-strings, which are an optimized
    and much more shorthand means of interpolating values into strings. Throughout
    this book, I stick to the older format to make the code more approachable to people
    who are familiar with that, but in practice I use f-strings.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `'{}'.format()` 语法（如果声明变量和类型格式化也在其中，则加分）可以让你避免烦人的错误，并使你的代码看起来更整洁，这对于维护性来说应该是最终目标。如果你不喜欢格式化语法，你总是可以使用
    f-strings，这是一种优化且更简短的将值插入字符串的方法。在这本书中，我坚持使用较旧的格式，以便让熟悉这种格式的人更容易理解代码，但在实践中我使用 f-strings。
- en: Executing the code from listing 5.10 and building a visualization (which can
    also be stored for later reference) is as simple as the following code.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 执行列表 5.10 中的代码并构建可视化（也可以存储以供以后参考）就像以下代码一样简单。
- en: Listing 5.11 Usage of the outlier visualization function
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.11 使用离群值可视化函数
- en: '[PRE11]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: If we execute this, we get the visualization shown in figure 5.10\. Notice that
    we don’t have to specify date windows, formatting, or any other boilerplate since
    it is all dynamically generated based on the function’s configuration arguments.
    We can even plot the international passenger counts with this function instead
    of hardcoding all the values into the script, as we did in listing 5.7 (and the
    subsequent visualization).
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们执行此操作，我们将得到图 5.10 中所示的可视化。请注意，我们不必指定日期窗口、格式或其他任何样板代码，因为所有这些都是根据函数的配置参数动态生成的。我们甚至可以使用此函数绘制国际乘客计数，而不是像列表
    5.7（及其后续可视化）中那样将所有值硬编码到脚本中。
- en: '![05-10](../Images/05-10.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![05-10](../Images/05-10.png)'
- en: Figure 5.10 Using a function to generate this plot provides adaptability, and
    its reusable nature allows for rapid validation of data anomalies, saving time.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.10 使用函数生成此图提供了适应性，其可重用性允许快速验证数据异常，节省时间。
- en: To demonstrate the benefits of taking a little bit of extra time and building
    a function out of even experimental validation code, let’s see what we can do
    with the data generation from a completely different airport, LaGuardia (LGA).
    If we scripted out our original outlier plotting and wanted to generate the same
    plot for LGA, we’d have to copy the JFK script, go through the painstaking process
    of overwriting each reference to `JFK`, change the plotting and analysis field
    from `International``Passengers` to `Domestic``Passengers`, and hope that we get
    all of the references replaced to prevent the wrong time series or values from
    being plotted. (Since the Python REPL has the concept of object constancy, all
    references are held in memory until the kernel REPL is stopped.) The code with
    the function implementation of the plotting is shown next.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示花一点额外时间构建函数，即使是实验验证代码的好处，让我们看看我们可以如何使用来自完全不同的机场，拉瓜迪亚（LGA）的数据生成。如果我们编写了原始的异常值绘图脚本，并希望为
    LGA 生成相同的绘图，我们就必须复制 JFK 脚本，经过繁琐的过程，逐个覆盖对 `JFK` 的引用，将绘图和分析字段从 `International` `Passengers`
    更改为 `Domestic` `Passengers`，并希望我们能够替换所有引用，以防止错误的时间序列或值被绘制。（由于 Python REPL 有对象常性的概念，所有引用都保留在内存中，直到内核
    REPL 停止。）接下来将展示具有绘图功能实现的代码。
- en: Listing 5.12 Experimental phase function use for outlier analysis
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.12 用于异常分析实验阶段函数的使用
- en: '[PRE12]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ❶ Pulls the data for LaGuardia. (This is for demonstration purposes only. In
    a properly developed solution, we would load the data only once and apply a filter
    directly on the in-memory DataFrame.)
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从拉瓜迪亚获取数据。（这仅用于演示目的。在一个正确开发的解决方案中，我们只会加载一次数据，并在内存中的 DataFrame 上直接应用过滤器。）
- en: ❷ Sets the index frequency of “beginning of month” in the same way that we did
    for JFK data
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 以与 JFK 数据相同的方式设置“月初”的索引频率
- en: ❸ Generates the visualizations and saves them to disk. The arguments for this
    function make generating these plots trivial, but more important, repeatable.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 生成可视化并将其保存到磁盘。此函数的参数使得生成这些绘图变得简单，但更重要的是，可重复。
- en: With these three brief lines, we can get a new visualization that is stored
    to disk, labeled appropriately for the indicated outlier period that we discovered,
    without the need to reimplement all the code originally used to build the dataset
    and the visualizations. Figure 5.11 shows the resulting visualization.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这三行简短的代码，我们可以获取一个存储到磁盘的新可视化，并适当地标记了我们发现的指示异常期，而无需重新实现构建数据集和可视化的所有原始代码。图 5.11
    显示了生成的可视化。
- en: '![05-11](../Images/05-11.png)'
  id: totrans-282
  prefs: []
  type: TYPE_IMG
  zh: '![05-11](../Images/05-11.png)'
- en: Figure 5.11 Plot result from listing 5.12
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.11 列表 5.12 的绘图结果
- en: NOTE The functions shown here are for illustrative purposes only. Later chapters
    cover proper ways of building functions and methods for ML so that fewer actions
    are taken in a single function or method. For now, the point is simply to illustrate
    the benefit of reusable code even in the early stages of a project.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：这里显示的函数仅用于说明目的。后面的章节将介绍构建函数和机器学习方法的正确方式，以便在单个函数或方法中减少操作步骤。目前，重点是简单地说明即使在项目的早期阶段，可重用代码的好处。
- en: When functions should be created
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 应该创建函数的情况
- en: In the course of experimentation, in addition to the immediate focus of solving
    a problem, we should consider which elements of the code need to be modularized
    for reuse. Not every aspect of a solution needs to be production-ready, particularly
    in the early stages, but it is helpful to start thinking about which aspects of
    the project will need to be referenced or executed many times over.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在实验过程中，除了立即解决问题的焦点之外，我们还应该考虑哪些代码元素需要模块化以供重用。并非解决方案的每个方面都需要达到生产就绪状态，尤其是在早期阶段，但开始思考哪些项目方面需要多次引用或执行是有帮助的。
- en: Stepping aside from rapid prototyping to build functions can sometimes feel
    like a temporary derailment of what you’re trying to get done. It’s important
    to realize that, by taking an hour or so to create a generic reference to a repeatable
    task, you could be saving yourself dozens of hours later.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 从快速原型设计转向构建函数有时会感觉像是暂时偏离了你的目标。重要的是要意识到，通过花上一两个小时创建一个通用的可重复任务参考，你可能会在之后节省数十个小时。
- en: These hours are mostly saved by the simple fact that when you’re working to
    convert your scripted solution into a properly developed ML code base, you won’t
    have to review so many implementations. Instead of dozens of visualizations and
    scoring functions littered throughout the code, you will be left with a group
    of single-purpose functions that will need to be looked at and evaluated as only
    a single unit.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 这些小时主要是由这样一个简单的事实节省下来的：当你努力将脚本解决方案转换为经过良好开发的机器学习代码库时，你不需要审查那么多的实现。而不是在代码中散布数十个可视化和评分函数，你将只剩下一些单用途函数，这些函数需要作为一个单一单元来查看和评估。
- en: 'Some elements that I typically look to create functions for as early as possible
    in the ML space are as follows:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习（ML）领域，我通常会尽早创建函数的一些元素如下：
- en: Data ingestion and data cleansing
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据摄取和数据清洗
- en: Scoring and error calculations
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评分和错误计算
- en: General data visualizations
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通用数据可视化
- en: Validation and prediction visualizations
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证和预测可视化
- en: Model performance reports (for example, ROC curves and confusion matrices)
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型性能报告（例如，ROC曲线和混淆矩阵）
- en: Many other instances are eligible for “function treatment” early in the process
    of building an ML solution. The important point to keep in mind when building
    even the earliest phases of a project is to either set aside the time to create
    reusable code immediately, or to at least flag the code for implementation in
    such a way that makes it easy to identify for action as soon as is practicable.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 许多其他实例在构建机器学习解决方案的早期阶段都适合进行“函数处理”。在构建项目早期阶段时，需要记住的重要一点是，要么立即留出时间创建可重用代码，要么至少将代码标记为易于实施，以便一旦可行就易于识别并采取行动。
- en: Why are we talking about the benefits of functions? Surely everyone knows when
    to use them, right?
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为什么要讨论函数的好处？难道每个人都知道何时使用它们吗？
- en: The reality of experimentation in predictive modeling is that most ML practitioners
    end up spending the vast majority of their efforts working on feature engineering,
    data validation, and modeling. The process of constant code rewrites and testing
    inures us all to the fact that the project experimentation code that we’re building
    can rapidly devolve into a half-implemented, commented-out, and generally unreadable
    sprawl of chaos.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 预测建模实验的现实情况是，大多数机器学习从业者最终会花费大量精力在特征工程、数据验证和建模上。不断的代码重写和测试让我们所有人都习惯了这样一个事实：我们构建的项目实验代码可能会迅速退化成半实现、注释掉且通常难以阅读的混乱状态。
- en: Sometimes it feels as if, in the process of wanting to test something new, it’s
    easier to copy a block of code from a notebook cell far above just to simply get
    something to work quickly. This ends up causing a complete disjointed mess of
    mangled code that is going to require a monumental undertaking to fashion into
    something eligible for further development.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候感觉，在想要测试新事物的时候，直接从笔记本的上方单元格复制一大块代码来快速实现某个功能似乎更容易。结果却导致了一团糟的混乱代码，需要巨大的努力才能将其整理成适合进一步开发的形态。
- en: Most of the time, when I’ve seen (or done, in the past) such greenfield experimentation,
    all the original testing code is simply abandoned when an approach is decided
    upon. It doesn’t have to be that way, though. If a little care is taken during
    this phase, the subsequent development phases can be much more efficient.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数时候，当我看到（或过去做过）这样的绿色田野实验时，一旦确定了方法，所有的原始测试代码就被简单地废弃了。然而，情况并不一定如此。如果在这一阶段稍加注意，后续的开发阶段可以更加高效。
- en: If you’re working on a team, these problems only compound themselves. Imagine
    if this project were being undertaken by six subteams of data scientists. By the
    time the testing phase of ideas was complete, dozens of implementations would
    exist of the data ingestion alone, paired with at least a dozen ways of plotting
    the data and running statistical analysis on the time-series data. Standardization
    and using functions can help reduce this redundant code.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在一个团队中工作，这些问题只会变得更加复杂。想象一下，如果这个项目是由六个数据科学子团队执行的。到测试阶段结束时，仅数据摄取就有几十种实现，至少有十种方式来绘制数据并运行时间序列数据的统计分析。标准化和使用函数可以帮助减少这种冗余代码。
- en: 5.2.3 One last note on building reusable code for experimentation
  id: totrans-301
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.3 关于为实验构建可重用代码的最后一则注意事项
- en: Before we move on to the modeling phase of this project’s experimentation, let’s
    look at another function. This function will help us get a useful snapshot of
    a particular time series (one of the passenger series of data) from one of the
    airports in the list of comparison locations for each of the models.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续进行这个项目实验的建模阶段之前，让我们看看另一个函数。这个函数将帮助我们从一个机场的列表中获取一个特定时间序列（乘客数据系列之一）的有用快照，该列表是每个模型的比较位置。
- en: Earlier we took a look at plotting outliers (section 5.2.2) and getting trend
    decomposition plots (section 5.2.1). Two additional plots, if we had them, would
    be invaluable in helping inform us of the initial settings we should use for some
    of the model types that we’ll be testing. Those two plots are of autocorrelation
    and partial autocorrelation.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 之前我们查看过绘制异常值（第 5.2.2 节）和获取趋势分解图（第 5.2.1 节）。如果我们有两个额外的图表，将非常有价值，帮助我们了解我们应该为将要测试的一些模型类型使用的初始设置。这两个图表是自相关和偏自相关图。
- en: '*Autocorrelation* is an algorithm that will run a Pearson’s test between the
    time series and lagged values of the same series (previous steps of the same data
    series), giving results in a range of -1 to +1, indicating the relative correlation
    between these lags. A value of +1 is a maximum positive correlation, indicating
    a perfect synchronicity between the values at that specified lag position throughout
    the data series (if there is a repeatable pattern every 10 values along the time
    series, this will show up as a maximum positive correlation of +1). The graph
    plotted from an autocorrelation test will show each lag value that has been calculated,
    and a blue cone stretching out from 0 in a logarithmic curve, denoting a confidence
    interval (defaulted at 95%). The points that extend outside this blue cone are
    considered statistically significant. The autocorrelation test includes direct
    dependence information in the lag measurement as well as indirect effects.'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '*自相关* 是一种算法，它将在时间序列和相同序列的滞后值（相同数据系列的先前步骤）之间运行皮尔逊测试，结果在 -1 到 +1 的范围内，表示这些滞后之间的相对相关性。+1
    的值表示最大正相关，表明在整个数据系列中指定滞后位置上的值完美同步（如果时间序列中每10个值有一个可重复的模式，这将显示为 +1 的最大正相关）。来自自相关测试绘制的图表将显示计算出的每个滞后值，以及从
    0 开始向外的蓝色圆锥体，表示置信区间（默认为 95%）。超出这个蓝色圆锥体的点被认为是统计上显著的。自相关测试在滞后测量中包括直接依赖信息以及间接影响。'
- en: Because of this impact of the nature of the autocorrelation test, it can be
    slightly misleading when looked at on its own. Along with the autocorrelation
    test, a useful additional plot, the *partial autocorrelation test*, is also used
    when analyzing time-series data. This additional test evaluates each lag position
    in a similar way that autocorrelation does, but it goes one step further by removing
    the effects that previous lag values introduced to the independent lag being measured.
    By removing these effects, the direct lag relationship at that particular value
    can be measured.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 由于自相关测试的性质对此有影响，单独查看时可能会有些误导。在分析时间序列数据时，除了自相关测试外，还有一个有用的附加图，即*部分自相关测试*也被使用。这个附加测试以与自相关类似的方式评估每个滞后位置，但它更进一步，通过消除先前滞后值对被测量的独立滞后引入的影响。通过消除这些影响，可以测量该特定值处的直接滞后关系。
- en: Why is this important?
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 这为什么很重要？
- en: We can use the values uncovered in these charts as starting points for our modeling
    (the models that are designed for autoregression, that is). We’ll get more into
    that in chapter 6.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这些图表中揭示的值作为我们建模的起点（即设计用于自回归的模型）。我们将在第6章中更深入地探讨这一点。
- en: For now, we should make sure that before anyone starts off on modeling, we have
    a standardized way of generating these charts in one shot so that all the teams
    can rapidly generate these visualizations to help guide their tuning. Let’s create
    a simple function to plot most of what we need to analyze the series that we’ll
    be forecasting.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们应该确保在任何人开始建模之前，我们有一个标准化的方法一次性生成这些图表，以便所有团队都能快速生成这些可视化，以帮助他们调整。让我们创建一个简单的函数来绘制我们分析将要预测的序列所需的大部分内容。
- en: Listing 5.13 Standardized time series visualization and analysis for model preparation
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.13 模型准备的标准时序可视化和分析
- en: '[PRE13]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ Calculates the log differencing data for the outlier plot
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 计算异常值图的日志差分数据
- en: ❷ Decomposes the series to get the trend component, seasonality component, and
    the residuals as NumPy series
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将序列分解为趋势成分、季节性成分和残差作为NumPy序列
- en: ❸ Extracts the start and end values of the index to allow for plotting horizontal
    lines
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 提取索引的起始和结束值，以便绘制水平线
- en: ❹ Wrapper around matplotlib.pyplot.plot to allow for setting graph styling and
    a more efficient rendering of plot cells
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ matplotlib.pyplot.plot的包装器，允许设置图形样式和更高效的绘图单元格渲染
- en: ❺ Slight adjustment for rendering the plots to ensure that the titles and axis
    labels don’t overlap
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 对渲染的图形进行轻微调整，以确保标题和轴标签不重叠
- en: ❻ Plot of the raw data to have a visual reference for all the other plots
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 绘制原始数据图，为其他所有图表提供视觉参考
- en: ❼ Outlier data plot (log diff)
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 异常值数据图（日志差分）
- en: ❽ Autocorrelation plot to provide insight for tuning (along with the partial
    autocorrelation) for autoregressive models
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 自相关图，为调整（连同部分自相关）提供洞察，用于自回归模型
- en: ❾ Partial autocorrelation plot to provide insight for tuning autoregressive
    models
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: ❾ 部分自相关图，为调整自回归模型提供洞察
- en: ❿ Plot of the extracted trend from the series
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: ❿ 从序列中提取的趋势图示
- en: ⓫ Plot of the seasonality signal from the series
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: ⓫ 序列季节性信号的图示
- en: ⓬ Plot of the residuals from the series
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: ⓬ 系列残差的图示
- en: ⓭ Saves the figure for later reference and for presentations
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: ⓭ 保存图形以供以后参考和演示
- en: ⓮ Returns the composed figure in case additional processing is desired
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: ⓮ 返回组合图形，以便在需要额外处理的情况下使用
- en: Now let’s see what that code produces. Figure 5.12 is the result of executing
    the following code.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看这段代码会产生什么结果。图5.12是执行以下代码的结果。
- en: '![05-12](../Images/05-12.png)'
  id: totrans-326
  prefs: []
  type: TYPE_IMG
  zh: '![05-12](../Images/05-12.png)'
- en: Figure 5.12 The full trend visualization suite for model preparation, applied
    to Newark International Airport domestic passenger travel data
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.12 模型准备的全趋势可视化套件，应用于纽瓦克国际机场国内旅客数据
- en: Listing 5.14 Trend visualization for Newark domestic passengers
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.14 纽瓦克国内旅客趋势可视化
- en: '[PRE14]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ❶ From the original source dataset, acquires the data for EWR (Newark International
    Airport)
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从原始数据源获取EWR（纽瓦克国际机场）的数据
- en: ❷ Applies the frequency on the date index of the DataFrame
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在DataFrame的日期索引上应用频率
- en: ❸ Generates the snapshot charts for the time series specified (domestic passengers)
    for Newark
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 为指定的时序（国内旅客）生成纽瓦克的快照图表
- en: 'Now we’re finally ready to start model evaluations. We have some standard visualizations
    that are wrapped up nicely in reusable functions, we know which airports are going
    to be adjudicated for the test, and the tooling that we’ve developed will ensure
    that each experimental test will be using the same set of visualizations and data
    processing steps. We’ve eliminated much of the boilerplate code that might have
    been developed, and reduced the time to get started on the core problem that we’re
    trying to solve: forecasting.'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们终于准备开始模型评估了。我们有一些标准的可视化，它们被很好地封装在可重用的函数中，我们知道哪些机场将被用于测试，而我们开发的工具将确保每个实验测试都将使用相同的可视化集和数据预处理步骤。我们已经消除了可能开发的大部分样板代码，并减少了开始解决我们试图解决的核心理问题的所需时间：预测。
- en: 'We’ll be building additional standard visualizations for the modeling phase
    when we start that in the next chapter. For now, we can guarantee one thing: the
    teams won’t be reinventing the wheel or using copy and paste too much.'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在下一章开始建模阶段时，我们将构建额外的标准可视化。目前，我们可以保证一件事：团队不会重新发明轮子或过度使用复制粘贴。
- en: Summary
  id: totrans-335
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Thorough research of potential approaches to solve a problem involves time-constrained
    evaluation through dataset statistical analysis, model API review, API documentation
    perusal, rapid prototyping, and objective comparison.
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对解决问题可能方法的彻底研究涉及通过数据集统计分析、模型API审查、API文档阅读、快速原型设计和目标比较的时间限制评估。
- en: Gaining a deep understanding of candidate feature data through appropriate statistical
    evaluation and visualization will help uncover issues early. Starting with a clean
    and well-defined state of familiarity with the training data for a project will
    eliminate costly rework later in the project’s development cycle.
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过适当的统计评估和可视化来深入了解候选特征数据将有助于早期发现问题。从对项目训练数据的清晰和定义良好的熟悉状态开始，将在项目开发周期后期消除昂贵的返工。
