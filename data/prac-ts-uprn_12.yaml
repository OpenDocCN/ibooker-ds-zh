- en: Chapter 12\. Performance Considerations in Fitting and Serving Time Series Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第十二章。适合时间序列模型的性能考虑
- en: In the literature on machine learning and statistical analyses, the overwhelming
    focus tends to be on performance of models in terms of accuracy. While accuracy
    should usually be the primary concern when evaluating a model, sometimes computational
    performance considerations matter tremendously in the face of large data sets
    or widely deployed models to serve large populations of client applications.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习和统计分析的文献中，过于关注模型的准确性。虽然在评估模型时通常准确性应该是主要关注点，但有时在面对大数据集或广泛部署的模型以服务大量客户应用程序时，计算性能的考虑也非常重要。
- en: 'Time series data sets get so large that analyses can’t be done at all—or can’t
    be done properly—because they are too intensive in their demands on available
    computing resources. In such cases, many organizations treat their options as
    follows:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列数据集变得如此庞大，以至于分析根本无法完成，或者因为对可用计算资源的需求太大而无法进行适当的分析。在这种情况下，许多组织会如下处理他们的选择：
- en: Upsize on computing resources (expensive and often wasteful both economically
    and environmentally).
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增加计算资源（在经济和环境上既昂贵又常常是浪费的）。
- en: Do the project badly (not enough hyperparameter tuning, not enough data, etc.).
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 把项目做糟（不够的超参数调整，数据不足等）。
- en: Don’t do the project.^([1](ch12.html#idm45576020725864))
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要做这个项目。^([1](ch12.html#idm45576020725864))
- en: None of these options are satisfying, particularly when you are just starting
    out with a new data set or a new analytical technique. It can be frustrating not
    to know whether your failures are the result of poor data, an overly difficult
    problem, or a lack of resources. Hopefully, we will find some workarounds to expand
    your options in the case of very demanding analyses or very large data sets.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 当您刚开始使用新数据集或新分析技术时，这些选项都不令人满意。不知道您的失败是由于数据质量差，问题过于复杂，还是资源不足，可能会令人沮丧。希望我们能找到一些解决方案，以扩展您在非常严苛的分析或非常大的数据集情况下的选择。
- en: This chapter is designed to guide you through some considerations of how to
    lessen the computing resources you need to train or infer using a particular model.
    For the most part, such questions are specific to a given data set, the resources
    you have available, and both your accuracy and speed targets. You will see this
    reality echoed in the concerns detailed in this chapter, but the hope is that
    they will partly cover the problems you run into and can provide inspiration for
    further brainstorming. These are considerations to come when you have completed
    your first rounds of analysis and modeling and should not be a priority when you
    are first attaching a problem. However, when it’s time to put something into production
    or extend a small research project into a larger one, you should revisit these
    concerns often.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章旨在指导您考虑如何减少训练或推断使用特定模型所需的计算资源。在很大程度上，这些问题是特定于给定数据集、您可用的资源以及您的准确性和速度目标的。您将在本章中详细讨论的关注点中看到这种现实，但希望它们部分地涵盖您遇到的问题，并能为进一步的头脑风暴提供灵感。这些是在您完成首轮分析和建模后才需要考虑的事项，但在将某事投入生产或将小型研究项目扩展为更大项目时，您应经常重新审视这些问题。
- en: Working with Tools Built for More General Use Cases
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用为更通用用例构建的工具
- en: One challenge of time series data is that most tools, particularly those for
    machine learning, are built for a more general use case, with most illustrative
    examples showcasing uses of cross-sectional data. There are a few ways these machine
    learning methods then fail to be as efficient as possible with time series data.
    The solutions to your individual problems will vary, but the general ideas are
    the same. In this section I discuss common problems and potential solutions.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列数据的一个挑战是，大多数工具，特别是用于机器学习的工具，都是为更通用的用例而构建的，大多数说明性示例展示了横截面数据的用法。这些机器学习方法因此无法像处理时间序列数据那样高效。你的具体问题的解决方案会有所不同，但一般的思路是相同的。在本节中，我将讨论常见问题和潜在解决方案。
- en: Models Built for Cross-Sectional Data Don’t “Share” Data Across Samples
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为横截面数据构建的模型不会在样本之间“共享”数据
- en: 'In many cases where you are feeding discrete samples of time series data into
    an algorithm, most often with machine learning models, you will notice that large
    chunks of the data you are feeding between samples overlap. For example, suppose
    you have the following data on monthly sales:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，当您将时间序列数据的离散样本输入算法时，最常见的是在机器学习模型中，您会注意到您在样本之间输入的大部分数据存在重叠。例如，假设您拥有以下月销售数据：
- en: '| Month | Widgets sold |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| 月份 | 销售的小部件数量 |'
- en: '| --- | --- |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Jan 2014 | 11,221 |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| 2014年1月 | 11,221 |'
- en: '| Feb 2014 | 9,880 |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| 2014年2月 | 9,880 |'
- en: '| Mar 2014 | 14,423 |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 2014年3月 | 14,423 |'
- en: '| Apr 2014 | 16,720 |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| 2014年4月 | 16,720 |'
- en: '| May 2014 | 17,347 |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| 2014年5月 | 17,347 |'
- en: '| Jun 2014 | 22,020 |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 2014年6月 | 22,020 |'
- en: '| Jul 2014 | 21,340 |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| 2014年7月 | 21,340 |'
- en: '| Aug 2014 | 25,973 |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| 2014年8月 | 25,973 |'
- en: '| Sep 2014 | 11,210 |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| 2014年9月 | 11,210 |'
- en: '| Oct 2014 | 11,583 |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| 2014年10月 | 11,583 |'
- en: '| Nov 2014 | 12,014 |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 2014年11月 | 12,014 |'
- en: '| Dec 2014 | 11,400 |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 2014年12月 | 11,400 |'
- en: '| Jan 2015 | 11,539 |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 2015年1月 | 11,539 |'
- en: '| Feb 2015 | 10,240 |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 2015年2月 | 10,240 |'
- en: You are seeking to make predictions by mapping each “shape” to a nearest neighbor
    curve. You prepare many shapes from this data. Just a smattering of those data
    points are listed here, as you might want to use six-month-long curves as the
    “shapes” of interest (note we are not doing any data preprocessing to normalize
    or create additional features of interest, such as moving average or smoothed
    curves):^([2](ch12.html#idm45576020688152))
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 您正在通过将每个“形状”映射到最近的邻居曲线来进行预测。您从这些数据准备了许多形状。这里列出了其中一小部分数据点，因为您可能希望使用六个月的曲线作为感兴趣的“形状”（请注意，我们不会对数据进行任何预处理，例如归一化或创建额外的感兴趣特征，如移动平均或平滑曲线）：^([2](ch12.html#idm45576020688152))
- en: '| 11221, 9880, 14423, 16720, 17347, 22020 |'
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_TB
  zh: '| 11221, 9880, 14423, 16720, 17347, 22020 |'
- en: '| 9880, 14423, 16720, 17347, 22020, 21340 |'
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_TB
  zh: '| 9880, 14423, 16720, 17347, 22020, 21340 |'
- en: '| 14423, 16720, 17347, 22020, 21340, 25973 |'
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_TB
  zh: '| 14423, 16720, 17347, 22020, 21340, 25973 |'
- en: Interestingly, all we have managed to do with this preparation of inputs is
    to make our data set six times larger, without including any additional information.
    This is a catastrophe from a performance standpoint, but it’s often necessary
    for inputs into a variety of machine learning modules.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，我们通过这些输入的准备工作，只是使我们的数据集扩大了六倍，而没有包含任何额外的信息。从性能的角度来看，这是一场灾难，但通常是各种机器学习模块的输入必需品。
- en: If this is a problem you run into, there are a few solutions you should consider.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您遇到这个问题，您应该考虑几个解决方案。
- en: Don’t use overlapping data
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 不要使用重叠的数据
- en: 'Consider only producing a “data point” so that each individual month makes
    its way into only one curve. If you do so, the preceding data could look like
    the following table:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑仅生成“数据点”，以便每个单独的月份只出现在一个曲线中。如果这样做，前面的数据可能看起来像以下表格：
- en: '| 11221, 9880, 14423, 16720, 17347, 22020 |'
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_TB
  zh: '| 11221, 9880, 14423, 16720, 17347, 22020 |'
- en: '| 21340, 25973, 11210, 11583, 12014, 11400 |'
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_TB
  zh: '| 21340, 25973, 11210, 11583, 12014, 11400 |'
- en: Note that this would be particularly simple because it amounts to a simple array
    reshape rather than a custom repetition of data.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这将特别简单，因为它只是一个简单的数组重塑，而不是数据的自定义重复。
- en: Employ a generator-like paradigm to iterate through the data set
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 采用类似生成器的范式来迭代数据集
- en: 'Employing a generator-like paradigm to iterate through the data set, resampling
    from the same data structure as appropriate, is particularly easy to code up in
    Python but can also be done with R and other languages. If we imagine that the
    original data is stored in a 1D NumPy array, this could look something like the
    following code (note that this would have to be paired with a machine learning
    data structure or algorithm that accepts generators):'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 使用类似生成器的范式来迭代数据集，根据需要从相同的数据结构重新采样，特别容易在Python中编码，但也可以在R和其他语言中完成。如果我们想象原始数据存储在一个1D
    NumPy数组中，这可能看起来像以下代码（请注意，这需要与接受生成器的机器学习数据结构或算法配对使用）：
- en: '[PRE0]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note that designing data modeling code that does not unnecessarily blow up a
    data set is desirable from both a training and production standpoint. In training
    this will allow you to fit more training examples in memory, and in production
    you can make multiple predictions with fewer training resources in the case of
    predictions (or classifications) on overlapping data. If you are making frequent
    predictions for the same use case, you will likely be working with overlapping
    data, so this problem and its solutions will be quite relevant.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，设计不会不必要地扩大数据集的数据建模代码，从培训和生产的角度来看都是可取的。在培训中，这将允许你在内存中拟合更多的训练示例，在生产中，你可以使用更少的训练资源进行多次预测（或分类）在重叠数据上。如果你为同一用例频繁进行预测，你可能会处理重叠数据，因此这个问题及其解决方案将非常相关。
- en: Models That Don’t Precompute Create Unnecessary Lag Between Measuring Data and
    Making a Forecast
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不预先计算的模型会在测量数据和进行预测之间造成不必要的延迟
- en: Usually machine learning models do not prepare for or take into account the
    possibility of precomputing part of a result in advance of having all the data.
    Yet for time series this is a very common scenario.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，机器学习模型不会准备或考虑提前计算部分结果，而不是等到所有数据都准备好。然而对于时间序列来说，这是一个非常常见的场景。
- en: 'If you are serving your model in a time-sensitive application, such as for
    medical predictions, vehicle location estimations, or stock price forecasting,
    you may find that the lag of computing a forecast only after all the data becomes
    available is too great. In such a case, you should consider whether the model
    you have chosen can actually be partly precomputed in advance. A few examples
    of where this is possible are as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在为医学预测、车辆位置估计或股票价格预测等对时间敏感的应用程序提供模型服务，你可能会发现在所有数据可用后才计算预测的延迟时间过长。在这种情况下，你应该考虑你选择的模型是否实际上可以部分提前计算。以下是一些可能性的示例：
- en: If you are using a recurrent neural network that takes several channels of information
    over 100 different time steps, you can precompute/unroll the neural network for
    the first 99 time steps. Then when the last data point finally comes in, you only
    need to do 1 final set of matrix multiplications (and other activation function
    computations) rather than 100\. In theory this could speed up your response time
    100-fold.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你正在使用一个递归神经网络，在超过 100 个不同时间步的多个信道中传递信息，你可以预先计算/展开神经网络的前 99 个时间步。然后，当最后一个数据点最终到来时，你只需进行一次最终的矩阵乘法（和其他激活函数计算），而不是
    100 次。理论上，这可以使你的响应时间加快 100 倍。
- en: 'If you are using an AR(5) model, you can precompute all but the most recent
    term in the sum that constitutes the mode. As a reminder, an AR(5) process looks
    like the equation that follows. If you are about to output a prediction, it means
    that you already know the values of *y*[*t* – 4], *y*[*t*–3], *y*[*t*–2], and
    *y*[*t*–1], which means that you can have everything other than <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi>
    <mi>h</mi> <msub><mi>i</mi> <mn>0</mn></msub> <mi>Ã</mi> <mi>—</mi> <msub><mi>y</mi>
    <mi>t</mi></msub></mrow></math> ready to go in advance of knowing *y[t]*:'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你正在使用 AR(5) 模型，你可以预先计算除了构成模型的和的最近项之外的所有项。作为提醒，AR(5) 过程看起来像下面的方程。如果你要输出预测，这意味着你已经知道
    *y*[t – 4]、*y*[t–3]、*y*[t–2] 和 *y*[t–1] 的值，这意味着你可以在知道 *y*[t] 之前提前准备好除了 <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi>
    <mi>h</mi> <msub><mi>i</mi> <mn>0</mn></msub> <mi>Ã</mi> <mi>—</mi> <msub><mi>y</mi>
    <mi>t</mi></msub></mrow></math> 外的一切：
- en: <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msub><mi>y</mi> <mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub>
    <mo>=</mo> <mi>p</mi> <mi>h</mi> <msub><mi>i</mi> <mn>4</mn></msub> <mo>×</mo>
    <msub><mi>y</mi> <mrow><mi>t</mi><mo>-</mo><mn>4</mn></mrow></msub> <mo>+</mo>
    <mi>p</mi> <mi>h</mi> <msub><mi>i</mi> <mn>3</mn></msub> <mo>×</mo> <msub><mi>y</mi>
    <mrow><mi>t</mi><mo>-</mo><mn>3</mn></mrow></msub> <mo>+</mo> <mi>p</mi> <mi>h</mi>
    <msub><mi>i</mi> <mn>2</mn></msub> <mo>×</mo> <msub><mi>y</mi> <mrow><mi>t</mi><mo>-</mo><mn>2</mn></mrow></msub>
    <mo>+</mo> <mi>p</mi> <mi>h</mi> <msub><mi>i</mi> <mn>1</mn></msub> <mo>×</mo>
    <msub><mi>y</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub> <mo>+</mo>
    <mi>p</mi> <mi>h</mi> <msub><mi>i</mi> <mn>0</mn></msub> <mo>×</mo> <msub><mi>y</mi>
    <mi>t</mi></msub></mrow></math>
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msub><mi>y</mi> <mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub>
    <mo>=</mo> <mi>p</mi> <mi>h</mi> <msub><mi>i</mi> <mn>4</mn></msub> <mo>×</mo>
    <msub><mi>y</mi> <mrow><mi>t</mi><mo>-</mo><mn>4</mn></mrow></msub> <mo>+</mo>
    <mi>p</mi> <mi>h</mi> <msub><mi>i</mi> <mn>3</mn></msub> <mo>×</mo> <msub><mi>y</mi>
    <mrow><mi>t</mi><mo>-</mo><mn>3</mn></mrow></msub> <mo>+</mo> <mi>p</mi> <mi>h</mi>
    <msub><mi>i</mi> <mn>2</mn></msub> <mo>×</mo> <msub><mi>y</mi> <mrow><mi>t</mi><mo>-</mo><mn>2</mn></mrow></msub>
    <mo>+</mo> <mi>p</mi> <mi>h</mi> <msub><mi>i</mi> <mn>1</mn></msub> <mo>×</mo>
    <msub><mi>y</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub> <mo>+</mo>
    <mi>p</mi> <mi>h</mi> <msub><mi>i</mi> <mn>0</mn></msub> <mo>×</mo> <msub><mi>y</mi>
    <mi>t</mi></msub></mrow></math>
- en: If you are using a clustering model to find nearest neighbors by summarizing
    features of a time series (mean, standard deviation, max, min, etc.), you can
    compute these features with a time series with one less data point and run your
    model with that time series to identify several nearest neighbors. You can then
    update these features once the final value rolls in and rerun the analysis with
    only the nearest neighbors found in the first round of analysis. This will actually
    require more computation resources overall but will result in a lower lag time
    between taking the final measurement and delivering the forecast.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你正在使用聚类模型来通过总结时间序列的特征（均值、标准差、最大值、最小值等）来找到最近的邻居，你可以用一个数据点较少的时间序列计算这些特征，并用该时间序列运行你的模型来识别几个最近的邻居。然后，当最终值到来时更新这些特征，并重新运行在第一轮分析中找到的最近邻的分析。这实际上会在总体上需要更多的计算资源，但会导致在采取最终测量和提供预测之间的延迟时间减少。
- en: In many cases your model may not be nearly as slow as the network lag or other
    factors, so precomputation is a worthwhile technique only where feedback time
    is extremely important and where you are confident that model computation is substantially
    contributing to the time between an application receiving all needed information
    and outputting a useful prediction.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，您的模型可能并不像网络延迟或其他因素那样缓慢，因此预计算只有在反馈时间极为重要并且您确信模型计算实质上在应用程序接收所有所需信息并输出有用预测之间的时间中有重大贡献时才是一种值得的技术。
- en: 'Data Storage Formats: Pluses and Minuses'
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据存储格式：优缺点
- en: 'One overlooked area of performance bottlenecks for both training and productionizing
    time series models is the method of storing data. Some common errors are:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练和生产化时间序列模型的性能瓶颈中，一个被忽视的领域是数据存储的方法。一些常见的错误包括：
- en: '*Storing data in a row-based data format even though the time series is formed
    by traversing a column*. This results in data where time-adjacent points are not
    memory-adjacent.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*即使时间序列是通过遍历列来形成的，也要将数据存储在基于行的数据格式中*。这将导致时间相邻的点在内存中不是相邻的。'
- en: '*Storing raw data and running analyses off this data*. Preprocessed and downsampled
    data is preferable to the greatest extent possible for a given model.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*存储原始数据并从这些数据运行分析*。对于给定的模型，预处理和降采样的数据优先。'
- en: Next we discuss these data storage factors to keep your model training and inference
    as speedy as possible.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们讨论这些数据存储因素，以尽可能保持模型训练和推断的速度。
- en: Store Your Data in a Binary Format
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将数据存储为二进制格式
- en: It is tempting to store data in a comma-separated text file, such as a CSV file.
    That is often how data is provided, so inertia pushes us to make this choice.
    Such file formats are also human readable, which makes it easy to check the data
    in the file against pipeline outputs. Finally, such data is usually easy to ship
    around different platforms.^([3](ch12.html#idm45576020536184))
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 很容易将数据存储在逗号分隔的文本文件中，比如CSV文件。这通常是数据的提供方式，所以惯性驱使我们选择这种方式。这些文件格式也是人类可读的，这使得可以轻松地检查文件中的数据与流水线输出的一致性。最后，这种数据通常易于在不同平台之间传输。^([3](ch12.html#idm45576020536184))
- en: 'However, it’s not easy for your computer [to read text files](https://perma.cc/XD3Y-NEGP).
    If you are working with data sets so large that you are not able to fit all your
    data in memory during training, you will be dealing with I/O and related processing
    all tied to the file format you choose. By storing data in a binary format, you
    can substantially cut down on I/O-related slowdowns in a number of ways:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，对于您的计算机来说并不容易[读取文本文件](https://perma.cc/XD3Y-NEGP)。如果您处理的数据集非常大，以至于在训练过程中无法将所有数据放入内存中，您将需要处理与您选择的文件格式相关的I/O和相关处理。通过将数据存储为二进制格式，您可以通过多种方式大大减少与I/O相关的减速：
- en: Because the data is in binary format, your data processing package already “understands”
    it. There is no need to read a CSV and turn it into a data frame. You will already
    have a data frame when you input your data.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因为数据以二进制格式存储，您的数据处理包已经“理解”它。无需读取CSV并将其转换为数据框架。当您输入数据时，您将已经拥有一个数据框架。
- en: Because the data is in binary format, it can be compressed far more than a CSV
    or other text-based file. This means that I/O itself will be shorter because there
    is less physical memory to read in a file so as to re-create its contents.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因为数据以二进制格式存储，它可以比CSV或其他基于文本的文件压缩得更多。这意味着I/O本身将更短，因为要读取一个文件所需的物理内存较少，以便重新创建其内容。
- en: Binary storage formats are easily accessible in both R and Python. In R, use
    `save()` and `load()` for `data.table`. In Python, use pickling and note that
    both Pandas (`pd.DataFrame.load()` and `pd.DataFrame.save()`) and NumPy (`np.load()`
    and `np.save()`) include wrappers around pickling that you can use for their specific
    objects.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 二进制存储格式在R和Python中都很容易访问。在R中，使用`save()`和`load()`来处理`data.table`。在Python中，使用pickling，并注意Pandas（`pd.DataFrame.load()`和`pd.DataFrame.save()`）和NumPy（`np.load()`和`np.save()`）都包含了围绕pickling的包装器，您可以用来处理它们特定的对象。
- en: Preprocess Your Data in a Way That Allows You to “Slide” Over It
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 以允许您“滑动”处理数据的方式预处理数据
- en: This recommendation is related to [“Models Built for Cross-Sectional Data Don’t
    “Share” Data Across Samples”](#models-for-cross-sectional-data). In this case,
    you should also think about how you preprocess your data and make sure the way
    you do so is consistent with using a moving window over that data to generate
    multiple test samples.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 此建议与[“为横截面数据构建的模型不会在样本间‘共享’数据”](#models-for-cross-sectional-data)相关。在这种情况下，您还应考虑如何预处理数据，并确保您的做法与使用移动窗口在数据上生成多个测试样本的方式一致。
- en: 'As an example, consider normalization or moving averages as preprocessing steps.
    If you plan to do these for each time window, this may lead to improved model
    accuracy (although in my experience such gains are often marginal). However, there
    are several downsides:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 作为示例，考虑归一化或移动平均作为预处理步骤。如果您计划针对每个时间窗口执行这些操作，则可能会提高模型的准确性（尽管根据我的经验，这种增益通常不大）。但是，存在几个缺点：
- en: You need more computational resources to compute these preprocessing features
    many, many times on overlapping data—only to end up with very similar numbers.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您需要更多计算资源来多次在重叠数据上计算这些预处理特征，最终得到非常相似的数字。
- en: You need to store overlapping data with slightly different preprocessing many,
    many times.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您需要多次存储具有稍有不同预处理的重叠数据。
- en: You cannot take optimum advantage of sliding a window over your data.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您无法充分利用滑动窗口在数据上的滑动优势。
- en: Modifying Your Analysis to Suit Performance Considerations
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 修改您的分析以适应性能考虑
- en: Many of us are guilty of getting too comfortable with a particular set of analytical
    tools, and the accompanying suite of software and rules of thumb about how to
    fit a model. We also tend to assess accuracy needs once and not reassess them
    when we determine the computational cost of various possible model performances.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们许多人都有使用特定分析工具集的习惯，以及关于如何拟合模型的软件套件和经验法则。我们也倾向于在一次评估准确性需求后就不再重新评估它们，尽管我们确定了各种可能的模型性能的计算成本。
- en: Time series data, often used to make a fast forecast, is particularly prone
    to needing models that can be both fit and productionized quickly. The models
    need to be fit quickly so they can be updated with new data coming in, and they
    need to perform quickly so that the consumers of the models’ forecasts have as
    much time as possible to act on those forecasts. For this reason, you may sometimes
    want to modify your expectations—and accompanying analysis—to make faster and
    more computationally streamlined processes for analysis and forecasting.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列数据通常用于快速预测，特别容易需要能够快速拟合和生产化的模型。模型需要快速拟合，以便可以用新数据进行更新，同时需要快速执行，以便模型预测的消费者有尽可能多的时间来采取行动。因此，您有时可能希望修改您的期望值及相关分析，以实现更快速和更简化计算的过程用于分析和预测。
- en: Using All Your Data Is Not Necessarily Better
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用所有您的数据并非总是更好
- en: One important factor in thinking about how to streamline your analysis is to
    understand that not all data in a time series is equally important. More distant
    data is less important. Data during “exceptional” times is less important to building
    a model for ordinary times.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 思考如何简化分析的一个重要因素是要理解时间序列中并非所有数据都同等重要。更遥远的数据较不重要。在“异常”时期的数据对建立普通时期模型较不重要。
- en: 'There are many ways you should consider lessening the amount of data you use
    to train a model. While many of these options have been discussed earlier in this
    book, it’s good to review them, particularly with respect to performance:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种方式可以考虑减少用于训练模型的数据量。虽然这本书前面已经讨论了许多这些选项，但仍然有必要进行复习，特别是关于性能方面：
- en: Downsampling
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 降采样
- en: It is often the case that you can use data that is less frequent to cover the
    same lookback window when making a prediction. This is a way to downsize your
    data by a multiplicative factor. Note that, depending on the analytical technique
    you use, you also have more creative options, such as downsampling at different
    rates depending on how far back the data goes.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，您可以使用较少频率的数据来覆盖相同的回溯窗口进行预测。这是通过乘法因子缩小数据的一种方法。请注意，根据您使用的分析技术，您还有更多创造性的选项，例如根据数据远近以不同速率进行降采样。
- en: Training only on recent data
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 仅训练最近的数据
- en: While machine learning loves data, there are many time series models where statistical
    or even deep learning techniques will actually do better just focusing on recent
    data rather than training on all data. This will help you reduce your input data
    by subtracting out data that is only marginally informative for your model.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管机器学习喜欢数据，但在许多时间序列模型中，仅专注于最近数据而不是对所有数据进行训练，统计或甚至深度学习技术实际上会更好。这将帮助您通过剔除对模型而言信息量较小的数据来减少输入数据。
- en: Reduce the lookback window used to make your prediction
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 缩小用于预测的回顾窗口
- en: In many time series models, the model’s performance will continue to improve,
    if only slightly, as you look further and further back into the past. You should
    make some decisions about how much accuracy is really required relative to performance.
    It may be that you are loading far more data into memory per sample than is really
    necessary for acceptable performance.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多时间序列模型中，随着你向过去看得越久，模型的性能可能会继续提高，即使只有稍微。你应该对实际需要的准确性与性能做出一些决策。也许每个样本加载到内存中的数据量远远超出了实现可接受性能所需的数据量。
- en: Complicated Models Don’t Always Do Better Enough
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 复杂的模型并不总是表现得更好
- en: It can be interesting and fun to try the latest and greatest when it comes to
    choosing an analytical model. However, the real question is whether a fancier
    model “pays” for any additional computational resources required.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择分析模型时尝试最新和最好的可能会很有趣和有趣。然而，真正的问题是，是否更复杂的模型需要额外的计算资源来“支付”。
- en: Almost all the computational advances in machine learning of recent years have
    come from throwing more computing power at a problem. With problems such as image
    recognition, where there is definitely a right answer and 100% accuracy, this
    can certainly make sense.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来机器学习中几乎所有的计算进步都来自于对问题投入更多计算资源。对于像图像识别这样确实存在正确答案且需要100%准确性的问题，这当然是合理的选择。
- en: On the other hand, with problems such as time series predictions, where there
    may be physical or mathematical limits to how accurate a prediction can be, you
    should make sure that choosing a more complex model is not simply automatic upgrading
    without a cost-benefit analysis. Think about whether the accuracy gains justify
    the additional lag the model may produce in computing a forecast, or the additional
    training time that will be required, or the additional computational resources
    that will be spun up. It may be that a less resource-intensive method with slightly
    poorer accuracy is a far better “deal” than a fancy model that barely improves
    upon the simple version.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，对于像时间序列预测这样的问题，可能存在物理或数学限制，决定选择更复杂的模型不应该只是自动升级而没有成本效益分析。考虑准确性增益是否足以证明模型可能在计算预测时产生的额外延迟，或者所需的额外训练时间，或者将启动的额外计算资源。也许一个资源消耗较少但准确性稍差的方法比一个几乎与简单版本无异的花哨模型更好。
- en: If you are the data analyst, this trade-off between complexity/accuracy and
    lag time/computer resources is something you should analyze, thinking of it as
    another hyperparameter to tune. It’s your job to point out these trade-offs rather
    than assume that a data engineer will take care of it. People upstream or downstream
    in the data pipeline cannot substitute your judgment for model selection, so you
    have to acknowledge the engineering side of data science while weighing pros and
    cons.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是数据分析师，这种复杂性/准确性和延迟时间/计算资源之间的权衡是你应该分析的内容，把它看作另一个需要调整的超参数。你的工作是指出这些权衡，而不是假设数据工程师会处理这些问题。数据管道中上下游的人员不能替代你在模型选择上的判断，因此在权衡利弊时你必须考虑到数据科学的工程方面。
- en: A Brief Mention of Alternative High-Performance Tools
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简要提及备选高性能工具
- en: 'If you have fully explored the previous options, you can also consider changing
    your underlying code base, more specifically by moving away from slower scripting
    languages, such as Python and R. There are a number of ways to do this:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经全面探索了前述选项，你还可以考虑改变你的基础代码库，更具体地说是摆脱像Python和R这样的较慢脚本语言。有几种方法可以实现这一点：
- en: Go all in with C++ and Java. Even if you haven’t looked at these languages,
    just learning the basics can sometimes speed up the slow parts of your pipeline
    enough to transform impossible tasks into manageable ones. C++ in particular has
    evolved tremendously in terms of usability and standard libraries applicable to
    data processing. The STL and C++ 17 syntax now offers many options quite comparable
    to Python for operating on sets of data in a variety of data structures. Even
    if you hated C++ and Java years ago, you should revisit them.^([4](ch12.html#idm45576020485688))
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全面采用 C++ 和 Java。即使你以前没有接触过这些语言，仅仅学习基础知识有时也足以加速管道中的慢部分，将不可能的任务转变为可以管理的任务。特别是
    C++ 在可用性和适用于数据处理的标准库方面已经有了巨大的进展。STL 和 C++ 17 语法现在提供了许多与 Python 在各种数据结构上操作相当的选项。即使你多年前讨厌
    C++ 和 Java，也应该重新审视它们。^([4](ch12.html#idm45576020485688))
- en: In Python, you can use several different modules wherein you can write Python
    code that gets compiled into C or C++ code, speeding up execution time. This can
    be especially useful for very repetitive code with many `for` loops, which are
    slow in Python and can become much more performant in C or C++ without the need
    for clever design—simply implementing the same code in the faster language can
    do the trick. `Numba` and `Cython` are both accessible drop-in Python modules
    that can help you speed up slow chunks of Python code this way.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Python 中，你可以使用几个不同的模块，其中可以编写 Python 代码并编译为 C 或 C++ 代码，加快执行时间。这对于具有许多`for`循环的非常重复的代码特别有用，在
    Python 中这些循环很慢，在 C 或 C++ 中可以更加高效，而无需进行巧妙的设计 —— 只需在更快的语言中实现相同的代码即可解决问题。`Numba`
    和 `Cython` 都是可以帮助你通过这种方式加速 Python 代码的可访问的 Python 模块。
- en: Likewise, in R, you can use `Rcpp` for similar functionality.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同样，在 R 中，你可以使用 `Rcpp` 来实现类似的功能。
- en: More Resources
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多资源
- en: 'On models performing equally:'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在模型表现相等的情况下：
- en: 'Anthony Bagnall et al., [“The Great Time Series Classification Bake Off: An
    Experimental Evaluation of Recently Proposed Algorithms,”](https://perma.cc/T76B-M635)
    *Data Mining and Knowledge Discovery* 31, no. 3 (2017): 606–60, https://perma.cc/T76B-M635.'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'Anthony Bagnall 等人，[“时间序列分类大比拼: 最近提出的算法的实验评估,”](https://perma.cc/T76B-M635)
    *数据挖掘与知识发现* 31, no. 3 (2017): 606–60, https://perma.cc/T76B-M635。'
- en: This article runs an extensive array of experiments to assess performance of
    modern time series classification methodologies, comparing their performance on
    a wide variety of publicly available data sets. The computational complexity of
    the data sets ultimately ends up varying quite a bit more than does the actual
    performance of the methods tried. As the authors highlight, it remains an art
    and an area of research to determine, without trying them all, which method will
    work best on a given data set. From a computing resources perspective, the lesson
    to learn here is that computational complexity should factor in significantly
    in methodological decisions. Unless you have a very compelling use case for a
    complicated and resource-intensive algorithm, choose something simpler.
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本文进行了大量的实验来评估现代时间序列分类方法的性能，在广泛的公开数据集上比较它们的表现。数据集的计算复杂性最终变化比尝试的方法实际表现更加显著。正如作者所强调的那样，确定在给定数据集上哪种方法最有效，不尝试所有方法仍然是一门艺术和研究领域。从计算资源的角度来看，这里需要学习的教训是计算复杂性应在方法决策中起重要作用。除非你对复杂且资源密集型算法有非常具有说服力的用例，否则选择一些更简单的东西。
- en: 'On building simpler models:'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在构建简单模型方面：
- en: 'Yoon Kim and Alexander M. Rush, [“Sequence Level Knowledge Distillation,”](https://perma.cc/V4U6-EJNU)
    in *Proceedings of the 2016 Conference on Empirical Methods in Natural Language
    Processing*, ed. Jian Su, Kevin Duh, and Xavier Carreras (Austin, TX: Association
    for Computational Linguistics, 2016), 1317–27, https://perma.cc/V4U6-EJNU.'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'Yoon Kim 和 Alexander M. Rush，[“序列级知识蒸馏,”](https://perma.cc/V4U6-EJNU) 收录于《2016年经验方法在自然语言处理会议论文集》,
    编辑 Jian Su, Kevin Duh, 和 Xavier Carreras (Austin, TX: Association for Computational
    Linguistics, 2016), 1317–27, https://perma.cc/V4U6-EJNU。'
- en: This article applies the general concept of “distillation” to sequence learning,
    as applied to a machine translation task. The concept of distillation is a broadly
    useful one. The idea is that first a complex model is designed and trained on
    the original data, and then a simpler model is trained on the outputs of the complex
    model. The outputs of the complex model, rather than the data itself, reduces
    noise and simplifies the learning problem, making it easier for a simpler model
    to learn approximately the same relationship by cutting out the noise. While such
    a technique will not lessen training time, it should produce a model that executes
    faster and demands fewer resources when put into production.
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本文将“蒸馏”的一般概念应用于序列学习，适用于机器翻译任务。蒸馏的概念是一个广泛有用的概念。其核心思想是首先设计并训练一个复杂模型，然后在复杂模型的输出上训练一个简化模型。通过利用复杂模型的输出而不是数据本身，可以减少噪音并简化学习问题，使得简化模型能够通过去除噪音来学习大致相同的关系。虽然这种技术不会减少训练时间，但应该能够产生一个在生产中执行速度更快、资源需求更少的模型。
- en: ^([1](ch12.html#idm45576020725864-marker)) Yes, this happens all the time in
    the real world.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch12.html#idm45576020725864-marker)) 是的，在现实世界中这种情况经常发生。
- en: ^([2](ch12.html#idm45576020688152-marker)) We extracted many time series samples
    from one large time series in the case of both the machine learning and the deep
    learning models discussed in earlier chapters.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch12.html#idm45576020688152-marker)) 我们在早期章节讨论的机器学习和深度学习模型案例中，从一个大的时间序列中提取了许多时间序列样本。
- en: ^([3](ch12.html#idm45576020536184-marker)) Although there are Unicode problems
    related to different platforms and devices, so you are not in the clear just because
    you use a text-based file format.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch12.html#idm45576020536184-marker)) 尽管存在与不同平台和设备相关的Unicode问题，因此仅仅因为使用了基于文本的文件格式，并不代表你可以轻松解决问题。
- en: ^([4](ch12.html#idm45576020485688-marker)) There is a steep learning curve,
    but once you have the basic compilation infrastructure figured out, this can be
    a huge bonus to your organization.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch12.html#idm45576020485688-marker)) 学习曲线陡峭，但一旦你掌握了基本的编译基础设施，这对你的组织将是一个巨大的优势。
