- en: 5 Filtering a DataFrame
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5. 过滤DataFrame
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Reducing a `DataFrame`’s memory use
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少DataFrame的内存使用
- en: Extracting `DataFrame` rows by one or more conditions
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过一个或多个条件提取`DataFrame`行
- en: Filtering a `DataFrame` for rows that include or exclude null values
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过滤包含或排除空值的`DataFrame`行
- en: Selecting column values that fall between a range
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择介于某个范围内的列值
- en: Removing duplicate and null values from a `DataFrame`
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从`DataFrame`中删除重复和空值
- en: In chapter 4, we learned how to extract rows, columns, and cell values from
    a `DataFrame` by using the `loc` and `iloc` accessors. These accessors work well
    when we know the index labels and positions of the rows/columns we want to target.
    Sometimes, we may want to target rows not by an identifier but by a condition
    or a criterion. We may want to extract a subset of rows in which a column holds
    a specific value, for example.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在第4章中，我们学习了如何通过使用`loc`和`iloc`访问器从`DataFrame`中提取行、列和单元格值。这些访问器在我们知道要针对的行/列的索引标签和位置时工作得很好。有时，我们可能想要通过条件或标准而不是标识符来定位行。例如，我们可能想要提取一个列包含特定值的行子集。
- en: In this chapter, we’ll learn how to declare logical conditions that include
    and exclude rows from a `DataFrame`. We’ll see how to combine multiple conditions
    by using `AND` and `OR` logic. Finally, we’ll introduce some pandas utility methods
    that simplify the filtering process. Lots of fun lies ahead, so let’s jump in.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何声明包含和排除`DataFrame`行的逻辑条件。我们将看到如何通过使用`AND`和`OR`逻辑结合多个条件。最后，我们将介绍一些pandas实用方法，这些方法简化了过滤过程。前方有很多乐趣，让我们开始吧。
- en: 5.1 Optimizing a data set for memory use
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 优化数据集以减少内存使用
- en: 'Before we segue into filtering, let’s quickly talk about reducing memory in
    pandas. Whenever importing a data set, it’s important to consider whether each
    column stores its data in the most optimal type. The “best” data type is the one
    that consumes the least memory or provides the most utility. Integers occupy less
    memory than floating-point numbers on most computers, for example, so if your
    data set includes whole numbers, it’s ideal to import them as integers rather
    than floating-points. As another example, if your data set includes dates, it’s
    ideal to import them as datetimes rather than as strings, which allows for datetime-specific
    operations. In this section, we’ll learn some tips and tricks to shrink memory
    consumption by converting column data to different types, which will facilitate
    faster filtering later. Let’s begin with the usual import of our favorite data
    analysis library:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们过渡到过滤之前，让我们快速谈谈在pandas中减少内存使用。每次导入数据集时，考虑每个列是否以最优化类型存储其数据都很重要。“最佳”数据类型是消耗最少内存或提供最多效用的一种类型。例如，在大多数计算机上，整数比浮点数占用更少的内存，所以如果你的数据集包含整数，理想的情况是将它们导入为整数而不是浮点数。作为另一个例子，如果你的数据集包含日期，理想的情况是将它们导入为日期时间而不是字符串，这允许进行日期时间特定的操作。在本节中，我们将学习一些技巧和窍门，通过将列数据转换为不同类型来减少内存消耗，这将有助于后续的快速过滤。让我们从导入我们最喜欢的数据分析库的常规操作开始：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This chapter’s employees.csv data set is a fictional collection of workers
    at a company. Each record includes the employee’s first name, gender, start date
    at the firm, salary, manager status (`True` or `False`), and team. Let’s take
    a peek at the data set with the `read_csv` function:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的employees.csv数据集是一个虚构的公司员工集合。每条记录包括员工的姓氏、性别、在公司的工作开始日期、薪水、经理状态（`True`或`False`）和团队。让我们用`read_csv`函数看一下数据集：
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Take a second to notice the `NaNs` scattered throughout the output. Every column
    has missing values. In fact, the last row consists only of `NaNs`. Imperfect data
    like this is common in the real world. Data sets can arrive with blank rows, blank
    columns, and more.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 请花点时间注意输出中散布的`NaNs`。每一列都有缺失值。实际上，最后一行只包含`NaNs`。在现实世界中，像这样的不完整数据很常见。数据集可能包含空白行、空白列等。
- en: 'How can we increase the utility of our data set? Our first optimization is
    one that we should feel comfortable with by now. We can convert the text values
    in the Start Date column to datetimes with the `parse_dates` parameter:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何提高数据集的效用？我们的第一个优化是我们现在应该感到舒适的。我们可以使用`parse_dates`参数将开始日期列中的文本值转换为日期时间：
- en: '[PRE2]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We’re in a good place with the CSV import, so let’s assign the `DataFrame`
    object to a descriptive variable such as `employees`:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: CSV导入进展顺利，所以让我们将`DataFrame`对象分配给一个描述性的变量，例如`employees`：
- en: '[PRE3]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'A few options are available for improving the speed and efficiency of `DataFrame`
    operations. First, let’s summarize the data set as it currently stands. We can
    invoke the `info` method to see a list of the columns, their data types, a count
    of missing values, and the `DataFrame`’s total memory consumption:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种选项可以提高`DataFrame`操作的速度和效率。首先，让我们总结当前的数据集。我们可以调用`info`方法来查看列列表、它们的数据类型、缺失值的计数以及`DataFrame`的总内存消耗：
- en: '[PRE4]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Let’s walk through the output from top to bottom. We have a `DataFrame` with
    1,001 rows, starting at index 0 and proceeding to index 1000\. There are four
    string columns, one datetime column, and one floating-point column. All six columns
    have missing data.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从上到下浏览输出结果。我们有一个包含1,001行的`DataFrame`，从索引0开始，到索引1000结束。有四个字符串列，一个日期时间列和一个浮点列。所有六列都有缺失数据。
- en: Memory use currently is ~47 KB—a small amount for modern computers, but let’s
    try to whittle the number down. As you read the following examples, focus more
    on the percentage reductions than on the numeric reductions. The larger your data
    sets grow, the more significant the performance improvement will be.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 当前内存使用量约为47 KB——对于现代计算机来说是一个小数字，但让我们尝试将其数量减少。在阅读以下示例时，请更多地关注百分比减少而不是数值减少。随着数据集的增长，性能改进将更加显著。
- en: 5.1.1 Converting data types with the astype method
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.1 使用astype方法转换数据类型
- en: 'Did you notice that pandas imported the Mgmt column’s values as strings? The
    column stores only two values: `True` and `False`. We can reduce memory use by
    converting the values to the more lightweight Boolean data type.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 你注意到pandas将Mgmt列的值作为字符串导入了吗？该列只存储两个值：`True`和`False`。我们可以通过将值转换为更轻量级的布尔数据类型来减少内存使用。
- en: 'The `astype` method converts a `Series`’ values to a different data type. It
    accepts a single argument: the new data type. We can pass either the data type
    or a string with its name.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`astype`方法将`Series`的值转换为不同的数据类型。它接受一个参数：新的数据类型。我们可以传递数据类型或其名称的字符串。'
- en: The next example extracts the Mgmt `Series` from `employees` and invokes its
    `astype` method with an argument of `bool`. Pandas returns a new `Series` object
    of Booleans. Note that the library converts `NaNs` to `True` values. We’ll discuss
    removing missing values in section 5.5.4.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个示例从`employees`中提取Mgmt `Series`并使用`bool`参数调用其`astype`方法。Pandas返回一个新的布尔`Series`对象。请注意，库将`NaNs`转换为`True`值。我们将在5.5.4节中讨论删除缺失值。
- en: '[PRE5]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Looks good! Now that we’ve previewed what the `Series` will look like, we can
    overwrite the existing Mgmt column in `employees`. Updating a `DataFrame` column
    works similarly to setting a key-value pair in a dictionary. If a column with
    the specified name exists, pandas overwrites it with the new `Series`. If the
    column with the name does not exist, pandas creates a new `Series` and appends
    it to the right of the `DataFrame`. The library matches rows in the `Series` and
    `DataFrame` by shared index labels.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来不错！现在我们已经预览了`Series`将如何显示，我们可以覆盖`employees`中现有的Mgmt列。更新`DataFrame`列的工作方式与在字典中设置键值对类似。如果存在具有指定名称的列，pandas会用新的`Series`覆盖它。如果不存在具有该名称的列，pandas会创建一个新的`Series`并将其追加到`DataFrame`的右侧。库通过共享索引标签来匹配`Series`和`DataFrame`中的行。
- en: 'The next code sample overwrites the Mgmt column with our new `Series` of Booleans.
    As a reminder, Python evaluates the right side of the assignment operator (`=`)
    first. First, we create a new `Series`, then we overwrite our existing Mgmt column:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个代码示例使用我们的新布尔`Series`覆盖Mgmt列。作为提醒，Python首先评估赋值运算符（`=`）的右侧。首先，我们创建一个新的`Series`，然后我们覆盖现有的Mgmt列：
- en: '[PRE6]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'A column assignment does not produce a return value, so the code does not output
    anything in Jupyter Notebook. Let’s take a look at the `DataFrame` again to see
    the results:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 列赋值不会产生返回值，因此在Jupyter Notebook中代码不会输出任何内容。让我们再次查看`DataFrame`以查看结果：
- en: '[PRE7]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Except for the `True` in the last row of missing values, the `DataFrame` looks
    no different. But what about our memory use? Let’s invoke the `info` method again
    to see the difference:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 除了缺失值最后一行的`True`之外，`DataFrame`看起来没有不同。但我们的内存使用量如何呢？让我们再次调用`info`方法来查看差异：
- en: '[PRE8]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We’ve reduced `employees`’ memory use by almost 15%, from 47 KB to 40.2 KB.
    That’s a pretty good start!
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将`employees`的内存使用量减少了近15%，从47 KB降至40.2 KB。这是一个相当不错的开始！
- en: 'Next, let’s transition to the Salary column. If we open the raw CSV file, we
    can see that its values are stored as whole numbers:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们过渡到Salary列。如果我们打开原始CSV文件，我们可以看到其值存储为整数：
- en: '[PRE9]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In `employees`, however, pandas stores the Salary values at floats. To support
    the `NaNs` throughout the column, pandas converts the integers to floating-point
    numbers—a technical requirement of the library that we observed in earlier chapters.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在`employees`中，然而，pandas将Salary值存储为浮点数。为了在整个列中支持`NaNs`，pandas将整数转换为浮点数——这是我们在前面的章节中观察到的库的技术要求。
- en: 'Following our previous Boolean example, we might try to coerce the column’s
    values to integers with the `astype` method. Unfortunately, pandas raises a `ValueError`
    exception:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的布尔示例之后，我们可能会尝试使用`astype`方法将列的值强制转换为整数。不幸的是，pandas会引发一个`ValueError`异常：
- en: '[PRE10]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Pandas is unable to convert the `NaN` values to integers. We can solve this
    problem by replacing the `NaN` values with a constant value. The `fillna` method
    replaces a `Series`’ null values with the argument we pass in. The next example
    provides a fill value of 0\. Note that your choice of value can distort the data;
    0 is passed solely for the sake of example.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas无法将`NaN`值转换为整数。我们可以通过用常数值替换`NaN`值来解决这个问题。`fillna`方法用我们传入的参数替换`Series`的空值。下一个示例提供了一个填充值为0。请注意，您选择的价值可能会扭曲数据；0仅用于示例。
- en: 'We know that the original Salary column has a missing value in its last row.
    Let’s take a look at the last row after we invoke the `fillna` method:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道原始的Salary列在其最后一行有一个缺失值。让我们在调用`fillna`方法后查看最后一行：
- en: '[PRE11]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Excellent. Now that the Salary column has no missing values, we can convert
    its values to integers with the `astype` method:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了。现在，由于Salary列没有缺失值，我们可以使用`astype`方法将其值转换为整数：
- en: '[PRE12]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Next, we can overwrite the existing Salary `Series` in `employees`:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以覆盖`employees`中现有的Salary `Series`：
- en: '[PRE13]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We can make one additional optimization. Pandas includes a special data type
    called a *category*, which is ideal for a column consisting of a small number
    of unique values relative to its total size. Some everyday examples of data points
    with a limited number of values include gender, weekdays, blood types, planets,
    and income groups. Behind the scenes, pandas stores only one copy of each categorical
    value rather than storing duplicates across rows.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以做出一个额外的优化。Pandas包括一个称为*类别*的特殊数据类型，这对于相对于其总大小具有少量唯一值的列来说非常理想。一些具有有限数量值的日常数据点示例包括性别、工作日、血型、行星和收入群体。在幕后，pandas只为每个分类值存储一个副本，而不是在行之间存储重复的副本。
- en: 'The `nunique` method can reveal the number of unique values in each `DataFrame`
    column. Note that it excludes missing values (`NaN`) from the count by default:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`nunique`方法可以揭示每个`DataFrame`列中唯一值的数量。请注意，它默认排除计数中的缺失值（`NaN`）：'
- en: '[PRE14]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The Gender and Team columns stand out as good candidates to store categorical
    values. In 1,001 rows of data, Gender has only two unique values, and Team has
    only ten unique values.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Gender和Team列是存储分类值的良好候选。在1,001行数据中，Gender只有两个唯一值，而Team只有十个唯一值。
- en: 'Let’s use the `astype` method again. First, we’ll convert the Gender column’s
    values to categories by passing an argument of `"category"` to the method:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次使用`astype`方法。首先，我们将通过将“category”作为参数传递给方法将Gender列的值转换为类别：
- en: '[PRE15]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Pandas has identified two unique categories: `"Female"` and `"Male"`. We’re
    good to overwrite our existing Gender column:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas已经识别出两个独特的类别：“Female”和“Male”。我们可以覆盖现有的Gender列：
- en: '[PRE16]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Let’s check in on the memory use by invoking the `info` method. Memory use
    has dropped significantly once again because pandas has to keep track of only
    two values instead of 1,001:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过调用`info`方法检查内存使用情况。由于pandas只需要跟踪两个值而不是1,001个，内存使用量再次显著下降：
- en: '[PRE17]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Let’s repeat the same process for the Team column, which has only ten unique
    values:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为只有十个唯一值的Team列重复相同的流程：
- en: '[PRE18]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: With fewer than ten lines of code, we’ve reduced the `DataFrame`’s memory consumption
    by more than 40%. Imagine that impact on data sets with millions of rows!
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在不到十行代码的情况下，我们已经将`DataFrame`的内存消耗减少了40%以上。想象一下对拥有数百万行数据集的影响！
- en: 5.2 Filtering by a single condition
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 通过单个条件进行过滤
- en: Extracting a subset of data is perhaps the most common operation in data analysis.
    A *subset* is a portion of a larger data set that fits some kind of condition.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 提取数据子集可能是数据分析中最常见的操作。一个*子集*是符合某种条件的大数据集的一部分。
- en: Suppose that we want to generate a list of all employees named `"Maria"`. To
    accomplish this task, we need to filter our employees data set based on the values
    in the First Name column. The list of employees named Maria is a subset of all
    employees.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要生成所有名为“Maria”的员工的列表。为了完成这个任务，我们需要根据“First Name”列中的值过滤我们的员工数据集。名为Maria的员工列表是所有员工的一个子集。
- en: 'First, a quick reminder of how equality works in Python. The equality operator
    (`==`) compares the equality of two objects in Python, returning `True` if the
    objects are equal and `False` if they are unequal. (See appendix B for a detailed
    explanation.) Here’s a simple example:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，简要回顾一下Python中相等性的工作原理。在Python中，相等运算符（`==`）比较两个对象是否相等，如果对象相等则返回`True`，如果不相等则返回`False`。（有关详细解释，请参阅附录B。）以下是一个简单的示例：
- en: '[PRE19]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'To compare every `Series` entry with a constant value, we place the `Series`
    on one side of the equality operator and the value on the other:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 要比较每个`Series`条目与一个常量值，我们将`Series`放在等号的一侧，而将值放在另一侧：
- en: '[PRE20]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: One might think that this syntax would lead to an error, but pandas is smart
    enough to recognize that we want to compare the equality of each `Series` value
    with the specified string, not with the `Series` itself. We explored similar ideas
    in chapter 2 when we paired a `Series` with mathematical operators such as the
    addition sign.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 有些人可能会认为这种语法会导致错误，但pandas足够智能，能够识别出我们想要比较的是每个`Series`值与指定字符串的相等性，而不是与`Series`本身进行比较。我们在第二章中探讨了类似的想法，当时我们将`Series`与数学运算符（如加号）配对。
- en: 'When we combine a `Series` with an equality operator, pandas returns a `Series`
    of Booleans. The next example compares each First Name column value with `"Maria"`.
    A `True` value indicates that the string `"Maria"` does occur at that index, and
    a `False` value indicates that it does not. The following output communicates
    that index 2 stores the value `"Maria"`:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将`Series`与相等运算符结合时，pandas返回一个布尔`Series`。下一个示例比较每个“First Name”列的值与“Maria”。`True`值表示字符串“Maria”确实出现在该索引处，而`False`值表示没有。以下输出表明索引2存储的值是“Maria”：
- en: '[PRE21]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '`If we could extract only the rows with a True value above from our employees
    DataFrame, we would have all the "Maria" records in the data set. Luckily, pandas
    offers a convenient syntax for extracting rows by using a Boolean Series. To filter
    rows, we provide the Boolean Series between square brackets following the DataFrame`:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只能提取具有True值的行，那么我们的employees DataFrame将包含数据集中所有的"Maria"记录。幸运的是，pandas提供了一个方便的语法，通过布尔`Series`提取行。要过滤行，我们在DataFrame后提供布尔`Series`，并用方括号括起来：
- en: '[PRE22]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Great success! We’ve used our Boolean `Series` to filter rows with a value of
    `"Maria"` in the First Name column.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 大获成功！我们已经使用布尔`Series`过滤了“First Name”列中值为“Maria”的行。
- en: 'If the use of multiple square brackets is confusing, you can assign the Boolean
    `Series` to a descriptive variable and then pass the variable into the square
    brackets instead. The following code yields the same subset of rows as the preceding
    code:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用多个方括号令人困惑，您可以将布尔`Series`分配给一个描述性变量，然后通过方括号传递该变量。以下代码产生与前面代码相同的行子集：
- en: '[PRE23]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The most common mistake beginners make when comparing the equality of values
    is using one equal sign instead of two. Remember that a single equal sign assigns
    an object to a variable, and two equal signs check for equality between objects.
    If we accidentally used a single equal sign in this example, we would overwrite
    all the First Name column’s values with the string `"Maria"`. No good.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 初学者在比较值相等性时最常见的错误是使用一个等号而不是两个。请记住，单个等号将对象分配给变量，而两个等号检查对象之间的相等性。如果我们在这个例子中不小心使用了单个等号，我们将所有“First
    Name”列的值覆盖为字符串“Maria”。这可不是什么好事。
- en: 'Let’s try another example. What if we want to extract a subset of employees
    who are not on the Finance team? The protocol remains the same, but with a slight
    twist. We need to generate a Boolean `Series` that checks which of the Team column’s
    values are not equal to `"Finance"`. Then we can use the Boolean `Series` to filter
    `employees`. Python’s inequality operator returns `True` if two values are not
    equal and `False` if they are equal:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再举一个例子。如果我们想提取不属于财务团队的员工子集，协议保持不变，但略有变化。我们需要生成一个布尔`Series`，检查团队列的哪些值不等于`"Finance"`。然后我们可以使用布尔`Series`来过滤`employees`。Python的不等运算符在两个值不相等时返回`True`，在相等时返回`False`：
- en: '[PRE24]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The `Series` object plays friendly with the inequality operator as well. The
    next example compares the values in the Team column with the string `"Finance"`.
    `True` denotes that the Team value for a given index is not `"Finance"`, and `False`
    indicates the Team value is `"Finance"`:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '`Series` 对象也与不等式运算符友好地配合。以下示例比较团队列中的值与字符串 `"Finance"`。`True` 表示给定索引的 `Team`
    值不是 `"Finance"`，而 `False` 表示 `Team` 值是 `"Finance"`：'
- en: '[PRE25]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '`Now that we have our Boolean Series, we can pass it inside square brackets
    to extract the DataFrame rows with a value of True. In the following output, we
    see that pandas has excluded the rows at indexes 2 and 3 because the` Team `value
    there` is `"Finance"`:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '`现在我们有了布尔 `Series`，我们可以将其放入方括号中，以提取值为 `True` 的 DataFrame 行。在以下输出中，我们看到 pandas
    排除了索引 2 和 3 的行，因为那里的 `Team` 值为 `"Finance"`：'
- en: '[PRE26]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Note that the results include rows with missing values. We can see an example
    at index 1000\. In this scenario, pandas considers a `NaN` to be unequal to the
    string `"Finance"`.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，结果包括具有缺失值的行。我们可以在索引 1000 处看到一个例子。在这种情况下，pandas 将 `NaN` 视为不等于字符串 `"Finance"`。
- en: 'What if we want to retrieve all the managers in the company? Managers have
    a value of `True` in the Mgmt column. We could execute `employees["Mgmt"]` `==
    True`, but we don’t need to because Mgmt is already a `Series` of Booleans. The
    `True` values and `False` values already indicate whether pandas should keep or
    discard a row. Therefore, we can pass the Mgmt column by itself inside the square
    brackets:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要检索公司中的所有经理？经理在 `Mgmt` 列中的值为 `True`。我们可以执行 `employees["Mgmt"] == True`，但不需要，因为
    Mgmt 已经是一个布尔 `Series`。`True` 值和 `False` 值已经表明 pandas 应该保留还是丢弃一行。因此，我们可以将 `Mgmt`
    列本身放入方括号中：
- en: '[PRE27]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We can also use arithmetic operands to filter columns based on mathematical
    conditions. The next example generates a Boolean `Series` for Salary values greater
    than $100,000 (see chapter 2 for more on this syntax):'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以使用算术运算符根据数学条件来过滤列。以下示例生成一个布尔 `Series`，用于筛选薪资值大于 $100,000 的记录（有关此语法的更多信息，请参阅第
    2 章）：
- en: '[PRE28]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Let’s see which employees earn a salary above $100,000:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看哪些员工的薪资超过 $100,000：
- en: '[PRE29]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Try practicing the syntax on some of the other columns in `employees`. As long
    as you provide a Boolean `Series`, pandas will be able to filter the `DataFrame`.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试在 `employees` 的其他列上练习语法。只要提供布尔 `Series`，pandas 就能够过滤 `DataFrame`。
- en: 5.3 Filtering by multiple conditions
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 多条件过滤
- en: We can filter a `DataFrame` with multiple conditions by creating two independent
    Boolean `Series` and then declaring the logical criterion that pandas should apply
    between them.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过创建两个独立的布尔 `Series` 并声明 pandas 应在它们之间应用的逻辑标准来使用多个条件过滤 `DataFrame`。
- en: 5.3.1 The AND condition
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.1 AND 条件
- en: 'Suppose that we want to find all female employees who work on the business
    development team. Now pandas must look for two conditions to select a row: a value
    of `"Female"` in the Gender column and a value of `"Business` `Dev"` in the Team
    column. The two criteria are independent, but both must be met. Here’s a quick
    reminder of how `AND` logic works with two conditions:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要找到所有在业务发展团队工作的女性员工。现在 pandas 必须查找两个条件来选择行：性别列中的值为 `"Female"`，团队列中的值为 `"Business
    Dev"`。这两个标准是独立的，但都必须满足。以下是一个关于如何使用 `AND` 逻辑与两个条件快速提醒的例子：
- en: '| Condition 1 | Condition 2 | Evaluation |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 条件 1 | 条件 2 | 评估 |'
- en: '| `True` | `True` | `True` |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| `True` | `True` | `True` |'
- en: '| `True` | `False` | `False` |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| `True` | `False` | `False` |'
- en: '| `False` | `True` | `False` |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| `False` | `True` | `False` |'
- en: '| `False` | `False` | `False` |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| `False` | `False` | `False` |'
- en: 'Let’s construct one Boolean `Series` at a time. We can begin by isolating the
    `"Female"` values in the Gender column:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一次构建一个布尔 `Series`。我们可以从隔离性别列中的 `"Female"` 值开始：
- en: '[PRE30]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Next, we’ll target all employees who work on the `"Business Dev"` team:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将针对所有在 `"Business Dev"` 团队工作的员工：
- en: '[PRE31]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Finally, we need to calculate the intersection of the two `Series`, the rows
    in which both the `is_female` and `in_biz_dev` `Series` have `True` values. Pass
    both Series into the square brackets, and place an ampersand symbol (`&`) between
    them. The ampersand declares an `AND` logical criterion. The `is_female` `Series`
    must have `True` *and* the `in_biz_dev` `Series` must have `True`:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要计算两个 `Series` 的交集，即 `is_female` 和 `in_biz_dev` `Series` 都有 `True` 值的行。将两个
    `Series` 都放入方括号中，并在它们之间放置一个 `&` 符号。`&` 符号声明了一个 `AND` 逻辑标准。`is_female` `Series`
    必须为 `True`，并且 `in_biz_dev` `Series` 也必须为 `True`：
- en: '[PRE32]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We can include any amount of `Series` within the square brackets as long as
    we separate every subsequent two with a `&` symbol. The next example adds a third
    criterion to identify the female managers on the business development team:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 只要我们用`&`符号分隔连续的两个`Series`，我们就可以在方括号内包含任意数量的`Series`。以下示例添加了一个第三个标准来识别业务发展团队的女性经理：
- en: '[PRE33]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: In summary, the `&` symbol selects rows that fit all conditions. Declare two
    or more Boolean `Series` and then use the ampersand to weave them together.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，`&`符号选择符合所有条件的行。声明两个或多个布尔`Series`，然后使用`&`符号将它们编织在一起。
- en: 5.3.2 The OR condition
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.2 OR 条件
- en: 'We can also extract rows if they fit one of several conditions. Not all conditions
    have to be true, but at least one does. Here’s a quick reminder of how `OR` logic
    works with two conditions:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以提取符合几个条件之一的行。并非所有条件都必须为真，但至少有一个条件必须满足。以下是一个关于如何使用两个条件进行`OR`逻辑的快速提醒：
- en: '| Condition 1 | Condition 2 | Evaluation |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 条件 1 | 条件 2 | 评估 |'
- en: '| `True` | `True` | `True` |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| `True` | `True` | `True` |'
- en: '| `True` | `False` | `True` |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| `True` | `False` | `True` |'
- en: '| `False` | `True` | `True` |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| `False` | `True` | `True` |'
- en: '| `False` | `False` | `False` |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| `False` | `False` | `False` |'
- en: 'Suppose that we want to identify all employees with a Salary below $40,000
    or a Start Date after January 1, 2015\. We can use mathematical operators such
    as < and > to arrive at two separate Boolean `Series` for these conditions:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要识别所有薪资低于4万美元或开始日期在2015年1月1日之后的员工。我们可以使用数学运算符如<和>来得到这两个条件的两个单独的布尔`Series`：
- en: '[PRE34]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We use a pipe symbol ( `|` ) between Boolean `Series` to declare `OR` criteria.
    The next example selects the rows in which either of the Boolean `Series` holds
    a `True` value:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在布尔`Series`之间使用管道符号（`|`）来声明`OR`标准。在下一个示例中，我们选择任一布尔`Series`持有`True`值的行：
- en: '[PRE35]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The rows at index positions 958, 964, 989, and 1000 fit the Salary condition,
    and the row at index 967 fits the Start Date condition. Pandas will also include
    rows that fit both conditions.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 索引位置958、964、989和1000的行符合薪资条件，索引位置967的行符合开始日期条件。Pandas还会包括符合这两个条件的行。
- en: 5.3.3 Inversion with ~
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.3 使用 ~ 进行反转
- en: 'The tilde symbol (`~`) inverts the values in a Boolean `Series`. All `True`
    values become `False`, and all `False` values become `True`. Here’s a simple example
    with a small `Series`:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 波浪线符号（`~`）反转布尔`Series`中的值。所有`True`值变为`False`，所有`False`值变为`True`。以下是一个简单的示例，使用了一个小的`Series`：
- en: '[PRE36]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Inversion is helpful when we’d like to reverse a condition. Let’s say we want
    to identify employees with a Salary of less than $100,000\. We could use two approaches,
    the first of which is to write `employees["Salary"] < 100000`:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要反转一个条件时，反转非常有用。假设我们想要识别薪资低于10万美元的员工。我们可以使用两种方法，第一种是编写`employees["Salary"]
    < 100000`：
- en: '[PRE37]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Alternatively, we could invert the results set of employees earning more than
    or equal to $100,000\. The resulting `DataFrames` will be identical. In the next
    example, we wrap our greater-than operation inside a parenthesis. The syntax ensures
    that pandas generates the Boolean `Series` before inverting its values. In general,
    you should use parentheses whenever the order of evaluation may be unclear to
    pandas:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以反转收入超过或等于10万美元的员工的结果集。生成的`DataFrames`将是相同的。在下一个示例中，我们将大于操作放在括号内。这种语法确保pandas在反转其值之前生成布尔`Series`。一般来说，当评估顺序可能对pandas不清楚时，你应该使用括号：
- en: '[PRE38]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: TIP For complex extractions like this one, consider assigning the Boolean `Series`
    to a descriptive variable.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: TIP 对于像这样复杂的提取，考虑将布尔`Series`分配给一个描述性变量。
- en: 5.3.4 Methods for Booleans
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.4 布尔方法
- en: 'Pandas provides an alternative syntax for analysts who prefer methods over
    operators. The following table displays the method alternatives for equality,
    inequality, and other arithmetic operations:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas为喜欢方法而不是运算符的分析师提供了一个替代语法。以下表格显示了相等、不等式和其他算术运算的方法替代方案：
- en: '| Operation | Arithmetic syntax | Method syntax |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 操作 | 算术语法 | 方法语法 |'
- en: '| Equality | `employees["Team"] == "Marketing"` | `employees["Team"].eq("Marketing")`
    |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 相等 | `employees["Team"] == "Marketing"` | `employees["Team"].eq("Marketing")`
    |'
- en: '| Inequality | `employees["Team"] != "Marketing"` | `employees["Team"].ne("Marketing")`
    |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 不等式 | `employees["Team"] != "Marketing"` | `employees["Team"].ne("Marketing")`
    |'
- en: '| Less than | `employees["Salary"] < 100000` | `employees["Salary"].lt(100000)`
    |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| 小于 | `employees["Salary"] < 100000` | `employees["Salary"].lt(100000)` |'
- en: '| Less than or equal to | `employees["Salary"] <= 100000` | `employees["Salary"].le(100000)`
    |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| 小于或等于 | `employees["Salary"] <= 100000` | `employees["Salary"].le(100000)`
    |'
- en: '| Greater than | `employees["Salary"] > 100000` | `employees["Salary"].gt(100000)`
    |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 大于 | `employees["Salary"] > 100000` | `employees["Salary"].gt(100000)` |'
- en: '| Greater than or equal to | `employees["Salary"] >= 100000` | `employees["Salary"].ge(100000)`
    |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 大于等于 | `employees["Salary"] >= 100000` | `employees["Salary"].ge(100000)`
    |'
- en: The same rules apply regarding the use of `&` and `|` symbols for `AND`/`OR`
    logic.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 关于使用`&`和`|`符号进行`AND`/`OR`逻辑的规则同样适用。
- en: 5.4 Filtering by condition
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4 通过条件过滤
- en: Some filtering operations are more complex than simple equality or inequality
    checks. Luckily, pandas ships with many helper methods that generate Boolean Series
    for these types of extractions.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 一些过滤操作比简单的相等或不等式检查更复杂。幸运的是，pandas提供了许多辅助方法，这些方法为这些类型的提取生成布尔`Series`。
- en: 5.4.1 The isin method
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.1 `isin`方法
- en: 'What if we want to isolate the employees who belong to either the Sales, Legal,
    or Marketing team? We could provide three separate Boolean `Series` inside the
    square brackets and add the `|` symbol to declare `OR` criteria:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想隔离属于销售、法律或市场营销团队的员工呢？我们可以在方括号内提供三个单独的布尔`Series`，并添加`|`符号来声明`OR`条件：
- en: '[PRE39]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Although this solution works, it isn’t scalable. What if our next report asked
    for employees from 15 teams instead of three? Declaring a `Series` for each condition
    is laborious.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这个解决方案是可行的，但它并不具有可扩展性。如果我们的下一个报告要求从15个团队而不是三个团队中获取员工呢？为每个条件声明一个`Series`是费时的。
- en: 'A better solution is the `isin` method, which accepts an iterable of elements
    (list, tuple, `Series`, and so on) and returns a Boolean `Series`. `True` denotes
    that pandas found the row’s value among the iterable’s values, and `False` denotes
    that it did not. When we have the `Series`, we can use it to filter the `DataFrame`
    in the usual manner. The next example achieves the same result set:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更好的解决方案是`isin`方法，它接受一个元素的可迭代序列（列表、元组、`Series`等）并返回一个布尔`Series`。`True`表示pandas在可迭代序列的值中找到了行的值，而`False`表示没有找到。当我们有了`Series`，我们可以用它以通常的方式过滤`DataFrame`。下一个示例达到相同的结果集：
- en: '[PRE40]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: An optimal situation for using the `isin` method is when we do not know the
    comparison collection in advance, such as when it is generated dynamically.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`isin`方法的最佳情况是我们事先不知道比较集合，例如当它是动态生成的时候。
- en: 5.4.2 The between method
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.2 `between`方法
- en: 'When working with numbers or dates, we often want to extract values that fall
    within a range. Suppose that we want to identify all employees with a salary between
    $80,000 and $90,000\. We could create two Boolean `Series`, one to declare the
    lower bound and one to declare the upper bound. Then we could use the `&` operator
    to mandate that both conditions are `True`:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理数字或日期时，我们经常想要提取位于某个范围内的值。假设我们想要识别所有薪资在$80,000和$90,000之间的员工。我们可以创建两个布尔`Series`，一个用于声明下限，一个用于声明上限。然后我们可以使用`&`运算符强制两个条件都为`True`：
- en: '[PRE41]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'A slightly cleaner solution is to use a method called `between`, which accepts
    a lower bound and an upper bound; it returns a Boolean `Series` where `True` denotes
    that a row’s value falls between the specified interval. Note that the first argument,
    the lower bound, is inclusive, and the second argument, the upper bound, is exclusive.
    The following code returns the same `DataFrame` as the preceding code, filtering
    for salaries between $80,000 and $90,000:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 一个稍微更简洁的解决方案是使用一个名为`between`的方法，它接受一个下限和一个上限；它返回一个布尔`Series`，其中`True`表示行的值位于指定的区间内。请注意，第一个参数，即下限，是包含的，而第二个参数，即上限，是排除的。以下代码返回与前面代码相同的`DataFrame`，过滤出在$80,000和$90,000之间的薪资：
- en: '[PRE42]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The `between` method also works on columns of other data types. To filter datetimes,
    we can pass strings for the start and end dates of our time range. The keyword
    parameters for the first and second arguments of the method are `left` and `right`.
    Here, we find all employees who started with the company in the 1980s:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '`between`方法也适用于其他数据类型的列。要过滤日期时间，我们可以传递时间范围的起始和结束日期的字符串。该方法的第一个和第二个参数的关键字参数是`left`和`right`。在这里，我们找到所有在20世纪80年代开始与公司合作的员工：'
- en: '[PRE43]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'We can also apply the `between` method to string columns. Let’s extract all
    employees whose first names starts with the letter `"R"`. We’ll start with a capital
    `"R"` as our inclusive lower bound and go up to the noninclusive upper bound of
    `"S"`:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以将`between`方法应用于字符串列。让我们提取所有名字以字母`"R"`开头的员工。我们将以大写字母`"R"`作为包含的下限，并向上到非包含上限`"S"`：
- en: '[PRE44]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: As always, be mindful of case sensitivity when working with characters and strings.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 像往常一样，在处理字符和字符串时，请注意大小写敏感性。
- en: 5.4.3 The isnull and notnull methods
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.3 `isnull`和`notnull`方法
- en: 'The employees data set includes plenty of missing values. We can see a few
    missing values in our first five rows:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 员工数据集包含大量的缺失值。我们可以在前五行中看到一些缺失值：
- en: '[PRE45]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Pandas marks missing text values and missing numeric values with a `NaN` (not
    a number) designation, and it marks missing datetime values with a `NaT` (not
    a time) designation. We can see an example in the Start Date column at index position
    2.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas用`NaN`（不是一个数字）标记缺失的文本值和缺失的数值，并用`NaT`（不是一个时间）标记缺失的日期时间值。我们可以在开始日期列的索引位置2看到一个示例。
- en: 'We can use several pandas methods to isolate rows with either null or present
    values in a given column. The `isnull` method returns a Boolean `Series` in which
    `True` denotes that a row’s value is missing:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用几个pandas方法来隔离给定列中具有null或现有值的行。`isnull`方法返回一个布尔`Series`，其中`True`表示某行的值缺失：
- en: '[PRE46]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Pandas considers the `NaT` and `None` values to be null as well. The next example
    invokes the `isnull` method on the Start Date column:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas将`NaT`和`None`值视为null。下一个示例在开始日期列上调用`isnull`方法：
- en: '[PRE47]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The `notnull` method returns the inverse `Series`, one in which `True` indicates
    that a row’s value is present. The following output communicates that indices
    0, 2, 3, and 4 do not have missing values:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '`notnull`方法返回其逆`Series`，其中`True`表示某行的值存在。以下输出表明索引0、2、3和4没有缺失值：'
- en: '[PRE48]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'We can produce the same result set by inverting the `Series` returned by the
    `isnull` method. As a reminder, we use the tilde symbol (`~`) to invert a Boolean
    `Series`:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过反转`isnull`方法返回的`Series`来产生相同的结果集。提醒一下，我们使用波浪符号（`~`）来反转布尔`Series`：
- en: '[PRE49]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Either approach works, but `notnull` is a bit more descriptive and thus is recommended.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 两种方法都有效，但`notnull`更具有描述性，因此推荐使用。
- en: 'As always, we can use these Boolean `Series` to extract specific `DataFrame`
    rows. Here, we extract all employees with a missing Team value:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 和往常一样，我们可以使用这些布尔`Series`来提取特定的`DataFrame`行。在这里，我们提取了所有缺少团队值的员工：
- en: '[PRE50]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The next example pulls out employees with a present First Name value:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个示例提取了具有现有姓氏值的员工：
- en: '[PRE51]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: The `isnull` and `notnull` methods are the best way to quickly filter for present
    and missing values in one or more rows.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '`isnull`和`notnull`方法是快速过滤一个或多个行中现有和缺失值的最优方式。'
- en: 5.4.4 Dealing with null values
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.4 处理null值
- en: While we’re on the topic of missing values, let’s discuss some options for dealing
    with them. In section 5.2, we learned how to use the `fillna` method to replace
    `NaNs` with a constant value. We could also remove them.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论缺失值的话题上，让我们讨论一些处理它们的方法。在5.2节中，我们学习了如何使用`fillna`方法用常数值替换`NaNs`。我们也可以删除它们。
- en: 'Let’s kick off this section by bringing our data set back to its original shape.
    We’ll reimport the CSV by using the `read_csv` function:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过将数据集恢复到其原始形状来开始本节。我们将使用`read_csv`函数重新导入CSV文件：
- en: '[PRE52]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Here’s a reminder of what it looks like:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个提醒，它看起来是这样的：
- en: '[PRE53]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The `dropna` method removes `DataFrame` rows that hold any `NaN` values. It
    doesn’t matter how many values a row is missing; the method excludes the row if
    a single `NaN` is present. The employees `DataFrame` has a missing value at index
    0 of the Salary column, index 1 of the Team column, index 2 of the Start Date
    column, and index 3 of the Gender column. Notice that pandas excludes all these
    rows in the following output:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '`dropna`方法删除包含任何`NaN`值的`DataFrame`行。一行缺失多少个值无关紧要；如果存在单个`NaN`，则方法会排除该行。员工`DataFrame`在薪资列的索引0、团队列的索引1、开始日期列的索引2和性别列的索引3处有缺失值。注意，pandas在以下输出中排除了所有这些行：'
- en: '[PRE54]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'We can pass the `how` parameter an argument of `"all"` to remove rows in which
    all values are missing. Only one row in the data set, the last one, satisfies
    this condition:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将`how`参数传递一个`"all"`的参数来删除所有值都缺失的行。数据集中只有最后一行满足这个条件：
- en: '[PRE55]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The `how` parameter’s default argument is `"any"`. An argument of `"any"` removes
    a row if any of its values is absent. Notice that the row at index label 995 has
    `NaN` in the Gender column of the preceding output. Compare that output with the
    following output, in which row 995 is not present; pandas still removes the last
    row because it has at least one `NaN` value:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '`how`参数的默认参数是`"any"`。一个`"any"`的参数会在某行的任何值缺失时删除该行。注意，在先前的输出中，索引标签995的性别列中有`NaN`。将此输出与以下输出进行比较，其中第995行不存在；pandas仍然删除了最后一行，因为它至少有一个`NaN`值：'
- en: '[PRE56]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'We can use the `subset` parameter to target rows with a missing value in a
    specific column. The next example removes rows that have a missing value in the
    Gender column:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `subset` 参数来针对具有特定列中缺失值的行。下一个示例删除性别列中具有缺失值的行：
- en: '[PRE57]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'We can also pass the `subset` parameter a list of columns. Pandas will remove
    a row if it has a missing value in any of the specified columns. The next example
    removes rows with missing values in the Start Date column, the Salary column,
    or both:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以将 `subset` 参数传递给列的列表。如果行在指定的任何列中具有缺失值，pandas 将删除该行。下一个示例删除具有缺失值的开始日期列、薪资列或两者的行：
- en: '[PRE58]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The `thresh` parameter specifies a minimum threshold of non-null values that
    a row must have for pandas to keep it. The next example filters `employees` for
    rows with at least four present values:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '`thresh` 参数指定一行必须具有的最小非空值阈值，以便 pandas 保留该行。下一个示例筛选 `employees` 以获取至少有四个现有值的行：'
- en: '[PRE59]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: The `thresh` parameter is great when a certain number of missing values renders
    a row useless for analysis.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 当一定数量的缺失值使行对分析无用时，`thresh` 参数非常出色。
- en: 5.5 Dealing with duplicates
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.5 处理重复项
- en: Missing values are a common occurrence in messy data sets, and so are duplicate
    values. Luckily, pandas includes several methods for identifying and excluding
    duplicate values.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失值在杂乱的数据集中很常见，重复值也是如此。幸运的是，pandas 包含了几个用于识别和排除重复值的方法。
- en: 5.5.1 The duplicated method
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5.1 重复项方法
- en: 'First up, here’s a quick reminder of the first five rows of the Team column.
    Notice that the value `"Finance"` appears at index positions 2 and 3:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，这是一个关于团队列前五行的快速提醒。注意，值 `"Finance"` 出现在索引位置 2 和 3：
- en: '[PRE60]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'The `duplicated` method returns a Boolean `Series` that identifies duplicates
    in a column. Pandas returns `True` any time it sees a value that it previously
    encountered in the `Series`. Consider the next example. The `duplicated` method
    marks the first occurrence of `"Finance"` in the Team column as a nonduplicate
    with `False`. It marks all subsequent occurrences of `"Finance"` as duplicates
    (with `True`). The same logic applies to all other Team values:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '`duplicated` 方法返回一个布尔 `Series`，用于识别列中的重复值。Pandas 在 `Series` 中遇到之前遇到的任何值时返回
    `True`。考虑下一个示例。`duplicated` 方法将团队列中 `"Finance"` 的第一次出现标记为非重复（`False`）。它将 `"Finance"`
    的所有后续出现标记为重复（`True`）。相同的逻辑适用于所有其他团队值：'
- en: '[PRE61]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'The `duplicated` method’s `keep` parameter informs pandas which duplicate occurrence
    to keep. Its default argument, `"first"`, keeps the first occurrence of each duplicate
    value. The following code is equivalent to the preceding code:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '`duplicated` 方法的 `keep` 参数告诉 pandas 保留哪个重复出现的值。它的默认参数 `"first"` 保留每个重复值的第一次出现。以下代码与前面的代码等价：'
- en: '[PRE62]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'We can also ask pandas to mark the last occurrence of a value in a column as
    the nonduplicate. Pass a string of `"last"` to the `keep` parameter:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以要求 pandas 将列中值的最后一次出现标记为非重复。将 `"last"` 字符串传递给 `keep` 参数：
- en: '[PRE63]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Let’s say we want to extract one employee from each team. One strategy we could
    use is pulling out the first row for each unique team in the Team column. Our
    existing `duplicated` method returns a Boolean `Series`; `True` identifies all
    duplicate values after the first encounter. If we invert that `Series`, we’ll
    get a `Series` in which `True` denotes the first time pandas encounters a value:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要从每个团队中提取一名员工。我们可以使用的策略是提取每个独特团队在团队列中的第一行。我们现有的 `duplicated` 方法返回一个布尔 `Series`；`True`
    识别第一次出现后的所有重复值。如果我们反转这个 `Series`，我们将得到一个 `Series`，其中 `True` 表示 pandas 首次遇到该值：
- en: '[PRE64]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Now we can extract one employee per team by passing the Boolean `Series` inside
    square brackets. Pandas will include the rows with the first occurrences of a
    value in the Team column. Note that the library considers `NaNs` to be a unique
    value:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以通过传递方括号内的布尔 `Series` 来按团队提取一名员工。Pandas 将包含具有团队列中值第一次出现的行。请注意，库将 `NaNs`
    视为唯一值：
- en: '[PRE65]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: This output tells us that Douglas is the first employee on the Marketing team
    in the data set, Thomas is the first one with a missing team, Maria is the first
    one on the Finance team, and so on.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 这个输出告诉我们，Douglas 是数据集中营销团队的第一个员工，Thomas 是第一个缺少团队的人，Maria 是财务团队的第一个员工，等等。
- en: 5.5.2 The drop_duplicates method
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5.2 删除重复项方法
- en: 'A `DataFrame`’s `drop_duplicates` method provides a convenient shortcut for
    accomplishing the operation in section 5.5.1\. By default, the method removes
    rows in which all values are equal to those in a previously encountered row. There
    are no `employees` rows in which all six row values are equal, so the method doesn’t
    accomplish much for us with a standard invocation:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '`DataFrame` 的 `drop_duplicates` 方法提供了一个方便的快捷方式来完成 5.5.1 节中的操作。默认情况下，该方法会删除所有值都等于之前遇到的一行中的值的行。没有所有六个行值都相等的
    `employees` 行，所以使用标准调用方法，该方法对我们来说并没有做什么：'
- en: '[PRE66]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'But we can pass the method a `subset` parameter with a list of columns that
    pandas should use to determine a row’s uniqueness. The next example finds the
    first occurrence of each unique value in the Team column. In other words, pandas
    keeps a row only if it has the first occurrence of a Team value (such as `"Marketing"`).
    It excludes all rows with duplicate Team values after the first one:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们可以向该方法传递一个 `subset` 参数，其中包含 pandas 应该用来确定行唯一性的列的列表。下一个示例找到 Team 列中每个唯一值的第一个出现。换句话说，pandas
    只保留具有 Team 值（例如 `"Marketing"`）的第一个出现的行。它排除了第一个之后具有重复 Team 值的所有行：
- en: '[PRE67]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The `drop_duplicates` method also accepts a `keep` parameter. We can pass it
    an argument of `"last"` to keep the rows with each duplicate value’s last occurrence.
    These rows are likely to be closer to the end of the data set. In the following
    example, Alice is the last employee in the data set on the HR team, Justin is
    the last employee on the Legal team, and so on:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '`drop_duplicates` 方法还接受一个 `keep` 参数。我们可以传递一个 `"last"` 参数来保留每个重复值的最后出现行。这些行可能更接近数据集的末尾。在下面的示例中，Alice
    是数据集中 HR 团队中的最后一名员工，Justin 是 Legal 团队中的最后一名员工，依此类推：'
- en: '[PRE68]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'One additional option is available for the `keep` parameter. We can pass an
    argument of `False` to exclude all rows with duplicate values. Pandas will reject
    a row if there are any other rows with the same value. The next example filters
    for rows in `employees` with a unique value in the First Name column. In other
    words, these first names occur only once in the `DataFrame`:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 `keep` 参数还有一个额外的选项。我们可以传递一个 `False` 参数来排除所有具有重复值的行。如果存在任何其他具有相同值的行，Pandas
    将拒绝该行。下一个示例筛选出 `employees` 中在 First Name 列中具有唯一值的行。换句话说，这些名字在 `DataFrame` 中只出现一次：
- en: '[PRE69]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Let’s say we want to identify duplicates by a combination of values across
    multiple columns. We may want the first occurrence of each employee with a unique
    combination of First Name and Gender in the data set, for example. For reference,
    here’s a subset of all employees with a First Name of `"Douglas"` and a Gender
    of `"Male"`:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要通过多个列的组合来识别重复项。我们可能想要找到数据集中具有唯一 First Name 和 Gender 组合的每个员工的第一个出现，例如。为了参考，这里是一个具有
    `"Douglas"` 名字和 `"Male"` 性别的所有员工的子集：
- en: '[PRE70]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'We can pass a list of columns to the `drop_duplicates` method’s `subset` parameter.
    Pandas will use the columns to determine the presence of duplicates. The next
    example uses a combination of values across the Gender and Team columns to identify
    duplicates:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将列的列表传递给 `drop_duplicates` 方法的 `subset` 参数。Pandas 将使用这些列来确定重复项的存在。下一个示例使用性别和
    Team 列中的值的组合来识别重复项：
- en: '[PRE71]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: Let’s walk through the output. The row at index 0 holds the first occurrence
    of the name `"Douglas"` and the gender `"Male"` in the employees data set. Pandas
    will exclude any other rows with the same two values from the results set. To
    clarify, the library will still include a row if it has a First Name of `"Douglas"`
    and a Gender not equal to `"Male"`. Similarly, it will include rows with Gender
    of `"Male"` and a First Name not equal to `"Douglas"`. Pandas uses the combination
    of values across the two columns to identify the duplicates.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们浏览一下输出。索引为 0 的行持有 employees 数据集中 `"Douglas"` 和 `"Male"` 性别的第一个出现。Pandas 将排除任何具有相同两个值的其他行。为了澄清，如果某行具有
    `"Douglas"` 名字和不同的 `"Male"` 性别，库仍然会包括该行。同样，它也会包括具有 `"Male"` 性别和不同的 `"Douglas"`
    名字的行。Pandas 使用两个列的值组合来识别重复项。
- en: 5.6 Coding challenge
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.6 编程挑战
- en: Here’s your chance to practice the concepts introduced in this chapter.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 这是您练习本章引入的概念的机会。
- en: 5.6.1 Problems
  id: totrans-227
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.6.1 问题
- en: 'The netflix.csv data set is a collection of almost 6,000 titles that were available
    to watch in November 2019 on the video streaming service Netflix. It includes
    four columns: the video’s title, director, the date Netflix added it, and its
    type/category. The director and date_added columns contain missing values. We
    can see examples at index positions 0, 2, and 5836 of the following output:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: netflix.csv数据集是Netflix视频流媒体服务在2019年11月可观看的近6,000个标题的集合。它包括四个列：视频的标题、导演、Netflix添加它的日期以及它的类型/类别。导演和date_added列包含缺失值。我们可以在以下输出的索引位置0、2和5836中看到示例：
- en: '[PRE72]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Using the skills you learned in this chapter, solve the following challenges:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 使用本章学到的技能，解决以下挑战：
- en: Optimize the data set for limited memory use and maximum utility.
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 优化数据集以减少内存使用并最大化实用性。
- en: Find all rows with a title of `"Limitless"`.
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查找所有标题为`"Limitless"`的行。
- en: Find all rows with a director of `"Robert Rodriguez"` and a type of `"Movie"`.
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查找所有导演为`"Robert Rodriguez"`且类型为`"Movie"`的行。
- en: Find all rows with either a date_added of `"2019-07-31"` or a director of `"Robert`
    `Altman"`.
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查找所有`date_added`值为`"2019-07-31"`或导演为`"Robert"` `Altman`的行。
- en: Find all rows with a director of `"Orson Welles"`, `"Aditya` `Kripalani"`, or
    "`Sam Raimi"`.
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查找所有导演为`"Orson Welles"`、`"Aditya"` `Kripalani`或`"`Sam Raimi"`的行。
- en: Find all rows with a date_added value between May 1, 2019 and June 1, 2019.
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查找所有`date_added`值在2019年5月1日至2019年6月1日之间的行。
- en: Drop all rows with a `NaN` value in the director column.
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除导演列中所有包含`NaN`值的行。
- en: Identify the days when Netflix added only one movie to its catalog.
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定Netflix在其目录中仅添加了一部电影的日子。
- en: 5.6.2 Solutions
  id: totrans-239
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.6.2 解决方案
- en: Let’s tackle the questions!
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们解决这些问题！
- en: 'To optimize the data set for memory and utility, we can first convert the date_
    added column’s values to datetimes. We can force the type coercion during the
    import with the `parse_dates` parameter to the `read_csv` function:'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了优化数据集以节省内存和提高实用性，我们首先可以将`date_added`列的值转换为日期时间格式。我们可以在导入时通过将`parse_dates`参数传递给`read_csv`函数来强制类型转换：
- en: '[PRE73]'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'It’s important to keep benchmarks, so let’s take a look at current memory use:'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 保持基准很重要，让我们看看当前的内存使用情况：
- en: '[PRE74]'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Can we convert any column’s values to a different data type? How about categorical
    values? Let’s use the `nunique` method to count the number of unique values per
    column:'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们能否将任何列的值转换为不同的数据类型？比如分类值？让我们使用`nunique`方法来计算每列的唯一值数量：
- en: '[PRE75]'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'The type column is a perfect candidate for categorical values. In a data set
    of 5,837 rows, it has only two unique values: `"Movie"` and `"TV Show"`. We can
    convert its values by using the `astype` method. Remember to overwrite the original
    `Series`:'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 类型列是分类值的完美候选者。在一个包含5,837行的数据集中，它只有两个唯一值：`"Movie"`和`"TV Show"`。我们可以使用`astype`方法转换其值。请记住覆盖原始`Series`：
- en: '[PRE76]'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'How much has the conversion to categorical data reduced our memory use? A whopping
    22%:'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将数据转换为分类数据后，我们的内存使用减少了多少？惊人的22%：
- en: '[PRE77]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'We’ll need to use the equality operator to compare each title column value
    with the string `"Limitless"`. Afterward, we can use the Boolean `Series` to extract
    rows from `netflix` for which the evaluation returns `True`:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要使用等号运算符来比较每个标题列的值与字符串`"Limitless"`。之后，我们可以使用布尔`Series`从`netflix`中提取返回`True`的行：
- en: '[PRE78]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'To extract movies directed by Robert Rodriguez, we’ll need two Boolean `Series`,
    one comparing the director column’s values with `"Robert Rodriguez"` and the other
    comparing the type column’s values with `"Movie"`. The `&` symbol applies `AND`
    logic for two Boolean `Series`:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了提取由Robert Rodriguez执导的电影，我们需要两个布尔`Series`，一个比较导演列的值与`"Robert Rodriguez"`，另一个比较类型列的值与`"Movie"`。`&`符号应用于两个布尔`Series`的`AND`逻辑：
- en: '[PRE79]'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'The next question asks all for all titles with a date_added of `"2019-07-31"`
    or a director of `"Robert Altman"`. This problem is similar to the preceding one
    but requires a `|` symbol for `OR` logic:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一个问题要求所有标题为`"2019-07-31"`或导演为`"Robert Altman"`的标题。这个问题与上一个问题类似，但需要`|`符号进行`OR`逻辑：
- en: '[PRE80]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'The next challenge asks for entries with a director of `"Orson Welles"`, `"Aditya`
    `Kripalani"`, or `"Sam` `Raimi"`. One option is to create three Boolean `Series`,
    one for each of the three directors, and then use the `|` operator. But a more
    concise and scalable way to generate the Boolean `Series` is to invoke the `isin`
    method on the director column and pass in the list of directors:'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一个挑战要求找到导演为`"Orson Welles"`、`"Aditya"` `Kripalani`或`"`Sam Raimi"`的条目。一个选项是创建三个布尔`Series`，每个导演一个，然后使用`|`运算符。但生成布尔`Series`的更简洁和可扩展的方法是在导演列上调用`isin`方法并传入导演列表：
- en: '[PRE81]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'The most concise way to find all rows with a date_added value between May 1,
    2019 and June 1, 2019, is to use the `between` method. We can provide the two
    dates as the lower and upper bounds. This approach eliminates the need for two
    separate Boolean `Series`:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要找到所有`date_added`值在2019年5月1日和2019年6月1日之间的行，最简洁的方法是使用`between`方法。我们可以提供这两个日期作为下限和上限。这种方法消除了需要两个单独的布尔`Series`的需求：
- en: '[PRE82]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: The `dropna` method removes `DataFrame` rows with missing values. We have to
    include the `subset` parameter to limit the columns in which pandas should look
    for null values. For this question, we’ll target `NaN` values in the director
    column`:`
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`dropna`方法删除具有缺失值的`DataFrame`行。我们必须包含`subset`参数以限制pandas应查找空值的列。对于这个问题，我们将针对导演列中的`NaN`值`:`。'
- en: '[PRE83]'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'The final challenge asks to identify the days when Netflix added only one movie
    to the service. One solution is to recognize that the date_added column holds
    duplicate date values for titles added on the same day. We can invoke the `drop_duplicates`
    method with a `subset` of date_added and the `keep` parameter set to `False`.
    Pandas will remove any rows with duplicate entries in the date_added column. The
    resulting `DataFrame` will have the titles that were the only ones added on their
    respective dates:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后的挑战要求识别Netflix仅在服务中添加一部电影的日子。一个解决方案是认识到`date_added`列包含同一日添加的标题的重复日期值。我们可以使用`drop_duplicates`方法，并设置`subset`为`date_added`以及`keep`参数为`False`。Pandas将删除`date_added`列中任何重复条目的行。结果`DataFrame`将包含在其各自日期上仅添加的标题：
- en: '[PRE84]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: Congratulations on completing the coding challenge!
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你完成了编码挑战！
- en: Summary
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: The `astype` method converts a `Series`’ values to another data type.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`astype`方法将`Series`的值转换为另一种数据类型。'
- en: The `category` data type is ideal when a `Series` has a small number of unique
    values.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当一个`Series`具有少量唯一值时，`category`数据类型是理想的。
- en: Pandas can extract subsets of data from a `DataFrame` based on one or more conditions.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pandas可以根据一个或多个条件从`DataFrame`中提取数据子集。
- en: Pass a Boolean `Series` inside square brackets to extract a subset of a `DataFrame`.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将一个布尔`Series`放在方括号内以提取`DataFrame`的子集。
- en: Use the equality, inequality, and mathematical operators to compare each `Series`
    entry with a constant value.
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用相等、不等和数学运算符将每个`Series`条目与一个常数值进行比较。
- en: The `&` symbol mandates that multiple conditions be met to extract a row.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`&`符号强制要求满足多个条件才能提取一行。'
- en: The `|` symbol mandates that either condition be met to extract a row.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`|`符号强制要求满足任一条件才能提取一行。'
- en: Helper methods such as `isnull`, `notnull`, `between`, and `duplicated` return
    Boolean `Series` that we can use to filter data sets.
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 像`isnull`、`notnull`、`between`和`duplicated`这样的辅助方法返回布尔`Series`，我们可以使用它们来过滤数据集。
- en: The `fillna` method replaces `NaNs` with a constant value.
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fillna`方法用常数值替换`NaNs`。'
- en: The `dropna` method removes rows with null values. We can customize its arguments
    to target missing values in all or some columns.
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dropna`方法删除具有空值的行。我们可以自定义其参数以针对所有或某些列中的缺失值。'
