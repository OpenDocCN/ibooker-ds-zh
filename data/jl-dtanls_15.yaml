- en: 13 Advanced transformations of data frames
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 13 数据框的高级转换
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Performing advanced transformations of data frames and grouped data frames
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行数据框和分组数据框的高级转换
- en: Chaining transformation operations to create data processing pipelines
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 链接转换操作以创建数据处理管道
- en: Sorting, joining, and reshaping data frames
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 排序、连接和重塑数据框
- en: Working with categorical data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理分类数据
- en: Evaluating classification models
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估分类模型
- en: 'In chapter 12, you learned how to perform basic transformations of data frames
    by using operation specification syntax with the combine function. In this chapter,
    you will learn more advanced scenarios for using this syntax, along with more
    functions that accept it: select, select!, transform, transform!, subset, and
    subset!. With these functions, you can conveniently perform any operation you
    need on columns. At the same time, these functions are optimized for speed, and
    optionally can use multiple threads to perform computations. As in chapter 12,
    I also show you how to specify these transformations by using the DataFramesMeta.jl
    domain-specific language.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在第12章中，你学习了如何通过使用组合函数的操作指定语法来执行数据框的基本转换。在本章中，你将学习更多使用此语法的复杂场景，以及更多接受此语法的函数：select、select!、transform、transform!、subset和subset!。使用这些函数，你可以方便地对列执行任何需要的操作。同时，这些函数针对速度进行了优化，并且可以选择使用多线程来执行计算。与第12章一样，我还将向你展示如何使用DataFramesMeta.jl领域特定语言来指定这些转换。
- en: 'In this chapter, you will also learn to combine multiple tables by using join
    operations. DataFrames.jl has an efficient implementation for all standard joins:
    inner joins, left and right joins, outer joins, semi and anti joins, and cross
    joins. Similarly, I will show you how to reshape data frames with the stack and
    unstack functions.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你还将学习如何通过使用连接操作来合并多个表。DataFrames.jl对所有标准连接都有高效的实现：内连接、左连接和右连接、外连接、半连接和反连接，以及交叉连接。同样，我将向你展示如何使用stack和unstack函数重塑数据框。
- en: The combination of advanced data transformation capabilities and support for
    joining and reshaping data frames makes DataFrames.jl a complete ecosystem for
    creating complex data analysis pipelines. Creating these pipelines is greatly
    simplified by the ability to chain multiple operations together. This can be achieved
    using the @chain macro that you will learn about in this chapter.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 高级数据转换能力与对连接和重塑数据框的支持相结合，使DataFrames.jl成为创建复杂数据分析管道的完整生态系统。通过能够将多个操作链接在一起，创建这些管道大大简化了。这可以通过本章中你将学习的@chain宏来实现。
- en: Additionally, you will learn to work with categorical data (known as *factors*
    by R users) by using the CategoricalArrays.jl package. This functionality is often
    needed when performing statistical analysis of data.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你还将学习如何使用CategoricalArrays.jl包来处理分类数据（R用户称之为*因子*）。在执行数据统计分析时，通常需要此功能。
- en: As usual in this book, I present all these concepts on a real-life data set.
    This time, we will use the Stanford Open Policing Project data, which is available
    under the Open Data Commons Attribution License. In this data set, each observation
    is one police stop, and it holds information about multiple features of the event.
    Our goal is to understand which features influence the probability that an arrest
    is made during a police stop in Owensboro, Kentucky. In the process, we will focus
    on performing feature engineering by using DataFrames.jl to prepare data that
    can be used to create a predictive model.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如本书惯例，我将所有这些概念都基于真实数据集进行展示。这次，我们将使用斯坦福开放警务项目数据，该数据集可在Open Data Commons Attribution
    License下获得。在这个数据集中，每个观测值代表一次警察拦截，并包含关于事件多个特征的信息。我们的目标是了解哪些特征会影响在肯塔基州奥文斯伯勒警察拦截期间被捕的概率。在这个过程中，我们将专注于使用DataFrames.jl进行特征工程，以准备可用于创建预测模型的可用数据。
- en: Since we are nearing the end of the book, expect the material in this chapter
    to be more advanced than in earlier chapters. The chapter covers many functionalities
    of DataFrames.jl, so it is relatively long. Therefore, in the descriptions, I
    concentrate on explaining new material.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们即将结束本书，因此预期本章的内容将比前几章更高级。本章涵盖了DataFrames.jl的许多功能，因此相对较长。因此，在描述中，我专注于解释新材料。
- en: 13.1 Getting and preprocessing the police stop data set
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.1 获取和预处理警察拦截数据集
- en: In this section, we’ll perform preparatory operations for our analysis. This
    material should be familiar to you from chapter 12, as the steps are the same
    (getting a ZIP archive from the web, checking its SHA, extracting a CSV file from
    the archive, and loading its contents to a data frame).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将执行分析前的准备工作。这些内容应该对您来说很熟悉，因为步骤是相同的（从网络上获取ZIP存档，检查其SHA，从存档中提取CSV文件，并将内容加载到数据框中），正如第12章所述。
- en: The difference is that I will show you how to pipe multiple operations by using
    the @chain macro. Creating pipelines combining several operations is a feature
    that many data scientists, especially those experienced with the %>% operator
    in R, enjoy and often use. At the end of this section, I’ll show you how to drop
    columns from a data frame in place by using the select! function.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '不同之处在于，我将向您展示如何使用@chain宏进行多个操作的管道。创建结合多个操作的管道是许多数据科学家，尤其是那些熟悉R中的%>%操作符的数据科学家所喜爱并经常使用的功能。在本节的末尾，我将向您展示如何使用select!函数就地删除数据框中的列。 '
- en: 13.1.1 Loading all required packages
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.1.1 加载所有必需的包
- en: 'A common practice in Julia is to start analysis by loading all packages we
    are going to use in our project. I’ve added comments for packages that we have
    not used yet in this book:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在Julia中，一个常见的做法是在分析开始时加载我们将在项目中使用的所有包。我为尚未在本书中使用的包添加了注释：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Package allowing you to work with categorical data (factors in R)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 包允许您处理分类数据（R中的因子）
- en: ❷ Package providing support for working with various statistical distributions
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 提供支持处理各种统计分布的包
- en: ❸ Package supplying functionalities for evaluation of classification models
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 提供用于评估分类模型功能的包
- en: 13.1.2 Introducing the @chain macro
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.1.2 介绍@chain宏
- en: The @chain macro provides functionality similar to the pipe (%>%) operator in
    R. We imported it in the preceding section by using the DataFramesMeta.jl package
    (which is originally provided by the Chain.jl package and re-exported by DataFramesMeta.jl).
    By using the @chain macro, you can conveniently perform multistep processing of
    your data.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '@chain宏提供了类似于R中的管道（%>%）操作符的功能。我们在上一节中通过使用DataFramesMeta.jl包（该包最初由Chain.jl包提供并由DataFramesMeta.jl重新导出）导入了它。通过使用@chain宏，您可以方便地执行数据的多步骤处理。'
- en: Basic rules for how the @chain macro works
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '@chain宏的工作基本规则'
- en: 'The @chain macro takes a starting value and a begin-end block of expressions,
    where typically one expression is one line of code. The basic rules of how this
    macro works are as follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '@chain宏接受一个起始值和一个表达式块的范围（通常一行代码对应一个表达式）。这个宏的基本工作规则如下：'
- en: By default, the result of the previous expression is used as the first argument
    in the current expression, and this argument is omitted when you specify the current
    expression.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认情况下，上一个表达式的结果用作当前表达式的第一个参数，并且当您指定当前表达式时，此参数被省略。
- en: As an exception, if at least one underscore (_) is present in the current expression,
    the first rule does not apply. Instead, every underscore is replaced with the
    result of the previous expression.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为例外，如果当前表达式中至少有一个下划线（_），则第一个规则不适用。相反，每个下划线都被替换为上一个表达式的结果。
- en: 'You can find a complete list of rules that the @chain macro follows at the
    Chain.jl GitHub page ([https://github.com/jkrumbiegel/Chain.jl](https://github.com/jkrumbiegel/Chain.jl)).
    The following are several code examples of its use. Start with the following expression:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在Chain.jl的GitHub页面（[https://github.com/jkrumbiegel/Chain.jl](https://github.com/jkrumbiegel/Chain.jl)）上找到@chain宏遵循的完整规则列表。以下是一些使用示例的代码。从以下表达式开始：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This can be equivalently written using the @chain macro as follows:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这也可以用@chain宏等价地写成如下：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In this example, the sum and sqrt functions take one argument, so we do not
    have to use the underscore to indicate placement of the previous expression’s
    result, and we can even drop the parentheses after the functions. The 1:8 start
    value is passed to the sum function, and then the result is passed to the sqrt
    function. Figure 13.1 illustrates this process. The var1 and var2 variable names
    are chosen only for illustrative purposes, as in practice, the @chain macro generates
    variable names that are guaranteed to not conflict with existing identifiers.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，sum和sqrt函数只接受一个参数，所以我们不需要使用下划线来指示上一个表达式结果的放置，我们甚至可以在函数后面省略括号。1:8的起始值传递给sum函数，然后结果传递给sqrt函数。图13.1说明了这个过程。var1和var2变量名仅用于说明目的，因为在实践中，@chain宏生成的变量名保证不会与现有标识符冲突。
- en: '![CH13_F01_Kaminski2](../Images/CH13_F01_Kaminski2.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![CH13_F01_Kaminski2](../Images/CH13_F01_Kaminski2.png)'
- en: Figure 13.1 In this @chain macro, each operation is a function taking one argument.
    Arrows show how each part of the macro call is rewritten using temporary variables.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.1在这个@chain宏中，每个操作都是一个接受一个参数的函数。箭头显示了如何使用临时变量重写宏调用的每个部分。
- en: 'If you wanted to use the _ explicitly, you could write our example code in
    the following way:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想显式使用下划线，您可以按以下方式编写我们的示例代码：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now let’s consider a more complex example:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们考虑一个更复杂的例子：
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This can be equivalently written as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以等价地写成以下形式：
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In this case, 1 is sent as the first argument to form the string(1, 2) call
    since the string(2) expression has no underscore. The result of this operation,
    which is a "12" string, is passed to the string(3, _) expression. Since in this
    expression the underscore is present, it is turned into string(3, "12") and produces
    "312" as its result. Figure 13.2 depicts this process.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，1作为第一个参数发送给string(1, 2)调用，因为string(2)表达式没有下划线。这个操作的结果，即一个"12"字符串，被传递给string(3,
    _)表达式。由于在这个表达式中下划线存在，它被转换为string(3, "12")并产生"312"作为其结果。图13.2描述了这一过程。
- en: '![CH13_F02_Kaminski2](../Images/CH13_F02_Kaminski2.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![CH13_F02_Kaminski2](../Images/CH13_F02_Kaminski2.png)'
- en: Figure 13.2 Evaluating the @chain macro when each operation is a function taking
    two arguments
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.2评估每个操作都是接受两个参数的函数的@chain宏
- en: 13.1.3 Getting the police stop data set
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.1.3 获取警察拦截数据集
- en: 'We are now ready to download, uncompress, and load to a data frame the police
    stop data from Owensboro, Kentucky. In the process, we will use the @chain macro,
    which you learned about in section 13.1.2:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备下载、解压缩并将肯塔基州奥文斯伯勒的警察拦截数据加载到数据框中。在这个过程中，我们将使用@chain宏，您在13.1.2节中了解过：
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ URL of the file we want to fetch
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 我们想要获取的文件URL
- en: ❷ Name of the file we want to save locally
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 我们想要保存到本地的文件名
- en: ❸ Fetches the file only if it is not present yet; true is printed if the file
    is already present
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 仅在文件不存在时获取文件；如果文件已存在，则打印true
- en: ❹ Checks if the file is indeed present
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 检查文件是否确实存在
- en: ❺ Makes sure that the content of the file is correct by checking its SHA-256
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 通过检查其SHA-256确保文件内容正确
- en: ❻ Opens the ZIP archive and visually inspects its contents
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 打开ZIP存档并检查其内容
- en: ❼ Extracts the CSV file from the archive and loads it into a DataFrame; treats
    NA values as missing by using the @chain macro
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 从存档中提取CSV文件并将其加载到DataFrame中；使用@chain宏将NA值视为缺失
- en: ❽ Closes the ZIP archive after we are done reading it
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 在我们完成读取后关闭ZIP存档
- en: 'In this example, the expression using the @chain macro is equivalent to the
    following line of code:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，使用@chain宏的表达式等同于以下代码行：
- en: '[PRE7]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In my opinion, the version using the @chain macro is easier to read and modify,
    if needed.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，使用@chain宏的版本更容易阅读和修改，如果需要的话。
- en: 'We have created the owensboro data frame. I have suppressed printing its contents
    because it is large. Instead, let’s get its summary information by using the summary
    and describe functions that we used in chapter 12:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经创建了owensboro数据框。我抑制了其内容的打印，因为它很大。相反，让我们使用在第12章中使用的summary和describe函数来获取其摘要信息：
- en: '[PRE8]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Our data set has almost 7,000 observations and 18 columns. I have presented
    the information about the number of unique values in text columns, the number
    of missing values recorded, and the element type of each column. In this chapter,
    we will not work with all columns of the data frame. Instead, we will concentrate
    on the following features:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据集有近7000个观测值和18列。我已经展示了关于文本列中唯一值的数量、记录的缺失值数量以及每列的元素类型的信息。在本章中，我们不会处理数据框的所有列。相反，我们将专注于以下特征：
- en: date—Gives information on when the event happened.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日期—提供事件发生的时间信息。
- en: type—Indicates who was stopped by the police (vehicle or pedestrian). This column
    has 42 missing observations.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类型—指示谁被警察拦截（车辆或行人）。这个列有42个缺失观测值。
- en: arrest_made—Shows whether an arrest was made. This will be our target column.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否逮捕—显示是否进行了逮捕。这将是我们目标列。
- en: violation—Provides a text description of the type of violation recorded.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 违规—提供记录的违规类型的文本描述。
- en: We will look in more detail at data contained in these columns in the following
    sections. First, we’ll drop the columns we do not need by using the select! function
    in the next listing.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几节中，我们将更详细地查看这些列中的数据。首先，我们将使用下一列表中的select!函数删除我们不需要的列。
- en: Listing 13.1 Dropping unwanted columns from the owensboro data frame in place
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 列表13.1：在owensboro数据框中就地删除不需要的列
- en: '[PRE9]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ Updates the data frame in place and keeps only the listed columns in it
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 就地更新数据框并仅保留其中列出的列
- en: 13.1.4 Comparing functions that perform operations on columns
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.1.4 比较执行列操作的函数
- en: 'In listing 13.1, we see the select! function, which is one of the five functions
    provided by DataFrames.jl for performing operations on data frame columns. You
    have already seen another, the combine function, in chapter 12, when working with
    GroupedDataFrame objects. Now, let’s look at all available functions:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表13.1中，我们看到select!函数，这是DataFrames.jl提供的五个用于在数据框列上执行操作的函数之一。您已经在第12章中看到另一个，即组合函数，当时您正在处理GroupedDataFrame对象。现在，让我们看看所有可用的函数：
- en: combine—Performs column transformations following operation specification syntax,
    allowing for changing the number of rows in the source (typically, combining multiple
    rows into one row—that is, aggregating them)
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: combine—按照操作指定语法执行列转换，允许更改源中的行数（通常，将多行合并为一行，即聚合它们）
- en: select—Performs column transformations following operation specification syntax
    with the restriction that the result will have the same number of rows and in
    the same order as the source
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: select—按照操作指定语法执行列转换，但结果将具有与源相同的行数和顺序
- en: select!—The same as select, but updates the source in place
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: select!—与select相同，但就地更新源
- en: transform—The same as select, but always keeps all columns from the source
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: transform—与select相同，但始终保留源中的所有列
- en: transform!—The same as transform, but updates the source in place
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: transform!—与transform相同，但就地更新源
- en: Since in listing 13.1 we use the select! function, it updates the owensboro
    data frame in place by keeping only the columns whose names we pass.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在列表13.1中我们使用了select!函数，它通过仅保留我们传递的列名来就地更新owensboro数据框。
- en: 'All the functions I have listed allow passing several operation specifications
    in one call, as shown in listing 13.1\. Also, all of them work with both data
    frames and grouped data frames. In the latter case, these functions process the
    data groupwise, as you learned in chapter 12 regarding combine. For select, select!,
    transform, and transform!, if they are applied to the GroupedDataFrame, the same
    rule applies: the result must have the same number of rows and in the same order
    as the source.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我列出的所有函数都允许在一个调用中传递多个操作指定，如列表13.1所示。此外，它们都与数据框和分组数据框一起工作。在后一种情况下，这些函数按组处理数据，正如您在第12章中关于组合所学的。对于select、select!、transform和transform!，如果它们应用于GroupedDataFrame，则适用相同的规则：结果必须具有与源相同的行数和顺序。
- en: The following listing compares combine and transform on a minimal example. Figures
    13.3 and 13.4 also illustrate these functions, since the differences between the
    options are important to remember.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表比较了组合和转换在最小示例上的应用。图13.3和13.4也展示了这些函数，因为选项之间的差异很重要需要记住。
- en: '![CH13_F03_Kaminski2](../Images/CH13_F03_Kaminski2.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![CH13_F03_Kaminski2](../Images/CH13_F03_Kaminski2.png)'
- en: Figure 13.3 Result of performing the :v => sum => :sum operation on a data frame
    using the combine, transform, and select functions. The transform function is
    the only one that always keeps all columns from the source. The combine function
    is the only one that allows for changing the number of rows of its result in comparison
    to the source data frame.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.3：使用组合、转换和选择函数在数据框上执行:v => sum => :sum操作的结果。转换函数是唯一一个始终保留源中所有列的函数。组合函数是唯一一个允许更改其结果行数与源数据框相比的函数。
- en: '![CH13_F04_Kaminski2](../Images/CH13_F04_Kaminski2.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![CH13_F04_Kaminski2](../Images/CH13_F04_Kaminski2.png)'
- en: Figure 13.4 Result of performing the :v => sum => :sum operation on a grouped
    data frame using the combine, transform, and select functions. The transform function
    is the only one that always keeps all columns from the source. The combine function
    is the only one that allows for changing the number and order of rows of its result
    in comparison to the source data frame.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.4：使用组合、转换和选择函数在分组数据框上执行:v => sum => :sum操作的结果。转换函数是唯一一个始终保留源中所有列的函数。组合函数是唯一一个允许更改其结果行数和顺序与源数据框相比的函数。
- en: Listing 13.2 Comparing the combine, select, and transform operations
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 列表13.2：比较组合、选择和转换操作
- en: '[PRE10]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ❶ Rows of df are combined into a single value 10, which is a sum of column v.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ df的行合并成一个单一值10，这是列v的总和。
- en: ❷ transform keeps columns from the source. As all rows from the source are kept,
    value 10 is pseudo broadcasted to all rows (see chapter 10 for an explanation
    of pseudo broadcasting).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ transform 保留源数据框的列。由于保留了源数据框的所有行，值 10 被伪广播到所有行（参见第 10 章中对伪广播的解释）。
- en: ❸ Same as transform, but the columns from the source data frame df are not kept
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 与转换相同，但源数据框 df 的列不会被保留
- en: ❹ sum is applied groupwise. Rows per group are combined so a single value per
    group is produced; results are stored in the order of groups.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ sum 是按组应用。每个组的行合并，因此每个组产生一个值；结果按组顺序存储。
- en: ❺ sum is applied groupwise; transform keeps columns from the source. As all
    rows from the source are kept in the original order, values 4 and 6 are pseudo
    broadcasted to rows corresponding to groups.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ sum 是按组应用；transform 保留源数据框的列。由于源数据框的所有行都按原始顺序保留，值 4 和 6 被伪广播到对应于组的行。
- en: ❻ Same as transform, but the v column is not kept. The id column is kept, as
    this is the column by which we are grouping data.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 与转换相同，但 v 列不会被保留。id 列被保留，因为这是我们按此列分组数据。
- en: In summary, the most important thing to understand about the way transform and
    select work in listing 13.2 is that they guarantee that all rows from the source
    data frame df are kept in the result and that their order is not changed. If an
    operation returns a scalar, it is pseudo broadcasted to fill all required rows
    (see chapter 10 for an explanation of pseudo broadcasting). The difference between
    select and transform is that the latter keeps all columns from the source data
    frame.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，关于列表 13.2 中 transform 和 select 的工作方式，最重要的是它们保证源数据框 df 的所有行都保留在结果中，并且它们的顺序没有改变。如果一个操作返回一个标量，它将被伪广播以填充所有所需的行（参见第
    10 章中对伪广播的解释）。select 和 transform 的区别在于后者保留源数据框的所有列。
- en: 13.1.5 Using short forms of operation specification syntax
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.1.5 使用操作规范语法的简写形式
- en: 'Another thing to notice in listing 13.1 is that when we use the select! function,
    we pass only column names we want to keep. In chapter 12, you learned that the
    operation specification syntax uses this general pattern: source_column => operation_
    function => target_column_name.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表 13.1 中需要注意的另一件事是，当我们使用 select! 函数时，我们只传递我们想要保留的列名。在第 12 章中，你学习了操作规范语法使用以下通用模式：source_column
    => operation_function => target_column_name。
- en: Using this syntax, you might think that to keep the :date column without changing
    its name in listing 13.1, you would need to write :date => identity => :date.
    But this is not needed, as the operation_function and target_column_name parts
    are optional in the operation specification syntax. The following listing, which
    uses the df data frame defined in listing 13.2, shows the consequences of dropping
    the second and third components of operation specification syntax.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种语法，你可能认为为了在列表 13.1 中保留 :date 列而不更改其名称，你需要编写 :date => identity => :date。但实际上不需要这样做，因为在操作规范语法的操作函数和目标列名部分是可选的。以下列表，使用列表
    13.2 中定义的 df 数据框，展示了省略操作规范语法的第二和第三部分的结果。
- en: Listing 13.3 Short versions of operation specification syntax
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.3 操作规范语法的简写版本
- en: '[PRE11]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ Full version of operation specification syntax
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 操作规范语法的完整版本
- en: ❷ Version with dropped target_column_name; in this case, the target column name
    is autogenerated and is v_identity.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 省略目标列名的版本；在这种情况下，目标列名是自动生成的，名为 v_identity。
- en: ❸ Version with dropped operation_function; in this case, the operation is column
    renaming.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 省略操作函数的版本；在这种情况下，操作是列重命名。
- en: ❹ Version with dropped operation_function and target_column_name; in this case,
    the operation is storing the column in the target data frame under the same name
    as it was in the source.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 省略操作函数和目标列名的版本；在这种情况下，操作是在目标数据框中以与源相同的名称存储列。
- en: Here, all four operations produce the same output vector but give different
    names to the column. Observe that both the operation_function and target_column_
    name parts can be dropped in the operation specification syntax. Dropping operation_function
    is the same as asking to not perform any transformation of the column, and dropping
    target_column_name leads to automatic generation of the target column name.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，所有四个操作都产生相同的输出向量，但给列命名不同。注意，在操作规范语法的操作函数和目标列名部分都可以省略。省略操作函数等同于请求不对列进行任何转换，省略目标列名会导致自动生成目标列名。
- en: In listing 13.1, we dropped unwanted columns from the owensboro data frame.
    Let’s now move to transforming these columns.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表13.1中，我们从owensboro数据框中删除了不需要的列。现在让我们转向转换这些列。
- en: 13.2 Investigating the violation column
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.2 调查违规项
- en: We start by investigating the :violation column. It is a text column, so we
    need to perform text processing to understand its contents. In this section, you
    will learn how to do that. Analyzing the contents of data frame columns storing
    text data is a common operation, so practicing these operations is worthwhile.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先调查的是：违规项。它是一个文本列，因此我们需要进行文本处理来理解其内容。在本节中，你将学习如何进行这些操作。分析存储文本数据的DataFrame列的内容是一个常见的操作，因此练习这些操作是值得的。
- en: 13.2.1 Finding the most frequent violations
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.2.1 寻找最常见的违规行为
- en: 'First, take a quick peek at the contents of the :violation column:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，快速查看：违规项的内容：
- en: '[PRE12]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We can see that the violation types are codified using standard text, and if
    multiple violations happen, their descriptions are separated by a semicolon (;).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，违规类型使用标准文本进行编码，如果发生多个违规，它们的描述由分号 (;) 分隔。
- en: To structure this data, we want to extract from this column the indicators of
    violations that are encountered most frequently. In this analysis, we will additionally
    aggregate all speeding violations into one type since we can see that they differ
    only in number of miles per hour (mph) over the speed limit.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 为了结构化这些数据，我们希望从该列中提取最常见的违规行为的指标。在本分析中，我们还将所有超速违规行为聚合为一种类型，因为我们看到它们仅在超过速度限制的每小时英里数（mph）上有所不同。
- en: To achieve this goal, we first need to learn the types of the most frequent
    violations, following the steps in table 13.1.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一目标，我们首先需要学习最常见的违规行为的类型，按照表13.1中的步骤进行。
- en: Table 13.1 Steps taken to find the most frequent violations
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 表13.1 寻找最常见的违规行为所采取的步骤
- en: '| # | Step description | Simplified example output |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| # | 步骤描述 | 简化示例输出 |'
- en: '|  | Input data. | ["a1; b;c ","b; a2","a3"] |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '|  | 输入数据。 | ["a1; b;c ","b; a2","a3"] |'
- en: '| 1 | Split each observation by using ; as a delimiter, and strip leading and
    trailing whitespace characters. | [["a1","b","c"],["b","a2"],["a3"]] |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 使用 ; 作为分隔符拆分每个观测，并去除前导和尾随空格字符。 | [["a1","b","c"],["b","a2"],["a3"]] |'
- en: '| 2 | Vertically concatenate all individual observation vectors into a single
    vector. | ["a1","b","c","b","a2","a3"] |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 将所有单个观测向量垂直连接成一个向量。 | ["a1","b","c","b","a2","a3"] |'
- en: '| 3 | Change all elements containing the substring "a" into a string "a" (for
    actual data, this string is "SPEEDING"). | ["a","b","c","b","a","a"] |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 将包含子串 "a" 的所有元素更改为字符串 "a"（对于实际数据，此字符串是 "SPEEDING"）。 | ["a","b","c","b","a","a"]
    |'
- en: '| 4 | Count occurrences of different strings in the vector and present them
    sorted by frequency in descending order. | "a" │ 3"b" │ 2"c" │ 1 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 在向量中计算不同字符串的出现的次数，并按频率降序呈现。 | "a" │ 3"b" │ 2"c" │ 1 |'
- en: The following listing shows an implementation of these steps without DataFrames.jl,
    using functions you learned in part 1.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表展示了不使用DataFrames.jl，使用你在第1部分学到的函数实现这些步骤的示例。
- en: Listing 13.4 Finding the most frequent violations by using Base Julia
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 列表13.4 使用Base Julia寻找最常见的违规行为
- en: '[PRE13]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ Splits each violation description into a vector and removes leading and trailing
    whitespace from it
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将每个违规描述拆分成一个向量，并从中去除前导和尾随空格
- en: ❷ Vertically concatenates all individual vectors into one vector by using the
    reduce function (see chapter 10 for a discussion of this function)
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用reduce函数（参见第10章关于此函数的讨论）将所有单个向量垂直连接成一个向量
- en: ❸ Replaces all violations that contain "SPEEDING" in their text with "SPEEDING"
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将包含文本中的 "SPEEDING" 的所有违规项替换为 "SPEEDING"
- en: ❹ Finds the counts of various violations and sorts them in descending order
    by using rev=true
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 使用rev=true按降序对各种违规行为的计数进行排序
- en: 'In the results, we see that the most frequent violations are as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在结果中，我们看到最常见的违规行为如下：
- en: Failure to wear seat belts
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未佩戴安全带
- en: No registration plates
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有车牌
- en: Failure to produce insurance card
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未出示保险卡
- en: Speeding
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超速
- en: Later, we will investigate how these violation types influence the probability
    of being arrested. In the analysis in listing 13.4, we used the contains function,
    which checks whether the string passed as its first argument contains the string
    passed as its second argument.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们将调查这些违规类型如何影响被捕的概率。在列表13.4的分析中，我们使用了contains函数，该函数检查传递给它的第一个字符串是否包含传递给它的第二个字符串。
- en: Now, let’s rewrite this code using DataFrames.jl and piping. The following listing
    presents the result. Again, we follow the steps described in table 13.1.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用 DataFrames.jl 和管道重写此代码。以下列表展示了结果。我们再次遵循表 13.1 中描述的步骤。
- en: Listing 13.5 Finding the most frequent violations by using DataFrames.jl
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.5 使用 DataFrames.jl 查找最频繁违规情况
- en: '[PRE14]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ❶ Splits each violation description into a vector, removes the leading and trailing
    whitespace from it, and stores the result in the :v column
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将每个违规描述拆分为一个向量，从中删除前导和尾随空格，并将结果存储在 :v 列中
- en: ❷ Flattens the :v column data frame to turn vectors contained in it into consecutive
    rows of a data frame
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将 :v 列的数据框展平，将其包含的向量转换为数据框的连续行
- en: ❸ Replaces all violations that contain "SPEEDING" in their text with "SPEEDING"
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将包含 "SPEEDING" 的所有违规替换为 "SPEEDING"
- en: ❹ Gets the number of rows in every group created, grouping the data by :v column,
    and stores it in the :count column
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 通过按 :v 列对数据进行分组，获取每个组中行数，并将其存储在 :count 列中
- en: ❺ Sorts violations in descending order by using rev=true
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 使用 rev=true 按降序对违规进行排序
- en: I selected this example to teach you more features of DataFrames.jl that I discuss
    in the following sections.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我选择这个例子来教你们更多关于 DataFrames.jl 的功能，这些功能我在接下来的章节中会讨论。
- en: 13.2.2 Vectorizing functions by using the ByRow wrapper
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.2.2 使用 ByRow 包装器向量化函数
- en: In listing 13.5, in selection operations, we use the ByRow wrapper around operation
    functions. For example, in ByRow(x -> strip.(split(x, ";"))), it is a wrapper
    around an anonymous function.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表 13.5 中，在选择操作中，我们使用操作函数的 ByRow 包装器。例如，在 ByRow(x -> strip.(split(x, ";")))
    中，它是一个匿名函数的包装器。
- en: 'The purpose of ByRow is simple: it turns a regular function into a vectorized
    one so that you can easily apply it to each element of a collection. In the case
    of DataFrames.jl, these elements are rows of data frame objects, hence the name.
    Here is a minimal example how ByRow works:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: ByRow 的目的是简单的：它将一个常规函数转换为一个向量化的函数，这样你就可以轻松地将其应用于集合中的每个元素。在 DataFrames.jl 的情况下，这些元素是数据框对象的行，因此得名。以下是一个
    ByRow 如何工作的最小示例：
- en: '[PRE15]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: ❶ sqrt works on scalars.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ sqrt 函数适用于标量。
- en: ❷ sqrt does not work on vectors.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ sqrt 函数不适用于向量。
- en: ❸ ByRow(sqrt) is a vectorized version of sqrt that works on vectors.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ ByRow(sqrt) 是一个适用于向量的 sqrt 的向量化版本。
- en: ❹ Creates a new callable object f that is vectorized
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 创建一个新的可调用对象 f，它是向量化的
- en: ❺ You can call f without writing a dot (.) after it to have a vectorized operation.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 你可以调用 f 而不需要在其后写一个点（.），以进行向量化操作。
- en: ByRow(sqrt)([4, 9, 16]) has the same effect as broadcasting sqrt.([4, 9, 16]).
    You might ask, then, why it is needed. Broadcasting requires a function call to
    be specified immediately, while ByRow(sqrt) creates a new callable object. Therefore,
    you can think of ByRow as a lazy signal that you want the function to be broadcasted
    later after you pass an argument to it. You can see this when we define the f
    callable object in our example.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ByRow(sqrt)([4, 9, 16]) 与广播 sqrt.([4, 9, 16]) 有相同的效果。那么，为什么还需要它呢？广播需要立即指定一个函数调用，而
    ByRow(sqrt) 创建了一个新的可调用对象。因此，你可以将 ByRow 视为一个懒信号，你希望在传递参数后稍后将其函数广播。你可以在我们示例中定义 f
    可调用对象时看到这一点。
- en: 13.2.3 Flattening data frames
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.2.3 展平数据框
- en: 'Listing 13.5 also introduced the flatten function. Its purpose is to expand
    a column storing vectors into multiple rows of a data frame. Here’s a minimal
    example:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.5 还介绍了 flatten 函数。其目的是将存储向量的列扩展为数据框的多个行。以下是一个最小示例：
- en: '[PRE16]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: In this code, we expand vectors stored in the v column into multiple rows of
    a data frame. The values stored in the id column get appropriately repeated.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在此代码中，我们将存储在 v 列中的向量扩展为数据框的多个行。存储在 id 列中的值会适当地重复。
- en: 13.2.4 Using convenience syntax to get the number of rows of a data frame
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.2.4 使用便利语法获取数据框的行数
- en: You might have been surprised by the nrow => :count operation specification
    syntax in the combine call in listing 13.5, as it does not match any rules of
    the operation specification syntax you have learned so far. This case is an exception.
    This is because asking for the number of rows in a data frame, or in each group
    of a data frame, is a common operation. Additionally, the result of this operation
    does not require passing a source column (it would be the same for every source
    column).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能对列表 13.5 中 combine 调用中的 nrow => :count 操作指定语法感到惊讶，因为它不符合你迄今为止所学的操作指定语法的任何规则。这种情况是一个例外。这是因为请求数据框中的行数，或在数据框的每个组中的行数，是一个常见的操作。此外，此操作的结果不需要传递源列（对于每个源列都会相同）。
- en: 'Therefore, to support this case with a simpler syntax, two special forms are
    allowed: just passing nrow or passing nrow => target_column_name. In the first
    case, the default :nrow column name is used; in the second, the user passes the
    name of the column where we want to store the data. Here is an example showing
    both variants of this syntax:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了支持这种用更简单的语法，允许两种特殊形式：只需传递 nrow 或传递 nrow => target_column_name。在第一种情况下，使用默认的
    :nrow 列名；在第二种情况下，用户传递我们想要存储数据的列的名称。以下是一个显示这种语法两种变体的示例：
- en: '[PRE17]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: In this example, the source data frame has five rows. In two of the rows, we
    have the value 1, and in three rows, we have the value 2 in the :id column. When
    passing nrow, we get the column named :nrow holding these numbers. Passing nrow
    => :rows produces the same values, but under the :rows column name.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，源数据框有五行。在两行中，我们有一个值 1，在三行中，:id 列中有值 2。当传递 nrow 时，我们得到名为 :nrow 的列，包含这些数字。传递
    nrow => :rows 产生相同的值，但列名为 :rows。
- en: 13.2.5 Sorting data frames
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.2.5 排序数据框
- en: 'Listing 13.5 uses the sort function to sort rows of a data frame. Since data
    frames can contain many columns, we pass a list of columns on which sorting should
    be performed (when passing multiple columns, sorting is performed lexicographically).
    Here are some examples of sorting a data frame:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.5 使用 sort 函数对数据框的行进行排序。由于数据框可以包含许多列，我们传递一个列列表，指定应该在这些列上执行排序（当传递多个列时，排序是按字典顺序进行的）。以下是一些对数据框进行排序的示例：
- en: '[PRE18]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ❶ Data frame is sorted in ascending order by column :b
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 数据框按列 :b 升序排序
- en: ❷ Data frame is sorted in ascending order by columns :a and :b lexicographically
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 数据框按列 :a 和 :b 的字典顺序升序排序
- en: 13.2.6 Using advanced functionalities of DataFramesMeta.jl
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.2.6 使用 DataFramesMeta.jl 的高级功能
- en: 'Listing 13.5 works but is a bit verbose because we need to use ByRow and anonymous
    functions. For simple transformations, in my opinion, using ByRow is quite convenient
    and readable. Here’s an example:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.5 可以工作，但有点冗长，因为我们需要使用 ByRow 和匿名函数。对于简单的转换，在我看来，使用 ByRow 非常方便且易于阅读。以下是一个示例：
- en: '[PRE19]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'However, in listing 13.5, we work with very long expressions. In these cases,
    it is often easier to use the DataFramesMeta.jl domain-specific language to perform
    transformations. Let’s rewrite the code from listing 13.5 using DataFramesMeta.jl
    to replace the select function calls:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在列表 13.5 中，我们处理了非常长的表达式。在这些情况下，使用 DataFramesMeta.jl 的领域特定语言进行转换通常更容易。让我们用
    DataFramesMeta.jl 重新编写列表 13.5 中的代码，以替换 select 函数调用：
- en: '[PRE20]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: ❶ The @rselect macro is defined in the DataFramesMeta.jl package.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ @rselect 宏定义在 DataFramesMeta.jl 包中。
- en: The code is much easier to read now. Visually distinguishing the DataFramesMeta.jl
    macros is easy, as they are prefixed with @. As discussed in chapter 12, DataFramesMeta.jl
    macros use the domain-specific language following the assignment syntax instead
    of the operation specification syntax supported by DataFrames.jl.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 代码现在更容易阅读了。由于 DataFramesMeta.jl 宏以 @. 为前缀，因此视觉上区分它们很容易。如第 12 章所述，DataFramesMeta.jl
    宏使用赋值语法之后的领域特定语言，而不是 DataFrames.jl 支持的操作规范语法。
- en: 'In this example, we see the @rselect macro from the DataFramesMeta.jl package.
    It is an equivalent of the select function, but the r in front of it signals that
    all operations should be performed by row, or in other words, wrapped with ByRow.
    In addition, the @select macro works like the select function on entire columns
    of a data frame. Let’s compare them by doing the same operation of computing a
    square root of a column in a data frame:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们看到了 DataFramesMeta.jl 包中的 @rselect 宏。它是 select 函数的等效，但前面的 r 表示所有操作都应该按行执行，换句话说，用
    ByRow 包装。此外，@select 宏在数据框的整个列上工作，就像 select 函数一样。让我们通过在数据框的列上计算平方根的相同操作来比较它们：
- en: '[PRE21]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: In this example, all code lines give an equivalent result. The difference between
    @rselect and @select is that in the latter, we need to add a dot (.) after the
    sqrt function.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，所有代码行都给出了等效的结果。@rselect 和 @select 之间的区别在于后者中，我们需要在 sqrt 函数后添加一个点（.）。
- en: Table 13.2 lists the relevant macros that DataFramesMeta.jl provides (you learned
    about @combine in chapter 12), mapped to DataFrames.jl functions.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 表 13.2 列出了 DataFramesMeta.jl 提供的相关宏（你已经在第 12 章中学习了 @combine），映射到 DataFrames.jl
    函数。
- en: Table 13.2 Mapping DataFramesMeta.jl macros to DataFrames.jl functions
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 表 13.2 将 DataFramesMeta.jl 宏映射到 DataFrames.jl 函数
- en: '| DataFramesMeta.jl | DataFrames.jl |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| DataFramesMeta.jl | DataFrames.jl |'
- en: '| @combine | combine |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| @combine | combine |'
- en: '| @select | select |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| @select | select |'
- en: '| @select! | select! |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| @select! | select! |'
- en: '| @transform | transform |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| @transform | transform |'
- en: '| @transform! | transform! |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| @transform! | transform! |'
- en: '| @rselect | select with automatic ByRow of operations |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| @rselect | select with automatic ByRow of operations |'
- en: '| @rselect! | select! with automatic ByRow of operations |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| @rselect! | select! with automatic ByRow of operations |'
- en: '| @rtransform | transform with automatic ByRow of operations |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| @rtransform | transform with automatic ByRow of operations |'
- en: '| @rtransform! | transform! with automatic ByRow of operations |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| @rtransform! | transform! with automatic ByRow of operations |'
- en: This list seems long but is relatively simple to learn. The basic functions
    you need to know are combine, select, and transform. When constructing a macro
    call name, just remember that you can append ! after the name to make the operation
    in place and place r in front of the name to make the operation automatically
    wrap all operations with ByRow (thus vectorizing them).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这个列表看起来很长，但相对容易学习。你需要了解的基本函数是 combine、select 和 transform。在构造宏调用名称时，只需记住你可以在名称后追加
    ! 以使操作就地执行，并在名称前放置 r 以使操作自动将所有操作用 ByRow 包装（从而向量化它们）。
- en: 13.3 Preparing data for making predictions
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.3 准备预测所需的数据
- en: In section 13.2, we extracted the most common violation types from the police
    stop data set. We are now ready to prepare data that we will use to predict the
    probability of arrest.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在 13.2 节中，我们从警察拦截数据集中提取了最常见的违规类型。我们现在准备使用的数据，以预测逮捕的概率。
- en: In this section, you will learn how to perform complex transformations of data
    frame objects, as well as how to join and reshape them. All these operations are
    often needed when you prepare data for modeling.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习如何执行数据框对象的复杂转换，以及如何将它们连接和重塑。所有这些操作在准备建模数据时通常都是必需的。
- en: 13.3.1 Performing initial transformation of the data
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.3.1 执行数据的初始转换
- en: 'To prepare data so that it can later be used to fit a model predicting the
    probability of arrest, we want to create a data frame with the following structure:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准备数据，以便以后可以用来拟合预测逮捕概率的模型，我们想要创建一个具有以下结构的数据框：
- en: One Boolean column called arrest that indicates whether an arrest was made.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个名为 arrest 的布尔列，指示是否进行了逮捕。
- en: One column named day, showing the day of the week on which the incident happened.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个名为 day 的列，显示事件发生的星期几。
- en: A column type informing us of whom was stopped by police.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个列类型，告诉我们谁被警察拦截。
- en: Four Boolean columns, v1, v2, v3, and v4, indicating the four most common reasons
    for being stopped by the police. I use short column names in this case to save
    horizontal space in the output.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 四个布尔列，v1、v2、v3 和 v4，指示被警察拦截的四个最常见原因。在这种情况下，我使用简短的列名以节省输出中的水平空间。
- en: The following listing shows the syntax of the transformation creating the requested
    data frame.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的列表展示了创建所需数据框的转换语法。
- en: Listing 13.6 Preparing data for making a prediction model
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.6 准备预测模型所需的数据
- en: '[PRE22]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: ❶ Column renaming
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 列重命名
- en: ❷ Extracts the day-of-week number by using the dayofweek function from the Dates
    module
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用 Dates 模块中的 dayofweek 函数提取星期几的数字
- en: ❸ Selects the column without transformation
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 选择未进行转换的列
- en: ❹ Generates a vector of four operation specifications programmatically
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 通过程序生成四个操作指定的向量
- en: 'The most important part of this code is the last one, which shows us that operation
    specifications can also be passed in vectors. In this example, the vector of operations
    is as follows:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 代码中最重要的一部分是最后一段，它展示了操作指定也可以作为向量传递。在这个例子中，操作向量如下：
- en: '[PRE23]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We can see that it performs a lookup in the violation column for the four most
    common violations that we identified in the agg_violation data frame. Next, the
    select function properly handles this object as a vector holding four operation
    specification requests.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到它在对 agg_violation 数据框中的四个最常见的违规行为进行查找。接下来，select 函数正确地处理了这个对象，将其作为一个包含四个操作指定请求的向量。
- en: 'Let’s see one more example of transformations generated programmatically. Assume
    that we want to extract minimum and maximum elements from the date and arrest_made
    columns in the owensboro data frame. We can express this operation as follows:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再看看一个通过程序生成的转换示例。假设我们想要从 owensboro 数据框中的日期和 arrest_made 列中提取最小和最大元素。我们可以将此操作表达如下：
- en: '[PRE24]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This works because we broadcast one row matrix with a column vector to specify
    the transformation (this kind of application of broadcasting is discussed in chapter
    5):'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 这之所以有效，是因为我们广播了一个行矩阵和一个列向量来指定转换（这种广播的应用在第五章中讨论过）：
- en: '[PRE25]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Additionally, as you can see in the output of the combine function, the autogenerated
    column names nicely describe the results of the performed operations.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，正如您在combine函数的输出中可以看到的，自动生成的列名很好地描述了执行的操作的结果。
- en: Exercise 13.1 Rewrite the code from listing 13.6 using the @rselect macro from
    DataFramesMeta.jl.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 练习13.1 使用DataFramesMeta.jl的@rselect宏重写列表13.6中的代码。
- en: Renaming a data frame’s columns
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 重命名数据框的列
- en: The operation specification syntax allows you to rename columns of a data frame
    by using the form :old_column_name => :new_column_name.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 操作指定语法允许您使用形式:old_column_name => :new_column_name重命名数据框的列。
- en: 'However, column renaming is needed quite often. Therefore, DataFrames.jl provides
    two functions that are dedicated to this task: rename and rename!. As usual, the
    difference between these two functions is that rename creates a new data frame,
    while rename! changes the passed data frame in place.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，列重命名非常常见。因此，DataFrames.jl提供了两个专门用于此任务的函数：rename和rename!。与往常一样，这两个函数之间的区别在于rename创建一个新的数据框，而rename!则就地更改传递的数据框。
- en: The basic syntax is the same as for operations specification—that is, writing
    rename(df, :old_column_name => :new_column_name) renames the column :old_column_name
    to :new_column_name without changing any other column names in the data frame
    df. These two functions support several other styles of column renaming; refer
    to the package documentation ([http://mng.bz/m2jW](http://mng.bz/m2jW)) to learn
    more about them.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 基本语法与操作指定相同，即写作rename(df, :old_column_name => :new_column_name)将列:old_column_name重命名为:new_column_name，而不会更改数据框df中的其他列名。这两个函数支持几种其他列重命名样式；请参阅包文档([http://mng.bz/m2jW](http://mng.bz/m2jW))以了解更多信息。
- en: As a rule, use rename when you want to only rename columns in a data frame.
    Use select when, apart from renaming columns, you also want to perform other manipulations
    on columns of the passed data frame.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，当您只想重命名数据框中的列时，请使用rename。当您除了重命名列之外，还想对传递的数据框的列执行其他操作时，请使用select。
- en: 13.3.2 Working with categorical data
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.3.2 处理分类数据
- en: This section covers working with categorical data by using the CategoricalArrays.jl
    package.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了使用CategoricalArrays.jl包处理分类数据。
- en: Now, in our owensboro2 data frame, we have the column day, which stores the
    day number, where Monday is 1, Tuesday is 2, . . . , and Sunday is 7\. It would
    be nice to use day names instead of numbers in our analysis. Additionally, we
    would like day names to be correctly ordered—that is, Monday should be seen as
    the first day, through Sunday, which should be seen as the last day. This means
    that we cannot store day names as strings, as Julia would then use alphabetical
    order when sorting our data (alphabetically, Friday is the first day name and
    Wednesday is the last).
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在我们的owensboro2数据框中，我们有一个名为day的列，它存储的是天数，其中星期一是1，星期二是2，……，星期天是7。在分析中使用天名而不是数字会更好。此外，我们希望天名能正确排序——也就是说，星期一应被视为第一天，通过星期天，应被视为最后一天。这意味着我们不能将天名作为字符串存储，因为Julia在排序我们的数据时会使用字母顺序（按字母顺序，星期五是第一个天名，星期三是最后的一个天名）。
- en: The functionality allowing us to specify a custom order for a predefined set
    of values is provided in other ecosystems by factors or categorical columns. It
    is also available in Julia and is provided by the CategoricalArrays.jl package.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 其他生态系统通过因子或分类列提供了允许我们为预定义值集指定自定义顺序的功能。在Julia中也有提供，由CategoricalArrays.jl包提供。
- en: Categorical values
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 分类值
- en: Categorical variables can be unordered (nominal variables) or ordered categories
    (ordinal variables).
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 分类变量可以是无序的（名义变量）或有序的分类（序数变量）。
- en: An example of a *nominal variable* is a color of a car that is one of several
    from a closed list, like blue, black, or green.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一种*名义变量*是一个汽车的颜色，它是从封闭列表中的几个颜色之一，如蓝色、黑色或绿色。
- en: 'An example of an *ordinal variable* is, for example, traditional academic grading
    in the United States: A+, A, A-, B+, B, B-, C+, C, C-, D+, D, D-, and F, with
    A+ being the highest and F being the lowest.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，美国传统的学术评级是一种*序数变量*，包括：A+、A、A-、B+、B、B-、C+、C、C-、D+、D、D-和F，其中A+为最高分，F为最低分。
- en: 'The CategoricalArrays.jl package provides support for working with categorical
    values in Julia. The four most important functions that this package defines and
    that you need to learn are as follows:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: CategoricalArrays.jl包为在Julia中处理分类值提供支持。您需要学习的这个包定义的四个最重要的函数如下：
- en: categorical—Creates arrays of categorical values
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: categorical—创建分类值数组
- en: levels—Checks levels of values stored in a categorical array
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: levels——检查存储在分类数组中的值级别
- en: levels!—Sets levels and their order in a categorical array
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: levels!——在分类数组中设置级别及其顺序
- en: isordered—Checks whether a categorical array is ordered (stores ordinal values)
    or unordered (stores nominal values)
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: isordered——检查一个分类数组是有序的（存储序数值）还是无序的（存储名义值）
- en: We will use these functions when creating a reference data frame that stores
    a mapping between the day number and day name, as shown in the following listing.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 当创建存储天数和天名之间映射的参考数据框时，我们将使用这些函数，如下所示。
- en: Listing 13.7 Creating a reference data frame of day-of-week names
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.7 创建一周中天名的参考数据框
- en: '[PRE26]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We first create a weekdays data frame storing a mapping between day number and
    day name. We create a column of day names by using the dayname function, which
    returns the text name of a given day number. Next, using the categorical function,
    we turn this column into a categorical one and make it ordered by passing the
    ordered=true keyword argument. Next, we check that the column is ordered and inspect
    its levels. As you can see, levels are ordered alphabetically by default. To fix
    this, we use the levels! function to set the order of days to be the same as the
    order of day numbers. This function takes a categorical array as a first argument
    and a vector containing new level ordering as a second argument.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先创建一个 weekdays 数据框，存储天数和天名之间的映射。我们通过使用 dayname 函数创建一个天名字段，该函数返回给定天数的文本名称。接下来，使用
    categorical 函数将此列转换为分类列，并通过传递 ordered=true 关键字参数使其有序。接下来，我们检查该列是否有序并检查其级别。如你所见，级别默认按字母顺序排序。为了解决这个问题，我们使用
    levels! 函数将天数的顺序设置为与天数顺序相同。该函数将分类数组作为第一个参数，将包含新级别排序的向量作为第二个参数。
- en: You might ask what the benefit is of using a categorical array for day names.
    One benefit is that in this way, we clearly signal to the user that the column
    contains a closed set of allowed values. However, another important benefit exists.
    Later, if we use functions that are sensitive to the order of values (for example,
    sort), they will respect the order that we have set for the categorical vector.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会问，使用分类数组来表示天名有什么好处。一个好处是，这样我们可以清楚地向用户表明该列包含一个封闭的允许值集合。然而，还存在另一个重要的好处。稍后，如果我们使用对值顺序敏感的函数（例如，排序），它们将尊重我们为分类向量设置的顺序。
- en: 13.3.3 Joining data frames
  id: totrans-235
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.3.3 数据框连接
- en: In this section, you will learn the functions from DataFrames.jl that allow
    you to join several data frames together.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习 DataFrames.jl 提供的函数，这些函数允许你将多个数据框连接在一起。
- en: 'We have a mapping of day numbers to categorical day names, but how do we put
    them in our owensboro2 data frame? This can be done by joining the owensboro2
    data frame with the weekdays data frame. In this case, we need to perform a left
    join that we want to execute in place—that is, we want to add the column to the
    owensboro2 data frame. The function that accomplishes this is leftjoin!, where
    we pass the on keyword argument specifying the column name on which the join should
    be performed (this is a column storing keys on which the join should be performed).
    In the result of the operation, the owensboro2 data frame has all the columns
    that we have put into it in listing 13.6 (that is, arrest, day, type, v1, v2,
    v3, and v4) and additionally has the dayname column added from the joined weekdays
    data frame:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个将天数映射到分类天名的映射，但如何将它们放入我们的 owensboro2 数据框中呢？这可以通过将 owensboro2 数据框与 weekdays
    数据框进行连接来实现。在这种情况下，我们需要执行一个左连接，我们希望在原地执行该操作——也就是说，我们希望将列添加到 owensboro2 数据框中。完成此操作的是
    leftjoin! 函数，我们通过传递 on 关键字参数指定执行连接的列名（这是一个存储执行连接时应使用的键的列）。在操作的结果中，owensboro2 数据框包含我们在
    13.6 列表中放入的所有列（即，arrest、day、type、v1、v2、v3 和 v4），并且还添加了从连接的 weekdays 数据框中添加的 dayname
    列：
- en: '[PRE27]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'In addition to leftjoin!, the most-often-used join functions provided by DataFrames.jl
    create a new data frame from passed source data frames. These functions are the
    following:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 leftjoin! 之外，DataFrames.jl 提供的最常用的连接函数会从传递的源数据框中创建一个新的数据框。这些函数如下所示：
- en: innerjoin—Includes rows with keys that match in all passed data frames
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: innerjoin——包含所有通过数据框传递的键匹配的行
- en: leftjoin—Includes all rows from the left data frame and matching rows from the
    right data frame
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: leftjoin——包含来自左侧数据框的所有行以及来自右侧数据框的匹配行
- en: rightjoin—Includes all rows from the right data frame and matching rows from
    the left data frame
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: rightjoin——包含来自右侧数据框的所有行以及来自左侧数据框的匹配行
- en: outerjoin—Includes rows with keys that appear in any of the passed data frames
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: outerjoin—包括任何传递的数据帧中出现的键的行
- en: You can find more information about available join functions along with available
    options in the DataFrames.jl manual ([http://mng.bz/wyz2](http://mng.bz/wyz2))
    and in the documentation of the relevant functions.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 DataFrames.jl 手册（[http://mng.bz/wyz2](http://mng.bz/wyz2)）以及相关函数的文档中找到有关可用连接函数及其选项的更多信息。
- en: Exercise 13.2 Write a select operation creating the owensboro2 data frame that
    immediately has the dayname column (without having to perform a join).
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 13.2 编写一个选择操作创建 owensboro2 数据帧，该数据帧立即具有 dayname 列（无需执行连接）。
- en: 13.3.4 Reshaping data frames
  id: totrans-246
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.3.4 重塑数据帧
- en: In this section, you will learn to reshape a data frame by using the stack and
    unstack functions. Before moving forward, let’s check in the next listing to see
    whether owensoboro2 has a correct mapping of day numbers to day names.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习如何使用 stack 和 unstack 函数来重塑数据帧。在继续之前，让我们查看下一个列表，以查看 owensoboro2 是否有正确的日期数字到日期名称的映射。
- en: Listing 13.8 Mapping day numbers to day names in long format
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.8 以长格式映射日期数字到日期名称
- en: '[PRE28]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This looks to be the case. Additionally, we can see that the smallest number
    of police stops happen on Sundays. Another way to check the mapping is to build
    a frequency table:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来情况确实如此。此外，我们可以看到，警察拦截次数最少的是星期日。检查映射的另一种方法是构建一个频率表：
- en: '[PRE29]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We can see that we only have values stored on a main diagonal. The frequency
    table we produce is a matrix. Since in this chapter we are working with data frames,
    you might ask if we can obtain a similar result using a data frame. Indeed, it
    is possible, using the unstack function, as the following listing shows.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，我们只存储在主对角线上的值。我们生成的频率表是一个矩阵。由于在本章中我们正在使用数据帧，你可能想知道我们是否可以使用数据帧获得类似的结果。确实，这是可能的，使用
    unstack 函数，如下所示。
- en: Listing 13.9 Mapping day numbers to day names in wide format
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.9 以宽格式映射日期数字到日期名称
- en: '[PRE30]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'As you can see, we get the same result, but this time as a data frame. The
    unstack function takes three positional arguments: the first is the data that
    should be used to specify row keys (dayname, in this case), the second is the
    column that should be used to specify column keys (day, in this case), and the
    third is the column that should be used to specify values for the row key-column
    key combinations (in this case, nrow). We additionally pass the fill=0 argument
    to signal that entries with missing combinations of keys should take this value
    (by default, it would be missing).'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们得到了相同的结果，但这次是以数据帧的形式。unstack 函数接受三个位置参数：第一个是要用于指定行键（在这种情况下为 dayname）的数据，第二个是要用于指定列键（在这种情况下为
    day）的列，第三个是要用于指定行键-列键组合的值的列（在这种情况下为 nrow）。我们另外传递了 fill=0 参数来指示具有缺失键组合的条目应取此值（默认情况下将是缺失）。
- en: Reshaping data frames
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 重塑数据帧
- en: 'Data analysis uses two approaches to representing data: wide and long ([www.statology.org/long-vs-wide-data/](https://www.statology.org/long-vs-wide-data/)).'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析使用两种方法来表示数据：宽格式和长格式（[www.statology.org/long-vs-wide-data/](https://www.statology.org/long-vs-wide-data/))）。
- en: For data stored in wide format, also called *unstacked*, it is assumed that
    each entity is represented as one row of data and that each attribute is a column
    of data. Listing 13.9 presents an example of such a mapping, where day names are
    treated as entities (each row represents one day name) and day numbers as attributes
    (represented by columns with names from 1 to 7).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 对于以宽格式存储的数据，也称为 *unstacked*，假设每个实体代表一行数据，每个属性代表一列数据。列表 13.9 展示了这样一个映射的例子，其中日期名称被视为实体（每一行代表一个日期名称），日期数字被视为属性（由名为
    1 到 7 的列表示）。
- en: For data in long format, also called *stacked*, a single row represents a mapping
    from an entity-attribute combination to a value assigned to it. Listing 13.8 presents
    an example of such a mapping, where entity names are stored in the dayname column,
    attribute names are stored in the day column, and values related to them are stored
    in the nrow column.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 对于长格式数据，也称为 *stacked*，一行代表从实体-属性组合到分配给它的值的映射。列表 13.8 展示了这样一个映射的例子，其中实体名称存储在
    dayname 列中，属性名称存储在 day 列中，与之相关的值存储在 nrow 列中。
- en: In DataFrames.jl, you can reshape data frames from wide to long format by using
    the stack function, and from long to wide format by using the unstack function.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在 DataFrames.jl 中，你可以通过使用 stack 函数将数据帧从宽格式转换为长格式，通过使用 unstack 函数从长格式转换为宽格式。
- en: A related operation is transposition of a data frame, which is supported with
    the permutedims function.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 相关操作是数据框的转置，这由permutedims函数支持。
- en: You can find examples of how these functions can be used in the package manual
    ([http://mng.bz/QnR1](http://mng.bz/QnR1)). For your reference, the following
    figure shows the relationship between the stack and unstack functions.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在包手册中找到这些函数的使用示例（[http://mng.bz/QnR1](http://mng.bz/QnR1)）。为了你的参考，以下图显示了stack和unstack函数之间的关系。
- en: '![CH13_F05_Kaminski2](../Images/CH13_F05_Kaminski2.png)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![CH13_F05_Kaminski2](../Images/CH13_F05_Kaminski2.png)'
- en: 'The stack function takes data in wide format and transforms it into long format.
    The [:a, :b] column selector indicates which columns should be transformed into
    variable-value pairs. The unstack function performs the reverse operation. We
    pass information to it: which columns should identify rows in an unstacked data
    frame (key, in our example), which column contains column names (variable, in
    our example), and which column contains the values to put in row-column combinations
    (value, in our example).'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: stack函数将宽格式数据转换为长格式。[:a, :b]列选择器表示哪些列应转换为变量-值对。unstack函数执行相反的操作。我们向它传递信息：哪些列应标识未展开数据框中的行（键，在我们的例子中），哪个列包含列名（变量，在我们的例子中），以及哪个列包含要放入行-列组合中的值（值，在我们的例子中）。
- en: 13.3.5 Dropping rows of a data frame that hold missing values
  id: totrans-265
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.3.5 删除包含缺失值的数据框的行
- en: 'The last step in data preparation for modeling is related to missing values.
    In listing 13.1, we can see that the type column has 42 missing elements. Assume
    we want to remove them from the owensboro2 data frame before the analysis. This
    can be done in place by using the dropmissing! function:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备建模的最后一步与缺失值有关。在列表13.1中，我们可以看到类型列有42个缺失元素。假设我们想在分析之前从owensboro2数据框中删除它们。这可以通过使用dropmissing!函数就地完成：
- en: '[PRE31]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: ❶ All element types do not have ? at their end, which signals that no columns
    contain missing data.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 所有元素类型在其末尾都没有?，这表示没有列包含缺失数据。
- en: The operation changes the data frame in place. If we wanted to create a new
    data frame with dropped missing values, we could use the dropmissing function.
    Note that now the data frame has 6,879 rows, which is 42 fewer than the original
    6,921 row count, as expected.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 该操作就地更改数据框。如果我们想创建一个新的数据框，其中包含删除的缺失值，我们可以使用dropmissing函数。注意，现在数据框有6,879行，比原始的6,921行减少了42行，正如预期的那样。
- en: Additionally, we can easily visually confirm that no columns hold missing data.
    If you look at listing 13.6, you can see that the element type of column type
    was String15?, and now it is String15. The question mark appended to the type
    signals that a column allows for missing values. Since it is now gone, this means
    that after the dropmissing! operation, our data frame has no missing values.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以轻松地通过视觉确认没有列包含缺失数据。如果你查看列表13.6，你可以看到列的类型元素是String15?，而现在它是String15。类型后面附加的问号表示该列允许缺失值。由于它现在已经消失了，这意味着在dropmissing!操作之后，我们的数据框没有缺失值。
- en: Exercise 13.3 To practice the operations you have learned in this section, prepare
    the following two analyses. First, calculate the probability of arrest per dayname
    column. Second, compute the probability of arrest again, but this time, per the
    dayname and type columns, and present the results in wide form, where dayname
    levels are rows and type values form columns.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 练习13.3 为了练习你在本节中学到的操作，准备以下两个分析。首先，计算每天的名字列的逮捕概率。其次，再次计算逮捕概率，但这次是按dayname和type列计算的，并以宽表形式呈现结果，其中dayname级别是行，type值是列。
- en: 'Before we move forward, let’s drop the day column from owensboro2, as we will
    not need it in further analyses:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续前进之前，让我们从owensboro2中删除day列，因为我们将在进一步的分析中不需要它：
- en: '[PRE32]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 13.4 Building a predictive model of arrest probability
  id: totrans-274
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.4 构建逮捕概率的预测模型
- en: In this section, we will build a predictive model of arrest probability. In
    comparison to methods presented in earlier chapters, we will use a more-advanced
    procedure. We will split the data randomly into training and test data sets to
    verify that our model is not overfitted ([www.ibm.com/cloud/learn/overfitting](https://www.ibm.com/cloud/learn/overfitting)).
    Learning how to do this with DataFrames.jl is useful, as ensuring that your model
    is not overfitted is a standard procedure in most data science workflows.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将构建一个逮捕概率的预测模型。与前面章节中介绍的方法相比，我们将使用更高级的流程。我们将随机将数据分成训练集和测试集，以验证我们的模型没有过拟合([www.ibm.com/cloud/learn/overfitting](https://www.ibm.com/cloud/learn/overfitting))。学习如何使用DataFrames.jl来完成这项工作是有用的，因为确保你的模型没有过拟合是大多数数据科学工作流程中的标准程序。
- en: 13.4.1 Splitting the data into train and test data sets
  id: totrans-276
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.4.1 将数据分成训练集和测试集
- en: We start by adding the indicator variable train, signaling whether a row of
    the owensboro2 data frame should go to a training or test data set. Assume we
    want to perform a 70/30 split between these sets.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先添加指示变量train，表示owensboro2数据框的某一行是否应该进入训练集或测试集。假设我们想要在这两个集合之间进行70/30的划分。
- en: Listing 13.10 Randomly generating the indicator column for our data
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 列表13.10 随机生成数据指示列
- en: '[PRE33]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: ❶ Sets the seed of a random number generator for reproducibility of our experiment
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 设置随机数生成器的种子，以确保实验的可重复性
- en: ❷ Draws random numbers from a Bernoulli distribution with a probability of success
    equal to 0.7
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 从成功概率为0.7的伯努利分布中抽取随机数
- en: We can see that in around 70% of cases, the train column has the value true,
    indicating that the row should go to the training data set. With the false value,
    the row goes to the test data set. When generating the train column, we sample
    the true and false values from the Bernoulli distribution ([http://mng.bz/Xaql](http://mng.bz/Xaql))
    with 0.7 probability of success. The Bernoulli type is defined in the Distributions.jl
    package. This package provides a wide range of distributions you might want to
    use in your code—both univariate (like Beta or Binomial) and multivariate (like
    Multinomial or Dirichlet). See the package documentation for details ([https://juliastats.org/Distributions.jl/stable/](https://juliastats.org/Distributions.jl/stable/)).
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，在大约70%的情况下，train列的值为true，表示该行应该进入训练数据集。当值为false时，该行进入测试数据集。在生成train列时，我们从伯努利分布([http://mng.bz/Xaql](http://mng.bz/Xaql))中以0.7的成功概率抽取true和false值。伯努利类型在Distributions.jl包中定义。这个包提供了你可能在代码中想要使用的广泛分布——包括单变量（如Beta或Binomial）和多变量（如Multinomial或Dirichlet）。有关详细信息，请参阅包文档([https://juliastats.org/Distributions.jl/stable/](https://juliastats.org/Distributions.jl/stable/))。
- en: The design of this package is highly composable. For example, if you want to
    draw a random sample from a distribution, you pass it as a first argument to the
    standard rand function. In listing 13.10, we have written rand(Bernoulli(0.7),
    nrow(owensboro2)) to sample from the Bernoulli distribution the same number of
    times as the number of rows in our owensboro2 data frame.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 该包的设计高度可组合。例如，如果你想从一个分布中抽取一个随机样本，你可以将其作为第一个参数传递给标准的rand函数。在列表13.10中，我们编写了rand(Bernoulli(0.7),
    nrow(owensboro2))来从伯努利分布中抽取与owensboro2数据框行数相同的次数。
- en: In the next listing, we create train and test data frames that contain rows
    of the owensboro2 data frame that have true and false values, respectively.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个列表中，我们创建了包含owensboro2数据框具有true和false值的行的train和测试数据框。
- en: Listing 13.11 Creating train and test data frames
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 列表13.11 创建训练和测试数据框
- en: '[PRE34]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Note that the train column in the train data frame contains only true values,
    and in the test data frame, it contains only false values. To perform row subsetting,
    this time we use the subset function that creates a new data frame based on passed
    conditions. As usual, its subset! equivalent operates in place. The subset function
    accepts operation specification syntax, just like combine or select. The only
    difference is that it requires forms that do not specify a target column name
    since we are not creating any columns, but subsetting rows. Also, naturally, the
    result of the operation must be Boolean, as we use it as a condition to subset
    rows.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，train 数据框中的 train 列只包含真实值，而在测试数据框中，它只包含假值。为了执行行子集操作，这次我们使用 subset 函数，该函数根据传递的条件创建一个新的数据框。像往常一样，它的
    subset! 等价函数在原地操作。subset 函数接受操作指定语法，就像 combine 或 select 一样。唯一的区别是它需要不指定目标列名的形式，因为我们不是创建任何列，而是在子集行。当然，操作的结果必须是布尔值，因为我们将其用作子集行的条件。
- en: 'As for other functions that accept operation specification syntax, DataFramesMeta.jl
    provides the @subset, @subset!, @rsubset, and @rsubset! convenience macros. Recall
    that the r prefix means that the passed operation should be performed by row,
    and the ! suffix means that we want to update the data frame in place instead
    of creating a new data frame. Let’s use the @rsubset macro to create the test
    data frame again as an exercise:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 对于接受操作指定语法的其他函数，DataFramesMeta.jl 提供了 @subset、@subset!、@rsubset 和 @rsubset!
    便利宏。回想一下，r 前缀意味着传递的操作应该按行执行，而 ! 后缀意味着我们想要原地更新数据框而不是创建一个新的数据框。让我们使用 @rsubset 宏再次创建测试数据框作为练习：
- en: '[PRE35]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Exercise 13.4 Create train and test data frames by using (a) data frame indexing
    syntax and (b) the groupby function.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 13.4 通过（a）数据框索引语法和（b）groupby 函数创建训练和测试数据框。
- en: 13.4.2 Fitting a logistic regression model
  id: totrans-291
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.4.2 拟合逻辑回归模型
- en: 'We are now ready to build our model. We will use the GLM.jl package that you
    learned about in earlier chapters. We will build the model by using the train
    data set and then compare its predictive power between the train and test data
    sets:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好构建我们的模型了。我们将使用在前面章节中介绍过的 GLM.jl 包。我们将通过使用训练数据集来构建模型，然后比较其在训练和测试数据集之间的预测能力：
- en: '[PRE36]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: From the model, we learn that the probability of arrest goes up the most on
    Sundays. If the type of stop is vehicular, the probability of arrest goes down.
    Also, for violation types v1, v2, v3, and v4, the probability of arrest goes down.
    This should be expected, as the violations are failure to wear seat belts, no
    registration plates, failure to produce proof of insurance, and speeding. None
    seems to be severe enough to typically lead to an arrest.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 从模型中，我们了解到逮捕的概率在星期日最高。如果拦截类型是车辆，逮捕的概率会下降。此外，对于违规类型 v1、v2、v3 和 v4，逮捕的概率也会下降。这是可以预料的，因为这些违规行为包括未系安全带、未注册车牌、未出示保险证明和超速。似乎没有哪一项违规行为足够严重，通常会导致逮捕。
- en: I would like to draw your attention to one property of the output that we have
    obtained. For the dayname variable, Monday is selected as the reference level
    (and thus is not present in the summary), and the remaining levels are properly
    ordered. This is possible because the dayname column is categorical, so the glm
    function respects the order of levels in this variable.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 我想引起您对我们所获得输出的一项特性的注意。对于 dayname 变量，星期一被选为参考水平（因此不在摘要中显示），其余水平被正确排序。这是可能的，因为
    dayname 列是分类的，所以 glm 函数尊重该变量中级别的顺序。
- en: 'Let’s now assess the predictive quality of our model. We start with storing
    its predictions in train and test data frames, respectively, using the predict
    function:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们评估我们模型的预测质量。我们首先使用 predict 函数将它的预测存储在 train 和 test 数据框中，分别：
- en: '[PRE37]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: ❶ By default, the predict function returns predictions for the data set that
    was used to build the model.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 默认情况下，predict 函数返回用于构建模型的那个数据集的预测结果。
- en: ❷ If you pass a data set as a second argument to the predict function, you get
    predictions for new data.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 如果你将数据集作为 predict 函数的第二个参数传递，你将得到对新数据的预测。
- en: 13.4.3 Evaluating the quality of a model’s predictions
  id: totrans-300
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.4.3 评估模型预测质量
- en: 'Let’s compare histograms of model predictions in groups defined by the value
    of the arrest column. We expect that the histograms will not overlap much, as
    this would indicate that the model is able to separate arrests from non-arrests
    relatively well:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较由逮捕列的值定义的组别中模型预测的直方图。我们预计直方图之间不会重叠太多，因为这表明模型能够相对较好地将逮捕和非逮捕区分开来：
- en: '[PRE38]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: We group the test data frame by the arrest column. Then, to produce histograms,
    we extract from this grouped data frame the first group that represents a false
    value of arrest, and next, a true value of arrest. If you would like to refresh
    your understanding of GroupedDataFrame indexing, you can find all the needed explanations
    in chapter 11.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 我们按逮捕列对测试数据框进行分组。然后，为了生成直方图，我们从这个分组数据框中提取代表逮捕值为假的第一个组，然后是逮捕值为真的第二个组。如果你想要刷新你对分组DataFrame索引的理解，你可以在第11章中找到所有需要的解释。
- en: For the first group, we use the histogram function. For the second, we use the
    histogram! function, which adds a second histogram to the same plot. Both histograms
    are plotted with 10 bins, and the presented values are probabilities of these
    bins. With the fillalpha=0.5 keyword argument, we make the second histogram transparent.
    The fillstyle=:/ keyword argument adds lines to the first histogram so that it
    can be easily distinguished when printed in black and white. Figure 13.5 shows
    the result of our operation.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一组，我们使用直方图函数。对于第二组，我们使用直方图!函数，它将第二个直方图添加到同一图表中。两个直方图都使用10个区间进行绘制，所呈现的值是这些区间的概率。通过fillalpha=0.5关键字参数，我们使第二个直方图变得透明。fillstyle=:/关键字参数为第一个直方图添加线条，以便在黑白打印时易于区分。图13.5显示了我们的操作结果。
- en: Figure 13.5 confirms that if arrest is false, predictions are low, while if
    it is true, predictions are high.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.5确认了如果逮捕为假，预测值较低，而如果为真，预测值较高。
- en: '![CH13_F06_Kaminski2](../Images/CH13_F06_Kaminski2.png)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![CH13_F06_Kaminski2](../Images/CH13_F06_Kaminski2.png)'
- en: Figure 13.5 Histograms of predictions on a test data set for values in the arrest
    column equal to true and false. We can see that the model separates the observations
    relatively well.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.5展示了测试数据集中逮捕列值为真和假的预测值的直方图。我们可以看到，模型相对较好地将观察结果分开。
- en: 'Now consider the following experiment. Assume you set a certain threshold—let’s
    pick 0.15 as an example—and decide to classify all observations with predictions
    less than or equal to 0.15 as false, and greater than 0.15 as true. If we perform
    such a classification, we sometimes make a correct decision (predict observed
    true as true or observed false as false) and sometimes make a mistake (predict
    observed true as false or observed false as true). In the following code, we make
    a table summarizing these results:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 现在考虑以下实验。假设你设置了一个特定的阈值——让我们以0.15为例——并决定将所有预测值小于或等于0.15的观察结果分类为假，大于0.15的为真。如果我们进行这样的分类，我们有时会做出正确的决定（预测观察到的真为真或观察到的假为假），有时会犯错误（预测观察到的真为假或观察到的假为真）。在下面的代码中，我们制作了一个表格来总结这些结果：
- en: '[PRE39]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: This table is typically called a *confusion matrix* ([http://mng.bz/yaZ7](http://mng.bz/yaZ7)).
    We create it by using the proptable function from the FreqTables.jl package, and
    since we pass the margins=2 keyword argument, the values in the columns add up
    to 1.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 这个表格通常被称为*混淆矩阵*([http://mng.bz/yaZ7](http://mng.bz/yaZ7))。我们通过使用FreqTables.jl包中的proptable函数来创建它，并且由于我们传递了margins=2关键字参数，列中的值加起来等于1。
- en: For example, the value 0.188846 in the second row and first column of our confusion
    matrix tells us that for the selected threshold, there is around an 18.88% probability
    that we will incorrectly classify an observed false as true. Let’s call this a
    *probability of false alarm* (*pfa*). Similarly, the value 0.169492 that we have
    in the first row and second column of our confusion matrix tells us that for the
    selected threshold, there is around a 16.95% probability that we will incorrectly
    classify observed true as false. Let’s call this a *probability of miss* (*pmiss*).
    Figure 13.6 illustrates these relationships.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们混淆矩阵的第二行第一列中的数值0.188846告诉我们，对于所选的阈值，大约有18.88%的概率我们会错误地将观察到的假分类为真。让我们称这个为*假警报概率*（*pfa*）。同样，我们混淆矩阵的第一行第二列中的数值0.169492告诉我们，对于所选的阈值，大约有16.95%的概率我们会错误地将观察到的真分类为假。让我们称这个为*漏报概率*（*pmiss*）。图13.6展示了这些关系。
- en: '![CH13_F07_Kaminski2](../Images/CH13_F07_Kaminski2.png)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![CH13_F07_Kaminski2](../Images/CH13_F07_Kaminski2.png)'
- en: Figure 13.6 Elements in the columns of this confusion matrix add up to 1\. The
    model makes two kinds of errors, whose probabilities are pmiss and pfa.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 这个混淆矩阵的列元素加起来等于1。模型犯两种错误，其概率为pmiss和pfa。
- en: The lower the pfa and pmiss, the better the quality of our model. However, we
    have calculated them for a fixed-value classification threshold, 0.15 in the example,
    which was picked arbitrarily. A natural approach to resolve this problem is to
    plot how the relationship of pfa and pmiss changes for all possible values of
    cutoff thresholds. This functionality is provided by the ROCAnalysis.jl package.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: pfa 和 pmiss 越低，我们模型的品质就越好。然而，我们已经针对一个固定的分类阈值进行了计算，例如示例中的 0.15，这个值是任意选择的。解决这个问题的自然方法是为所有可能的截止阈值绘制
    pfa 和 pmiss 之间的关系图。ROCAnalysis.jl 包提供了这个功能。
- en: We will now create a plot showing the relationship between pfa on the x-axis
    and pmiss on the y-axis. Additionally, we will calculate the probability that
    a randomly picked observation that has a true label has a lower prediction than
    the randomly picked observation that has a false label. We want this probability
    to be close to 0% for a good classifier. Note that for the random model (not making
    any useful prediction), this probability is equal to 50%. Let’s call this value
    the *area under the pfa-pmiss curve* (*AUC*). Under our definition, the lower
    the AUC, the better the model.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将创建一个图表，展示 x 轴上的 pfa 与 y 轴上的 pmiss 之间的关系。此外，我们还将计算一个随机选择的具有真实标签的观测值比随机选择的具有错误标签的观测值预测概率。我们希望这个概率接近
    0%，这对于一个好的分类器来说是很重要的。请注意，对于随机模型（不做任何有用的预测），这个概率等于 50%。我们可以称这个值为“pfa-pmiss 曲线下的面积”（AUC）。根据我们的定义，AUC
    越低，模型越好。
- en: Using the ROCAnalysis.jl package, we’ll draw the pfa-pmiss curves for the test
    and train data set predictions of our model and calculate the AUC metric in the
    next listing.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 ROCAnalysis.jl 包，我们将为模型的测试和训练数据集预测绘制 pfa-pmiss 曲线，并在下一个列表中计算 AUC 指标。
- en: Listing 13.12 Drawing pfa-pmiss curves for evaluating the model
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.12 绘制用于评估模型的 pfa-pmiss 曲线
- en: '[PRE40]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'We first use the roc function from the ROCAnalysis.jl package. It takes a data
    frame as an argument, along with the score and target keyword arguments in which
    we pass the names of columns storing predictions and true labels of data, respectively.
    The produced object has two properties that we use: pfa and pmiss, which store
    information about the pfa and pmiss metric values for different values of the
    cutoff threshold, and thus can be used to produce the plots. Finally, using the
    auc function, we calculate the area under the pfa-pmiss curve. The operations
    are done for both the test and train data frames to check whether the obtained
    results are similar.'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先使用 ROCAnalysis.jl 包中的 roc 函数。它接受一个数据框作为参数，以及 score 和 target 关键字参数，其中我们传递存储预测和真实标签的列名。生成的对象有两个我们使用的属性：pfa
    和 pmiss，它们存储了不同截止阈值下的 pfa 和 pmiss 指标值，因此可以用来生成图表。最后，使用 auc 函数，我们计算 pfa-pmiss 曲线下的面积。这些操作是在测试和训练数据框上进行的，以检查获得的结果是否相似。
- en: Figure 13.7 shows the result produced by listing 13.12\. We can see that the
    pfa-pmiss curves for the test and train models are almost identical, so we can
    conclude that it is not overfitted. The AUC is below 15%, which shows that the
    model has a relatively good predictive power.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.7 显示了列表 13.12 生成的结果。我们可以看到测试和训练模型的 pfa-pmiss 曲线几乎完全相同，因此我们可以得出结论，它没有过度拟合。AUC
    低于 15%，这表明模型具有相对较好的预测能力。
- en: I have intentionally kept the model simple in order to not overly complicate
    the discussion presented in this chapter. If we wanted to use this model in practice,
    I would recommend adding more features and allowing for their interactions. Additionally,
    in the Julia ecosystem, in addition to generalized linear models, many other predictive
    models are available. You can find an example list in the MLJ.jl package documentation
    ([http://mng.bz/M09E](http://mng.bz/M09E)).
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 我故意保持模型简单，以避免过度复杂化本章中讨论的内容。如果我们想在实践中使用这个模型，我会建议添加更多特征并允许它们之间的交互。此外，在 Julia 生态系统内，除了广义线性模型外，还有许多其他预测模型可用。你可以在
    MLJ.jl 包的文档中找到一个示例列表（[http://mng.bz/M09E](http://mng.bz/M09E)）。
- en: '![CH13_F08_Kaminski2](../Images/CH13_F08_Kaminski2.png)'
  id: totrans-322
  prefs: []
  type: TYPE_IMG
  zh: '![CH13_F08_Kaminski2](../Images/CH13_F08_Kaminski2.png)'
- en: Figure 13.7 The pfa-pmiss curves for model predictions on the test and train
    data sets are almost identical, which shows that we do not have a problem with
    overfitting the model.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.7 测试和训练数据集上模型预测的 pfa-pmiss 曲线几乎完全相同，这表明我们没有过度拟合模型的问题。
- en: The ROCAnalysis.jl package takes a convention to analyze the area under the
    pfa-pmiss curve. In some other sources (for example, [http://mng.bz/aPmx](http://mng.bz/aPmx)),
    the pmiss metric is replaced by a 1-pmiss measure. Then, on the y-axis of the
    curve, we plot the probability that we make a correct decision when the target
    is true. In such a situation, the area under the curve is maximized (not minimized,
    as in our case) and can be computed as 1 minus the return value of the auc function.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: ROCAnalysis.jl包采用了一种分析pfa-pmiss曲线下面积的方法。在其他一些来源中（例如，[http://mng.bz/aPmx](http://mng.bz/aPmx)），pmiss度量被1-pmiss度量所取代。然后，在曲线的y轴上，我们绘制当目标为真时做出正确决策的概率。在这种情况下，曲线下的面积是最大化的（不是最小化，如我们案例中所示），可以计算为1减去auc函数的返回值。
- en: Doing machine learning with Julia
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Julia进行机器学习
- en: In this chapter, we have manually created and evaluated a simple predictive
    model. If you would like to create more-complex machine learning workflows, I
    recommend learning the MLJ framework ([https://github.com/alan-turing-institute/MLJ.jl](https://github.com/alan-turing-institute/MLJ.jl)).
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们手动创建并评估了一个简单的预测模型。如果您想创建更复杂的机器学习工作流程，我建议学习MLJ框架 ([https://github.com/alan-turing-institute/MLJ.jl](https://github.com/alan-turing-institute/MLJ.jl))。
- en: Machine Learning in Julia (MLJ) is a toolbox providing a common interface and
    meta-algorithms for selecting, tuning, evaluating, composing, and comparing over
    160 machine learning models.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: Julia中的机器学习（MLJ）是一个工具箱，提供选择、调整、评估、组合和比较160多个机器学习模型的通用接口和元算法。
- en: Additionally, appendix C lists various packages that you might find useful if
    you want to go beyond simple data analysis and start doing advanced data science
    projects in Julia.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，附录C列出了您可能觉得有用的各种包，如果您想超越简单的数据分析，开始在Julia中做高级数据科学项目。
- en: 13.5 Reviewing functionalities provided by DataFrames.jl
  id: totrans-329
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.5 查看DataFrames.jl提供的功能
- en: 'In this chapter, you have seen a lot of functionalities provided by DataFrames.jl.
    In conclusion, here’s an overview of functions discussed throughout part 2 so
    that you can have a brief reference:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您看到了DataFrames.jl提供的许多功能。总之，以下是第2部分讨论的函数概述，以便您有一个简要的参考：
- en: '*Constructing data frames*—DataFrame and copy'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*构建数据框*—DataFrame 和 copy'
- en: '*Providing summary information*—describe, summary, ncol, nrow'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*提供摘要信息*—describe, summary, ncol, nrow'
- en: '*Working with column names*—names, rename, rename!'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*与列名一起工作*—名称、重命名、重命名！'
- en: '*Adding rows to data frames*—append!, push!, vcat'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*向数据框添加行*—append!, push!, vcat'
- en: '*Iterating*—eachrow, eachcol'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*迭代*—eachrow, eachcol'
- en: '*Indexing*—getindex, setindex!'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*索引*—getindex, setindex!'
- en: '*Adding columns*—insertcols!'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*添加列*—insertcols!'
- en: '*Transforming columns*—combine, select, select!, transform, transform!, flatten'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*转换列*—combine, select, select!, transform, transform!, flatten'
- en: '*Grouping*—groupby'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*分组*—groupby'
- en: '*Subsetting rows*—subset, subset!, dropmissing, dropmissing!'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*子集行*—subset, subset!, dropmissing, dropmissing!'
- en: '*Reshaping*—stack, unstack, permutedims'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*重塑*—stack, unstack, permutedims'
- en: '*Sorting*—sort, sort!'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*排序*—sort, sort!'
- en: '*Joining*—innerjoin, leftjoin, leftjoin!, rightjoin, outerjoin'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*连接*—innerjoin, leftjoin, leftjoin!, rightjoin, outerjoin'
- en: This list is quite long. I have listed only functions presented in part 2\.
    For a complete list of available functions, check the DataFrames.jl documentation
    ([http://mng.bz/gR7Z](http://mng.bz/gR7Z)). Also, for the functions we have discussed,
    I have omitted some of the functionalities they provide, and instead focus on
    only the most used ones. In the documentation, you will find a complete description
    of every function provided by DataFrames.jl, along with usage examples.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 这个列表相当长。我只列出了第2部分中介绍的功能。要查看所有可用功能的完整列表，请查看DataFrames.jl文档 ([http://mng.bz/gR7Z](http://mng.bz/gR7Z))。此外，对于我们已经讨论过的函数，我省略了它们提供的一些功能，而只关注最常用的功能。在文档中，您将找到DataFrames.jl提供的每个函数的完整描述，以及使用示例。
- en: The operation specification syntax supported by combine, select, select!, transform,
    transform!, subset, and subset! also has more functionalities than are covered
    in this part of the book. I have selected only the most used patterns. You can
    find a complete explanation of all available features in the package documentation
    ([http://mng.bz/epow](http://mng.bz/epow)). Additionally, in my blog post “DataFrames.jl
    Minilanguage Explained” ([http://mng.bz/p6pE](http://mng.bz/p6pE)), I have prepared
    a review of operation specification syntax.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: combine、select、select!、transform、transform!、subset和subset!支持的操作规范语法比本书的这一部分所涵盖的功能更多。我仅选择了最常用的模式。您可以在软件包文档中找到所有可用功能的完整解释（[http://mng.bz/epow](http://mng.bz/epow)）。此外，在我的博客文章“DataFrames.jl
    Minilanguage Explained”([http://mng.bz/p6pE](http://mng.bz/p6pE))中，我还准备了对操作规范语法的回顾。
- en: Many users of DataFrames.jl enjoy using the DataFramesMeta.jl domain-specific
    language, especially in combination with the @chain macro. This package also has
    many more functionalities than I am able to cover in this book; you can find more
    information in its documentation ([http://mng.bz/O6Z2](http://mng.bz/O6Z2)). In
    my blog post “Welcome to DataFramesMeta.jl” ([http://mng.bz/YK7e](http://mng.bz/YK7e)),
    I have additionally created a short guide to the most used macros provided by
    this package.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 许多DataFrames.jl的用户喜欢使用DataFramesMeta.jl领域特定语言，尤其是在与@chain宏结合使用时。这个软件包也具有许多我无法在本书中涵盖的功能；您可以在其文档中找到更多信息（[http://mng.bz/O6Z2](http://mng.bz/O6Z2)）。在我的博客文章“Welcome
    to DataFramesMeta.jl”([http://mng.bz/YK7e](http://mng.bz/YK7e))中，我还为这个软件包提供的最常用宏创建了一个简短的指南。
- en: In summary, you can consider DataFrames.jl a mature package. It has been developed
    for 10 years, and the vast number of functionalities it provides reflects the
    various requirements of its users over this period.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，您可以将DataFrames.jl视为一个成熟的软件包。它已经开发了10年，它提供的众多功能反映了在这段时间内其用户的各种需求。
- en: Additionally, the package is past the 1.0 release, which means that it gives
    a guarantee of not introducing breaking changes until its 2.0 release (which is
    not expected anytime soon). This promise is, in my experience, most relevant for
    users considering it for production use.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，该软件包已经超过了1.0版本发布，这意味着它保证在2.0版本发布之前（预计不会很快）不会引入破坏性更改。在我的经验中，这个承诺对于考虑将其用于生产环境的用户来说最为相关。
- en: Another important design aspect related to production use of DataFrames.jl is
    that it was designed to either produce a correct result or raise an exception.
    You might have noticed that nowhere in this book have you seen any warning message
    printed. This is intentional. Warnings are often silently ignored when you run
    your code in production. In DataFrames.jl, in many functions, we instead provide
    keyword arguments that allow you to turn an error into accepted behavior. Let’s
    look at one example.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 与DataFrames.jl的生产使用相关的一个重要设计方面是，它被设计为要么产生正确的结果，要么引发异常。您可能已经注意到，在这本书的任何地方都没有看到任何警告信息打印出来。这是故意的。在生产环境中运行代码时，警告通常会被无声地忽略。在DataFrames.jl中，在许多函数中，我们提供了关键字参数，允许您将错误转换为可接受的行为。让我们来看一个例子。
- en: 'In R, when you create a data frame with duplicate column names, it is silently
    accepted, and column renaming is done (this is R code):'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 在R中，当您创建具有重复列名的数据框时，它会被静默接受，并且会进行列重命名（这是R代码）：
- en: '[PRE41]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'In DataFrames.jl, by default, we do not allow duplicate column names, as most
    of the time this code is incorrect and should be fixed:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 在DataFrames.jl中，默认情况下，我们不允许重复的列名，因为大多数情况下此代码是错误的，并且应该被修复：
- en: '[PRE42]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'However, we allow you to opt in to accepting duplicate column names by passing
    the makeunique=true keyword argument if this is what you want:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果您希望接受重复的列名，可以通过传递makeunique=true关键字参数来实现：
- en: '[PRE43]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Summary
  id: totrans-356
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: You can create data processing pipelines by using the @chain macro. Functions
    and macros provided by DataFrames.jl and DataFramesMeta.jl integrate well with
    this macro, as typically they take an input data frame or grouped data frame as
    a first positional argument and return a data frame.
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以使用@chain宏创建数据处理管道。DataFrames.jl和DataFramesMeta.jl提供的函数和宏与这个宏很好地集成，因为它们通常将输入数据框或分组数据框作为第一个位置参数，并返回一个数据框。
- en: 'DataFrames.jl defines five functions that allow you to perform operations on
    columns of data frames or grouped data frames: combine, select, select!, transform,
    and transform!. Functions with the ! suffix mutate the object passed to them in
    place, while functions without it allocate a new return value.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DataFrames.jl 定义了五个函数，允许你对数据框或分组数据框的列执行操作：combine、select、select!、transform 和
    transform!。带有 ! 后缀的函数会就地修改传递给它们的对象，而没有 ! 后缀的函数则分配一个新的返回值。
- en: The combine function is used to combine (aggregate) rows from a source object.
    The select and transform functions keep the same number and order of rows as are
    in the source object. The difference between them is that select keeps only columns
    that you specify, while transform additionally keeps all columns from the source
    object.
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: combine 函数用于将（聚合）源对象中的行组合起来。select 和 transform 函数保持与源对象中相同的行数和顺序。它们之间的区别在于 select
    只保留你指定的列，而 transform 还会保留源对象中的所有列。
- en: If you have a function that works on scalars, wrapping it with the ByRow object
    turns them into vectorized (accepting) collections of data and applies the original
    function elementwise.
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你有一个作用于标量的函数，通过使用 ByRow 对象包装它，可以将它们转换为向量化的（接受）数据集合，并按元素应用原始函数。
- en: 'Functions performing operations on columns use a common operation specification
    syntax. It uses the general pattern source_column => operation_ function => target_column_name,
    but selected elements of this pattern can be dropped, as shown in listing 13.3\.
    The three most common variants are as follows: (1) passing source_column stores
    it in the result without any modification, (2) passing source_column => operation_function
    automatically generates the target column name, and (3) passing source_column
    => target_column_name is a syntax used for column renaming.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在对列执行操作的函数中，使用的是通用的操作规范语法。它遵循通用模式 source_column => operation_function => target_column_name，但该模式中的某些元素可以被省略，如列表13.3所示。最常见的三种变体如下：(1)
    传递 source_column 并将其存储在结果中而不做任何修改，(2) 传递 source_column => operation_function 会自动生成目标列名，以及(3)
    传递 source_column => target_column_name 是用于列重命名的语法。
- en: DataFramesMeta.jl provides macros for all column transformation functions provided
    in DataFrames.jl. An important rule is that macros can be prefixed with r in front
    of the macro name. This prefix signals that the operation specified in the macro
    should be automatically vectorized (performed rowwise). For example, the @select
    and @rselect macros are equivalents of the select function. The difference is
    that operations in @select operate on whole columns, while operations in @rselect
    operate on single elements.
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DataFramesMeta.jl 为 DataFrames.jl 中提供的所有列转换函数提供了宏。一个重要的规则是，宏名前可以加前缀 r。这个前缀表示宏中指定的操作应该自动向量化（按行执行）。例如，@select
    和 @rselect 宏与 select 函数等价。区别在于 @select 中的操作作用于整个列，而 @rselect 中的操作作用于单个元素。
- en: CategoricalArrays.jl provides support for categorical arrays. This data is useful
    if you want to treat your data as nominal or ordinal in a statistical sense.
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CategoricalArrays.jl 提供了对分类数组的支持。如果你想在统计意义上将数据视为名义或有序的，这种数据很有用。
- en: DataFrames.jl provides functions that allow you to perform all the standard
    join operations of several tables. These functions are used when you want to combine
    data from several source data frames.
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DataFrames.jl 提供了允许你执行多个表的标准连接操作的函数。当你想要将来自几个源数据框的数据组合在一起时，会使用这些函数。
- en: You use the stack and unstack functions to reshape data frames between long
    and wide formats. Such operations are often needed when you analyze data.
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你使用 stack 和 unstack 函数在长格式和宽格式之间重塑数据框。在分析数据时，这些操作通常都是必需的。
- en: The subset and subset! functions allow you to subset rows of a data frame. They
    use operation specification syntax that is the same as is used in combine or select.
    DataFramesMeta.jl provides macros that are equivalents of these two functions.
    The benefit of using these functions, over, for example, data frame indexing,
    is that they are designed to be easily used in @chain operations.
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: subset 和 subset! 函数允许你对数据框的行进行子集化。它们使用与 combine 或 select 中相同的操作规范语法。DataFramesMeta.jl
    提供了与这两个函数等价的宏。使用这些函数的好处，例如与数据框索引相比，是它们设计得易于在 @chain 操作中使用。
- en: The ROCAnalysis.jl package provides a set of functionalities that allow you
    to evaluate the predictive power of classifiers. This functionality is needed
    essentially every time you build a model with a binary target variable.
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ROCAnalysis.jl 包提供了一套功能，允许您评估分类器的预测能力。这一功能在您每次构建具有二元目标变量的模型时都是必需的。
