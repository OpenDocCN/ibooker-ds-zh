- en: Chapter 8\. Advanced data preparation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 8 章\. 高级数据准备
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Using the `vtreat` package for advanced data preparation
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `vtreat` 包进行高级数据准备
- en: Cross-validated data preparation
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交叉验证数据准备
- en: 'In our last chapter, we built substantial models on nice or well-behaved data.
    In this chapter, we will learn how to prepare or treat messy real-world data for
    modeling. We will use the principles of [chapter 4](../Text/04.xhtml#ch04) and
    the advanced data preparation package: `vtreat`. We will revisit the issues that
    arise with missing values, categorical variables, recoding variables, redundant
    variables, and having too many variables. We will spend some time on variable
    selection, which is an important step even with current machine learning methods.
    The mental model summary ([figure 8.1](../Text/08.xhtml#ch08fig01)) of this chapter
    emphasizes that this chapter is about working with data and preparing for machine
    learning modeling. We will first introduce the `vtreat` package, then work a detailed
    real-world problem, and then go into more detail about using the `vtreat` package.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们上一章中，我们基于良好或行为良好的数据构建了大量的模型。在本章中，我们将学习如何准备或处理混乱的现实世界数据以进行建模。我们将使用第 4 章（[第
    4 章](../Text/04.xhtml#ch04)）的原则和高级数据准备包：`vtreat`。我们将重新审视缺失值、分类变量、变量重编码、冗余变量以及变量过多等问题。我们将花一些时间讨论变量选择，这在当前的机器学习方法中也是一个重要的步骤。本章的心智模型总结（[图
    8.1](../Text/08.xhtml#ch08fig01)）强调，本章是关于处理数据和为机器学习建模做准备。我们首先介绍 `vtreat` 包，然后解决一个详细的现实世界问题，接着更详细地介绍如何使用
    `vtreat` 包。
- en: Figure 8.1\. Mental model
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1\. 心智模型
- en: '![](Images/08fig01.jpg)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/08fig01.jpg)'
- en: 8.1\. The purpose of the vtreat package
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.1\. vtreat 包的用途
- en: '`vtreat` is an R package designed to prepare real-world data for supervised
    learning or predictive modeling. It is designed to deal with a lot of common issues,
    so the data scientist doesn’t have to. This leaves them much more time to find
    and work on unique domain-dependent issues. `vtreat` is an excellent realization
    of the concepts discussed in [chapter 4](../Text/04.xhtml#ch04) as well as many
    other concepts. One of the goals of [chapter 4](../Text/04.xhtml#ch04) was to
    give you an understanding of some of the issues we can run into working with data,
    and principled steps to take in dealing with such data. `vtreat` automates these
    steps into a high-performance production-capable package, and is a formally citable
    methodology you can incorporate into your own work. We can’t succinctly explain
    everything `vtreat` does with data, as it does a lot; for details please see the
    long-form documentation here: [https://arxiv.org/abs/1611.09477](https://arxiv.org/abs/1611.09477).
    In addition, `vtreat` has many explanatory vignettes and worked examples here:
    [https://CRAN.R-project.org/package=vtreat](https://CRAN.R-project.org/package=vtreat).'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '`vtreat` 是一个 R 包，旨在为监督学习或预测建模准备现实世界的数据。它旨在处理许多常见问题，因此数据科学家无需处理。这为他们留下了更多时间来寻找和解决独特的领域相关问题。`vtreat`
    是对第 4 章（[第 4 章](../Text/04.xhtml#ch04)）中讨论的概念以及许多其他概念的出色实现。第 4 章（[第 4 章](../Text/04.xhtml#ch04)）的一个目标是为您提供一些我们在处理数据时可能遇到的问题的理解，以及处理此类数据时应采取的原则性步骤。`vtreat`
    将这些步骤自动化为高性能的生产级包，并且是一种可以正式引用的方法，您可以将其纳入自己的工作中。由于 `vtreat` 做了很多事情，我们无法简要解释它对数据所做的一切；有关详细信息，请参阅此处的高级文档：[https://arxiv.org/abs/1611.09477](https://arxiv.org/abs/1611.09477)。此外，`vtreat`
    在此处有许多解释性小节和工作示例：[https://CRAN.R-project.org/package=vtreat](https://CRAN.R-project.org/package=vtreat)。'
- en: 'We will work through `vtreat`’s capabilities in this chapter using an example
    of predicting account cancellation (called *customer churn*) using the KDD Cup
    2009 dataset. In this example scenario, we will use `vtreat` to prepare the data
    for use in later modeling steps. Some of the issues `vtreat` helps with include
    the following:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将通过使用 KDD Cup 2009 数据集预测账户取消（称为 *客户流失*）的例子来探讨 `vtreat` 的功能。在这个示例场景中，我们将使用
    `vtreat` 准备数据，以便在后续建模步骤中使用。`vtreat` 帮助解决的问题包括以下几方面：
- en: Missing values in numeric variables
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数值变量中的缺失值
- en: Extreme or out-of-range values in numeric variables
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数值变量中的极端或超出范围的值
- en: Missing values in categorical variables
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类变量中的缺失值
- en: Rare values in categorical data
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类数据中的稀有值
- en: Novel values (values seen during testing or application, but not during training)
    in categorical data
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类数据中的新颖值（在测试或应用期间看到，但在训练期间没有看到）
- en: Categorical data with very many possible values
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有非常多个可能值的分类数据
- en: Overfit due to a large number of variables
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于变量数量过多导致的过拟合
- en: Overfit due to “nested model bias”
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于“嵌套模型偏差”导致的过度拟合
- en: The basic `vtreat` workflow (shown in [figure 8.2](../Text/08.xhtml#ch08fig02))
    is to use some of the training data to create a *treatment plan* that records
    key characteristics of the data such as relationships between individual variables
    and the outcome. This treatment plan is then used to *prepare* data that will
    be used to fit the model, as well as to prepare data that the model will be applied
    to. The idea is that this prepared or treated data will be “safe,” with no missing
    or unexpected values, and will possibly have new synthetic variables that will
    improve the model fitting. In this sense, `vtreat` itself looks a lot like a model.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '`vtreat` 的基本工作流程（如图 8.2 所示）是使用一些训练数据来创建一个 *处理计划*，该计划记录了数据的关键特征，例如个体变量与结果之间的关系。然后，这个处理计划被用来
    *准备* 将用于拟合模型的数据，以及准备模型将应用到的数据。这个想法是，这种准备或处理过的数据将是“安全”的，没有缺失或意外的值，并且可能包含新的合成变量，这将提高模型拟合度。从这个意义上说，`vtreat`
    本身看起来很像一个模型。'
- en: Figure 8.2\. `vtreat` three-way split strategy
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.2\. `vtreat` 三分分割策略
- en: '![](Images/08fig02_alt.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/08fig02_alt.jpg)'
- en: We saw a simple use of `vtreat` in [chapter 4](../Text/04.xhtml#ch04) to treat
    missing values. In this chapter, we will use `vtreat`’s full coding power on our
    customer churn example. For motivation, we will solve the KDD Cup 2009 problem,
    and then we will discuss how to use `vtreat` in general.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 [第 4 章](../Text/04.xhtml#ch04) 中看到了 `vtreat` 的简单用法，用于处理缺失值。在本章中，我们将使用 `vtreat`
    的全部编码能力来处理我们的客户流失示例。为了激发兴趣，我们将解决 KDD Cup 2009 问题，然后我们将讨论如何一般性地使用 `vtreat`。
- en: The KDD Cup 2009 provided a dataset about customer relationship management.
    This contest data supplied 230 facts about 50,000 credit card accounts. From these
    features, one of the contest goals was to predict account cancellation (called
    *churn*).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: KDD Cup 2009 提供了一个关于客户关系管理的数据集。这个竞赛数据提供了 50,000 个信用卡账户的 230 个事实。从这些特征中，竞赛的一个目标就是预测账户取消（称为
    *流失*）。
- en: 'The basic way to use `vtreat` is with a three-way data split: one set for learning
    the data treatment, one for modeling, and a third for estimating the model quality
    on new data. [Figure 8.2](../Text/08.xhtml#ch08fig02) shows the concept, which
    will serve as a good mnemonic once we have worked an example. As the diagram shows,
    to use `vtreat` in this manner, we split the data three ways and use one subset
    to prepare the treatment plan. Then we use the treatment plan to prepare the other
    two subsets: one subset to fit the desired model, and the other subset to evaluate
    the fitted model. The process may seem complicated, but from the user’s point
    of view it is very simple.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `vtreat` 的基本方法是采用三分数据分割：一组用于学习数据处理，一组用于建模，第三组用于在新数据上评估模型质量。[图 8.2](../Text/08.xhtml#ch08fig02)
    展示了这一概念，一旦我们通过一个示例，它将作为一个很好的记忆点。如图所示，要这样使用 `vtreat`，我们将数据分成三部分，并使用其中一部分来准备处理计划。然后我们使用处理计划来准备其他两个子集：一个子集用于拟合所需的模型，另一个子集用于评估拟合的模型。这个过程可能看起来很复杂，但从用户的角度来看，它非常简单。
- en: Let’s start with a look at an example scenario using `vtreat` with the KDD Cup
    2009 account cancellation prediction problem.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从使用 `vtreat` 的一个示例场景开始，该场景使用 KDD Cup 2009 账户取消预测问题。
- en: 8.2\. KDD and KDD Cup 2009
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.2\. KDD 和 KDD Cup 2009
- en: '* * *'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Example
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '*We are given the task of predicting which credit card accounts will cancel
    in a given time period. This sort of cancellation is called churn. To build our
    model, we have supervised training data available. For each account in the training
    data, we have hundreds of measured features and we know whether the account later
    cancelled. We want to build a model that identifies “at risk of canceling” accounts
    in this data, as well as for future application.*'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们被赋予预测在特定时间段内哪些信用卡账户将取消的任务。这种取消称为流失。为了构建我们的模型，我们有监督的训练数据可用。对于训练数据中的每个账户，我们有数百个测量的特征，并且我们知道账户后来是否取消。我们希望构建一个模型，能够识别数据中的“有取消风险”的账户，以及未来的应用。*'
- en: '* * *'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: To simulate this scenario, we will use the KDD Cup 2009 contest dataset.^([[1](../Text/08.xhtml#ch08fn1)])
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟这个场景，我们将使用 KDD Cup 2009 竞赛数据集.^([[1](../Text/08.xhtml#ch08fn1)])
- en: ¹
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ¹
- en: ''
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'We share the data and steps to prepare this data for modeling in R here: [https://github.com/WinVector/PDSwR2/tree/master/KDD2009](https://github.com/WinVector/PDSwR2/tree/master/KDD2009).'
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们在这里分享数据以及使用 R 准备这些数据以进行建模的步骤：[https://github.com/WinVector/PDSwR2/tree/master/KDD2009](https://github.com/WinVector/PDSwR2/tree/master/KDD2009)。
- en: '* * *'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '**Shortcomings of the data**'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据的不足之处**'
- en: As with many score-based competitions, this contest concentrated on machine
    learning and deliberately abstracted out or skipped over a number of important
    data science issues, such as cooperatively defining goals, requesting new measurements,
    collecting data, and quantifying classifier performance in terms of business goals.
    For this contest data, we don’t have names or definitions for any of the independent
    (or input) variables^([[a](../Text/08.xhtml#ch08fn2a)]) and no real definition
    of the dependent (or outcome) variables. We have the advantage that the data comes
    in a ready-to-model format (all input variables and the results arranged in single
    rows). But we don’t know the meaning of any variable (so we unfortunately can’t
    join in outside data sources), and we can’t use any method that treats time and
    repetition of events carefully (such as time series methods or survival analysis).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 与许多基于评分的竞赛一样，这次竞赛专注于机器学习，并故意抽象或跳过了一些重要的数据科学问题，例如共同定义目标、请求新的度量、收集数据以及根据业务目标量化分类器的性能。对于这次竞赛的数据，我们没有任何独立（或输入）变量的名称或定义，也没有对依赖（或结果）变量的真正定义。我们有优势，即数据以准备好建模的格式提供（所有输入变量和结果都安排在单行中）。但我们不知道任何变量的含义（因此我们很遗憾不能加入外部数据源），而且我们不能使用任何处理时间和事件重复的仔细方法（如时间序列方法或生存分析）。
- en: ^a
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ^a
- en: ''
  id: totrans-38
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We’ll call variables or columns used to build the model variously *variables*,
    *independent variables*, *input variables*, and so on to try and distinguish them
    from the value to be predicted (which we’ll call *the outcome* or *dependent variable*).
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们将使用各种名称或列来构建模型，称为*变量*、*独立变量*、*输入变量*等，以尝试区分它们与要预测的值（我们将称之为*结果*或*依赖变量*）。
- en: '* * *'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: To simulate the data science processes, we’ll assume that we can use any column
    we’re given to make predictions (that all of these columns are known prior to
    needing a prediction).^([[2](../Text/08.xhtml#ch08fn2)]) We will assume the contest
    metric (*AUC*, or *area under the curve* as discussed in [section 6.2.5](../Text/06.xhtml#ch06lev2sec9))
    is the correct one, and the AUC of the top contestant is a good upper bound (telling
    us when to stop tuning).^([[3](../Text/08.xhtml#ch08fn3)])
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟数据科学过程，我们将假设我们可以使用我们给出的任何列来进行预测（即所有这些列在需要预测之前都是已知的）^([[2](../Text/08.xhtml#ch08fn2)])。我们将假设竞赛指标（*AUC*，或*曲线下面积*，如第
    6.2.5 节中讨论的）是正确的，并且顶级参赛者的 AUC 是一个很好的上限（告诉我们何时停止调整）^([[3](../Text/08.xhtml#ch08fn3)])。
- en: ²
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ²
- en: ''
  id: totrans-43
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Checking if a column is actually going to be available during prediction (and
    not some later function of the unknown output) is a critical step in data science
    projects.
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 检查列是否实际上将在预测期间可用（而不是未知输出的某个后续函数）是数据科学项目中的一个关键步骤。
- en: ³
  id: totrans-45
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ³
- en: ''
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: AUC is a good initial screening metric, as it measures if any monotone transformation
    of your score is a good score. For fine tuning, we will use R-squared and pseudo
    R-squared (also defined in [chapter 6](../Text/06.xhtml#ch06)) as they are stricter,
    measuring if the exact values at hand are good scores.
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: AUC 是一个好的初始筛选指标，因为它衡量你的分数的任何单调变换是否是一个好的分数。为了微调，我们将使用 R 平方和伪 R 平方（也在第 6 章中定义）作为它们更严格，衡量手头的确切值是否是好的分数。
- en: 8.2.1\. Getting started with KDD Cup 2009 data
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.1\. 开始使用 KDD Cup 2009 数据
- en: For our example, we’ll try to predict churn in the KDD dataset. The KDD contest
    was judged in terms of AUC (*area under the curve*, a measure of prediction quality
    discussed in [section 6.2.5](../Text/06.xhtml#ch06lev2sec9)), so we’ll also use
    AUC as our measure of performance.^([[4](../Text/08.xhtml#ch08fn4)]) The winning
    team achieved an AUC of 0.76 on churn, so we’ll treat that as our upper bound
    on possible performance. Our lower bound on performance is an AUC of 0.5, as an
    AUC below 0.5 is worse than random predictions.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的示例，我们将尝试预测 KDD 数据集中的客户流失。KDD 竞赛是根据 AUC（*曲线下面积*，第 6.2.5 节中讨论的预测质量度量）来评判的，因此我们也将使用
    AUC 作为我们的性能度量^([[4](../Text/08.xhtml#ch08fn4)])。获胜团队在客户流失上的 AUC 为 0.76，因此我们将将其视为可能性能的上限。我们的性能下限是
    AUC 为 0.5，因为 AUC 低于 0.5 比随机预测更差。
- en: ⁴
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⁴
- en: ''
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Also, as is common for example problems, we have no project sponsor to discuss
    metrics with, so our choice of evaluation is a bit arbitrary.
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 此外，正如常见的示例问题一样，我们没有项目赞助商来讨论指标，因此我们的评估选择有点随意。
- en: 'This problem has a large number of variables, many of which are categorical
    variables that have a large number of possible levels. As we will see, such variables
    are especially liable to overfit, even during the process of creating the treatment
    plan. Because of this concern, we’ll split our data into three sets: training,
    calibration, and test. In the following example, we’ll use the training set to
    design the treatment plan, and the calibration set to check for overfit in the
    treatment plan. The test set is reserved for a final estimate of model performance.
    This three-way split procedure is recommended by many researchers.^([[5](../Text/08.xhtml#ch08fn5)])'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 此问题具有大量变量，其中许多是具有大量可能级别的分类变量。正如我们将看到的，此类变量在创建治疗方案的过程中特别容易过拟合。由于这个担忧，我们将数据分为三个集合：训练集、校准集和测试集。在以下示例中，我们将使用训练集来设计治疗方案，并使用校准集来检查治疗方案中的过拟合。测试集保留用于对模型性能进行最终估计。许多研究人员推荐这种三方分割程序。[5](../Text/08.xhtml#ch08fn5)
- en: ⁵
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⁵
- en: ''
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Normally, we would use the calibration set to design the treatment plan, the
    training set to train the model, and the test set to evaluate the model. Since
    the focus of this chapter is on the data treatment process, we’ll use the largest
    set (`dTrain`) to design the treatment plan, and the other sets to evaluate it.
  id: totrans-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 通常，我们会使用校准集来设计治疗方案，训练集来训练模型，测试集来评估模型。由于本章的重点是数据处理过程，我们将使用最大的集合（`dTrain`）来设计治疗方案，并使用其他集合来评估它。
- en: Let’s start work as shown in the following listing, where we prepare the data
    for analysis and modeling.^([[6](../Text/08.xhtml#ch08fn6)])
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们按照以下列表开始工作，其中我们准备数据进行分析和建模。[6](../Text/08.xhtml#ch08fn6)
- en: ⁶
  id: totrans-58
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⁶
- en: ''
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Please either work in the KDD2009 subdirectory of the PDSwR2 support materials,
    or copy the relevant files to where you are working. The PDSwR2 support materials
    are available from [https://github.com/WinVector/PDSwR2](https://github.com/WinVector/PDSwR2),
    and instructions for getting started can be found in [appendix A](../Text/A.xhtml#app01).
  id: totrans-60
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 请在 PDSwR2 支持材料的 KDD2009 子目录中工作，或者将相关文件复制到您正在工作的位置。PDSwR2 支持材料可在 [https://github.com/WinVector/PDSwR2](https://github.com/WinVector/PDSwR2)
    获取，有关入门说明请参阅 [附录 A](../Text/A.xhtml#app01)。
- en: Listing 8.1\. Preparing the KDD data for analysis
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.1\. 准备 KDD 数据进行分析
- en: '[PRE0]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Reads the file of independent variables. All the data is from [https://github.com/WinVector/PDSwR2/tree/master/KDD2009](https://github.com/WinVector/PDSwR2/tree/master/KDD2009).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 读取独立变量文件。所有数据均来自 [https://github.com/WinVector/PDSwR2/tree/master/KDD2009](https://github.com/WinVector/PDSwR2/tree/master/KDD2009)。
- en: ❷ Treats both NA and the empty string as missing data
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将 NA 和空字符串都视为缺失数据
- en: ❸ Reads the known churn outcomes
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 读取已知的流失结果
- en: ❹ Adds churn as a new column
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 添加流失作为新列
- en: '❺ By setting the seed to the pseudo-random number generator, we make our work
    reproducible: someone redoing it will see the exact same results.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 通过设置伪随机数生成器的种子，我们使我们的工作可重复：有人重新执行它将看到完全相同的结果。
- en: ❻ Splits data into train, calibration, and test sets. Explicitly specifies the
    base::sample() function to avoid name collision with dplyr::sample(), if the dplyr
    package is loaded.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 将数据分为训练集、校准集和测试集。显式指定 base::sample() 函数以避免与 dplyr::sample() 函数发生名称冲突，如果已加载
    dplyr 包。
- en: ❻ Removes unneeded objects from the workspace
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 从工作区移除不必要的对象
- en: We have also saved an R workspace with most of the data, functions, and results
    of this chapter in the GitHub repository, which you can load with the command
    `load('KDD2009.Rdata')`. We’re now ready to build some models.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还在 GitHub 仓库中保存了一个 R 工作空间，其中包含本章的大部分数据、函数和结果，您可以使用命令 `load('KDD2009.Rdata')`
    加载它。我们现在准备好构建一些模型。
- en: 'We want to remind the reader: always look at your data. Looking at your data
    is the quickest way to find surprises. Two functions are particularly helpful
    for taking an initial look at your data: `str()` (which shows the structure of
    the first few rows in transposed form) and `summary()`.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想提醒读者：始终查看您的数据。查看数据是发现惊喜的最快方式。有两个函数特别有助于对数据进行初步查看：`str()`（以转置形式显示前几行的结构）和
    `summary()`。
- en: '* * *'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Exercise: Using str() and summary()'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 练习：使用 str() 和 summary()
- en: '*Before moving on, please run all of the steps in [listing 8.1](../Text/08.xhtml#ch08ex01),
    and then try running* `str(dTrain)` *and* `summary(dTrain)` *yourself. We try
    to avoid overfit by not making modeling decisions based on looking at our holdout
    data.*'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，请运行[列表 8.1](../Text/08.xhtml#ch08ex01)中的所有步骤，然后尝试自己运行`str(dTrain)`和`summary(dTrain)`。我们试图通过不在我们的保留数据上做出建模决策来避免过拟合。
- en: '* * *'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '* * *'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '**Subsample to prototype quickly**'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**快速进行子样本**'
- en: Often the data scientist will be so engrossed with the business problem, math,
    and data that they forget how much trial and error is needed. It’s often an excellent
    idea to first work on a small subset of your training data, so that it takes seconds
    to debug your code instead of minutes. Don’t work with large and slow data sizes
    until you have to.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 经常数据科学家会如此专注于业务问题、数学和数据，以至于他们忘记了需要多少试错。首先在小部分训练数据上工作通常是一个非常好的主意，这样调试代码只需要几秒钟，而不是几分钟。除非你真的需要，否则不要处理大型和缓慢的数据集。
- en: '* * *'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Characterizing the outcome
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 描述结果
- en: 'Before starting on modeling, we should look at the distribution of the outcome.
    This tells how much variation there is to even attempt to predict. We can do this
    as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始建模之前，我们应该查看结果分布。这告诉我们有多少变异，以至于甚至尝试预测。我们可以这样做：
- en: '[PRE1]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ Tabulates levels of churn outcome
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 列出客户流失结果的水平
- en: ❷ Includes NA values in the tabulation
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在列表中包含 NA 值
- en: ❸ Estimates the observed churn rate or prevalence
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 估计观察到的客户流失率或流行率
- en: 'The table in [figure 8.3](../Text/08.xhtml#ch08fig03) indicates that churn
    takes on two values: –1 and 1\. The value 1 (indicating a churn, or cancellation
    of account, has happened) is seen about 7% of the time. So we could trivially
    be 93% accurate by predicting that no account ever cancels, though obviously this
    is not a useful model!^([[7](../Text/08.xhtml#ch08fn7)])'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 8.3](../Text/08.xhtml#ch08fig03)中的表格表明，客户流失有两个值：-1 和 1。值 1（表示发生了客户流失或账户取消）大约有
    7% 的时间被看到。因此，我们可以简单地通过预测没有任何账户取消来达到 93% 的准确率，尽管显然这不是一个有用的模型！^([[7](../Text/08.xhtml#ch08fn7)])'
- en: ⁷
  id: totrans-87
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⁷
- en: ''
  id: totrans-88
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: See [http://www.win-vector.com/blog/2009/11/i-dont-think-that-means-what-you-think-it-means-statistics-to-english-translation-part-1-accuracy-measures/](http://www.win-vector.com/blog/2009/11/i-dont-think-that-means-what-you-think-it-means-statistics-to-english-translation-part-1-accuracy-measures/).
  id: totrans-89
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 见[http://www.win-vector.com/blog/2009/11/i-dont-think-that-means-what-you-think-it-means-statistics-to-english-translation-part-1-accuracy-measures/](http://www.win-vector.com/blog/2009/11/i-dont-think-that-means-what-you-think-it-means-statistics-to-english-translation-part-1-accuracy-measures/)。
- en: Figure 8.3\. KDD2009 churn rate
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.3\. KDD2009 客户流失率
- en: '![](Images/08fig03.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/08fig03.jpg)'
- en: 8.2.2\. The bull-in-the-china-shop approach
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.2\. 中国瓷器店的牛
- en: 'Let’s deliberately ignore our advice to look at the data, to look at the columns,
    and to characterize the relations between the proposed explanatory variables and
    the quantity to be predicted. For this first attempt, we aren’t building a treatment
    plan, so we’ll use both the `dTrain` and `dCal` data together to fit the model
    (as the set `dTrainAll`). Let’s see what happens if we jump in and immediately
    try to build a model for `churn == 1`, given the explanatory variables (hint:
    it won’t be pretty).'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们故意忽略查看数据、查看列以及描述拟议的解释变量与要预测的数量之间关系的建议。对于这个第一次尝试，我们不是在制定治疗方案，所以我们将使用`dTrain`和`dCal`数据一起来拟合模型（作为`dTrainAll`集合）。让我们看看如果我们立即尝试为`churn
    == 1`构建模型会发生什么，给定解释变量（提示：这不会很漂亮）。
- en: Listing 8.2\. Attempting to model without preparation
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.2\. 尝试在没有准备的情况下进行建模
- en: '[PRE2]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ Attaches the wrapr package for convenience functions, such as mk_formula()
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 为方便函数（如 mk_formula()）附加 wrapr 包
- en: ❷ Builds a model formula specification, asking churn == 1 to be predicted as
    a function of our explanatory variables
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 构建模型公式规范，要求预测 churn == 1 作为我们的解释变量的函数
- en: ❸ Asks the glm() function to build a logistic regression model
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 要求 glm() 函数构建一个逻辑回归模型
- en: ❹ The attempt failed with an error.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 尝试失败，出现错误。
- en: As we can see, this first attempt failed. Some research will show us that some
    of the columns we are attempting to use as explanatory variables do not vary and
    have the exact same value for every row or example. We could attempt to filter
    these bad columns out by hand, but fixing common data issues in an ad hoc manner
    is tedious. For example, [listing 8.3](../Text/08.xhtml#ch08ex03) shows what happens
    if we try to use just the first explanatory variable `Var1` to build a model.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，这次尝试失败了。一些研究将表明，我们试图用作解释变量的某些列没有变化，并且对于每一行或示例都具有完全相同的值。我们可以尝试手动过滤掉这些不良列，但以这种方式修复常见的数据问题是非常繁琐的。例如，[列表8.3](../Text/08.xhtml#ch08ex03)展示了如果我们只使用第一个解释变量`Var1`来构建模型会发生什么。
- en: '* * *'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '**Explanatory variables**'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**解释变量**'
- en: '*Explanatory variables* are columns or variables we are trying to use as inputs
    for our model. In this case, the variables came to us without informative names,
    so they go by the names `Var#` where `#` is a number. In a real project, this
    would be a possible sign of uncommitted data-managing partners, and something
    to work on fixing before attempting modeling.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '*解释变量*是我们试图用作模型输入的列或变量。在这种情况下，变量到达我们这里时没有信息性的名称，因此它们以`Var#`的形式命名，其中`#`是一个数字。在一个真实的项目中，这可能是数据管理伙伴未承诺的迹象，并且在尝试建模之前需要解决的问题。'
- en: '* * *'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Listing 8.3\. Trying just one variable
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.3\. 尝试仅使用一个变量
- en: '[PRE3]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ This means the modeling procedure threw out this much (almost all) of our
    training data.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 这意味着建模过程丢弃了这么多的（几乎全部）训练数据。
- en: We saw how to read the model summary in detail in [section 7.2](../Text/07.xhtml#ch07lev1sec2).
    What jumps out here is the line “44407 observations deleted due to missingness.”
    This means the modeling procedures threw out 44407 of our 45028 training rows,
    building a model on the remaining 621 rows of data. So in addition to columns
    that do not vary, we have columns that have damaging amounts of missing values.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第7.2节](../Text/07.xhtml#ch07lev1sec2)中详细介绍了如何阅读模型摘要。这里引人注目的是“由于缺失值删除了44407个观测值”这一行。这意味着建模过程丢弃了我们45028个训练行中的44407行，基于剩余的621行数据构建模型。因此，除了不变化的列之外，我们还有包含大量缺失值的列。
- en: 'The data problems do not end there. Take a look at another variable, this time
    the one named `Var200`:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 数据问题并没有结束。看看另一个变量，这次是名为`Var200`的变量：
- en: '[PRE4]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `head()` command shows us the first few values of `Var200`, telling us this
    column has string values encoded as factors. Factors are R’s representation for
    strings taken from a known set. And this is where an additional problem lies.
    Notice the listing says the factor has 15415 possible levels. A factor or string
    variable with this many distinct levels is going to be a big problem in terms
    of overfitting and also difficult for the `glm()` code to work with. In addition,
    the `length(unique(dTrainAll$Var200))` summary tells us that `Var200` takes on
    only 14391 distinct values in our training sample. This tells us our training
    data sample did not see all known values for this variable. Our held-out test
    set contains, in addition to values seen during training, new values not in the
    training set. This is quite common for string-valued or categorical variables
    with a large number of levels, and causes most R modeling code to error-out when
    trying to make predictions on new data.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '`head()`命令显示了`Var200`的前几个值，告诉我们这个列具有作为因子的字符串值编码。因子是R对来自已知集合的字符串的表示。这正是问题的所在。注意列表中提到因子有15415个可能的水平。具有这么多不同水平的因子或字符串变量在过拟合方面将是一个大问题，并且对于`glm()`代码来说也难以处理。此外，`length(unique(dTrainAll$Var200))`摘要告诉我们`Var200`在我们的训练样本中只采取了14391个不同的值。这告诉我们我们的训练数据样本没有看到这个变量的所有已知值。我们的保留测试集除了在训练期间看到的值之外，还包含训练集之外的新的值。这对于具有大量水平的字符串值或分类变量来说是很常见的，并且导致大多数R建模代码在尝试对新数据进行预测时出错。'
- en: 'We could go on. We have not yet exhausted the [section 8.1](../Text/08.xhtml#ch08lev1sec1)
    list of things that can commonly go wrong. At this point, we hope the reader will
    agree: a sound systematic way of identifying, characterizing, and mitigating common
    data quality issues would be a great help. Having a good way to work though common
    data quality issues in a domain-independent way leaves us more time to work with
    the data and work through any domain-specific issues. The `vtreat` package is
    a great tool for this task. For the rest of this chapter, we will work a bit with
    the KDD Cup 2009 data, and then master using `vtreat` in general.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以继续。我们还没有用尽[第8.1节](../Text/08.xhtml#ch08lev1sec1)中常见错误事项的列表。到目前为止，我们希望读者会同意：一种合理的系统方法来识别、描述和减轻常见的数据质量问题将大有裨益。以领域无关的方式处理常见的数据质量问题，让我们有更多时间处理数据并解决任何特定领域的问题。`vtreat`包是这项任务的优秀工具。在本章的其余部分，我们将与KDD
    Cup 2009数据略作工作，然后掌握一般使用`vtreat`的方法。
- en: 8.3\. Basic data preparation for classification
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.3\. 分类的基本数据准备
- en: '`vtreat` prepares data for use by both cleaning up existing columns or variables
    and by introducing new columns or variables. For our order cancellation scenario,
    `vtreat` will address the missing values, the categorical variables with very
    many levels, and other issues. Let’s master the `vtreat` process here.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '`vtreat`通过清理现有列或变量以及引入新的列或变量来准备数据。对于我们的订单取消场景，`vtreat`将处理缺失值、具有许多级别的分类变量和其他问题。让我们在这里掌握`vtreat`的过程。'
- en: First, we’ll use a portion of our data (the `dTrain` set) to design our variable
    treatments.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将使用我们数据的一部分（`dTrain`集）来设计我们的变量处理。
- en: Listing 8.4\. Basic data preparation for classification
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.4\. 分类的基本数据准备
- en: '[PRE5]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ Attaches the vtreat package for functions such as designTreatmentsC()
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 添加vtreat包以使用如designTreatmentsC()等函数
- en: ❷ Starts up a parallel cluster to speed up calculation. If you don’t want a
    parallel cluster, just set parallel_ cluster to NULL.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 启动一个并行集群以加快计算速度。如果您不想使用并行集群，只需将parallel_cluster设置为NULL。
- en: ❸ Uses designTreatmentsC() to learn the treatment plan from the training data.
    For a dataset the size and complexity of KDD2009, this can take a few minutes.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 使用designTreatmentsC()从训练数据中学习处理计划。对于大小和复杂度类似于KDD2009的数据集，这可能需要几分钟。
- en: Then, we’ll use the treatment plan to prepare cleaned and treated data. The
    `prepare()` method builds a new data frame with the same row order as the original
    data frame, and columns from the treatment plan (plus copying over the dependent
    variable column if it is present). The idea is illustrated in [figure 8.4](../Text/08.xhtml#ch08fig04).
    In [listing 8.5](../Text/08.xhtml#ch08ex05), we apply the treatment plan to the
    `dTrain` data, so we can compare the treated data to the original data.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将使用处理计划来准备清洗和处理后的数据。`prepare()`方法构建一个新的数据框，其行顺序与原始数据框相同，并包含处理计划中的列（如果存在，则复制依赖变量列）。这一想法在[图8.4](../Text/08.xhtml#ch08fig04)中得到了说明。在[列表8.5](../Text/08.xhtml#ch08ex05)中，我们将处理计划应用于`dTrain`数据，以便我们可以比较处理后的数据与原始数据。
- en: Figure 8.4\. `vtreat` variable preparation
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.4\. `vtreat`变量准备
- en: '![](Images/08fig04_alt.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/08fig04_alt.jpg)'
- en: Listing 8.5\. Preparing data with `vtreat`
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.5\. 使用`vtreat`准备数据
- en: '[PRE6]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ Compares the columns of the original dTrain data to its treated counterpart
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 比较原始dTrain数据的列与其处理后的对应数据
- en: Note that the treated data both converts existing columns and introduces new
    columns or derived variables. In the next section, we will work through what those
    new variables are and how to use them.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，处理后的数据既转换了现有列，也引入了新的列或派生变量。在下一节中，我们将探讨这些新变量是什么以及如何使用它们。
- en: 8.3.1\. The variable score frame
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3.1\. 变量得分框架
- en: 'The `vtreat` process we have worked with up to now centers around `designTreatmentsC()`,
    which returns the treatment plan. The treatment plan is an R object with two purposes:
    to be used in data preparation by the `prepare()` statement, and to deliver a
    simple summary and initial critique of the proposed variables. This simple summary
    is encapsulated in the *score frame*. The score frame lists the variables that
    will be created by the `prepare()` method, along with some information about them.
    The score frame is our guide to the new variables `vtreat` introduces to make
    our modeling work easier. Let’s take a look at the score frame:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们到目前为止所处理的`vtreat`过程集中在`designTreatmentsC()`上，它返回治疗方案。治疗方案是一个R对象，有两个目的：通过`prepare()`语句用于数据准备，并提供对建议变量的简单总结和初步评估。这个简单的总结封装在*分数框架*中。分数框架列出了`prepare()`方法将创建的变量，以及一些关于它们的信息。分数框架是我们了解`vtreat`引入的新变量以简化我们的建模工作的指南。让我们看一下分数框架：
- en: '[PRE7]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ The name of the derived variable or column
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 派生变量或列的名称
- en: ❷ An indicator that this variable is not always the same value (not a constant,
    which would be useless for modeling)
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 一个指示符，表明这个变量不总是相同的值（不是一个常数，这对建模是无用的）
- en: ❸ The R-squared or pseudo R-squared of the variable; what fraction of the outcome
    variation this variable can explain on its own in a linear model
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 变量的R-squared或伪R-squared；这个变量在线性模型中可以解释的因变量变异的分数
- en: ❹ The significance of the estimated R-squared
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 估计R-squared的重要性
- en: ❺ An indicator that, when TRUE, is a warning to the user that the variable is
    hiding extra degrees of freedom (a measure of model complexity) and needs to be
    evaluated using cross-validation techniques
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 一个指示符，当为TRUE时，是对用户的一个警告，表明该变量隐藏了额外的自由度（模型复杂度的度量），需要使用交叉验证技术进行评估
- en: ❻ How complex the variable is; for a categorical variable, this is related to
    the number of levels.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 变量的复杂程度；对于分类变量，这与级别的数量有关。
- en: ❻ Name of the original column the variable was derived from
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 变量派生自原始列的名称
- en: ❽ Name of the type of transformation used to build this variable
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 用于构建此变量的转换类型的名称
- en: The score frame is a `data.frame` with one row per derived explanatory variable.
    Each row shows which original variable the derived variable will be produced from
    (`orig-Name`), what type of transform will be used to produce the derived variable
    (`code`), and some quality summaries about the variable.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 分数框架是一个`data.frame`，每行对应一个派生解释变量。每一行显示派生变量将来自哪个原始变量（`orig-Name`），将使用什么类型的转换来生成派生变量（`code`），以及一些关于变量的质量摘要。
- en: 'In our example, Var126 produces two new or derived variables: Var126 (a cleaned-up
    version of the original Var126 that has no NA/missing values), and Var116_isBAD
    (an indicator variable that indicates which rows of Var126 originally held missing
    or bad values).'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，Var126生成了两个新的或派生变量：Var126（原始Var126的清理版本，没有NA/缺失值），以及Var116_isBAD（一个指示变量，表示Var126原始的哪些行包含缺失或不良值）。
- en: The `rsq` column records the pseudo R-squared of the given variable, which is
    an indication of how informative the variable would be if treated as a single-variable
    model for the outcome. The `sig` column is an estimate of the significance of
    this pseudo R-squared. Notice that `var126_isBAD` is more informative than the
    cleaned up original variable `var126`. This indicates we should consider including
    `var126_isBAD` in our model, even if we decide not to include the cleaned-up version
    of `var126` itself!
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '`rsq`列记录了给定变量的伪R-squared，这是如果将其作为因变量的单变量模型处理时，变量信息性的一个指标。`sig`列是对此伪R-squared显著性的估计。请注意，`var126_isBAD`比清理后的原始变量`var126`更有信息量。这表明我们应该考虑将`var126_isBAD`包含在我们的模型中，即使我们决定不包含`var126`的清理版本本身！'
- en: '* * *'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '**Informative missing values**'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**信息性缺失值**'
- en: In production systems, missingness is often very informative. Missingness usually
    indicates the data in question was subject to some condition (temperature out
    of range, test not run, or something else) and gives a lot of context in an encoded
    form. We have seen many situations where the information that a variable is missing
    is more informative than the cleaned-up values of the variable itself.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产系统中，缺失值通常非常有信息。缺失值通常表明相关数据经历了某种条件（温度超出范围，测试未运行，或其他情况），并以编码的形式提供了大量上下文。我们见过许多情况，其中变量缺失的信息比变量本身的清理值更有信息量。
- en: '* * *'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Let’s look at a categorical variable. The original `Var218` has two possible
    levels: `cJvF` and `UYBR`.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个分类变量。原始 `Var218` 有两个可能的水平：`cJvF` 和 `UYBR`。
- en: '[PRE8]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The original variable `Var218` produced four derived variables. In particular,
    notice that the levels `cJvF` and `UYBR` each gave us new derived columns or variables.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 原变量 `Var218` 产生了四个派生变量。特别是，请注意，水平 `cJvF` 和 `UYBR` 分别为我们提供了新的派生列或变量。
- en: Level variables (lev)
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 水平变量（lev）
- en: '`Var218_lev_x_cJvF` and `Var218_lev_x_UYBR` are indicator variables that have
    the value `1` when the original `Var218` had the values `cJvF` and `UYBR` respectively;^([[8](../Text/08.xhtml#ch08fn8)])
    we will discuss the other two variables in a bit. Recall from [chapter 7](../Text/07.xhtml#ch07)
    that most modeling methods work with a categorical variable with *n* possible
    levels by converting it to *n* (or *n-1*) binary variables, or indicator variables
    (sometimes referred to as *one-hot encoding* or *dummies*). Many modeling functions
    in R, such as `lm` or `glm`, do this conversion automatically; others, such as
    `xgboost`, don’t. `vtreat` tries to explicitly one-hot encode categoricals when
    it is feasible. In this way, the data can be used either by modeling functions
    like `glm`, or by functions like `xgboost`.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '`Var218_lev_x_cJvF` 和 `Var218_lev_x_UYBR` 是指示变量，当原始 `Var218` 的值分别为 `cJvF` 和
    `UYBR` 时，它们的值为 `1`；^([[8](../Text/08.xhtml#ch08fn8)]) 我们稍后会讨论其他两个变量。回顾 [第 7 章](../Text/07.xhtml#ch07)，大多数建模方法通过将其转换为
    *n*（或 *n-1*）个二元变量，或指示变量（有时称为 *独热编码* 或 *虚拟变量*）来处理具有 *n* 个可能水平的分类变量。R 中的许多建模函数，如
    `lm` 或 `glm`，会自动进行这种转换；而其他函数，如 `xgboost`，则不会。`vtreat` 尝试在可行的情况下显式地独热编码分类变量。这样，数据既可以由
    `glm` 等建模函数使用，也可以由 `xgboost` 等函数使用。'
- en: ⁸
  id: totrans-151
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⁸
- en: ''
  id: totrans-152
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In a real modeling project, we would insist on meaningful level names and a
    *data dictionary* describing the meanings of the various levels. The KDD2009 contest
    data did not supply such information, which is a limitation of the contest data
    and prevents powerful methods such as using variables to join in additional information
    from external data sources.
  id: totrans-153
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在一个真实的建模项目中，我们会坚持使用有意义的水平名称和一个 *数据字典* 来描述各种水平的含义。KDD2009 竞赛数据没有提供此类信息，这是竞赛数据的一个局限性，阻碍了使用变量从外部数据源获取额外信息等强大方法。
- en: 'By default, `vtreat` only creates indicator variables for “non-rare” levels:
    levels that appear more than 2% of the time. As we will see, `Var218` also has
    some missing values, but the missingness only occurs 1.4% of the time. If missingness
    had been more informative, then `vtreat` would have also created a `Var218_lev_x_NA`
    indicator, as well.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`vtreat` 只为“非稀有”水平创建指示变量：出现频率超过 2% 的水平。正如我们将看到的，`Var218` 也有一些缺失值，但缺失值只占
    1.4% 的时间。如果缺失值更有信息量，那么 `vtreat` 也会创建一个 `Var218_lev_x_NA` 指示变量。
- en: Impact variables (catB)
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 影响变量（catB）
- en: 'One-hot encoding creates a new variable for every non-rare level of a categorical
    variable. The `catB` encoding returns a single new variable, with a numerical
    value for every possible level of the original categorical variable. This value
    represents how informative a given level is: values with large magnitudes correspond
    to more-informative levels. We call this the *impact* of the level on the outcome;
    hence, the term “impact variable.” To understand impact variables, let’s compare
    the original `Var218` to `Var218_catB`:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 独热编码为分类变量的每个非稀有水平创建一个新变量。`catB` 编码返回一个单一的新变量，其中每个原始分类变量的可能水平都有一个数值。这个值表示给定水平的信息量：具有大绝对值的值对应于更具有信息量的水平。我们称此为该水平对结果的影响；因此，术语“影响变量”。为了理解影响变量，让我们比较原始
    `Var218` 与 `Var218_catB`：
- en: '[PRE9]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: For classification problems, the values of impact encoding are related to the
    predictions of a logistic regression model that predicts churn from `Var218`.
    To see this, we’ll use the simple missingness treatment that we used in [section
    4.1.3](../Text/04.xhtml#ch04lev2sec3) to explicitly convert the `NA` values in
    `Var218` to a new level. We will also use the `logit`, or log-odds function that
    we saw in [chapter 7](../Text/07.xhtml#ch07).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分类问题，影响编码的值与从 `Var218` 预测流失的逻辑回归模型的预测相关。为了展示这一点，我们将使用我们在 [第 4.1.3 节](../Text/04.xhtml#ch04lev2sec3)
    中使用的简单缺失值处理方法，将 `Var218` 中的 `NA` 值显式地转换为新的水平。我们还将使用我们在 [第 7 章](../Text/07.xhtml#ch07)
    中看到的 `logit` 或对数优势函数。
- en: '[PRE10]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ❶ Simple treatment to turn NA into a safe string
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将 NA 转换为安全字符串的简单处理
- en: ❷ Creates the treated data
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 创建处理后的数据
- en: ❸ Fits the one-variable logistic regression model
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 符合一元逻辑回归模型
- en: ❹ Makes predictions on the data
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 在数据上做出预测
- en: ❺ Calculates the global probability of churn.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 计算流失的全球概率。
- en: ❻ A function to calculate the logit, or log-odds of a probability
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 一个计算概率的对数几率或对数优势的函数
- en: ❻ Calculates the catB values by hand
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 手动计算catB值
- en: ❽ Notice that the impact codes from vtreat match the “delta logit” encoded predictions
    from the standard glm model. This helps illustrate how vtreat is implemented.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 注意，vtreat的影响代码与标准glm模型中编码的“delta logit”预测相匹配。这有助于说明vtreat是如何实现的。
- en: In our KDD2009 example, we see the `catB` impact encoding is replacing a categorical
    variable with the predictions of the corresponding one-variable logistic regression
    model. For technical reasons, the predictions are in “link space,” or `logit`
    space, rather than in probability space, and are expressed as a difference from
    the null model of always predicting the global probability of the outcome. In
    all cases this data preparation takes a potentially complex categorical variable
    (that may imply many degrees of freedom, or dummy variable columns) and derives
    a single numeric column that picks up most of the variable’s modeling utility.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的KDD2009示例中，我们看到`catB`影响编码正在用一个对应的一元逻辑回归模型的预测来替换一个分类变量。由于技术原因，预测是在“链接空间”或`logit`空间中，而不是在概率空间中，并且表示为与总是预测全局结果概率的零模型之间的差异。在所有情况下，这种数据准备都涉及一个可能复杂的分类变量（可能表示许多自由度或虚拟变量列），并推导出一个单一的数值列，该列提取了变量的大部分建模效用。
- en: When the modeling problem is a regression rather than a classification (the
    outcome is numeric), the impact encoding is related to the predictions of a one-variable
    linear regression. We’ll see an example of this later in the chapter.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 当建模问题是一个回归而不是分类（结果为数值）时，影响编码与一元线性回归的预测相关。我们将在本章后面看到这个示例。
- en: The prevalence variables (catP)
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 普及变量（catP）
- en: 'The idea is this: for some variables, knowing how often a level occurs is very
    informative. For example, for United States ZIP codes, rare ZIP codes may all
    be from low-population rural areas. The prevalence variable simply encodes what
    fraction of the time the original variable takes the given level, making these
    whole-dataset statistics available to the modeling process in a convenient per-example
    format.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 想法是这样的：对于某些变量，知道某个水平出现的频率非常有信息量。例如，对于美国的ZIP代码，罕见的ZIP代码可能都是来自低人口密度的农村地区。普及变量简单地编码了原始变量在给定水平上占的时间比例，使得这些整个数据集的统计数据以方便的按例格式可用于建模过程。
- en: '* * *'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '**Variable ethics**'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '**变量伦理**'
- en: 'Note: For some applications, certain variables and inference may be either
    unethical or illegal to use. For example, ZIP code and race are both prohibited
    in the United States for credit approval decisions, due to historic “red lining”
    discrimination practices.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：对于某些应用，某些变量和推断可能既不道德也可能非法使用。例如，由于历史上的“红线”歧视做法，美国禁止在信用批准决策中使用ZIP代码和种族。
- en: Having a sensitivity to ethical issues and becoming familiar with data and modeling
    law are critical in real-world applications.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际应用中，对伦理问题的敏感性和熟悉数据和建模法律是至关重要的。
- en: '* * *'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Let’s look at what happened to another variable that was giving us trouble:
    `Var200`. Recall that this variable has 15415 possible values, of which only 13324
    appear in the training data.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看另一个给我们带来麻烦的变量发生了什么：`Var200`。回想一下，这个变量有15415个可能的值，其中只有13324个出现在训练数据中。
- en: '[PRE11]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Note that `vtreat` only returned one indicator variable, indicating missing
    values. All the other possible values of `Var200` were rare: they occurred less
    than 2% of the time. For a variable like `Var200` with a very large number of
    levels, it isn’t practical to encode all the levels as indicator variables when
    modeling; it’s more computationally efficient to represent the variable as a single
    numeric variable, like the `catB` variable.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`vtreat`只返回了一个指示变量，表示缺失值。`Var200`的所有其他可能值都很罕见：它们出现的频率不到2%。对于像`Var200`这样的具有非常大量级的变量，在建模时将所有级别编码为指示变量并不实用；将变量表示为单个数值变量，如`catB`变量，计算上更有效。
- en: In our example, the `designTreatmentsC()` method recoded the original 230 explanatory
    variables into 546 new all-numeric explanatory variables that have no missing
    values. The idea is that these 546 variables are easier to work with and have
    a good shot of representing most of the original predictive signal in the data.
    A full description of what sorts of new variables `vtreat` can introduce can be
    found in the `vtreat` package documentation.^([[9](../Text/08.xhtml#ch08fn9)])
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，`designTreatmentsC()` 方法将原始的 230 个解释变量重新编码为 546 个新的全数值解释变量，这些变量没有缺失值。想法是这些
    546 个变量更容易处理，并且有很大的机会代表数据中大部分原始的预测信号。`vtreat` 可以引入的新变量的完整描述可以在 `vtreat` 包文档中找到。[9](../Text/08.xhtml#ch08fn9)]
- en: ⁹
  id: totrans-181
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⁹
- en: ''
  id: totrans-182
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: See [https://winvector.github.io/vtreat/articles/vtreatVariableTypes.html](https://winvector.github.io/vtreat/articles/vtreatVariableTypes.html).
  id: totrans-183
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 查看 [https://winvector.github.io/vtreat/articles/vtreatVariableTypes.html](https://winvector.github.io/vtreat/articles/vtreatVariableTypes.html)。
- en: 8.3.2\. Properly using the treatment plan
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 8.3.2\. 正确使用治疗计划
- en: The primary purpose of the treatment plan object is to allow `prepare()` to
    convert new data into a safe, clean form before fitting and applying models. Let’s
    see how that is done. Here, we apply the treatment plan that we learned from the
    `dTrain` set to the calibration set, `dCal`, as shown in [figure 8.5](../Text/08.xhtml#ch08fig05).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 治疗计划对象的主要目的是允许 `prepare()` 在拟合和应用模型之前将新数据转换为安全、干净的形式。让我们看看这是如何完成的。在这里，我们将从 `dTrain`
    集中学习到的治疗计划应用于校准集 `dCal`，如图 [8.5](../Text/08.xhtml#ch08fig05) 所示。
- en: Figure 8.5\. Preparing held-out data
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.5\. 准备保留数据
- en: '![](Images/08fig05.jpg)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/08fig05.jpg)'
- en: '[PRE12]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Normally, we could now use `dCal_treated` to fit a model for churn. In this
    case, we’ll use it to illustrate the risk of overfit on transformed variables
    that have `needsSplit == TRUE` in the score frame.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们现在可以使用 `dCal_treated` 来拟合一个关于客户流失的模型。在这种情况下，我们将用它来说明在得分框架中 `needsSplit
    == TRUE` 的转换变量上过度拟合的风险。
- en: 'As we mentioned earlier, you can think of the `Var200_catB` variable as a single-variable
    logistic regression model for churn. This model was fit using `dTrain` when we
    called `designTreatmentsC()`; it was then applied to the `dCal` data when we called
    `prepare()`. Let’s look at the AUC of this model on the training and calibration
    sets:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前提到的，你可以将 `Var200_catB` 变量视为一个关于客户流失的单变量逻辑回归模型。当我们调用 `designTreatmentsC()`
    时，这个模型使用了 `dTrain` 进行拟合；然后当我们调用 `prepare()` 时，它被应用于 `dCal` 数据。让我们看看这个模型在训练集和校准集上的
    AUC：
- en: '[PRE13]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Notice the AUC estimated in the training data is 0.83, which seems very good.
    However, this AUC is not confirmed when we look at the calibration data that was
    not used to design the variable treatment. `Var200_catB` is overfit with respect
    to `dTrain_ treated`. `Var200_catB` is a useful variable, just not as good as
    it appears to be on the training data.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 注意训练数据中估计的 AUC 为 0.83，这似乎非常好。然而，当我们查看未用于设计变量处理的校准数据时，这个 AUC 并没有得到证实。`Var200_catB`
    相对于 `dTrain_ treated` 过度拟合。`Var200_catB` 是一个有用的变量，只是不如它在训练数据上看起来那么好。
- en: '* * *'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Do not directly reuse the same data for fitting the treatment plan and the model!
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 不要直接重用相同的数据来拟合治疗计划和模型！
- en: To avoid overfit, the general rule is that whenever a premodeling data processing
    step uses knowledge of the outcome, you should not use the same data for the premodeling
    step and the modeling.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免过度拟合，一般规则是，每当预建模数据预处理步骤使用对结果的知识时，你不应该使用相同的数据进行预建模步骤和建模。
- en: The AUC calculations in this section show that `Var200_catB` looks “too good”
    on the training data. Any model-fitting algorithm using `dTrain_ treated` to fit
    a churn model will likely overuse this variable based on its apparent value. The
    resulting model then fails to realize that value on new data, and it will not
    predict as well as expected.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中的 AUC 计算表明 `Var200_catB` 在训练数据上看起来“太好”了。任何使用 `dTrain_ treated` 来拟合客户流失模型的模型拟合算法都可能基于其明显的值过度使用这个变量。结果模型将无法在新的数据上实现这个值，并且它的预测效果不会像预期的那样好。
- en: '* * *'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The correct procedure is to not reuse `dTrain` after designing the data treatment
    plan, but instead use `dCal_treated` for model training (although in this case,
    we should use a larger fraction of the available data than we originally allocated).
    With enough data and the right data split (say, 40% data treatment design, 50%
    model training, and 10% model testing/evaluation), this is an effective strategy.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 正确的程序是在设计数据处理计划后不重复使用 `dTrain`，而是使用 `dCal_treated` 进行模型训练（尽管在这种情况下，我们应该使用比最初分配更多的可用数据）。有了足够的数据和正确的数据分割（例如，40%
    数据处理设计，50% 模型训练，10% 模型测试/评估），这是一种有效的策略。
- en: In some cases, we may not have enough data for a good three-way split. The built-in
    `vtreat` cross-validation procedures allow us to use the same training data both
    for designing the data treatment plan and to correctly build models. This is what
    we will master next.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，我们可能没有足够的数据来进行良好的三路分割。内置的 `vtreat` 交叉验证程序允许我们使用相同的训练数据来设计数据处理计划，并正确构建模型。这是我们接下来要掌握的。
- en: 8.4\. Advanced data preparation for classification
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.4\. 高级数据准备用于分类
- en: Now that we have seen how to prepare messy data for classification, let’s work
    through how to do this in a more statistically efficient manner. That is, let’s
    master techniques that let us safely reuse the same data for both designing the
    treatment plan and model training.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了如何为分类准备杂乱的数据，让我们探讨如何以更统计有效的方式进行。也就是说，让我们掌握那些让我们可以安全地重复使用相同数据来设计处理计划和模型训练的技术。
- en: 8.4.1\. Using mkCrossFrameCExperiment()
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.4.1\. 使用 mkCrossFrameCExperiment()
- en: Safely using the same data for data treatment design and for model construction
    is easy using `vtreat`. All we do is use the method `mkCrossFrameCExperiment()`
    instead of `designTreatmentsC()`. The `designTreatmentsC()` method uses cross-validation
    techniques to produce a special *cross-frame* for training instead of using `prepare()`
    on the training data, which we review in [figure 8.6](../Text/08.xhtml#ch08fig06).
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `vtreat` 安全地使用相同的数据进行数据处理设计和模型构建是很容易的。我们所做的只是使用 `mkCrossFrameCExperiment()`
    方法而不是 `designTreatmentsC()` 方法。`designTreatmentsC()` 方法使用交叉验证技术来生成一个特殊的 *交叉帧*
    用于训练，而不是在训练数据上使用 `prepare()`，这一点我们在[图8.6](../Text/08.xhtml#ch08fig06)中进行了回顾。
- en: Figure 8.6\. `vtreat` three-way split strategy again
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.6\. `vtreat` 三路分割策略再次
- en: '![](Images/08fig06_alt.jpg)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/08fig06_alt.jpg)'
- en: The cross-frame is special surrogate training data that behaves as if it hadn’t
    been used to build its own treatment plan. The process is shown in [figure 8.7](../Text/08.xhtml#ch08fig07),
    which we can contrast with [figure 8.6](../Text/08.xhtml#ch08fig06).
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉帧是一种特殊的代理训练数据，其行为就像它没有被用来构建自己的处理计划一样。这个过程在[图8.7](../Text/08.xhtml#ch08fig07)中显示，我们可以将其与[图8.6](../Text/08.xhtml#ch08fig06)进行对比。
- en: Figure 8.7\. `vtreat` cross-frame strategy
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.7\. `vtreat` 交叉帧策略
- en: '![](Images/08fig07_alt.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/08fig07_alt.jpg)'
- en: 'The user-visible parts of the procedures are small and simple. [Figure 8.7](../Text/08.xhtml#ch08fig07)
    only looks complex because `vtreat` is supplying a very sophisticated service:
    the proper cross-validated organization that allows us to safely reuse data for
    both treatment design and model training.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 程序的用户可见部分很小且简单。[图8.7](../Text/08.xhtml#ch08fig07)之所以看起来复杂，是因为 `vtreat` 提供了一个非常复杂的服务：适当的交叉验证组织，这允许我们安全地重复使用数据来进行处理设计和模型训练。
- en: The treatment plan and cross-frame can be built as follows. Here, we use all
    the data that we originally allocated for training and calibration as a single
    training set, `dTrainAll.` Then we will evaluate the data on the test set.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 治疗计划和交叉帧可以按以下方式构建。在这里，我们将最初分配用于训练和校准的所有数据作为一个单独的训练集，`dTrainAll`。然后我们将评估测试集中的数据。
- en: Listing 8.6\. Advanced data preparation for classification
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.6\. 高级数据准备用于分类
- en: '[PRE14]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ❶ We will use the cross-frame to train the logistic regression model.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 我们将使用交叉帧来训练逻辑回归模型。
- en: ❷ Prepares the test set so we can call the model on it
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 准备测试集，以便我们可以对其调用模型
- en: The steps in [listing 8.6](../Text/08.xhtml#ch08ex06) are intentionally very
    similar to those of [listing 8.4](../Text/08.xhtml#ch08ex04). Notice that `dTrainAll_treated`
    is a value returned as part of the experiment, not something we use `prepare()`
    to produce. This overall data treatment strategy implements the ideas of [figure
    8.7](../Text/08.xhtml#ch08fig07).
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表8.6](../Text/08.xhtml#ch08ex06)中的步骤故意与[列表8.4](../Text/08.xhtml#ch08ex04)中的步骤非常相似。请注意，`dTrainAll_treated`
    是作为实验的一部分返回的值，而不是我们使用 `prepare()` 产生的。这种整体数据处理策略实现了[图8.7](../Text/08.xhtml#ch08fig07)中的想法。'
- en: 'Let’s recheck the estimated prediction quality of `Var200` on both the training
    and test sets:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重新检查 `Var200` 在训练集和测试集上的预测质量估计：
- en: '[PRE15]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Notice that the estimated utility of `Var200` on the training data is now much
    closer to its future performance on the test data.^([[10](../Text/08.xhtml#ch08fn10)])
    This means decisions made on the training data have a good chance of being correct
    when later retested on held-out test data or future application data.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`Var200` 在训练数据上的估计效用现在与其在测试数据上的未来性能非常接近.^([[10](../Text/08.xhtml#ch08fn10)])
    这意味着在训练数据上做出的决策在稍后重新测试保留的测试数据或未来的应用数据时，有很大机会是正确的。
- en: ^(10)
  id: totrans-219
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ^(10)
- en: ''
  id: totrans-220
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Remember we are estimating performance from data subject to sampling, so all
    quality estimates are noisy, and we should not consider this observed difference
    to be an issue.
  id: totrans-221
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 记住，我们是从受抽样影响的数据中估计性能的，因此所有质量估计都是嘈杂的，我们不应将观察到的差异视为问题。
- en: 8.4.2\. Building a model
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.4.2\. 构建模型
- en: Now that we have treated our variables, let’s try again to build a model.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经处理了我们的变量，让我们再次尝试构建一个模型。
- en: Variable selection
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 变量选择
- en: A key part of building many variable models is selecting what variables to use.
    Each variable we use represents a chance of explaining more of the outcome variation
    (a chance of building a better model), but also represents a possible source of
    noise and overfitting. To control this effect, we often preselect which subset
    of variables we’ll use to fit. Variable selection can be an important defensive
    modeling step, even for types of models that “don’t need it.” The large number
    of columns typically seen in modern data warehouses can overwhelm even state-of-the-art
    machine learning algorithms.^([[11](../Text/08.xhtml#ch08fn11)])
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 构建许多变量模型的关键部分是选择要使用的变量。我们使用的每个变量都代表解释更多结果变化的机会（构建更好模型的机会），但也代表噪声和过拟合的可能来源。为了控制这种影响，我们通常预先选择我们将用于拟合的变量子集。变量选择可以是一个重要的防御性建模步骤，即使是那些“不需要”这种步骤的模型类型。现代数据仓库中通常看到的列数可能会压倒最先进的机器学习算法.^([[11](../Text/08.xhtml#ch08fn11)])
- en: ^(11)
  id: totrans-226
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ^(11)
- en: ''
  id: totrans-227
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: See [http://www.win-vector.com/blog/2014/02/bad-bayes-an-example-of-why-you-need-hold-out-testing/](http://www.win-vector.com/blog/2014/02/bad-bayes-an-example-of-why-you-need-hold-out-testing/).
  id: totrans-228
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 查看 [http://www.win-vector.com/blog/2014/02/bad-bayes-an-example-of-why-you-need-hold-out-testing/](http://www.win-vector.com/blog/2014/02/bad-bayes-an-example-of-why-you-need-hold-out-testing/)。
- en: '`vtreat` supplies two ways to filter variables: the summary statistics in the
    score frame and also a method called `value_variables_C()`. The summaries in the
    score frame are the qualities of the linear fits of each variable, so they may
    undervalue complex non-linear numeric relationships. In general, you might want
    to try `value_variables_C()` to properly score non-linear relationships. For our
    example, we’ll fit a linear model, so using the simpler score frame method is
    appropriate.^([[12](../Text/08.xhtml#ch08fn12)])'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '`vtreat` 提供了两种过滤变量的方法：评分框架中的汇总统计以及一种称为 `value_variables_C()` 的方法。评分框架中的汇总是每个变量的线性拟合质量，因此它们可能低估了复杂的非线性数值关系。一般来说，你可能想尝试
    `value_variables_C()` 来正确评分非线性关系。对于我们的例子，我们将拟合一个线性模型，因此使用更简单的评分框架方法是合适的.^([[12](../Text/08.xhtml#ch08fn12)])'
- en: ^(12)
  id: totrans-230
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ^(12)
- en: ''
  id: totrans-231
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We share a worked `xgboost` solution at [https://github.com/WinVector/PDSwR2/blob/master/KDD2009/KDD2009vtreat.md](https://github.com/WinVector/PDSwR2/blob/master/KDD2009/KDD2009vtreat.md),
    which achieves similar performance (as measured by AUC) as the linear model. Things
    can be improved, but we appear to be getting into a region of diminishing returns.
  id: totrans-232
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们在 [https://github.com/WinVector/PDSwR2/blob/master/KDD2009/KDD2009vtreat.md](https://github.com/WinVector/PDSwR2/blob/master/KDD2009/KDD2009vtreat.md)
    分享了一个 `xgboost` 的工作解决方案，它在 AUC（曲线下面积）方面与线性模型具有相似的性能。事情可以改进，但我们似乎已经进入了一个收益递减的区域。
- en: 'We are going to filter the variables on significances, but be aware that significance
    estimates are themselves very noisy, and variable selection itself can be a source
    of errors and biases if done improperly.^([[13](../Text/08.xhtml#ch08fn13)]) The
    idea we’ll use is this: assume some columns are in fact irrelevant, and use the
    loosest criterion that would only allow a moderate number of irrelevant columns
    to pass through. We use the loosest condition to try to minimize the number of
    actual useful columns or variables that we may accidentally filter out. Note that,
    while relevant columns should have a significance value close to zero, irrelevant
    columns should have a significance that is uniformly distributed in the interval
    zero through one (this is very closely related to the definition of significance).
    So a good selection filter would be to retain all variables that have a significance
    of no more than `k/nrow(score_frame)`; we would expect only about `k` irrelevant
    variables to pass through such a filter.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将根据显著性过滤变量，但请注意，显著性估计本身非常嘈杂，如果不当进行变量选择，本身也可能成为错误和偏差的来源。[13](../Text/08.xhtml#ch08fn13)]
    我们将使用以下思路：假设某些列实际上是不相关的，并使用最宽松的标准，只允许少量不相关列通过。我们使用最宽松的条件来尽量减少我们可能意外过滤掉的实际有用列或变量的数量。请注意，虽然相关列的显著性值应接近零，但不相关列的显著性应在零到一之间均匀分布（这与显著性的定义非常接近）。因此，一个好的选择过滤器将保留所有显著性不超过`k/nrow(score_frame)`的变量；我们预计只有大约`k`个不相关变量会通过这样的过滤器。
- en: ^(13)
  id: totrans-234
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ^(13)
- en: ''
  id: totrans-235
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A good article on this effect is Freedman, “A note on screening regression equations,”
    *The American Statistician*, volume 37, pp. 152-155, 1983.
  id: totrans-236
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 关于这个效果的优秀文章是Freedman的“关于筛选回归方程的注释”，*《美国统计学家》*，第37卷，第152-155页，1983年。
- en: 'This variable selection can be performed as follows:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 变量选择可以按以下方式进行：
- en: '[PRE16]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ❶ Uses our filter significances at k / nrow (score_frame) heuristic with k =
    1
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用我们的k / nrow(score_frame)启发式方法进行过滤显著性，其中k = 1
- en: ❷ Brings in the dplyr package to help summarize the selections
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 引入dplyr包以帮助总结选择
- en: The table shows for each converted variable type how many variables were selected
    or rejected. In particular, notice that almost all the variables of type `clean`
    (which is the code for cleaned up numeric variables) are discarded as being unusable.
    This is possible evidence that linear methods may not be sufficient for this problem,
    and that we should consider non-linear models instead. In this case, you might
    use `value_variables_C()` (which returns a structure similar to the score frame)
    to select variables, and also use the advanced non-linear machine learning methods
    of [chapter 10](../Text/10.xhtml#ch10). In this chapter, we are focusing on the
    variable preparation steps, so we will only build a linear model, and leave trying
    different modeling techniques as an important exercise for the reader.^([[14](../Text/08.xhtml#ch08fn14)])
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 表格显示了对于每种转换后的变量类型，选择了多少个变量或被拒绝。特别是，请注意，几乎所有的`clean`类型变量（这是清理后的数值变量的代码）都被丢弃，因为它们不可用。这可能表明线性方法可能不足以解决这个问题，我们应该考虑使用非线性模型。在这种情况下，你可以使用`value_variables_C()`（它返回一个类似于得分框架的结构）来选择变量，并使用[第10章](../Text/10.xhtml#ch10)中提到的先进的非线性机器学习方法。在本章中，我们专注于变量准备步骤，因此我们只构建一个线性模型，将尝试不同的建模技术作为读者的重要练习。[14](../Text/08.xhtml#ch08fn14)]
- en: ^(14)
  id: totrans-242
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ^(14)
- en: ''
  id: totrans-243
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Though we do share a worked `xgboost` solution here: [https://github.com/WinVector/PDSwR2/blob/master/KDD2009/KDD2009vtreat.md](https://github.com/WinVector/PDSwR2/blob/master/KDD2009/KDD2009vtreat.md).'
  id: totrans-244
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 尽管我们在这里提供了一个工作的`xgboost`解决方案：[https://github.com/WinVector/PDSwR2/blob/master/KDD2009/KDD2009vtreat.md](https://github.com/WinVector/PDSwR2/blob/master/KDD2009/KDD2009vtreat.md)。
- en: Building a multivariable model
  id: totrans-245
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 构建多变量模型
- en: Once we have our variables ready to go, building the model seems relatively
    straightforward. For this example, we will use a logistic regression (the topic
    of [section 7.2](../Text/07.xhtml#ch07lev1sec2)). The code to fit the multivariable
    model is given in the next listing.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们的变量准备就绪，构建模型似乎相对直接。在这个例子中，我们将使用逻辑回归（[第7.2节](../Text/07.xhtml#ch07lev1sec2)的主题）。拟合多变量模型的代码将在下一列表中给出。
- en: Listing 8.7\. Basic variable recoding and selection
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.7\. 基本变量重新编码和选择
- en: '[PRE17]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: ❶ Builds a formula specifying modeling churn == 1 as a function of all variables
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 构建一个公式，指定建模流失 == 1是所有变量的函数
- en: ❷ Uses the modeling formula with R’s glm() function
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用R的glm()函数建模公式
- en: '❸ Take heed of this warning: it is hinting we should move on to a regularized
    method such as glmnet.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 注意这个警告：它暗示我们应该转向正则化方法，如glmnet。
- en: Evaluating the model
  id: totrans-252
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 评估模型
- en: 'Now that we have a model, let’s evaluate it on our test data:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了模型，让我们在测试数据上评估它：
- en: '[PRE18]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ❶ Adds the model prediction to the evaluation data as a new column
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将模型预测添加到评估数据作为新列
- en: '❷ Again, take heed of this warning: it is hinting we should move on to a regularized
    method such as glmnet.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 再次注意这个警告：它暗示我们应该转向正则化方法，如glmnet。
- en: ❸ Calculates the AUC of the model on holdout data
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 在保留数据上计算模型的AUC
- en: ❹ Calculates the AUC a second time, using an alternative method that also estimates
    a standard deviation or error bar
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 使用另一种估计标准差或误差条的方法，第二次计算AUC
- en: ❺ Here we calculate the best single variable model AUC for comparison.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 在这里，我们计算最佳单变量模型AUC以进行比较。
- en: The model’s AUC is 0.72\. This is not as good as the winning entry’s 0.76 (on
    different test data), but much better than the quality of the best input variable
    treated as a single variable model (which showed an AUC of 0.59). Keep in mind
    that the `perm-TestAUC()` calculation indicated a standard deviation of the AUC
    estimate of 0.015 for a test set of this size. This means a difference of plus
    or minus 0.015 in AUC is not statistically significant.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的AUC为0.72。这不如获胜者的0.76（在不同的测试数据上），但比最佳输入变量作为单变量模型的AUC（显示为0.59）要好得多。请记住，`perm-TestAUC()`计算表明，对于这个大小的测试集，AUC估计的标准差为0.015。这意味着AUC的加减0.015的差异在统计学上并不显著。
- en: Turning the logistic regression model into a classifier
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 将逻辑回归模型转换为分类器
- en: 'As we can see from the double density plot of the model’s scores ([figure 8.8](../Text/08.xhtml#ch08fig08)),
    this model only does a moderate job of separating accounts that churn from those
    that don’t. If we made the mistake of using this model as a hard classifier where
    all individuals with a predicted churn propensity above 50% are considered at
    risk, we would see the following awful performance:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们从模型分数的双密度图（[图8.8](../Text/08.xhtml#ch08fig08)）中可以看出，该模型在区分流失账户和非流失账户方面只做了中等的工作。如果我们犯了一个错误，将这个模型用作硬分类器，其中所有预测流失倾向超过50%的个体都被认为是风险，我们会看到以下糟糕的性能：
- en: Figure 8.8\. Distribution of the `glm` model’s scores on test data
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.8. `glm`模型在测试数据上的分数分布
- en: '![](Images/08fig08_alt.jpg)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/08fig08_alt.jpg)'
- en: '[PRE19]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The model only identifies nine individuals with such a high probability, and
    only one of those churn. Remember this was an unbalanced classification problem;
    only 7.6% of the test examples do in fact churn. What the model can identify is
    individuals at an elevated risk of churning, not those that will certainly churn.
    For example, what if we ask the model for the individuals that are predicted to
    have double the expected churn risk:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型仅识别出9个具有如此高概率的个人，其中只有1个流失。记住这是一个不平衡的分类问题；只有7.6%的测试示例实际上流失。模型可以识别出处于较高流失风险的个体，而不是那些肯定会流失的个体。例如，如果我们要求模型找出预测流失风险是预期流失风险两倍的个体：
- en: '[PRE20]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Notice that in this case, using 0.15 as our scoring threshold, the model identified
    466 potentially at-risk accounts, of which 101 did in fact churn. This subset
    therefore has a churn rate of 24%, or about 3 times the overall churn rate. And
    this model identified 110 of the 376 churners, or 29% of them. From a business
    point of view, this model is identifying a 10% subgroup of the population that
    is responsible for 29% of the churning. This can be useful.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在这种情况下，使用0.15作为我们的评分阈值，模型识别出466个潜在风险账户，其中101个实际上已经流失。因此，这个子集的流失率为24%，大约是整体流失率的3倍。并且，该模型识别出376个流失者中的110个，即29%。从商业角度来看，这个模型正在识别出占人口10%的子群体，他们负责29%的流失。这可能很有用。
- en: In [section 7.2.3](../Text/07.xhtml#ch07lev2sec9), we saw how to present the
    family of trade-offs between recall (what fraction of the churners are detected)
    and enrichment or lift (how much more common churning is in the selected set)
    as a graph. [Figure 8.9](../Text/08.xhtml#ch08fig09) shows the plot of recall
    and enrichment as a function of threshold for the churn model.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第7.2.3节](../Text/07.xhtml#ch07lev2sec9)中，我们看到了如何将召回率（检测到的流失者占流失者的比例）和富集或提升（在所选集中流失的频率有多高）之间的权衡关系表示为图表。[图8.9](../Text/08.xhtml#ch08fig09)显示了流失模型中召回率和富集作为阈值的函数的图。
- en: Figure 8.9\. `glm` recall and enrichment as a function of threshold
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.9. `glm`召回率和富集作为阈值的函数
- en: '![](Images/08fig09_alt.jpg)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/08fig09_alt.jpg)'
- en: One way to use [figure 8.9](../Text/08.xhtml#ch08fig09) is to draw a vertical
    line at a chosen x-axis threshold, say 0.2\. Then the height at which this vertical
    line crosses each curve tells us the simultaneous enrichment and recall we would
    see if we classify scores above our threshold as positive. In this case, we would
    have a recall of around 0.12 (meaning we identify about 12% of the at-risk accounts),
    and an enrichment of around 3 (meaning the population we warn about has an account
    cancellation rate of 3 times the general population, indicating this is indeed
    an enhanced-risk population).
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[图8.9](../Text/08.xhtml#ch08fig09)的一种方法是，在选择的x轴阈值处画一条垂直线，比如0.2。然后这条垂直线与每条曲线交叉的高度告诉我们，如果我们把高于阈值的分数分类为阳性，我们会看到的同时丰富度和召回率。在这种情况下，我们的召回率大约为0.12（意味着我们识别了大约12%的受风险账户），丰富度大约为3（意味着我们警告的群体账户取消率是普通群体的3倍，这表明这确实是一个高风险群体）。
- en: 'The code to produce these charts looks like this:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 生成这些图表的代码看起来像这样：
- en: '[PRE21]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: And now we have worked a substantial classification problem using `vtreat`.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经使用`vtreat`解决了一个实质性的分类问题。
- en: 8.5\. Preparing data for regression modeling
  id: totrans-276
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.5\. 为回归建模准备数据
- en: Preparing data for regression is very similar to preparing data for classification.
    Instead of calling `designTreatmentsC()` or `mkCrossFrameCExperiment()`, we call
    `designTreatmentsN()` or `mkCrossFrameNExperiment()`.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 为回归建模准备数据与为分类建模准备数据非常相似。我们不是调用`designTreatmentsC()`或`mkCrossFrameCExperiment()`，而是调用`designTreatmentsN()`或`mkCrossFrameNExperiment()`。
- en: '* * *'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Example
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '*You wish to predict automobile fuel economy stated in miles per gallon from
    other facts about cars, such as weight and horsepower.*'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '*您希望根据汽车的其他事实（如重量和马力）预测每加仑英里数的汽车燃油经济性。*'
- en: '* * *'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: To simulate this scenario, we will use the Auto MPG Data Set from the UCI Machine
    Learning Repository. We can load this data from the file auto_mpg.RDS in the directory
    `auto_mpg/` of [https://github.com/WinVector/PDSwR2/](https://github.com/WinVector/PDSwR2/)
    (after downloading this repository).
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟这种情况，我们将使用来自UCI机器学习仓库的Auto MPG数据集。我们可以从`auto_mpg/`目录中的`auto_mpg.RDS`文件加载此数据（在下载此存储库后）。
- en: '[PRE22]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: ❶ Take a quick look at the data.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 快速查看数据。
- en: 'Having glanced at the data in [figure 8.10](../Text/08.xhtml#ch08fig10), let’s
    take the “bull in the china shop” approach to modeling, and directly call `lm()`
    without examining or treating the data:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 看过[图8.10](../Text/08.xhtml#ch08fig10)中的数据后，让我们采取“闯入瓷器店的大象”的方法进行建模，直接调用`lm()`函数，而不检查或处理数据：
- en: Figure 8.10\. The first few rows of the `auto_mpg` data
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.10\. `auto_mpg`数据的前几行
- en: '![](Images/08fig10_alt.jpg)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/08fig10_alt.jpg)'
- en: '[PRE23]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: ❶ Jump into modeling without bothering to treat the data.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在不处理数据的情况下直接跳入建模。
- en: ❷ Adds the model predictions as a new column
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 添加模型预测作为新列
- en: ❸ Notice that these cars do not have a recorded horsepower.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 注意，这些汽车没有记录马力。
- en: ❹ So these cars do not get a prediction.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 因此，这些汽车没有获得预测。
- en: 'Because the dataset had missing values, the model could not return a prediction
    for every row. Now, we’ll try again, using `vtreat` to treat the data first:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据集有缺失值，模型无法为每一行返回预测。现在，我们将再次尝试，使用`vtreat`先处理数据：
- en: '[PRE24]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: ❶ Try it again with vtreat data preparation.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 再次尝试使用vtreat数据准备。
- en: ❷ Now we can make predictions, even for items that have missing data.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 现在我们可以进行预测，即使是对有缺失数据的项。
- en: Now, the model returns a prediction for every row, including those with missing
    data.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，模型为每一行返回预测，包括那些有缺失数据的行。
- en: 8.6\. Mastering the vtreat package
  id: totrans-298
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.6\. 掌握vtreat包
- en: Now that we have seen how to use the `vtreat` package, we will take some time
    to review what the package is doing for us. This is easiest to see with toy-sized
    examples.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了如何使用`vtreat`包，我们将花一些时间来回顾这个包为我们做了什么。这可以通过玩具大小的例子最容易地看到。
- en: '`vtreat` is designed to prepare data for supervised machine learning or predictive
    modeling. The package is designed to help with the task of relating a bunch of
    input or explanatory variables to a single output to be predicted or to a dependent
    variable.'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '`vtreat`旨在为监督机器学习或预测建模准备数据。该包旨在帮助将一组输入或解释变量与单个要预测的输出或因变量相关联。'
- en: 8.6.1\. The vtreat phases
  id: totrans-301
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.6.1\. vtreat阶段
- en: 'As illustrated in [figure 8.11](../Text/08.xhtml#ch08fig11), `vtreat` works
    in two phases: a design phase and an application/prepare phase. In the design
    phase, `vtreat` learns details of your data. For each explanatory variable, it
    estimates the variable’s relationship to the outcome, so both the explanatory
    variables and the dependent variable must be available. In the application phase,
    `vtreat` introduces new variables that are derived from the explanatory variables,
    but are better suited for simple predictive modeling. The transformed data is
    all numeric and has no missing values.^([[15](../Text/08.xhtml#ch08fn15)]) R itself
    has methods for dealing with missing values, including many missing value imputation
    packages.^([[16](../Text/08.xhtml#ch08fn16)]) R also has a canonical method to
    convert arbitrary `data.frame`s to numeric data: `model.matrix()`, which many
    models use to accept arbitrary data. `vtreat` is a specialized tool for these
    tasks that is designed to work very well for supervised machine learning or predictive
    modeling tasks.'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图8.11](../Text/08.xhtml#ch08fig11)所示，`vtreat`在两个阶段工作：设计阶段和应用/准备阶段。在设计阶段，`vtreat`学习数据的细节。对于每个解释变量，它估计变量与结果之间的关系，因此解释变量和因变量都必须可用。在应用阶段，`vtreat`引入了从解释变量派生的新变量，但更适合简单的预测建模。转换后的数据都是数值型且没有缺失值.^([[15](../Text/08.xhtml#ch08fn15)])
    R本身有处理缺失值的方法，包括许多缺失值插补包.^([[16](../Text/08.xhtml#ch08fn16)]) R还有一个将任意`data.frame`转换为数值数据的规范方法：`model.matrix()`，许多模型都使用它来接受任意数据。`vtreat`是专门为这些任务设计的工具，旨在为监督机器学习或预测建模任务提供非常好的效果。
- en: ^(15)
  id: totrans-303
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ^(15)
- en: ''
  id: totrans-304
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Remember: missing values are not the only thing that can go wrong with the
    data, and not the only point `vtreat` addresses.'
  id: totrans-305
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 记住：缺失值不是数据可能出错的所有情况，也不是`vtreat`唯一解决的问题。
- en: ^(16)
  id: totrans-306
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ^(16)
- en: ''
  id: totrans-307
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: See [https://cran.r-project.org/web/views/MissingData.html](https://cran.r-project.org/web/views/MissingData.html).
  id: totrans-308
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 查看[https://cran.r-project.org/web/views/MissingData.html](https://cran.r-project.org/web/views/MissingData.html)。
- en: Figure 8.11\. The two `vtreat` phases
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.11\. `vtreat`的两个阶段
- en: '![](Images/08fig11_alt.jpg)'
  id: totrans-310
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/08fig11_alt.jpg)'
- en: 'For the treatment-design phase, call one of the following functions:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 对于处理设计阶段，调用以下函数之一：
- en: '***`designTreatmentsC()`—*** Designs a variable treatment plan for a binary
    classification task. A binary classification task is where we want to predict
    if an example is in a given category, or predict the probability that an example
    is in the given category.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***`designTreatmentsC()`—*** 设计一个用于二元分类任务的变量处理计划。二元分类任务是我们想要预测一个示例是否属于给定类别，或者预测一个示例属于给定类别的概率。'
- en: '***`designTreatmentsN()`—*** Designs a variable treatment plan for a regression
    task. A regression task predicts a numeric outcome, given example numeric outcomes.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***`designTreatmentsN()`—*** 设计一个用于回归任务的变量处理计划。回归任务是在给定示例数值结果的情况下预测数值结果。'
- en: '***`designTreatmentsZ()`—*** Designs a simple variable treatment plan that
    does not look at the training data outcomes. This plan deals with missing values
    and recodes strings as indicator variables (one-hot encoding), but it does not
    produce impact variables (which require knowledge of the training data outcomes).'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***`designTreatmentsZ()`—*** 设计一个简单的变量处理计划，不查看训练数据的结果。此计划处理缺失值并将字符串重新编码为指示变量（独热编码），但不产生影响变量（这需要了解训练数据的结果）。'
- en: '***`design_missingness_treatment()`—*** Designs a very simple treatment that
    only deals with missing values, but does not one-hot encode categorical variables.
    Instead, it replaces `NA` with the token `"_invalid_"`.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***`design_missingness_treatment()`—*** 设计一个非常简单的处理方案，仅处理缺失值，但不进行独热编码分类变量。相反，它将`NA`替换为标记`"_invalid_"`。'
- en: '***`mkCrossFrameCExperiment()`—*** Prepares data for classification, using
    a cross-validation technique so the data used to design the variable treatment
    can be safely reused to train the model.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***`mkCrossFrameCExperiment()`—*** 使用交叉验证技术准备用于分类的数据，这样设计变量处理所使用的数据可以安全地重新用于训练模型。'
- en: '***`mkCrossFrameNExperiment()`—*** Prepares data for regression, using a cross-validation
    technique so the data used to design the variable treatment can be safely reused
    to train the model.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***`mkCrossFrameNExperiment()`—*** 使用交叉验证技术准备用于回归的数据，这样设计变量处理所使用的数据可以安全地重新用于训练模型。'
- en: For the application or data preparation phase, we always call the `prepare()`
    method.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 对于应用或数据准备阶段，我们始终调用`prepare()`方法。
- en: The `vtreat` package comes with a large amount of documentation and examples
    that can be found at [https://winvector.github.io/vtreat/](https://winvector.github.io/vtreat/).
    However, in addition to knowing how to operate the package, it is critical that
    data scientists know what the packages they use are doing for them. So we will
    discuss what `vtreat` actually does here.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '`vtreat` 包附带大量文档和示例，可以在 [https://winvector.github.io/vtreat/](https://winvector.github.io/vtreat/)
    找到。然而，除了了解如何操作包之外，数据科学家还必须知道他们使用的包为他们做了什么。因此，我们将在这里讨论 `vtreat` 实际上做了什么。'
- en: 'The concepts we need to review include these:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要回顾的概念包括以下这些：
- en: Missing values
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺失值
- en: Indicator variables
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指示变量
- en: Impact coding
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 影响编码
- en: The treatment plan
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 治疗计划
- en: The variable score frame
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变量得分框架
- en: The cross-frame
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跨框架
- en: These are a lot of concepts, but they are key to data repair and preparation.
    We will keep this concrete by working specific, but tiny, examples. Larger examples
    showing the performance of these can be found at [https://arxiv.org/abs/1611.09477](https://arxiv.org/abs/1611.09477).
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 这些概念很多，但它们是数据修复和准备的关键。我们将通过具体但微小的例子来保持具体性。可以在此处找到展示这些方法性能的更大例子：[https://arxiv.org/abs/1611.09477](https://arxiv.org/abs/1611.09477)。
- en: 8.6.2\. Missing values
  id: totrans-328
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.6.2\. 缺失值
- en: 'As we have discussed before, R has a special code for values that are missing,
    not known, or not available: `NA`. Many modeling procedures will not accept data
    with missing values, so if they occur, we must do something about them. The common
    strategies include these:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前讨论的，R 有一个特殊的代码用于缺失、未知或不可用的值：`NA`。许多建模过程不接受带有缺失值的数据，因此如果出现缺失值，我们必须采取一些措施。常见的策略包括以下这些：
- en: '***Restricting down to “complete cases”—*** Using only the data rows where
    no columns have missing values. This can be problematic for model training, as
    the complete cases may not be distributed the same or representative of the actual
    dataset. Also, this strategy does not give a good idea of how to score new data
    that has missing values. There are some theories about how to reweight data to
    make it more representative, but we do not encourage these methods.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***限制为“完整案例”—*** 只使用没有缺失值的列的数据行。这对于模型训练可能是个问题，因为完整案例可能分布不均或不具有代表性，实际数据集。此外，这种策略也无法很好地说明如何评分具有缺失值的新数据。有一些关于如何重新加权数据使其更具代表性的理论，但我们不鼓励这些方法。'
- en: '***Missing-value imputation—*** These are methods that use the non-missing
    values to infer or impute values (or distributions of values) for the missing
    values. An R task view dedicated to these methods can be found at [https://cran.r-project.org/web/views/MissingData.html](https://cran.r-project.org/web/views/MissingData.html).'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***缺失值插补—*** 这些是使用非缺失值来推断或插补缺失值（或值的分布）的方法。可以在 [https://cran.r-project.org/web/views/MissingData.html](https://cran.r-project.org/web/views/MissingData.html)
    找到专门针对这些方法的 R 任务视图。'
- en: '***Using models that tolerate missing values—*** Some implementations of decision
    trees or random forests can tolerate missing values.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***使用可以容忍缺失值的模型—*** 一些决策树或随机森林的实现可以容忍缺失值。'
- en: '***Treating missingness as observable information—*** Replacing missing values
    with stand-in information.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***将缺失性视为可观察信息—*** 用替代信息替换缺失值。'
- en: '`vtreat` supplies an implementation of the last idea (treating missingness
    as observable information), as this is easy to do and very suitable for supervised
    machine learning or predictive modeling. The idea is simple: the missing values
    are replaced with some stand-in value (it can be zero, or it can be the average
    of the non-missing values), and an extra column is added to indicate this replacement
    has taken place. This extra column gives any modeling step an extra degree of
    freedom, or the ability to treat the imputed values separately from not-imputed
    values.'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: '`vtreat` 提供了将缺失性视为可观察信息的最后一种方法的实现，因为这很容易做到，并且非常适合监督机器学习或预测建模。这个想法很简单：缺失值被替换为某个替代值（可以是零，也可以是非缺失值的平均值），并添加一个额外的列来指示这种替换已经发生。这个额外的列给任何建模步骤提供了额外的自由度，或者说是将插补值与未插补值分开处理的能力。'
- en: 'The following is a simple example showing the addition of the transformation:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个简单示例，展示了变换的添加：
- en: '[PRE25]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: ❶ Brings in the wrapr package for build_frame and the wrapr “dot pipe”
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 引入 wrapr 包用于 build_frame 和 wrapr 的“点管道”
- en: ❷ Using wrapr’s dot pipe instead of magrittr’s forward pipe. The dot pipe requires
    the explicit dot argument notation discussed in [chapter 5](../Text/05.xhtml#ch05).
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用wrapr的点管道而不是magrittr的前向管道。点管道需要显式点参数符号，这在[第5章](../Text/05.xhtml#ch05)中讨论过。
- en: Notice that in [figure 8.12](../Text/08.xhtml#ch08fig12) the `x1` column has
    the missing value, and that value is replaced in [figure 8.13](../Text/08.xhtml#ch08fig13)
    by a stand-in value, the average of the known values. The treated or prepared
    data (see [figure 8.13](../Text/08.xhtml#ch08fig13)) also has a new column, `x1_isBAD`,
    indicating where `x1` was replaced. Finally, notice that for the string-valued
    column `x2`, the `NA` value is replaced with a special level code.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到在[图8.12](../Text/08.xhtml#ch08fig12)中`x1`列有缺失值，并且在[图8.13](../Text/08.xhtml#ch08fig13)中用已知值的平均值替换了该值。处理后的或准备好的数据（见[图8.13](../Text/08.xhtml#ch08fig13)）还有一个新列，`x1_isBAD`，表示`x1`被替换的位置。最后，注意对于字符串值列`x2`，`NA`值被替换为一个特殊的级别代码。
- en: 'Figure 8.12\. Our simple example data: raw'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.12\. 我们简单的示例数据：原始的
- en: '![](Images/08fig12.jpg)'
  id: totrans-341
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/08fig12.jpg)'
- en: 'Figure 8.13\. Our simple example data: treated'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.13\. 我们简单的示例数据：处理后的
- en: '![](Images/08fig13.jpg)'
  id: totrans-343
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/08fig13.jpg)'
- en: 8.6.3\. Indicator variables
  id: totrans-344
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.6.3\. 指示变量
- en: Many statistical and machine learning procedures expect all variables to be
    numeric. Some R users may not be aware of this, as many R model implementations
    call `model .matrix()` under the covers to convert arbitrary data to numeric data.
    For real-world projects, we advise using a more controllable explicit transformation
    such as `vtreat`.^([[17](../Text/08.xhtml#ch08fn17)])
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 许多统计和机器学习程序都期望所有变量都是数值型的。一些R用户可能没有意识到这一点，因为许多R模型实现都在幕后调用`model.matrix()`将任意数据转换为数值数据。对于现实世界的项目，我们建议使用更可控的显式转换，例如`vtreat`.^([[17](../Text/08.xhtml#ch08fn17)])
- en: ^(17)
  id: totrans-346
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ^(17)
- en: ''
  id: totrans-347
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: However, in this book, for didactic purposes, we will try to minimize the number
    of preparation steps in each example when these steps are not the subject being
    discussed.
  id: totrans-348
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 然而，在这本书中，为了教学目的，我们将尽量减少每个例子中不必要的准备步骤，因为这些步骤不是讨论的主题。
- en: 'This transformation goes by a number of names, including indicator variables,
    dummy variables, and one-hot encoding. The idea is this: for each possible value
    of a string-valued variable, we create a new data column. We set each of these
    new columns to `1` when the string-valued variable has a value matching the column
    label, and zero otherwise. This is easy to see in the following example:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 这种转换有多个名称，包括指示变量、虚拟变量和独热编码。其思路是这样的：对于字符串值变量的每个可能值，我们创建一个新的数据列。当字符串值变量具有与列标签匹配的值时，我们将这些新列中的每个设置为`1`，否则为`0`。以下示例中可以很容易地看到这一点：
- en: '[PRE26]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: ❶ The second value of x2 is b.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ x2的第二个值是b。
- en: ❷ In the second row of the treated data, x2_lev_x_b = 1.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在处理数据的第二行中，x2_lev_x_b = 1。
- en: Notice that `x2_lev_x_b` is `1` in the second prepared data row. This is how
    the transformed data retains the information that the `x2` variable originally
    had the value of `b` in this row.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到在第二个准备好的数据行中`x2_lev_x_b`是`1`。这就是转换后的数据如何保留`x2`变量在这个行中原本的值为`b`的信息。
- en: As we saw in the discussions of `lm()` and `glm()` in [chapter 7](../Text/07.xhtml#ch07),
    it is traditional statistical practice to not actually reserve a new column for
    one possible level of the string-valued variable. This level is called the *reference
    level*. We can identify rows where the string-valued variable was equal to the
    reference level, as all the other level columns are zero in such rows (other rows
    have exactly one 1 in the level columns). For supervised learning in general,
    and especially for advanced techniques such as regularized regression, we recommend
    encoding all levels, as seen here.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第7章](../Text/07.xhtml#ch07)中关于`lm()`和`glm()`的讨论中看到的，在传统统计实践中，实际上并不为字符串值变量的一个可能级别保留一个新列。这个级别被称为*参考级别*。我们可以识别字符串值变量等于参考级别的行，因为在这样的行中，所有其他级别的列都是零（其他行在级别列中恰好有一个`1`）。对于一般的监督学习，特别是对于正则化回归等高级技术，我们建议编码所有级别，正如这里所看到的。
- en: 8.6.4\. Impact coding
  id: totrans-355
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.6.4\. 影响编码
- en: Impact coding is a good idea that gets rediscovered often under different names
    (*effects* coding, *impact* coding, and more recently *target* encoding).^([[18](../Text/08.xhtml#ch08fn18)])
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 影响编码是一个经常在不同名称下被重新发现的好主意（*效果*编码、*影响*编码，以及最近更常见的*目标*编码）.^([[18](../Text/08.xhtml#ch08fn18)])
- en: ^(18)
  id: totrans-357
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ^(18)
- en: ''
  id: totrans-358
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The earliest discussion we can find on effects coding is Robert E. Sweeney and
    Edwin F. Ulveling, “A Transformation for Simplifying the Interpretation of Coefficients
    of Binary Variables in Regression Analysis.” *The American Statistician*, 26(5),
    30–32, 1972\. We, the authors, have produced research and popularized the methodology
    among R and Kaggle users, adding key cross-validation methods similar to a method
    called “stacking” [https://arxiv.org/abs/1611.09477](https://arxiv.org/abs/1611.09477).
  id: totrans-359
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们能找到的关于影响编码的最早讨论是Robert E. Sweeney和Edwin F. Ulveling的“用于简化回归分析中二元变量系数解释的转换。”
    *《美国统计学家》*，第26卷(5)，30–32，1972年。我们，即作者，已经产生了研究并在R和Kaggle用户中推广了该方法，并添加了类似于“堆叠”方法的关键交叉验证方法[https://arxiv.org/abs/1611.09477](https://arxiv.org/abs/1611.09477)。
- en: 'When a string-valued variable has thousands of possible values or levels, producing
    a new indicator column for each possible level causes extreme data expansion and
    overfitting (if the model fitter can even converge in such situations). So instead
    we use an *impact code*: replacing the level code with its effect as a single-variable
    model. This is what produced derived variables of type `catB` in our KDD2009 credit
    account cancellation example, and produced `catN`-style variables in the case
    of regression.'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个字符串类型的变量有数千个可能的值或级别时，为每个可能的级别生成一个新的指标列会导致数据极度膨胀和过拟合（如果模型拟合器在这种情况下甚至可以收敛）。因此，我们使用一个*影响代码*：将级别代码替换为其作为单一变量模型的效果。这就是我们在KDD2009信用账户取消示例中产生`catB`类型派生变量的原因，以及在回归情况下产生`catN`风格变量的原因。
- en: 'Let’s see the effect of a simple numeric prediction or regression example:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个简单的数值预测或回归示例的影响：
- en: '[PRE27]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The impact-coded variable is in the new column named `x2_catN`. Notice that
    in the first row it is `-10`, as the `y`-value is `10`, which is 10 below the
    average value of `y`. This encoding of “conditional delta from mean” is where
    names like “impact code” or “effect code” come from.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 影响编码的变量位于名为`x2_catN`的新列中。注意，在第一行它为`-10`，因为`y`的值是`10`，这比`y`的平均值低10。这种“条件delta从均值”的编码就是“影响代码”或“效果代码”名称的由来。
- en: 'The impact coding for categorical variables is similar, except they are in
    logarithmic units, just like the logistic regression in [section 8.3.1](../Text/08.xhtml#ch08lev2sec3).
    In this case, for data this small, the naive value of `x2_catB` would be minus
    infinity in rows 1 and 3, and plus infinity in row 2 (as the `x2` level values
    perfectly predict or separate cases whether `y == 20` or not). The fact that we
    see values near plus or minus `10` is due to an important adjustment called *smoothing*
    which says when computing conditional probabilities, add a little bias towards
    “no effect” for safer calculations.^([[19](../Text/08.xhtml#ch08fn19)]) An example
    of using `vtreat` to prepare data for a possible classification task is given
    next:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分类变量的影响编码类似，只是它们是以对数单位表示的，就像[第8.3.1节](../Text/08.xhtml#ch08lev2sec3)中的逻辑回归一样。在这种情况下，对于如此小的数据，`x2_catB`的初始值在第一行和第三行将是负无穷大，在第二行是正无穷大（因为`x2`级别值完美地预测或区分`y
    == 20`的情况）。我们看到接近正负`10`的值是由于一个重要的调整，称为*平滑*，它说在计算条件概率时，为了更安全的计算，添加一点偏向“无效果”的偏差.^([[19](../Text/08.xhtml#ch08fn19)])
    下一个示例将展示如何使用`vtreat`为可能的分类任务准备数据：
- en: ^(19)
  id: totrans-365
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ^(19)
- en: ''
  id: totrans-366
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'A reference on smoothing can be found here: [https://en.wikipedia.org/wiki/Additive_smoothing](https://en.wikipedia.org/wiki/Additive_smoothing).'
  id: totrans-367
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 关于平滑的参考资料可以在这里找到：[https://en.wikipedia.org/wiki/Additive_smoothing](https://en.wikipedia.org/wiki/Additive_smoothing)。
- en: '[PRE28]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '* * *'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '**Smoothing**'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: '**平滑**'
- en: Smoothing is a method to prevent some degree of overfit and nonsense answers
    on small data. The idea of smoothing is an attempt to obey *Cromwell’s rule* that
    no probability estimate of zero should ever be used in empirical probabilistic
    reasoning. This is because if you’re combining probabilities by multiplication
    (the most common method of combining probability estimates), then once some term
    is 0, the entire estimate will be 0 *no matter what the values of the other terms
    are*. The most common form of smoothing is called *Laplace smoothing*, which counts
    `k` successes out of `n` trials as a success ratio of `(k+1)/(n+1)` and not as
    a ratio of `k/n` (defending against the `k=0` case). Frequentist statisticians
    think of smoothing as a form of regularization, and Bayesian statisticians think
    of smoothing in terms of priors.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 平滑是一种防止在小数据上出现一定程度过拟合和胡说八道答案的方法。平滑的想法是试图遵守 *Cromwell’s rule*，即在任何经验概率推理中不应使用零概率估计。这是因为如果你通过乘法（结合概率估计的最常见方法）组合概率，那么一旦某个项为
    0，整个估计将变为 0 *无论其他项的值如何*。最常见形式的平滑称为 *Laplace 平滑*，它将 `n` 次试验中的 `k` 次成功计为一个成功比率 `(k+1)/(n+1)`，而不是
    `k/n` 的比率（防御 `k=0` 的情况）。频率派统计学家认为平滑是一种正则化的形式，而贝叶斯派统计学家认为平滑是从先验的角度来看。
- en: '* * *'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 8.6.5\. The treatment plan
  id: totrans-373
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.6.5\. 治疗方案
- en: 'The treatment plan specifies how training data will be processed before using
    it to fit a model, and how new data will be processed before applying the model.
    It is returned directly by the `design*()` methods. For the `mkExperiment*()`
    methods, the treatment plan is the item with the key `treatments` on the returned
    result. The following code shows the structure of a treatment plan:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 治疗方案指定了在用其拟合模型之前如何处理训练数据，以及在使用模型之前如何处理新数据。它直接由 `design*()` 方法返回。对于 `mkExperiment*()`
    方法，治疗方案是返回结果中键为 `treatments` 的项目。以下代码显示了治疗方案的结构：
- en: '[PRE29]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The variable score frame
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 变量分数框架
- en: 'An important item included in all treatment plans is the score frame. It can
    be pulled out of a treatment plan as follows (continuing our earlier example):'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 所有治疗方案中都包含的一个重要项目是分数框架。可以从治疗方案中提取出来，如下所示（继续我们之前的例子）：
- en: '[PRE30]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The score frame is a `data.frame` with one row per derived explanatory variable.
    Each row shows which original variable the derived variable was produced from
    (`orig-Name`), what type of transform was used to produce the derived variable
    (`code`), and some quality summaries about the variable. For instance, `needsSplit`
    is an indicator that, when `TRUE`, indicates the variable is complex and requires
    cross-validated scoring, which is in fact how `vtreat` produces the variable quality
    estimates.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 分数框架是一个每行一个派生解释变量的 `data.frame`。每一行显示派生变量是从哪个原始变量派生出来的 (`orig-Name`)，用于生成派生变量的转换类型
    (`code`)，以及关于变量的某些质量摘要。例如，`needsSplit` 是一个指示符，当 `TRUE` 时，表示变量复杂且需要交叉验证评分，这正是 `vtreat`
    生成变量质量估计的方法。
- en: 8.6.6\. The cross-frame
  id: totrans-380
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.6.6\. 交叉框架
- en: 'A critical innovation of `vtreat` is the *cross-frame*. The cross-frame is
    an item found in the list of objects returned by the `mkCrossFrame*Experiment()`
    methods. It is an innovation that allows the safe use of the same data both for
    the design of the variable treatments and for training a model. Without this cross-validation
    method, you must reserve some of the training data to build the variable treatment
    plan and a disjoint set of training data to fit treated data. Otherwise, the composite
    system (data preparation plus model application) may suffer from severe nested
    model bias: producing a model that appears good on training data, but later fails
    on test or application data.'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: '`vtreat` 的一个关键创新是 *交叉框架*。交叉框架是 `mkCrossFrame*Experiment()` 方法返回的对象列表中的一个项目。这是一个允许安全地使用相同数据既用于变量处理的设计又用于训练模型的创新。如果没有这种交叉验证方法，你必须保留一部分训练数据来构建变量处理计划，以及一个不重叠的训练数据集来拟合处理后的数据。否则，复合系统（数据准备加模型应用）可能会受到严重的嵌套模型偏差的影响：产生一个在训练数据上看起来很好的模型，但后来在测试或应用数据上失败。'
- en: The dangers of naively reusing data
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 无知地重复使用数据的风险
- en: Here is an example of the problem. Suppose we start with some example data where
    there is in fact no relation between `x` and `y`. In this case, we know that any
    relation we think we find between them is just an artifact of our procedures,
    and not really there.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个例子。假设我们从一个例子数据开始，其中实际上 `x` 和 `y` 之间没有关系。在这种情况下，我们知道我们认为它们之间存在的任何关系只是我们程序的一个产物，实际上并不存在。
- en: Listing 8.8\. An information-free dataset
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.8\. 一个无信息数据集
- en: '[PRE31]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: ❶ Sets pseudo-random number generator seed to make the example reproducible
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 设置伪随机数生成器种子以使示例可重复
- en: ❷ Builds example data where there is no relation between x_bad and y
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 构建一个示例数据，其中 x_bad 和 y 之间没有关系
- en: ❸ x_good is a noisy prediction of the sign of y, so it does have some information
    about y.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ x_good 是 y 符号的嘈杂预测，因此它确实有关于 y 的信息。
- en: '❹ Take a look at our synthetic example data. The idea is this: y is related
    to x_good in a noisy fashion, but unrelated to x_bad. In this case, we know what
    variables should be chosen, so we can tell if our acceptance procedure is working
    correctly.'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 查看我们的合成示例数据。其思路是这样的：y 与 x_good 之间存在一种嘈杂的关系，但与 x_bad 无关。在这种情况下，我们知道应该选择哪些变量，因此我们可以判断我们的接受程序是否工作正确。
- en: We naively use the training data to create the treatment plan, and then prepare
    the same data prior to fitting the model.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 我们天真地使用训练数据来创建治疗方案，然后在拟合模型之前准备相同的数据。
- en: Listing 8.9\. The dangers of reusing data
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.9. 重复使用数据的危险
- en: '[PRE32]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: ❶ Designs a variable treatment plan using x_bad and x_good to predict y
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用 x_bad 和 x_good 设计变量处理计划以预测 y
- en: ❷ Notice that the derived variable x_good_catN comes out as having a significant
    signal, and x_bad_catN does not. This is due to the proper use of cross-validation
    in the vtreat quality estimates.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 注意到派生变量 x_good_catN 显示出显著的信号，而 x_bad_catN 则没有。这是由于在 vtreat 质量估计中正确使用了交叉验证。
- en: ❸ Calls prepare() on the same data used to design the treatment plan—this is
    not always safe, as we shall see.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 在设计治疗方案所用的相同数据上调用 prepare()——这并不总是安全的，正如我们将看到的。
- en: ❹ Combines the data frames d and training_data1, using training_data1 when there
    are columns with duplicate names
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 使用 training_data1 当存在重复列名时将数据帧 d 和 training_data1 合并
- en: ❺ Uses a statistical F-test to check the predictive power of x_good_catN
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 使用统计 F-test 检查 x_good_catN 的预测能力
- en: ❻ x_bad_catN’s F-test is inflated and falsely looks significant. This is due
    to failure to use cross-validated methods.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ x_bad_catN 的 F-test 被夸大，并看起来是显著的。这是由于未能使用交叉验证方法。
- en: In this example, notice the `sigr` F-test reports an R-squared of 0.23 between
    `x_bad_ catN` and the outcome variable `y`. This is the technical term for checking
    if the fraction of variation explained (itself called the R-squared) is statistically
    insignificant (a common occurrence under pure chance). So we *want* the true R-squared
    to be high (near 1) and true F-test significance low (near zero) for the good
    variable. We also expect the true R-squared to be low (near 0), and the true F-test
    significance to be non-vanishing (not near zero) for the bad variable.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，注意 `sigr` F-test 报告了 `x_bad_catN` 和结果变量 `y` 之间的 R-squared 为 0.23。这是检查解释变异分数（本身称为
    R-squared）是否在统计上不显著（在纯机会下常见）的技术术语。因此，我们希望真正的 R-squared 高（接近 1），真正的 F-test 显著性低（接近零）对于好变量。我们也期望真正的
    R-squared 低（接近 0），真正的 F-test 显著性非零（不接近零）对于坏变量。
- en: However, notice both the good and bad variables received favorable evaluations!
    This is an error, and happened because the variables we are testing, `x_good_catN`
    and `x_bad_catN`, are both impact codes of high-cardinality string-valued variables.
    When we test these variables on the same data they were constructed on, we suffer
    from overfitting, which erroneously inflates our variable quality estimate. In
    this case, a lot of the *apparent* quality of fit is actually just a measure of
    a variable’s complexity (or ability to overfit).
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，请注意，好变量和坏变量都得到了良好的评估！这是一个错误，发生是因为我们正在测试的变量 `x_good_catN` 和 `x_bad_catN` 都是高基数字符串值变量的影响代码。当我们在这组数据上测试这些变量时，我们会过度拟合，这错误地夸大了我们的变量质量估计。在这种情况下，大量的
    *表面* 质量实际上只是变量复杂性的度量（或过度拟合的能力）。
- en: Also notice that the R-squared and significance reported in the score frame
    correctly indicate that `x_bad_catN` is not a high-quality variable (R-squared
    near zero, and significance not near zero). This is because the score frame uses
    cross-validation to estimate variable significance. This matters because a modeling
    process involving multiple variables might pick the variable `x_bad_catN` over
    other actual useful variables due to `x_bad_catN`’s overfit inflated quality score.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，在得分框架中报告的 R-squared 和显著性正确地表明 `x_bad_catN` 不是一个高质量的变量（R-squared 接近零，显著性不接近零）。这是因为得分框架使用交叉验证来估计变量显著性。这很重要，因为涉及多个变量的建模过程可能会因为
    `x_bad_catN` 的过度拟合夸大的质量分数而选择 `x_bad_catN` 而不是其他实际有用的变量。
- en: As mentioned in previous sections, the way to fix the overfitting is to use
    one portion of our training data for the `designTreatments*()` step and a disjoint
    portion of our training data for the variable use or evaluation (such as the `sigr::wrapFTest()`
    step).
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 如前几节所述，解决过拟合的方法是将我们训练数据的一部分用于`designTreatments*()`步骤，而将另一部分不重叠的训练数据用于变量使用或评估（例如`sigr::wrapFTest()`步骤）。
- en: The cross-frame to safely reuse data
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 安全重用数据的交叉框架
- en: Another way to do this, which lets us use all of the training data both for
    the design of the variable treatment plan and for model fitting, is called the
    *cross-frame* method. This is a special cross-validation method built into `vtreat`’s
    `mkCrossFrame*Experiment()` methods. All we do in this case is call `mkCrossFrameNExperiment()`
    instead of `designTreatmentsN` and get the prepared training data from the `crossFrame`
    element of the returned list object (instead of calling `prepare()`). For future
    test or application data, we do call `prepare()` from the treatment plan (which
    is returned as the `treatments` item on the returned list object), but for training
    we do not call `prepare()`.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种实现方式，允许我们同时使用所有训练数据来设计变量处理计划和模型拟合，被称为*交叉框架*方法。这是`vtreat`的`mkCrossFrame*Experiment()`方法中内置的特殊交叉验证方法。在这种情况下，我们只需调用`mkCrossFrameNExperiment()`而不是`designTreatmentsN`，并从返回的列表对象的`crossFrame`元素中获取准备好的训练数据（而不是调用`prepare()`）。对于未来的测试或应用数据，我们确实从处理计划（作为返回列表对象的`treatments`项返回）中调用`prepare()`，但对于训练我们则不调用`prepare()`。
- en: The code is as follows.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下。
- en: Listing 8.10\. Using `mkCrossFrameNExperiment()`
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.10\. 使用`mkCrossFrameNExperiment()`
- en: '[PRE33]'
  id: totrans-407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: ❶ The F-tests on the data and the scoreFrame statistics now largely agree.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 数据和scoreFrame统计的F测试现在在很大程度上是一致的。
- en: Notice now that `sigr::wrapFTest()` correctly considers `x_bad_catN` to be a
    low-value variable. This scheme also scores good variables correctly, meaning
    we can tell good from bad. We can use the cross-frame `training_data2` for fitting
    models, with good protection against overfit from the variable treatment.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 注意现在`sigr::wrapFTest()`正确地将`x_bad_catN`视为低值变量。此方案也能正确评分变量，这意味着我们可以区分好坏。我们可以使用交叉框架的`training_data2`来拟合模型，并从变量处理中获得良好的保护，以防止过拟合。
- en: Nested model bias
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌套模型偏差
- en: Overfit due to using the result of one model as an input to another is called
    *nestedmodel bias*. With `vtreat`, this could be an issue with the impact codes,
    which are themselves models. For data treatments that do not look at the outcome,
    like `design_ missingness_treatment()` and `designTreatmentsZ()`, it is safe to
    use the same data to design the treatment plan and fit the model. However, when
    the data treatment uses the outcome, we suggest either an additional data split
    or using the `mkCrossFrame*Experiment()/$crossFrame` pattern from [section 8.4.1](../Text/08.xhtml#ch08lev2sec5).
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 将一个模型的输出作为另一个模型的输入导致的过拟合称为*嵌套模型偏差*。使用`vtreat`时，这可能是一个影响代码的问题，因为影响代码本身也是模型。对于不查看结果的数据处理，如`design_
    missingness_treatment()`和`designTreatmentsZ()`，可以使用相同的数据来设计处理计划并拟合模型。然而，当数据处理使用结果时，我们建议进行额外的数据拆分或使用[第8.4.1节](../Text/08.xhtml#ch08lev2sec5)中的`mkCrossFrame*Experiment()/$crossFrame`模式。
- en: '`vtreat` uses cross-validation procedures to create the cross-frame. For details,
    see [https://winvector.github.io/vtreat/articles/vtreatCrossFrames.html](https://winvector.github.io/vtreat/articles/vtreatCrossFrames.html).'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: '`vtreat`使用交叉验证程序来创建交叉框架。有关详细信息，请参阅[https://winvector.github.io/vtreat/articles/vtreatCrossFrames.html](https://winvector.github.io/vtreat/articles/vtreatCrossFrames.html)。'
- en: '* * *'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: designTreatments*() vs. mkCrossFrame*Experiment()
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: '`designTreatments*()` 与 `mkCrossFrame*Experiment()`'
- en: For larger datasets, it’s easier to use a three-way split of the training data
    and the `designTreatments*()`/`prepare()` pattern to design the treatment plan,
    fit the model, and evaluate it. For datasets that seem too small to split three
    ways (especially datasets with a very large number of variables), you may get
    better models by using the `mkCrossFrame*Experiment()`/`prepare()` pattern.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 对于较大的数据集，使用训练数据的三分法以及`designTreatments*()`/`prepare()`模式来设计处理计划、拟合模型和评估更容易。对于看起来太小而无法三分的数据集（特别是具有非常大量变量的数据集），使用`mkCrossFrame*Experiment()`/`prepare()`模式可能会得到更好的模型。
- en: '* * *'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Summary
  id: totrans-417
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Real-world data is often messy. Raw uninspected and untreated data may crash
    your modeling or predicting step, or may give bad results. “Fixing” data does
    not compete with having better data. But being able to work with the data you
    have (instead of the data you want) is an advantage.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 现实世界的数据通常很杂乱。未经检查和处理的原始数据可能会使你的建模或预测步骤失败，或者可能给出不良的结果。“修复”数据并不与拥有更好的数据相竞争。但能够处理你拥有的数据（而不是你希望拥有的数据）是一种优势。
- en: In addition to many domain-specific or problem-specific problems, you may find
    that in your data, there are a number of common problems that should be anticipated
    and dealt with systematically. `vtreat` is a package specialized for preparing
    data for supervised machine learning or predictive modeling tasks. It can also
    reduce your project documentation requirements through its citable documentation.^([[20](../Text/08.xhtml#ch08fn20)])
    However, remember that tools are not an excuse to avoid looking at your data.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 除了许多特定领域或特定问题的领域特定问题之外，你可能会发现，在你的数据中，存在许多应该被预见并系统处理的常见问题。`vtreat`是一个专门用于为监督机器学习或预测建模任务准备数据的包。它还可以通过其可引用的文档来减少你的项目文档需求^([[20](../Text/08.xhtml#ch08fn20)])。然而，请记住，工具不是避免查看数据的借口。
- en: ^(20)
  id: totrans-420
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ^(20)
- en: ''
  id: totrans-421
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: See [https://arxiv.org/abs/1611.09477](https://arxiv.org/abs/1611.09477).
  id: totrans-422
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 查看[https://arxiv.org/abs/1611.09477](https://arxiv.org/abs/1611.09477)。
- en: In this chapter you have learned
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了
- en: How to use the `vtreat` package’s `designTreatments*()`/`prepare()` pattern
    with a three-way split of your training data to prepare messy data for model fitting
    and model application
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用`vtreat`包的`designTreatments*()`/`prepare()`模式，通过将训练数据分为三部分来准备用于模型拟合和模型应用的前处理数据
- en: How to use the `vtreat` package’s `mkCrossFrame*Experiment()`/`prepare()` pattern
    with a two-way split of your training data to prepare messy data for model fitting
    and model application, when statistical efficiency is important
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用`vtreat`包的`mkCrossFrame*Experiment()`/`prepare()`模式，通过将训练数据分为两部分来准备用于模型拟合和模型应用的前处理数据，尤其是在统计效率很重要的情况下
