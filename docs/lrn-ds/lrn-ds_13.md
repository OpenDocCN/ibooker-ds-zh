# 第10章。探索性数据分析

50多年前，John Tukey热情推广了一种与置信区间、假设检验和建模的正式世界不同的数据分析方法。今天，Tukey的[*探索性数据分析*](https://oreil.ly/Himzi)（EDA）被广泛应用。Tukey [描述EDA](https://oreil.ly/UO9F8)为处理数据的哲学方法：

> 探索性数据分析是积极的，而不是被动的描述，真正强调发现意外的重要性。

作为一名数据科学家，您将希望在数据生命周期的每个阶段中使用EDA，从检查数据质量到准备形式建模，再到确认您的模型是否合理。确实，在描述的工作中[第9章](ch09.html#ch-wrangling)清理和转换数据过程中，EDA在指导我们的质量检查和转换中起到了重要作用。

在EDA中，我们进入一个发现的过程，不断提出问题，深入探讨未知领域来探索想法。我们使用图表来揭示数据的特征，检查值的分布，并揭示不能从简单的数值摘要中检测到的关系。这种探索包括转换、可视化和总结数据，以建立和确认我们的理解，识别和解决数据可能存在的问题，并为随后的分析提供信息。

EDA很有趣！但需要实践。学习如何进行EDA的最佳方法之一是从他人那里学习，因为他们描述他们在探索数据时的思维过程，我们在本书的例子和案例研究中试图揭示EDA思维。

EDA（探索性数据分析）可以提供宝贵的见解，但您需要谨慎对待您所得出的结论。重要的是要认识到，EDA可能会影响您分析的偏见。EDA是一个筛选过程和决策过程，可能会影响您后续基于模型的发现的可复制性。有足够的数据，如果您仔细观察，通常可以挖掘出一些完全虚假的有趣内容。

EDA在科学可重复性危机中的角色已被注意到，数据科学家已经警告不要过度使用它。例如，[Gelman 和 Loken](https://doi.org/10.1511/2014.111.460)指出：

> 即使在已对给定数据进行了单一分析的情况下，多重比较[数据挖掘]的问题也会出现，因为对变量组合、案例包含和排除、变量转换、在没有主效应的情况下进行交互测试以及分析中的许多其他步骤的不同选择都可能与不同的数据发生。

最佳实践是报告并提供您的EDA代码，以便他人了解您所做的选择和您在了解数据过程中采取的路径。

关于可视化的主题分布在三章之间。在[第9章](ch09.html#ch-wrangling)中，我们使用图表来辅助我们进行数据整理。那里的图表很基础，发现也很直接。我们没有深入探讨解释和选择图表的问题。在本章中，我们将花更多时间学习如何选择合适的图表并进行解释。由于我们的目标是在执行探索性数据分析时快速生成图表，通常采用绘图函数的默认参数设置。在[第11章](ch11.html#ch-viz)，我们将提供制作有效和信息丰富的图表的指南，并提供建议，说明如何使我们的视觉论证清晰和令人信服。

根据[Tukey](https://oreil.ly/AIWW5)，可视化在探索性数据分析中是核心：

> 数据中最大的收益来自于惊喜……意外的情况最好通过图片来引起我们的注意。

要制作这些图片，我们需要选择适当类型的图表，我们的选择取决于已收集的数据类型。特征类型与图表选择之间的映射是下一节的主题。然后，我们详细描述如何“读取”图表，要查找的内容以及如何解释所见内容。我们首先讨论单特征图表要查找的内容，然后关注两个特征之间的关系，最后描述三个或更多特征的图表。在介绍了探索性数据分析的可视化工具后，我们提供了执行探索性数据分析的指南，并按照这些指南的步骤进行示例演练。

# 特征类型

在制作探索性图表或任何图表之前，检查特征（或特征），并确定其*特征类型*是个好主意。（有时我们将特征称为*变量*，其类型称为*变量类型*。）尽管有多种分类特征类型的方法，在本书中，我们考虑三种基本类型。有序和名义数据是*分类*数据的子类型。分类数据的另一个名称是*定性*。相反，我们还有*定量*特征：

*名义*

代表“命名”类别的特征，其中类别没有自然顺序，称为名义。例如政党隶属（民主党、共和党、绿党、其他）、狗的类型（牧群、猎犬、非体育、体育、梗类、玩具、工作类）和计算机操作系统（Windows、macOS、Linux）。

*有序*

表示有序类别的测量称为有序测量。有序特征的例子包括 T 恤尺寸（小号、中号、大号）、Likert 量表响应（不同意、中立、同意）和教育水平（高中、大学、研究生院）。重要的是要注意，对于有序特征，例如小号和中号之间的差异不一定等同于中号和大号之间的差异。此外，连续类别之间的差异可能甚至无法量化。考虑餐厅评论中的星级数量及一颗星的含义与两颗星之间的含义。

*定量*

代表数值测量或数量的数据被称为定量数据。例如，以厘米为单位测量的身高，以美元报告的价格和以公里为单位测量的距离。定量特征可以进一步分为*离散*，意味着特征只能有几个可能值，以及*连续*，意味着理论上数量可以测量到任意精度。家庭中兄弟姐妹的数量采用离散的值集（例如 0, 1, 2, …, 8）。相比之下，身高理论上可以报告到任意数量的小数位数，因此我们认为它是连续的。确定数量是离散还是连续没有硬性规定。在某些情况下，这可能是一种判断，而在其他情况下，我们可能希望有意将连续特征视为离散特征。

特征类型与数据存储类型不同。`pandas` 的每一列 `DataFrame` 都有自己的*存储类型*。这些类型可以是整数、浮点数、布尔值、日期时间格式、类别和对象（Python 中以指向字符串的指针存储可变长度的字符串）。我们使用术语*特征类型*来指代信息的概念性概念，使用术语*存储类型*来指代计算机中信息的表示。

一个以整数存储的特征可以代表名义数据，字符串可以是定量的（比如 `"\$100.00"`），在实践中，布尔值通常表示只有两种可能值的名义特征。

###### 注意

`pandas` 将存储类型称为 `dtype`，这是数据类型的简称。我们在这里避免使用 *数据类型* 这个术语，因为它可能会与存储类型和特征类型混淆。

为了确定特征类型，我们经常需要查阅数据集的*数据字典*或*代码簿*。数据字典是与数据一起包含的文件，描述了数据表中每一列代表的内容。在以下示例中，我们查看了关于各种狗品种的数据框的列的存储和特征类型，并且发现存储类型通常不能很好地指示字段中包含的信息类型。

## 示例：狗品种

我们使用 [美国肯尼尔俱乐部 (AKC)](https://www.akc.org) 的注册狗品种数据来介绍与探索数据分析相关的各种概念。成立于1884年的非营利组织AKC的宗旨是“推动纯种狗的研究、繁殖、展示、运动和维护”。AKC组织了诸如全国锦标赛、敏捷邀请赛和服从经典等活动，混种狗在大多数活动中也可以参与。[信息美化](https://informationisbeautiful.net) 网站提供了来自AKC关于172种狗品种的信息数据集。其可视化作品 [最佳展示](https://oreil.ly/amksD) 包含了多种品种的特征，非常有趣。

AKC 数据集包含多种不同类型的特征，我们已提取了一些显示各种信息类型的特征。这些特征包括品种的名称；其寿命、体重和身高；以及其他信息，例如其适合儿童的程度和学习新技巧所需的重复次数。数据集中的每条记录都是一种狗的品种，提供的信息意在典型代表该品种。让我们将数据读入数据框中：

```py
dogs = pd.read_csv('data/akc.csv')
dogs
```

|   | 品种 | 组 | 得分 | 寿命 | ... | 大小 | 重量 | 身高 | 重复次数 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **0** | 边境牧羊犬 | 牧羊 | 3.64 | 12.52 | ... | 中型 | NaN | 51.0 | <5 |
| **1** | 边境梗 | 梗类犬 | 3.61 | 14.00 | ... | 小型 | 6.0 | NaN | 15-25 |
| **2** | 布列塔尼犬 | 狩猎 | 3.54 | 12.92 | ... | 中型 | 16.0 | 48.0 | 5-15 |
| **...** | ... | ... | ... | ... | ... | ... | ... | ... | ... |
| **169** | 电线狐狸梗 | 梗类犬 | NaN | 13.17 | ... | 小型 | 8.0 | 38.0 | 25-40 |
| **170** | 硬毛指示格里芬猎犬 | 狩猎 | NaN | 8.80 | ... | 中型 | NaN | 56.0 | 25-40 |
| **171** | 墨西哥无毛犬 | 非狩猎 | NaN | NaN | ... | 中型 | NaN | 42.0 | NaN |

```py
172 rows × 12 columns
```

粗略看一下表格，品种、组和大小似乎是字符串，其他列则是数字。这里显示的数据框摘要提供了索引、名称、非空值计数和每列的`dtype`：

```py
`dogs``.``info``(``)`

```

```py
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 172 entries, 0 to 171
Data columns (total 12 columns):
 #   Column          Non-Null Count  Dtype  
---  ------          --------------  -----  
 0   breed           172 non-null    object 
 1   group           172 non-null    object 
 2   score           87 non-null     float64
 3   longevity       135 non-null    float64
 4   ailments        148 non-null    float64
 5   purchase_price  146 non-null    float64
 6   grooming        112 non-null    float64
 7   children        112 non-null    float64
 8   size            172 non-null    object 
 9   weight          86 non-null     float64
 10  height          159 non-null    float64
 11  repetition      132 non-null    object 
dtypes: float64(8), object(4)
memory usage: 16.2+ KB

```

这个数据框的几列具有数值计算类型，如`float64`，这意味着该列可以包含除整数以外的数字。我们还确认`pandas`将字符串列编码为`object`类型，而不是`string`类型。请注意，我们错误地猜测`重复次数`是定量的。仔细观察数据表后，我们发现`重复次数`包含范围的字符串值，如`"<5"`、`"15-25"`和`"25-40"`，因此这个特征是有序的。

###### 注意

在计算机体系结构中，浮点数或简称“float”指的是可以具有小数部分的数。我们不会在本书中深入探讨计算机体系结构，但在影响术语时，我们会指出它，就像在这种情况下一样。`dtype` `float64` 表示该列包含的是在计算机内存中存储时每个占用 64 位空间的十进制数。

另外，`pandas` 使用了优化的存储类型来存储数值数据，如 `float64` 或 `int64`。然而，对于像字符串、字典或集合这样的 Python 对象，它没有优化，因此这些数据类型都存储为 `object` `dtype`。这意味着存储类型是不明确的，但在大多数情况下，我们知道 `object` 列包含字符串或其他某种 Python 类型。

在查看列存储类型时，我们可能会猜测 `ailments` 和 `children` 是定量特征，因为它们存储为 `float64` `dtype`。但让我们统计它们的唯一值：

```py
`display_df``(``dogs``[``'``ailments``'``]``.``value_counts``(``)``,` `rows``=``8``)`

```

```py
ailments
0.0    61
1.0    42
2.0    24
4.0    10
3.0     6
5.0     3
9.0     1
8.0     1
Name: count, dtype: int64

```

```py
`dogs``[``'``children``'``]``.``value_counts``(``)`

```

```py
children
1.0    67
2.0    35
3.0    10
Name: count, dtype: int64

```

`ailments` 和 `children` 都只接受几个整数值。`children` 的值为 `3.0` 或 `ailments` 的值为 `9.0` 代表什么意思？我们需要更多信息才能搞清楚。列名及其在数据框中的存储方式不足以解释。因此，我们需要查阅表 10-1 中显示的数据字典。

表 10-1\. AKC 狗品种代码手册

| 特征 | 描述 |
| --- | --- |
| `breed` | 犬品种，例如边境牧羊犬、达尔马提亚犬、威尔士波音犬 |
| `group` | 美国典狗俱乐部分组（牧羊犬、猎犬、非运动犬、运动犬、梗类犬、玩具犬、工作犬） |
| `score` | AKC 评分 |
| `longevity` | 典型寿命（年） |
| `ailments` | 严重遗传疾病的数量 |
| `purchase_price` | 从 [puppyfind.com](http://puppyfind.com) 平均购买价格 |
| `grooming` | 每次需要的美容频率：1 = 天，2 = 周，3 = 几周 |
| `children` | 对儿童的适合度：1 = 高，2 = 中，3 = 低 |
| `size` | 尺寸：小型、中型、大型 |
| `weight` | 典型体重（公斤） |
| `height` | 肩膀高度（厘米） |
| `repetition` | 理解新命令所需的重复次数：＜5，5-15，15-25，25-40，40-80，＞80 |

尽管数据字典未明确指定特征类型，但描述足以让我们了解到，`children` 特征代表品种对儿童的适合程度，`1.0` 的值对应于“高”适合度。我们还发现 `ailments` 特征表示该品种狗犬通常具有的严重遗传疾病的数量。根据代码手册，我们将 `children` 视为分类特征，即使它存储为浮点数，由于低 < 中 < 高，该特征是有序的。由于 `ailments` 是一个计数，我们将其视为定量（数值）类型，并且对于某些分析，我们进一步定义它为离散型，因为 `ailments` 可能的取值只有几个。

数据代码表还确认了`score`、`longevity`、`purchase_price`、`weight`和`height`特征是定量的。这里的想法是，数值特征具有可以通过差异进行比较的值。可以说吉娃娃的寿命通常比腊肠犬长大约四年（16.5年对12.6年）。另一个检查是是否有意义比较值的比率：一只腊肠犬通常比吉娃娃重大约五倍（11公斤对2公斤）。所有这些定量特征都是连续的；只有`ailments`是离散的。

对于`breed`、`group`、`size`和`repetition`，数据字典描述表明这些特征是定性的。每个变量具有不同但常见的特征，值得进一步探索。我们通过检查各个特征的唯一值计数来做到这一点。我们从`breed`开始：

```py
`dogs``[``'``breed``'``]``.``value_counts``(``)`

```

```py
breed
Border Collie       1
Great Pyrenees      1
English Foxhound    1
                   ..
Saluki              1
Giant Schnauzer     1
Xoloitzcuintli      1
Name: count, Length: 172, dtype: int64

```

`breed`特征有172个唯一值，与数据框中的记录数相同，因此我们可以将`breed`视为数据表的*主键*。按设计，每个犬种有一条记录，而这个`breed`特征决定了数据集的粒度。虽然`breed`也被视为名义特征，但分析它没有真正的意义。我们确实希望确认所有值都是唯一且干净的，但除此之外，我们只会用它来标记绘图中的异常值。

接下来，我们检查`group`特征：

```py
`dogs``[``'``group``'``]``.``value_counts``(``)`

```

```py
group
terrier         28
sporting        28
working         27
hound           26
herding         25
toy             19
non-sporting    19
Name: count, dtype: int64

```

该特征有七个唯一值。由于被标记为“运动型”的犬种与被认为是“玩具型”的犬种在多方面有所不同，这些类别不能轻易归纳为一种顺序。因此，我们将`group`视为名义特征。名义特征甚至不提供差异方向上的含义。

接下来，我们检查`size`的唯一值及其计数：

```py
`dogs``[``'``size``'``]``.``value_counts``(``)`

```

```py
size
medium    60
small     58
large     54
Name: count, dtype: int64

```

`size`特征具有自然的顺序：小 < 中 < 大，因此它是序数的。我们不知道“小”类别是如何确定的，但我们知道小型品种在某种意义上比中型品种小，而中型品种又比大型品种小。我们有一个顺序，但概念上差异和比率没有意义。

`repetition`特征是定量变量的一个示例，已经被折叠成类别，变为序数。数据代码表告诉我们，`repetition`是新命令需要重复几次才能让狗理解的次数：

```py
`dogs``[``'``repetition``'``]``.``value_counts``(``)`

```

```py
repetition
25-40     39
15-25     29
40-80     22
5-15      21
80-100    11
<5        10
Name: count, dtype: int64

```

数值值已被汇总为`<5`、`5-15`、`15-25`、`25-40`、`40-80`、`80-100`，注意这些类别的宽度不同。第一个有5次重复，而其他的宽度为10、15和40次重复。顺序清晰，但从一个类别到下一个的间隔不是相同大小。

现在我们已经再次检查了变量中的值与代码手册中描述的值，我们可以扩充数据字典，包括关于特征类型的额外信息。我们修订后的字典出现在[表 10-2](#revised-akc-codebook)中。

表 10-2\. 修订后的AKC犬种代码手册

| 特征 | 描述 | 特征类型 | 存储类型 |
| --- | --- | --- | --- |
| `breed` | 犬种，例如边境牧羊犬、达尔马提亚犬、威尔士激罗犬 | 主键 | 字符串 |
| `group` | AKC分组（牧羊犬、猎犬、非运动犬、运动犬、梗类犬、玩具犬、工作犬） | 定性 - 名义 | 字符串 |
| score | AKC `score` | 定量 | 浮点数 |
| `longevity` | 典型寿命（年） | 定量 | 浮点数 |
| `ailments` | 严重遗传疾病数量（0, 1, …, 9） | 定量 - 离散 | 浮点数 |
| `purchase_price` | 从[puppyfind.com](http://puppyfind.com)平均购买价格 | 定量 | 浮点数 |
| `grooming` | 每隔多久梳理一次：1 = 天、2 = 周、3 = 几周 | 定性 - 序数 | 浮点数 |
| `children` | 适合儿童程度：1 = 高、2 = 中、3 = 低 | 定性 - 序数 | 浮点数 |
| `size` | 尺寸：小、中、大 | 定性 - 序数 | 字符串 |
| `weight` | 典型体重（公斤） | 定量 | 浮点数 |
| `height` | 肩膀高度（厘米） | 定量 | 浮点数 |
| `repetition` | 理解新指令所需的重复次数：＜5、5–15、15–25、25–40、40–80、80–100 | 定性 - 序数 | 字符串 |

对AKC数据特征类型的更清晰理解有助于我们进行质量检查和转换。我们在[第9章](ch09.html#ch-wrangling)中讨论了转换，但还有一些未涉及的额外转换。这些与定性特征的类别有关，我们接下来将对其进行描述。

## 转换定性特征

无论特征是名义还是序数，我们可能会发现重新标记类别使其更具信息性，合并类别以简化可视化，甚至将数值特征转换为序数以便专注于特定的过渡点都是有用的。我们解释了何时进行每种转换，并给出了示例。

### 重新标记类别

摘要统计数据，如平均值和中位数，对定量数据是有意义的，但通常对定性数据不是。例如，计算玩具品种的平均价格（$687）是有意义的，但是关于儿童的“平均”适合性不是。然而，如果我们要求它，`pandas` 将乐意计算`children`列中值的平均值：

```py
`# Don't use this value in actual data analysis!`
`dogs``[``"``children``"``]``.``mean``(``)`

```

```py
1.4910714285714286

```

相反，我们希望考虑`children`的1、2和3的分布。

###### 注意

存储类型和特征类型之间的主要区别在于，存储类型表示我们可以编写代码来*计算*哪些操作，而特征类型表示对于数据*何种操作是有意义*的。

我们可以通过用它们的字符串描述替换数字来转换`孩子们`。将1、2和3改为高、中和低，使得很容易识别出`孩子们`是分类的。使用字符串，我们不会被诱惑计算平均值，类别会与它们的含义相联系，并且绘图的标签默认具有合理的值。例如，让我们只关注玩具品种，并制作适合儿童的酒吧图。首先，我们创建一个新的列，用字符串表示适合性的类别：

```py
`kids` `=` `{``1``:``"``high``"``,` `2``:``"``medium``"``,` `3``:``"``low``"``}`
`dogs` `=` `dogs``.``assign``(``kids``=``dogs``[``'``children``'``]``.``replace``(``kids``)``)`

```

```py
`dogs`

```

|   | 品种 | 分组 | 得分 | 寿命 | ... | 重量 | 身高 | 重复 | 孩子们 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **0** | 边境牧羊犬 | 牧羊犬 | 3.64 | 12.52 | ... | NaN | 51.0 | <5 | 低 |
| **1** | 边境泰瑞尔 | 梗犬 | 3.61 | 14.00 | ... | 6.0 | NaN | 15-25 | 高 |
| **2** | 布列塔尼 | 运动型 | 3.54 | 12.92 | ... | 16.0 | 48.0 | 5-15 | 中等 |
| **...** | ... | ... | ... | ... | ... | ... | ... | ... | ... |
| **169** | 线毛福克斯梗 | 梗犬 | NaN | 13.17 | ... | 8.0 | 38.0 | 25-40 | NaN |
| **170** | 线毛指示格里芬 | 运动型 | NaN | 8.80 | ... | NaN | 56.0 | 25-40 | NaN |
| **171** | 什么狗品种 | 非运动型 | NaN | NaN | ... | NaN | 42.0 | NaN | NaN |

```py
172 rows × 13 columns
```

然后我们可以制作玩具品种中每个适合性类别的计数条形图：

```py
`toy_dogs` `=` `dogs``.``query``(``'``group ==` `"``toy``"``'``)``.``groupby``(``'``kids``'``)``.``count``(``)``.``reset_index``(``)`
`px``.``bar``(``toy_dogs``,` `x``=``'``kids``'``,` `y``=``'``breed``'``,` `width``=``350``,` `height``=``250``,`
       `category_orders``=``{``"``kids``"``:` `[``"``low``"``,` `"``medium``"``,` `"``high``"``]``}``,`
       `labels``=``{``"``kids``"``:` `"``Suitability for children``"``,` `"``breed``"``:` `"``count``"``}``)`

```

![](assets/leds_10in01.png)

我们并不总是希望用字符串表示分类数据。字符串通常需要更多的存储空间，如果数据集包含许多分类特征，可能会大大增加数据集的大小。

有时候，一个定性特征有许多类别，我们更喜欢对数据进行更高级别的查看，因此我们会合并类别。

### 折叠类别

让我们创建一个名为`play`的新列，以表示“目的”是玩耍的狗的组（或不是）。 （这是一个虚构的区分，用于演示目的。）此类别由玩具和非运动品种组成。 新特征`play`是将特征`group`折叠的转换：将玩具和非运动组合成一个类别，剩下的类别放在第二个非玩耍类别中。 布尔（`bool`）存储类型对于指示此特征的存在或不存在非常有用：

```py
`with_play` `=` `dogs``.``assign``(``play``=``(``dogs``[``"``group``"``]` `==` `"``toy``"``)` `|`
                             `(``dogs``[``"``group``"``]` `==` `"``non-sporting``"``)``)`

```

将一个两类定性特征表示为布尔值有一些优点。 例如，`play`的平均值是有意义的，因为它返回`True`值的比例。 当布尔值用于数字计算时，`True`变为1，`False`变为0：

```py
`with_play``[``'``play``'``]``.``mean``(``)`

```

```py
0.22093023255813954

```

此存储类型为我们提供了计算布尔值的计数和平均值的快捷方式。 在[第15章](ch15.html#ch-linear)中，我们将看到它对建模也是一个方便的编码。

有时候，例如当一个离散的定量特征有一个长尾时，我们希望截断更高的值，这将定量特征转化为序数。接下来我们将描述这一点。

### 将定量转换为序数

最后，我们有时会发现另一种有用的转换是将数值转换为类别。例如，我们可以将`ailments`中的值合并为类别：0, 1, 2, 3, 4+。换句话说，我们将`ailments`从定量特征转换为序数特征，映射为 0→0, 1→1, 2→2, 3→3，任何值大于等于4→4+。我们可能希望进行这种转换，因为几乎没有品种有三种以上的遗传疾病。这种简化可以更清晰和足够用于调查。

###### 注意

截至2022年底，`pandas`也实现了一个设计用于定性数据的`category` `dtype`。然而，这种存储类型目前在可视化和建模库中尚未广泛采用，限制了其实用性。因此，我们不将定性变量转换为`category` `dtype`。我们预计将来的读者可能会希望在更多库支持它之后使用`category` `dtype`。

当我们将定量特征转换为序数时，我们会丢失信息。我们无法回到原来的状态。也就是说，如果我们知道某品种的疾病数为四个或更多，我们无法重新创建实际的数值。当我们合并类别时也是同样的情况。因此，保留原始特征是一个良好的实践。如果需要检查我们的工作或更改类别，我们可以记录和重新创建我们的步骤。

一般来说，特征类型帮助我们确定哪种绘图最合适。接下来我们讨论特征类型与绘图之间的映射。

## 特征类型的重要性

特征类型指导我们进行数据分析。它们有助于指定我们可以对数据应用的操作、可视化和模型。[表 10-3](#feature-plot) 将特征类型匹配到通常适合的各种绘图类型。变量是定量还是定性通常决定了可以制作的可选绘图集，尽管也有例外情况。决策的其他因素包括观察数量以及特征是否仅取几个不同的值。例如，对于离散定量变量，我们可能制作柱状图而不是直方图。

表10-3. 将特征类型映射到绘图

| 特征类型 | 维度 | 绘图 |
| --- | --- | --- |
| 定量 | 一个特征 | 地毯图，直方图，密度曲线，箱线图，小提琴图 |
| 定性 | 一个特征 | 柱状图，点图，线图，饼图 |
| 定量 | 两个特征 | 散点图，平滑曲线，等高线图，热力图，分位数-分位数图 |
| 定性 | 两个特征 | 并排柱状图，马赛克图，叠加线条 |
| 混合 | 两个特征 | 叠加密度曲线，并排箱线图，叠加平滑曲线，分位数-分位数图 |

特征类型还帮助我们决定计算哪种摘要统计数据。对于定性数据，我们通常不计算均值或标准差，而是计算每个类别中记录的数量、比例或百分比。对于定量特征，我们计算均值或中位数作为中心测量，以及标准差或四分位间距（第75百分位至第25百分位）作为扩展测量。除了四分位数外，我们可能还会发现其他百分位数有信息意义。

###### 注意

第*n*百分位数是使得*n%的数据值不超过它*的值*q*。值*q*可能不唯一，有几种方法可以选择可能的唯一值。有足够的数据时，这些定义之间应该几乎没有区别。

在Python中计算百分位数时，我们更喜欢使用：

```py
`np``.``percentile``(``data``,` `method``=``'``lower``'``)`

```

当探索数据时，我们需要知道如何解释我们的图形显示的形状。接下来的三节将指导这种解释。我们还通过示例介绍了表格[10-3](#feature-plot)中列出的许多图表类型。其他类型在[第11章](ch11.html#ch-viz)中介绍。

# 如何选择分布特征

特征的视觉展示可以帮助我们看到观察结果中的模式；它们通常比直接检查数字或字符串本身要好得多。简单的毯子图将每个观察结果定位为沿轴上的“纱线”。“毯子”图在我们有少量观察结果时可能很有用，但是当我们有100个值时，很快就难以区分高密度（人口最多）区域，比如说。以下图显示了大约150个品种寿命值沿直方图顶部的毯子图：

```py
`px``.``histogram``(``dogs``,` `x``=``"``longevity``"``,` `marginal``=``"``rug``"``,` `nbins``=``20``,`
             `histnorm``=``'``percent``'``,` `width``=``350``,` `height``=``250``,`
             `labels``=``{``'``longevity``'``:``'``Typical lifespan (yr)``'``}``)`

```

![](assets/leds_10in02.png)

尽管我们可以看到一个异常大的值大于16在毯子图中，但很难比较其他区域的纱线密度。相反，直方图为各种寿命值的观察密度提供了更好的感知。类似地，下图中显示的*密度曲线*描绘了高低密度区域的图像：

![](assets/leds_10in03.png)

在直方图和密度曲线中，我们可以看到寿命分布是不对称的。在大约12年处有一个主要模式，9到11年的范围内有一个肩膀，这意味着虽然12年是最常见的寿命，但许多品种的寿命比12年短一到三年。我们还看到大约7岁的小次要模式，以及一些寿命长达14到16年的品种。

当解读直方图或密度曲线时，我们会检查分布的对称性和偏斜度；高频区域（模式）的数量、位置和大小；尾部长度（通常与钟形曲线进行比较）；未观察到值的间隙；以及异常大或异常值。[图 10-1](#example-density-plot) 提供了一个具有这些特征的分布的描述。当我们读取分布时，我们将在图中看到的特征与所测量的数量联系起来。

![](assets/leds_1001.png)

###### 图 10-1\. 示例密度图，根据其形状识别分布的特征

作为另一个例子，犬种中遗传病数量的分布如下直方图所示：

```py
`bins` `=` `[``-``0.5``,` `0.5``,` `1.5``,` `2.5``,` `3.5``,` `9.5``]`
`g` `=` `sns``.``histplot``(``data``=``dogs``,` `x``=``"``ailments``"``,` `bins``=``bins``,` `stat``=``"``density``"``)`
`g``.``set``(``xlabel``=``'``Number of ailments``'``,` `ylabel``=``'``density``'``)``;`

```

![](assets/leds_10in04.png)

当遗传病数量为0时，意味着这个品种没有遗传病，当为1时对应一个遗传病，以此类推。从直方图中可以看出，遗传病的分布是单峰的，峰值在0处。我们还可以看到，分布向右严重倾斜，右尾长，表明很少的品种有四到九种遗传病。虽然是定量的，但遗传病是离散的，因为只有少数整数值是可能的。因此，我们将区间设定在整数上，例如从1.5到2.5的区间只包含有两种病的品种。我们还扩宽了最右边的区间。我们将所有有四到九种病的品种归为一组。当区间计数较小时，我们使用更宽的区间进一步平滑分布，因为我们不想过多关注小数字的波动。在这种情况下，没有品种有六或七种病，但有些有四、五、八或九种病。

接下来，我们指出直方图和密度曲线的三个关键方面：y轴应该使用密度刻度，平滑隐藏了不重要的细节，直方图与条形图基本上是不同的。我们依次描述每个方面：

y轴上的密度

长寿和遗传病直方图中的y轴都标记为“密度”。这个标签意味着直方图中条的总面积等于1。简单来说，我们可以把直方图想象成一个天际线，高楼密集的地方人口更多，我们可以从矩形的面积中找到任意区间的观察比例。例如，在遗传病直方图中，从3.5到9.5的矩形大约包含了10%的品种：6（宽度）× 0.017（高度）大约是0.10。如果所有的区间宽度相同，那么无论y轴表示计数还是密度，天际线看起来都会一样。但是在这个直方图中将y轴改为计数会给出一个误导性的图片，右尾的一个非常大的矩形。

平滑处理

使用直方图时，我们隐藏了地毯图中个别纱线的细节，以便查看分布的一般特征。平滑是指这个过程，将点集替换为矩形；我们选择不展示数据集中的每个点，以揭示更广泛的趋势。我们可能希望平滑这些点，因为这是一个样本，我们相信观察到的值附近的其他值是合理的，和/或者我们想要关注的是一般结构而不是个别观测值。没有地毯，我们无法确定一个箱子中的点在哪里。平滑的密度曲线，就像我们之前展示的关于寿命的那个，也具有总面积和为1的属性。密度曲线使用平滑的*核*函数来展开个别纱线，有时被称为*核密度估计*（KDE）。

条形图 ≠ 直方图

对于定性数据，条形图与直方图起着类似的作用。条形图以视觉方式展示不同组的“流行度”或频率。然而，我们不能像直方图那样解释条形图的形状。在此设置中，尾部和对称性没有意义。此外，类别的频率由条的高度表示，宽度不包含信息。接下来的两个条形图显示了关于各个类别品种数量的相同信息；它们唯一的区别在于条的宽度。在极端情况下，最右边的图表完全消除了条，并通过单个点来表示每个计数。在没有连接线的情况下，这种图称为*点图*。阅读这个线图时，我们可以看到只有少数品种不适合儿童：

```py
`kid_counts` `=` `dogs``.``groupby``(``[``'``kids``'``]``)``.``count``(``)`
`kid_counts` `=` `kid_counts``.``reindex``(``[``"``high``"``,` `"``medium``"``,` `"``low``"``]``)`

```

![](assets/leds_10in05.png)

现在我们已经讨论了如何检查单个特征的分布情况，接下来我们转向当我们想要查看两个特征及其关系时的情况。

# 关系中要寻找的内容

当我们研究多个变量时，我们不仅要检查它们的分布，还要检查它们之间的关系。在这一部分中，我们考虑特征对并描述需要寻找的内容。根据特征类型，[表 10-3](#feature-plot) 提供了绘制图表类型的指南。对于两个特征来说，类型的组合（全是定量、全是定性或混合）很重要。我们逐个考虑每种组合。

## 两个定量特征

如果两个特征都是定量的，那么我们通常用散点图来考察它们的关系。散点图中的每个点表示一个观测值的一对数值的位置。因此，我们可以将散点图视为一个二维的地毯图。

在散点图中，我们寻找线性和简单的非线性关系，并检查这些关系的强度。我们还要看看是否将一个或两个特征进行变换会导致线性关系。

下面的散点图展示了狗品种的体重和身高（两者都是定量的）：

```py
`px``.``scatter``(``dogs``,` `x``=``'``height``'``,` `y``=``'``weight``'``,` 
           `marginal_x``=``"``rug``"``,` `marginal_y``=``"``rug``"``,`
           `labels``=``{``'``height``'``:``'``Height (cm)``'``,` `'``weight``'``:``'``Weight (kg)``'``}``,`
           `width``=``350``,` `height``=``250``)`

```

![](assets/leds_10in06.png)

我们观察到，身高高于平均水平的狗往往体重也高于平均水平。这种关系呈非线性：对于较高的狗，体重的变化速度比对于较矮的狗要快。事实上，如果我们将狗看作基本上呈盒状，那么对于类似比例的盒子，盒子内的内容的重量与其长度呈立方关系是有道理的。

需要注意的是，两个单变量图缺少双变量图中的信息——关于两个特征如何一起变化的信息。实际上，两个定量特征的直方图不包含足够的信息来创建特征的散点图。我们必须谨慎行事，不要过多解读一对单变量图。相反，我们需要使用[表 10-3](#feature-plot) 中适当行中列出的图之一（散点图，平滑曲线，等高线图，热图，分位数-分位数图），以了解两个定量特征之间的关系。

当一个特征是数值的而另一个是定性的时候，[表 10-3](#feature-plot) 提出了不同的建议。我们接下来描述它们。

## 一个定性和一个定量变量

要检验定量和定性特征之间的关系，我们通常使用定性特征将数据分成组，并比较这些组中定量特征的分布。例如，我们可以比较小型、中型和大型狗品种的身高分布，同时绘制三个重叠的密度曲线：

![](assets/leds_10in07.png)

我们看到小型和中型品种的身高分布都呈双峰性，每组左峰较大。此外，小型和中型组的身高范围比大型品种组要大。

并排的箱线图提供了跨组分布的类似比较。箱线图提供了一种简单的方法，可以粗略了解分布情况。同样，小提琴图沿轴为每个组绘制密度曲线。曲线被翻转以创建对称的“小提琴”形状。小提琴图旨在弥合密度曲线和箱线图之间的差距。我们为品种的高度创建了箱线图（左）和小提琴图（右），给出了大小标签：

![](assets/leds_10in08.png)

狗的三个身高箱线图，每种大小的狗一个，清楚地表明大小分类是基于身高的，因为组间的身高范围几乎没有重叠。（由于平滑处理，这在密度曲线中并不明显。）在这些箱线图中我们看不到小型和中型狗群体的双峰性，但我们仍然可以看到大型狗与其他两组相比具有较窄的分布。

箱线图（也称为箱线图）是对分布的几个重要统计数据的视觉总结。箱子代表第25百分位数、中位数和第75百分位数，箱须显示尾部，还绘制了异常大或小的值。箱线图不能像直方图或密度曲线那样显示形状。它们主要显示对称性和偏斜、长/短尾巴以及异常大/小的值（也称为*异常值*）。

[图 10-2](#box-plot) 是对箱线图各部分的视觉解释。从中位数不在箱子中间可以看出不对称性，箱须的长度显示了尾部的大小，超出箱须的点显示了异常值。最大值被视为异常值，因为它出现在右侧箱须之外。

![](assets/leds_1002.png)

###### 图 10-2\. 带有标记的箱线图摘要统计的图示

当我们研究两个定性特征之间的关系时，我们的重点在于比例，接下来我们会详细解释。

## 两个定性特征

对于两个定性特征，我们经常比较一个特征在另一个特征定义的子组中的分布。实际上，我们保持一个特征不变，并绘制另一个特征的分布。为此，我们可以使用用于显示一个定性特征分布的一些相同图表，例如线图或条形图。举个例子，让我们来研究品种对儿童适宜性和品种大小之间的关系。

要研究这两个定性特征之间的关系，我们计算三组比例（分别对应低、中、高适宜性）。在每个适宜性类别中，我们找出小型、中型和大型狗的比例。这些比例显示在下表中。注意，每列总和为1（相当于100%）：

```py
`prop_table_t`

```

| 儿童 | 高 | 中 | 低 |
| --- | --- | --- | --- |
| 大小 |   |   |   |
| --- | --- | --- | --- |
| **大型** | 0.37 | 0.29 | 0.1 |
| **中等** | 0.36 | 0.34 | 0.2 |
| **小型** | 0.27 | 0.37 | 0.7 |

下面的线图提供了这些比例的可视化。每个适宜性级别都有一条“线”（连接的点集）。连接的点显示了适宜性类别内大小的分布。我们看到，适宜性低的品种主要是小型犬：

```py
`fig` `=` `px``.``line``(``prop_table_t``,` `y``=``prop_table_t``.``columns``,` 
        `x``=``prop_table_t``.``index``,` `line_dash``=``'``kids``'``,`
        `markers``=``True``,` `width``=``500``,` `height``=``250``)`

`fig``.``update_layout``(`
    `yaxis_title``=``"``proportion``"``,` `xaxis_title``=``"``Size``"``,`
    `legend_title``=``"``Suitability <br>for children``"`
`)`

```

![](assets/leds_10in09.png)

我们还可以将这些比例呈现为一组并列条形图，如下所示：

```py
`fig` `=` `px``.``bar``(``prop_table_t``,` `y``=``prop_table_t``.``columns``,` `x``=``prop_table_t``.``index``,`
             `barmode``=``'``group``'``,` `width``=``500``,` `height``=``250``)`

`fig``.``update_layout``(`
    `yaxis_title``=``"``proportion``"``,` `xaxis_title``=``"``Size``"``,` 
    `legend_title``=``"``Suitability <br>for children``"`
`)`

```

![](assets/leds_10in10.png)

到目前为止，我们已经涵盖了包含一个或两个特征的可视化。在下一节中，我们将讨论涵盖超过两个特征的可视化。

# 多元设置中的比较

当我们检查一个分布或者关系时，我们经常希望能够跨数据子群组进行比较。这个在额外因素的条件下进行的过程通常导致涉及三个或更多变量的可视化。在这一节中，我们将解释如何阅读用于可视化多个变量的常用图表。

例如，让我们比较重复类别之间身高和寿命之间的关系。首先，我们将重复（狗学习新命令的典型次数）从六个类别合并为四个：<15、15-25、25-40和40+：

```py
`rep_replacements` `=` `{`
    `'``80-100``'``:` `'``40+``'``,` `'``40-80``'``:` `'``40+``'``,` 
    `'``<5``'``:` `'``<15``'``,` `'``5-15``'``:` `'``<15``'``,`
`}`
`dogs` `=` `dogs``.``assign``(`
    `repetition``=``dogs``[``'``repetition``'``]``.``replace``(``rep_replacements``)``)`

```

现在每个组大约有30种品种，并且更少的类别使关系更容易解读。这些类别在散点图中由不同形状的符号表示：

```py
`px``.``scatter``(``dogs``.``dropna``(``subset``=``[``'``repetition``'``]``)``,` `x``=``'``height``'``,` `y``=``'``longevity``'``,` 
           `symbol``=``'``repetition``'``,` `width``=``450``,` `height``=``250``,`
           `labels``=``{``'``height``'``:``'``Height (cm)``'``,` 
                   `'``longevity``'``:``'``Typical lifespan (yr)``'``,`
                  `'``repetition``'``:``'``Repetition``'``}``,`
          `)`

```

![](assets/leds_10in11.png)

如果“重复”特征内部有更多级别，这种图表将很难解释。

分面图提供了显示这三个特征的另一种方法：

```py
`px``.``scatter``(``dogs``.``dropna``(``subset``=``[``'``repetition``'``]``)``,` 
           `x``=``'``height``'``,` `y``=``'``longevity``'``,` `trendline``=``'``ols``'``,` 
           `facet_col``=``'``repetition``'``,` `facet_col_wrap``=``2``,`
           `labels``=``{``'``height``'``:``'``Height (cm)``'``,` 
                   `'``longevity``'``:``'``Typical lifespan (yr)``'``}``)`

```

![](assets/leds_10in12.png)

这四个散点图中的每一个展示了不同重复范围内寿命与身高之间的关系。通过分离散点图，我们可以更好地评估两个定量特征之间的关系如何随着子组的变化而变化。我们还可以更轻松地看到每个重复范围内身高和寿命的范围。我们可以看到，较大的品种往往寿命较短。另一个有趣的特征是，这些线的斜率相似，但40+重复的线大约比其他线低1.5年。这些品种的平均寿命比其他重复类别低约1.5年，无论其身高如何。

在这里，我们总结了当我们有三个（或更多）特征时进行比较的各种绘图技术：

两个定量和一个定性

我们已经通过散点图演示了这种情况，根据定性特征的类别变化标记，或者通过每个类别的散点图面板。

两个定性和一个定量特征

我们已经看到了根据品种大小的箱线图集合中，我们可以通过并排箱线图比较不同子组的分布的基本形状。当我们有两个或更多定性特征时，我们可以根据其中一个定性特征将箱线图组织成组。

三个定量特征

当我们绘制两个定量特征和一个定性特征时，我们可以使用类似的技术。这次，我们将其中一个定量特征转换为序数特征，其中每个类别通常具有大致相同数量的记录。然后，我们制作其他两个特征的分面散点图。我们再次寻找跨分面的关系相似性。

三个定性特征

当我们检查定性特征之间的关系时，我们会检查在另一个定性特征定义的子组内一个特征的比例。 在上一节中，一个图中的三条线图和并排的条形图都显示了这些比较。 对于三（或更多）个定性特征，我们可以继续根据特征级别的组合细分数据，并使用线图、点图、并排条形图等比较这些比例。 但是这些图往往在进一步细分时变得越来越难以理解。

###### 注意

将可视化分解以查看由定性特征确定的数据子组是否会改变关系是一种良好的做法。 这种技术称为对特征进行“控制”。 当您在散点图中看到一个线性关系有上升趋势，但在散点图的一些或全部方面中却逆转为下降趋势时，您可能会感到惊讶。 这种现象称为“辛普森悖论”。 这种悖论也可能发生在定性特征中。 在伯克利，男性的研究生院录取率高于女性的情况曾是一个[著名案例](https://oreil.ly/h9tMw)，但在每个项目中单独检查时，录取率更青睐于女性。 问题在于，女性更多地申请了录取率较低的项目。

涉及多个分类变量的比较可能会很快变得复杂，因为类别组合的可能性增多。例如，有 3 × 4 = 12 种大小重复的组合（如果我们保留原始的重复类别，会有 18 种组合）。检查 12 个子组的分布可能会很困难。此外，我们面临的问题是子组中观察数太少。尽管狗数据框中有近 200 行，但一半的大小重复组合观察次数为 10 或更少。 （当一个特征具有缺失值时，会丢失一个观察。）当我们比较与定量数据的关系时，也会出现这种“维度灾难”。仅仅三个定量变量在多面图中的一些散点图很容易观察到有太少的观察以确认两个变量在子组之间的关系形状。

现在我们已经看到了在探索性数据分析中常用的可视化实例，我们继续讨论一些EDA的高级指导原则。

# 探索指南

到目前为止，在本章中，我们介绍了特征类型的概念，看到了特征类型如何帮助确定要制作的图表，并描述了如何在可视化中读取分布和关系。 EDA依赖于建立这些技能和灵活地发展对数据的理解。

在[第9章](ch09.html#ch-wrangling)中，我们开发了数据质量检查和特征转换，以提高它们在数据分析中的实用性，从而展示了EDA的实际应用。接下来是一些指导你进行绘图探索数据时的问题：

+   特征X的值是如何分布的？

+   特征X和特征Y之间的关系如何？

+   特征X的分布在由特征Z定义的子组中是否相同？

+   特征X中是否存在任何不寻常的观察？（X，Y）的组合中是否存在？在Z的子组中的X中是否存在？

当回答每个问题时，重要的是将你的答案与测量的特征和上下文联系起来。采用积极好奇的探索方法也很重要。为了指导你的探索，问自己“接下来怎么办”和“这对于什么有意义”的问题，例如以下问题：

+   你有理由期望一个组/观察结果可能不同吗？

+   为什么你对形状的发现很重要？

+   哪些额外的比较可能为调查增加价值？

+   是否有任何重要的特征可以进行比较/对比？

在这个过程中，重要的是偶尔离开电脑，深思熟虑你的工作。你可能想要阅读关于这个主题的额外文献，或者去找领域内的专家讨论你的发现。例如，对于一个不寻常的观察可能有很好的理由，领域内的人可以帮助澄清并提供更多背景。

我们将在接下来的具体EDA示例中将这些准则付诸实践。

# 示例：房屋销售价格

在最后一节中，我们使用前一节的问题进行探索性分析来引导我们的调查。尽管EDA通常从数据整理阶段开始，但出于演示目的，我们处理的数据已经部分清理，以便我们可以专注于探索感兴趣的特征。还要注意，我们没有详细讨论优化可视化的细节；该主题在[第11章](ch11.html#ch-viz)中有涵盖。

我们的数据来自[*旧金山纪事报*](https://oreil.ly/tP9Xp)（SFChron）网站。该数据包括2003年4月至2008年12月旧金山地区出售的所有房屋的完整列表。由于我们没有计划将我们的发现推广到时间段和位置之外，我们正在使用的是普查，人口与访问框架相匹配，样本包括整个人口。

至于粒度，每条记录代表了在指定时间段内在旧金山湾区销售的房屋。这意味着如果一套房在这段时间内销售了两次，那么表中将有两条记录。如果旧金山湾区的一套房在此期间没有上市出售，则它不会出现在数据集中。

数据位于数据帧`sfh_df`中：

```py
`sfh_df`

```

|   | 城市 | 邮政编码 | 街道 | 价格 | 卧室数 | 居住面积 | 建筑面积 | 时间戳 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **0** | Alameda | 94501.0 | 1001 Post Street | 689000.0 | 4.0 | 4484.0 | 1982.0 | 2004-08-29 |
| **1** | Alameda | 94501.0 | 1001 Santa Clara Avenue | 880000.0 | 7.0 | 5914.0 | 3866.0 | 2005-11-06 |
| **2** | Alameda | 94501.0 | 1001 Shoreline Drive \#102 | 393000.0 | 2.0 | 39353.0 | 1360.0 | 2003-09-21 |
| **...** | ... | ... | ... | ... | ... | ... | ... | ... |
| **521488** | 温莎 | 95492.0 | 9998 Blasi Drive | 392500.0 | NaN | 3111.0 | NaN | 2008-02-17 |
| **521489** | 温莎 | 95492.0 | 9999 Blasi Drive | 414000.0 | NaN | 2915.0 | NaN | 2008-02-17 |
| **521490** | 温莎 | 95492.0 | 999 Gemini Drive | 325000.0 | 3.0 | 7841.0 | 1092.0 | 2003-09-21 |

```py
521491 rows × 8 columns
```

The dataset does not have an accompanying codebook, but we can determine the features and their storage types by inspection:

```py
`sfh_df``.``info``(``)`

```

```py
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 521491 entries, 0 to 521490
Data columns (total 8 columns):
 #   Column     Non-Null Count   Dtype         
---  ------     --------------   -----         
 0   city       521491 non-null  object        
 1   zip        521462 non-null  float64       
 2   street     521479 non-null  object        
 3   price      521491 non-null  float64       
 4   br         421343 non-null  float64       
 5   lsqft      435207 non-null  float64       
 6   bsqft      444465 non-null  float64       
 7   timestamp  521491 non-null  datetime64[ns]
dtypes: datetime64[ns](1), float64(5), object(2)
memory usage: 31.8+ MB

```

Based on the names of the fields, we expect the primary key to consist of some combination of city, zip code, street address, and date.

Sale price is our focus, so let’s begin by exploring its distribution. To develop your intuition about distributions, make a guess about the shape of the distribution before you start reading the next section. Don’t worry about the range of prices, just sketch the general shape.

## Understanding Price

It seems that a good guess for the shape of the distribution of sale price might be highly skewed to the right with a few very expensive houses. The following summary statistics confirm this skewness:

```py
`percs` `=` `[``0``,` `25``,` `50``,` `75``,` `100``]`
`prices` `=` `np``.``percentile``(``sfh_df``[``'``price``'``]``,` `percs``,` `method``=``'``lower``'``)`
`pd``.``DataFrame``(``{``'``price``'``:` `prices``}``,` `index``=``percs``)`

```

|   | price |
| --- | --- |
| **0** | 22000.00 |
| **25** | 410000.00 |
| **50** | 555000.00 |
| **75** | 744000.00 |
| **100** | 20000000.00 |

The median is closer to the lower quartile than the upper quartile. Also, the maximum is 40 times the median! We might wonder whether that $20M sale price is simply an anomalous value or whether there are many houses that sold at such a high price. To find out, we can zoom in on the right tail of the distribution and compute a few high percentiles:

```py
`percs` `=` `[``95``,` `97``,` `98``,` `99``,` `99.5``,` `99.9``]`
`prices` `=` `np``.``percentile``(``sfh_df``[``'``price``'``]``,` `percs``,` `method``=``'``lower``'``)`
`pd``.``DataFrame``(``{``'``price``'``:` `prices``}``,` `index``=``percs``)`

```

|   | price |
| --- | --- |
| **95.00** | 1295000.00 |
| **97.00** | 1508000.00 |
| **98.00** | 1707000.00 |
| **99.00** | 2110000.00 |
| **99.50** | 2600000.00 |
| **99.90** | 3950000.00 |

We see that 99.9% of the houses sold for under $4M, so the $20M sale is indeed a rarity. Let’s examine the histogram of sale prices below $4M:

```py
`under_4m` `=` `sfh_df``[``sfh_df``[``'``price``'``]` `<` `4_000_000``]``.``copy``(``)`

```

```py
`px``.``histogram``(``under_4m``,` `x``=``'``price``'``,` `nbins``=``50``,` `width``=``350``,` `height``=``250``,`
             `labels``=``{``'``price``'``:``'``Sale price (USD)``'``}``)`

```

![](assets/leds_10in13.png)

Even without the top 0.1%, the distribution remains highly skewed to the right, with a single mode around $500,000\. Let’s plot the histogram of the log-transformed sale price. The logarithm transformation often does a good job at converting a right-skewed distribution into one that is more symmetric:

```py
`under_4m``[``'``log_price``'``]` `=` `np``.``log10``(``under_4m``[``'``price``'``]``)`

```

```py
`px``.``histogram``(``under_4m``,` `x``=``'``log_price``'``,` `nbins``=``50``,` `width``=``350``,` `height``=``250``,`
             `labels``=``{``'``log_price``'``:``'``Sale price (log10 USD)``'``}``)`

```

![](assets/leds_10in14.png)

We see that the distribution of log-transformed sale price is roughly symmetric. Now that we have an understanding of the distribution of sale price, let’s consider the so-what questions posed in the previous section on EDA guidelines.

## What Next?

我们已经描述了销售价格的形状，但我们需要考虑形状的重要性，并寻找可能有所不同的分布的比较组。

形状很重要，因为基于对称分布的模型和统计性质往往比高度偏斜的分布更具有稳健和稳定的特性（我们在[第15章](ch15.html#ch-linear)中详细讨论这个问题）。因此，我们主要使用对数转换后的销售价格进行分析。而且，我们可能还会选择限制分析范围在400万美元以下的销售价格，因为超级昂贵的房屋可能表现出截然不同的行为。

至于可能进行的比较，我们需要看背景情况。房地产市场在此期间迅速上涨，然后市场崩溃。因此，比如说，2004年的销售价格分布可能与2008年市场崩盘前的情况有很大不同。为了进一步探索这一观点，我们可以分析价格随时间的变化。或者，我们可以固定时间，分析价格与其他感兴趣特征之间的关系。这两种方法都可能是有价值的。

我们将焦点缩小到一年（在[第11章](ch11.html#ch-viz)中我们将研究时间维度）。我们将数据限制在2004年的销售情况，因此上涨的房价对我们研究的分布和关系的影响应该是有限的。为了限制非常昂贵和大型的房屋的影响，我们还将数据集限制在售价低于400万美元和面积小于12,000平方英尺的房屋范围内。这个子集仍然包含大型和昂贵的房屋，但不会过于夸张。稍后，我们将进一步限制我们的研究范围到几个感兴趣的城市：

```py
`def` `subset``(``df``)``:`
    `return` `df``.``loc``[``(``df``[``'``price``'``]` `<` `4_000_000``)` `&`
                  `(``df``[``'``bsqft``'``]` `<` `12_000``)` `&` 
                  `(``df``[``'``timestamp``'``]``.``dt``.``year` `==` `2004``)``]`

`sfh` `=` `sfh_df``.``pipe``(``subset``)`
`sfh`

```

|   | 城市 | 邮政编码 | 街道 | 价格 | 卧室数量 | 生活面积 | 建筑面积 | 时间戳 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **0** | 阿拉米达 | 94501.00 | 1001 Post Street | 689000.00 | 4.00 | 4484.00 | 1982.00 | 2004-08-29 |
| **3** | 阿拉米达 | 94501.00 | 1001 Shoreline Drive \#108 | 485000.00 | 2.00 | 39353.00 | 1360.00 | 2004-09-05 |
| **10** | 阿拉米达 | 94501.00 | 1001 Shoreline Drive \#306 | 390000.00 | 2.00 | 39353.00 | 1360.00 | 2004-01-25 |
| **...** | ... | ... | ... | ... | ... | ... | ... | ... |
| **521467** | 温莎 | 95492.00 | 9960 Herb Road | 439000.00 | 3.00 | 9583.00 | 1626.00 | 2004-04-04 |
| **521471** | 温莎 | 95492.00 | 9964 Troon Court | 1200000.00 | 3.00 | 20038.00 | 4281.00 | 2004-10-31 |
| **521478** | 温莎 | 95492.00 | 9980 Brooks Road | 650000.00 | 3.00 | 45738.00 | 1200.00 | 2004-10-24 |

```py
105996 rows × 8 columns
```

对于这些数据，销售价格分布的形状保持不变——价格仍然高度右偏。我们继续使用这个子集来解决是否有任何重要特征需要与价格一起研究的问题。

## 研究其他特征

除了销售价格外，这是我们的主要关注点，还有一些可能对我们的调查很重要的其他特征，例如房屋大小、地块（或物业）大小和卧室数量。我们探索这些特征的分布以及它们与销售价格和彼此之间的关系。

由于房屋和地产的大小可能与其价格有关，因此猜测这些特征也可能向右倾斜，因此我们对建筑物大小进行对数转换是合理的：

```py
`sfh` `=` `sfh``.``assign``(``log_bsqft``=``np``.``log10``(``sfh``[``'``bsqft``'``]``)``)`

```

我们比较了常规和对数比例尺上建筑面积的分布：

```py
`fig` `=` `make_subplots``(``1``,``2``)`
`fig``.``add_trace``(``go``.``Histogram``(``x``=``sfh``[``'``bsqft``'``]``,` `histnorm``=``'``percent``'``,` 
                           `nbinsx``=``60``)``,` `row``=``1``,` `col``=``1``)`
`fig``.``add_trace``(``go``.``Histogram``(``x``=``sfh``[``'``log_bsqft``'``]``,` `histnorm``=``'``percent``'``,` 
                           `nbinsx``=``60``)``,` `row``=``1``,` `col``=``2``)`

`fig``.``update_xaxes``(``title``=``'``Building size (ft²)``'``,` `row``=``1``,` `col``=``1``)`
`fig``.``update_xaxes``(``title``=``'``Building size (ft², log10)``'``,` `row``=``1``,` `col``=``2``)`
`fig``.``update_yaxes``(``title``=``"``percent``"``,` `row``=``1``,` `col``=``1``)`
`fig``.``update_yaxes``(``range``=``[``0``,` `18``]``)`
`fig``.``update_layout``(``width``=``450``,` `height``=``250``,` `showlegend``=``False``)`
`fig`

```

![](assets/leds_10in15.png)

分布是单峰的，峰值约为1,500平方英尺，许多房屋的面积超过2,500平方英尺。我们已经确认了我们的直觉：对数转换后的建筑面积几乎是对称的，尽管保持了轻微的倾斜。对于地块面积的分布也是如此。

鉴于房屋和地块面积都呈现偏斜分布，两者的散点图很可能也应采用对数比例尺：

```py
`sfh` `=` `sfh``.``assign``(``log_lsqft``=``np``.``log10``(``sfh``[``'``lsqft``'``]``)``)`

```

我们比较了有和没有对数转换的图形：

![](assets/leds_10in16.png)

左边的散点图是以原始单位表示的，这使得很难辨别它们之间的关系，因为大多数点都挤在绘图区域的底部。相比之下，右边的散点图显示了一些有趣的特征：沿着散点图底部有一条水平线，看起来许多房屋的地块大小相同，无论建筑物的大小如何；而且似乎地块和建筑物大小之间存在轻微的正对数线性关系。

让我们看一下地块大小的一些较低分位数，试图弄清这个异常值：

```py
`percs` `=` `[``0.5``,` `1``,` `1.5``,` `2``,` `2.5``,` `3``]`
`lots` `=` `np``.``percentile``(``sfh``[``'``lsqft``'``]``.``dropna``(``)``,` `percs``,` `method``=``'``lower``'``)`
`pd``.``DataFrame``(``{``'``lot_size``'``:` `lots``}``,` `index``=``percs``)`

```

|   | lot_size |
| --- | --- |
| **0.50** | 436.00 |
| **1.00** | 436.00 |
| **1.50** | 436.00 |
| **2.00** | 436.00 |
| **2.50** | 436.00 |
| **3.00** | 782.00 |

我们发现了一些有趣的东西：大约有2.5%的房屋的地块面积为436平方英尺。这太小了，几乎没有意义，因此我们记录下这个异常值以供进一步调查。

另一种衡量房屋大小的方法是卧室数量。由于这是一个离散的定量变量，我们可以将其视为定性特征并制作条形图。

旧金山湾区的房屋往往比较小，所以我们猜测分布会在三处达到峰值，并向右倾斜，有些房屋有五六间卧室。让我们来检查一下：

```py
`br_cat` `=` `sfh``[``'``br``'``]``.``value_counts``(``)``.``reset_index``(``)`
`px``.``bar``(``br_cat``,` `x``=``"``br``"``,` `y``=``"``count``"``,` `width``=``350``,` `height``=``250``,`
       `labels``=``{``'``br``'``:``'``Number of bedrooms``'``}``)`

```

![](assets/leds_10in17.png)

条形图证实了我们一般的想法。然而，我们发现有些房屋有超过30间卧室！这有点难以置信，也指向另一个可能的数据质量问题。由于记录包括房屋的地址，我们可以在房地产应用程序上再次检查这些值。

与此同时，让我们将卧室数量转换为有序特征，将所有大于8的值重新分配为8+，并使用转换后的数据重新创建条形图：

```py
`eight_up` `=` `sfh``.``loc``[``sfh``[``'``br``'``]` `>``=` `8``,` `'``br``'``]``.``unique``(``)`
`sfh``[``'``new_br``'``]` `=` `sfh``[``'``br``'``]``.``replace``(``eight_up``,` `8``)`

`br_cat` `=` `sfh``[``'``new_br``'``]``.``value_counts``(``)``.``reset_index``(``)`
`px``.``bar``(``br_cat``,` `x``=``"``new_br``"``,` `y``=``"``count``"``,` `width``=``350``,` `height``=``250``,`
       `labels``=``{``'``new_br``'``:``'``Number of bedrooms``'``}``)`

```

![](assets/leds_10in18.png)

我们可以看到，即使我们将所有具有8个或更多卧室的房屋归为一类，它们的数量也不多。分布几乎对称，高峰出现在3个卧室，大约有相同比例的房屋有两个或四个卧室，同样有一个或五个卧室的房屋。存在不对称性，有少数房屋拥有六个或更多卧室。

现在我们来研究卧室数量与销售价格之间的关系。在我们继续之前，我们先保存目前已经完成的转换：

```py
`def` `log_vals``(``df``)``:`
    `return` `df``.``assign``(``log_price``=``np``.``log10``(``df``[``'``price``'``]``)``,`
                     `log_bsqft``=``np``.``log10``(``df``[``'``bsqft``'``]``)``,`
                     `log_lsqft``=``np``.``log10``(``df``[``'``lsqft``'``]``)``)`

`def` `clip_br``(``df``)``:`
    `eight_up` `=` `df``.``loc``[``df``[``'``br``'``]` `>``=` `8``,` `'``br``'``]``.``unique``(``)`
    `new_br` `=` `df``[``'``br``'``]``.``replace``(``eight_up``,` `8``)`
    `return` `df``.``assign``(``new_br``=``new_br``)`

`sfh` `=` `(``sfh_df`
 `.``pipe``(``subset``)`
 `.``pipe``(``log_vals``)`
 `.``pipe``(``clip_br``)`
`)`

```

现在我们准备考虑卧室数量与其他变量之间的关系。

## 深入探讨关系

让我们从检查不同卧室数量的房屋价格分布开始。我们可以通过箱线图来完成这个任务：

```py
`px``.``box``(``sfh``,` `x``=``'``new_br``'``,` `y``=``'``price``'``,` `log_y``=``True``,` `width``=``450``,` `height``=``250``,`
      `labels``=``{``'``new_br``'``:``'``Number of bedrooms``'``,``'``price``'``:``'``Sale price (USD)``'``}``)`

```

![](assets/leds_10in19.png)

中位数销售价格随着卧室数量从一增加到五而增加，但对于最大的房屋（超过六个卧室的房屋），对数转换后的销售价格分布几乎相同。

我们预期一居室的房屋比四居室的房屋小。我们还可能猜想，六个或更多卧室的房屋在大小和价格上是类似的。为了深入了解，我们考虑一种将价格除以建筑面积的转换，得到每平方英尺价格的方法。我们想要检查这个特征是否对所有房屋都是恒定的；换句话说，价格是否主要由房屋大小决定。为此，我们查看了大小和价格、每平方英尺价格和大小之间的关系：

```py
`sfh` `=` `sfh``.``assign``(`
    `ppsf``=``sfh``[``'``price``'``]` `/` `sfh``[``'``bsqft``'``]``,` 
    `log_ppsf``=``lambda` `df``:` `np``.``log10``(``df``[``'``ppsf``'``]``)``)`

```

我们创建了两个散点图。左侧图显示价格与建筑面积（都进行了对数转换），右侧图显示每平方英尺价格（进行了对数转换）与建筑面积之间的关系。此外，每个图中都添加了一个平滑曲线，反映了大致相同大小建筑的局部平均价格或每平方英尺价格：

![](assets/leds_10in20.png)

左侧图表显示了我们的预期—更大的房屋成本更高。我们还看到这些特征之间大致存在对数关联。

此图中的右侧图表非常有趣地呈现了非线性特征。我们看到较小的房屋每平方英尺的成本比较大的房屋更高，而较大房屋的每平方英尺价格相对平稳。这一特征似乎非常有趣，因此我们将每平方英尺价格转换保存为`sfh`：

```py
def compute_ppsf(df):
    return df.assign(
        ppsf=df['price'] / df['bsqft'],
        log_ppsf=lambda df: np.log10(df['ppsf']))

```

到目前为止，我们还没有考虑价格与位置之间的关系。这个数据集中来自150多个不同城市的房屋销售数据。有些城市只有少数销售记录，而其他城市则有数千条。我们继续缩小数据范围，并在接下来的几个城市中研究关系。

## 修正位置

你可能听过这样的表达：房地产有三个重要因素—*位置、位置、位置*。比较不同城市的房价可能会为我们的调查带来额外的见解。

我们检查了旧金山东湾一些城市的数据：里士满、埃尔塞里托、奥尔巴尼、伯克利、核桃溪、拉莫林达（这是拉斐特、莫拉加和奥林达三个相邻的卧室社区的组合），以及皮德蒙特。

让我们开始比较这些城市的销售价格分布：

```py
`cities` `=` `[``'``Richmond``'``,` `'``El Cerrito``'``,` `'``Albany``'``,` `'``Berkeley``'``,`
          `'``Walnut Creek``'``,` `'``Lamorinda``'``,` `'``Piedmont``'``]`

`px``.``box``(``sfh``.``query``(``'``city in @cities``'``)``,` `x``=``'``city``'``,` `y``=``'``price``'``,` 
       `log_y``=``True``,` `width``=``450``,` `height``=``250``,` 
       `labels``=``{``'``city``'``:``'``'``,` `'``price``'``:``'``Sale price (USD)``'``}``)`

```

![](assets/leds_10in21.png)

箱线图显示，拉莫林达和皮德蒙特的房屋更昂贵，里士满最便宜，但许多城市的销售价格存在重叠。

接下来，我们将使用分面散点图更仔细地检查每个四个城市的房价与房屋大小之间的关系：

```py
`four_cities` `=` `[``"``Berkeley``"``,` `"``Lamorinda``"``,` `"``Piedmont``"``,` `"``Richmond``"``]`
`fig` `=` `px``.``scatter``(``sfh``.``query``(``"``city in @four_cities``"``)``,`
    `x``=``"``bsqft``"``,` `y``=``"``log_ppsf``"``,` `facet_col``=``"``city``"``,` `facet_col_wrap``=``2``,`
    `labels``=``{``'``bsqft``'``:``'``Building size (ft^2)``'``,` 
            `'``log_ppsf``'``:` `"``Price per square foot``"``}``,` 
    `trendline``=``"``ols``"``,` `trendline_color_override``=``"``black``"``,`
`)`

`fig``.``update_layout``(``xaxis_range``=``[``0``,` `5500``]``,` `yaxis_range``=``[``1.5``,` `3.5``]``,`
                  `width``=``450``,` `height``=``400``)`
`fig``.``show``(``)`

```

![](assets/leds_10in22.png)

价格每平方英尺与建筑面积的关系大致呈对数线性，对于这四个地点每个都存在负相关。虽然不是平行的，但似乎在房子方面存在地理位置的提升，例如伯克利的房屋每平方英尺比里士满的房屋贵约250美元。我们还看到皮德蒙特和拉莫林达是更昂贵的城市，在这两个城市中，与较小房屋相比，较大房屋每平方英尺的价格没有同样的降低。这些图表支持“地段，地段，地段”的格言。

在探索性数据分析（EDA）中，我们经常回顾早期的图表，以检查新发现是否为先前的可视化增添了新的见解。持续盘点我们的发现并利用它们指导我们进一步的探索至关重要。让我们总结一下到目前为止我们的发现。

## EDA 发现

我们的EDA揭示了几个有趣的现象。简而言之，其中一些最显著的是：

+   销售价格和建筑面积呈右偏分布，有一个主模式。

+   每平方英尺价格随建筑面积的增加呈非线性下降趋势，较小的房屋每平方英尺的成本高于较大的房屋，并且每平方英尺的价格在大房屋中大致保持不变。

+   更理想的地理位置为房屋的销售价格增加了一点，对于不同大小的房屋增加的金额大致相同。

我们可以（也应该）进行许多其他探索，还有几个我们应该进行的检查。这些包括调查占地面积436的价值和用在线房地产应用程序交叉检查异常房屋，例如30卧室房屋和2000万美元的房屋。

我们将我们的调查限制在一年内，后来又缩小到几个城市。这种缩小帮助我们控制可能干扰发现简单关系的特征。例如，由于数据是在几年内收集的，销售日期可能混淆了销售价格和卧室数量之间的关系。在其他时候，我们希望考虑时间对价格的影响。为了检查随时间的价格变化，我们经常制作折线图，并对通货膨胀进行调整。我们在[第11章](ch11.html#ch-viz)重新审视这些数据时，考虑数据范围并更仔细地观察时间趋势。

尽管简短，本节传达了EDA实践的基本方法。有关不同数据集的扩展案例研究，请参阅[第12章](ch12.html#ch-pa)。

# 总结

在本章中，我们介绍了名义、序数和数值特征类型及其在数据分析中的重要性。当面对数据集时，我们展示了如何查阅数据字典和数据本身，以确定每列的特征类型。我们还解释了存储类型与特征类型不应混淆。由于大部分EDA是通过统计图表进行的，我们描述了如何识别和解释出现的形状和模式，以及如何将其与正在绘制的数据联系起来。最后，我们提供了进行EDA的指导方针，并提供了一个示例。

有一种方法可能对你在开发关于特征分布和关系直觉很有帮助，那就是在绘制图表之前先对你将看到的内容进行猜测。试着草拟或描述你认为分布形状会是什么样子，然后再绘制图表。例如，具有自然下限/上限值的变量往往在边界的对面有一个长尾。收入分布（下限为0）往往有一个长尾在右侧，而考试成绩（上限为100）往往有一个长尾在左侧。你可以对关系的形状做类似的猜测。我们发现价格和房屋大小几乎呈对数-对数线性关系。当你对形状有了直觉后，进行探索性数据分析（EDA）就变得更容易；你可以更容易地识别出图表显示出令人惊讶的形状。

本章的重点是“阅读”可视化结果。在[第11章](ch11.html#ch-viz)中，我们提供了如何创建信息丰富、有效和美观的图表的样式指南。这一章中许多思想也在这里得到了遵循，但我们并未特别指出它们。
