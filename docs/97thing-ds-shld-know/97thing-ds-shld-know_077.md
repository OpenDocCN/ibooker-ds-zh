# 第七十一章：在数字时代平等分配道德结果

# Keyur Desai

![](img/Keyur_Desai.png)

TD Ameritrade 首席数据官

数据是一种不可腐化的原材料，经过分析可以揭示和证明真理——本质上来说，“数据即真理”。自 17 世纪中期数据首次用于科学理解以来，这种观念就错误地渗透到了社会中。更接近现实的是，当数据被错误使用时，它是一种可腐化的原材料，可以被物理操纵以得出符合原始者利益的真理/洞察，或者得出符合原始者意识或潜意识偏见的真理/洞察。我喜欢作者史蒂芬·杰·古尔德在他的著作《人的误量》（W. W. Norton）中如何简洁而深刻地表达这一点：“期望是行动的强有力指导。” 近代和远古历史上有很多例子，显示个人和社区因数据或算法偏见分析而受到错误影响。数据可以影响权力、人的生活、健康、知识、信仰和福祉的动态。算法可以强化压迫和不平等，并与监控资本主义相关联。我认为“只有在道德和诚信的前提下，数据才是真理”。

要揭示其真理，数据必须在其整个供应链中使用诚信和道德。也就是说，数据必须从人类创建、定义、查找、检查、获取、准备分析、分析以及分享洞见或建立人工智能系统的起点开始，都要保持诚信和道德。我们能做些什么来确保整个分析供应链都在道德和诚信的指导下运作，以便我们可以完全信任所接受的真理/洞察？这里有三件事情。

首先，我们需要一个伦理框架，以确保所有参与者理解分析供应链对他们施加的共同操作期望。要建立这一框架，我们需要确保这些期望可以被社区成员轻松快速地理解，并且足够灵活，适用于许多不同的情况。我们需要的是一套指导原则，而不是一套死板的规则。此外，我们需要意识到整个分析供应链是由人类创造的，由人类操作，并将影响其他人类。因此，当我们定义伦理框架时，我们需要以社会学的视角而不是技术视角来做。正如医学研究社区在 20 世纪 70 年代由于图斯基吉梅梅梅梅疯狂患者研究中的伦理缺失而苦苦挣扎一样，一个委员会由 1974 年国家研究法案创建，负责确定应该支持涉及人类受试者的生物医学和行为研究的基本伦理原则，并制定指南以确保这些研究符合这些原则。结果是贝尔蒙特报告。该报告概述了三个原则：

尊重个人

保护所有人的自治权，并对他们彬彬有礼和尊重，并允许知情同意。研究人员必须真实无欺。

善行

尊重“不做伤害”的理念，同时最大化研究项目的利益，最小化对研究对象的风险。

*公正*

确保通过公平分配成本和利益给潜在的研究参与者，合理、非剥削和深思熟虑的程序公平地执行。

将这些原则适应于分析领域，我们可以重新表述为：（1）自治权——人们应该能够自主决定其数据的收集和使用；（2）不做伤害；以及（3）共情和透明度——你是否愿意成为创建数据真相/见解的人，或者是受这些真相/见解影响的人，并且能够解释数据和分析的来源导致了什么行动？

第二，我们需要对分析供应链进行独立监督，监督者思想的多样性至关重要。伦理原则是一个很好的起点，并将对参与分析供应链的人类产生一致性，幸运的是，他们大多数是出于善意。但仅靠原则无法阻止那些有意扭曲数据真相的不良信息提供者，或者无意间存在偏见的信息提供者。任何一种情况的后果都可能对个人或人群造成灾难性影响。为了防止这些后果，我们需要一个独立监督整个分析供应链的机制。然而，单靠独立监督还无法消除偏见。为此，我们还需要确保监督者中存在多样化的视角。社会科学家与数据科学家和人工智能专家的协作视角可以揭示出后两者可能忽视的后果，同样受到数据/系统行动影响的人们的视角也是如此。

第三，独立监督需要适应快速发展的数字世界。每个决策都必须得到委员会批准的非数字化结构将阻碍数字世界需要保持的速度和灵活性。对此的一个引人注目且现代的解决方案是创建一个数字能力，允许数据和分析专家在分析供应链的每个环节独立执行其工作。当他们执行工作时，就像亚马逊可以查看您的浏览活动和购买记录而无需您明确向亚马逊提供这些数据一样，监督委员会有能力审查关于数据来源的信息；数据来源中数据的创建、更新和删除方式；这些来源的数据质量；在这些数据上执行的具体计算；以及使用这些计算和结论制定行动的报告。这一切都可能通过捕获整个分析供应链的端到端传承实现，以及包括数据湖、数据目录和数据准备在内的现代数据治理技术。数据科学和人工智能可以在这样一个技术系统的基础上使用，为监督委员会标记可疑行为，就像银行可能会为进一步审查的潜在欺诈行为进行标记一样。

借助易于理解且灵活的伦理框架，独立监督整个分析供应链，监督过程中多元化的视角，以及数字化监督系统，我们可以确保我们人工智能系统产生的洞察和行动是符合伦理的。

¹ 维基百科，参见“贝尔蒙报告”，最后修改于 2020 年 5 月 17 日，07:41，[*https://oreil.ly/jkUv-*](https://oreil.ly/jkUv-)。
