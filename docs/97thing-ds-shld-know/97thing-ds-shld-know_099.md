# 第九十二章：为 LAWS 奠定基础

# Stephanie Seward

![](img/Stephanie_Seward.png)

同事，Booz Allen Hamilton¹

AI 技术的进步引发了对禁止致命自主武器系统（LAWS）的正当呼吁。全球各国政府对这些呼吁沉默以对。当国家、治理方法和生命岌岌可危时，领导者们会采取极端措施以确保生存并保护其公民。在未来的战争中，LAWS 快速评估和参与目标的能力将为拥有最先进技术并愿意使用的国家提供决定性优势。在战争中，获胜所需的技术必定占据主导地位。考虑到这些鲜明的现实，AI 机器需要多大程度的确证才能自主参与或通知重要决策？以下是从业者可用来决定在自主系统中给予多少自由度的方法论。

## 性能期望方法（PEM）

在一组数据上训练并在另一组数据上测试的模型具有准确性的基准指标，可能不代表真实场景。PEM 旨在以代表真实场景的方式测试 LAWS，并应作为 LAWS 在独立决策前必须通过的测试要求的基准。就像一名在医学院期间表现优异的医生仍需完成住院医师培训一样，LAWS 也应经历严格的试用期。

PEM 由两个组成部分组成：测试环境（TE）和输出准确性度量（OAM）。TE 旨在模拟真实场景。例如，用于识别敌方火炮的 LAWS 可以在包含友军和敌军装备、试验假人及其他非敌方火炮物体的 TE 中进行测试。LAWS 在正确识别目标方面的性能即为 OAM。

此外，在决策过程中，LAWS 训练中的 TE 必须部署到类似的环境中。例如，完成 PEM 的沙漠 TE 中的 LAWS 必须在完成 PEM 后部署到沙漠环境中。如果同一台 LAWS 在 PEM 后部署到森林环境中，可能由于环境偏差而导致精度下降，需要重新评估其性能。

## PEM 期间的 LAWS 性能

考虑这样一个场景，即正在进行 PEM 的火炮识别 LAWS 获得了 99.9%的 OAM；在 1000 个目标中，系统正确地将 999 个识别为敌方火炮或非敌方火炮。*要求 LAWS 参与标准化的 PEM 使数据科学家能够识别和确定 LAWS 在识别方面的优势和劣势，并确定 LAWS 在部署前必须表现得多好。*在这种情况下，LAWS 的准确率为 99.9%，但它有 0.1%的时间将友方火炮误认为敌方火炮。0.1%的混淆水平是否指导了 PEM 的成功完成标准？当 LAWS 可能犯下友军误伤时，应该部署它吗？如果同一 LAWS 将敌方火炮错误地识别为敌方坦克 0.1%的时间，那是否更可接受？也许这同一 LAWS 的准确率超过了人类。是否可以部署它？

这些问题的答案与当前的战争法律和国家参与的战争水平相一致。例如，在全面战争中，PEM 的标准可能较低，因为潜在的附带损害被继续战争中失去的生命所超越。在反恐怖主义场景中，也许 PEM 的 OAM 要求和 TE 条件要高得多，否则 LAWS 将完全被禁止使用，因为即使微小的不准确性风险也可能产生深远的战略影响。PEM 是一种方法，使各国有机会制定政策，以确保 LAWS 尽可能以道德方式使用。

## PEM：持续和循环

PEM 要求在国际范围内实施额外的可执行标准。此外，PEM 仅确定 LAWS 是否最初可部署。必须定期监控 LAWS 以确保持续准确性，否则它们可能会被“撤出生产线”，并使用 PEM 重新测试。已经进行模型重新训练的 LAWS 在部署之前也必须在 PEM 下重新认证，以确保持续性能。

## PEM 的扩展

PEM 适用于各种情境。随着人工智能系统的持续进入和改善生活，必须确保 AI 系统在其使用意图基础上的成功度量标准贯穿整个生命周期。

¹ 本文中表达的观点是作者个人的观点，不代表 Booz Allen Hamilton 的观点。
