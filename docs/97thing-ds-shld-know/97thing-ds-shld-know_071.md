# 第六十六章：自动检查伦理违规

# 杰西·安德森

![](img/Jesse_Anderson.png)

大数据研究所董事总经理

数据科学有时候喜欢很元。有推动使用机器学习模型来检查数据科学家或其他机器学习模型是否存在伦理违规的趋势。看守者正在被机器学习模型监视。

我经常被问到机器学习模型是否真的能够自动检查伦理违规。这个问题通常来自那些担心数据科学家需要运行的查询数量和总体发现的公司。随着数据民主化的推动，更多人将获得数据访问权限，这意味着更多的可能出现伦理违规。对于管理团队或总法律顾问来说，要审查每一个查询几乎是不可能的。

我认为，依靠机器学习模型来查找伦理违规是不可能的。编写机器学习模型的人与机器会监视潜在违规的人是同一个人。如果他们不是编写它的人，他们将有足够的背景知识，知道如何避免将其查询标记为伦理违规。特别是数据科学家将能够对使用的算法进行有根据的猜测，并且将知道每个算法的弱点在哪里。

尽管如此，公司对伦理违规的曝光仍然相同。必须采取行动。公司能做些什么呢？

在公司甚至尝试手动或自动检查伦理违规之前，公司需要将代码和查询集中化，以便它们被记录在一个地方。这是数据工程团队需要实施的事情。如果没有一个地方来记录所有查询和代码执行，将会有太多的临时位置可以运行检查。这将使得在某人确实下决心行事不道德时很容易绕过日志记录。

一旦所有查询和代码执行被集中，管理团队和总法律顾问可以开始寻找违规行为。通过 SQL 查询，意图和结果将相对容易进行审查。

使用代码，审查过程可能会更加困难和耗时。这是因为管理团队和总法律顾问可能不知道如何阅读代码。即使他们懂得编码，代码的意图和结果可能不会立即显现出来——代码甚至可能会被混淆以隐藏其背后的意图。此外，代码本身可能无法访问或检入源代码控制，以便可以阅读运行的确切代码。

我认为   我认为唯一可行的解决方案是雇佣优秀的人员，对公司数据的使用规范进行培训，并对他们的代码和查询进行抽查。仅仅检查每一行代码显然不是现实的方法。避免代码检查的两种替代方案都不可行。一种选择是因为担心伦理问题而决定永远不将数据交给员工处理——那么，为何还要有数据战略呢？另一种选择是对员工的一切行为都默许并寄希望于最好的结果。我认为最佳选择在于两者之间的某个地方。
