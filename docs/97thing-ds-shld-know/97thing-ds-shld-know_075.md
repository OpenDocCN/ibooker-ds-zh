# 第七十章：向算法谦卑迈进

# Marc Faddoul

![](img/marc_faddoul.png)

加州大学伯克利分校信息学院研究助理

被告 #3172 是一名未婚的 22 岁女性。她曾因大麻贩卖入狱两个月，并刚刚因与伴侣在公共场合发生激烈冲突而被捕。在审判前三个月内，被告会不会再次犯下暴力犯罪？要回答这样的问题，许多美国司法管辖区使用称为预审风险评估工具的算法系统。让我们考虑其中最常见的工具之一，公共安全评估（PSA）。

当 PSA 看到高风险时，它会引发警示，这会自动将被告送入拘留，而不再考虑法官对机器预测的挑战。风险很高，因为预审拘留通常会对被告的工作和住房安全造成毁灭性后果，包括那些在审判中后来被证明无罪的人。*悲剧的是，这些毁掉生活的算法警示中，97% 实际上都是误报。*² 换句话说，被标记的被告中，有 3% 实际上会在释放后犯下暴力犯罪，而其他 97% 则是不必要的拘留。这是一个惊人的糟糕表现，但也不足为奇。

预见未来犯罪是困难的，机器不是神谕。然而，它们可以提供有价值的预测线索，但前提是要有必要的智慧谦卑。遗憾的是，PSA 被设计成一种傲慢的算法。

如果被告在审判前被系统性地释放，大约有 1% 的被告会犯下暴力犯罪。通过比较这些罪犯的档案和特定被告的档案，PSA 的表现比随机猜测好三倍：它仅仅对每个检测到的罪犯关押了 33 名被告。 

事实上，有限的人口统计和司法数据远远不足以预测犯罪。有关心理健康或住房稳定性的信息可能更具预测性，但也很难以公正和系统的方式收集。即便如此，仍会存在一些随机性。两个对算法看起来完全相同的人可能最终处于不同的情况，并做出不同的决定。

此外，算法无法从其错误中学习。当特定被告被拘留时，无法知道如果他们被释放是否真的会犯罪。从根本上说，预测信号很弱。因此，该算法永远无法高准确度地预测犯罪。

错误是不可避免的，但这本身并不是问题。像其他经验科学一样，数据科学可以通过进行概率预测和包括置信区间来处理不确定性。然而，PSA（Public Safety Assessment，公共安全评估）则在任意刻度上进行预测，没有显示置信度或错误率的迹象。一些人为此设计辩护，声称这样更容易让法官理解，因为他们无法理解概率。这是一种傲慢的想法。当前系统并不简单；它是简单化的，这使它具有误导性。算法通过提升规范性红旗误导法官。如果它实际上给出了概率，法官就会知道“高风险标志”实际上意味着“大约有 3%的机会”。

这种设计也低估了法官获取额外背景信息的能力。例如，一个谦逊的算法可能指出，对于特定被告来说，家庭暴力是一个可能的风险情景，鼓励法官调查该被告当前的伴侣关系。对于某些档案，算法的训练记录可能有限或不一致。如果统计信号不足以进行良好的预测，一个谦逊的算法会完全依赖法官做出决定。

算法和人类一样，并非完全或均衡地具备专业知识。因此，它们应该承认自己的局限性。在法庭上使用算法的目的是消除人类的偏见。这是一个合理的担忧，因为法官可能存在对种族、性别、社会阶层甚至午餐选择的偏见³。

有时人们认为算法是纯客观的，但除了午餐菜单之外，它们并不免于偏见。与人类一样，它们的偏见源于对世界有限和非典型经验的不准确概括。当算法面对美国的司法记录时，它会立即得出结论，认为非裔美国人更有可能犯罪。美国残存的种族歧视遗产以及司法系统对非裔美国人的结构性偏见对这种机器来说并不重要。即使没有提供被告的种族信息，也可以从被告的邮政编码或被告犯罪记录中推断出来。

为了平衡这种影响，可以设计算法以实施某种公平主张。例如，可以将错误率限制在不同族裔群体之间相等。具体来说，这种限制定义了一项平权行动政策：*当考虑黑人被告以抵消种族歧视时，算法应该更加宽容多少？* 算法散布有这样的参数，可以调整幕后的关键权衡。傲慢的算法可能有意地不透明，以掩盖政策决策。最基本的参数就是这个：*我们愿意为了防止一个人犯下暴力犯罪而将多少无辜人关进监狱？* 答案是“为了每个罪犯，愿意让 33 个无辜人坐牢”，这个数字隐藏在代码内部。确实，谁能合理地大声辩论说，1:33 的比率是公平的？这个数字被选择，以便算法能够复制当前系统的监禁率。但这种做法是错误的：算法不应悄悄地自动化荒谬的司法标准，而应暴露和挑战它们的假设。

在数字时代，计算机程序已成为我们自由的主要调控者——因此有了“代码即法则”的说法。⁴ 算法设计、训练集、错误率和公平主张都应该是透明的，因为不透明可能是暴政。数据科学可以提供宝贵的洞察力，指导复杂和重大的决策。然而，当数据科学掩盖底层问题的复杂性时，它可能对决策造成不利影响。

围绕人工智能的流行神话夸大了预测工具的能力。如果算法要取代或支持人类专业知识，它们不应该表现得像拥有无上否决权的神秘裁判，而应该更像明智的顾问。无论是机器还是人类专家，都应该具备同样的勤奋精神：证明决策的合理性，承认盲点，并保持谦逊。相应地，人类应该以批判的态度与算法交互，利用人工智能永远缺乏的基本认知部分：常识。

¹ PSA 被用作举例，但在本文所描绘的缺点也适用于美国司法管辖区使用的其他预审风险评估工具。PSA 可以说是设计较为符合伦理的工具之一。

² Marc Faddoul, Henriette Ruhrmann, and Joyce Lee，《一种预先风险评估工具的风险评估：斗争、缓解策略和固有限制》，《计算机与社会》，康奈尔大学，2020 年 5 月 14 日提交，[*https://arxiv.org/abs/2005.07299*](https://arxiv.org/abs/2005.07299)。

³ Shai Danziger, Jonathan Levav, 和 Liora Avnaim-Pesso，《司法决策中的外部因素》，《国家科学院院刊》108 卷，第 17 期（2011 年）：6889–92，[*https://doi.org/10.1073/pnas.1018033108*](https://doi.org/10.1073/pnas.1018033108)。

⁴ Lawrence Lessig，《网络空间的法则与其他法律》（纽约：基础书籍，1999 年）。
