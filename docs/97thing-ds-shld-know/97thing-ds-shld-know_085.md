# 第七十九章：使问责成为优先事项

# Yiannis Kanellopoulos

![](img/Yiannis_Kanellopoulos.png)

创始人，Code4Thought

毫无疑问，算法系统正在做出对我们日常生活产生重大影响的决策。正如尤瓦尔·诺亚·哈拉利在他的书《21 世纪的 21 堂课》（Random House）中所述：“今天，‘真理’已由谷歌搜索的前几个结果来定义。”因此，关于这些系统功能的透明性不仅仅是目的本身，而是达到问责的手段。

根据西北大学计算新闻实验室（CJL）主任、助理教授 Nicholas Diakopoulos 的说法，这里的“问责”意味着决定何时以及如何引导（或限制）算法系统在面临关键或昂贵错误、歧视、不公正拒绝或审查风险时的程度。

简而言之，对系统进行问责意味着我们应该在技术和组织层面上对其进行控制。尤其是当我们（有点简单地）考虑到算法系统仅仅是一个能够：

+   解决组织提出的业务问题集（系统）

+   以由人类或自动化过程选择和预处理的数据作为输入

+   利用模型（例如支持向量机、深度学习、随机森林等），处理选定的数据并最终做出决策或提出组织提出的问题/问题集的答案/解决方案

要能够控制这种软件，我们需要深入了解（或对每个前述方面做出明智决策）。

创建该系统的组织需要在系统开始开发之前，为系统的问责性提供设计和关注。具体来说，该组织应该：

+   建立可见的补救方式，以应对其系统造成的不利个人或社会影响。

+   遵循人在环路中的原则，并指定适当的人员在出现问题时做出正确的决策。

+   能够以非技术术语向最终用户和其他利益相关者解释其系统的决策。

+   知道其算法的潜在误差来源及其如何减轻其影响。

+   允许感兴趣的第三方探索、理解和审查其算法的行为。

+   确保算法决策在考虑不同人群（例如种族、性别、教育水平等）时不会产生歧视性或不公正的影响。

关于系统的输入数据，即现代经济中所谓的“新油”，我们主要需要关心其：

+   质量，包括准确性、完整性和不确定性，以及及时性，样本对特定人群的代表性和假设或其他限制

+   处理，包括数据定义，收集方式，审查和编辑（手动或自动化）。

关于模型本身，考虑的最重要的事情包括：

+   它是否适合当前的问题。这可能看起来很奇怪，但我们看到有些模型从未被操作化，仅仅因为它们不适合特定目的。

+   模型构建的过程，即确定其输入和所选特征或变量，以及它们的权重（如果它们是加权的）。

+   评估这个模型的方式，即确定要使用的评估指标，其选择背后的理由，以及最重要的是如何使用和解释这些指标。

+   模型的准确度或误差范围，以及数据科学家能够将其与标准数据集和标准准确度度量进行基准比较的能力。

考虑责任并以责任为设计基础的组织可以获得以下好处：

+   使用系统的组织与其输出受影响的人之间的信任（无论是客户、公民还是普通用户），因为结果可以解释清楚。

+   系统输出的改进，因为可以根据需要校准/微调识别的加权因子和阈值。

+   使系统更具说服力，因为其推理将更易于解释。

当前，公共讨论充满了自动决策出现严重问题的例子，从关键问题（例如，亚马逊的人力资源系统偏向于男性候选人）到甚至涉及生死的错误（例如，由优步自动驾驶汽车引发的致命事故）。很明显，我们人类需要控制我们所创造的技术。在我们开始开发自主决策系统之前，建立评估流程并让人类参与其中应成为组织部署任何为我们做出决策但没有我们的系统的先决条件。
