# 第七十八章：人工智能：在新兴伦理中的法律责任

# Pamela Passman

![](img/Pamela_Passman.png)

副主席，Ethisphere

CEO，负责企业与贸易的中心（CREATe.org）

对 AI 的使用兴趣正在增加，2019 年全球 500 强企业中 30%的受访样本报告称他们已经在选择性的业务功能中使用 AI。AI 可以在广泛的应用和活动中发挥作用，从产品设计和测试到各种数据分析、市场营销功能、机器学习、医疗测试、虚拟援助和其他任务。

人们对 AI 的可靠性和潜在误用的担忧也是企业、[投资者](https://oreil.ly/JxvO-)、政府和消费者关注的焦点。AI 带来的广泛新机遇和风险已经促使至少[32 种不同的 AI 伦理准则](https://oreil.ly/4PwWR)的制定，这些准则由行业、非政府组织和政府共同提供指导，以支持社会价值观并管理风险。

总体而言，AI 的代码处理[三个高级问题](https://oreil.ly/FMsMO)：AI 的负责设计和使用，AI 的道德使用，以及我们将在这里深入探讨的问题——AI 的合法使用。AI 的合法使用涉及符合公司在与 AI 相关的法律要求和责任方面的规定，包括*数据隐私*和*网络安全*。它还涉及将 AI 用于*合法目的*，而不是用于本身非法、危险或可能为公司带来责任的活动。

## 数据隐私

许多 AI 功能涉及分析大量数据，以预测行为或结果，并作出更为明智的决策。从实际应用角度来看，这意味着 AI 系统可以分析和综合数百万份医疗报告、患者记录、临床试验、科学研究和其他数据点，以帮助提供更快速和更准确的医疗诊断和治疗建议。

纽约的斯隆-凯特琳癌症中心和其他肿瘤学医院和诊所一直在[使用 IBM Watson AI](https://oreil.ly/oPdji)进行大规模数据分析，以帮助医生对癌症患者进行诊断并制定管理计划。

当个人的医疗数据或其他个人信息在这些和其他方式中被收集和使用时，一个明显的合规问题是保护和维护此类可识别个人信息的隐私。在美国，特定的联邦[HIPAA 法律和法规](https://oreil.ly/YjY0d)要求那些收集和处理[“受保护健康信息”](https://oreil.ly/-hu7x)，包括患者的医疗和个人数据，不得在未遵守 HIPAA 的情况下使用或披露此类信息。

更广泛的数据保护法律，例如欧盟的[通用数据保护条例](https://oreil.ly/29sdy)和 2018 年的[加州消费者隐私法案](https://oreil.ly/l_qPQ)，规范了所有类型个人身份信息的收集、处理、使用和转移，正在建立新的监管范式。数据保护机构公开表达了对“个人数据越来越成为 AI 应用的来源和目标”的担忧，认为 AI 的使用不应损害用户的数据保护权利。

许多公司正在投入资源解决这些挑战。在很大程度上，新兴的 AI 伦理准则明确指出，AI 的开发、实施和使用应保护个人的个人数据。IBM 的[AI 原则](https://oreil.ly/f5q-n)明确表示，“IBM 遵守我们运营国家和地区的所有数据隐私法律，并完全致力于保护客户数据隐私，在数据驱动社会中至关重要。”

开发、实施或使用 AI 以收集和处理个人身份数据的公司，应当确保其公司政策和程序同样依据适用法律和法规保护个人数据，这是明智之举。

## 网络安全

新兴的法律要求和涉及 AI 的伦理准则也突显了 AI 使用需伴随有效的安全措施——尤其是网络安全，以减少黑客攻击和数据盗窃的风险。

近年来，网络安全风险引发了政府、行业和广大关注，导致了“网络安全法规的潮流上升”。这些法规包括数据保护、政府合同、医疗保健和其他领域的特定网络安全要求，以及强制性的网络安全职责和责任，可由政府和私人诉讼当事人执行。

AI 的开发、实施和使用可能涉及各种网络风险——不仅是数据分析和使用可能丢失或被盗的风险，还包括 AI 系统本身准确性和可靠性的风险。[在一个著名的实验中](https://oreil.ly/mdwjS)，黑客通过改变几个像素，成功欺骗了基于 AI 的图像识别系统，使其将一张猫的图像误认为狗，甚至是隐形战斗机。

AI 伦理准则，例如[OECD 关于人工智能的建议](https://oreil.ly/sItzf)，要求 AI 系统在其整个生命周期中“强大、安全和安全”，并要求 AI 行为者对 AI 系统生命周期的每个阶段应用系统化和持续的风险管理，以解决与 AI 系统相关的风险，包括数字安全。

公司的人工智能相关活动的安全性必须得到审查，并纳入公司的整体网络安全和其他安全政策及管理体系中。

## 仅限合法用途

不应该让人感到意外的是，像人工智能这样有助于促进一整套有益用途的技术，也可以被用于有害或明显违法的活动中。例如，2019 年初，网络犯罪分子利用 AI 技术驱动的语音技术[模仿欧洲公司高管的声音](https://oreil.ly/ID2yU)，成功地通过电话欺骗了他的英国 CEO，将 243,000 美元汇入了欺诈者在匈牙利的银行账户。

除了欺诈之外，一些公司官员和各种非政府组织对人工智能在自主武器甚至“杀手机器人”中的潜在使用表达了关注。例如，Google 在其[AI Principles](https://oreil.ly/HHBAM)中做出了具体承诺，不设计或部署可能会造成整体伤害的技术，并且不会开发用于武器的人工智能。该公司还表示，不会在“其目的违反广泛接受的国际法和人权原则的技术中使用人工智能”。类似地，微软的总裁呼吁制定一个新的[“数字日内瓦公约”](https://oreil.ly/6xUqn)，以应对全球范围内人工智能和其他技术的潜在有害用途。

不同公司在开发、实施或使用人工智能技术时可能存在的法律考虑和潜在危害可以有很大差异。但对于处理人工智能的公司来说，考虑承诺不将人工智能用于非法或危险目的在制定自身具体人工智能政策或实施更广泛的人工智能伦理原则时非常重要。
