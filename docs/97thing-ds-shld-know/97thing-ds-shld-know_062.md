# 第五十七章：伦理与无花果：为什么数据科学家不能走捷径

# 詹妮弗·刘易斯·普里斯特利

![](img/JENNIFER_PRIESTLEY.png)

亚特兰大州立大学分析与数据科学研究所副院长兼主任

> 我不在乎简单性在复杂性这一侧，但我会为复杂性另一侧的简单性奉献我的生命。
> 
> 最高法院法官奥利弗·温德尔·霍尔姆斯小学

数据科学家应花时间反思前面的引用。

简化复杂是困难的。计算器、计算机和可下载包都是计算速度的工具，而不是计算能力的替代品。

在急于成为“数据科学家”的过程中，许多人走捷径——止步于复杂性的近侧。虽然“公民数据科学家”的概念有其存在的理由，但太多自称为数据科学家的人在数据科学领域没有接受过正规的培训，只是参加了周末的集训营。其后果不仅仅是与“数据科学家”定义相关的混乱，还成为了涉及算法偏见结果的众多伦理问题的主要来源。

注意，“算法”本身并不带有偏见；深度学习和加法一样没有“偏见”。然而，两者都受到两种偏见的影响——模型规范中固有的人类偏见以及我们选择用来构建算法的数据。

为此，道德的数据科学家在算法开发的背景下应考虑三个基本问题。

我试图解决什么问题？

许多人在逻辑上走捷径，直接采用方法而不理解数据。更糟糕的是，许多分析平台简单地允许将数据倒入“黑匣子”，同时进行多种机器学习方法，然后按分类率自动排序。这些平台——在复杂性的近侧——不需要对原始问题进行模型规范考虑。换句话说，该方法可能在计算上进行了优化——但是用于不同的问题。

我使用的数据是否代表将受到输出影响的人群？

如果用于开发和训练算法的数据来自人群的同质子集，但其结果将应用于多样化人群，则原始训练集中未包括的群体的分类准确率总是较低的。如果他们负责主要数据收集，数据科学家需要理解实验设计和抽样原则，以确保代表性。如果数据是之前收集的（更可能），数据科学家仍然有责任确保训练数据集在应用算法的人群中没有显著差异。

我能解释输入/特征的影响吗（或者如果不能，我能证明结果没有偏差吗）？

“解释权”意味着个人有权了解对其生活有直接影响的决策是如何做出的。一个常见的例子是要求放贷人能够解释信用决策。在数学术语中，这意味着 x 对 y 的影响是什么？

尽管大多数监督统计建模技术是直接可解释的，但许多机器学习技术却不是。数据科学家需要深思熟虑地考虑，如果他们无法解释开发算法所用输入如何影响人们的生活（而几乎所有算法在某种程度上都会影响到人们的生活），这是否可接受。或者，如果算法被正确规定并且输入数据已经经过偏差测试，那么放弃可解释性以支持事后解释和示例解释是否可接受？

作为一个社区，大多数数据科学家都有道德意图。然而，意图是不足的，捷径会带来后果。作为社区，数据科学家有责任通过简化复杂性来确保开发和应用社会责任算法的发展，这些算法在复杂性的近侧容易出现失误。
