# 第六十八章：“所有模型都是错误的。”我们该怎么办？

# 米洛斯拉瓦·瓦莱科娃

![](img/Miroslava_Walekova.png)

变革平台有限公司高级经理

机器学习将继续改变我们生活的方方面面：我们彼此交流的方式，我们学习和成长的方式，以及我们与社会互动的方式。然而，这些系统偶尔会不可避免地出现故障。

> 所有模型都是近似值。基本上，所有模型都是错误的，但有些是有用的。
> 
> —乔治·E·P·博克斯

换句话说：没有模型、机器学习或人工智能解决方案能始终正确。如果我们认同失败是无法避免的，那么我们的主要关注点是集中在能够有效和高效地减少对个体任何不利影响的过程和控制上。

一个机器学习治理框架必须涵盖从构思到废弃解决方案的所有阶段，并且需要：

1.  通过设计预防解决方案问题

1.  迅速、透明和负责任地纠正任何问题

1.  持续改进治理框架

让我们逐个审视这些要求。

## 1. 预防

最大化的努力从内部保证，以确保解决方案遵守公平原则。

然而，定义公平性面临着多个挑战。不仅个体对公平的认知存在差异，而且在地理上也有广泛的观点差异。有必要建立专业机构，积极发展公平意味着什么的统一视野。通过恰当的定义和对什么构成公平解决方案的清晰界定，“公平”可能成为机器学习解决方案设计的核心元素。如果我们不是嵌入我们自己的偏见，而是通过“多样性设计”，我们可能会发现机器学习的最终影响是积极的。

任何专业机构或内部治理框架可能规定的每一项原则或规则，仍然会受到个体解释的影响。责任分离和这些原则的正式遵从流程是成功的关键。

## 2. 纠正

由于我们无法完全通过设计消除不利影响，因此重要的是定义透明和迅速纠正任何失败的过程，并将其作为任何产品或服务部署的核心。

任何组织文化的核心组成部分应该是 ART —— 账户、责任和透明度。 ART 应该被转化为参与机器学习解决方案开发和维护的所有个人的目标。鼓励提出与任何内部或外部应用机器学习相关的伦理问题，并应用给予举报者的同等保护。

实际上，引起伦理关注的责任不仅应由内部人员承担，还应由外部利益相关者承担，包括客户、供应商、政府等。开发机器学习解决方案的组织和专业机构都需要使所有利益相关者能够提出他们的关注。

这一过程可能类似于欧盟的 GDPR 过程，其中个人有权向公司请求信息，了解他们持有的个人信息。组织有义务在一个月内对此类请求作出回应。这段时间足以进行“伦理原则”评估，并使组织能够防止进一步对个人造成不利影响。

## 3\. 改进

机器学习应用以及社会将继续发展。因此，公平定义和治理框架需要同时进化。因此，所有组织都应允许灵活性，以便持续审查和改进机器学习解决方案。
