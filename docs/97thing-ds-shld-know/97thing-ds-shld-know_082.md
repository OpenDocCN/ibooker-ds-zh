# 第七十六章：如何负责创新

# Carole Piovesan

![](img/Carole_Piovesan.png)

合作伙伴兼创始人，INQ 数据法律

“负责任创新”这个词组曾经是矛盾的。回到 15 年前左右，你使用这两个词会被嘲笑。在 2000 年代初期，创新的公认伦理是“快速行动，打破常规”。这种伦理优先考虑实验和探索，而非谨慎和勤勉。无尽的好奇心受到欢迎，由对下一个大点子的投资狂热推动。

然而，快进到 2010 年代，那种无尽的好奇心所带来的后果不再能被忽视。随着我们现在收集和分析人类行为的各个方面，并使用诸如 AI 之类的先进预测技术，创新的基本影响正在接受审视和测试。

对“负责任”的创新的关注引发了关于社会中技术的充分和诚挚的辩论（请注意，并非新问题，但被重新激发）。关于大数据和 AI 的问题从能够、应该和愿意到如何、为什么、由谁，以及然后正在被问到。AI 的社会、政治、经济、人权和法律影响是确实被质疑的，对于保护社会免受意外伤害的防护栏的需求正在蔓延。

但要密切关注这些辩论。决策者、公民社会领袖、学者、企业家、伦理学家、律师等并不是在单纯讨论算法本身。我们正在讨论技术对我们价值观的影响——这些价值观支撑着我们的民主社会——以确保我们的创造能够增强我们希望生活在其中的社会类型，而不是颠覆它们。像剑桥分析公司这样的丑闻或最近关于执法部门使用 Clearview AI 面部识别系统的曝光，不仅仅（或根本不）是关于技术本身，而是关于其背后使用意图的问题。

负责任的创新——这些词可以并且应该在一起使用——由对这些复杂技术系统的开发、运作和监督进行周密、勤勉和可辩护的过程所管理。勤勉可以与创新并存。我提出一个四点框架，计划在任何组织中进行负责任的创新：

从人的因素开始

考虑用户，并使用户的利益和期望与组织的创新计划保持一致。同时，识别组织的价值观，并将这些价值观与组织的创新议程保持一致。简言之，让人们加入，并提前将您的组织叙述与之一致。

确保良好的数据实践

遵守数据保护法律只是开始。对 AI 系统的数据实践进行周到和情境化评估是有价值的，特别是对那些用于高风险活动的系统，例如与某些医疗设备配合使用的系统。映射并记录用于评估和评估这些高风险系统的训练数据和持续数据暴露的过程。记录适当的缓解活动以帮助降低风险。

在上下文中评估 AI 系统。

审查并记录合理归因于组织更先进的 AI 项目的风险水平。并非所有 AI 系统都是平等的。有些对人类福祉和/或社会造成的风险非常小。这些系统不需要像在更敏感或短暂环境中使用的系统那样进行同等级别的审查，例如医疗保健或安全领域。

建立合理和周到的行动方案，用于更高风险的 AI 系统。

勤勉和问责制至关重要，并且坦率地说，这些是在意外后果出现时的良好法律防御。展示一种考虑周到、富有见地和积极主动的风险管理方法对于建立信任、降低风险、组织叙事以及最重要的一点，做正确的事情，是非常重要的。

这种基于风险的框架被提议为一个合理的防护措施，直到相关法规出台或取而代之。我们将看到在某些情境下（例如执法和政府进行的面部识别）对某些 AI 用途进行监管。与此同时，组织必须继续创新，但与过去的理念不同，必须负责任地进行创新。
