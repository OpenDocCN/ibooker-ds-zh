# 第二十二章：数据科学与审议正义：关于“他者”的声音伦理学

# 罗伯特·J·麦格拉思

![](img/Robert_McGrath.png)

卫生管理与政策系主席，

新罕布什尔大学

数据科学——我指的是主要依赖于人工智能形式（机器学习、深度学习、总体技术学习）的方法的集合——已经以其有充分记录的影响普及到社会中，既有积极的¹，也有负面的²。它继续引发许多讨论，权衡这两者以及对社会的最终利益³。

但正是在这里，即社会与技术的交汇处，可能需要更基础的思考。在这些数据科学影响的审查中经常引用的是结果，或者是行动的意外后果，例如算法发展的伦理或者在学习进程中的修改。这些出现在系统偏见的情况中，如少数族裔偏见、种族偏见或其他结构性偏见，如果不加以解决，将会在自主学习过程中传播。但在这个审视中失去的是行动本身以及技术如何不仅取代了人类活动，还取代了集体声音的部分。

集体决策是所有社会结构的基础，所有社会的基础。它是贯穿所有社会关系的集体身份，包括政治结构、司法结构、社区支持、法律和公民责任⁴。但是，当算法取代人类的声音——例如通过机器学习在购买偏好、选民抽样、预测案例法律或几乎任何人类行为在总体上采取行动时——这种非人类的声音或“他者”的声音实质上被计算在如何分配和解释那些商品、服务和公民结构的集体声音中。一些人可能会认为，决策不是公民本身，而是他们利用技术及其提供的好处在做出公民选择，因此集体声音得到了增强。然而，其他人可能会认为，如果选择本身因预测过程而受限，那么审议过程在途中基本上已经受到了阻碍。这些困境导致一些人询问，当为数据科学家的工作提供信息时，是否需要考虑伦理框架或基础正义模型的问题，如社会正义和审议正义⁵。

这些是伦理学栖息的正义理论的基础问题。关于如何、为何以及朝着何种目的的问题，均牢牢地栖息在这种基础公民声音的空间中，以及赋予该声音的价值。这个问题仍然存在：如果那个声音没有人类面孔，会怎样？

¹ Sonja Marjanovic, Ioana Ghiga, Miaoqing Yang, and Anna Knack，“理解健康数据生态系统中的价值：当前证据综述与前进方向”，*Rand Health Quarterly* 7, no. 2（2018 年 1 月）：3；L. Nelson Sanchez-Pinto, Yuan Luo, 和 Matthew M. Churpek，“重症监护中的大数据与数据科学”，*Chest* 154, no. 5（2018 年 11 月）：1239–48；Stuart J. Russell 和 Peter Norvig, 与 John Canny 等合著，《人工智能：现代方法》，第 2 版（Upper Saddle River, NJ：Prentice Hall/Pearson Education, 2003），1081。

² Rebecca Wexler，“生命、自由和商业秘密：刑事司法系统中的知识产权”，*Stanford Law Review* 70（2018）：1343–1429；Soroush Vosoughi, Deb Roy, 和 Sinan Aral，“在线真假新闻的传播”，*Science* 359, no. 6380（2018）：1146–51，[*https://doi.org/10.1126/science.aap9559*](https://doi.org/10.1126/science.aap9559)；Jack Smith IV，“《少数派报告》是真实存在的，而且真的在报道少数群体”，Mic，2015 年 11 月 9 日，[*https://oreil.ly/qpT_Z*](https://oreil.ly/qpT_Z)；Jack Nicas，“YouTube 如何将人们引向互联网最黑暗的角落”，*Wall Street Journal*，2018 年 2 月 7 日，[*https://oreil.ly/ceaey*](https://oreil.ly/ceaey)。

³ Luke Muehlhauser 和 Anna Salamon，“智能爆炸：证据与影响”，收录于 *Singularity Hypotheses: A Scientific and Philosophical Assessment*，Amnon Eden, Johnny Søraker, James H. Moor, 和 Eric Steinhart 编（Berlin: Springer, 2012）；Eliezer Yudkowsky，“人工智能作为全球风险的正面和负面因素”，收录于 *Global Catastrophic Risks*，Nick Bostrom 和 Milan M. Ćirković 编（New York: Oxford University Press, 2008），308–45；Nick Bostrom，“超智能的意志：先进人工智能代理的动机和工具理性”，*Minds and Machines* 22（2012）：71，[*https://doi.org/10.1007/s11023-012-9281-3*](https://doi.org/10.1007/s11023-012-9281-3)。

⁴ Bernard Yack，“亚里士多德政治哲学中的社区与冲突”，*The Review of Politics* 47, no. 1（1985）：92–112，[*https://oreil.ly/HwRf_*](https://oreil.ly/HwRf_）。

⁵ Ben Green，“数据科学作为政治行动：将数据科学扎根于正义的政治”，Computers and Society，康奈尔大学，最后修改于 2019 年 1 月 14 日，[*https://arxiv.org/abs/1811.03435*](https://arxiv.org/abs/1811.03435)。
