# 第四十四章：概率——统治分析伦理的法则

# 托马斯·凯西

![](img/Thomas_Casey.png)

Teradata 执行董事

多年来，分析帮助我们更好地理解我们的世界，并支持我们的决策。随着更先进的分析技术的出现，我们已经发展到非人类可以代表我们做出决策的地步。很多文章讨论了像“机器学习”和“深度学习”这样的概念，作为可以推动令人难以置信结果的技术。然而，无论如何，如果你不先理解概率及其对分析驱动决策的伦理影响，你无法使用这些技术来做出任何决定。

## 当概率和伦理相冲突时

如果你问一个算法是否应该玩彩票，答案肯定是“不”。基于概率和置信水平，你赢得彩票的可能性是统计上不可能的，因此玩彩票并不值得冒这种实际风险。事实上，尽管这个决定对几乎所有人来说都是合适的，但是由于玩彩票的人数众多，总有人最终会赢得。在这种情况下犯错似乎是微不足道的（除非你错过了百万美元）。然而，如果一个由算法做出的决定阻止你登机怎么办？如果它误诊了癌症？如果自动驾驶车辆决定向右转而撞击你的孩子，因为它“预测”左转存在更大的风险？这些决策都无法确定，每一个都会根据可能性或正确性应用某种可接受的风险水平——如果模型做出错误的决定，它也不会感到后悔。

## 人类如何试图在算法中注入伦理

人类和机器的婚姻用于增强决策有很大的优点。问题在于每次人们试图将伦理标准应用于模型时，他们固有地（无论好坏）注入了一定程度的偏见。例如：

注入“正确”的偏见

像谷歌和 Facebook 这样的公司在研究中面临了显著的反对意见，显示他们的算法推荐了一些信息提供者而不是其他人。无论是否有恶意或明确的偏见意图，这些公司继续调整他们的算法，以展示他们的结果更好地反映了某些人认为它们应该代表的看法。

简化模型

近几年来，深度学习作为一种在许多知名应用中使用的技术（如图像识别、语音翻译、高级游戏玩法等）声名鹊起。深度学习的缺点在于很难，如果不是不可能，确定达成某个特定结果的原因。在某些情况下，公司和其他机构被迫转向更简单和不那么有效的（有些人甚至会说愚蠢的）技术，只是为了能够解释决策背后的理由。

覆盖决定

存在许多情况下，覆盖算法的能力是有意义的。然而，在其他情况下，覆盖算法会给我们一种虚假的安全感。例如，一些自动驾驶汽车服务因重大事故而遭受负面新闻，于是让一名员工坐在前排不做任何事情，虽然他们可能随时准备抓住方向盘。虽然这可能给我们一种控制感，但有人可能会认为以这种方式注入人类是毫无意义的，最好的情况下是无益的，最坏的情况下甚至是危险的。

## 非人类决策的伦理影响

向更多自主决策的方向前进是不可避免的。然而，毫无疑问地，会有一些情况下，一个决策在统计上是合理的……但它会是错误的。如果你推荐了一部错误的电影观看，那并不是灾难性的。然而，如果一个算法在数千或数百万次生死决策中偶尔出错，那将是问题的。也许好处远远超过错误的可能性，也许算法在做出决策方面比人类要好得多。然而，对于受到非情感决策者情感结果影响的人来说，这显然是不够安慰的。因此，在未来，当我们考虑将复杂决策交给基于概率法则做出决策的无情算法的伦理影响时，我们需要问自己：我们确定吗？
