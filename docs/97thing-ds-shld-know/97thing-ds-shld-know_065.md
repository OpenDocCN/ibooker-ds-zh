# 第六十章：伦理系统的之前、现在和之后

# Evan Stubbs

![](img/Evan_Stubbs.png)

波士顿咨询集团的合伙人兼副总监

利用数据驱动人工智能的闭环系统有能力改变世界。这些系统已经在拯救生命、分配资本、执行合同，并代表其人类主人做出越来越多的决策。作为未来的设计师，行使这种权力以使世界变得更好而非更坏，需要尊重和考虑。就像隐私或安全性一样，这些系统中的伦理问题不能被视为一种附带。从概念到执行以及更远的未来，伦理必须作为设计的一个整体部分来对待。

在非常实际的意义上，每个工程师的旅程中有三个时间点，糟糕的选择可能导致逆向结果：**之前**，**现在**和**之后**。

以下所有例子都是真实的，尽管为了保护有罪之人，姓名已被隐去。

在**之前**的时刻，天穹尚未建立。在这里，尽管有最好的意图，最大的风险是无意中导致个人或社会的伤害；算法是基于数据训练的，如果这些数据反映出制度性劣势，未来将不得不反映现在。

想象一个有意向使用 AI 识别和加速其员工中高绩效者的公司。为了训练其算法，它获取人力资源数据并训练模型来区分成功者和失败者。然而，通过这样做，它无意中创造了一个风险，将性别歧视制度化到公司的运营模式中。

让我们假设公司不是性别歧视的，也不是故意采用性别歧视的治理框架；我们是怎么到这里的呢？

即使公司的管理团队一直试图基于功绩来提升，但历史上男性主导的研究领域已经导致几十年来招聘男性毕业生存在代际偏见。算法使用的数据从根本上是受到污染的；即使模型没有明确将性别作为预测因素，性别很可能与男性行为有历史上的相关性，如较少可能休产假。

逆向结果是，一个准确的模型可能存在向男性加速的固有偏见，这并不是因为男性是更好的候选人，而仅仅因为他们人数众多，因此在绝对术语上历史上更有可能得到晋升。

在**之前**，你需要考虑你的选择如何可能无意中破坏你试图解决的问题本身。即使是最好的意图也可能因错误的数据而无意中出错。

在**现在**的时刻，我们必须做出选择。我们知道我们能做到，但我们应该吗？

想象一家有意最大化利润的银行。信用卡带动利润，但只有在特定的使用方式下。消费过度会导致客户无法偿还债务，迫使银行出现违约，并造成损失。带余额不足，则银行可能只能收回卡费，利润微薄。理想的客户是“循环信用”客户，每月带有债务并支付最低余额，从而最大化银行的利息收入。

有了正确的数据，轻而易举地就能建立一个模型，识别如何最好地鼓励人们增加消费。影响行为的方法多种多样，包括忠诚度奖励、徽章和无差别使用黑暗模式。这样做可以对银行的底线产生实质性影响。然而，如果银行选择这样做，哪些人最终会陷入债务循环？

在当前时代，你需要对你的算法后果感到舒适。你的工作反映了你改变世界的能力，无论是好是坏。

在*之后*，一切都运作良好，希望如此。很容易认为不再需要监督了。这种信念是错误的。

想象一家有意定制内容的媒体公司。其算法擅长将内容与兴趣匹配。然而，随着时间的推移，这些算法也会创建高度封闭的信息圈。多巴胺驱动的信息消费导致整个群体只看到与其世界观一致的内容。观点变得极端化，并在没有对立观点的情况下日益极端化。最初可能是增加观众黏性的相对无害方法很容易成为社会动荡的温床，这几乎完全是由于潜在的算法，尽管无意间如此。

在之后，你需要积极监视你建立的事物，确保你没有创造一个你不愿生活的世界。你的算法就像你的孩子，它们的行为是你的责任。
