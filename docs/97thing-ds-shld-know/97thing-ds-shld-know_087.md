# 第八十一章：算法影响评估

# 兰迪·古斯

![](img/Randy_Guse.png)

美国联合健康集团 Optum 企业分析总监

自动决策系统正在各行各业中被使用。这些系统在透明度和效果上有所不同，通常会导致意外后果。算法影响评估（AIA）可以揭示解决方案功能的问题，并在严重伤害发生之前提供采取纠正措施的机会。

[AI Now Institute](https://ainowinstitute.org)发布了多篇文章，探讨分析算法和自动决策系统内潜在的道德问题和偏见。其中一份报告，*算法影响评估：公共机构问责的实际框架*，建立了评估自动决策系统不良影响的协议。¹

尽管该报告是为政府机构撰写的，但行业应该同样被要求遵守相同的标准。AIA 的关键元素包括：

+   政府机构应自我评估现有和拟议的自动决策系统，评估对公平性、正义、偏见或其他影响的潜在影响，涵盖受影响社区。

+   政府机构应开发有意义的外部研究人员审查过程，以便随时间发现、衡量或跟踪影响。

+   在获取系统之前，政府机构应向公众公布他们对“自动决策系统”的定义、现有和拟议的系统以及任何相关的自我评估和研究人员审查过程。

+   政府机构应征求公众意见，澄清关注点并回答未解决的问题。

+   政府应为受影响的个人或社区提供增强的正当程序机制，以挑战未经充分评估或不公平、偏见或其他有害系统使用，政府未能减轻或纠正的情况。

报告继续强调，AIA 将有助于实现四个目标：

+   尊重公众知情权，公开列出和描述对个人和社区有重大影响的自动决策系统。

+   增强公共机构内部专业知识和评估能力，以评估其构建或采购的系统，从而能够预见可能引起关注的问题，如不平等影响或违反正当程序。

+   通过提供持续的有意义的外部研究人员审查、审核和评估这些系统的机会，确保自动决策系统的更大问责性，使用能够帮助他们识别和检测问题的方法。

+   确保公众有充分的机会对某个系统的使用或机构的算法问责方法进行回应，并在必要时提出争议。

在 AIAs 所要求的披露级别方面，企业实体可能不愿意遵守。然而，他们应该遵守责任标准，同时保持专有知识。例如，报告特别讨论了第二部分中关于商业秘密的挑战。

第二部分还涉及获得资金和资源来实施人工智能评估（AIAs）的挑战。对于政府实体而言，在建议的独立监督机构存在的情况下可能是一个挑战。然而，对于行业来说，如果将指导方针纳入现有的产品开发框架中，增加的成本应该是最小的。事实上，在实施之前突出算法潜在缺陷应该能够导致更高效的产品开发，并减少意外后果的发生。

¹ [AI Now 的报告](https://ainowinstitute.org/aiareport2018.pdf)根据知识共享许可证提供。
