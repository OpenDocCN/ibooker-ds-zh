# 第五十五章：AI 的负责任设计和使用：管理安全性、风险和透明度

# Pamela Passman

![](img/Pamela_Passman.png)

副主席，Ethisphere

CEO，负责任企业与贸易中心（CREATe.org）

AI 正对全球市场和商业实践产生日益增长的影响。而其潜力更是巨大。[IDC 在 2019 年 9 月发现](https://oreil.ly/sMAiL)，“到 2023 年，AI 系统的支出将达到 979 亿美元，是 2019 年 375 亿美元的两倍多”。根据麦肯锡全球研究所的数据，[到 2030 年，AI 可能会为全球经济增加额外的产出](https://oreil.ly/hJ1d5)达到 13 万亿美元。

然而，尽管 AI 释放出业务潜力和更广泛的社会效益，但其使用也可能导致一系列[不受欢迎且有时严重的后果](https://oreil.ly/lz_zR)。这些考虑因素已经催生了不少于[32 个不同的行业、非政府组织和政府 AI 伦理准则](https://oreil.ly/TetYv)，这些准则详述了组织应采取的步骤，以开发、实施和使用符合社会价值并管理风险的 AI 技术。

许多有远见的公司——其中一些公司有处理 AI 意外后果的第一手经验——也制定了自己的 AI 伦理准则。虽然这些准则可能有很大不同，但已经确定了九项共同的责任[（已被确认）](https://oreil.ly/PIYYz)。这些责任可以分为三组：负责任的设计和使用、合法使用和伦理使用。在这里，我们重点关注第一组，*负责任的设计和使用*，它涵盖了 AI 安全、安全性、风险管理和透明度。

## 安全和安全性

媒体偶尔会报道一些引人注目的 AI 事件，比如涉及自动驾驶汽车的事故。这种报道反映了消费者和企业的广泛关切，从而巩固了 AI 需以安全和可靠的方式开发、实施和使用的必要性。

对公司而言，这意味着全面管理 AI 的安全性和安全性影响，使组织所有相关部门超越技术参与进来。这种跨功能的机构方法使公司能够高效、有效地拥抱 AI 的力量和责任，同时避免意外风险和伤害。

例如，作为人工智能早期采用者之一，微软在其[负责任人工智能原则](https://oreil.ly/iBUvd)中直接涉及安全和安全考虑。通过要求“人工智能系统在正常和意外情况下都应可靠且安全运行”，微软承诺其人工智能系统将按照最初设计的方式运行，安全应对意外情况，并抵抗有害操纵。因此，对人工智能系统的初步和持续测试、维护和保护至关重要。而人类判断力仍然是识别人工智能系统潜在盲点和偏见的关键，并确定何时、如何以及多长时间使用人工智能系统的重要因素。

## 持续风险管理

鉴于人工智能技术的相对新出现和使用，似乎还没有多少公司对人工智能风险和风险管理进行了深入的机构化审视。因此，对公司来说至关重要的是认识到，尽管人工智能可能带来的潜在风险无法完全消除，但可以并且应该预见、评估和管理这些风险，以符合其预期影响的程度。

麦肯锡分析《*面对人工智能风险*》指出，“很少有领导人有机会磨练自己对社会、组织和个人人工智能风险的整体认识。”因此，领导们往往忽视潜在的危险（‘我们没有在像自动驾驶车辆等可能“爆炸”的领域使用人工智能’），或者过高估计组织的风险缓解能力（‘我们长期以来一直在进行分析，所以我们已经有了正确的控制措施，并且我们的做法与同行业相符’）。领导们还经常将人工智能风险与由 IT 和分析专家负责的其他风险混为一谈（‘我信任我的技术团队；他们正在尽一切可能保护我们的客户和公司’）。

许多公司已经在其组织中使用企业风险管理（ERM）方法*识别 > 评估 > 管理*来处理其他类型的风险。因此，在整体 ERM 框架内评估和管理新出现的人工智能风险是合乎逻辑的。

随着我们的网络日益互联，将人工智能风险管理实践扩展到公司的第三方也是合乎逻辑的。无论是供应商、客户还是其他业务伙伴，都不应忽视这些第三方可能出现的关键人工智能风险管理。Telefónica 通过[合同约定保留权利](https://oreil.ly/zzQ0D)，持续验证其第三方供应商 AI 产品的逻辑和数据使用披露的真实性，从而阐明了这一原则。

## 透明度

随着人工智能系统的扩展和发展，以及由于使用人工智能带来的更多风险的出现，消费者和企业开始要求更多关于其使用的基于人工智能的产品和服务的透明度。[研究显示](https://oreil.ly/rIpRv)，消费者对人工智能的感受存在分歧：仅有 35%的人表示他们对企业使用人工智能与他们进行交互感到舒适，28%的人表示他们对此感到不舒服，而最大的群体——37%的人表示他们还不知道。

这有助于解释为什么大多数行业、非政府组织、政府以及公司人工智能伦理准则都包括对人工智能开发、实施和使用各个方面透明性的要求。例如，IBM 的[《人工智能信任和透明原则》](https://oreil.ly/G9ykX)要求，如果人工智能用于做出重要决策，必须能够解释其决策过程：“技术公司必须清楚地说明是谁训练了他们的人工智能系统，使用了哪些数据进行了训练，最重要的是，他们的算法推荐的依据是什么。”

作为其特定的人工智能透明原则的一部分，IBM 已经承诺在何时以及出于何种目的应用人工智能时进行明确说明，其人工智能系统使用的数据和训练方法，其持续测试和改进的承诺，以及其保护客户数据的措施，以及支持确保人们能够理解人工智能系统是如何得出结论或建议的。

## 结论

人工智能的进一步扩展是不可避免的。尽管许多消费者仍然对人工智能心存恐惧，但对负责任人工智能的新需求为企业提供了一个重大机遇，可以以符合客户期望的方式开发和解释其人工智能计划。

通过专注于安全性和保障、管理风险以及保持人工智能透明和负责任披露，企业不仅能赢得客户的信任，还能以难以想象的方式改善业务和社会。
