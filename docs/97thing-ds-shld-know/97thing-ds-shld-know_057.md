# 第五十三章：因果性和机器学习中的公平意识

# 斯科特·拉德克利夫

![](img/Scott_Radcliffe.png)

商业分析硕士项目董事总经理

埃默里大学

处理机器学习模型中的公平性和偏见已经成为不可选的命题。然而，部署学习模型的竞争已经超过了检测和系统避免偏见的标准和方法的发展。这种情况在某种程度上是因为机器学习实践通常不关注因果关系，而是基于观察标准。焦点是预测、分类和识别。观察标准基本上无法确定预测因子是否存在未解决的歧视。

在社会科学和医学领域的长期数据分析历史表明，公平性应该从因果关系的视角进行研究。为了关注公平性，特别强调了支持所有因果推断的假设、用于制定这些假设的语言、所有因果和反事实主张的条件性质以及已开发用于评估此类主张的方法。

什么是“因果模型”？维基百科提供了一个有用的定义。因果模型（或结构性因果模型）是描述系统因果机制的*概念*模型。因果模型可以通过提供清晰的规则来改进研究设计，以决定哪些独立变量需要被包含/控制。

它们可以通过现有的观察数据回答一些问题，而无需进行类似随机对照试验的干预研究。某些干预研究由于伦理或实际原因而不适当，这意味着在没有因果模型的情况下，某些假设无法得到验证。

因果模型是可证伪的——这意味着如果它们与数据不符合，则必须被拒绝为无效。它们还必须对打算解释的现象非常可信。

数据科学和机器学习实践必须包括对因果推理的理解和培训是至关重要的。Judea Pearl 是加州大学洛杉矶分校计算机科学教授和认知系统实验室主任，他是将因果关系建立为统计和数学概念的先驱。Pearl 是 2018 年著作《*为什么：因果关系的新科学*》（基础书籍出版）的作者。

*《为什么之书》*的核心隐喻是作者称之为“因果推理梯子”的三个升级阶段。最低的阶段仅仅涉及观察，基本上是寻找过去行为的规律性。珍珠将“当今学习机器”明确置于第一阶段。“尽管计算能力的爆炸和可接触的深度数据集产生了许多令人惊讶和重要的结果，但机制仍然“基本上是统计学家试图将一条线拟合到一组点的方式。”

因果推理梯子的第二阶段从看到行动转变。也就是说，它从询问发生了什么转变为基于可能干预的结果会发生什么。珍珠指出，“许多科学家对于了解统计学所学方法无法足以表达，更不用说回答‘如果我们将价格翻倍会发生什么’这样简单的问题感到心碎。” *《为什么之书》*详细解释了在实验缺失的情况下，模型单独如何回答此类问题的历史和详细说明。

梯子的第三个和顶部阶段涉及反事实问题，例如：如果采取了不同的路径，世界会是什么样子？这些问题“是道德行为以及科学思想的基石。”回顾过去并想象可能会发生的事情，决定了我们对成功和失败，对与错的判断。

机器学习在这个梯子上处于何位置？从胸部放射学的最先进诊断成就到超越人类水平的游戏技能，如围棋和 Dota 2，展示了深度学习的力量和现实世界的实用性。尽管如此，有时候这些方法被傲慢地描述为简单的“曲线拟合”。可以说，这些方法涉及学习由神经网络架构定义的高度复杂函数，用于将输入 X 连接到输出 Y。对于一个游戏代理，X 是游戏的观察状态（棋盘位置，玩家健康等），而 Y 是随后的动作或计划。如珍珠所言，“只要我们的系统优化观察数据的某种特性，无论多么高尚或复杂，同时不引用数据之外的世界，我们回到了层次结构的第一级别，具有这个级别所带来的所有限制。”因此，我们发现 AI/ML 处于珍珠因果推理梯子的第一阶段。

那么为什么 AI/ML 实践不能更快地向上移动梯子？面对数据科学家和机器学习工程师对因果关系感兴趣的挑战之一是，大多数关于此主题的资源都是针对统计学家或经济学家的需求，而不是数据科学家和机器学习工程师的需求。弥合这一差距代表了一个重大机会，可以在 AI/ML 技术的快速进步中推动公平意识的提升。
