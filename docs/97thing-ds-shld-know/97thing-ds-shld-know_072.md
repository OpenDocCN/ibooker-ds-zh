# 第六十七章：聊天机器人是否应该比人类拥有更高的道德标准？

# Naomi Arcadia Kaduwela

![](img/Naomi_Arcadia_Kaduwela.png)

Kavi Labs 的负责人，Kavi Global

我们看到市场上聊天机器人的爆炸性增长。AI 已经深深融入到我们日常生活的织物中。服务行业已经转向由 AI 驱动的聊天机器人来管理客户互动，提高解决问题的速度和质量，同时降低成本。千禧一代越来越倾向于与聊天机器人而不是与人类进行互动。当我们在生活中接纳聊天机器人时，评估它们在强化和延续社会偏见和刻板印象中所扮演角色至关重要。随着聊天机器人的普及，一种有趣的伦理问题浮现出来：我们是否应该对聊天机器人提出比对自己更高的道德标准？

聊天机器人的核心是由称为神经网络的深度学习算法组成的自然语言处理（NLP）模型。深度学习模型具有从杂乱数据（文本和图像）中精确映射复杂关系的能力。那么像卷积神经网络（CNNs）、循环神经网络（RNNs）和长短期记忆网络（LSTMs）这样的流行 NLP 模型在聊天机器人中做些什么呢？它们数学地定义单词之间的关系，如同训练语料库中明确或隐含定义的那样。

## 聊天机器人继承人类偏见的例子

已经发生过几起令人不安的 NLP 算法失误。亚马逊的秘密 AI 招聘工具显示出对女性的偏见。微软那个如今臭名昭著的聊天机器人 Tay14，在社交互动的机器学习实验中，由于接受了一系列种族歧视言论，不得不被停用。

这些故事让我们感到震惊和愤慨。我们往往责怪公司或 AI 开发者。然而，这些 NLP 模型所训练的是人类生成的数据。NLP 模型仅仅是暴露了从训练数据中学到的现有人类偏见。NLP 的失误反映了人类的黑暗面。

## 如何聊天机器人延续人类偏见

就像一个孩子的道德准则是由其父母和环境塑造的一样，机器学习模型从其创建者指定的人类生成的训练数据中学习。就像人类通过经验变得更加睿智一样，机器学习模型需要大量的训练语料库来学习强健且具有泛化能力的关系。正如孩子长大并传递他们的道德准则和偏见一样，机器也将通过与未来世代的互动延续它们的道德准则和偏见。不同的是，这些机器是不朽的，将在时间中超越世代。因此，我们的聊天机器人必须被置于最高的道德标准，并且必须纠正由有缺陷的人类生成的训练数据中存在的偏见。

## 纠正聊天机器人偏见的方法

在追求卓越的不断过程中，我们必须承认我们的过失，并寻求在未来几代中加以纠正。从 NLP 建模的角度看，存在三种偏见校正方法，帮助聊天机器人克服其训练数据中的人类偏见。

一种选择是从 NLP 模型中完全删除有偏见的概念。例如，在准备 NLP 模型时，训练语料库中的单词和短语被映射到称为词嵌入的实数向量中。从数学上讲，可以从这些向量中减去性别。然而，在性别是关键预测变量或分割变量的应用中，完全删除性别的概念可能不实际。在保留性别概念的同时消除性别刻板印象的一种替代方法是简单地删除我们不希望的性别刻板印象（例如接待员），并保留我们希望的（例如 CEO）。最后，可以通过翻转代词（即“他”和“她”）来合成生成额外的数据，以使模型不会由于训练数据中表现不足而学习到任何意外的偏见。

## 为何聊天机器人需要持续学习

我们看到，我们的道德准则在数千年间不断发展演变。近年来，公民权利、妇女权利和 LGBT 运动取得了进展。尽管自苏格拉底时代以来道德的核心原则并未根本改变，道德的实际应用是流动的，并且随着社会的不断发展而不断演变。如果我们把今天的偏见硬编码到永恒的机器中，我们将用过去几代人的偏见来污染未来几代人的思想，从而减缓人类道德进化的步伐。相反，我们可以利用技术手段帮助聊天机器人克服今天的人类偏见，这样它们反过来可以使人类在道德上变得更好！
