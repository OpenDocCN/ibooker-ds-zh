# 第十二章：适合时间序列模型的性能考虑

在机器学习和统计分析的文献中，过于关注模型的准确性。虽然在评估模型时通常准确性应该是主要关注点，但有时在面对大数据集或广泛部署的模型以服务大量客户应用程序时，计算性能的考虑也非常重要。

时间序列数据集变得如此庞大，以至于分析根本无法完成，或者因为对可用计算资源的需求太大而无法进行适当的分析。在这种情况下，许多组织会如下处理他们的选择：

+   增加计算资源（在经济和环境上既昂贵又常常是浪费的）。

+   把项目做糟（不够的超参数调整，数据不足等）。

+   不要做这个项目。¹

当您刚开始使用新数据集或新分析技术时，这些选项都不令人满意。不知道您的失败是由于数据质量差，问题过于复杂，还是资源不足，可能会令人沮丧。希望我们能找到一些解决方案，以扩展您在非常严苛的分析或非常大的数据集情况下的选择。

本章旨在指导您考虑如何减少训练或推断使用特定模型所需的计算资源。在很大程度上，这些问题是特定于给定数据集、您可用的资源以及您的准确性和速度目标的。您将在本章中详细讨论的关注点中看到这种现实，但希望它们部分地涵盖您遇到的问题，并能为进一步的头脑风暴提供灵感。这些是在您完成首轮分析和建模后才需要考虑的事项，但在将某事投入生产或将小型研究项目扩展为更大项目时，您应经常重新审视这些问题。

# 使用为更通用用例构建的工具

时间序列数据的一个挑战是，大多数工具，特别是用于机器学习的工具，都是为更通用的用例而构建的，大多数说明性示例展示了横截面数据的用法。这些机器学习方法因此无法像处理时间序列数据那样高效。你的具体问题的解决方案会有所不同，但一般的思路是相同的。在本节中，我将讨论常见问题和潜在解决方案。

## 为横截面数据构建的模型不会在样本之间“共享”数据

在许多情况下，当您将时间序列数据的离散样本输入算法时，最常见的是在机器学习模型中，您会注意到您在样本之间输入的大部分数据存在重叠。例如，假设您拥有以下月销售数据：

| 月份 | 销售的小部件数量 |
| --- | --- |
| 2014 年 1 月 | 11,221 |
| 2014 年 2 月 | 9,880 |
| 2014 年 3 月 | 14,423 |
| 2014 年 4 月 | 16,720 |
| 2014 年 5 月 | 17,347 |
| 2014 年 6 月 | 22,020 |
| 2014 年 7 月 | 21,340 |
| 2014 年 8 月 | 25,973 |
| 2014 年 9 月 | 11,210 |
| 2014 年 10 月 | 11,583 |
| 2014 年 11 月 | 12,014 |
| 2014 年 12 月 | 11,400 |
| 2015 年 1 月 | 11,539 |
| 2015 年 2 月 | 10,240 |

您正在通过将每个“形状”映射到最近的邻居曲线来进行预测。您从这些数据准备了许多形状。这里列出了其中一小部分数据点，因为您可能希望使用六个月的曲线作为感兴趣的“形状”（请注意，我们不会对数据进行任何预处理，例如归一化或创建额外的感兴趣特征，如移动平均或平滑曲线）：²

> | 11221, 9880, 14423, 16720, 17347, 22020 |
> | --- |
> | 9880, 14423, 16720, 17347, 22020, 21340 |
> | 14423, 16720, 17347, 22020, 21340, 25973 |

有趣的是，我们通过这些输入的准备工作，只是使我们的数据集扩大了六倍，而没有包含任何额外的信息。从性能的角度来看，这是一场灾难，但通常是各种机器学习模块的输入必需品。

如果您遇到这个问题，您应该考虑几个解决方案。

### 不要使用重叠的数据

考虑仅生成“数据点”，以便每个单独的月份只出现在一个曲线中。如果这样做，前面的数据可能看起来像以下表格：

> | 11221, 9880, 14423, 16720, 17347, 22020 |
> | --- |
> | 21340, 25973, 11210, 11583, 12014, 11400 |

请注意，这将特别简单，因为它只是一个简单的数组重塑，而不是数据的自定义重复。

### 采用类似生成器的范式来迭代数据集

使用类似生成器的范式来迭代数据集，根据需要从相同的数据结构重新采样，特别容易在 Python 中编码，但也可以在 R 和其他语言中完成。如果我们想象原始数据存储在一个 1D NumPy 数组中，这可能看起来像以下代码（请注意，这需要与接受生成器的机器学习数据结构或算法配对使用）：

```
## python
>>> def array_to_ts(arr):
>>>   idx = 0
>>>   while idx + 6 <= arr.shape[0]:
>>>      yield arr[idx:(idx+6)]
```

注意，设计不会不必要地扩大数据集的数据建模代码，从培训和生产的角度来看都是可取的。在培训中，这将允许你在内存中拟合更多的训练示例，在生产中，你可以使用更少的训练资源进行多次预测（或分类）在重叠数据上。如果你为同一用例频繁进行预测，你可能会处理重叠数据，因此这个问题及其解决方案将非常相关。

## 不预先计算的模型会在测量数据和进行预测之间造成不必要的延迟

通常情况下，机器学习模型不会准备或考虑提前计算部分结果，而不是等到所有数据都准备好。然而对于时间序列来说，这是一个非常常见的场景。

如果你正在为医学预测、车辆位置估计或股票价格预测等对时间敏感的应用程序提供模型服务，你可能会发现在所有数据可用后才计算预测的延迟时间过长。在这种情况下，你应该考虑你选择的模型是否实际上可以部分提前计算。以下是一些可能性的示例：

+   如果你正在使用一个递归神经网络，在超过 100 个不同时间步的多个信道中传递信息，你可以预先计算/展开神经网络的前 99 个时间步。然后，当最后一个数据点最终到来时，你只需进行一次最终的矩阵乘法（和其他激活函数计算），而不是 100 次。理论上，这可以使你的响应时间加快 100 倍。

+   如果你正在使用 AR(5) 模型，你可以预先计算除了构成模型的和的最近项之外的所有项。作为提醒，AR(5) 过程看起来像下面的方程。如果你要输出预测，这意味着你已经知道 *y*[t – 4]、*y*[t–3]、*y*[t–2] 和 *y*[t–1] 的值，这意味着你可以在知道 *y*[t] 之前提前准备好除了 <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi> <mi>h</mi> <msub><mi>i</mi> <mn>0</mn></msub> <mi>Ã</mi> <mi>—</mi> <msub><mi>y</mi> <mi>t</mi></msub></mrow></math> 外的一切：

    <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msub><mi>y</mi> <mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub> <mo>=</mo> <mi>p</mi> <mi>h</mi> <msub><mi>i</mi> <mn>4</mn></msub> <mo>×</mo> <msub><mi>y</mi> <mrow><mi>t</mi><mo>-</mo><mn>4</mn></mrow></msub> <mo>+</mo> <mi>p</mi> <mi>h</mi> <msub><mi>i</mi> <mn>3</mn></msub> <mo>×</mo> <msub><mi>y</mi> <mrow><mi>t</mi><mo>-</mo><mn>3</mn></mrow></msub> <mo>+</mo> <mi>p</mi> <mi>h</mi> <msub><mi>i</mi> <mn>2</mn></msub> <mo>×</mo> <msub><mi>y</mi> <mrow><mi>t</mi><mo>-</mo><mn>2</mn></mrow></msub> <mo>+</mo> <mi>p</mi> <mi>h</mi> <msub><mi>i</mi> <mn>1</mn></msub> <mo>×</mo> <msub><mi>y</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub> <mo>+</mo> <mi>p</mi> <mi>h</mi> <msub><mi>i</mi> <mn>0</mn></msub> <mo>×</mo> <msub><mi>y</mi> <mi>t</mi></msub></mrow></math>

+   如果你正在使用聚类模型来通过总结时间序列的特征（均值、标准差、最大值、最小值等）来找到最近的邻居，你可以用一个数据点较少的时间序列计算这些特征，并用该时间序列运行你的模型来识别几个最近的邻居。然后，当最终值到来时更新这些特征，并重新运行在第一轮分析中找到的最近邻的分析。这实际上会在总体上需要更多的计算资源，但会导致在采取最终测量和提供预测之间的延迟时间减少。

在许多情况下，您的模型可能并不像网络延迟或其他因素那样缓慢，因此预计算只有在反馈时间极为重要并且您确信模型计算实质上在应用程序接收所有所需信息并输出有用预测之间的时间中有重大贡献时才是一种值得的技术。

# 数据存储格式：优缺点

在训练和生产化时间序列模型的性能瓶颈中，一个被忽视的领域是数据存储的方法。一些常见的错误包括：

+   *即使时间序列是通过遍历列来形成的，也要将数据存储在基于行的数据格式中*。这将导致时间相邻的点在内存中不是相邻的。

+   *存储原始数据并从这些数据运行分析*。对于给定的模型，预处理和降采样的数据优先。

接下来我们讨论这些数据存储因素，以尽可能保持模型训练和推断的速度。

## 将数据存储为二进制格式

很容易将数据存储在逗号分隔的文本文件中，比如 CSV 文件。这通常是数据的提供方式，所以惯性驱使我们选择这种方式。这些文件格式也是人类可读的，这使得可以轻松地检查文件中的数据与流水线输出的一致性。最后，这种数据通常易于在不同平台之间传输。³

但是，对于您的计算机来说并不容易[读取文本文件](https://perma.cc/XD3Y-NEGP)。如果您处理的数据集非常大，以至于在训练过程中无法将所有数据放入内存中，您将需要处理与您选择的文件格式相关的 I/O 和相关处理。通过将数据存储为二进制格式，您可以通过多种方式大大减少与 I/O 相关的减速：

+   因为数据以二进制格式存储，您的数据处理包已经“理解”它。无需读取 CSV 并将其转换为数据框架。当您输入数据时，您将已经拥有一个数据框架。

+   因为数据以二进制格式存储，它可以比 CSV 或其他基于文本的文件压缩得更多。这意味着 I/O 本身将更短，因为要读取一个文件所需的物理内存较少，以便重新创建其内容。

二进制存储格式在 R 和 Python 中都很容易访问。在 R 中，使用`save()`和`load()`来处理`data.table`。在 Python 中，使用 pickling，并注意 Pandas（`pd.DataFrame.load()`和`pd.DataFrame.save()`）和 NumPy（`np.load()`和`np.save()`）都包含了围绕 pickling 的包装器，您可以用来处理它们特定的对象。

## 以允许您“滑动”处理数据的方式预处理数据

此建议与“为横截面数据构建的模型不会在样本间‘共享’数据”相关。在这种情况下，您还应考虑如何预处理数据，并确保您的做法与使用移动窗口在数据上生成多个测试样本的方式一致。

作为示例，考虑归一化或移动平均作为预处理步骤。如果您计划针对每个时间窗口执行这些操作，则可能会提高模型的准确性（尽管根据我的经验，这种增益通常不大）。但是，存在几个缺点：

+   您需要更多计算资源来多次在重叠数据上计算这些预处理特征，最终得到非常相似的数字。

+   您需要多次存储具有稍有不同预处理的重叠数据。

+   您无法充分利用滑动窗口在数据上的滑动优势。

# 修改您的分析以适应性能考虑

我们许多人都有使用特定分析工具集的习惯，以及关于如何拟合模型的软件套件和经验法则。我们也倾向于在一次评估准确性需求后就不再重新评估它们，尽管我们确定了各种可能的模型性能的计算成本。

时间序列数据通常用于快速预测，特别容易需要能够快速拟合和生产化的模型。模型需要快速拟合，以便可以用新数据进行更新，同时需要快速执行，以便模型预测的消费者有尽可能多的时间来采取行动。因此，您有时可能希望修改您的期望值及相关分析，以实现更快速和更简化计算的过程用于分析和预测。

## 使用所有您的数据并非总是更好

思考如何简化分析的一个重要因素是要理解时间序列中并非所有数据都同等重要。更遥远的数据较不重要。在“异常”时期的数据对建立普通时期模型较不重要。

有多种方式可以考虑减少用于训练模型的数据量。虽然这本书前面已经讨论了许多这些选项，但仍然有必要进行复习，特别是关于性能方面：

降采样

通常情况下，您可以使用较少频率的数据来覆盖相同的回溯窗口进行预测。这是通过乘法因子缩小数据的一种方法。请注意，根据您使用的分析技术，您还有更多创造性的选项，例如根据数据远近以不同速率进行降采样。

仅训练最近的数据

尽管机器学习喜欢数据，但在许多时间序列模型中，仅专注于最近数据而不是对所有数据进行训练，统计或甚至深度学习技术实际上会更好。这将帮助您通过剔除对模型而言信息量较小的数据来减少输入数据。

缩小用于预测的回顾窗口

在许多时间序列模型中，随着你向过去看得越久，模型的性能可能会继续提高，即使只有稍微。你应该对实际需要的准确性与性能做出一些决策。也许每个样本加载到内存中的数据量远远超出了实现可接受性能所需的数据量。

## 复杂的模型并不总是表现得更好

在选择分析模型时尝试最新和最好的可能会很有趣和有趣。然而，真正的问题是，是否更复杂的模型需要额外的计算资源来“支付”。

近年来机器学习中几乎所有的计算进步都来自于对问题投入更多计算资源。对于像图像识别这样确实存在正确答案且需要 100%准确性的问题，这当然是合理的选择。

另一方面，对于像时间序列预测这样的问题，可能存在物理或数学限制，决定选择更复杂的模型不应该只是自动升级而没有成本效益分析。考虑准确性增益是否足以证明模型可能在计算预测时产生的额外延迟，或者所需的额外训练时间，或者将启动的额外计算资源。也许一个资源消耗较少但准确性稍差的方法比一个几乎与简单版本无异的花哨模型更好。

如果你是数据分析师，这种复杂性/准确性和延迟时间/计算资源之间的权衡是你应该分析的内容，把它看作另一个需要调整的超参数。你的工作是指出这些权衡，而不是假设数据工程师会处理这些问题。数据管道中上下游的人员不能替代你在模型选择上的判断，因此在权衡利弊时你必须考虑到数据科学的工程方面。

## 简要提及备选高性能工具

如果你已经全面探索了前述选项，你还可以考虑改变你的基础代码库，更具体地说是摆脱像 Python 和 R 这样的较慢脚本语言。有几种方法可以实现这一点：

+   全面采用 C++ 和 Java。即使你以前没有接触过这些语言，仅仅学习基础知识有时也足以加速管道中的慢部分，将不可能的任务转变为可以管理的任务。特别是 C++ 在可用性和适用于数据处理的标准库方面已经有了巨大的进展。STL 和 C++ 17 语法现在提供了许多与 Python 在各种数据结构上操作相当的选项。即使你多年前讨厌 C++ 和 Java，也应该重新审视它们。⁴

+   在 Python 中，你可以使用几个不同的模块，其中可以编写 Python 代码并编译为 C 或 C++ 代码，加快执行时间。这对于具有许多`for`循环的非常重复的代码特别有用，在 Python 中这些循环很慢，在 C 或 C++ 中可以更加高效，而无需进行巧妙的设计 —— 只需在更快的语言中实现相同的代码即可解决问题。`Numba` 和 `Cython` 都是可以帮助你通过这种方式加速 Python 代码的可访问的 Python 模块。

+   同样，在 R 中，你可以使用 `Rcpp` 来实现类似的功能。

# 更多资源

+   在模型表现相等的情况下：

    Anthony Bagnall 等人，[“时间序列分类大比拼: 最近提出的算法的实验评估,”](https://perma.cc/T76B-M635) *数据挖掘与知识发现* 31, no. 3 (2017): 606–60, https://perma.cc/T76B-M635。

    本文进行了大量的实验来评估现代时间序列分类方法的性能，在广泛的公开数据集上比较它们的表现。数据集的计算复杂性最终变化比尝试的方法实际表现更加显著。正如作者所强调的那样，确定在给定数据集上哪种方法最有效，不尝试所有方法仍然是一门艺术和研究领域。从计算资源的角度来看，这里需要学习的教训是计算复杂性应在方法决策中起重要作用。除非你对复杂且资源密集型算法有非常具有说服力的用例，否则选择一些更简单的东西。

+   在构建简单模型方面：

    Yoon Kim 和 Alexander M. Rush，[“序列级知识蒸馏,”](https://perma.cc/V4U6-EJNU) 收录于《2016 年经验方法在自然语言处理会议论文集》, 编辑 Jian Su, Kevin Duh, 和 Xavier Carreras (Austin, TX: Association for Computational Linguistics, 2016), 1317–27, https://perma.cc/V4U6-EJNU。

    本文将“蒸馏”的一般概念应用于序列学习，适用于机器翻译任务。蒸馏的概念是一个广泛有用的概念。其核心思想是首先设计并训练一个复杂模型，然后在复杂模型的输出上训练一个简化模型。通过利用复杂模型的输出而不是数据本身，可以减少噪音并简化学习问题，使得简化模型能够通过去除噪音来学习大致相同的关系。虽然这种技术不会减少训练时间，但应该能够产生一个在生产中执行速度更快、资源需求更少的模型。

¹ 是的，在现实世界中这种情况经常发生。

² 我们在早期章节讨论的机器学习和深度学习模型案例中，从一个大的时间序列中提取了许多时间序列样本。

³ 尽管存在与不同平台和设备相关的 Unicode 问题，因此仅仅因为使用了基于文本的文件格式，并不代表你可以轻松解决问题。

⁴ 学习曲线陡峭，但一旦你掌握了基本的编译基础设施，这对你的组织将是一个巨大的优势。
