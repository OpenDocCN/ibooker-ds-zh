# 二、白人名字有助于获得工作面试吗？

> 原文：[`causal-methods.github.io/Book/2%29_Does_a_White_Sounding_Name_Help_to_Get_Job_Interview.html`](https://causal-methods.github.io/Book/2%29_Does_a_White_Sounding_Name_Help_to_Get_Job_Interview.html)

[Vitor Kamada](https://www.linkedin.com/in/vitor-kamada-1b73a078)

电子邮件：econometrics.methods@gmail.com

最近更新：2020 年 9 月 15 日

让我们加载 Bertrand & Mullainathan（2004）的数据集。

```py
import pandas as pd
path = "https://github.com/causal-methods/Data/raw/master/" 
df = pd.read_stata(path + "lakisha_aer.dta")
df.head(4) 
```

|  | id | ad | education | ofjobs | yearsexp | honors | volunteer | military | empholes | occupspecific | ... | compreq | orgreq | manuf | transcom | bankreal | trade | busservice | othservice | missind | ownership |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 0 | b | 1 | 4 | 2 | 6 | 0 | 0 | 0 | 1 | 17 | ... | 1.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 |  |
| 1 | b | 1 | 3 | 3 | 6 | 0 | 1 | 1 | 0 | 316 | ... | 1.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 |  |
| 2 | b | 1 | 4 | 1 | 6 | 0 | 0 | 0 | 0 | 19 | ... | 1.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 |  |
| 3 | b | 1 | 3 | 4 | 6 | 0 | 1 | 0 | 1 | 313 | ... | 1.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 |  |

4 行×65 列

让我们将分析限制在变量'call'和'race'上。

回拨：1 = 应聘者被召回面试；否则为 0。

种族：w = 白人，b = 黑人。

```py
callback = df.loc[:, ('call', 'race')]
callback 
```

|  | 回拨 | 种族 |
| --- | --- | --- |
| 0 | 0.0 | w |
| 1 | 0.0 | w |
| 2 | 0.0 | b |
| 3 | 0.0 | b |
| 4 | 0.0 | w |
| ... | ... | ... |
| 4865 | 0.0 | b |
| 4866 | 0.0 | b |
| 4867 | 0.0 | w |
| 4868 | 0.0 | b |
| 4869 | 0.0 | w |

4870 行×2 列

让我们计算按种族分组的观察数量（大小）和变量'call'的平均值。

我们有相同数量（2435）的黑人和白人申请者的简历。

只有 6.4%的黑人收到了回拨；而 9.7%的白人收到了回拨。

因此，白人申请者获得面试回拨的可能性约高出 50%。

换句话说，每 10 份白人申请者发送的简历中，才能得到 1 次面试机会，黑人申请者需要发送 15 份简历才能得到相同的结果。

```py
# Round 2 decimals
pd.set_option('precision', 4)

import numpy as np
callback.groupby('race').agg([np.size, np.mean]) 
```

|  | 回拨 |
| --- | --- |
|  | 大小 | 平均 |
| --- | --- | --- |
| 种族 |  |  |
| --- | --- | --- |
| b | 2435.0 | 0.0645 |
| w | 2435.0 | 0.0965 |

有人可能会争辩说，这 3.2%的差异（9.65 - 6.45）不一定意味着对黑人的歧视。

你可以争辩说，白人申请者获得更多回拨，是因为他们拥有更多的教育、经验、技能，而不是因为肤色。

具体来说，你可以争辩说，白人申请者更有可能获得回拨，是因为他们更有可能拥有大学学位（资格的信号），而不是因为他们是黑人。

如果你从美国人口中随机抽取样本或检查美国人口普查数据，你会发现黑人获得大学学位的可能性比白人小。这是一个不容置疑的事实。

让我们检查 Bertrand & Mullainathan（2004）的数据集中拥有大学学位的黑人和白人的比例。

最初，大学毕业生在变量'education'中被编码为 4，3 = 一些大学，2 = 高中毕业，1 = 一些高中，0 = 未报告。

让我们创建变量'college' = 1，如果一个人完成了大学学位；否则为 0。

```py
df['college'] = np.where(df['education'] == 4, 1, 0) 
```

我们可以看到 72.3%的黑人申请者拥有大学学位。白人拥有大学学位的比例非常相似，为 71.6%。

为什么这些数字不代表美国人口，而且这些值彼此更接近？

因为数据不是从现实中随机抽取的样本。

```py
college = df.loc[:, ('college', 'race')]
college.groupby('race').agg([np.size, np.mean]) 
```

|  | 大学 |
| --- | --- |
|  | 大小 | 平均 |
| --- | --- | --- |
| 种族 |  |  |
| --- | --- | --- |
| b | 2435 | 0.7228 |
| w | 2435 | 0.7162 |

Bertrand＆Mullainathan（2004）产生了实验数据。他们创建了简历。他们将黑人听起来的名字（例如：Lakish 或 Jamal）随机分配给一半简历，将白人听起来的名字（例如：Emily 或 Greg）分配给另一半。

通过姓名对种族的随机化使得两个类别白人和黑人在所有可观察和不可观察的因素上都相等（非常相似）。

让我们检查简历中其他因素的陈述。变量的名称是不言自明的，更多信息可以通过阅读 Bertrand＆Mullainathan（2004）的论文获得。

```py
resume = ['college', 'yearsexp', 'volunteer', 'military',
          'email', 'workinschool', 'honors',
          'computerskills', 'specialskills']
both = df.loc[:, resume]
both.head() 
```

|  | college | yearsexp | volunteer | military | email | workinschool | honors | computerskills | specialskills |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 0 | 1 | 6 | 0 | 0 | 0 | 0 | 0 | 1 | 0 |
| 1 | 0 | 6 | 1 | 1 | 1 | 1 | 0 | 1 | 0 |
| 2 | 1 | 6 | 0 | 0 | 0 | 1 | 0 | 1 | 0 |
| 3 | 0 | 6 | 1 | 0 | 1 | 0 | 0 | 1 | 1 |
| 4 | 0 | 22 | 0 | 0 | 1 | 1 | 0 | 1 | 0 |

让我们使用不同的代码来计算整个样本（白人和黑人）以及黑人和白人之间的分样本变量的平均值。

请注意，整个样本的平均工作经验（yearsexp）为 7.84，黑人为 7.83，白人为 7.86。

如果您检查所有变量，您会发现黑人的平均值非常接近白人的平均值。这是随机化的结果。

我们还计算标准偏差（std），这是平均值周围变化的度量。请注意，整个样本和分样本之间的标准偏差几乎相同。就像平均值一样，在实验数据的情况下，你不应该看到标准偏差之间有太大的差异。

年龄经验变量的标准偏差为 5 年。我们可以粗略地说，大部分观察（约 68%）在平均值的 1 个标准差以下和 1 个标准差以上之间，即在[2.84，12.84]之间。

```py
black = both[df['race']=='b']
white = both[df['race']=='w']
summary = {'mean_both': both.mean(),   'std_both': both.std(),
           'mean_black': black.mean(), 'std_black': black.std(),
           'mean_white': white.mean(), 'std_white': white.std()}
pd.DataFrame(summary) 
```

|  | mean_both | std_both | mean_black | std_black | mean_white | std_white |
| --- | --- | --- | --- | --- | --- | --- |
| college | 0.7195 | 0.4493 | 0.7228 | 0.4477 | 0.7162 | 0.4509 |
| yearsexp | 7.8429 | 5.0446 | 7.8296 | 5.0108 | 7.8563 | 5.0792 |
| volunteer | 0.4115 | 0.4922 | 0.4144 | 0.4927 | 0.4086 | 0.4917 |
| military | 0.0971 | 0.2962 | 0.1018 | 0.3025 | 0.0924 | 0.2897 |
| email | 0.4793 | 0.4996 | 0.4797 | 0.4997 | 0.4789 | 0.4997 |
| workinschool | 0.5595 | 0.4965 | 0.5610 | 0.4964 | 0.5581 | 0.4967 |
| honors | 0.0528 | 0.2236 | 0.0513 | 0.2207 | 0.0542 | 0.2265 |
| computerskills | 0.8205 | 0.3838 | 0.8324 | 0.3735 | 0.8086 | 0.3935 |
| specialskills | 0.3287 | 0.4698 | 0.3273 | 0.4693 | 0.3302 | 0.4704 |

为什么我们如此关心上表，显示平均白人和平均黑人申请者几乎相同？

因为白人申请者更有可能因为他们更高的教育水平而获得回电的论点是站不住脚的，如果白人和黑人申请者两组都具有类似的教育水平。

无论是未观察到的因素还是无法测量的因素，比如动机、心理特征等，都不能用来证明回电率的不同。

在一个实验中，只有处理变量（种族）是外生操纵的。其他一切都保持不变，因此结果变量（回电）的变化只能归因于处理变量（种族）的变化。

因此，实验研究消除了观察研究中出现的所有混杂因素。

实验是硬科学中的金标准。宣称因果关系的最严格方式。

调查、人口普查、直接从现实中提取的观察数据不能用来建立因果关系。它可能有助于捕捉关联，但不能证明因果关系。

形式上，我们可以写出下面的因果模型。这 3 行是等价的。我们只有在处理变量（$T$）被随机化时，才能声称$\beta$具有“因果”解释。在没有随机化的情况下，$\beta$只捕捉到相关性。

$$结果 = 截距 + 斜率*处理 + 误差$$

$$Y=\alpha+\beta T +\epsilon$$

$$回电 = \alpha+\beta 种族+\epsilon$$

让我们使用普通最小二乘（OLS）方法估计上述模型。

在 Python 的 stasmodels 库中，截距是一个值为 1 的常数。

让我们创建变量“处理”：1 = 黑人申请者，0 = 白人申请者。

变量‘call’是结果变量（Y）。

```py
df['Intercept'] = 1
df['Treatment'] = np.where(df['race'] =='b', 1, 0)
import statsmodels.api as sm
ols = sm.OLS(df['call'], df[['Intercept', 'Treatment']],
                    missing='drop').fit() 
```

```py
C:\Anaconda\envs\textbook\lib\site-packages\statsmodels\tools\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.
  import pandas.util.testing as tm 
```

让我们打印结果。

```py
print(ols.summary().tables[1]) 
```

```py
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      0.0965      0.006     17.532      0.000       0.086       0.107
Treatment     -0.0320      0.008     -4.115      0.000      -0.047      -0.017
============================================================================== 
```

现在我们可以将拟合模型写为：

$$\widehat{回电} = 0.0965-0.032\widehat{处理}$$

我们已经在本节开头的代码中得到了上述系数，我将再次重现：

```py
callback.groupby('race').agg([np.size, np.mean]) 
```

|  | 回电 |
| --- | --- |
|  | 大小 | 平均值 |
| --- | --- | --- |
| 种族 |  |  |
| --- | --- | --- |
| b | 2435.0 | 0.0645 |
| w | 2435.0 | 0.0965 |

请注意，截距的值为 9.65%。这是接到面试回电的白人申请者的比例。

处理变量的系数为 3.2%。解释是，作为黑人申请者“导致”接到面试回电的几率减少了 3.2%（6.45% - 9.65%）。

请记住，3.2%是一个很大的幅度，因为它代表了大约 50%的差异。在实际情况下，黑人申请者需要发送 15 份简历才能获得一个面试机会，而白人申请者只需要发送 10 份简历。

处理变量的系数在显著水平（$\alpha$ = 1%）上也是统计学上显著的。

-4.115 的 t 值是比率：

$$t = \frac{系数}{标准\ 误差} =\frac{-0.032}{0.008} = -4.115$$

零假设是：

$$H_0: \beta=0$$

-4 的 t 值意味着观察值（-3.2%）比均值（$\beta=0$）低 4 个标准偏差。得到这个值的概率或概率几乎为 0。因此，我们拒绝零假设，即处理的幅度为 0。

什么定义了一个实验？

处理变量（T）的随机化。

这自动使处理变量（T）独立于其他因素：

$$T \perp 其他\ 因素$$

在实验中，回归中其他因素的添加不会影响处理变量（$\beta$）的估计。如果您看到$\beta$有实质性的变化，您可以推断您没有使用实验数据。

请注意，在观察性研究中，您必须始终控制其他因素。否则，您将面临遗漏变量偏差问题。

让我们估计下面的多元回归：

$$y=\alpha+\beta T + 其他\ 因素+\epsilon$$

```py
other_factors = ['college', 'yearsexp', 'volunteer', 'military',
          'email', 'workinschool', 'honors',
          'computerskills', 'specialskills']
multiple_reg = sm.OLS(df['call'],
                      df[['Intercept', 'Treatment'] + other_factors],
                      missing='drop').fit() 
```

我们可以看到处理（-3.1%）的系数并没有像预期的那样随着额外的控制变量而发生太大变化。

```py
print(multiple_reg.summary().tables[1]) 
```

```py
==================================================================================
                     coef    std err          t      P>|t|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.0547      0.015      3.727      0.000       0.026       0.083
Treatment         -0.0311      0.008     -4.032      0.000      -0.046      -0.016
college            0.0068      0.009      0.768      0.443      -0.010       0.024
yearsexp           0.0029      0.001      3.630      0.000       0.001       0.005
volunteer         -0.0032      0.011     -0.295      0.768      -0.024       0.018
military          -0.0033      0.014     -0.232      0.817      -0.032       0.025
email              0.0143      0.011      1.285      0.199      -0.008       0.036
workinschool       0.0008      0.009      0.093      0.926      -0.016       0.018
honors             0.0642      0.018      3.632      0.000       0.030       0.099
computerskills    -0.0202      0.011     -1.877      0.061      -0.041       0.001
specialskills      0.0634      0.009      7.376      0.000       0.047       0.080
================================================================================== 
```

## 练习

1）在种族歧视的文献中，每个实验研究都有超过 1000 个观察性研究。假设您阅读了 100 个观察性研究，表明种族歧视是真实的。假设您还阅读了 1 个声称没有种族歧视证据的实验研究。您更倾向于接受 100 个观察性研究的结果还是一个实验研究的结果？请解释您的答案。

2）当组间均值差异存在偏差且未捕捉到平均因果效应时？请使用数学方程式来解释您的答案。

3）解释下面列出的列联表的 4 个值。具体地说明含义并比较这些值。

变量‘h’：1 = 更高质量的简历；0 = 更低质量的简历。这个变量是随机化的。

其他变量已经被定义。

```py
contingency_table = pd.crosstab(df['Treatment'], df['h'], 
                                values=df['call'], aggfunc='mean')
contingency_table 
```

| h | 0.0 | 1.0 |
| --- | --- | --- |
| 处理 |  |  |
| --- | --- | --- |
| 0 | 0.0850 | 0.1079 |
| 1 | 0.0619 | 0.0670 |

4）我创建了一个交互变量'h_Treatment'，它是变量'h'和'treatment'的成对乘法。

如何使用下面回归的系数来获得练习 3 中列联表的值？展示计算过程。

```py
df['h_Treatment'] = df['h']*df['Treatment']
interaction = sm.OLS(df['call'],
                      df[['Intercept', 'Treatment', 'h', 'h_Treatment'] ],
                      missing='drop').fit()
print(interaction.summary().tables[1]) 
```

```py
===============================================================================
                  coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------
Intercept       0.0850      0.008     10.895      0.000       0.070       0.100
Treatment      -0.0231      0.011     -2.094      0.036      -0.045      -0.001
h               0.0229      0.011      2.085      0.037       0.001       0.045
h_Treatment    -0.0178      0.016     -1.142      0.253      -0.048       0.013
=============================================================================== 
```

5）我在没有交互项'h_Treatment'的情况下运行了下面的回归。我能使用下面的系数来获得练习 3 中列联表的值吗？如果可以，展示确切的计算过程。

```py
interaction = sm.OLS(df['call'],
                      df[['Intercept', 'Treatment', 'h'] ],
                      missing='drop').fit()
print(interaction.summary().tables[1]) 
```

```py
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      0.0894      0.007     13.250      0.000       0.076       0.103
Treatment     -0.0320      0.008     -4.116      0.000      -0.047      -0.017
h              0.0141      0.008      1.806      0.071      -0.001       0.029
============================================================================== 
```

6）编写一个代码以获得下面的列联表：

| 名字 h | 0.0 | 1.0 |
| --- | --- | --- |
| Aisha | 0.010000 | 0.037500 |
| Allison | 0.121739 | 0.068376 |
| … | … | … |

表格内是由简历质量分解的回访率。Kristen 和 Lakisha 的回访率是多少？为什么回访率如此不同？我们能否证明回访率的差异，认为其中一个比另一个更受教育和合格？

7）使用 Bertrand＆Mullainathan（2004）的数据来测试白人和黑人是否具有相同的平均工作经验。陈述零假设。写出测试的数学公式。解释结果。

8）像 Bertrand＆Mullainathan（2004）一样打破常规。提出一个实际的方法来找出蓝眼睛和金发是否会导致更高的薪水。具体说明如何在实践中实施随机化策略。

## 参考

Bertrand, Marianne, and Sendhil Mullainathan.（2004）。[Are Emily and Greg More Employable Than Lakisha and Jamal? A Field Experiment on Labor Market Discrimination](https://github.com/causal-methods/Papers/raw/master/Are%20Emily%20and%20Greg%20More%20Employable%20than%20Lakisha%20and%20Jamal.pdf)。《美国经济评论》，94（4）：991-1013。
