# 第十三章：监控 Kafka

Apache Kafka 应用程序有许多用于其操作的测量值，事实上有很多，以至于很容易变得令人困惑，不知道要观察什么是重要的，什么可以搁置。这些范围从关于流量总体速率的简单指标，到每种请求类型的详细定时指标，再到每个主题和每个分区的指标。它们提供了对代理中每个操作的详细视图，但也可能使您成为负责管理监控系统的人的梦魇。

本章将详细介绍始终监控的最关键指标以及如何对其做出响应。我们还将描述在调试问题时手头上最重要的一些指标。然而，这不是一个详尽的可用指标列表，因为列表经常变化，许多指标只对硬核 Kafka 开发人员有用。

# 指标基础知识

在进入由 Kafka 代理和客户端提供的具体指标之前，让我们讨论一下如何监控 Java 应用程序的基础知识以及一些关于监控和警报的最佳实践。这将为理解如何监控应用程序以及为什么后面描述的特定指标被选择为最重要的提供基础。

## 指标在哪里？

Kafka 公开的所有指标都可以通过 Java 管理扩展（JMX）接口访问。在外部监控系统中使用它们的最简单方法是使用监控系统提供的收集代理，并将其附加到 Kafka 进程上。这可能是在系统上运行并连接到 JMX 接口的单独进程，例如 Nagios XI 的`check_jmx`插件或`jmxtrans`。您还可以利用直接在 Kafka 进程中运行的 JMX 代理通过 HTTP 连接访问指标，例如 Jolokia 或 MX4J。

如何设置监控代理的深入讨论超出了本章的范围，而且有太多选择，无法公平地对所有选择进行公正。如果您的组织目前没有监控 Java 应用程序的经验，可能值得考虑监控作为一项服务。有许多公司提供监控代理、指标收集点、存储、绘图和警报的服务包。他们可以帮助您进一步设置所需的监控代理。

# 查找 JMX 端口

为了帮助配置直接连接到 Kafka 代理的应用程序（如监控系统），代理在存储在 ZooKeeper 中的代理信息中设置了配置的 JMX 端口。`/brokers/ids/<ID>` znode 包含代理的 JSON 格式数据，包括`hostname`和`jmx_port`键。但是，应该注意的是，出于安全原因，Kafka 默认情况下禁用了远程 JMX。如果您要启用它，必须正确配置端口的安全性。这是因为 JMX 不仅允许查看应用程序的状态，还允许执行代码。强烈建议您使用加载到应用程序中的 JMX 指标代理。

### 非应用程序指标

并非所有指标都来自 Kafka 本身。您可以从五个一般分组中获取指标。表 13-1 描述了我们在监控 Kafka 代理时的类别。

表 13-1。指标来源

| 类别 | 描述 |
| --- | --- |
| 应用程序指标 | 这些是您从 Kafka 本身获取的指标，来自 JMX 接口。 |
| 日志 | 来自 Kafka 本身的另一种监控数据类型。因为它是某种形式的文本或结构化数据，而不仅仅是一个数字，所以需要更多的处理。 |
| 基础设施指标 | 这些指标来自于您在 Kafka 前面的系统，但仍然在请求路径内并在您的控制范围内。一个例子是负载均衡器。 |
| 合成客户端 | 这是来自与您的 Kafka 部署外部工具的数据，就像客户端一样，但在您的直接控制下，通常不执行与您的客户端相同的工作。像 Kafka Monitor 这样的外部监视器属于这一类别。 |
| 客户端指标 | 这些是由连接到您的集群的 Kafka 客户端公开的指标。 |

Kafka 生成的日志将在本章后面讨论，客户端指标也是如此。我们还将简要涉及合成指标。然而，基础设施指标取决于您的特定环境，并且超出了这里讨论的范围。在您的 Kafka 旅程中越深入，这些指标来源对于充分了解应用程序的运行方式就越重要，因为在列表中越靠后，它们提供的对 Kafka 的客观视图就越多。例如，在开始阶段依赖经纪人的指标就足够了，但以后您会希望更客观地了解它们的表现。客观测量价值的一个熟悉例子是监控网站的健康状况。Web 服务器正常运行，并且它报告的所有指标都表明它正在工作。然而，您的 Web 服务器和外部用户之间的网络存在问题，这意味着您的用户无法访问 Web 服务器。在您的网络之外运行的合成客户端将检测到这一情况并向您发出警报。

## 我需要哪些指标？

对您重要的具体指标几乎与您要使用的最佳编辑器一样重要。这将大大取决于您打算如何使用它们，您有哪些可用于收集数据的工具，您在使用 Kafka 方面的进展如何，以及您有多少时间可用于围绕 Kafka 构建基础设施。一个经纪人内部开发人员的需求将远远不同于运行 Kafka 部署的站点可靠性工程师的需求。

### 警报还是调试？

您应该问自己的第一个问题是，您的主要目标是在 Kafka 出现问题时警报您，还是调试出现的问题。答案通常会涉及两者，但知道一个指标是用于哪个目的将使您在收集后对其进行不同处理。

用于警报的指标在很短的时间内非常有用——通常不会超过解决问题所需的时间。您可以测量几个小时，或者可能几天。这些指标将被自动化消耗，自动化将为您响应已知问题，以及在自动化尚不存在的情况下由人工操作员消耗。这些指标通常更为客观，因为不影响客户端的问题远不及影响客户端的问题严重。

主要用于调试的数据具有更长的时间范围，因为您经常诊断已经存在一段时间的问题，或者深入研究更复杂的问题。这些数据将需要在收集后的几天或几周内保持可用。通常还会是更主观的测量，或者来自 Kafka 应用程序本身的数据。请记住，不一定需要将这些数据收集到监控系统中。如果指标用于现场调试问题，则在需要时可用即可。您无需通过持续收集成千上万个值来压倒监控系统。

# 历史指标

最终，您还将需要应用程序的历史数据。历史数据最常见的用途是用于容量管理，因此包括有关使用的资源的信息，包括计算资源、存储和网络。这些指标需要长时间存储，以年为单位。您还可能需要收集额外的元数据来将指标放入上下文中，例如代理何时添加到集群或从集群中删除。

### 自动化还是人类？

还需要考虑的一个问题是指标的使用者是谁。如果指标由自动化程序使用，它们应该非常具体。拥有大量描述细节的指标是可以接受的，因为这正是计算机存在的原因：处理大量数据。数据越具体，就越容易创建基于其操作的自动化程序，因为数据不会留下太多关于其含义的解释空间。另一方面，如果指标将由人类使用，呈现大量指标将会令人不知所措。在基于这些测量值定义警报时，这变得更加重要。很容易陷入“警报疲劳”，因为有太多警报响起，很难知道问题有多严重。正确定义每个指标的阈值并使其保持最新也很困难。当警报过多或经常不正确时，我们开始不相信警报是否正确描述了我们应用程序的状态。

想想汽车的运行。为了在汽车运行时正确调整空气与燃料的比例，计算机需要对空气密度、燃料、排气和发动机运行等细微之处进行多次测量。然而，这些测量对车辆的人类操作者来说将是不堪重负的。相反，我们有一个“发动机故障”指示灯。一个指示器告诉您有问题，并且有一种方法可以获取更详细的信息，告诉您问题的确切所在。在本章中，我们将确定提供最高覆盖率的指标，以保持您的警报简单。

## 应用程序健康检查

无论您如何从 Kafka 收集指标，都应确保有一种方法来通过简单的健康检查监控应用程序进程的整体健康状况。这可以通过两种方式实现：

+   报告代理是否正常运行的外部过程（健康检查）

+   对 Kafka 代理报告的指标缺失进行警报（有时称为*陈旧指标*）

尽管第二种方法有效，但它可能会使难以区分 Kafka 代理的故障和监控系统本身的故障。

对于 Kafka 代理，这可以简单地连接到外部端口（客户端用于连接代理的相同端口）以检查其响应。对于客户端应用程序，可能会更复杂，从简单检查进程是否正在运行，到确定应用程序健康状况的内部方法。

# 服务级目标

监控的一个特别关键的领域是基础设施服务，比如 Kafka，其中的服务级目标或 SLO。这是我们向客户传达基础设施服务可以提供的服务水平。客户希望能够将 Kafka 等服务视为不透明系统：他们不希望也不需要了解其内部工作原理，只需要了解他们正在使用的接口，并知道它将按照他们的需求进行操作。

## 服务级定义

在讨论 Kafka 中的 SLO 之前，必须就所使用的术语达成一致。经常会听到工程师、经理、高管和其他人在“服务级”领域错误地使用术语，这导致对实际讨论的内容产生困惑。

*服务级指标*（SLI）是描述服务可靠性的指标。它应该与客户的体验密切相关，因此通常情况下，这些测量越客观，它们就越好。在请求处理系统（如 Kafka）中，通常最好将这些测量表达为良好事件数量与总事件数量之间的比率，例如，返回 2xx、3xx 或 4xx 响应的网页服务器请求的比例。

*服务级目标*（SLO），也可以称为*服务级阈值*（SLT），将 SLI 与目标值结合起来。表达目标的常见方式是通过数量的 nines（99.9%是“三个 nines”），尽管这并不是必需的。SLO 还应包括在其上进行测量的时间范围，通常在天的时间尺度上。例如，在 7 天内，网页服务器的请求中必须返回 2xx、3xx 或 4xx 响应的 99%。

*服务级协议*（SLA）是服务提供商和客户之间的合同。它通常包括几个 SLO，以及有关如何测量和报告它们、客户如何从服务提供商那里寻求支持以及服务提供商如果未能在 SLA 范围内执行将受到的处罚的详细信息。例如，前述 SLO 的 SLA 可能规定，如果服务提供商未能在 SLO 范围内运营，他们将退还客户支付的服务期间的所有费用。

# 运营级别协议

*运营级别协议*（OLA）这个术语使用得较少。它描述了在 SLA 的整体交付中多个内部服务或支持提供者之间的协议。目标是确保履行 SLA 所必需的多个活动在日常运营中得到适当描述和核算。

人们经常谈论 SLA 时实际上是指 SLO。虽然向付费客户提供服务的人可能与这些客户有 SLA，但负责运行应用程序的工程师很少负责超出 SLO 范围的任何事情。此外，只有内部客户（即为更大的服务运行 Kafka 作为内部数据基础设施的人）通常不与这些内部客户有 SLA。然而，这不应阻止您设定和传达 SLO，因为这样做将减少客户对他们认为 Kafka 应该表现如何的假设。

## 什么指标可以成为良好的 SLI？

一般来说，SLI 的指标应该使用 Kafka 经纪人之外的东西进行收集。原因是 SLO 应该描述您的服务的典型用户是否满意，而您无法主观地衡量这一点。您的客户不在乎您是否认为您的服务正在正确运行；重要的是他们的体验（总体而言）。这意味着基础设施指标是可以的，合成客户端是好的，而客户端指标对于大多数 SLI 来说可能是最好的。

虽然这并不是一个详尽的列表，但在请求/响应和数据存储系统中使用的最常见的 SLI 在表 13-2 中。

# 客户总是想要更多

有一些 SLO 可能会引起客户的兴趣，但这些 SLO 对他们很重要，但不在你的控制范围内。例如，他们可能会关心 Kafka 生成的数据的正确性或新鲜度。不要同意支持你不负责的 SLO，因为这只会导致承担削弱保持 Kafka 正常运行的核心工作的工作。确保将他们与适当的团队联系起来，以建立对这些额外要求的理解和协议。

表 13-2\. SLI 的类型

| 可用性 | 客户能否发出请求并获得响应？ |
| --- | --- |
| 延迟 | 响应返回的速度有多快？ |
| 质量 | 响应是否包含适当的响应？ |
| 安全性 | 请求和响应是否得到适当的保护，无论是授权还是加密？ |
| 吞吐量 | 客户端是否能够快速获取足够的数据？ |

请记住，通常最好让您的 SLI 基于落在 SLO 阈值内的事件计数。这意味着理想情况下，应逐个检查每个事件，以查看它是否满足 SLO 的阈值。这排除了分位数指标作为良好 SLI 的可能性，因为这些指标只会告诉您 90%的事件低于给定值，而不允许您控制该值是多少。然而，将值聚合到桶中（例如，“小于 10 毫秒”，“10-50 毫秒”，“50-100 毫秒”等）在处理 SLO 时可能很有用，特别是当您还不确定良好阈值是什么时。这将使您了解 SLO 范围内事件的分布，并且您可以配置桶，使边界值成为 SLO 阈值的合理值。

## 使用警报中的 SLO

简而言之，SLO 应该为您的主要警报提供信息。原因是 SLO 从客户的角度描述了问题，这些问题应该是您首先关心的问题。一般来说，如果问题不影响您的客户，那么它就不需要在夜间叫醒您。SLO 还将告诉您有关您不知道如何检测的问题，因为您以前从未见过它们。它们不会告诉您这些问题是什么，但它们会告诉您这些问题存在。

挑战在于直接将 SLO 用作警报非常困难。SLO 最适合长时间尺度，例如一周，因为我们希望以可消化的方式向管理层和客户报告它们。此外，当 SLO 警报触发时，为时已晚 - 您已经在 SLO 范围之外运行。有些人会使用导数值提供预警，但使用 SLO 进行警报的最佳方法是观察您在其时间范围内通过 SLO 的速率。

例如，假设您的 Kafka 集群每周接收一百万个请求，并且您定义了一个 SLO，规定 99.9％的请求必须在 10 毫秒内发送第一个响应字节。这意味着在一周内，您最多可以有一千个请求的响应速度慢于此，而一切仍将正常。通常，您每小时会看到一个这样的请求，这大约是每周 168 个不良请求，从周日到周六进行测量。您有一个指标显示这是 SLO 燃烧速率，每小时一个请求在一百万个请求每周中是 0.1％的燃烧速率。

在周二上午 10 点，您的指标发生变化，现在显示燃烧速率为每小时 0.4％。这不是很好，但这还不是问题，因为到本周末时，您将远远在 SLO 范围内。您打开了一个工单来查看问题，但又回到了一些更高优先级的工作。在周三下午 2 点，燃烧速率跳升到每小时 2％，您的警报响了。您知道以这个速度，您将在周五中午之前违反 SLO。放下一切，您诊断了问题，大约 4 个小时后，您将燃烧速率降至每小时 0.4％，并且一直保持在这个水平。通过使用燃烧速率，您成功避免了本周违反 SLO。

有关利用 SLO 和燃烧速率进行警报的更多信息，您会发现[*Site Reliability Engineering*](https://oreil.ly/bPBxC)和[*The Site Reliability Workbook*](https://oreil.ly/qSmOc)是优秀的资源，两者均由 Betsy Beyer 等人编辑（O'Reilly）。

# Kafka Broker Metrics

有许多 Kafka 经纪人指标。其中许多是低级测量，由开发人员在调查特定问题或预期以后需要调试信息时添加的。这些指标提供有关经纪人内几乎每个功能的信息，但最常见的指标提供了日常运行 Kafka 所需的信息。

# 谁来监视监视者？

许多组织使用 Kafka 收集应用程序指标、系统指标和日志，供中央监控系统使用。这是将应用程序与监控系统解耦的绝佳方式，但对于 Kafka 本身来说，也提出了特定的问题。如果您使用相同的系统来监视 Kafka 本身，很可能您永远不会知道 Kafka 何时出现故障，因为监控系统的数据流也会中断。

有许多方法可以解决这个问题。一种方法是为 Kafka 使用一个不依赖于 Kafka 的单独监控系统。另一种方法是，如果您有多个数据中心，要确保数据中心 A 的 Kafka 集群的指标被生成到数据中心 B，反之亦然。无论您决定如何处理，都要确保 Kafka 的监控和警报不依赖于 Kafka 的正常工作。

在本节中，我们将首先讨论诊断 Kafka 集群问题的高级工作流程，参考有用的指标。这些指标和其他指标将在本章后面更详细地描述。这绝不是经纪人指标的详尽清单，而是检查经纪人和集群健康状况的几个“必备”指标。最后，我们将讨论日志记录，然后转向客户端指标。

## 诊断集群问题

在涉及 Kafka 集群的问题时，有三个主要类别：

+   单经纪人问题

+   超载的集群

+   控制器问题

与单个经纪人的问题相比，诊断和响应集群问题要容易得多。这些问题将显示为集群指标中的异常值，并且通常与存储设备的缓慢或故障，或系统中其他应用程序的计算限制有关。要检测它们，确保您正在监视单个服务器的可用性，以及存储设备的状态，利用操作系统（OS）指标。

然而，在操作系统或硬件级别没有发现问题的情况下，问题几乎总是 Kafka 集群负载不平衡。虽然 Kafka 试图使集群中的数据均匀分布在所有经纪人之间，但这并不意味着客户端对该数据的访问是均匀分布的。它也无法检测到热分区等问题。强烈建议您始终使用外部工具来保持集群的平衡。其中一个工具是[Cruise Control](https://oreil.ly/rLybu)，这是一个不断监视集群并在其中重新平衡分区的应用程序。它还提供许多其他管理功能，例如添加和删除经纪人。

# 首选副本选举

在进一步诊断问题之前的第一步是确保您最近已运行了首选副本选举（参见第十二章）。Kafka 经纪人在释放领导权后（例如，当经纪人失败或关闭时），不会自动重新接管分区领导权（除非启用了自动领导者重新平衡）。这意味着领导副本在集群中很容易变得不平衡。首选副本选举是安全且易于运行的，因此最好先这样做，看看问题是否消失。

过载的集群是另一个容易检测到的问题。如果集群是平衡的，并且许多代理显示出增加的请求延迟或低请求处理程序池空闲比率，那么您的代理已经达到了为该集群提供流量的极限。在深入检查后，您可能会发现有一个客户端改变了其请求模式，现在导致了问题。然而，即使发生这种情况，您可能无法改变客户端。您可以采取的解决方案要么是减少对集群的负载，要么是增加代理的数量。

Kafka 集群中控制器的问题要难以诊断得多，通常属于 Kafka 本身的错误类别。这些问题表现为代理元数据不同步、代理离线时代理似乎正常，以及主题控制操作（如创建）未能正确进行。如果您在集群中遇到问题并说“这真的很奇怪”，那么很有可能是因为控制器做了一些不可预测且不好的事情。监控控制器的方法并不多，但监控活动控制器计数以及控制器队列大小将为您提供一个高级别的指标，以判断是否存在问题。

## 未复制的分区的艺术

监控 Kafka 时使用的最流行的指标之一是未复制的分区。在集群中的每个代理上提供的这个度量值，给出了代理是领导副本的分区数量，其中跟随者副本没有赶上。这个单一的度量值可以揭示 Kafka 集群的许多问题，从代理宕机到资源耗尽。由于这个度量值可以指示的问题种类繁多，因此值得深入研究如何应对非零值。本章后面将描述用于诊断这些问题的许多度量值。有关未复制的分区的更多详细信息，请参见表 13-3。

表 13-3。度量值及其对应的未复制的分区

| 指标名称 | 未复制的分区 |
| --- | --- |
| JMX MBean | `kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions` |
| 值范围 | 整数，零或更大 |

# 未复制的分区警报陷阱

在本书的上一版以及许多会议演讲中，作者们长时间地谈到了未复制的分区（URP）度量应该是您的主要警报度量，因为它描述了多少问题。这种方法存在大量问题，其中最主要的问题之一是，未复制的分区度量通常由于良性原因而频繁出现非零值。这意味着作为 Kafka 集群的运维人员，您将收到错误警报，从而忽略警报。这也需要相当多的知识才能理解度量值告诉您的信息。因此，我们不再建议使用 URP 进行警报。相反，您应该依赖基于 SLO 的警报来检测未知问题。

集群中许多代理报告的未复制的分区数量保持稳定（不变），通常表明集群中的一个代理已经离线。整个集群中的未复制的分区数量将等于分配给该代理的分区数量，而宕机的代理将不会报告度量值。在这种情况下，您需要调查发生了什么，并解决这种情况。这通常是硬件故障，但也可能是导致问题的操作系统或 Java 问题。

如果未复制的分区数量波动，或者数量稳定但没有经纪人离线，通常表明集群中存在性能问题。由于这些问题的多样性，这些类型的问题更难诊断，但有几个步骤可以帮助您缩小问题的可能原因。第一步是尝试确定问题是与单个经纪人相关还是与整个集群相关。有时这可能是一个难以回答的问题。如果未复制的分区在单个经纪人上，就像下面的例子一样，那么通常这个经纪人就是问题所在。错误显示其他经纪人在复制来自该经纪人的消息时出现问题。

如果有几个经纪人有未复制的分区，这可能是一个集群问题，但仍可能是一个单个经纪人的问题。在这种情况下，这可能是因为一个单个经纪人在复制来自任何地方的消息时出现问题，您将不得不找出是哪个经纪人。一种方法是获取集群的未复制分区列表，并查看是否有一个特定的经纪人是所有未复制分区的共同线索。使用`kafka-topics.sh`工具（在第十二章中有详细讨论），您可以获取未复制分区的列表，以寻找一个共同的线索。

例如，在集群中列出未复制的分区：

```java
# kafka-topics.sh --bootstrap-server kafka1.example.com:9092/kafka-cluster
--describe --under-replicated
    Topic: topicOne   Partition: 5    Leader: 1    Replicas: 1,2 Isr: 1
    Topic: topicOne   Partition: 6    Leader: 3    Replicas: 2,3 Isr: 3
    Topic: topicTwo   Partition: 3    Leader: 4    Replicas: 2,4 Isr: 4
    Topic: topicTwo   Partition: 7    Leader: 5    Replicas: 5,2 Isr: 5
    Topic: topicSix   Partition: 1    Leader: 3    Replicas: 2,3 Isr: 3
    Topic: topicSix   Partition: 2    Leader: 1    Replicas: 1,2 Isr: 1
    Topic: topicSix   Partition: 5    Leader: 6    Replicas: 2,6 Isr: 6
    Topic: topicSix   Partition: 7    Leader: 7    Replicas: 7,2 Isr: 7
    Topic: topicNine  Partition: 1    Leader: 1    Replicas: 1,2 Isr: 1
    Topic: topicNine  Partition: 3    Leader: 3    Replicas: 2,3 Isr: 3
    Topic: topicNine  Partition: 4    Leader: 3    Replicas: 3,2 Isr: 3
    Topic: topicNine  Partition: 7    Leader: 3    Replicas: 2,3 Isr: 3
    Topic: topicNine  Partition: 0    Leader: 3    Replicas: 2,3 Isr: 3
    Topic: topicNine  Partition: 5    Leader: 6    Replicas: 6,2 Isr: 6
#
```

在这个例子中，常见的经纪人是编号 2。这表明这个经纪人在消息复制方面存在问题，将导致我们将调查重点放在这个经纪人身上。如果没有常见的经纪人，那么很可能是整个集群出现了问题。

### 集群级问题

集群问题通常分为两类：

+   不平衡的负载

+   资源耗尽

第一个问题，不平衡的分区或领导权，是最容易发现的，尽管修复它可能是一个复杂的过程。为了诊断这个问题，您需要从集群中的经纪人获取几个指标：

+   分区计数

+   领导分区计数

+   所有主题的消息输入速率

+   所有主题的字节输入速率

+   所有主题的字节输出速率

检查这些指标。在一个完全平衡的集群中，所有经纪人的数字将是均匀的，如表 13-4 中所示。

表 13-4。利用率指标

| 经纪人 | 分区 | 领导者 | 消息数 | 字节输入 | 字节输出 |
| --- | --- | --- | --- | --- | --- |
| 1 | 100 | 50 | 13130 msg/s | 3.56 MBps | 9.45 MBps |
| 2 | 101 | 49 | 12842 msg/s | 3.66 MBps | 9.25 MBps |
| 3 | 100 | 50 | 13086 msg/s | 3.23 MBps | 9.82 MBps |

这表明所有经纪人大约承担着相同数量的流量。假设您已经运行了首选副本选举，大的偏差表明集群内的流量不平衡。为了解决这个问题，您需要将分区从负载较重的经纪人移动到负载较轻的经纪人。这是使用`kafka-reassign-partitions.sh`工具来完成的，该工具在第十二章中有描述。

# 用于平衡集群的辅助工具

Kafka 经纪人本身不提供集群中分区的自动重新分配。这意味着在 Kafka 集群中平衡流量可能是一个令人昏昏欲睡的过程，需要手动审查大量的指标列表，并尝试找出有效的副本分配。为了帮助解决这个问题，一些组织已经开发了自动化工具来执行这项任务。其中一个例子是 LinkedIn 在 GitHub 上发布的`kafka-assigner`工具（https://oreil.ly/8ilPw）。一些 Kafka 支持的企业产品也提供了这个功能。

另一个常见的集群性能问题是超出代理提供请求的能力。可能会有许多可能的瓶颈会减慢速度：CPU、磁盘 IO 和网络吞吐量是最常见的几个。磁盘利用率不在其中，因为代理将正常运行，直到磁盘填满，然后磁盘将突然失败。为了诊断容量问题，您可以在操作系统级别跟踪许多指标，包括：

+   CPU 利用率

+   入站网络吞吐量

+   出站网络吞吐量

+   磁盘平均等待时间

+   磁盘百分比利用率

耗尽任何这些资源通常会表现为相同的问题：副本不足的分区。重要的是要记住，代理复制过程的操作方式与其他 Kafka 客户端完全相同。如果您的集群在复制方面出现问题，那么您的客户在生产和消费消息方面也会出现问题。在集群正常运行时，为这些指标制定基线，然后设置指示出现问题的阈值，远在容量耗尽之前就能指示出问题的发展。您还需要查看这些指标随着时间推移而增加到集群的流量。就 Kafka 代理指标而言，“所有主题字节输入速率”是显示集群使用情况的良好指南。

### 主机级问题

如果 Kafka 的性能问题不是整个集群中存在，并且可以隔离到一个或两个代理，那么是时候检查该服务器，看看它与集群的其他部分有何不同了。这些问题属于几个一般类别：

+   硬件故障

+   网络

+   与另一个进程冲突

+   本地配置差异

# 典型服务器和问题

服务器及其操作系统是一个复杂的机器，有成千上万个组件，任何一个都可能出现问题，导致完全故障或性能下降。我们不可能在本书中涵盖所有可能出现故障的内容——已经有许多卷的书籍，而且将继续有关于这个主题的书籍。但我们可以讨论一些最常见的问题。本节将重点讨论运行 Linux 操作系统的典型服务器的问题。

硬件故障有时很明显，比如服务器突然停止工作，但是导致性能问题的是不太明显的问题。这些通常是允许系统继续运行但降低操作的软故障。这可能是一小部分内存出现问题，系统已检测到问题并绕过该段（减少了总可用内存）。CPU 故障也可能发生相同的情况。对于这类问题，您应该使用硬件提供的设施，例如智能平台管理接口（IPMI）来监控硬件健康状况。当存在活动问题时，查看使用`dmesg`的内核环形缓冲区将帮助您查看被抛到系统控制台的日志消息。

导致 Kafka 性能下降的更常见的硬件故障是磁盘故障。Apache Kafka 依赖磁盘来持久化消息，生产者的性能直接取决于磁盘提交写入的速度。任何偏差都会表现为生产者和副本获取者性能的问题。后者是导致副本不足的分区。因此，随时监控磁盘的健康状况并及时解决任何问题非常重要。

# 一个坏蛋

单个经纪人的单个磁盘故障可能破坏整个集群的性能。这是因为生产者客户端将连接到为主题引导分区的所有经纪人，如果您遵循最佳实践，这些分区将均匀分布在整个集群上。如果一个经纪人开始表现不佳并减慢生产请求，这将导致生产者中的背压，减慢对所有经纪人的请求。

首先，确保您正在监视来自 IPMI 或硬件提供的接口的磁盘的硬件状态信息。此外，在操作系统中，您应该定期运行 SMART（自我监控、分析和报告技术）工具来监视和测试磁盘。这将警示您即将发生的故障。另外，重要的是要密切关注磁盘控制器，特别是如果它具有 RAID 功能，无论您是使用硬件 RAID 还是其他方式。许多控制器具有内置缓存，仅在控制器健康且电池备份单元（BBU）正常工作时才会使用。BBU 的故障可能导致缓存被禁用，降低磁盘性能。

网络是另一个部分故障会导致问题的领域。其中一些问题是硬件问题，例如糟糕的网络电缆或连接器。有些是配置问题，通常是连接的速度或双工设置的更改，无论是在服务器端还是在网络硬件上游。网络配置问题也可能是操作系统问题，例如网络缓冲区过小或太多的网络连接占用了整体内存占用量的太多。在这个领域问题的一个关键指标将是网络接口上检测到的错误数量。如果错误计数正在增加，那么可能存在未解决的问题。

如果没有硬件问题，要查找的另一个常见问题是系统上运行的另一个应用程序正在消耗资源并对 Kafka 经纪人施加压力。这可能是错误安装的东西，也可能是应该运行的进程，例如监控代理，但出现了问题。使用系统上的工具，如`top`，来识别是否有进程使用的 CPU 或内存超出预期。

如果其他选项已经耗尽，但您尚未找到主机上差异的来源，那么很可能是出现了配置差异，无论是经纪人还是系统本身。考虑到任何单个服务器上运行的应用程序数量以及每个应用程序的配置选项数量，要找到差异可能是一项艰巨的任务。这就是为什么您必须利用配置管理系统（如[Chef](https://www.chef.io)或[Puppet](https://puppet.com)）来维护 OS 和应用程序（包括 Kafka）之间的一致配置的原因。

## 经纪人指标

除了副本不足的分区之外，还有其他在整体经纪人级别存在的指标应该被监视。虽然您可能不倾向于为所有这些指标设置警报阈值，但它们提供了有关您的经纪人和集群的宝贵信息。它们应该出现在您创建的任何监控仪表板中。

### 活动控制器计数

*活动控制器计数*指标指示经纪人当前是否是集群的控制器。该指标将是 0 或 1，其中 1 表示经纪人当前是控制器。始终只有一个经纪人应该是控制器，并且集群中必须始终有一个经纪人是控制器。如果两个经纪人表示它们当前是控制器，这意味着您遇到了一个控制器线程应该退出但却被卡住的问题。这可能导致无法正确执行管理任务，例如分区移动。为了解决这个问题，您至少需要重新启动两个经纪人。然而，当集群中有额外的控制器时，通常会出现无法安全关闭经纪人的问题，您将需要强制停止经纪人。有关活动控制器计数的更多详细信息，请参见表 13-5。

表 13-5。活动控制器计数指标详细信息

| 指标名称 | 活动控制器计数 |
| --- | --- |
| JMX MBean | `kafka.controller:type=KafkaController,name=ActiveControllerCount` |
| 值范围 | 零或一 |

如果没有经纪人声称是集群中的控制器，集群将无法在状态更改时正确响应，包括主题或分区创建或经纪人故障。在这种情况下，您必须进一步调查为什么控制器线程无法正常工作。例如，来自 ZooKeeper 集群的网络分区可能导致这样的问题。一旦解决了潜在的问题，明智的做法是重新启动集群中的所有经纪人，以重置控制器线程的状态。

### 控制器队列大小

*控制器队列大小*指标指示控制器当前正在等待为经纪人处理多少请求。该指标将是 0 或更多，其值会随着来自经纪人的新请求和管理操作（例如创建分区、移动分区和处理领导者更改）的发生而经常波动。指标的波动是可以预期的，但如果该值持续增加，或者保持在一个高值并且不下降，这表明控制器可能被卡住。这可能导致无法正确执行管理任务的问题。为了解决这个问题，您需要将控制器移动到另一个经纪人，这需要关闭当前是控制器的经纪人。然而，当控制器被卡住时，通常会出现无法受控地关闭任何经纪人的问题。有关控制器队列大小的更多详细信息，请参见表 13-6。

表 13-6。控制器队列大小指标详细信息

| 指标名称 | 控制器队列大小 |
| --- | --- |
| JMX MBean | `kafka.controller:type=ControllerEventManager,name=EventQueueSize` |
| 值范围 | 整数，零或更多 |

### 请求处理程序空闲比率

Kafka 使用两个线程池来处理所有客户端请求：*网络线程*和*请求处理程序线程*（也称为*I/O 线程*）。网络线程负责在网络上读取和写入客户端的数据。这不需要大量处理，这意味着网络线程的耗尽不太值得关注。然而，请求处理程序线程负责为客户端请求本身提供服务，包括将消息读取或写入磁盘。因此，随着经纪人负载更重，这个线程池会受到重大影响。有关请求处理程序空闲比率的更多详细信息，请参见表 13-7。

表 13-7。请求处理程序空闲比率详细信息

| 指标名称 | 请求处理程序平均空闲百分比 |
| --- | --- |
| JMX MBean | `kafka.server:type=KafkaRequestHandlerPool,name=RequestHandlerAvgIdlePercent` |
| 值范围 | 浮点数，介于零和一之间 |

# 智能线程使用

虽然看起来您可能需要数百个请求处理程序线程，但实际上您不需要配置比经纪人中的 CPU 更多的线程。Apache Kafka 在使用请求处理程序的方式上非常聪明，确保将需要很长时间处理的请求转移到“炼狱”，例如在报价请求或需要多个生产请求确认时使用。

请求处理程序空闲比指标表示请求处理程序未使用的时间百分比。这个数字越低，代表经纪人的负载越重。经验告诉我们，空闲比低于 20%表示潜在问题，低于 10%通常表示活跃的性能问题。除了集群容量不足外，这个池中高线程利用率的原因有两个。第一个是池中的线程不够。通常情况下，您应该将请求处理程序线程的数量设置为系统中处理器的数量（包括超线程处理器）。

请求处理程序线程利用率较高的另一个常见原因是线程对每个请求都在做不必要的工作。在 Kafka 0.10 之前，请求处理程序线程负责解压每个传入的消息批次，验证消息并分配偏移量，然后在将消息批次写入磁盘之前重新压缩带有偏移量的消息批次。更糟糕的是，所有压缩方法都在同步锁后面。从 0.10 版本开始，有一种新的消息格式允许消息批次中的相对偏移量。这意味着更新的生产者将在发送消息批次之前设置相对偏移量，这样经纪人就可以跳过消息批次的重新压缩。您可以做的最大的性能改进之一是确保所有生产者和消费者客户端都支持 0.10 消息格式，并将经纪人上的消息格式版本也更改为 0.10。这将大大减少请求处理程序线程的利用率。

### 所有主题字节

以每秒字节为单位的*所有主题字节*速率对于衡量经纪人从生产客户端接收的消息流量非常有用。这是一个很好的指标，可以帮助您确定何时需要扩展集群或进行其他与增长相关的工作。它还有助于评估集群中的一个经纪人是否比其他经纪人接收更多的流量，这表明有必要重新平衡集群中的分区。有关更多详细信息，请参见表 13-8。

表 13-8。所有主题字节指标详情

| 指标名称 | 每秒字节 |
| --- | --- |
| JMX MBean | `kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec` |
| 值范围 | 速率为双精度，计数为整数 |

由于这是讨论的第一个速率指标，值得简要讨论一下这些类型指标提供的属性。所有速率指标都有七个属性，选择使用哪些取决于您想要的测量类型。这些属性提供了事件的离散计数，以及在不同时间段内事件数量的平均值。确保适当使用指标，否则您将得到有缺陷的经纪人视图。

前两个属性不是测量，但它们将帮助您理解您正在查看的指标：

`EventType`

这是所有属性的测量单位。在这种情况下，它是“字节”。

`RateUnit`

对于速率属性，这是速率的时间段。在这种情况下，它是“秒”。

这两个描述性属性告诉我们，无论它们平均的时间段是多长，速率都以每秒字节的值呈现。提供了四个不同粒度的速率属性：

`OneMinuteRate`

过去 1 分钟的平均值

`FiveMinuteRate`

过去 5 分钟的平均值

`FifteenMinuteRate`

过去 15 分钟的平均值

`MeanRate`

自经纪人启动以来的平均值

`OneMinuteRate`将快速波动，并提供更多“即时”视图的测量。这对于查看交通短暂激增很有用。`MeanRate`几乎不会变化，并提供总体趋势。虽然`MeanRate`有其用途，但它可能不是您想要收到警报的指标。`FiveMinuteRate`和`FifteenMinuteRate`在两者之间提供了一个折衷方案。

除了速率属性之外，还有一个`Count`属性。这是自经纪人启动以来该指标的不断增加的值。对于此指标，所有主题的字节输入，`Count`表示自进程启动以来发送到经纪人的总字节数。与支持计数器指标的度量系统一起使用，这可以让您绝对查看测量结果，而不是平均速率。

### 所有主题的字节输出

*所有主题的字节输出*速率，类似于字节输入速率，是另一个总体增长指标。在这种情况下，字节输出速率显示消费者读取消息的速率。出站字节速率可能与入站字节速率不同，这要归功于 Kafka 轻松处理多个消费者的能力。有许多 Kafka 部署，其中出站速率很容易是入站速率的六倍！这就是为什么单独观察和趋势出站字节速率很重要。有关更多详细信息，请参见表 13-9。

表 13-9。所有主题字节输出指标详细信息

|指标名称|每秒输出的字节|
| --- | --- |

JMX MBean | `kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec`

|值范围|速率为双倍，计数为整数|

# 包括副本获取器

出站字节速率*还*包括副本流量。这意味着如果所有主题的配置副本因子为 2，则当没有消费者客户端时，您将看到与字节输入速率相等的字节输出速率。如果有一个消费者客户端读取集群中的所有消息，则字节输出速率将是字节输入速率的两倍。如果您不知道计数的内容，这在查看指标时可能会让人困惑。

### 所有主题的消息输入

虽然先前描述的字节速率显示了字节的绝对值，但*消息输入*速率显示了每秒产生的个别消息的数量，而不考虑其大小。这作为生长指标很有用，作为生产者流量的不同度量。它也可以与字节输入速率一起使用，以确定平均消息大小。您还可能会看到经纪人的不平衡，就像字节输入速率一样，这将提醒您需要进行必要的维护工作。有关更多详细信息，请参见表 13-10。

表 13-10。所有主题消息输入指标详细信息

|指标名称|每秒消息输入|
| --- | --- |

JMX MBean | `kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec`

|值范围|速率为双倍，计数为整数|

# 为什么没有消息输出？

人们经常问为什么 Kafka 经纪人没有消息输出指标。原因是当消息被消耗时，经纪人只是将下一批消息发送给消费者，而不会扩展以找出其中有多少消息。因此，经纪人实际上不知道发送了多少消息。唯一可以提供的指标是每秒获取的次数，这是一个请求速率，而不是消息计数。

### 分区计数

*分区计数*对于经纪人通常不会有太大变化，因为它是分配给该经纪人的分区总数。这包括经纪人拥有的每个副本，无论它是否是该分区的领导者或追随者。在启用自动主题创建的集群中监视这一点通常更有趣，因为这可能会使主题的创建超出运行集群的人的控制范围。更多详情请参见表 13-11。

表 13-11. 分区计数指标详情

| 指标名称 | 分区计数 |
| --- | --- |
| JMX MBean | `kafka.server:type=ReplicaManager,name=PartitionCount` |
| 值范围 | 整数，零或更大 |

### 领导者计数

*领导者计数*指标显示了经纪人当前担任领导者的分区数量。与经纪人中的大多数其他测量一样，这个指标在集群中的经纪人之间应该是均匀的。定期检查领导者计数非常重要，可能会对其进行警报，因为即使副本的数量和大小在整个集群中完全平衡，它也会指示集群不平衡的情况。这是因为经纪人可以因为许多原因而放弃对分区的领导地位，比如 ZooKeeper 会话过期，并且一旦恢复（除非您启用了自动领导者重新平衡），它不会自动重新担任领导地位。在这些情况下，这个指标将显示较少的领导者，或者经常是零，这表明您需要运行首选副本选举来重新平衡集群中的领导地位。更多详情请参见表 13-12。

表 13-12. 领导者计数指标详情

指标名称 | 领导者计数

| --- | --- |
| JMX MBean | `kafka.server:type=ReplicaManager,name=LeaderCount` |
| 值范围 | 整数，零或更大 |

使用这个指标的一个有用的方法是将它与分区计数一起使用，以显示经纪人担任领导者的分区的百分比。在使用复制因子为 2 的平衡集群中，所有经纪人应该担任大约 50%的分区的领导者。如果使用的复制因子是 3，这个百分比会下降到 33%。 

### 脱机分区

除了未复制的分区计数之外，*脱机分区*计数是监控的关键指标（见表 13-13）。这个测量只由集群的控制器经纪人提供（所有其他经纪人将报告 0），显示了当前在集群中没有领导者的分区数量。没有领导者的分区可能有两个主要原因：

+   托管此分区副本的所有经纪人都已宕机

+   由于消息计数不匹配（关闭不干净的领导者选举），没有同步的副本可以领导

表 13-13. 脱机分区计数指标详情

| 指标名称 | 脱机分区计数 |
| --- | --- |
| JMX MBean | `kafka.controller:type=KafkaController,name=OfflinePartitionsCount` |
| 值范围 | 整数，零或更大 |

在生产 Kafka 集群中，脱机分区可能会影响生产者客户端，导致消息丢失或在应用程序中造成背压。这往往是一种“站点宕机”类型的问题，需要立即解决。

### 请求指标

Kafka 协议在第六章中描述了许多不同的请求。针对每个请求的性能提供了指标。截至 2.5.0 版本，以下请求提供了指标：

表 13-14. 请求指标名称

| `AddOffsetsToTxn` | `AddPartitionsToTxn` | `AlterConfigs` |
| `AlterPartitionReassignments` | `AlterReplicaLogDirs` | `ApiVersions` |
| `ControlledShutdown` | `CreateAcls` | `CreateDelegationToken` |
| `CreatePartitions` | `CreateTopics` | `DeleteAcls` |
| `DeleteGroups` | `DeleteRecords` | `DeleteTopics` |
| `DescribeAcls` | `DescribeConfigs` | `DescribeDelegationToken` |
| `DescribeGroups` | `DescribeLogDirs` | `ElectLeaders` |
| `EndTxn` | `ExpireDelegationToken` | `Fetch` |
| `FetchConsumer` | `FetchFollower` | `FindCoordinator` |
| `Heartbeat` | `IncrementalAlterConfigs` | `InitProducerId` |
| `JoinGroup` | `LeaderAndIsr` | `LeaveGroup` |
| `ListGroups` | `ListOffsets` | `ListPartitionReassignments` |
| `Metadata` | `OffsetCommit` | `OffsetDelete` |
| `OffsetFetch` | `OffsetsForLeaderEpoch` | `Produce` |
| `RenewDelegationToken` | `SaslAuthenticate` | `SaslHandshake` |
| `StopReplica` | `SyncGroup` | `TxnOffsetCommit` |
| `UpdateMetadata` | `WriteTxnMarkers` |  |

对于每个请求，提供了八个度量标准，提供了对请求处理的每个阶段的洞察。例如，对于`Fetch`请求，在 Table 13-15 中显示的度量标准是可用的。

表 13-15。获取请求度量

| 名称 | JMX MBean |
| --- | --- |
| 总时间 | `kafka.network:``type=RequestMetrics,name=TotalTimeMs,request=Fetch` |
| 请求队列时间 | `kafka.network:``type=RequestMetrics,name=RequestQueueTimeMs,request=Fetch` |
| 本地时间 | `kafka.network:``type=RequestMetrics,name=LocalTimeMs,request=Fetch` |
| 远程时间 | `kafka.network:``type=RequestMetrics,name=RemoteTimeMs,request=Fetch` |
| 限流时间 | `kafka.network:``type=RequestMetrics,name=ThrottleTimeMs,request=Fetch` |
| 响应队列时间 | `kafka.network:``type=RequestMetrics,name=ResponseQueueTimeMs,request=Fetch` |

响应发送时间 | `kafka.network:``type=RequestMetrics,name=ResponseSendTimeMs,request=Fetch` |
| 每秒请求数 | `kafka.network:``type=RequestMetrics,name=RequestsPerSec,request=Fetch` |

每秒请求数度量是一个速率度量，如前所述，显示了在时间单位内接收和处理的该类型请求的总数。这提供了对每个请求时间频率的视图，尽管应该注意到，许多请求，如`StopReplica`和`UpdateMetadata`，是不频繁的。

七个*时间*度量标准为每个请求提供了一组百分位数，以及一个离散的`Count`属性，类似于速率度量标准。这些度量标准都是自代理启动以来计算的，因此在查看长时间不变的度量标准时要记住这一点；您的代理运行时间越长，数字就会越稳定。它们代表请求处理的部分是：

总时间

代理商处理请求所花费的总时间，从接收到发送响应给请求者

请求队列时间

请求在接收后但在处理开始之前在队列中花费的时间

本地时间

分区领导者处理请求所花费的时间，包括将其发送到磁盘（但不一定刷新它）

远程时间

在请求处理完成之前等待追随者所花费的时间

限流时间

响应必须保持的时间，以减慢请求者以满足客户端配额设置

响应队列时间

响应请求在发送给请求者之前在队列中花费的时间

响应发送时间

实际发送响应所花费的时间

每个度量标准提供的属性是：

`计数`

自进程启动以来请求的绝对数量

`最小值`

所有请求的最小值

`最大值`

所有请求的最大值

`平均值`

所有请求的平均值

`标准差`

请求时间测量的标准差

`百分位数`

`50thPercentile`, `75thPercentile`, `95thPercentile`, `98thPercentile`, `99thPercentile`, `999thPercentile`

# 什么是百分位数？

百分位数是查看时间测量的常见方法。第 99 百分位数测量告诉我们，样本组（在本例中为请求时间）中 99%的所有值都小于指标的值。这意味着 1%的值大于指定的值。常见的模式是查看平均值和 99%或 99.9%的值。通过这种方式，您可以了解平均请求的性能以及异常值是什么。

在所有这些请求的指标和属性中，哪些是重要的要监视的？至少，您应该至少收集每种请求类型的总时间指标的平均值和较高百分位数（99%或 99.9%之一），以及每秒请求指标。这可以让您了解对 Kafka 经纪人的请求的整体性能。如果可以的话，您还应该为每种请求类型收集其他六个时间度量的测量，因为这将使您能够将任何性能问题缩小到请求处理的特定阶段。

对于设置警报阈值，时间度量可能会很困难。例如，`Fetch`请求的时间度量可能会因许多因素而大幅变化，包括客户端设置等待消息的时间、被获取的特定主题的繁忙程度以及客户端与经纪人之间的网络连接速度。然而，为至少`Produce`请求的总时间开发 99.9th 百分位数测量的基线值并对其进行警报可能非常有用。与未复制分区指标类似，`Produce`请求的 99.9th 百分位数急剧增加可能会提醒您存在各种性能问题。

## 主题和分区指标

除了经纪人上可用的许多指标来描述 Kafka 经纪人的运行情况外，还有特定于主题和分区的指标。在较大的集群中，这些指标可能很多，可能无法将它们全部收集到指标系统中作为正常操作的一部分。然而，它们对于调试客户端的特定问题非常有用。例如，主题指标可用于识别导致集群流量大幅增加的特定主题。还可能重要的是提供这些指标，以便 Kafka 的用户（生产者和消费者客户端）能够访问它们。无论您是否能够定期收集这些指标，您都应该知道哪些是有用的。

对于表 13-16 中的所有示例，我们将使用示例主题名称`*TOPICNAME*`，以及分区 0。在访问所描述的指标时，请确保替换适合您集群的主题名称和分区号。

### 每个主题的指标

对于所有每个主题的指标，测量非常类似于先前描述的经纪人指标。实际上，唯一的区别是提供的主题名称，以及指标将特定于命名的主题。鉴于可用的指标数量庞大，取决于集群中存在的主题数量，这些几乎肯定是您不希望为其设置监视和警报的指标。然而，它们对于提供给客户非常有用，以便他们可以评估和调试他们对 Kafka 的使用。

表 13-16。每个主题的指标

| 名称 | JMX MBean |
| --- | --- |
| 每秒输入字节数 | `kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec,topic=*TOPICNAME*` |
| 每秒输出字节数 | `kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec,topic=*TOPICNAME*` |
| 失败获取率 | `kafka.server:type=BrokerTopicMetrics,name=FailedFetchRequestsPerSec,topic=*TOPICNAME*` |
| 失败生成率 | `kafka.server:type=BrokerTopicMetrics,name=FailedProduceRequestsPerSec,topic=*TOPICNAME*` |
| 每秒消息数 | `kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec,topic=*TOPICNAME*` |
| 获取请求速率 | `kafka.server:type=BrokerTopicMetrics,name=TotalFetchRequestsPerSec,topic=*TOPICNAME*` |
| 生产请求速率 | `kafka.server:type=BrokerTopicMetrics,name=TotalProduceRequestsPerSec,topic=*TOPICNAME*` |

### 每个分区的指标

每个分区的指标在持续基础上往往不如每个主题的指标有用。此外，它们相当多，因为数百个主题很容易成千上万个分区。尽管如此，在某些有限的情况下它们可能是有用的。特别是，分区大小指标指示当前在分区上保留在磁盘上的数据量（以字节为单位）（表 13-17）。结合起来，这些将指示单个主题保留的数据量，这对于将 Kafka 的成本分配给个别客户端可能是有用的。同一主题的两个分区大小之间的差异可能表明存在问题，即在生成时消息未均匀分布在使用的键上。日志段计数指标显示分区上磁盘上的日志段文件数。这可能与分区大小一起用于资源跟踪。

表 13-17。每个分区的指标

| 名称 | JMX MBean |
| --- | --- |
| 分区大小 | `kafka.log:type=Log,name=Size,topic=*TOPICNAME*,partition=0` |
| 日志段计数 | `kafka.log:type=Log,name=NumLogSegments,topic=*TOPICNAME*,partition=0` |
| 日志结束偏移量 | `kafka.log:type=Log,name=LogEndOffset,topic=*TOPICNAME*,partition=0` |
| 日志起始偏移量 | `kafka.log:type=Log,name=LogStartOffset,topic=*TOPICNAME*,partition=0` |

日志结束偏移量和日志起始偏移量指标分别是该分区中消息的最高和最低偏移量。然而，应该注意的是，这两个数字之间的差异并不一定表示分区中的消息数量，因为日志压缩可能导致已从分区中删除具有相同键的新消息而“丢失”的偏移量。在某些环境中，跟踪分区的这些偏移量可能是有用的。其中一个用例是提供时间戳到偏移量的更精细的映射，从而允许使用者客户端轻松地将偏移量回滚到特定时间（尽管在 Kafka 0.10.1 中引入了基于时间的索引搜索，这就不那么重要了）。

# 未复制分区指标

提供了一个每个分区的指标，用于指示分区是否未复制。一般来说，在日常操作中，这并不是非常有用，因为有太多的指标需要收集和监视。更容易的方法是监视整个代理范围内的未复制分区计数，然后使用命令行工具（在第十二章中描述）来确定未复制的特定分区。

## JVM 监控

除了 Kafka 代理提供的指标之外，您还应该监视所有服务器以及 Java 虚拟机（JVM）本身的标准套件测量。这些将有助于警示您某种情况，例如增加的垃圾回收活动，这将降低代理的性能。它们还将提供有关为什么在代理中看到指标变化的见解。

### 垃圾回收

对于 JVM 来说，需要监控的关键事项是垃圾回收（GC）的状态。您必须监视此信息的特定 bean 将取决于您使用的特定 Java 运行时环境（JRE），以及正在使用的特定 GC 设置。对于在 Oracle Java 1.8 JRE 上运行 G1 垃圾回收的情况，应使用的 bean 显示在表 13-18 中。

表 13-18。G1 垃圾回收指标

| 名称 | JMX MBean |
| --- | --- |
| 完整 GC 周期 | `java.lang:type=GarbageCollector,name=G1 Old Generation` |
| 年轻 GC 周期 | `java.lang:type=GarbageCollector,name=G1 Young Generation` |

请注意，在 GC 的语义中，“Old”和“Full”是相同的。对于这些指标，要关注的两个属性是`CollectionCount`和`CollectionTime`。`CollectionCount`是自 JVM 启动以来该类型（完整或年轻）的 GC 周期数。`CollectionTime`是自 JVM 启动以来在该类型的 GC 周期中花费的时间（以毫秒为单位）。由于这些测量值是计数器，因此可以由度量系统用来告诉您每单位时间的 GC 周期数和 GC 花费的时间。它们还可以用来提供每个 GC 周期的平均时间，尽管在正常操作中这并不太有用。

每个指标还有一个`LastGcInfo`属性。这是一个复合值，由五个字段组成，为您提供有关由 bean 描述的 GC 类型的最后一个 GC 周期的信息。要查看的重要值是`duration`值，因为这告诉您上一个 GC 周期花费了多长时间（以毫秒为单位）。复合值中的其他值（`GcThreadCount`、`id`、`startTime`和`endTime`）是信息性的，并且没有太大用处。重要的是要注意，使用此属性，您将无法看到每个 GC 周期的时间，特别是年轻的 GC 周期可能经常发生。

### Java 操作系统监控

JVM 可以通过`java.lang:type=OperatingSystem` bean 向您提供有关操作系统的一些信息。但是，这些信息有限，不能代表您需要了解的有关运行代理的系统的一切。可以在此处收集的两个有用属性，这些属性在操作系统中难以收集，分别是`MaxFileDescriptorCount`和`OpenFileDescriptorCount`属性。`MaxFileDescriptorCount`将告诉您 JVM 允许打开的文件描述符（FDs）的最大数量。`OpenFileDescriptorCount`属性告诉您当前打开的 FDs 的数量。每个日志段和网络连接都会打开 FDs，并且它们可能会迅速累积。无法正确关闭网络连接可能会导致代理迅速耗尽允许的数量。

## 操作系统监控

JVM 无法为我们提供关于其运行系统的所有信息。因此，我们不仅必须从代理收集经纪人的指标，还必须从操作系统本身收集指标。大多数监控系统将提供代理，这些代理将收集比您可能感兴趣的更多的操作系统信息。必须监视的主要领域是 CPU 使用率、内存使用率、磁盘使用率、磁盘 I/O 和网络使用率。

对于 CPU 利用率，至少要查看系统负载平均值。这提供了一个单一的数字，指示处理器的相对利用率。此外，捕获按类型分解的 CPU 使用率的百分比也可能很有用。根据收集方法和特定的操作系统，您可能具有以下 CPU 百分比分解中的一些或全部（使用的缩写提供）：

`us`

在用户空间中所花费的时间

`sy`

在内核空间中所花费的时间

`ni`

低优先级进程所花费的时间

`id`

空闲时间

`wa`

在等待（在磁盘上）所花费的时间

`hi`

处理硬件中断所花费的时间

`si`

处理软件中断所花费的时间

`st`

等待虚拟处理器的时间

# 什么是系统负载？

虽然许多人知道系统负载是系统上 CPU 使用率的一个度量，但大多数人误解了它是如何被测量的。负载平均值是等待执行的进程数量的计数。Linux 还包括处于不可中断睡眠状态的线程，比如等待磁盘的线程。负载以三个数字呈现，这是在过去一分钟、5 分钟和 15 分钟内的平均计数。在单 CPU 系统中，值为 1 意味着系统负载 100%，始终有一个线程在等待执行。这意味着在多 CPU 系统上，表示 100%的负载平均数等于系统中的 CPU 数量。例如，如果系统中有 24 个处理器，100%将是 24 的负载平均值。

Kafka 代理在处理请求时使用了大量的处理。因此，在监控 Kafka 时，跟踪 CPU 利用率是很重要的。对于代理本身来说，内存跟踪不那么重要，因为 Kafka 通常会以相对较小的 JVM 堆大小运行。它将在堆之外使用少量内存进行压缩功能，但大部分系统内存将被留用于缓存。尽管如此，您应该跟踪内存利用率，以确保其他应用程序不会侵占代理。您还需要确保没有使用交换内存，通过监控总交换内存和空闲交换内存的数量。

在涉及 Kafka 时，磁盘是最重要的子系统。所有消息都持久保存在磁盘上，因此 Kafka 的性能严重依赖于磁盘的性能。监控磁盘空间和 inode（*inode*是 Unix 文件系统的文件和目录元数据对象）的使用情况很重要，因为您需要确保没有空间。这对于存储 Kafka 数据的分区尤为重要。还需要监控磁盘 I/O 统计信息，因为这将告诉我们磁盘是否被有效地使用。对于存储 Kafka 数据的磁盘，至少要监控每秒的读写次数，平均读写队列大小，平均等待时间和磁盘的利用率。

最后，监控代理的网络利用率。这只是入站和出站网络流量的数量，通常以每秒位数报告。请记住，发送到 Kafka 代理的每个位都将是等于主题的复制因子的出站位数，不包括消费者。根据消费者的数量，出站网络流量可能比入站流量容易大一个数量级。在设置警报阈值时要记住这一点。

## 日志

监控的讨论没有日志是不完整的。像许多应用程序一样，如果你允许的话，Kafka 代理将在几分钟内用日志消息填满磁盘。为了从日志中获得有用的信息，重要的是在正确的级别启用正确的记录器。通过简单地在“INFO”级别记录所有消息，您将捕获关于代理状态的大量重要信息。然而，为了提供一组更清洁的日志文件，有必要从中分离出一些记录器。

有两个记录器分别写入磁盘上的不同文件。第一个是 `kafka.controller`，仍然处于 `INFO` 级别。此记录器用于提供关于集群控制器的特定消息。任何时候，只有一个经纪人将成为控制器，因此只有一个经纪人将写入此记录器。信息包括主题创建和修改、经纪人状态更改以及集群活动，如首选副本选举和分区移动。另一个分开的记录器是 `kafka.server.ClientQuotaManager`，也处于 `INFO` 级别。此记录器用于显示与生产和消费配额活动相关的消息。虽然这是有用的信息，但最好不要将其放在主经纪人日志文件中。

记录日志以了解日志压缩线程的状态也是有帮助的。没有单个指标可以显示这些线程的健康状况，一个分区的压缩失败可能会完全停止日志压缩线程，并且悄无声息。在 `DEBUG` 级别启用 `kafka.log.LogCleaner`、`kafka.log.Cleaner` 和 `kafka.log.LogCleanerManager` 记录器将输出有关这些线程状态的信息。这将包括有关正在压缩的每个分区的信息，包括每个分区中的消息大小和数量。在正常操作下，这不是很多的日志记录，这意味着可以默认启用它而不会使您不堪重负。

还有一些日志记录可能在调试 Kafka 问题时有用。其中一个记录器是 `kafka.request.logger`，在 `DEBUG` 或 `TRACE` 级别打开。这将记录发送到经纪人的每个请求的信息。在 `DEBUG` 级别，日志包括连接端点、请求时间和摘要信息。在 `TRACE` 级别，它还将包括主题和分区信息——几乎所有请求信息，除了消息有效载荷本身。在任何级别，此记录器会生成大量数据，除非必要进行调试，否则不建议启用它。

# 客户端监控

所有应用程序都需要监控。实例化 Kafka 客户端（生产者或消费者）的应用程序具有应该捕获的特定于客户端的指标。本节涵盖了官方的 Java 客户端库，尽管其他实现应该有它们自己的可用测量。

## 生产者指标

Kafka 生产者客户端通过将可用的指标作为少量 JMX MBean 的属性而大大压缩了这些指标。相比之下，之前的生产者客户端（不再受支持）使用了更多的 MBean，但在许多指标中有更多的细节（提供了更多的百分位数测量和不同的移动平均值）。因此，提供的指标总数涵盖了更广泛的范围，但更难以跟踪异常值。

所有生产者指标在 bean 名称中都有生产者客户端的客户端 ID。在提供的示例中，这已被替换为 `*CLIENTID*`。其中 bean 名称包含经纪人 ID，这已被替换为 `*BROKERID*`。主题名称已被替换为 `*TOPICNAME*`。有关示例，请参见表 13-19。

表 13-19. Kafka 生产者指标 MBeans

| 名称 | JMX MBean |
| --- | --- |
| 总体生产者 | `kafka.producer:type=producer-metrics,client-id=*CLIENTID*` |
| 按经纪人 | `kafka.producer:type=producer-node-metrics,client-id=*CLIENTID*,node-id=node-*BROKERID*` |
| 按主题 | `kafka.producer:type=producer-topic-metrics,client-id=*CLIENTID*,topic=*TOPICNAME*` |

表 13-19 中的每个指标 bean 都有多个属性可用于描述生产者的状态。下一节将描述最有用的特定属性。在继续之前，请确保您了解生产者的工作语义，如第三章中所述。

### 总体生产者指标

总体生产者指标 bean 提供了描述消息批次大小到内存缓冲区利用率的属性。虽然所有这些测量都在调试中有其用处，但通常只有少数需要定期使用，其中只有少数需要监视并设置警报。请注意，虽然我们将讨论几个平均值的指标（以“-avg”结尾），但每个指标也有最大值（以“-max”结尾），其有限的用处。

`record-error-rate`是一个绝对需要设置警报的属性。这个指标应该始终为零，如果大于零，表示生产者正在丢弃它试图发送到 Kafka 代理的消息。生产者有一个配置的重试次数和重试之间的间隔，一旦耗尽，消息（这里称为*记录*）将被丢弃。还有一个 `record-retry-rate`属性可以进行跟踪，但它不像错误率那么关键，因为重试是正常的。

另一个要警报的指标是 `request-latency-avg`。这是发送到代理的生成请求所花费的平均时间。您应该能够建立正常操作中此数字应该是多少的基线值，并设置高于该值的警报阈值。请求延迟的增加意味着生成请求变慢。这可能是由于网络问题，也可能表明代理存在问题。无论哪种情况，这都是一个性能问题，会在生成应用程序中引起背压和其他问题。

除了这些关键指标之外，了解生产者发送了多少消息流量总是很有用的。三个属性将提供这方面的三种不同视图。 `outgoing-byte-rate`描述了每秒以字节为单位的绝对大小的消息。 `record-send-rate`描述了每秒产生的消息数量。最后，`request-rate`提供了每秒发送到代理的生成请求的数量。单个请求包含一个或多个批次。单个批次包含一个或多个消息。当然，每个消息由一些字节组成。这些指标都对应用程序仪表板上有用。

还有一些描述记录、请求和批处理大小的指标。 `request-size-avg`指标提供了发送到代理的生产请求的平均大小（以字节为单位）。 `batch-size-avg`提供了单个消息批次的平均大小（根据定义，批次由单个主题分区的消息组成），以字节为单位。 `record-size-avg`显示单个记录的平均大小（以字节为单位）。对于单个主题的生产者，这提供了有关生成的消息的有用信息。对于多主题的生产者，例如 MirrorMaker，这种信息就不那么有用了。除了这三个指标之外，还有一个 `records-per-request-avg`指标，描述了单个生成请求中的消息平均数量。

建议的最后一个总体生产者指标属性是 `record-queue-time-avg`。这个度量是在应用程序发送消息后，消息在生产者中等待的平均时间（以毫秒为单位），直到实际产生到 Kafka。应用程序调用生产者客户端发送消息（通过调用 `send` 方法）后，生产者会等待直到发生以下两种情况之一：

+   它有足够的消息来填充基于 `batch.size` 配置的批处理。

+   根据`linger.ms`配置，自上次发送批处理以来已经过了足够长的时间。

这两者中的任何一个都将导致生产者客户端关闭它正在构建的当前批次并将其发送到代理。最容易理解的方法是，对于繁忙的主题，将应用第一个条件，而对于慢速主题，将应用第二个条件。`record-queue-time-avg`测量将指示消息需要多长时间才能被生成，因此在调整这两个配置以满足应用程序的延迟要求时是有帮助的。

### 每个代理和每个主题的度量

除了整体生产者度量之外，还有度量 bean 为与每个 Kafka 代理的连接以及正在生成的每个主题提供了一组有限的属性。在某些情况下，这些测量对于调试问题是有用的，但这些不是您希望经常审查的度量。这些 bean 上的所有属性与先前描述的整体生产者 bean 的属性相同，并且具有与先前描述相同的含义（除了它们适用于特定代理或特定主题）。

每个代理生产者度量提供的最有用的度量是`request-latency-avg`测量。这是因为这个度量大部分时间会保持稳定（假设消息的批处理稳定），并且仍然可以显示与特定代理的连接问题。其他属性，例如`outgoing-byte-rate`和`request-latency-avg`，往往会根据每个代理领导的分区而变化。这意味着这些测量在任何时间点上“应该”是什么，可以很快地改变，具体取决于 Kafka 集群的状态。

主题度量比每个代理度量更有趣，但只对使用多个主题的生产者有用。如果生产者不使用很多主题，这些度量也只能在常规情况下使用。例如，MirrorMaker 可能会生成数百个或数千个主题。很难审查所有这些度量，并且几乎不可能对其设置合理的警报阈值。与每个代理度量一样，当调查特定问题时，每个主题的测量最好用于。例如，例如，`record-send-rate`和`record-error-rate`属性可以用于将丢弃的消息隔离到特定主题（或验证是否跨所有主题）。此外，还有一个`byte-rate`度量，它提供了主题每秒字节的整体消息速率。

## 消费者度量

与生产者客户端类似，Kafka 中的消费者将许多指标合并为几个度量 bean 上的属性。这些度量也消除了延迟的百分位数和速率的移动平均值，这些在已弃用的 Scala 消费者中呈现，类似于生产者客户端。在消费者中，由于处理消息消费的逻辑比仅仅将消息发送到 Kafka 代理更复杂，因此还有一些更多的度量要处理。有关更多信息，请参见表 13-20。

13-20 表。Kafka 消费者度量 MBeans

| 名称 | JMX MBean |
| --- | --- |
| 整体消费者 | `kafka.consumer:type=consumer-metrics,client-id=*CLIENTID*` |
| 获取管理器 | `kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*CLIENTID*` |
| 每个主题 | `kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*CLIENT​ID*,topic=*TOPICNAME*` |
| 每个代理 | `kafka.consumer:type=consumer-node-metrics,client-id=*CLIENTID*,node-id=node-*BROKERID*` |
| 协调员 | `kafka.consumer:type=consumer-coordinator-metrics,client-id=*CLIENTID*` |

### 获取管理器度量

在消费者客户端中，总体消费者度量 bean 对我们来说不太有用，因为我们感兴趣的度量位于*fetch manager* bean 中。总体消费者 bean 具有有关较低级别网络操作的度量，但 fetch manager bean 具有有关字节、请求和记录速率的度量。与生产者客户端不同，消费者提供的度量是有用的，但不适合设置警报。

对于 fetch manager，您可能希望设置监视和警报的一个属性是`fetch-latency-avg`。与生产者客户端中的等效`request-latency-avg`一样，这个度量告诉我们向经纪人发出的获取请求需要多长时间。对此度量进行警报的问题在于延迟受消费者配置`fetch.min.bytes`和`fetch.max.wait.ms`的控制。一个慢的主题将具有不稳定的延迟，因为有时经纪人会快速响应（当有消息可用时），有时它将不会在`fetch.max.wait.ms`内响应（当没有消息可用时）。在消费具有更规律和丰富的消息流量的主题时，这个度量可能更有用。

# 等等！没有滞后？

对所有消费者的最佳建议是，您必须监视消费者滞后。那么为什么我们不建议监视 fetch manager bean 上的`records-lag-max`属性？这个度量显示了当前滞后（消费者偏移和经纪人日志结束偏移之间的差异），对于最滞后的分区。

这个问题有两个方面：它只显示一个分区的滞后，并且依赖于消费者的正常运行。如果没有其他选择，可以使用此属性进行滞后并设置警报。但最佳做法是使用外部滞后监视，如“滞后监视”中所述。

要了解您的消费者客户端处理了多少消息流量，您应该捕获`bytes-consumed-rate`或`records-consumed-rate`，或者最好两者兼而有之。这些度量描述了此客户端实例每秒消耗的消息流量，分别以字节和每秒消息计算。一些用户对这些度量设置了最低阈值以进行警报，以便在消费者未能完成足够工作时收到通知。但是，在执行此操作时，您应该小心。Kafka 旨在解耦消费者和生产者客户端，使它们能够独立运行。消费者能够消费消息的速率通常取决于生产者是否正常工作，因此在消费者上监视这些度量会对生产者的状态进行假设。这可能会导致对消费者客户端的错误警报。

了解字节、消息和请求之间的关系也很重要，fetch manager 提供了帮助的度量。`fetch-rate`度量告诉我们消费者每秒执行的获取请求数量。`fetch-size-avg`度量给出了这些获取请求的平均大小（以字节为单位）。最后，`records-per-request-avg`度量给出了每个获取请求中的平均消息数。请注意，消费者没有提供与生产者`record-size-avg`度量相当的度量，以告诉我们消息的平均大小。如果这很重要，您需要从其他可用的度量中推断出来，或者在从消费者客户端库接收消息后在应用程序中捕获它。

### 每个经纪人和每个主题的度量

与生产者客户端一样，消费者客户端为每个经纪人连接和每个被消费的主题提供的指标对于调试消费问题非常有用，但可能不会是您每天审查的测量值。与获取管理器一样，由每个经纪人指标 bean 提供的`request-latency-avg`属性具有有限的用处，具体取决于您正在消费的主题中的消息流量。`incoming-byte-rate`和`request-rate`指标将获取管理器提供的消耗消息指标分解为每个经纪人每秒字节和每秒请求的测量值。这些可以用于帮助隔离消费者与特定经纪人连接存在的问题。

消费者客户端提供的按主题划分的指标在消费多个主题时非常有用。否则，这些指标将与获取管理器的指标相同，并且收集起来是多余的。另一方面，如果客户端正在消费多个主题（例如 Kafka MirrorMaker），这些指标将很难进行审查。如果您计划收集它们，那么收集最重要的指标是`bytes-consumed-rate`、`records-consumed-rate`和`fetch-size-avg`。`bytes-consumed-rate`显示每秒针对特定主题消耗的绝对字节大小，而`records-consumed-rate`显示相同信息，但是以消息数量为单位。`fetch-size-avg`提供了每个主题的平均获取请求大小（以字节为单位）。

### 消费者协调器指标

如第四章所述，消费者客户端通常作为消费者组的一部分共同工作。该组具有协调活动，例如组成员加入，以及向经纪人发送心跳消息以维护组成员资格。消费者协调器是负责处理这项工作的消费者客户端的一部分，并且它维护自己的一组指标。与所有指标一样，提供了许多数字，但只有少数几个关键数字需要定期监视。

由于协调员活动而导致消费者可能遇到的最大问题是在消费暂停时，消费者组进行同步。这是消费者组实例协商由哪些个体客户端实例消费哪些分区的过程。根据正在消费的分区数量，这可能需要一些时间。协调员提供了`sync-time-avg`属性，它是同步活动所需的平均时间（以毫秒为单位）。捕获`sync-rate`属性也很有用，它是每秒发生的组同步次数。对于稳定的消费者组，这个数字大部分时间应该是零。

消费者需要提交偏移量以检查其在消费消息时的进度，可以自动定期提交，也可以通过应用程序代码中触发的手动检查点来提交。这些提交本质上只是生产请求（尽管它们有自己的请求类型），因为偏移量提交是发送到特殊主题的消息。消费者协调器提供了`commit-latency-avg`属性，用于测量偏移量提交所需的平均时间。您应该像监视生产者的请求延迟一样监视这个值。应该能够建立此指标的基线预期值，并设置合理的阈值，以便在该值之上发出警报。

最后一个有用的协调器指标是`assigned-partitions`。这是消费者客户端（作为消费者组中的单个实例）被分配消费的分区数量。这很有帮助，因为与消费者组中其他消费者客户端的此指标相比，可以看到整个消费者组的负载平衡。我们可以使用这个来识别可能由消费者协调器用于将分区分配给组成员的算法中的问题引起的不平衡。

## 配额

Apache Kafka 具有限制客户端请求的能力，以防止一个客户端压倒整个集群。这对生产者和消费者客户端都是可配置的，并且以每秒允许从单个客户端 ID 到单个代理的流量量来表示。有一个代理配置，为所有客户端设置默认值，以及可以动态设置的每个客户端覆盖。当代理计算出客户端已超出其配额时，它通过将响应保持在客户端足够长的时间来减慢客户端的速度，以使客户端保持在配额以下。

Kafka 代理在响应中不使用错误代码来指示客户端被限制。这意味着应用程序在没有监视提供的指标来显示客户端被限制的时间量时，不明显地发生了限制。必须监视的指标显示在表 13-21 中。

表 13-21\. 要监视的指标

| 客户端 | Bean 名称 |
| --- | --- |
| 消费者 | bean `kafka.consumer:type=consumer-fetch-manager-metrics,client-id=CLIENTID`, 属性 `fetch-throttle-time-avg` |
| 生产者 | bean `kafka.producer:type=producer-metrics,client-id=CLIENTID`, 属性 `produce-throttle-time-avg` |

Kafka 代理默认情况下未启用配额，但无论您当前是否使用配额，监视这些指标都是安全的。监视它们是一个好习惯，因为它们可能在将来的某个时候被启用，而且从监视它们开始要比以后添加指标更容易。

# 滞后监控

对于 Kafka 消费者，最重要的监控是消费者滞后。以消息数量衡量，这是特定分区中最后一条消息产生与消费者处理的最后一条消息之间的差异。虽然这个主题通常会在前一节关于消费者客户端监控中涵盖，但这是一个外部监控远远超过客户端本身提供的情况之一。如前所述，消费者客户端中有一个滞后指标，但使用它是有问题的。它只代表一个分区，即滞后最严重的分区，因此无法准确显示消费者滞后的程度。此外，它需要消费者的正常运行，因为该指标是由消费者在每次获取请求时计算的。如果消费者出现故障或离线，该指标要么不准确，要么不可用。

消费者滞后监控的首选方法是有一个外部进程，可以监视代理上分区的状态，跟踪最近生成的消息的偏移量，以及消费者的状态，跟踪消费者组为分区提交的最后偏移量。这提供了一个客观的视图，可以更新，而不受消费者本身状态的影响。必须对消费者组消费的每个分区执行此检查。对于像 MirrorMaker 这样的大型消费者，这可能意味着数万个分区。

第十二章提供了使用命令行实用程序获取消费者组信息，包括提交的偏移量和滞后的信息。然而，像这样监控滞后也存在自己的问题。首先，您必须了解对于每个分区，什么是合理的滞后量。每小时接收 100 条消息的主题将需要与每秒接收 100,000 条消息的主题不同的阈值。然后，您必须能够将所有滞后指标消耗到监控系统中，并对其设置警报。如果您有一个消费者组在 1,500 个主题上消费 100,000 个分区，您可能会发现这是一项艰巨的任务。

监控消费者组减少这种复杂性的一种方法是使用[Burrow](https://oreil.ly/supY1)。这是一个开源应用程序，最初由 LinkedIn 开发，它通过收集集群中所有消费者组的滞后信息并计算每个组的单个状态来提供消费者状态监控，指出消费者组是否正常工作、落后或完全停滞或停止。它可以在不需要阈值的情况下监控消费者组在处理消息时的进度，尽管您也可以获得消息滞后的绝对数量。关于 Burrow 工作原理和方法背后的深入讨论可以在[LinkedIn 工程博客](http://bit.ly/2sanKZb)上找到。部署 Burrow 可以轻松为集群中的所有消费者提供监控，以及在多个集群中，并且可以轻松集成到您现有的监控和警报系统中。

如果没有其他选择，消费者客户端的`records-lag-max`指标至少可以提供部分消费者状态的视图。然而，强烈建议您像 Burrow 这样利用外部监控系统。

# 端到端监控

推荐的另一种外部监控类型是端到端监控系统，它提供了客户端对 Kafka 集群健康状况的视角。消费者和生产者客户端具有可以指示 Kafka 集群可能存在问题的指标，但这可能是一个猜测游戏，增加的延迟是由于客户端、网络还是 Kafka 本身的问题。此外，这意味着如果您负责运行 Kafka 集群，而不是客户端，那么现在您还必须监控所有客户端。您真正需要知道的是：

+   我可以向 Kafka 集群生产消息吗？

+   我可以从 Kafka 集群中消费消息吗？

在理想的情况下，您将能够为每个主题单独监控这一点。然而，在大多数情况下，为了做到这一点，向每个主题注入合成流量是不合理的。然而，至少我们可以为集群中的每个代理提供这些答案，这就是[Xinfra Monitor（以前称为 Kafka Monitor）](https://oreil.ly/QqXD9)所做的。这个工具是由 LinkedIn 的 Kafka 团队开源的，它不断地从跨越集群中所有代理的主题中生成和消费数据。它测量了每个代理上生产和消费请求的可用性，以及总的生产到消费延迟。这种类型的监控对于能够外部验证 Kafka 集群是否按预期运行是非常宝贵的，因为就像消费者滞后监控一样，Kafka 代理无法报告客户端是否能够正确使用集群。

# 总结

监控是正确运行 Apache Kafka 的关键方面，这解释了为什么许多团队花费大量时间完善运维的这一部分。许多组织使用 Kafka 来处理 PB 级别的数据流。确保数据不会停止，消息不会丢失，这是一个关键的业务需求。我们还有责任通过提供用户需要的指标来协助用户监控他们的应用程序如何使用 Kafka。

在本章中，我们介绍了如何监控 Java 应用程序的基础知识，特别是 Kafka 应用程序。我们回顾了 Kafka broker 中可用的众多指标的子集，还涉及了 Java 和操作系统的监控，以及日志记录。然后，我们详细介绍了 Kafka 客户端库中可用的监控，包括配额监控。最后，我们讨论了使用外部监控系统进行消费者滞后监控和端到端集群可用性。虽然这当然不是所有可用指标的详尽列表，但本章回顾了需要密切关注的最关键的指标。
