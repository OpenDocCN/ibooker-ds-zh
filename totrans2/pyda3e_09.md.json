["```py\nIn [10]: !cat examples/ex1.csv\na,b,c,d,message\n1,2,3,4,hello\n5,6,7,8,world\n9,10,11,12,foo\n```", "```py\nIn [11]: df = pd.read_csv(\"examples/ex1.csv\")\n\nIn [12]: df\nOut[12]: \n a   b   c   d message\n0  1   2   3   4   hello\n1  5   6   7   8   world\n2  9  10  11  12     foo\n```", "```py\nIn [13]: !cat examples/ex2.csv\n1,2,3,4,hello\n5,6,7,8,world\n9,10,11,12,foo\n```", "```py\nIn [14]: pd.read_csv(\"examples/ex2.csv\", header=None)\nOut[14]: \n 0   1   2   3      4\n0  1   2   3   4  hello\n1  5   6   7   8  world\n2  9  10  11  12    foo\n\nIn [15]: pd.read_csv(\"examples/ex2.csv\", names=[\"a\", \"b\", \"c\", \"d\", \"message\"])\nOut[15]: \n a   b   c   d message\n0  1   2   3   4   hello\n1  5   6   7   8   world\n2  9  10  11  12     foo\n```", "```py\nIn [16]: names = [\"a\", \"b\", \"c\", \"d\", \"message\"]\n\nIn [17]: pd.read_csv(\"examples/ex2.csv\", names=names, index_col=\"message\")\nOut[17]: \n a   b   c   d\nmessage \nhello    1   2   3   4\nworld    5   6   7   8\nfoo      9  10  11  12\n```", "```py\nIn [18]: !cat examples/csv_mindex.csv\nkey1,key2,value1,value2\none,a,1,2\none,b,3,4\none,c,5,6\none,d,7,8\ntwo,a,9,10\ntwo,b,11,12\ntwo,c,13,14\ntwo,d,15,16\n\nIn [19]: parsed = pd.read_csv(\"examples/csv_mindex.csv\",\n ....:                      index_col=[\"key1\", \"key2\"])\n\nIn [20]: parsed\nOut[20]: \n value1  value2\nkey1 key2 \none  a          1       2\n b          3       4\n c          5       6\n d          7       8\ntwo  a          9      10\n b         11      12\n c         13      14\n d         15      16\n```", "```py\nIn [21]: !cat examples/ex3.txt\nA         B         C\naaa -0.264438 -1.026059 -0.619500\nbbb  0.927272  0.302904 -0.032399\nccc -0.264273 -0.386314 -0.217601\nddd -0.871858 -0.348382  1.100491\n```", "```py\nIn [22]: result = pd.read_csv(\"examples/ex3.txt\", sep=\"\\s+\")\n\nIn [23]: result\nOut[23]: \n A         B         C\naaa -0.264438 -1.026059 -0.619500\nbbb  0.927272  0.302904 -0.032399\nccc -0.264273 -0.386314 -0.217601\nddd -0.871858 -0.348382  1.100491\n```", "```py\nIn [24]: !cat examples/ex4.csv\n# hey!\na,b,c,d,message\n# just wanted to make things more difficult for you\n# who reads CSV files with computers, anyway?\n1,2,3,4,hello\n5,6,7,8,world\n9,10,11,12,foo\n\nIn [25]: pd.read_csv(\"examples/ex4.csv\", skiprows=[0, 2, 3])\nOut[25]: \n a   b   c   d message\n0  1   2   3   4   hello\n1  5   6   7   8   world\n2  9  10  11  12     foo\n```", "```py\nIn [26]: !cat examples/ex5.csv\nsomething,a,b,c,d,message\none,1,2,3,4,NA\ntwo,5,6,,8,world\nthree,9,10,11,12,foo\nIn [27]: result = pd.read_csv(\"examples/ex5.csv\")\n\nIn [28]: result\nOut[28]: \n something  a   b     c   d message\n0       one  1   2   3.0   4     NaN\n1       two  5   6   NaN   8   world\n2     three  9  10  11.0  12     foo\n```", "```py\nIn [29]: pd.isna(result)\nOut[29]: \n something      a      b      c      d  message\n0      False  False  False  False  False     True\n1      False  False  False   True  False    False\n2      False  False  False  False  False    False\n```", "```py\nIn [30]: result = pd.read_csv(\"examples/ex5.csv\", na_values=[\"NULL\"])\n\nIn [31]: result\nOut[31]: \n something  a   b     c   d message\n0       one  1   2   3.0   4     NaN\n1       two  5   6   NaN   8   world\n2     three  9  10  11.0  12     foo\n```", "```py\nIn [32]: result2 = pd.read_csv(\"examples/ex5.csv\", keep_default_na=False)\n\nIn [33]: result2\nOut[33]: \n something  a   b   c   d message\n0       one  1   2   3   4      NA\n1       two  5   6       8   world\n2     three  9  10  11  12     foo\n\nIn [34]: result2.isna()\nOut[34]: \n something      a      b      c      d  message\n0      False  False  False  False  False    False\n1      False  False  False  False  False    False\n2      False  False  False  False  False    False\n\nIn [35]: result3 = pd.read_csv(\"examples/ex5.csv\", keep_default_na=False,\n ....:                       na_values=[\"NA\"])\n\nIn [36]: result3\nOut[36]: \n something  a   b   c   d message\n0       one  1   2   3   4     NaN\n1       two  5   6       8   world\n2     three  9  10  11  12     foo\n\nIn [37]: result3.isna()\nOut[37]: \n something      a      b      c      d  message\n0      False  False  False  False  False     True\n1      False  False  False  False  False    False\n2      False  False  False  False  False    False\n```", "```py\nIn [38]: sentinels = {\"message\": [\"foo\", \"NA\"], \"something\": [\"two\"]}\n\nIn [39]: pd.read_csv(\"examples/ex5.csv\", na_values=sentinels,\n ....:             keep_default_na=False)\nOut[39]: \n something  a   b   c   d message\n0       one  1   2   3   4     NaN\n1       NaN  5   6       8   world\n2     three  9  10  11  12     NaN\n```", "```py\nIn [40]: pd.options.display.max_rows = 10\n```", "```py\nIn [41]: result = pd.read_csv(\"examples/ex6.csv\")\n\nIn [42]: result\nOut[42]: \n one       two     three      four key\n0     0.467976 -0.038649 -0.295344 -1.824726   L\n1    -0.358893  1.404453  0.704965 -0.200638   B\n2    -0.501840  0.659254 -0.421691 -0.057688   G\n3     0.204886  1.074134  1.388361 -0.982404   R\n4     0.354628 -0.133116  0.283763 -0.837063   Q\n...        ...       ...       ...       ...  ..\n9995  2.311896 -0.417070 -1.409599 -0.515821   L\n9996 -0.479893 -0.650419  0.745152 -0.646038   E\n9997  0.523331  0.787112  0.486066  1.093156   K\n9998 -0.362559  0.598894 -1.843201  0.887292   G\n9999 -0.096376 -1.012999 -0.657431 -0.573315   0\n[10000 rows x 5 columns]\n```", "```py\nIn [43]: pd.read_csv(\"examples/ex6.csv\", nrows=5)\nOut[43]: \n one       two     three      four key\n0  0.467976 -0.038649 -0.295344 -1.824726   L\n1 -0.358893  1.404453  0.704965 -0.200638   B\n2 -0.501840  0.659254 -0.421691 -0.057688   G\n3  0.204886  1.074134  1.388361 -0.982404   R\n4  0.354628 -0.133116  0.283763 -0.837063   Q\n```", "```py\nIn [44]: chunker = pd.read_csv(\"examples/ex6.csv\", chunksize=1000)\n\nIn [45]: type(chunker)\nOut[45]: pandas.io.parsers.readers.TextFileReader\n```", "```py\nchunker = pd.read_csv(\"examples/ex6.csv\", chunksize=1000)\n\ntot = pd.Series([], dtype='int64')\nfor piece in chunker:\n tot = tot.add(piece[\"key\"].value_counts(), fill_value=0)\n\ntot = tot.sort_values(ascending=False)\n```", "```py\nIn [47]: tot[:10]\nOut[47]: \nkey\nE    368.0\nX    364.0\nL    346.0\nO    343.0\nQ    340.0\nM    338.0\nJ    337.0\nF    335.0\nK    334.0\nH    330.0\ndtype: float64\n```", "```py\nIn [48]: data = pd.read_csv(\"examples/ex5.csv\")\n\nIn [49]: data\nOut[49]: \n something  a   b     c   d message\n0       one  1   2   3.0   4     NaN\n1       two  5   6   NaN   8   world\n2     three  9  10  11.0  12     foo\n```", "```py\nIn [50]: data.to_csv(\"examples/out.csv\")\n\nIn [51]: !cat examples/out.csv\n,something,a,b,c,d,message\n0,one,1,2,3.0,4,\n1,two,5,6,,8,world\n2,three,9,10,11.0,12,foo\n```", "```py\nIn [52]: import sys\n\nIn [53]: data.to_csv(sys.stdout, sep=\"|\")\n|something|a|b|c|d|message\n0|one|1|2|3.0|4|\n1|two|5|6||8|world\n2|three|9|10|11.0|12|foo\n```", "```py\nIn [54]: data.to_csv(sys.stdout, na_rep=\"NULL\")\n,something,a,b,c,d,message\n0,one,1,2,3.0,4,NULL\n1,two,5,6,NULL,8,world\n2,three,9,10,11.0,12,foo\n```", "```py\nIn [55]: data.to_csv(sys.stdout, index=False, header=False)\none,1,2,3.0,4,\ntwo,5,6,,8,world\nthree,9,10,11.0,12,foo\n```", "```py\nIn [56]: data.to_csv(sys.stdout, index=False, columns=[\"a\", \"b\", \"c\"])\na,b,c\n1,2,3.0\n5,6,\n9,10,11.0\n```", "```py\nIn [57]: !cat examples/ex7.csv\n\"a\",\"b\",\"c\"\n\"1\",\"2\",\"3\"\n\"1\",\"2\",\"3\"\n```", "```py\nIn [58]: import csv\n\nIn [59]: f = open(\"examples/ex7.csv\")\n\nIn [60]: reader = csv.reader(f)\n```", "```py\nIn [61]: for line in reader:\n ....:     print(line)\n['a', 'b', 'c']\n['1', '2', '3']\n['1', '2', '3']\n\nIn [62]: f.close()\n```", "```py\nIn [63]: with open(\"examples/ex7.csv\") as f:\n ....:     lines = list(csv.reader(f))\n```", "```py\nIn [64]: header, values = lines[0], lines[1:]\n```", "```py\nIn [65]: data_dict = {h: v for h, v in zip(header, zip(*values))}\n\nIn [66]: data_dict\nOut[66]: {'a': ('1', '1'), 'b': ('2', '2'), 'c': ('3', '3')}\n```", "```py\nclass my_dialect(csv.Dialect):\n lineterminator = \"\\n\"\n delimiter = \";\"\n quotechar = '\"'\n quoting = csv.QUOTE_MINIMAL\n```", "```py\nreader = csv.reader(f, dialect=my_dialect)\n```", "```py\nreader = csv.reader(f, delimiter=\"|\")\n```", "```py\nwith open(\"mydata.csv\", \"w\") as f:\n writer = csv.writer(f, dialect=my_dialect)\n writer.writerow((\"one\", \"two\", \"three\"))\n writer.writerow((\"1\", \"2\", \"3\"))\n writer.writerow((\"4\", \"5\", \"6\"))\n writer.writerow((\"7\", \"8\", \"9\"))\n```", "```py\nobj = \"\"\"\n{\"name\": \"Wes\",\n \"cities_lived\": [\"Akron\", \"Nashville\", \"New York\", \"San Francisco\"],\n \"pet\": null,\n \"siblings\": [{\"name\": \"Scott\", \"age\": 34, \"hobbies\": [\"guitars\", \"soccer\"]},\n {\"name\": \"Katie\", \"age\": 42, \"hobbies\": [\"diving\", \"art\"]}]\n}\n\"\"\"\n```", "```py\nIn [68]: import json\n\nIn [69]: result = json.loads(obj)\n\nIn [70]: result\nOut[70]: \n{'name': 'Wes',\n 'cities_lived': ['Akron', 'Nashville', 'New York', 'San Francisco'],\n 'pet': None,\n 'siblings': [{'name': 'Scott',\n 'age': 34,\n 'hobbies': ['guitars', 'soccer']},\n {'name': 'Katie', 'age': 42, 'hobbies': ['diving', 'art']}]}\n```", "```py\nIn [71]: asjson = json.dumps(result)\n\nIn [72]: asjson\nOut[72]: '{\"name\": \"Wes\", \"cities_lived\": [\"Akron\", \"Nashville\", \"New York\", \"San\n Francisco\"], \"pet\": null, \"siblings\": [{\"name\": \"Scott\", \"age\": 34, \"hobbies\": [\n\"guitars\", \"soccer\"]}, {\"name\": \"Katie\", \"age\": 42, \"hobbies\": [\"diving\", \"art\"]}\n]}'\n```", "```py\nIn [73]: siblings = pd.DataFrame(result[\"siblings\"], columns=[\"name\", \"age\"])\n\nIn [74]: siblings\nOut[74]: \n name  age\n0  Scott   34\n1  Katie   42\n```", "```py\nIn [75]: !cat examples/example.json\n[{\"a\": 1, \"b\": 2, \"c\": 3},\n {\"a\": 4, \"b\": 5, \"c\": 6},\n {\"a\": 7, \"b\": 8, \"c\": 9}]\n```", "```py\nIn [76]: data = pd.read_json(\"examples/example.json\")\n\nIn [77]: data\nOut[77]: \n a  b  c\n0  1  2  3\n1  4  5  6\n2  7  8  9\n```", "```py\nIn [78]: data.to_json(sys.stdout)\n{\"a\":{\"0\":1,\"1\":4,\"2\":7},\"b\":{\"0\":2,\"1\":5,\"2\":8},\"c\":{\"0\":3,\"1\":6,\"2\":9}}\nIn [79]: data.to_json(sys.stdout, orient=\"records\")\n[{\"a\":1,\"b\":2,\"c\":3},{\"a\":4,\"b\":5,\"c\":6},{\"a\":7,\"b\":8,\"c\":9}]\n```", "```py\nconda install lxml beautifulsoup4 html5lib\n```", "```py\nIn [80]: tables = pd.read_html(\"examples/fdic_failed_bank_list.html\")\n\nIn [81]: len(tables)\nOut[81]: 1\n\nIn [82]: failures = tables[0]\n\nIn [83]: failures.head()\nOut[83]: \n Bank Name             City  ST   CERT \n0                   Allied Bank         Mulberry  AR     91  \\\n1  The Woodbury Banking Company         Woodbury  GA  11297 \n2        First CornerStone Bank  King of Prussia  PA  35312 \n3            Trust Company Bank          Memphis  TN   9956 \n4    North Milwaukee State Bank        Milwaukee  WI  20364 \n Acquiring Institution        Closing Date       Updated Date \n0                         Today's Bank  September 23, 2016  November 17, 2016 \n1                          United Bank     August 19, 2016  November 17, 2016 \n2  First-Citizens Bank & Trust Company         May 6, 2016  September 6, 2016 \n3           The Bank of Fayette County      April 29, 2016  September 6, 2016 \n4  First-Citizens Bank & Trust Company      March 11, 2016      June 16, 2016 \n```", "```py\nIn [84]: close_timestamps = pd.to_datetime(failures[\"Closing Date\"])\n\nIn [85]: close_timestamps.dt.year.value_counts()\nOut[85]: \nClosing Date\n2010    157\n2009    140\n2011     92\n2012     51\n2008     25\n ... \n2004      4\n2001      4\n2007      3\n2003      3\n2000      2\nName: count, Length: 15, dtype: int64\n```", "```py\n<INDICATOR>\n <INDICATOR_SEQ>373889</INDICATOR_SEQ>\n <PARENT_SEQ></PARENT_SEQ>\n <AGENCY_NAME>Metro-North Railroad</AGENCY_NAME>\n <INDICATOR_NAME>Escalator Availability</INDICATOR_NAME>\n <DESCRIPTION>Percent of the time that escalators are operational\n systemwide. The availability rate is based on physical observations performed\n the morning of regular business days only. This is a new indicator the agency\n began reporting in 2009.</DESCRIPTION>\n <PERIOD_YEAR>2011</PERIOD_YEAR>\n <PERIOD_MONTH>12</PERIOD_MONTH>\n <CATEGORY>Service Indicators</CATEGORY>\n <FREQUENCY>M</FREQUENCY>\n <DESIRED_CHANGE>U</DESIRED_CHANGE>\n <INDICATOR_UNIT>%</INDICATOR_UNIT>\n <DECIMAL_PLACES>1</DECIMAL_PLACES>\n <YTD_TARGET>97.00</YTD_TARGET>\n <YTD_ACTUAL></YTD_ACTUAL>\n <MONTHLY_TARGET>97.00</MONTHLY_TARGET>\n <MONTHLY_ACTUAL></MONTHLY_ACTUAL>\n</INDICATOR>\n```", "```py\nIn [86]: from lxml import objectify\n\nIn [87]: path = \"datasets/mta_perf/Performance_MNR.xml\"\n\nIn [88]: with open(path) as f:\n ....:     parsed = objectify.parse(f)\n\nIn [89]: root = parsed.getroot()\n```", "```py\ndata = []\n\nskip_fields = [\"PARENT_SEQ\", \"INDICATOR_SEQ\",\n \"DESIRED_CHANGE\", \"DECIMAL_PLACES\"]\n\nfor elt in root.INDICATOR:\n el_data = {}\n for child in elt.getchildren():\n if child.tag in skip_fields:\n continue\n el_data[child.tag] = child.pyval\n data.append(el_data)\n```", "```py\nIn [91]: perf = pd.DataFrame(data)\n\nIn [92]: perf.head()\nOut[92]: \n AGENCY_NAME                        INDICATOR_NAME \n0  Metro-North Railroad  On-Time Performance (West of Hudson)  \\\n1  Metro-North Railroad  On-Time Performance (West of Hudson) \n2  Metro-North Railroad  On-Time Performance (West of Hudson) \n3  Metro-North Railroad  On-Time Performance (West of Hudson) \n4  Metro-North Railroad  On-Time Performance (West of Hudson) \n DESCRIPTION \n0  Percent of commuter trains that arrive at their destinations within 5 m...  \\\n1  Percent of commuter trains that arrive at their destinations within 5 m... \n2  Percent of commuter trains that arrive at their destinations within 5 m... \n3  Percent of commuter trains that arrive at their destinations within 5 m... \n4  Percent of commuter trains that arrive at their destinations within 5 m... \n PERIOD_YEAR  PERIOD_MONTH            CATEGORY FREQUENCY INDICATOR_UNIT \n0         2008             1  Service Indicators         M              %  \\\n1         2008             2  Service Indicators         M              % \n2         2008             3  Service Indicators         M              % \n3         2008             4  Service Indicators         M              % \n4         2008             5  Service Indicators         M              % \n YTD_TARGET YTD_ACTUAL MONTHLY_TARGET MONTHLY_ACTUAL \n0       95.0       96.9           95.0           96.9 \n1       95.0       96.0           95.0           95.0 \n2       95.0       96.3           95.0           96.9 \n3       95.0       96.8           95.0           98.3 \n4       95.0       96.6           95.0           95.8 \n```", "```py\nIn [93]: perf2 = pd.read_xml(path)\n\nIn [94]: perf2.head()\nOut[94]: \n INDICATOR_SEQ  PARENT_SEQ           AGENCY_NAME \n0          28445         NaN  Metro-North Railroad  \\\n1          28445         NaN  Metro-North Railroad \n2          28445         NaN  Metro-North Railroad \n3          28445         NaN  Metro-North Railroad \n4          28445         NaN  Metro-North Railroad \n INDICATOR_NAME \n0  On-Time Performance (West of Hudson)  \\\n1  On-Time Performance (West of Hudson) \n2  On-Time Performance (West of Hudson) \n3  On-Time Performance (West of Hudson) \n4  On-Time Performance (West of Hudson) \n DESCRIPTION \n0  Percent of commuter trains that arrive at their destinations within 5 m...  \\\n1  Percent of commuter trains that arrive at their destinations within 5 m... \n2  Percent of commuter trains that arrive at their destinations within 5 m... \n3  Percent of commuter trains that arrive at their destinations within 5 m... \n4  Percent of commuter trains that arrive at their destinations within 5 m... \n PERIOD_YEAR  PERIOD_MONTH            CATEGORY FREQUENCY DESIRED_CHANGE \n0         2008             1  Service Indicators         M              U  \\\n1         2008             2  Service Indicators         M              U \n2         2008             3  Service Indicators         M              U \n3         2008             4  Service Indicators         M              U \n4         2008             5  Service Indicators         M              U \n INDICATOR_UNIT  DECIMAL_PLACES YTD_TARGET YTD_ACTUAL MONTHLY_TARGET \n0              %               1      95.00      96.90          95.00  \\\n1              %               1      95.00      96.00          95.00 \n2              %               1      95.00      96.30          95.00 \n3              %               1      95.00      96.80          95.00 \n4              %               1      95.00      96.60          95.00 \n MONTHLY_ACTUAL \n0          96.90 \n1          95.00 \n2          96.90 \n3          98.30 \n4          95.80 \n```", "```py\nIn [95]: frame = pd.read_csv(\"examples/ex1.csv\")\n\nIn [96]: frame\nOut[96]: \n a   b   c   d message\n0  1   2   3   4   hello\n1  5   6   7   8   world\n2  9  10  11  12     foo\n\nIn [97]: frame.to_pickle(\"examples/frame_pickle\")\n```", "```py\nIn [98]: pd.read_pickle(\"examples/frame_pickle\")\nOut[98]: \n a   b   c   d message\n0  1   2   3   4   hello\n1  5   6   7   8   world\n2  9  10  11  12     foo\n```", "```py\nIn [100]: fec = pd.read_parquet('datasets/fec/fec.parquet')\n```", "```py\nconda install openpyxl xlrd\n```", "```py\nIn [101]: xlsx = pd.ExcelFile(\"examples/ex1.xlsx\")\n```", "```py\nIn [102]: xlsx.sheet_names\nOut[102]: ['Sheet1']\n```", "```py\nIn [103]: xlsx.parse(sheet_name=\"Sheet1\")\nOut[103]: \n Unnamed: 0  a   b   c   d message\n0           0  1   2   3   4   hello\n1           1  5   6   7   8   world\n2           2  9  10  11  12     foo\n```", "```py\nIn [104]: xlsx.parse(sheet_name=\"Sheet1\", index_col=0)\nOut[104]: \n a   b   c   d message\n0  1   2   3   4   hello\n1  5   6   7   8   world\n2  9  10  11  12     foo\n```", "```py\nIn [105]: frame = pd.read_excel(\"examples/ex1.xlsx\", sheet_name=\"Sheet1\")\n\nIn [106]: frame\nOut[106]: \n Unnamed: 0  a   b   c   d message\n0           0  1   2   3   4   hello\n1           1  5   6   7   8   world\n2           2  9  10  11  12     foo\n```", "```py\nIn [107]: writer = pd.ExcelWriter(\"examples/ex2.xlsx\")\n\nIn [108]: frame.to_excel(writer, \"Sheet1\")\n\nIn [109]: writer.close()\n```", "```py\nIn [110]: frame.to_excel(\"examples/ex2.xlsx\")\n```", "```py\nconda install pytables\n```", "```py\nIn [113]: frame = pd.DataFrame({\"a\": np.random.standard_normal(100)})\n\nIn [114]: store = pd.HDFStore(\"examples/mydata.h5\")\n\nIn [115]: store[\"obj1\"] = frame\n\nIn [116]: store[\"obj1_col\"] = frame[\"a\"]\n\nIn [117]: store\nOut[117]: \n<class 'pandas.io.pytables.HDFStore'>\nFile path: examples/mydata.h5\n```", "```py\nIn [118]: store[\"obj1\"]\nOut[118]: \n a\n0  -0.204708\n1   0.478943\n2  -0.519439\n3  -0.555730\n4   1.965781\n..       ...\n95  0.795253\n96  0.118110\n97 -0.748532\n98  0.584970\n99  0.152677\n[100 rows x 1 columns]\n```", "```py\nIn [119]: store.put(\"obj2\", frame, format=\"table\")\n\nIn [120]: store.select(\"obj2\", where=[\"index >= 10 and index <= 15\"])\nOut[120]: \n a\n10  1.007189\n11 -1.296221\n12  0.274992\n13  0.228913\n14  1.352917\n15  0.886429\n\nIn [121]: store.close()\n```", "```py\nIn [122]: frame.to_hdf(\"examples/mydata.h5\", \"obj3\", format=\"table\")\n\nIn [123]: pd.read_hdf(\"examples/mydata.h5\", \"obj3\", where=[\"index < 5\"])\nOut[123]: \n a\n0 -0.204708\n1  0.478943\n2 -0.519439\n3 -0.555730\n4  1.965781\n```", "```py\nIn [124]: import os\n\nIn [125]: os.remove(\"examples/mydata.h5\")\n```", "```py\nconda install requests\n```", "```py\nIn [126]: import requests\n\nIn [127]: url = \"https://api.github.com/repos/pandas-dev/pandas/issues\"\n\nIn [128]: resp = requests.get(url)\n\nIn [129]: resp.raise_for_status()\n\nIn [130]: resp\nOut[130]: <Response [200]>\n```", "```py\nIn [131]: data = resp.json()\n\nIn [132]: data[0][\"title\"]\nOut[132]: 'BUG: DataFrame.pivot mutates empty index.name attribute with typing._L\niteralGenericAlias'\n```", "```py\nIn [133]: issues = pd.DataFrame(data, columns=[\"number\", \"title\",\n .....:                                      \"labels\", \"state\"])\n\nIn [134]: issues\nOut[134]: \n number \n0    52629  \\\n1    52628 \n2    52626 \n3    52625 \n4    52624 \n..     ... \n25   52579 \n26   52577 \n27   52576 \n28   52571 \n29   52570 \n title \n0   BUG: DataFrame.pivot mutates empty index.name attribute with typing._Li...  \\\n1                                 DEPR: unused keywords in DTI/TDI construtors \n2                         ENH: Infer best datetime format from a random sample \n3            BUG: ArrowExtensionArray logical_op not working in all directions \n4              ENH: pandas.core.groupby.SeriesGroupBy.apply allow raw argument \n..                                                                         ... \n25                                     BUG: Axial inconsistency of pandas.diff \n26                  BUG: describe not respecting ArrowDtype in include/exclude \n27                  BUG: describe does not distinguish between Int64 and int64 \n28  BUG: `pandas.DataFrame.replace` silently fails to replace category type... \n29     BUG: DataFrame.describe include/exclude do not work for arrow datatypes \n labels \n0   [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ==', 'url': 'https://api.g... \\\n1                                                                           [] \n2 [] \n3   [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ==', 'url': 'https://api.g... \n4 [{'id': 76812, 'node_id': 'MDU6TGFiZWw3NjgxMg==', 'url': 'https://api.g... \n..                                                                         ... \n25  [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ==', 'url': 'https://api.g... \n26 [{'id': 3303158446, 'node_id': 'MDU6TGFiZWwzMzAzMTU4NDQ2', 'url': 'http... \n27 [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ==', 'url': 'https://api.g... \n28 [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ==', 'url': 'https://api.g... \n29 [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ==', 'url': 'https://api.g... \n state \n0   open \n1   open \n2   open \n3   open \n4   open \n..   ... \n25  open \n26  open \n27  open \n28  open \n29  open \n[30 rows x 4 columns]\n```", "```py\nIn [135]: import sqlite3\n\nIn [136]: query = \"\"\"\n .....: CREATE TABLE test\n .....: (a VARCHAR(20), b VARCHAR(20),\n .....:  c REAL,        d INTEGER\n .....: );\"\"\"\n\nIn [137]: con = sqlite3.connect(\"mydata.sqlite\")\n\nIn [138]: con.execute(query)\nOut[138]: <sqlite3.Cursor at 0x188e40ac0>\n\nIn [139]: con.commit()\n```", "```py\nIn [140]: data = [(\"Atlanta\", \"Georgia\", 1.25, 6),\n .....:         (\"Tallahassee\", \"Florida\", 2.6, 3),\n .....:         (\"Sacramento\", \"California\", 1.7, 5)]\n\nIn [141]: stmt = \"INSERT INTO test VALUES(?, ?, ?, ?)\"\n\nIn [142]: con.executemany(stmt, data)\nOut[142]: <sqlite3.Cursor at 0x188ed02c0>\n\nIn [143]: con.commit()\n```", "```py\nIn [144]: cursor = con.execute(\"SELECT * FROM test\")\n\nIn [145]: rows = cursor.fetchall()\n\nIn [146]: rows\nOut[146]: \n[('Atlanta', 'Georgia', 1.25, 6),\n ('Tallahassee', 'Florida', 2.6, 3),\n ('Sacramento', 'California', 1.7, 5)]\n```", "```py\nIn [147]: cursor.description\nOut[147]: \n(('a', None, None, None, None, None, None),\n ('b', None, None, None, None, None, None),\n ('c', None, None, None, None, None, None),\n ('d', None, None, None, None, None, None))\n\nIn [148]: pd.DataFrame(rows, columns=[x[0] for x in cursor.description])\nOut[148]: \n a           b     c  d\n0      Atlanta     Georgia  1.25  6\n1  Tallahassee     Florida  2.60  3\n2   Sacramento  California  1.70  5\n```", "```py\nconda install sqlalchemy\n```", "```py\nIn [149]: import sqlalchemy as sqla\n\nIn [150]: db = sqla.create_engine(\"sqlite:///mydata.sqlite\")\n\nIn [151]: pd.read_sql(\"SELECT * FROM test\", db)\nOut[151]: \n a           b     c  d\n0      Atlanta     Georgia  1.25  6\n1  Tallahassee     Florida  2.60  3\n2   Sacramento  California  1.70  5\n```"]