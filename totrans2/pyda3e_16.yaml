- en: 13  Data Analysis Examples
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 13 数据分析示例
- en: 原文：[https://wesmckinney.com/book/data-analysis-examples](https://wesmckinney.com/book/data-analysis-examples)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://wesmckinney.com/book/data-analysis-examples](https://wesmckinney.com/book/data-analysis-examples)
- en: '*This Open Access web version of *Python for Data Analysis 3rd Edition* is
    now available as a companion to the [print and digital editions](https://amzn.to/3DyLaJc).
    If you encounter any errata, [please report them here](https://oreilly.com/catalog/0636920519829/errata).
    Please note that some aspects of this site as produced by Quarto will differ from
    the formatting of the print and eBook versions from O’Reilly.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*本开放获取的网络版本*Python for Data Analysis第3版*现已作为[印刷版和数字版](https://amzn.to/3DyLaJc)的伴随版本提供。如果您发现任何勘误，请[在此处报告](https://oreilly.com/catalog/0636920519829/errata)。请注意，由Quarto制作的本网站的某些方面将与O''Reilly的印刷版和电子书版本的格式不同。'
- en: If you find the online edition of the book useful, please consider [ordering
    a paper copy](https://amzn.to/3DyLaJc) or a [DRM-free eBook](https://www.ebooks.com/en-us/book/210644288/python-for-data-analysis/wes-mckinney/?affId=WES398681F)
    to support the author. The content from this website may not be copied or reproduced.
    The code examples are MIT licensed and can be found on GitHub or Gitee.*  *Now
    that we've reached the final chapter of this book, we're going to take a look
    at a number of real-world datasets. For each dataset, we'll use the techniques
    presented in this book to extract meaning from the raw data. The demonstrated
    techniques can be applied to all manner of other datasets. This chapter contains
    a collection of miscellaneous example datasets that you can use for practice with
    the tools in this book.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您发现本书的在线版本有用，请考虑[订购纸质版](https://amzn.to/3DyLaJc)或[无DRM的电子书](https://www.ebooks.com/en-us/book/210644288/python-for-data-analysis/wes-mckinney/?affId=WES398681F)以支持作者。本网站的内容不得复制或复制。代码示例采用MIT许可证，可在GitHub或Gitee上找到。*
    *现在我们已经到达本书的最后一章，我们将查看一些真实世界的数据集。对于每个数据集，我们将使用本书中介绍的技术从原始数据中提取含义。演示的技术可以应用于各种其他数据集。本章包含一系列杂例数据集，您可以使用这些数据集练习本书中的工具。
- en: The example datasets are found in the book's accompanying [GitHub repository](http://github.com/wesm/pydata-book).
    If you are unable to access GitHub, you can also get them from the [repository
    mirror on Gitee](https://gitee.com/wesmckinn/pydata-book).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 示例数据集可在本书附带的[GitHub存储库](http://github.com/wesm/pydata-book)中找到。如果无法访问GitHub，还可以从[Gitee上的存储库镜像](https://gitee.com/wesmckinn/pydata-book)获取它们。
- en: 13.1 Bitly Data from 1.USA.gov
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.1 Bitly Data from 1.USA.gov
- en: In 2011, the URL shortening service [Bitly](https://bitly.com) partnered with
    the US government website [USA.gov](https://www.usa.gov) to provide a feed of
    anonymous data gathered from users who shorten links ending with *.gov* or *.mil*.
    In 2011, a live feed as well as hourly snapshots were available as downloadable
    text files. This service is shut down at the time of this writing (2022), but
    we preserved one of the data files for the book's examples.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 2011年，URL缩短服务[Bitly](https://bitly.com)与美国政府网站[USA.gov](https://www.usa.gov)合作，提供从缩短链接以*.gov*或*.mil*结尾的用户收集的匿名数据的源。2011年，可下载的文本文件提供了实时数据以及每小时的快照。本文撰写时（2022年），该服务已关闭，但我们保留了一份数据文件用于本书的示例。
- en: 'In the case of the hourly snapshots, each line in each file contains a common
    form of web data known as JSON, which stands for JavaScript Object Notation. For
    example, if we read just the first line of a file, we may see something like this:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个文件的每一行中，每小时快照包含一种称为JSON的常见网络数据形式，JSON代表JavaScript对象表示法。例如，如果我们只读取文件的第一行，可能会看到类似于这样的内容：
- en: '[PRE0]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Python has both built-in and third-party libraries for converting a JSON string
    into a Python dictionary. Here we’ll use the `json` module and its `loads` function
    invoked on each line in the sample file we downloaded:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Python有内置和第三方库，用于将JSON字符串转换为Python字典。在这里，我们将使用`json`模块及其在我们下载的示例文件中的每一行上调用的`loads`函数：
- en: '[PRE1]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The resulting object `records` is now a list of Python dictionaries:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 结果对象`records`现在是一个Python字典列表：
- en: '[PRE2]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Counting Time Zones in Pure Python
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用纯Python计算时区
- en: 'Suppose we were interested in finding the time zones that occur most often
    in the dataset (the `tz` field). There are many ways we could do this. First,
    let’s extract a list of time zones again using a list comprehension:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有兴趣找出数据集中最常出现的时区（`tz`字段）。我们可以通过多种方式来实现这一点。首先，让我们再次使用列表推导式提取时区列表：
- en: '[PRE3]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Oops! Turns out that not all of the records have a time zone field. We can
    handle this by adding the check `if "tz" in rec` at the end of the list comprehension:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 糟糕！原来并非所有记录都有时区字段。我们可以通过在列表推导式末尾添加检查`if "tz" in rec`来处理这个问题：
- en: '[PRE4]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Just looking at the first 10 time zones, we see that some of them are unknown
    (empty string). You can filter these out also, but I’ll leave them in for now.
    Next, to produce counts by time zone, I’ll show two approaches: a harder way (using
    just the Python standard library) and a simpler way (using pandas). One way to
    do the counting is to use a dictionary to store counts while we iterate through
    the time zones:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 仅查看前10个时区，我们会发现其中一些是未知的（空字符串）。您也可以将这些过滤掉，但我暂时保留它们。接下来，为了按时区生成计数，我将展示两种方法：一种更困难的方法（仅使用Python标准库）和一种更简单的方法（使用pandas）。计数的一种方法是使用字典来存储计数，同时我们遍历时区：
- en: '[PRE5]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Using more advanced tools in the Python standard library, you can write the
    same thing more briefly:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Python标准库中更高级的工具，您可以更简洁地编写相同的内容：
- en: '[PRE6]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'I put this logic in a function just to make it more reusable. To use it on
    the time zones, just pass the `time_zones` list:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我将这个逻辑放在一个函数中，以使其更具可重用性。要在时区上使用它，只需传递`time_zones`列表：
- en: '[PRE7]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If we wanted the top 10 time zones and their counts, we can make a list of
    tuples by `(count, timezone)` and sort it:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要前10个时区及其计数，我们可以通过`(count, timezone)`创建一个元组列表，并对其进行排序：
- en: '[PRE8]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We have then:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有：
- en: '[PRE9]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'If you search the Python standard library, you may find the `collections.Counter`
    class, which makes this task even simpler:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您搜索Python标准库，可能会找到`collections.Counter`类，这将使这个任务变得更简单：
- en: '[PRE10]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Counting Time Zones with pandas
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用pandas计算时区
- en: 'You can create a DataFrame from the original set of records by passing the
    list of records to `pandas.DataFrame`:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过将记录列表传递给`pandas.DataFrame`来从原始记录集创建一个DataFrame：
- en: '[PRE11]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We can look at some basic information about this new DataFrame, such as column
    names, inferred column types, or number of missing values, using `frame.info()`:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以查看有关这个新DataFrame的一些基本信息，比如列名、推断的列类型或缺失值的数量，使用`frame.info()`：
- en: '[PRE12]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The output shown for the `frame` is the *summary view*, shown for large DataFrame
    objects. We can then use the `value_counts` method for the Series:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`frame`的输出显示为*摘要视图*，适用于大型DataFrame对象。然后我们可以使用Series的`value_counts`方法：'
- en: '[PRE13]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We can visualize this data using matplotlib. We can make the plots a bit nicer
    by filling in a substitute value for unknown or missing time zone data in the
    records. We replace the missing values with the `fillna` method and use Boolean
    array indexing for the empty strings:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用matplotlib可视化这些数据。我们可以通过为记录中的未知或缺失时区数据填充替代值来使图表更加美观。我们使用`fillna`方法替换缺失值，并使用布尔数组索引来处理空字符串：
- en: '[PRE14]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'At this point, we can use the [seaborn package](http://seaborn.pydata.org)
    to make a horizontal bar plot (see [Top time zones in the 1.usa.gov sample data](#usa_gov_counts)
    for the resulting visualization):'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们可以使用[seaborn包](http://seaborn.pydata.org)制作一个水平条形图（参见[1.usa.gov示例数据中的顶级时区](#usa_gov_counts)以查看结果可视化）：
- en: '[PRE15]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![](../Images/7dd52fd5fa321b6a9d79111326825f9b.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7dd52fd5fa321b6a9d79111326825f9b.png)'
- en: 'Figure 13.1: Top time zones in the 1.usa.gov sample data'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.1：1.usa.gov示例数据中的顶级时区
- en: 'The `a` field contains information about the browser, device, or application
    used to perform the URL shortening:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '`a`字段包含有关用于执行URL缩短的浏览器、设备或应用程序的信息：'
- en: '[PRE16]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Parsing all of the interesting information in these “agent” strings may seem
    like a daunting task. One possible strategy is to split off the first token in
    the string (corresponding roughly to the browser capability) and make another
    summary of the user behavior:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 解析这些“代理”字符串中的所有有趣信息可能看起来是一项艰巨的任务。一种可能的策略是将字符串中的第一个标记（大致对应于浏览器功能）拆分出来，并对用户行为进行另一个摘要：
- en: '[PRE17]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, suppose you wanted to decompose the top time zones into Windows and non-Windows
    users. As a simplification, let’s say that a user is on Windows if the string
    `"Windows"` is in the agent string. Since some of the agents are missing, we’ll
    exclude these from the data:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设您想将顶级时区分解为Windows和非Windows用户。为简化起见，假设如果代理字符串中包含“Windows”字符串，则用户使用的是Windows。由于一些代理缺失，我们将排除这些数据：
- en: '[PRE18]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We want to then compute a value for whether or not each row is Windows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们想计算每行是否为Windows的值：
- en: '[PRE19]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Then, you can group the data by its time zone column and this new list of operating
    systems:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以按其时区列和这个新的操作系统列表对数据进行分组：
- en: '[PRE20]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The group counts, analogous to the `value_counts` function, can be computed
    with `size`. This result is then reshaped into a table with `unstack`:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于`value_counts`函数，可以使用`size`计算组计数。然后将结果重塑为表格，使用`unstack`：
- en: '[PRE21]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Finally, let’s select the top overall time zones. To do so, I construct an
    indirect index array from the row counts in `agg_counts`. After computing the
    row counts with `agg_counts.sum("columns")`, I can call `argsort()` to obtain
    an index array that can be used to sort in ascending order:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们选择顶级的整体时区。为此，我从`agg_counts`中的行计数构建一个间接索引数组。在使用`agg_counts.sum("columns")`计算行计数后，我可以调用`argsort()`来获得一个可以用于升序排序的索引数组：
- en: '[PRE22]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'I use `take` to select the rows in that order, then slice off the last 10 rows
    (largest values):'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用`take`按顺序选择行，然后切掉最后10行（最大值）：
- en: '[PRE23]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'pandas has a convenience method called `nlargest` that does the same thing:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: pandas有一个方便的方法叫做`nlargest`，可以做同样的事情：
- en: '[PRE24]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Then, this can be plotted in a grouped bar plot comparing the number of Windows
    and non-Windows users, using seaborn''s `barplot` function (see [Top time zones
    by Windows and non-Windows users](#usa_gov_tz_os)). I first call `count_subset.stack()`
    and reset the index to rearrange the data for better compatibility with seaborn:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，可以绘制一个分组条形图，比较Windows和非Windows用户的数量，使用seaborn的`barplot`函数（参见[按Windows和非Windows用户的顶级时区](#usa_gov_tz_os)）。我首先调用`count_subset.stack()`并重置索引以重新排列数据，以便更好地与seaborn兼容：
- en: '[PRE25]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![](../Images/f69b4d795dc2eedaf3e3e02e6e0a9d87.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f69b4d795dc2eedaf3e3e02e6e0a9d87.png)'
- en: 'Figure 13.2: Top time zones by Windows and non-Windows users'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.2：按Windows和非Windows用户的顶级时区
- en: 'It is a bit difficult to see the relative percentage of Windows users in the
    smaller groups, so let''s normalize the group percentages to sum to 1:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在较小的组中，很难看出Windows用户的相对百分比，因此让我们将组百分比归一化为1：
- en: '[PRE26]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Then plot this in [Percentage Windows and non-Windows users in top occurring
    time zones](#usa_gov_tz_os_normed):'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 然后在[出现频率最高的时区中Windows和非Windows用户的百分比](#usa_gov_tz_os_normed)中绘制这个图：
- en: '[PRE27]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![](../Images/a218b1a30914e6cbfa11d7eb83a4f1cb.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a218b1a30914e6cbfa11d7eb83a4f1cb.png)'
- en: 'Figure 13.3: Percentage Windows and non-Windows users in top occurring time
    zones'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.3：出现频率最高的时区中Windows和非Windows用户的百分比
- en: 'We could have computed the normalized sum more efficiently by using the `transform`
    method with `groupby`:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用`transform`方法和`groupby`更有效地计算归一化和：
- en: '[PRE28]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 13.2 MovieLens 1M Dataset
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.2 MovieLens 1M数据集
- en: '[GroupLens Research](https://grouplens.org/datasets/movielens) provides a number
    of collections of movie ratings data collected from users of MovieLens in the
    late 1990s and early 2000s. The data provides movie ratings, movie metadata (genres
    and year), and demographic data about the users (age, zip code, gender identification,
    and occupation). Such data is often of interest in the development of recommendation
    systems based on machine learning algorithms. While we do not explore machine
    learning techniques in detail in this book, I will show you how to slice and dice
    datasets like these into the exact form you need.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[GroupLens Research](https://grouplens.org/datasets/movielens)提供了从1990年代末到2000年代初从MovieLens用户收集的多个电影评分数据集。数据提供了电影评分、电影元数据（类型和年份）以及关于用户的人口统计数据（年龄、邮政编码、性别认同和职业）。这些数据通常在基于机器学习算法的推荐系统的开发中很有兴趣。虽然我们在本书中没有详细探讨机器学习技术，但我将向您展示如何将这些数据集切分成您需要的确切形式。'
- en: 'The MovieLens 1M dataset contains one million ratings collected from six thousand
    users on four thousand movies. It’s spread across three tables: ratings, user
    information, and movie information. We can load each table into a pandas DataFrame
    object using `pandas.read_table`. Run the following code in a Jupyter cell:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: MovieLens 1M数据集包含从六千名用户对四千部电影收集的一百万个评分。它分布在三个表中：评分、用户信息和电影信息。我们可以使用`pandas.read_table`将每个表加载到一个pandas
    DataFrame对象中。在Jupyter单元格中运行以下代码：
- en: '[PRE29]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'You can verify that everything succeeded by looking at each DataFrame:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过查看每个DataFrame来验证一切是否成功：
- en: '[PRE30]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Note that ages and occupations are coded as integers indicating groups described
    in the dataset’s *README* file. Analyzing the data spread across three tables
    is not a simple task; for example, suppose you wanted to compute mean ratings
    for a particular movie by gender identity and age. As you will see, this is more
    convenient to do with all of the data merged together into a single table. Using
    pandas’s `merge` function, we first merge `ratings` with `users` and then merge
    that result with the `movies` data. pandas infers which columns to use as the
    merge (or *join*) keys based on overlapping names:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，年龄和职业被编码为整数，表示数据集的*README*文件中描述的组。分析分布在三个表中的数据并不是一项简单的任务；例如，假设您想要按性别身份和年龄计算特定电影的平均评分。正如您将看到的，将所有数据合并到一个单一表中更方便。使用pandas的`merge`函数，我们首先将`ratings`与`users`合并，然后将该结果与`movies`数据合并。pandas根据重叠的名称推断要用作合并（或*join*）键的列：
- en: '[PRE31]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'To get mean movie ratings for each film grouped by gender, we can use the `pivot_table`
    method:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得按性别分组的每部电影的平均评分，我们可以使用`pivot_table`方法：
- en: '[PRE32]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'This produced another DataFrame containing mean ratings with movie titles as
    row labels (the "index") and gender as column labels. I first filter down to movies
    that received at least 250 ratings (an arbitrary number); to do this, I group
    the data by title, and use `size()` to get a Series of group sizes for each title:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了另一个包含平均评分的DataFrame，其中电影标题作为行标签（“索引”），性别作为列标签。我首先筛选出至少收到250个评分的电影（一个任意的数字）；为此，我按标题对数据进行分组，并使用`size()`来获取每个标题的组大小的Series：
- en: '[PRE33]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The index of titles receiving at least 250 ratings can then be used to select
    rows from `mean_ratings` using `.loc`:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，可以使用至少收到250个评分的标题的索引来从`mean_ratings`中选择行，使用`.loc`：
- en: '[PRE34]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'To see the top films among female viewers, we can sort by the `F` column in
    descending order:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看女性观众最喜欢的电影，我们可以按降序排序`F`列：
- en: '[PRE35]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Measuring Rating Disagreement
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测量评分分歧
- en: 'Suppose you wanted to find the movies that are most divisive between male and
    female viewers. One way is to add a column to `mean_ratings` containing the difference
    in means, then sort by that:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您想要找到在男性和女性观众之间最具分歧的电影。一种方法是向`mean_ratings`添加一个包含平均值差异的列，然后按照该列进行排序：
- en: '[PRE36]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Sorting by `"diff"` yields the movies with the greatest rating difference so
    that we can see which ones were preferred by women:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 按照“diff”排序，可以得到评分差异最大的电影，以便看到哪些电影更受女性喜欢：
- en: '[PRE37]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Reversing the order of the rows and again slicing off the top 10 rows, we get
    the movies preferred by men that women didn’t rate as highly:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 颠倒行的顺序并再次切片前10行，我们得到了男性喜欢但女性评分不高的电影：
- en: '[PRE38]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Suppose instead you wanted the movies that elicited the most disagreement among
    viewers, independent of gender identification. Disagreement can be measured by
    the variance or standard deviation of the ratings. To get this, we first compute
    the rating standard deviation by title and then filter down to the active titles:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您想要找到在观众中引起最大分歧的电影，而不考虑性别认同。分歧可以通过评分的方差或标准差来衡量。为了得到这个结果，我们首先按标题计算评分的标准差，然后筛选出活跃的标题：
- en: '[PRE39]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Then, we sort in descending order and select the first 10 rows, which are roughly
    the 10 most divisively rated movies:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们按降序排序并选择前10行，这大致是评分最具分歧的10部电影：
- en: '[PRE40]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'You may have noticed that movie genres are given as a pipe-separated (`|`)
    string, since a single movie can belong to multiple genres. To help us group the
    ratings data by genre, we can use the `explode` method on DataFrame. Let''s take
    a look at how this works. First, we can split the genres string into a list of
    genres using the `str.split` method on the Series:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经注意到电影类型是以管道分隔（`|`）的字符串给出的，因为一部电影可以属于多种类型。为了帮助我们按类型对评分数据进行分组，我们可以在DataFrame上使用`explode`方法。让我们看看这是如何工作的。首先，我们可以使用Series上的`str.split`方法将类型字符串拆分为类型列表：
- en: '[PRE41]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Now, calling `movies.explode("genre")` generates a new DataFrame with one row
    for each "inner" element in each list of movie genres. For example, if a movie
    is classified as both a comedy and a romance, then there will be two rows in the
    result, one with just `"Comedy"` and the other with just `"Romance"`:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，调用`movies.explode("genre")`会生成一个新的DataFrame，其中每个电影类型列表中的“内部”元素都有一行。例如，如果一部电影被分类为喜剧和浪漫片，那么结果中将有两行，一行只有“喜剧”，另一行只有“浪漫片”：
- en: '[PRE42]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Now, we can merge all three tables together and group by genre:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以将所有三个表合并在一起，并按类型分组：
- en: '[PRE43]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 13.3 US Baby Names 1880–2010
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.3美国婴儿姓名1880-2010
- en: The United States Social Security Administration (SSA) has made available data
    on the frequency of baby names from 1880 through the present. Hadley Wickham,
    an author of several popular R packages, has this dataset in illustrating data
    manipulation in R.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 美国社会保障管理局（SSA）提供了从1880年到现在的婴儿名字频率数据。Hadley Wickham，几个流行R包的作者，在R中说明数据操作时使用了这个数据集。
- en: 'We need to do some data wrangling to load this dataset, but once we do that
    we will have a DataFrame that looks like this:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要进行一些数据整理来加载这个数据集，但一旦我们这样做了，我们将得到一个看起来像这样的DataFrame：
- en: '[PRE44]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'There are many things you might want to do with the dataset:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多事情你可能想要对数据集做：
- en: Visualize the proportion of babies given a particular name (your own, or another
    name) over time
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化随着时间推移给定名字（您自己的名字或其他名字）的婴儿比例
- en: Determine the relative rank of a name
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定一个名字的相对排名
- en: Determine the most popular names in each year or the names whose popularity
    has advanced or declined the most
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定每年最受欢迎的名字或受欢迎程度增长或下降最多的名字
- en: 'Analyze trends in names: vowels, consonants, length, overall diversity, changes
    in spelling, first and last letters'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析名字的趋势：元音、辅音、长度、整体多样性、拼写变化、首尾字母
- en: 'Analyze external sources of trends: biblical names, celebrities, demographics'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析趋势的外部来源：圣经名字、名人、人口统计学
- en: With the tools in this book, many of these kinds of analyses are within reach,
    so I will walk you through some of them.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 使用本书中的工具，许多这类分析都可以实现，所以我会带你走一些。
- en: As of this writing, the US Social Security Administration makes available data
    files, one per year, containing the total number of births for each sex/name combination.
    You can download the [raw archive](http://www.ssa.gov/oact/babynames/limits.html)
    of these files.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 截至目前，美国社会保障管理局提供了数据文件，每年一个文件，其中包含每个性别/名字组合的总出生数。您可以下载这些文件的[原始存档](http://www.ssa.gov/oact/babynames/limits.html)。
- en: 'If this page has been moved by the time you’re reading this, it can most likely
    be located again with an internet search. After downloading the “National data”
    file *names.zip* and unzipping it, you will have a directory containing a series
    of files like *yob1880.txt*. I use the Unix `head` command to look at the first
    10 lines of one of the files (on Windows, you can use the `more` command or open
    it in a text editor):'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在阅读此页面时发现已移动，很可能可以通过互联网搜索再次找到。下载“国家数据”文件*names.zip*并解压缩后，您将获得一个包含一系列文件如*yob1880.txt*的目录。我使用Unix的`head`命令查看其中一个文件的前10行（在Windows上，您可以使用`more`命令或在文本编辑器中打开）：
- en: '[PRE45]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'As this is already in comma-separated form, it can be loaded into a DataFrame
    with `pandas.read_csv`:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这已经是逗号分隔形式，可以使用`pandas.read_csv`将其加载到DataFrame中：
- en: '[PRE46]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'These files only contain names with at least five occurrences in each year,
    so for simplicity’s sake we can use the sum of the births column by sex as the
    total number of births in that year:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这些文件只包含每年至少有五次出现的名字，所以为了简单起见，我们可以使用按性别的出生列的总和作为该年出生的总数：
- en: '[PRE47]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Since the dataset is split into files by year, one of the first things to do
    is to assemble all of the data into a single DataFrame and further add a `year`
    field. You can do this using `pandas.concat`. Run the following in a Jupyter cell:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据集按年份分成文件，首先要做的事情之一是将所有数据组装到一个单独的DataFrame中，并进一步添加一个`year`字段。您可以使用`pandas.concat`来做到这一点。在Jupyter单元格中运行以下内容：
- en: '[PRE48]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'There are a couple things to note here. First, remember that `concat` combines
    the DataFrame objects by row by default. Second, you have to pass `ignore_index=True`
    because we’re not interested in preserving the original row numbers returned from
    `pandas.read_csv`. So we now have a single DataFrame containing all of the names
    data across all years:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有几件事情需要注意。首先，记住`concat`默认按行组合DataFrame对象。其次，您必须传递`ignore_index=True`，因为我们不关心从`pandas.read_csv`返回的原始行号。因此，现在我们有一个包含所有年份的所有名字数据的单个DataFrame：
- en: '[PRE49]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'With this data in hand, we can already start aggregating the data at the year
    and sex level using `groupby` or `pivot_table` (see [Total births by sex and year](#baby_names_total_births)):'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些数据，我们可以开始使用`groupby`或`pivot_table`在年份和性别水平上对数据进行聚合（参见[按性别和年份统计的总出生数](#baby_names_total_births)）：
- en: '[PRE50]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '![](../Images/6716e4c3fc8eb1a44199a90351da2a0d.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6716e4c3fc8eb1a44199a90351da2a0d.png)'
- en: 'Figure 13.4: Total births by sex and year'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.4：按性别和年份统计的总出生数
- en: 'Next, let’s insert a column `prop` with the fraction of babies given each name
    relative to the total number of births. A `prop` value of `0.02` would indicate
    that 2 out of every 100 babies were given a particular name. Thus, we group the
    data by year and sex, then add the new column to each group:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们插入一个名为`prop`的列，该列显示每个名字相对于总出生数的比例。`prop`值为`0.02`表示每100个婴儿中有2个被赋予特定的名字。因此，我们按年份和性别对数据进行分组，然后向每个组添加新列：
- en: '[PRE51]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The resulting complete dataset now has the following columns:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在得到的完整数据集现在具有以下列：
- en: '[PRE52]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'When performing a group operation like this, it''s often valuable to do a sanity
    check, like verifying that the `prop` column sums to 1 within all the groups:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行这样的组操作时，通常很有价值进行一些合理性检查，比如验证所有组中`prop`列的总和是否为1：
- en: '[PRE53]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Now that this is done, I’m going to extract a subset of the data to facilitate
    further analysis: the top 1,000 names for each sex/year combination. This is yet
    another group operation:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在这样做了，我将提取数据的一个子集以便进一步分析：每个性别/年份组合的前1000个名字。这是另一个组操作：
- en: '[PRE54]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'We can drop the group index since we don''t need it for our analysis:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以删除组索引，因为我们不需要它进行分析：
- en: '[PRE55]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The resulting dataset is now quite a bit smaller:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 现在得到的数据集要小得多：
- en: '[PRE56]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: We’ll use this top one thousand dataset in the following investigations into
    the data.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的数据调查中使用这个前一千个数据集。
- en: Analyzing Naming Trends
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分析命名趋势
- en: 'With the full dataset and the top one thousand dataset in hand, we can start
    analyzing various naming trends of interest. First, we can split the top one thousand
    names into the boy and girl portions:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 有了完整的数据集和前一千个数据集，我们可以开始分析各种有趣的命名趋势。首先，我们可以将前一千个名字分为男孩和女孩部分：
- en: '[PRE57]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Simple time series, like the number of Johns or Marys for each year, can be
    plotted but require some manipulation to be more useful. Let’s form a pivot table
    of the total number of births by year and name:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的时间序列，比如每年约翰或玛丽的数量，可以绘制，但需要一些操作才能更有用。让我们形成一个按年份和姓名总数的数据透视表：
- en: '[PRE58]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Now, this can be plotted for a handful of names with DataFrame’s `plot` method
    ([A few boy and girl names over time](#baby_names_some_names) shows the result):'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，可以使用DataFrame的`plot`方法为一些名字绘制图表（[一些男孩和女孩名字随时间变化](#baby_names_some_names)显示了结果）：
- en: '[PRE59]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '![](../Images/e1a3230ba5c578a21a784b09be9c0e91.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e1a3230ba5c578a21a784b09be9c0e91.png)'
- en: 'Figure 13.5: A few boy and girl names over time'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.5：一些男孩和女孩名字随时间变化
- en: On looking at this, you might conclude that these names have grown out of favor
    with the American population. But the story is actually more complicated than
    that, as will be explored in the next section.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 看到这个，你可能会得出结论，这些名字已经不再受到美国人口的青睐。但事实实际上比这更复杂，将在下一节中探讨。
- en: Measuring the increase in naming diversity
  id: totrans-155
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 衡量命名多样性的增加
- en: 'One explanation for the decrease in plots is that fewer parents are choosing
    common names for their children. This hypothesis can be explored and confirmed
    in the data. One measure is the proportion of births represented by the top 1,000
    most popular names, which I aggregate and plot by year and sex ([Proportion of
    births represented in top one thousand names by sex](#baby_names_tot_prop) shows
    the resulting plot):'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 减少图表的原因之一是越来越少的父母选择常见的名字给他们的孩子。这个假设可以在数据中进行探索和确认。一个度量是由前1000个最受欢迎的名字代表的出生比例，我按年份和性别进行汇总和绘制（[性别在前一千个名字中所代表的出生比例](#baby_names_tot_prop)显示了结果图）：
- en: '[PRE60]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '![](../Images/24e093fb2856ccb1ffa83d884da1713d.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/24e093fb2856ccb1ffa83d884da1713d.png)'
- en: 'Figure 13.6: Proportion of births represented in top one thousand names by
    sex'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.6：性别在前一千个名字中所代表的出生比例
- en: 'You can see that, indeed, there appears to be increasing name diversity (decreasing
    total proportion in the top one thousand). Another interesting metric is the number
    of distinct names, taken in order of popularity from highest to lowest, in the
    top 50% of births. This number is trickier to compute. Let’s consider just the
    boy names from 2010:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到，确实存在着越来越多的名字多样性（前一千名中总比例减少）。另一个有趣的指标是在出生的前50%中按照从高到低的流行度顺序取的不同名字的数量。这个数字更难计算。让我们只考虑2010年的男孩名字：
- en: '[PRE61]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'After sorting `prop` in descending order, we want to know how many of the most
    popular names it takes to reach 50%. You could write a `for` loop to do this,
    but a vectorized NumPy way is more computationally efficient. Taking the cumulative
    sum, `cumsum`, of `prop` and then calling the method `searchsorted` returns the
    position in the cumulative sum at which `0.5` would need to be inserted to keep
    it in sorted order:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在对`prop`进行降序排序后，我们想知道最受欢迎的名字中有多少个名字达到了50%。您可以编写一个`for`循环来执行此操作，但使用矢量化的NumPy方法更具计算效率。对`prop`进行累积求和`cumsum`，然后调用`searchsorted`方法返回`0.5`需要插入的累积和位置，以保持其按顺序排序：
- en: '[PRE62]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Since arrays are zero-indexed, adding 1 to this result gives you a result of
    117\. By contrast, in 1900 this number was much smaller:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数组是从零开始索引的，将此结果加1将得到117的结果。相比之下，在1900年，这个数字要小得多：
- en: '[PRE63]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'You can now apply this operation to each year/sex combination, `groupby` those
    fields, and `apply` a function returning the count for each group:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以将此操作应用于每个年份/性别组合，对这些字段进行`groupby`，并`apply`一个返回每个组计数的函数：
- en: '[PRE64]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'This resulting DataFrame `diversity` now has two time series, one for each
    sex, indexed by year. This can be inspected and plotted as before (see [Plot of
    diversity metric by year](#baby_names_diversity_fig)):'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果DataFrame `diversity` 现在有两个时间序列，一个用于每个性别，按年份索引。这可以像以前一样进行检查和绘制（参见[按年份绘制的多样性指标](#baby_names_diversity_fig)）：
- en: '[PRE65]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '![](../Images/1e1bea5330bbf1ad2202b26ba95095b8.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1e1bea5330bbf1ad2202b26ba95095b8.png)'
- en: 'Figure 13.7: Plot of diversity metric by year'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.7：按年份绘制的多样性指标
- en: As you can see, girl names have always been more diverse than boy names, and
    they have only become more so over time. Further analysis of what exactly is driving
    the diversity, like the increase of alternative spellings, is left to the reader.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，女孩名字一直比男孩名字更多样化，而且随着时间的推移，它们变得更加多样化。关于到底是什么推动了这种多样性的进一步分析，比如替代拼写的增加，留给读者自行探讨。
- en: The “last letter” revolution
  id: totrans-173
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: “最后一个字母”革命
- en: 'In 2007, baby name researcher Laura Wattenberg pointed out that the distribution
    of boy names by final letter has changed significantly over the last 100 years.
    To see this, we first aggregate all of the births in the full dataset by year,
    sex, and final letter:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在2007年，婴儿姓名研究员劳拉·瓦滕伯格指出，过去100年来，以最后一个字母结尾的男孩名字的分布发生了显著变化。为了看到这一点，我们首先按年份、性别和最后一个字母聚合完整数据集中的所有出生情况：
- en: '[PRE66]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Then we select three representative years spanning the history and print the
    first few rows:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们选择三个代表性年份跨越历史，并打印前几行：
- en: '[PRE67]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Next, normalize the table by total births to compute a new table containing
    the proportion of total births for each sex ending in each letter:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，通过总出生数对表进行标准化，计算一个包含每个性别以每个字母结尾的总出生比例的新表：
- en: '[PRE68]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'With the letter proportions now in hand, we can make bar plots for each sex,
    broken down by year (see [Proportion of boy and girl names ending in each letter](#baby_names_last_letter)):'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 现在有了字母比例，我们可以按年份将每个性别分解为条形图（参见[以每个字母结尾的男孩和女孩名字的比例](#baby_names_last_letter)）：
- en: '[PRE69]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '![](../Images/5f557600f8cbeb90fd07375592d49c18.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5f557600f8cbeb90fd07375592d49c18.png)'
- en: 'Figure 13.8: Proportion of boy and girl names ending in each letter'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.8：以每个字母结尾的男孩和女孩名字的比例
- en: 'As you can see, boy names ending in *n* have experienced significant growth
    since the 1960s. Going back to the full table created before, I again normalize
    by year and sex and select a subset of letters for the boy names, finally transposing
    to make each column a time series:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，自20世纪60年代以来，以*n*结尾的男孩名字经历了显著增长。回到之前创建的完整表格，再次按年份和性别进行标准化，并选择男孩名字的一部分字母，最后转置使每一列成为一个时间序列：
- en: '[PRE70]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'With this DataFrame of time series in hand, I can make a plot of the trends
    over time again with its `plot` method (see [Proportion of boys born with names
    ending in d/n/y over time](#baby_names_letter_over_time)):'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个时间序列的DataFrame，我可以再次使用其`plot`方法制作时间趋势图（请参见[随时间变化以d/n/y结尾的男孩出生比例](#baby_names_letter_over_time)）：
- en: '[PRE71]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '![](../Images/e7ac4057ad5de3681057e0690540ab39.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e7ac4057ad5de3681057e0690540ab39.png)'
- en: 'Figure 13.9: Proportion of boys born with names ending in d/n/y over time'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.9：随时间变化以d/n/y结尾的男孩出生比例
- en: Boy names that became girl names (and vice versa)
  id: totrans-190
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 男孩名字变成女孩名字（反之亦然）
- en: 'Another fun trend is looking at names that were more popular with one gender
    earlier in the sample but have become preferred as a name for the other gender
    over time. One example is the name Lesley or Leslie. Going back to the `top1000`
    DataFrame, I compute a list of names occurring in the dataset starting with "Lesl":'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有趣的趋势是查看在样本早期更受一性别欢迎，但随着时间推移已成为另一性别的首选名字的名字。一个例子是Lesley或Leslie这个名字。回到`top1000`
    DataFrame，我计算出数据集中以"Lesl"开头的名字列表：
- en: '[PRE72]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'From there, we can filter down to just those names and sum births grouped by
    name to see the relative frequencies:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以筛选出那些名字，按名字分组对出生进行求和，以查看相对频率：
- en: '[PRE73]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Next, let’s aggregate by sex and year, and normalize within year:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们按性别和年份进行聚合，并在年份内进行归一化：
- en: '[PRE74]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Lastly, it’s now possible to make a plot of the breakdown by sex over time
    (see [Proportion of male/female Lesley-like names over time](#baby_names_lesley)):'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，现在可以制作按性别随时间变化的分布图（请参见[随时间变化男/女Lesley样式名字的比例](#baby_names_lesley)）：
- en: '[PRE75]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '![](../Images/61d4a67e0c93651a04b70d68220275c0.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/61d4a67e0c93651a04b70d68220275c0.png)'
- en: 'Figure 13.10: Proportion of male/female Lesley-like names over time'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.10：随时间变化男/女Lesley样式名字的比例
- en: 13.4 USDA Food Database
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.4 USDA食品数据库
- en: 'The US Department of Agriculture (USDA) makes available a database of food
    nutrient information. Programmer Ashley Williams created a version of this database
    in JSON format. The records look like this:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 美国农业部（USDA）提供了一个食品营养信息数据库。程序员Ashley Williams以JSON格式创建了这个数据库的一个版本。记录看起来像这样：
- en: '[PRE76]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: Each food has a number of identifying attributes along with two lists of nutrients
    and portion sizes. Data in this form is not particularly amenable to analysis,
    so we need to do some work to wrangle the data into a better form.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 每种食物都有一些标识属性，还有两个营养素和分量大小的列表。这种形式的数据不太适合分析，因此我们需要做一些工作，将数据整理成更好的形式。
- en: 'You can load this file into Python with any JSON library of your choosing.
    I’ll use the built-in Python `json` module:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用您选择的任何JSON库将此文件加载到Python中。我将使用内置的Python `json`模块：
- en: '[PRE77]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Each entry in `db` is a dictionary containing all the data for a single food.
    The `"nutrients"` field is a list of dictionaries, one for each nutrient:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '`db`中的每个条目都是一个包含单个食物所有数据的字典。`"nutrients"`字段是一个字典列表，每个营养素一个：'
- en: '[PRE78]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'When converting a list of dictionaries to a DataFrame, we can specify a list
    of fields to extract. We’ll take the food names, group, ID, and manufacturer:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 将字典列表转换为DataFrame时，我们可以指定要提取的字段列表。我们将提取食物名称、组、ID和制造商：
- en: '[PRE79]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: From the output of `info.info()`, we can see that there is missing data in the
    `manufacturer` column.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 从`info.info()`的输出中，我们可以看到`manufacturer`列中有缺失数据。
- en: 'You can see the distribution of food groups with `value_counts`:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`value_counts`查看食物组的分布：
- en: '[PRE80]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Now, to do some analysis on all of the nutrient data, it’s easiest to assemble
    the nutrients for each food into a single large table. To do so, we need to take
    several steps. First, I’ll convert each list of food nutrients to a DataFrame,
    add a column for the food `id`, and append the DataFrame to a list. Then, these
    can be concatenated with `concat`. Run the following code in a Jupyter cell:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，要对所有营养数据进行一些分析，最简单的方法是将每种食物的营养成分组装成一个单独的大表格。为此，我们需要采取几个步骤。首先，我将把每个食物营养列表转换为一个DataFrame，添加一个食物“id”的列，并将DataFrame附加到列表中。然后，可以使用`concat`将它们连接起来。在Jupyter单元格中运行以下代码：
- en: '[PRE81]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'If all goes well, `nutrients` should look like this:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，`nutrients`应该是这样的：
- en: '[PRE82]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'I noticed that there are duplicates in this DataFrame, so it makes things easier
    to drop them:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我注意到这个DataFrame中有重复项，所以删除它们会更容易：
- en: '[PRE83]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Since `"group"` and `"description"` are in both DataFrame objects, we can rename
    for clarity:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 由于DataFrame对象中都有`"group"`和`"description"`，我们可以重命名以便更清晰：
- en: '[PRE84]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'With all of this done, we’re ready to merge `info` with `nutrients`:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 完成所有这些后，我们准备将`info`与`nutrients`合并：
- en: '[PRE85]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'We could now make a plot of median values by food group and nutrient type (see
    [Median zinc values by food group](#fig_wrangle_zinc)):'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以制作按食物组和营养类型中位数值的图表（请参见[各食物组的锌中位数值](#fig_wrangle_zinc)）：
- en: '[PRE86]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '![](../Images/c65abbdbb1b538d16ea4f45c46581a89.png)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c65abbdbb1b538d16ea4f45c46581a89.png)'
- en: 'Figure 13.11: Median zinc values by food group'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.11：各食物组的锌中位数值
- en: 'Using the `idxmax` or `argmax` Series methods, you can find which food is most
    dense in each nutrient. Run the following in a Jupyter cell:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`idxmax`或`argmax` Series方法，您可以找到每种营养素中最密集的食物。在Jupyter单元格中运行以下内容：
- en: '[PRE87]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'The resulting DataFrame is a bit too large to display in the book; here is
    only the `"Amino Acids"` nutrient group:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的DataFrame太大，无法在书中显示；这里只有`"Amino Acids"`营养组：
- en: '[PRE88]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 13.5 2012 Federal Election Commission Database
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.5 2012年联邦选举委员会数据库
- en: 'The US Federal Election Commission (FEC) publishes data on contributions to
    political campaigns. This includes contributor names, occupation and employer,
    address, and contribution amount. The contribution data from the 2012 US presidential
    election was available as a single 150-megabyte CSV file *P00000001-ALL.csv* (see
    the book''s data repository), which can be loaded with `pandas.read_csv`:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 美国联邦选举委员会（FEC）发布了有关政治竞选捐款的数据。这包括捐助者姓名、职业和雇主、地址以及捐款金额。2012年美国总统选举的捐款数据作为一个150兆字节的CSV文件*P00000001-ALL.csv*可用（请参阅本书的数据存储库），可以使用`pandas.read_csv`加载：
- en: '[PRE89]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '*Note* *Several people asked me to update the dataset from the 2012 election
    to the 2016 or 2020 elections. Unfortunately, the more recent datasets provided
    by the FEC have become larger and more complex, and I decided that working with
    them here would be a distraction from the analysis techniques that I wanted to
    illustrate.*  *A sample record in the DataFrame looks like this:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '*注* *有几个人要求我将数据集从2012年选举更新到2016年或2020年选举。不幸的是，联邦选举委员会提供的最新数据集变得更大更复杂，我决定在这里使用它们会分散我想要说明的分析技术。*
    *数据框中的一个示例记录如下：'
- en: '[PRE90]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: You may think of some ways to start slicing and dicing this data to extract
    informative statistics about donors and patterns in the campaign contributions.
    I’ll show you a number of different analyses that apply the techniques in this
    book.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会想到一些方法来开始切片和切块这些数据，以提取有关捐赠者和竞选捐款模式的信息统计。我将展示一些应用本书中技术的不同分析方法。
- en: 'You can see that there are no political party affiliations in the data, so
    this would be useful to add. You can get a list of all the unique political candidates
    using `unique`:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 您会发现数据中没有政党隶属关系，因此添加这些信息会很有用。您可以使用`unique`获取所有唯一的政治候选人列表：
- en: '[PRE91]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: One way to indicate party affiliation is using a dictionary:[¹](#fn1)
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 表示政党隶属关系的一种方法是使用字典：[¹](#fn1)
- en: '[PRE92]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'Now, using this mapping and the `map` method on Series objects, you can compute
    an array of political parties from the candidate names:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，使用这个映射和Series对象上的`map`方法，您可以从候选人姓名计算一个政党数组：
- en: '[PRE93]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'A couple of data preparation points. First, this data includes both contributions
    and refunds (negative contribution amount):'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 一些数据准备要点。首先，这些数据包括捐款和退款（负捐款金额）：
- en: '[PRE94]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'To simplify the analysis, I’ll restrict the dataset to positive contributions:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 为简化分析，我将限制数据集为正捐款：
- en: '[PRE95]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'Since Barack Obama and Mitt Romney were the main two candidates, I’ll also
    prepare a subset that just has contributions to their campaigns:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 由于巴拉克·奥巴马和米特·罗姆尼是主要的两位候选人，我还将准备一个只包含对他们竞选活动的捐款的子集：
- en: '[PRE96]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: Donation Statistics by Occupation and Employer
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 按职业和雇主的捐款统计
- en: 'Donations by occupation is another oft-studied statistic. For example, attorneys
    tend to donate more money to Democrats, while business executives tend to donate
    more to Republicans. You have no reason to believe me; you can see for yourself
    in the data. First, the total number of donations by occupation can be computed
    with `value_counts`:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 按职业捐款是另一个经常研究的统计数据。例如，律师倾向于向民主党捐款更多，而商业高管倾向于向共和党捐款更多。您没有理由相信我；您可以在数据中自己看到。首先，可以使用`value_counts`计算每个职业的总捐款数：
- en: '[PRE97]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'You will notice by looking at the occupations that many refer to the same basic
    job type, or there are several variants of the same thing. The following code
    snippet illustrates a technique for cleaning up a few of them by mapping from
    one occupation to another; note the “trick” of using `dict.get` to allow occupations
    with no mapping to “pass through”:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看职业，您会注意到许多职业都指的是相同的基本工作类型，或者有几种相同事物的变体。以下代码片段演示了一种通过从一个职业映射到另一个职业来清理其中一些职业的技术；请注意使用`dict.get`的“技巧”，以允许没有映射的职业“通过”：
- en: '[PRE98]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'I’ll also do the same thing for employers:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 我也会为雇主做同样的事情：
- en: '[PRE99]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'Now, you can use `pivot_table` to aggregate the data by party and occupation,
    then filter down to the subset that donated at least $2 million overall:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以使用`pivot_table`按政党和职业对数据进行聚合，然后筛选出总捐款至少为200万美元的子集：
- en: '[PRE100]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: 'It can be easier to look at this data graphically as a bar plot (`"barh"` means
    horizontal bar plot; see [Total donations by party for top occupations](#groupby_fec_occ_party)):'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据以条形图形式更容易查看（“barh”表示水平条形图；请参见[按职业和政党分组的总捐款](#groupby_fec_occ_party)）：
- en: '[PRE101]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: '![](../Images/f4e8c3c83f755658e00aaadb7414d336.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f4e8c3c83f755658e00aaadb7414d336.png)'
- en: 'Figure 13.12: Total donations by party for top occupations'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.12：按职业分组的政党总捐款
- en: 'You might be interested in the top donor occupations or top companies that
    donated to Obama and Romney. To do this, you can group by candidate name and use
    a variant of the `top` method from earlier in the chapter:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能对捐赠最多的职业或向奥巴马和罗姆尼捐款最多的公司感兴趣。为此，您可以按候选人姓名分组，并使用本章早期的`top`方法的变体：
- en: '[PRE102]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'Then aggregate by occupation and employer:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 然后按职业和雇主进行汇总：
- en: '[PRE103]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: Bucketing Donation Amounts
  id: totrans-267
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将捐款金额分桶
- en: 'A useful way to analyze this data is to use the `cut` function to discretize
    the contributor amounts into buckets by contribution size:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 分析这些数据的一个有用方法是使用`cut`函数将捐助金额分成不同的桶：
- en: '[PRE104]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: 'We can then group the data for Obama and Romney by name and bin label to get
    a histogram by donation size:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以按姓名和bin标签对Obama和Romney的数据进行分组，以获得按捐款大小分组的直方图：
- en: '[PRE105]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: 'This data shows that Obama received a significantly larger number of small
    donations than Romney. You can also sum the contribution amounts and normalize
    within buckets to visualize the percentage of total donations of each size by
    candidate ([Percentage of total donations received by candidates for each donation
    size](#fig_groupby_fec_bucket) shows the resulting plot):'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据显示，奥巴马收到的小额捐款数量明显多于罗姆尼。您还可以对捐款金额进行求和，并在桶内进行归一化，以可视化每个候选人每个大小的总捐款的百分比（[每个捐款大小收到的候选人总捐款的百分比](#fig_groupby_fec_bucket)显示了结果图）：
- en: '[PRE106]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: '![](../Images/e84a484574c968c98c4258588ab07435.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e84a484574c968c98c4258588ab07435.png)'
- en: 'Figure 13.13: Percentage of total donations received by candidates for each
    donation size'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.13：每个捐款大小收到的候选人总捐款的百分比
- en: I excluded the two largest bins, as these are not donations by individuals.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 我排除了两个最大的桶，因为这些不是个人捐款。
- en: This analysis can be refined and improved in many ways. For example, you could
    aggregate donations by donor name and zip code to adjust for donors who gave many
    small amounts versus one or more large donations. I encourage you to explore the
    dataset yourself.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 这种分析可以以许多方式进行细化和改进。例如，您可以按捐赠人姓名和邮政编码对捐款进行汇总，以调整给出许多小额捐款与一笔或多笔大额捐款的捐赠者。我鼓励您自己探索数据集。
- en: Donation Statistics by State
  id: totrans-278
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 按州的捐款统计
- en: 'We can start by aggregating the data by candidate and state:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过候选人和州对数据进行汇总：
- en: '[PRE107]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: 'If you divide each row by the total contribution amount, you get the relative
    percentage of total donations by state for each candidate:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您将每一行都除以总捐款金额，您将得到每位候选人每个州的总捐款相对百分比：
- en: '[PRE108]*  *## 13.6 Conclusion'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '* * * '
- en: We've reached the end of this book. I have included some additional content
    you may find useful in the appendixes.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '## 13.6 结论'
- en: In the 10 years since the first edition of this book was published, Python has
    become a popular and widespread language for data analysis. The programming skills
    you have developed here will stay relevant for a long time into the future. I
    hope the programming tools and libraries we've explored will serve you well.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书第一版出版以来的10年里，Python已经成为数据分析中流行和广泛使用的语言。您在这里所学习的编程技能将在未来很长一段时间内保持相关性。希望我们探讨过的编程工具和库能够为您提供帮助。
- en: '* * *'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经到达了这本书的结尾。我在附录中包含了一些您可能会发现有用的额外内容。
- en: This makes the simplifying assumption that Gary Johnson is a Republican even
    though he later became the Libertarian party candidate.[↩︎](#fnref1)**
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这做出了一个简化的假设，即Gary Johnson是共和党人，尽管后来成为了自由党候选人。
