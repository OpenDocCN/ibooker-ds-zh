["```py\nIn [12]: data = pd.DataFrame({\n ....:     'x0': [1, 2, 3, 4, 5],\n ....:     'x1': [0.01, -0.01, 0.25, -4.1, 0.],\n ....:     'y': [-1.5, 0., 3.6, 1.3, -2.]})\n\nIn [13]: data\nOut[13]: \n x0    x1    y\n0   1  0.01 -1.5\n1   2 -0.01  0.0\n2   3  0.25  3.6\n3   4 -4.10  1.3\n4   5  0.00 -2.0\n\nIn [14]: data.columns\nOut[14]: Index(['x0', 'x1', 'y'], dtype='object')\n\nIn [15]: data.to_numpy()\nOut[15]: \narray([[ 1.  ,  0.01, -1.5 ],\n [ 2.  , -0.01,  0.  ],\n [ 3.  ,  0.25,  3.6 ],\n [ 4.  , -4.1 ,  1.3 ],\n [ 5.  ,  0.  , -2.  ]])\n```", "```py\nIn [16]: df2 = pd.DataFrame(data.to_numpy(), columns=['one', 'two', 'three'])\n\nIn [17]: df2\nOut[17]: \n one   two  three\n0  1.0  0.01   -1.5\n1  2.0 -0.01    0.0\n2  3.0  0.25    3.6\n3  4.0 -4.10    1.3\n4  5.0  0.00   -2.0\n```", "```py\nIn [18]: df3 = data.copy()\n\nIn [19]: df3['strings'] = ['a', 'b', 'c', 'd', 'e']\n\nIn [20]: df3\nOut[20]: \n x0    x1    y strings\n0   1  0.01 -1.5       a\n1   2 -0.01  0.0       b\n2   3  0.25  3.6       c\n3   4 -4.10  1.3       d\n4   5  0.00 -2.0       e\n\nIn [21]: df3.to_numpy()\nOut[21]: \narray([[1, 0.01, -1.5, 'a'],\n [2, -0.01, 0.0, 'b'],\n [3, 0.25, 3.6, 'c'],\n [4, -4.1, 1.3, 'd'],\n [5, 0.0, -2.0, 'e']], dtype=object)\n```", "```py\nIn [22]: model_cols = ['x0', 'x1']\n\nIn [23]: data.loc[:, model_cols].to_numpy()\nOut[23]: \narray([[ 1.  ,  0.01],\n [ 2.  , -0.01],\n [ 3.  ,  0.25],\n [ 4.  , -4.1 ],\n [ 5.  ,  0.  ]])\n```", "```py\nIn [24]: data['category'] = pd.Categorical(['a', 'b', 'a', 'a', 'b'],\n ....:                                   categories=['a', 'b'])\n\nIn [25]: data\nOut[25]: \n x0    x1    y category\n0   1  0.01 -1.5        a\n1   2 -0.01  0.0        b\n2   3  0.25  3.6        a\n3   4 -4.10  1.3        a\n4   5  0.00 -2.0        b\n```", "```py\nIn [26]: dummies = pd.get_dummies(data.category, prefix='category',\n ....:                          dtype=float)\n\nIn [27]: data_with_dummies = data.drop('category', axis=1).join(dummies)\n\nIn [28]: data_with_dummies\nOut[28]: \n x0    x1    y  category_a  category_b\n0   1  0.01 -1.5         1.0         0.0\n1   2 -0.01  0.0         0.0         1.0\n2   3  0.25  3.6         1.0         0.0\n3   4 -4.10  1.3         1.0         0.0\n4   5  0.00 -2.0         0.0         1.0\n```", "```py\nconda install statsmodels\n```", "```py\ny ~ x0 + x1\n```", "```py\nIn [29]: data = pd.DataFrame({\n ....:     'x0': [1, 2, 3, 4, 5],\n ....:     'x1': [0.01, -0.01, 0.25, -4.1, 0.],\n ....:     'y': [-1.5, 0., 3.6, 1.3, -2.]})\n\nIn [30]: data\nOut[30]: \n x0    x1    y\n0   1  0.01 -1.5\n1   2 -0.01  0.0\n2   3  0.25  3.6\n3   4 -4.10  1.3\n4   5  0.00 -2.0\n\nIn [31]: import patsy\n\nIn [32]: y, X = patsy.dmatrices('y ~ x0 + x1', data)\n```", "```py\nIn [33]: y\nOut[33]: \nDesignMatrix with shape (5, 1)\n y\n -1.5\n 0.0\n 3.6\n 1.3\n -2.0\n Terms:\n 'y' (column 0)\n\nIn [34]: X\nOut[34]: \nDesignMatrix with shape (5, 3)\n Intercept  x0     x1\n 1   1   0.01\n 1   2  -0.01\n 1   3   0.25\n 1   4  -4.10\n 1   5   0.00\n Terms:\n 'Intercept' (column 0)\n 'x0' (column 1)\n 'x1' (column 2)\n```", "```py\nIn [35]: np.asarray(y)\nOut[35]: \narray([[-1.5],\n [ 0. ],\n [ 3.6],\n [ 1.3],\n [-2. ]])\n\nIn [36]: np.asarray(X)\nOut[36]: \narray([[ 1.  ,  1.  ,  0.01],\n [ 1.  ,  2.  , -0.01],\n [ 1.  ,  3.  ,  0.25],\n [ 1.  ,  4.  , -4.1 ],\n [ 1.  ,  5.  ,  0.  ]])\n```", "```py\nIn [37]: patsy.dmatrices('y ~ x0 + x1 + 0', data)[1]\nOut[37]: \nDesignMatrix with shape (5, 2)\n x0     x1\n 1   0.01\n 2  -0.01\n 3   0.25\n 4  -4.10\n 5   0.00\n Terms:\n 'x0' (column 0)\n 'x1' (column 1)\n```", "```py\nIn [38]: coef, resid, _, _ = np.linalg.lstsq(X, y, rcond=None)\n```", "```py\nIn [39]: coef\nOut[39]: \narray([[ 0.3129],\n [-0.0791],\n [-0.2655]])\n\nIn [40]: coef = pd.Series(coef.squeeze(), index=X.design_info.column_names)\n\nIn [41]: coef\nOut[41]: \nIntercept    0.312910\nx0          -0.079106\nx1          -0.265464\ndtype: float64\n```", "```py\nIn [42]: y, X = patsy.dmatrices('y ~ x0 + np.log(np.abs(x1) + 1)', data)\n\nIn [43]: X\nOut[43]: \nDesignMatrix with shape (5, 3)\n Intercept  x0  np.log(np.abs(x1) + 1)\n 1   1                 0.00995\n 1   2                 0.00995\n 1   3                 0.22314\n 1   4                 1.62924\n 1   5                 0.00000\n Terms:\n 'Intercept' (column 0)\n 'x0' (column 1)\n 'np.log(np.abs(x1) + 1)' (column 2)\n```", "```py\nIn [44]: y, X = patsy.dmatrices('y ~ standardize(x0) + center(x1)', data)\n\nIn [45]: X\nOut[45]: \nDesignMatrix with shape (5, 3)\n Intercept  standardize(x0)  center(x1)\n 1         -1.41421        0.78\n 1         -0.70711        0.76\n 1          0.00000        1.02\n 1          0.70711       -3.33\n 1          1.41421        0.77\n Terms:\n 'Intercept' (column 0)\n 'standardize(x0)' (column 1)\n 'center(x1)' (column 2)\n```", "```py\nIn [46]: new_data = pd.DataFrame({\n ....:     'x0': [6, 7, 8, 9],\n ....:     'x1': [3.1, -0.5, 0, 2.3],\n ....:     'y': [1, 2, 3, 4]})\n\nIn [47]: new_X = patsy.build_design_matrices([X.design_info], new_data)\n\nIn [48]: new_X\nOut[48]: \n[DesignMatrix with shape (4, 3)\n Intercept  standardize(x0)  center(x1)\n 1          2.12132        3.87\n 1          2.82843        0.27\n 1          3.53553        0.77\n 1          4.24264        3.07\n Terms:\n 'Intercept' (column 0)\n 'standardize(x0)' (column 1)\n 'center(x1)' (column 2)]\n```", "```py\nIn [49]: y, X = patsy.dmatrices('y ~ I(x0 + x1)', data)\n\nIn [50]: X\nOut[50]: \nDesignMatrix with shape (5, 2)\n Intercept  I(x0 + x1)\n 1        1.01\n 1        1.99\n 1        3.25\n 1       -0.10\n 1        5.00\n Terms:\n 'Intercept' (column 0)\n 'I(x0 + x1)' (column 1)\n```", "```py\nIn [51]: data = pd.DataFrame({\n ....:     'key1': ['a', 'a', 'b', 'b', 'a', 'b', 'a', 'b'],\n ....:     'key2': [0, 1, 0, 1, 0, 1, 0, 0],\n ....:     'v1': [1, 2, 3, 4, 5, 6, 7, 8],\n ....:     'v2': [-1, 0, 2.5, -0.5, 4.0, -1.2, 0.2, -1.7]\n ....: })\n\nIn [52]: y, X = patsy.dmatrices('v2 ~ key1', data)\n\nIn [53]: X\nOut[53]: \nDesignMatrix with shape (8, 2)\n Intercept  key1[T.b]\n 1          0\n 1          0\n 1          1\n 1          1\n 1          0\n 1          1\n 1          0\n 1          1\n Terms:\n 'Intercept' (column 0)\n 'key1' (column 1)\n```", "```py\nIn [54]: y, X = patsy.dmatrices('v2 ~ key1 + 0', data)\n\nIn [55]: X\nOut[55]: \nDesignMatrix with shape (8, 2)\n key1[a]  key1[b]\n 1        0\n 1        0\n 0        1\n 0        1\n 1        0\n 0        1\n 1        0\n 0        1\n Terms:\n 'key1' (columns 0:2)\n```", "```py\nIn [56]: y, X = patsy.dmatrices('v2 ~ C(key2)', data)\n\nIn [57]: X\nOut[57]: \nDesignMatrix with shape (8, 2)\n Intercept  C(key2)[T.1]\n 1             0\n 1             1\n 1             0\n 1             1\n 1             0\n 1             1\n 1             0\n 1             0\n Terms:\n 'Intercept' (column 0)\n 'C(key2)' (column 1)\n```", "```py\nIn [58]: data['key2'] = data['key2'].map({0: 'zero', 1: 'one'})\n\nIn [59]: data\nOut[59]: \n key1  key2  v1   v2\n0    a  zero   1 -1.0\n1    a   one   2  0.0\n2    b  zero   3  2.5\n3    b   one   4 -0.5\n4    a  zero   5  4.0\n5    b   one   6 -1.2\n6    a  zero   7  0.2\n7    b  zero   8 -1.7\n\nIn [60]: y, X = patsy.dmatrices('v2 ~ key1 + key2', data)\n\nIn [61]: X\nOut[61]: \nDesignMatrix with shape (8, 3)\n Intercept  key1[T.b]  key2[T.zero]\n 1          0             1\n 1          0             0\n 1          1             1\n 1          1             0\n 1          0             1\n 1          1             0\n 1          0             1\n 1          1             1\n Terms:\n 'Intercept' (column 0)\n 'key1' (column 1)\n 'key2' (column 2)\n\nIn [62]: y, X = patsy.dmatrices('v2 ~ key1 + key2 + key1:key2', data)\n\nIn [63]: X\nOut[63]: \nDesignMatrix with shape (8, 4)\n Intercept  key1[T.b]  key2[T.zero]  key1[T.b]:key2[T.zero]\n 1          0             1                       0\n 1          0             0                       0\n 1          1             1                       1\n 1          1             0                       0\n 1          0             1                       0\n 1          1             0                       0\n 1          0             1                       0\n 1          1             1                       1\n Terms:\n 'Intercept' (column 0)\n 'key1' (column 1)\n 'key2' (column 2)\n 'key1:key2' (column 3)\n```", "```py\nconda install statsmodels\n```", "```py\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n```", "```py\n# To make the example reproducible\nrng = np.random.default_rng(seed=12345)\n\ndef dnorm(mean, variance, size=1):\n if isinstance(size, int):\n size = size,\n return mean + np.sqrt(variance) * rng.standard_normal(*size)\n\nN = 100\nX = np.c_[dnorm(0, 0.4, size=N),\n dnorm(0, 0.6, size=N),\n dnorm(0, 0.2, size=N)]\neps = dnorm(0, 0.1, size=N)\nbeta = [0.1, 0.3, 0.5]\n\ny = np.dot(X, beta) + eps\n```", "```py\nIn [66]: X[:5]\nOut[66]: \narray([[-0.9005, -0.1894, -1.0279],\n [ 0.7993, -1.546 , -0.3274],\n [-0.5507, -0.1203,  0.3294],\n [-0.1639,  0.824 ,  0.2083],\n [-0.0477, -0.2131, -0.0482]])\n\nIn [67]: y[:5]\nOut[67]: array([-0.5995, -0.5885,  0.1856, -0.0075, -0.0154])\n```", "```py\nIn [68]: X_model = sm.add_constant(X)\n\nIn [69]: X_model[:5]\nOut[69]: \narray([[ 1.    , -0.9005, -0.1894, -1.0279],\n [ 1.    ,  0.7993, -1.546 , -0.3274],\n [ 1.    , -0.5507, -0.1203,  0.3294],\n [ 1.    , -0.1639,  0.824 ,  0.2083],\n [ 1.    , -0.0477, -0.2131, -0.0482]])\n```", "```py\nIn [70]: model = sm.OLS(y, X)\n```", "```py\nIn [71]: results = model.fit()\n\nIn [72]: results.params\nOut[72]: array([0.0668, 0.268 , 0.4505])\n```", "```py\nIn [73]: print(results.summary())\nOLS Regression Results \n=================================================================================\n======\nDep. Variable:                      y   R-squared (uncentered): \n 0.469\nModel:                            OLS   Adj. R-squared (uncentered): \n 0.452\nMethod:                 Least Squares   F-statistic: \n 28.51\nDate:                Wed, 12 Apr 2023   Prob (F-statistic):                    2.\n66e-13\nTime:                        13:09:20   Log-Likelihood:                         -\n25.611\nNo. Observations:                 100   AIC: \n 57.22\nDf Residuals:                      97   BIC: \n 65.04\nDf Model:                           3 \n\nCovariance Type:            nonrobust \n\n==============================================================================\n coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nx1             0.0668      0.054      1.243      0.217      -0.040       0.174\nx2             0.2680      0.042      6.313      0.000       0.184       0.352\nx3             0.4505      0.068      6.605      0.000       0.315       0.586\n==============================================================================\nOmnibus:                        0.435   Durbin-Watson:                   1.869\nProb(Omnibus):                  0.805   Jarque-Bera (JB):                0.301\nSkew:                           0.134   Prob(JB):                        0.860\nKurtosis:                       2.995   Cond. No.                         1.64\n==============================================================================\nNotes:\n[1] R\u00b2 is computed without centering (uncentered) since the model does not contai\nn a constant.\n[2] Standard Errors assume that the covariance matrix of the errors is correctly \nspecified.\n```", "```py\nIn [74]: data = pd.DataFrame(X, columns=['col0', 'col1', 'col2'])\n\nIn [75]: data['y'] = y\n\nIn [76]: data[:5]\nOut[76]: \n col0      col1      col2         y\n0 -0.900506 -0.189430 -1.027870 -0.599527\n1  0.799252 -1.545984 -0.327397 -0.588454\n2 -0.550655 -0.120254  0.329359  0.185634\n3 -0.163916  0.824040  0.208275 -0.007477\n4 -0.047651 -0.213147 -0.048244 -0.015374\n```", "```py\nIn [77]: results = smf.ols('y ~ col0 + col1 + col2', data=data).fit()\n\nIn [78]: results.params\nOut[78]: \nIntercept   -0.020799\ncol0         0.065813\ncol1         0.268970\ncol2         0.449419\ndtype: float64\n\nIn [79]: results.tvalues\nOut[79]: \nIntercept   -0.652501\ncol0         1.219768\ncol1         6.312369\ncol2         6.567428\ndtype: float64\n```", "```py\nIn [80]: results.predict(data[:5])\nOut[80]: \n0   -0.592959\n1   -0.531160\n2    0.058636\n3    0.283658\n4   -0.102947\ndtype: float64\n```", "```py\ninit_x = 4\n\nvalues = [init_x, init_x]\nN = 1000\n\nb0 = 0.8\nb1 = -0.4\nnoise = dnorm(0, 0.1, N)\nfor i in range(N):\n new_x = values[-1] * b0 + values[-2] * b1 + noise[i]\n values.append(new_x)\n```", "```py\nIn [82]: from statsmodels.tsa.ar_model import AutoReg\n\nIn [83]: MAXLAGS = 5\n\nIn [84]: model = AutoReg(values, MAXLAGS)\n\nIn [85]: results = model.fit()\n```", "```py\nIn [86]: results.params\nOut[86]: array([ 0.0235,  0.8097, -0.4287, -0.0334,  0.0427, -0.0567])\n```", "```py\nconda install scikit-learn\n```", "```py\nIn [87]: train = pd.read_csv('datasets/titanic/train.csv')\n\nIn [88]: test = pd.read_csv('datasets/titanic/test.csv')\n\nIn [89]: train.head(4)\nOut[89]: \n PassengerId  Survived  Pclass \n0            1         0       3  \\\n1            2         1       1 \n2            3         1       3 \n3            4         1       1 \n Name     Sex   Age  SibSp \n0                              Braund, Mr. Owen Harris    male  22.0      1  \\\n1  Cumings, Mrs. John Bradley (Florence Briggs Thayer)  female  38.0      1 \n2                               Heikkinen, Miss. Laina  female  26.0      0 \n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1 \n Parch            Ticket     Fare Cabin Embarked \n0      0         A/5 21171   7.2500   NaN        S \n1      0          PC 17599  71.2833   C85        C \n2      0  STON/O2\\. 3101282   7.9250   NaN        S \n3      0            113803  53.1000  C123        S \n```", "```py\nIn [90]: train.isna().sum()\nOut[90]: \nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\nIn [91]: test.isna().sum()\nOut[91]: \nPassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n```", "```py\nIn [92]: impute_value = train['Age'].median()\n\nIn [93]: train['Age'] = train['Age'].fillna(impute_value)\n\nIn [94]: test['Age'] = test['Age'].fillna(impute_value)\n```", "```py\nIn [95]: train['IsFemale'] = (train['Sex'] == 'female').astype(int)\n\nIn [96]: test['IsFemale'] = (test['Sex'] == 'female').astype(int)\n```", "```py\nIn [97]: predictors = ['Pclass', 'IsFemale', 'Age']\n\nIn [98]: X_train = train[predictors].to_numpy()\n\nIn [99]: X_test = test[predictors].to_numpy()\n\nIn [100]: y_train = train['Survived'].to_numpy()\n\nIn [101]: X_train[:5]\nOut[101]: \narray([[ 3.,  0., 22.],\n [ 1.,  1., 38.],\n [ 3.,  1., 26.],\n [ 1.,  1., 35.],\n [ 3.,  0., 35.]])\n\nIn [102]: y_train[:5]\nOut[102]: array([0, 1, 1, 1, 0])\n```", "```py\nIn [103]: from sklearn.linear_model import LogisticRegression\n\nIn [104]: model = LogisticRegression()\n```", "```py\nIn [105]: model.fit(X_train, y_train)\nOut[105]: LogisticRegression()\n```", "```py\nIn [106]: y_predict = model.predict(X_test)\n\nIn [107]: y_predict[:10]\nOut[107]: array([0, 0, 0, 0, 1, 0, 1, 0, 1, 0])\n```", "```py\n(y_true == y_predict).mean()\n```", "```py\nIn [108]: from sklearn.linear_model import LogisticRegressionCV\n\nIn [109]: model_cv = LogisticRegressionCV(Cs=10)\n\nIn [110]: model_cv.fit(X_train, y_train)\nOut[110]: LogisticRegressionCV()\n```", "```py\nIn [111]: from sklearn.model_selection import cross_val_score\n\nIn [112]: model = LogisticRegression(C=10)\n\nIn [113]: scores = cross_val_score(model, X_train, y_train, cv=4)\n\nIn [114]: scores\nOut[114]: array([0.7758, 0.7982, 0.7758, 0.7883])\n```"]