- en: 12  Introduction to Modeling Libraries in Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://wesmckinney.com/book/modeling](https://wesmckinney.com/book/modeling)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*This Open Access web version of *Python for Data Analysis 3rd Edition* is
    now available as a companion to the [print and digital editions](https://amzn.to/3DyLaJc).
    If you encounter any errata, [please report them here](https://oreilly.com/catalog/0636920519829/errata).
    Please note that some aspects of this site as produced by Quarto will differ from
    the formatting of the print and eBook versions from O’Reilly.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: If you find the online edition of the book useful, please consider [ordering
    a paper copy](https://amzn.to/3DyLaJc) or a [DRM-free eBook](https://www.ebooks.com/en-us/book/210644288/python-for-data-analysis/wes-mckinney/?affId=WES398681F)
    to support the author. The content from this website may not be copied or reproduced.
    The code examples are MIT licensed and can be found on GitHub or Gitee.*  *In
    this book, I have focused on providing a programming foundation for doing data
    analysis in Python. Since data analysts and scientists often report spending a
    disproportionate amount of time with data wrangling and preparation, the book's
    structure reflects the importance of mastering these techniques.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Which library you use for developing models will depend on the application.
    Many statistical problems can be solved by simpler techniques like ordinary least
    squares regression, while other problems may call for more advanced machine learning
    methods. Fortunately, Python has become one of the languages of choice for implementing
    analytical methods, so there are many tools you can explore after completing this
    book.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, I will review some features of pandas that may be helpful when
    you're crossing back and forth between data wrangling with pandas and model fitting
    and scoring. I will then give short introductions to two popular modeling toolkits,
    [statsmodels](http://statsmodels.org) and [scikit-learn](http://scikit-learn.org).
    Since each of these projects is large enough to warrant its own dedicated book,
    I make no effort to be comprehensive and instead direct you to both projects'
    online documentation along with some other Python-based books on data science,
    statistics, and machine learning.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: 12.1 Interfacing Between pandas and Model Code
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A common workflow for model development is to use pandas for data loading and
    cleaning before switching over to a modeling library to build the model itself.
    An important part of the model development process is called *feature engineering*
    in machine learning. This can describe any data transformation or analytics that
    extract information from a raw dataset that may be useful in a modeling context.
    The data aggregation and GroupBy tools we have explored in this book are used
    often in a feature engineering context.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: While details of "good" feature engineering are out of scope for this book,
    I will show some methods to make switching between data manipulation with pandas
    and modeling as painless as possible.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: 'The point of contact between pandas and other analysis libraries is usually
    NumPy arrays. To turn a DataFrame into a NumPy array, use the `to_numpy` method:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To convert back to a DataFrame, as you may recall from earlier chapters, you
    can pass a two-dimensional ndarray with optional column names:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The `to_numpy` method is intended to be used when your data is homogeneous—for
    example, all numeric types. If you have heterogeneous data, the result will be
    an ndarray of Python objects:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'For some models, you may wish to use only a subset of the columns. I recommend
    using `loc` indexing with `to_numpy`:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Some libraries have native support for pandas and do some of this work for
    you automatically: converting to NumPy from DataFrame and attaching model parameter
    names to the columns of output tables or Series. In other cases, you will have
    to perform this "metadata management" manually.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: 'In [Ch 7.5: Categorical Data](/book/data-cleaning#pandas-categorical), we looked
    at pandas''s `Categorical` type and the `pandas.get_dummies` function. Suppose
    we had a nonnumeric column in our example dataset:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'If we wanted to replace the `''category''` column with dummy variables, we
    create dummy variables, drop the `''category''` column, and then join the result:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: There are some nuances to fitting certain statistical models with dummy variables.
    It may be simpler and less error-prone to use Patsy (the subject of the next section)
    when you have more than simple numeric columns.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: 12.2 Creating Model Descriptions with Patsy
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Patsy](https://patsy.readthedocs.io/) is a Python library for describing statistical
    models (especially linear models) with a string-based "formula syntax," which
    is inspired by (but not exactly the same as) the formula syntax used by the R
    and S statistical programming languages. It is installed automatically when you
    install statsmodels:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Patsy is well supported for specifying linear models in statsmodels, so I will
    focus on some of the main features to help you get up and running. Patsy''s *formulas*
    are a special string syntax that looks like:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The syntax `a + b` does not mean to add `a` to `b`, but rather that these are
    *terms* in the *design matrix* created for the model. The `patsy.dmatrices` function
    takes a formula string along with a dataset (which can be a DataFrame or a dictionary
    of arrays) and produces design matrices for a linear model:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now we have:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'These Patsy `DesignMatrix` instances are NumPy ndarrays with additional metadata:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You might wonder where the `Intercept` term came from. This is a convention
    for linear models like ordinary least squares (OLS) regression. You can suppress
    the intercept by adding the term `+ 0` to the model:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The Patsy objects can be passed directly into algorithms like `numpy.linalg.lstsq`,
    which performs an ordinary least squares regression:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The model metadata is retained in the `design_info` attribute, so you can reattach
    the model column names to the fitted coefficients to obtain a Series, for example:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Data Transformations in Patsy Formulas
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can mix Python code into your Patsy formulas; when evaluating the formula,
    the library will try to find the functions you use in the enclosing scope:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Some commonly used variable transformations include *standardizing* (to mean
    0 and variance 1) and *centering* (subtracting the mean). Patsy has built-in functions
    for this purpose:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: As part of a modeling process, you may fit a model on one dataset, then evaluate
    the model based on another. This might be a *hold-out* portion or new data that
    is observed later. When applying transformations like center and standardize,
    you should be careful when using the model to form predications based on new data.
    These are called *stateful* transformations, because you must use statistics like
    the mean or standard deviation of the original dataset when transforming a new
    dataset.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: 'The `patsy.build_design_matrices` function can apply transformations to new
    *out-of-sample* data using the saved information from the original *in-sample*
    dataset:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Because the plus symbol (`+`) in the context of Patsy formulas does not mean
    addition, when you want to add columns from a dataset by name, you must wrap them
    in the special `I` function:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Patsy has several other built-in transforms in the `patsy.builtins` module.
    See the online documentation for more.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: Categorical data has a special class of transformations, which I explain next.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: Categorical Data and Patsy
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Nonnumeric data can be transformed for a model design matrix in many different
    ways. A complete treatment of this topic is outside the scope of this book and
    would be studied best along with a course in statistics.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: 'When you use nonnumeric terms in a Patsy formula, they are converted to dummy
    variables by default. If there is an intercept, one of the levels will be left
    out to avoid collinearity:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'If you omit the intercept from the model, then columns for each category value
    will be included in the model design matrix:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Numeric columns can be interpreted as categorical with the `C` function:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'When you''re using multiple categorical terms in a model, things can be more
    complicated, as you can include interaction terms of the form `key1:key2`, which
    can be used, for example, in analysis of variance (ANOVA) models:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Patsy provides for other ways to transform categorical data, including transformations
    for terms with a particular ordering. See the online documentation for more.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: 12.3 Introduction to statsmodels
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[statsmodels](http://www.statsmodels.org) is a Python library for fitting many
    kinds of statistical models, performing statistical tests, and data exploration
    and visualization. statsmodels contains more "classical" frequentist statistical
    methods, while Bayesian methods and machine learning models are found in other
    libraries.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: 'Some kinds of models found in statsmodels include:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: Linear models, generalized linear models, and robust linear models
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linear mixed effects models
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analysis of variance (ANOVA) methods
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time series processes and state space models
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generalized method of moments
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the next few pages, we will use a few basic tools in statsmodels and explore
    how to use the modeling interfaces with Patsy formulas and pandas DataFrame objects.
    If you didn''t install statsmodels in the Patsy discussion earlier, you can install
    it now with:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Estimating Linear Models
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are several kinds of linear regression models in statsmodels, from the
    more basic (e.g., ordinary least squares) to more complex (e.g., iteratively reweighted
    least squares).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: 'Linear models in statsmodels have two different main interfaces: array based
    and formula based. These are accessed through these API module imports:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'To show how to use these, we generate a linear model from some random data.
    Run the following code in a Jupyter cell:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Here, I wrote down the "true" model with known parameters `beta`. In this case,
    `dnorm` is a helper function for generating normally distributed data with a particular
    mean and variance. So now we have:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'A linear model is generally fitted with an intercept term, as we saw before
    with Patsy. The `sm.add_constant` function can add an intercept column to an existing
    matrix:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The `sm.OLS` class can fit an ordinary least squares linear regression:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The model''s `fit` method returns a regression results object containing estimated
    model parameters and other diagnostics:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The `summary` method on `results` can print a model detailing diagnostic output
    of the model:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The parameter names here have been given the generic names `x1, x2`, and so
    on. Suppose instead that all of the model parameters are in a DataFrame:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now we can use the statsmodels formula API and Patsy formula strings:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Observe how statsmodels has returned results as Series with the DataFrame column
    names attached. We also do not need to use `add_constant` when using formulas
    and pandas objects.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: 'Given new out-of-sample data, you can compute predicted values given the estimated
    model parameters:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: There are many additional tools for analysis, diagnostics, and visualization
    of linear model results in statsmodels that you can explore. There are also other
    kinds of linear models beyond ordinary least squares.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Estimating Time Series Processes
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another class of models in statsmodels is for time series analysis. Among these
    are autoregressive processes, Kalman filtering and other state space models, and
    multivariate autoregressive models.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s simulate some time series data with an autoregressive structure and
    noise. Run the following in Jupyter:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This data has an AR(2) structure (two *lags*) with parameters `0.8` and `–0.4`.
    When you fit an AR model, you may not know the number of lagged terms to include,
    so you can fit the model with some larger number of lags:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The estimated parameters in the results have the intercept first, and the estimates
    for the first two lags next:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Deeper details of these models and how to interpret their results are beyond
    what I can cover in this book, but there's plenty more to discover in the statsmodels
    documentation.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: 12.4 Introduction to scikit-learn
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[scikit-learn](http://scikit-learn.org) is one of the most widely used and
    trusted general-purpose Python machine learning toolkits. It contains a broad
    selection of standard supervised and unsupervised machine learning methods, with
    tools for model selection and evaluation, data transformation, data loading, and
    model persistence. These models can be used for classification, clustering, prediction,
    and other common tasks. You can install scikit-learn from conda like so:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: There are excellent online and print resources for learning about machine learning
    and how to apply libraries like scikit-learn to solve real-world problems. In
    this section, I will give a brief flavor of the scikit-learn API style.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: pandas integration in scikit-learn has improved significantly in recent years,
    and by the time you are reading this it may have improved even more. I encourage
    you to check out the latest project documentation.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example for this chapter, I use a [now-classic dataset from a Kaggle
    competition](https://www.kaggle.com/c/titanic) about passenger survival rates
    on the *Titanic* in 1912\. We load the training and test datasets using pandas:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Libraries like statsmodels and scikit-learn generally cannot be fed missing
    data, so we look at the columns to see if there are any that contain missing data:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: In statistics and machine learning examples like this one, a typical task is
    to predict whether a passenger would survive based on features in the data. A
    model is fitted on a *training* dataset and then evaluated on an out-of-sample
    *testing* dataset.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: 'I would like to use `Age` as a predictor, but it has missing data. There are
    a number of ways to do missing data imputation, but I will do a simple one and
    use the median of the training dataset to fill the nulls in both tables:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Now we need to specify our models. I add a column `IsFemale` as an encoded
    version of the `''Sex''` column:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Then we decide on some model variables and create NumPy arrays:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'I make no claims that this is a good model or that these features are engineered
    properly. We use the `LogisticRegression` model from scikit-learn and create a
    model instance:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'We can fit this model to the training data using the model''s `fit` method:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Now, we can form predictions for the test dataset using `model.predict`:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'If you had the true values for the test dataset, you could compute an accuracy
    percentage or some other error metric:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: In practice, there are often many additional layers of complexity in model training.
    Many models have parameters that can be tuned, and there are techniques such as
    *cross-validation* that can be used for parameter tuning to avoid overfitting
    to the training data. This can often yield better predictive performance or robustness
    on new data.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: 'Cross-validation works by splitting the training data to simulate out-of-sample
    prediction. Based on a model accuracy score like mean squared error, you can perform
    a grid search on model parameters. Some models, like logistic regression, have
    estimator classes with built-in cross-validation. For example, the `LogisticRegressionCV`
    class can be used with a parameter indicating how fine-grained of a grid search
    to do on the model regularization parameter `C`:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'To do cross-validation by hand, you can use the `cross_val_score` helper function,
    which handles the data splitting process. For example, to cross-validate our model
    with four nonoverlapping splits of the training data, we can do:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: The default scoring metric is model dependent, but it is possible to choose
    an explicit scoring function. Cross-validated models take longer to train but
    can often yield better model performance.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: 12.5 Conclusion
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While I have only skimmed the surface of some Python modeling libraries, there
    are more and more frameworks for various kinds of statistics and machine learning
    either implemented in Python or with a Python user interface.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我只是浅尝了一些Python建模库的表面，但有越来越多的框架适用于各种统计和机器学习，要么是用Python实现的，要么有Python用户界面。
- en: 'This book is focused especially on data wrangling, but there are many others
    dedicated to modeling and data science tools. Some excellent ones are:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书专注于数据整理，但还有许多其他专门用于建模和数据科学工具的书籍。一些优秀的书籍包括：
- en: '*Introduction to Machine Learning with Python* by Andreas Müller and Sarah
    Guido (O''Reilly)'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 《Python机器学习入门》作者Andreas Müller和Sarah Guido（O'Reilly）
- en: '*Python Data Science Handbook* by Jake VanderPlas (O''Reilly)'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 《Python数据科学手册》作者Jake VanderPlas（O'Reilly）
- en: '*Data Science from Scratch: First Principles with Python* by Joel Grus (O''Reilly)'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 《从零开始的数据科学：Python基础》作者Joel Grus（O'Reilly）
- en: '*Python Machine Learning* by Sebastian Raschka and Vahid Mirjalili (Packt Publishing)'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 《Python机器学习》作者Sebastian Raschka和Vahid Mirjalili（Packt Publishing）
- en: '*Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow* by Aurélien
    Géron (O''Reilly)'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 《使用Scikit-Learn、Keras和TensorFlow进行实践机器学习》作者Aurélien Géron（O'Reilly）
- en: While books can be valuable resources for learning, they can sometimes grow
    out of date when the underlying open source software changes. It's a good idea
    to be familiar with the documentation for the various statistics or machine learning
    frameworks to stay up to date on the latest features and API.*
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管书籍可以是学习的宝贵资源，但当底层的开源软件发生变化时，它们有时会变得过时。熟悉各种统计或机器学习框架的文档是一个好主意，以便了解最新功能和API。
