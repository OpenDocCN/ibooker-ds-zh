- en: 7  Data Cleaning and Preparation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://wesmckinney.com/book/data-cleaning](https://wesmckinney.com/book/data-cleaning)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*This Open Access web version of *Python for Data Analysis 3rd Edition* is
    now available as a companion to the [print and digital editions](https://amzn.to/3DyLaJc).
    If you encounter any errata, [please report them here](https://oreilly.com/catalog/0636920519829/errata).
    Please note that some aspects of this site as produced by Quarto will differ from
    the formatting of the print and eBook versions from O’Reilly.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you find the online edition of the book useful, please consider [ordering
    a paper copy](https://amzn.to/3DyLaJc) or a [DRM-free eBook](https://www.ebooks.com/en-us/book/210644288/python-for-data-analysis/wes-mckinney/?affId=WES398681F)
    to support the author. The content from this website may not be copied or reproduced.
    The code examples are MIT licensed and can be found on GitHub or Gitee.*  *During
    the course of doing data analysis and modeling, a significant amount of time is
    spent on data preparation: loading, cleaning, transforming, and rearranging. Such
    tasks are often reported to take up 80% or more of an analyst''s time. Sometimes
    the way that data is stored in files or databases is not in the right format for
    a particular task. Many researchers choose to do ad hoc processing of data from
    one form to another using a general-purpose programming language, like Python,
    Perl, R, or Java, or Unix text-processing tools like sed or awk. Fortunately,
    pandas, along with the built-in Python language features, provides you with a
    high-level, flexible, and fast set of tools to enable you to manipulate data into
    the right form.'
  prefs: []
  type: TYPE_NORMAL
- en: If you identify a type of data manipulation that isn’t anywhere in this book
    or elsewhere in the pandas library, feel free to share your use case on one of
    the Python mailing lists or on the pandas GitHub site. Indeed, much of the design
    and implementation of pandas have been driven by the needs of real-world applications.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter I discuss tools for missing data, duplicate data, string manipulation,
    and some other analytical data transformations. In the next chapter, I focus on
    combining and rearranging datasets in various ways.
  prefs: []
  type: TYPE_NORMAL
- en: 7.1 Handling Missing Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Missing data occurs commonly in many data analysis applications. One of the
    goals of pandas is to make working with missing data as painless as possible.
    For example, all of the descriptive statistics on pandas objects exclude missing
    data by default.
  prefs: []
  type: TYPE_NORMAL
- en: The way that missing data is represented in pandas objects is somewhat imperfect,
    but it is sufficient for most real-world use. For data with `float64` dtype, pandas
    uses the floating-point value `NaN` (Not a Number) to represent missing data.
  prefs: []
  type: TYPE_NORMAL
- en: 'We call this a *sentinel value*: when present, it indicates a missing (or *null*)
    value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The `isna` method gives us a Boolean Series with `True` where values are null:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In pandas, we've adopted a convention used in the R programming language by
    referring to missing data as NA, which stands for *not available*. In statistics
    applications, NA data may either be data that does not exist or that exists but
    was not observed (through problems with data collection, for example). When cleaning
    up data for analysis, it is often important to do analysis on the missing data
    itself to identify data collection problems or potential biases in the data caused
    by missing data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The built-in Python `None` value is also treated as NA:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The pandas project has attempted to make working with missing data consistent
    across data types. Functions like `pandas.isna` abstract away many of the annoying
    details. See [Table 7.1](#tbl-table_na_method) for a list of some functions related
    to missing data handling.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 7.1: NA handling object methods'
  prefs: []
  type: TYPE_NORMAL
- en: '| Method | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `dropna` | Filter axis labels based on whether values for each label have
    missing data, with varying thresholds for how much missing data to tolerate. |'
  prefs: []
  type: TYPE_TB
- en: '| `fillna` | Fill in missing data with some value or using an interpolation
    method such as `"ffill"` or `"bfill"`. |'
  prefs: []
  type: TYPE_TB
- en: '| `isna` | Return Boolean values indicating which values are missing/NA. |'
  prefs: []
  type: TYPE_TB
- en: '| `notna` | Negation of `isna`, returns `True` for non-NA values and `False`
    for NA values. |'
  prefs: []
  type: TYPE_TB
- en: Filtering Out Missing Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are a few ways to filter out missing data. While you always have the
    option to do it by hand using `pandas.isna` and Boolean indexing, `dropna` can
    be helpful. On a Series, it returns the Series with only the nonnull data and
    index values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the same thing as doing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'With DataFrame objects, there are different ways to remove missing data. You
    may want to drop rows or columns that are all NA, or only those rows or columns
    containing any NAs at all. `dropna` by default drops any row containing a missing
    value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Passing `how="all"` will drop only rows that are all NA:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Keep in mind that these functions return new objects by default and do not modify
    the contents of the original object.
  prefs: []
  type: TYPE_NORMAL
- en: 'To drop columns in the same way, pass `axis="columns"`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Suppose you want to keep only rows containing at most a certain number of missing
    observations. You can indicate this with the `thresh` argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Filling In Missing Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Rather than filtering out missing data (and potentially discarding other data
    along with it), you may want to fill in the “holes” in any number of ways. For
    most purposes, the `fillna` method is the workhorse function to use. Calling `fillna`
    with a constant replaces missing values with that value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Calling `fillna` with a dictionary, you can use a different fill value for
    each column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The same interpolation methods available for reindexing (see [Table 5.3](/book/pandas-basics#tbl-table_reindex_function))
    can be used with `fillna`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'With `fillna` you can do lots of other things such as simple data imputation
    using the median or mean statistics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: See [Table 7.2](#tbl-table_fillna_function) for a reference on `fillna` function
    arguments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 7.2: `fillna` function arguments'
  prefs: []
  type: TYPE_NORMAL
- en: '| Argument | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `value` | Scalar value or dictionary-like object to use to fill missing values
    |'
  prefs: []
  type: TYPE_TB
- en: '| `method` | Interpolation method: one of `"bfill"` (backward fill) or `"ffill"`
    (forward fill); default is `None` |'
  prefs: []
  type: TYPE_TB
- en: '| `axis` | Axis to fill on (`"index"` or `"columns"`); default is `axis="index"`
    |'
  prefs: []
  type: TYPE_TB
- en: '| `limit` | For forward and backward filling, maximum number of consecutive
    periods to fill |'
  prefs: []
  type: TYPE_TB
- en: 7.2 Data Transformation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far in this chapter we’ve been concerned with handling missing data. Filtering,
    cleaning, and other transformations are another class of important operations.
  prefs: []
  type: TYPE_NORMAL
- en: Removing Duplicates
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Duplicate rows may be found in a DataFrame for any number of reasons. Here
    is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The DataFrame method `duplicated` returns a Boolean Series indicating whether
    each row is a duplicate (its column values are exactly equal to those in an earlier
    row) or not:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Relatedly, `drop_duplicates` returns a DataFrame with rows where the `duplicated`
    array is `False` filtered out:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Both methods by default consider all of the columns; alternatively, you can
    specify any subset of them to detect duplicates. Suppose we had an additional
    column of values and wanted to filter duplicates based only on the `"k1"` column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '`duplicated` and `drop_duplicates` by default keep the first observed value
    combination. Passing `keep="last"` will return the last one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Transforming Data Using a Function or Mapping
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For many datasets, you may wish to perform some transformation based on the
    values in an array, Series, or column in a DataFrame. Consider the following hypothetical
    data collected about various kinds of meat:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Suppose you wanted to add a column indicating the type of animal that each
    food came from. Let’s write down a mapping of each distinct meat type to the kind
    of animal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The `map` method on a Series (also discussed in [Ch 5.2.5: Function Application
    and Mapping](/book/pandas-basics#pandas_apply)) accepts a function or dictionary-like
    object containing a mapping to do the transformation of values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'We could also have passed a function that does all the work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Using `map` is a convenient way to perform element-wise transformations and
    other data cleaning-related operations.
  prefs: []
  type: TYPE_NORMAL
- en: Replacing Values
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Filling in missing data with the `fillna` method is a special case of more
    general value replacement. As you''ve already seen, `map` can be used to modify
    a subset of values in an object, but `replace` provides a simpler and more flexible
    way to do so. Let’s consider this Series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The `-999` values might be sentinel values for missing data. To replace these
    with NA values that pandas understands, we can use `replace`, producing a new
    Series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want to replace multiple values at once, you instead pass a list and
    then the substitute value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'To use a different replacement for each value, pass a list of substitutes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The argument passed can also be a dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '*Note* *The `data.replace` method is distinct from `data.str.replace`, which
    performs element-wise string substitution. We look at these string methods on
    Series later in the chapter.*  *### Renaming Axis Indexes'
  prefs: []
  type: TYPE_NORMAL
- en: 'Like values in a Series, axis labels can be similarly transformed by a function
    or mapping of some form to produce new, differently labeled objects. You can also
    modify the axes in place without creating a new data structure. Here’s a simple
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Like a Series, the axis indexes have a `map` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'You can assign to the `index` attribute, modifying the DataFrame in place:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want to create a transformed version of a dataset without modifying
    the original, a useful method is `rename`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Notably, `rename` can be used in conjunction with a dictionary-like object,
    providing new values for a subset of the axis labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '`rename` saves you from the chore of copying the DataFrame manually and assigning
    new values to its `index` and `columns` attributes.'
  prefs: []
  type: TYPE_NORMAL
- en: Discretization and Binning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Continuous data is often discretized or otherwise separated into “bins” for
    analysis. Suppose you have data about a group of people in a study, and you want
    to group them into discrete age buckets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s divide these into bins of 18 to 25, 26 to 35, 36 to 60, and finally 61
    and older. To do so, you have to use `pandas.cut`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The object pandas returns is a special Categorical object. The output you see
    describes the bins computed by `pandas.cut`. Each bin is identified by a special
    (unique to pandas) interval value type containing the lower and upper limit of
    each bin:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Note that `pd.value_counts(categories)` are the bin counts for the result of
    `pandas.cut`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the string representation of an interval, a parenthesis means that the side
    is *open* (exclusive), while the square bracket means it is *closed* (inclusive).
    You can change which side is closed by passing `right=False`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'You can override the default interval-based bin labeling by passing a list
    or array to the `labels` option:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'If you pass an integer number of bins to `pandas.cut` instead of explicit bin
    edges, it will compute equal-length bins based on the minimum and maximum values
    in the data. Consider the case of some uniformly distributed data chopped into
    fourths:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: The `precision=2` option limits the decimal precision to two digits.
  prefs: []
  type: TYPE_NORMAL
- en: 'A closely related function, `pandas.qcut`, bins the data based on sample quantiles.
    Depending on the distribution of the data, using `pandas.cut` will not usually
    result in each bin having the same number of data points. Since `pandas.qcut`
    uses sample quantiles instead, you will obtain roughly equally sized bins:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Similar to `pandas.cut`, you can pass your own quantiles (numbers between 0
    and 1, inclusive):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: We’ll return to `pandas.cut` and `pandas.qcut` later in the chapter during our
    discussion of aggregation and group operations, as these discretization functions
    are especially useful for quantile and group analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting and Filtering Outliers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Filtering or transforming outliers is largely a matter of applying array operations.
    Consider a DataFrame with some normally distributed data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Suppose you wanted to find values in one of the columns exceeding 3 in absolute
    value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'To select all rows having a value exceeding 3 or –3, you can use the `any`
    method on a Boolean DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: The parentheses around `data.abs() > 3` are necessary in order to call the `any`
    method on the result of the comparison operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Values can be set based on these criteria. Here is code to cap values outside
    the interval –3 to 3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The statement `np.sign(data)` produces 1 and –1 values based on whether the
    values in `data` are positive or negative:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Permutation and Random Sampling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Permuting (randomly reordering) a Series or the rows in a DataFrame is possible
    using the `numpy.random.permutation` function. Calling `permutation` with the
    length of the axis you want to permute produces an array of integers indicating
    the new ordering:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'That array can then be used in `iloc`-based indexing or the equivalent `take`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'By invoking `take` with `axis="columns"`, we could also select a permutation
    of the columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'To select a random subset without replacement (the same row cannot appear twice),
    you can use the `sample` method on Series and DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'To generate a sample *with* replacement (to allow repeat choices), pass `replace=True`
    to `sample`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Computing Indicator/Dummy Variables
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Another type of transformation for statistical modeling or machine learning
    applications is converting a categorical variable into a *dummy* or *indicator*
    matrix. If a column in a DataFrame has `k` distinct values, you would derive a
    matrix or DataFrame with `k` columns containing all 1s and 0s. pandas has a `pandas.get_dummies`
    function for doing this, though you could also devise one yourself. Let’s consider
    an example DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Here I passed `dtype=float` to change the output type from boolean (the default
    in more recent versions of pandas) to floating point.
  prefs: []
  type: TYPE_NORMAL
- en: 'In some cases, you may want to add a prefix to the columns in the indicator
    DataFrame, which can then be merged with the other data. `pandas.get_dummies`
    has a prefix argument for doing this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: The `DataFrame.join` method will be explained in more detail in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'If a row in a DataFrame belongs to multiple categories, we have to use a different
    approach to create the dummy variables. Let’s look at the MovieLens 1M dataset,
    which is investigated in more detail in [Ch 13: Data Analysis Examples](#data-analysis-examples):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'pandas has implemented a special Series method `str.get_dummies` (methods that
    start with `str.` are discussed in more detail later in [String Manipulation](#text_string_manip))
    that handles this scenario of multiple group membership encoded as a delimited
    string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, as before, you can combine this with `movies` while adding a `"Genre_"`
    to the column names in the `dummies` DataFrame with the `add_prefix` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '*Note* *For much larger data, this method of constructing indicator variables
    with multiple membership is not especially speedy. It would be better to write
    a lower-level function that writes directly to a NumPy array, and then wrap the
    result in a DataFrame.*  *A useful recipe for statistical applications is to combine
    `pandas.get_dummies` with a discretization function like `pandas.cut`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: We will look again at `pandas.get_dummies` later in [Creating dummy variables
    for modeling](#pandas-categorical-dummy).**  **## 7.3 Extension Data Types
  prefs: []
  type: TYPE_NORMAL
- en: '*Note* *This is a newer and more advanced topic that many pandas users do not
    need to know a lot about, but I present it here for completeness since I will
    reference and use extension data types in various places in the upcoming chapters.*  *pandas
    was originally built upon the capabilities present in NumPy, an array computing
    library used primarily for working with numerical data. Many pandas concepts,
    such as missing data, were implemented using what was available in NumPy while
    trying to maximize compatibility between libraries that used NumPy and pandas
    together.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Building on NumPy led to a number of shortcomings, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Missing data handling for some numerical data types, such as integers and Booleans,
    was incomplete. As a result, when missing data was introduced into such data,
    pandas converted the data type to `float64` and used `np.nan` to represent null
    values. This had compounding effects by introducing subtle issues into many pandas
    algorithms.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Datasets with a lot of string data were computationally expensive and used a
    lot of memory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some data types, like time intervals, timedeltas, and timestamps with time zones,
    could not be supported efficiently without using computationally expensive arrays
    of Python objects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More recently, pandas has developed an *extension type* system allowing for
    new data types to be added even if they are not supported natively by NumPy. These
    new data types can be treated as first class alongside data coming from NumPy
    arrays.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at an example where we create a Series of integers with a missing
    value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Mainly for backward compatibility reasons, Series uses the legacy behavior
    of using a `float64` data type and `np.nan` for the missing value. We could create
    this Series instead using `pandas.Int64Dtype`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'The output `<NA>` indicates that a value is missing for an extension type array.
    This uses the special `pandas.NA` sentinel value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'We also could have used the shorthand `"Int64"` instead of `pd.Int64Dtype()`
    to specify the type. The capitalization is necessary, otherwise it will be a NumPy-based
    nonextension type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'pandas also has an extension type specialized for string data that does not
    use NumPy object arrays (it requires the pyarrow library, which you may need to
    install separately):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: These string arrays generally use much less memory and are frequently computationally
    more efficient for doing operations on large datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Another important extension type is `Categorical`, which we discuss in more
    detail in [Categorical Data](#pandas-categorical). A reasonably complete list
    of extension types available as of this writing is in [Table 7.3](#tbl-table_pandas_extension_types).
  prefs: []
  type: TYPE_NORMAL
- en: 'Extension types can be passed to the Series `astype` method, allowing you to
    convert easily as part of your data cleaning process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Table 7.3: pandas extension data types'
  prefs: []
  type: TYPE_NORMAL
- en: '| Extension type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `BooleanDtype` | Nullable Boolean data, use `"boolean"` when passing as string
    |'
  prefs: []
  type: TYPE_TB
- en: '| `CategoricalDtype` | Categorical data type, use `"category"` when passing
    as string |'
  prefs: []
  type: TYPE_TB
- en: '| `DatetimeTZDtype` | Datetime with time zone |'
  prefs: []
  type: TYPE_TB
- en: '| `Float32Dtype` | 32-bit nullable floating point, use `"Float32"` when passing
    as string |'
  prefs: []
  type: TYPE_TB
- en: '| `Float64Dtype` | 64-bit nullable floating point, use `"Float64"` when passing
    as string |'
  prefs: []
  type: TYPE_TB
- en: '| `Int8Dtype` | 8-bit nullable signed integer, use `"Int8"` when passing as
    string |'
  prefs: []
  type: TYPE_TB
- en: '| `Int16Dtype` | 16-bit nullable signed integer, use `"Int16"` when passing
    as string |'
  prefs: []
  type: TYPE_TB
- en: '| `Int32Dtype` | 32-bit nullable signed integer, use `"Int32"` when passing
    as string |'
  prefs: []
  type: TYPE_TB
- en: '| `Int64Dtype` | 64-bit nullable signed integer, use `"Int64"` when passing
    as string |'
  prefs: []
  type: TYPE_TB
- en: '| `UInt8Dtype` | 8-bit nullable unsigned integer, use `"UInt8"` when passing
    as string |'
  prefs: []
  type: TYPE_TB
- en: '| `UInt16Dtype` | 16-bit nullable unsigned integer, use `"UInt16"` when passing
    as string |'
  prefs: []
  type: TYPE_TB
- en: '| `UInt32Dtype` | 32-bit nullable unsigned integer, use `"UInt32"` when passing
    as string |'
  prefs: []
  type: TYPE_TB
- en: '| `UInt64Dtype` | 64-bit nullable unsigned integer, use `"UInt64"` when passing
    as string |*  *## 7.4 String Manipulation'
  prefs: []
  type: TYPE_NORMAL
- en: Python has long been a popular raw data manipulation language in part due to
    its ease of use for string and text processing. Most text operations are made
    simple with the string object’s built-in methods. For more complex pattern matching
    and text manipulations, regular expressions may be needed. pandas adds to the
    mix by enabling you to apply string and regular expressions concisely on whole
    arrays of data, additionally handling the annoyance of missing data.
  prefs: []
  type: TYPE_NORMAL
- en: Python Built-In String Object Methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In many string munging and scripting applications, built-in string methods
    are sufficient. As an example, a comma-separated string can be broken into pieces
    with `split`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: '`split` is often combined with `strip` to trim whitespace (including line breaks):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'These substrings could be concatenated together with a two-colon delimiter
    using addition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'But this isn’t a practical generic method. A faster and more Pythonic way is
    to pass a list or tuple to the `join` method on the string `"::"`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Other methods are concerned with locating substrings. Using Python’s `in` keyword
    is the best way to detect a substring, though `index` and `find` can also be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the difference between `find` and `index` is that `index` raises
    an exception if the string isn’t found (versus returning –1):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Relatedly, `count` returns the number of occurrences of a particular substring:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: '`replace` will substitute occurrences of one pattern for another. It is commonly
    used to delete patterns, too, by passing an empty string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: See [Table 7.4](#tbl-table_string_methods) for a listing of some of Python's
    string methods.
  prefs: []
  type: TYPE_NORMAL
- en: Regular expressions can also be used with many of these operations, as you’ll
    see.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 7.4: Python built-in string methods'
  prefs: []
  type: TYPE_NORMAL
- en: '| Method | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `count` | Return the number of nonoverlapping occurrences of substring in
    the string |'
  prefs: []
  type: TYPE_TB
- en: '| `endswith` | Return `True` if string ends with suffix |'
  prefs: []
  type: TYPE_TB
- en: '| `startswith` | Return `True` if string starts with prefix |'
  prefs: []
  type: TYPE_TB
- en: '| `join` | Use string as delimiter for concatenating a sequence of other strings
    |'
  prefs: []
  type: TYPE_TB
- en: '| `index` | Return starting index of the first occurrence of passed substring
    if found in the string; otherwise, raises `ValueError` if not found |'
  prefs: []
  type: TYPE_TB
- en: '| `find` | Return position of first character of *first* occurrence of substring
    in the string; like `index`, but returns –1 if not found |'
  prefs: []
  type: TYPE_TB
- en: '| `rfind` | Return position of first character of *last* occurrence of substring
    in the string; returns –1 if not found |'
  prefs: []
  type: TYPE_TB
- en: '| `replace` | Replace occurrences of string with another string |'
  prefs: []
  type: TYPE_TB
- en: '| `strip, rstrip, lstrip` | Trim whitespace, including newlines on both sides,
    on the right side, or on the left side, respectively |'
  prefs: []
  type: TYPE_TB
- en: '| `split` | Break string into list of substrings using passed delimiter |'
  prefs: []
  type: TYPE_TB
- en: '| `lower` | Convert alphabet characters to lowercase |'
  prefs: []
  type: TYPE_TB
- en: '| `upper` | Convert alphabet characters to uppercase |'
  prefs: []
  type: TYPE_TB
- en: '| `casefold` | Convert characters to lowercase, and convert any region-specific
    variable character combinations to a common comparable form |'
  prefs: []
  type: TYPE_TB
- en: '| `ljust, rjust` | Left justify or right justify, respectively; pad opposite
    side of string with spaces (or some other fill character) to return a string with
    a minimum width |'
  prefs: []
  type: TYPE_TB
- en: Regular Expressions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Regular expressions* provide a flexible way to search or match (often more
    complex) string patterns in text. A single expression, commonly called a *regex*,
    is a string formed according to the regular expression language. Python’s built-in
    `re` module is responsible for applying regular expressions to strings; I’ll give
    a number of examples of its use here.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Note* *The art of writing regular expressions could be a chapter of its own
    and thus is outside the book’s scope. There are many excellent tutorials and references
    available on the internet and in other books.*  *The `re` module functions fall
    into three categories: pattern matching, substitution, and splitting. Naturally
    these are all related; a regex describes a pattern to locate in the text, which
    can then be used for many purposes. Let’s look at a simple example: suppose we
    wanted to split a string with a variable number of whitespace characters (tabs,
    spaces, and newlines).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The regex describing one or more whitespace characters is `\s+`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'When you call `re.split(r"\s+", text)`, the regular expression is first *compiled*,
    and then its `split` method is called on the passed text. You can compile the
    regex yourself with `re.compile`, forming a reusable regex object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'If, instead, you wanted to get a list of all patterns matching the regex, you
    can use the `findall` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: '*Note* *To avoid unwanted escaping with `\` in a regular expression, use *raw*
    string literals like `r"C:\x"` instead of the equivalent `"C:\\x"`.*  *Creating
    a regex object with `re.compile` is highly recommended if you intend to apply
    the same expression to many strings; doing so will save CPU cycles.'
  prefs: []
  type: TYPE_NORMAL
- en: '`match` and `search` are closely related to `findall`. While `findall` returns
    all matches in a string, `search` returns only the first match. More rigidly,
    `match` *only* matches at the beginning of the string. As a less trivial example,
    let’s consider a block of text and a regular expression capable of identifying
    most email addresses:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'Using `findall` on the text produces a list of the email addresses:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: '`search` returns a special match object for the first email address in the
    text. For the preceding regex, the match object can only tell us the start and
    end position of the pattern in the string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: '`regex.match` returns `None`, as it will match only if the pattern occurs at
    the start of the string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'Relatedly, `sub` will return a new string with occurrences of the pattern replaced
    by a new string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'Suppose you wanted to find email addresses and simultaneously segment each
    address into its three components: username, domain name, and domain suffix. To
    do this, put parentheses around the parts of the pattern to segment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'A match object produced by this modified regex returns a tuple of the pattern
    components with its `groups` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: '`findall` returns a list of tuples when the pattern has groups:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: '`sub` also has access to groups in each match using special symbols like `\1`
    and `\2`. The symbol `\1` corresponds to the first matched group, `\2` corresponds
    to the second, and so forth:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: There is much more to regular expressions in Python, most of which is outside
    the book’s scope. [Table 7.5](#tbl-table_regex_method) provides a brief summary.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 7.5: Regular expression methods'
  prefs: []
  type: TYPE_NORMAL
- en: '| Method | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `findall` | Return all nonoverlapping matching patterns in a string as a
    list |'
  prefs: []
  type: TYPE_TB
- en: '| `finditer` | Like `findall`, but returns an iterator |'
  prefs: []
  type: TYPE_TB
- en: '| `match` | Match pattern at start of string and optionally segment pattern
    components into groups; if the pattern matches, return a match object, and otherwise
    `None` |'
  prefs: []
  type: TYPE_TB
- en: '| `search` | Scan string for match to pattern, returning a match object if
    so; unlike `match`, the match can be anywhere in the string as opposed to only
    at the beginning |'
  prefs: []
  type: TYPE_TB
- en: '| `split` | Break string into pieces at each occurrence of pattern |'
  prefs: []
  type: TYPE_TB
- en: '| `sub, subn` | Replace all (`sub`) or first `n` occurrences (`subn`) of pattern
    in string with replacement expression; use symbols `\1, \2, ...` to refer to match
    group elements in the replacement string |**  **### String Functions in pandas'
  prefs: []
  type: TYPE_NORMAL
- en: 'Cleaning up a messy dataset for analysis often requires a lot of string manipulation.
    To complicate matters, a column containing strings will sometimes have missing
    data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'String and regular expression methods can be applied (passing a `lambda` or
    other function) to each value using `data.map`, but it will fail on the NA (null)
    values. To cope with this, Series has array-oriented methods for string operations
    that skip over and propagate NA values. These are accessed through Series’s `str`
    attribute; for example, we could check whether each email address has `"gmail"`
    in it with `str.contains`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the result of this operation has an `object` dtype. pandas has *extension
    types* that provide for specialized treatment of strings, integers, and Boolean
    data which until recently have had some rough edges when working with missing
    data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: Extension types are discussed in more detail in [Extension Data Types](#pandas-ext-types).
  prefs: []
  type: TYPE_NORMAL
- en: 'Regular expressions can be used, too, along with any `re` options like `IGNORECASE`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'There are a couple of ways to do vectorized element retrieval. Either use `str.get`
    or index into the `str` attribute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'You can similarly slice strings using this syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'The `str.extract` method will return the captured groups of a regular expression
    as a DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: See [Table 7.6](#tbl-table_vec_string) for more pandas string methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 7.6: Partial listing of Series string methods'
  prefs: []
  type: TYPE_NORMAL
- en: '| Method | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `cat` | Concatenate strings element-wise with optional delimiter |'
  prefs: []
  type: TYPE_TB
- en: '| `contains` | Return Boolean array if each string contains pattern/regex |'
  prefs: []
  type: TYPE_TB
- en: '| `count` | Count occurrences of pattern |'
  prefs: []
  type: TYPE_TB
- en: '| `extract` | Use a regular expression with groups to extract one or more strings
    from a Series of strings; the result will be a DataFrame with one column per group
    |'
  prefs: []
  type: TYPE_TB
- en: '| `endswith` | Equivalent to `x.endswith(pattern)` for each element |'
  prefs: []
  type: TYPE_TB
- en: '| `startswith` | Equivalent to `x.startswith(pattern)` for each element |'
  prefs: []
  type: TYPE_TB
- en: '| `findall` | Compute list of all occurrences of pattern/regex for each string
    |'
  prefs: []
  type: TYPE_TB
- en: '| `get` | Index into each element (retrieve *i*-th element) |'
  prefs: []
  type: TYPE_TB
- en: '| `isalnum` | Equivalent to built-in `str.alnum` |'
  prefs: []
  type: TYPE_TB
- en: '| `isalpha` | Equivalent to built-in `str.isalpha` |'
  prefs: []
  type: TYPE_TB
- en: '| `isdecimal` | Equivalent to built-in `str.isdecimal` |'
  prefs: []
  type: TYPE_TB
- en: '| `isdigit` | Equivalent to built-in `str.isdigit` |'
  prefs: []
  type: TYPE_TB
- en: '| `islower` | Equivalent to built-in `str.islower` |'
  prefs: []
  type: TYPE_TB
- en: '| `isnumeric` | Equivalent to built-in `str.isnumeric` |'
  prefs: []
  type: TYPE_TB
- en: '| `isupper` | Equivalent to built-in `str.isupper` |'
  prefs: []
  type: TYPE_TB
- en: '| `join` | Join strings in each element of the Series with passed separator
    |'
  prefs: []
  type: TYPE_TB
- en: '| `len` | Compute length of each string |'
  prefs: []
  type: TYPE_TB
- en: '| `lower, upper` | Convert cases; equivalent to `x.lower()` or `x.upper()`
    for each element |'
  prefs: []
  type: TYPE_TB
- en: '| `match` | Use `re.match` with the passed regular expression on each element,
    returning `True` or `False` whether it matches |'
  prefs: []
  type: TYPE_TB
- en: '| `pad` | Add whitespace to left, right, or both sides of strings |'
  prefs: []
  type: TYPE_TB
- en: '| `center` | Equivalent to `pad(side="both")` |'
  prefs: []
  type: TYPE_TB
- en: '| `repeat` | Duplicate values (e.g., `s.str.repeat(3)` is equivalent to `x
    * 3` for each string) |'
  prefs: []
  type: TYPE_TB
- en: '| `replace` | Replace occurrences of pattern/regex with some other string |'
  prefs: []
  type: TYPE_TB
- en: '| `slice` | Slice each string in the Series |'
  prefs: []
  type: TYPE_TB
- en: '| `split` | Split strings on delimiter or regular expression |'
  prefs: []
  type: TYPE_TB
- en: '| `strip` | Trim whitespace from both sides, including newlines |'
  prefs: []
  type: TYPE_TB
- en: '| `rstrip` | Trim whitespace on right side |'
  prefs: []
  type: TYPE_TB
- en: '| `lstrip` | Trim whitespace on left side |**  **## 7.5 Categorical Data'
  prefs: []
  type: TYPE_NORMAL
- en: This section introduces the pandas `Categorical` type. I will show how you can
    achieve better performance and memory use in some pandas operations by using it.
    I also introduce some tools that may help with using categorical data in statistics
    and machine learning applications.
  prefs: []
  type: TYPE_NORMAL
- en: Background and Motivation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Frequently, a column in a table may contain repeated instances of a smaller
    set of distinct values. We have already seen functions like `unique` and `value_counts`,
    which enable us to extract the distinct values from an array and compute their
    frequencies, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'Many data systems (for data warehousing, statistical computing, or other uses)
    have developed specialized approaches for representing data with repeated values
    for more efficient storage and computation. In data warehousing, a best practice
    is to use so-called *dimension tables* containing the distinct values and storing
    the primary observations as integer keys referencing the dimension table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use the `take` method to restore the original Series of strings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: This representation as integers is called the *categorical* or *dictionary-encoded*
    representation. The array of distinct values can be called the *categories*, *dictionary*,
    or *levels* of the data. In this book we will use the terms *categorical* and
    *categories*. The integer values that reference the categories are called the
    *category codes* or simply *codes*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The categorical representation can yield significant performance improvements
    when you are doing analytics. You can also perform transformations on the categories
    while leaving the codes unmodified. Some example transformations that can be made
    at relatively low cost are:'
  prefs: []
  type: TYPE_NORMAL
- en: Renaming categories
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appending a new category without changing the order or position of the existing
    categories
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Categorical Extension Type in pandas
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: pandas has a special `Categorical` extension type for holding data that uses
    the integer-based categorical representation or *encoding*. This is a popular
    data compression technique for data with many occurrences of similar values and
    can provide significantly faster performance with lower memory use, especially
    for string data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider the example Series from before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, `df[''fruit'']` is an array of Python string objects. We can convert
    it to categorical by calling:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'The values for `fruit_cat` are now an instance of `pandas.Categorical`, which
    you can access via the `.array` attribute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Categorical` object has `categories` and `codes` attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: These can be accessed more easily using the `cat` accessor, which will be explained
    soon in [Categorical Methods](#pandas-categorical-methods).
  prefs: []
  type: TYPE_NORMAL
- en: 'A useful trick to get a mapping between codes and categories is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: 'You can convert a DataFrame column to categorical by assigning the converted
    result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also create `pandas.Categorical` directly from other types of Python
    sequences:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: 'If you have obtained categorical encoded data from another source, you can
    use the alternative `from_codes` constructor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'Unless explicitly specified, categorical conversions assume no specific ordering
    of the categories. So the `categories` array may be in a different order depending
    on the ordering of the input data. When using `from_codes` or any of the other
    constructors, you can indicate that the categories have a meaningful ordering:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: 'The output `[foo < bar < baz]` indicates that `''foo''` precedes `''bar''`
    in the ordering, and so on. An unordered categorical instance can be made ordered
    with `as_ordered`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: As a last note, categorical data need not be strings, even though I have shown
    only string examples. A categorical array can consist of any immutable value types.
  prefs: []
  type: TYPE_NORMAL
- en: Computations with Categoricals
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Using `Categorical` in pandas compared with the nonencoded version (like an
    array of strings) generally behaves the same way. Some parts of pandas, like the
    `groupby` function, perform better when working with categoricals. There are also
    some functions that can utilize the `ordered` flag.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider some random numeric data and use the `pandas.qcut` binning
    function. This returns `pandas.Categorical`; we used `pandas.cut` earlier in the
    book but glossed over the details of how categoricals work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s compute a quartile binning of this data and extract some statistics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: 'While useful, the exact sample quartiles may be less useful for producing a
    report than quartile names. We can achieve this with the `labels` argument to
    `qcut`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: 'The labeled `bins` categorical does not contain information about the bin edges
    in the data, so we can use `groupby` to extract some summary statistics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: 'The `''quartile''` column in the result retains the original categorical information,
    including ordering, from `bins`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: Better performance with categoricals
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'At the beginning of the section, I said that categorical types can improve
    performance and memory use, so let''s look at some examples. Consider some Series
    with 10 million elements and a small number of distinct categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we convert `labels` to categorical:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we note that `labels` uses significantly more memory than `categories`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: 'The conversion to category is not free, of course, but it is a one-time cost:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: 'GroupBy operations can be significantly faster with categoricals because the
    underlying algorithms use the integer-based codes array instead of an array of
    strings. Here we compare the performance of `value_counts()`, which internally
    uses the GroupBy machinery:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: Categorical Methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Series containing categorical data have several special methods similar to
    the `Series.str` specialized string methods. This also provides convenient access
    to the categories and codes. Consider the Series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: 'The special *accessor* attribute `cat` provides access to categorical methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: 'Suppose that we know the actual set of categories for this data extends beyond
    the four values observed in the data. We can use the `set_categories` method to
    change them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: 'While it appears that the data is unchanged, the new categories will be reflected
    in operations that use them. For example, `value_counts` respects the categories,
    if present:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: 'In large datasets, categoricals are often used as a convenient tool for memory
    savings and better performance. After you filter a large DataFrame or Series,
    many of the categories may not appear in the data. To help with this, we can use
    the `remove_unused_categories` method to trim unobserved categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: See [Table 7.7](#tbl-table_categorical_methods) for a listing of available categorical
    methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 7.7: Categorical methods for Series in pandas'
  prefs: []
  type: TYPE_NORMAL
- en: '| Method | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `add_categories` | Append new (unused) categories at end of existing categories
    |'
  prefs: []
  type: TYPE_TB
- en: '| `as_ordered` | Make categories ordered |'
  prefs: []
  type: TYPE_TB
- en: '| `as_unordered` | Make categories unordered |'
  prefs: []
  type: TYPE_TB
- en: '| `remove_categories` | Remove categories, setting any removed values to null
    |'
  prefs: []
  type: TYPE_TB
- en: '| `remove_unused_categories` | Remove any category values that do not appear
    in the data |'
  prefs: []
  type: TYPE_TB
- en: '| `rename_categories` | Replace categories with indicated set of new category
    names; cannot change the number of categories |'
  prefs: []
  type: TYPE_TB
- en: '| `reorder_categories` | Behaves like `rename_categories`, but can also change
    the result to have ordered categories |'
  prefs: []
  type: TYPE_TB
- en: '| `set_categories` | Replace the categories with the indicated set of new categories;
    can add or remove categories |'
  prefs: []
  type: TYPE_TB
- en: Creating dummy variables for modeling
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When you're using statistics or machine learning tools, you'll often transform
    categorical data into *dummy variables*, also known as *one-hot* encoding. This
    involves creating a DataFrame with a column for each distinct category; these
    columns contain 1s for occurrences of a given category and 0 otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the previous example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: 'As mentioned previously in this chapter, the `pandas.get_dummies` function
    converts this one-dimensional categorical data into a DataFrame containing the
    dummy variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: 7.6 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Effective data preparation can significantly improve productivity by enabling
    you to spend more time analyzing data and less time getting it ready for analysis.
    We have explored a number of tools in this chapter, but the coverage here is by
    no means comprehensive. In the next chapter, we will explore pandas's joining
    and grouping functionality.******
  prefs: []
  type: TYPE_NORMAL
