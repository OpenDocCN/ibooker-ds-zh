["```py\nIn [12]: import numpy as np\n\nIn [13]: import pandas as pd\n```", "```py\nIn [14]: from datetime import datetime\n\nIn [15]: now = datetime.now()\n\nIn [16]: now\nOut[16]: datetime.datetime(2023, 4, 12, 13, 9, 16, 484533)\n\nIn [17]: now.year, now.month, now.day\nOut[17]: (2023, 4, 12)\n```", "```py\nIn [18]: delta = datetime(2011, 1, 7) - datetime(2008, 6, 24, 8, 15)\n\nIn [19]: delta\nOut[19]: datetime.timedelta(days=926, seconds=56700)\n\nIn [20]: delta.days\nOut[20]: 926\n\nIn [21]: delta.seconds\nOut[21]: 56700\n```", "```py\nIn [22]: from datetime import timedelta\n\nIn [23]: start = datetime(2011, 1, 7)\n\nIn [24]: start + timedelta(12)\nOut[24]: datetime.datetime(2011, 1, 19, 0, 0)\n\nIn [25]: start - 2 * timedelta(12)\nOut[25]: datetime.datetime(2010, 12, 14, 0, 0)\n```", "```py\nIn [26]: stamp = datetime(2011, 1, 3)\n\nIn [27]: str(stamp)\nOut[27]: '2011-01-03 00:00:00'\n\nIn [28]: stamp.strftime(\"%Y-%m-%d\")\nOut[28]: '2011-01-03'\n```", "```py\nIn [29]: value = \"2011-01-03\"\n\nIn [30]: datetime.strptime(value, \"%Y-%m-%d\")\nOut[30]: datetime.datetime(2011, 1, 3, 0, 0)\n\nIn [31]: datestrs = [\"7/6/2011\", \"8/6/2011\"]\n\nIn [32]: [datetime.strptime(x, \"%m/%d/%Y\") for x in datestrs]\nOut[32]: \n[datetime.datetime(2011, 7, 6, 0, 0),\n datetime.datetime(2011, 8, 6, 0, 0)]\n```", "```py\nIn [33]: datestrs = [\"2011-07-06 12:00:00\", \"2011-08-06 00:00:00\"]\n\nIn [34]: pd.to_datetime(datestrs)\nOut[34]: DatetimeIndex(['2011-07-06 12:00:00', '2011-08-06 00:00:00'], dtype='dat\netime64[ns]', freq=None)\n```", "```py\nIn [35]: idx = pd.to_datetime(datestrs + [None])\n\nIn [36]: idx\nOut[36]: DatetimeIndex(['2011-07-06 12:00:00', '2011-08-06 00:00:00', 'NaT'], dty\npe='datetime64[ns]', freq=None)\n\nIn [37]: idx[2]\nOut[37]: NaT\n\nIn [38]: pd.isna(idx)\nOut[38]: array([False, False,  True])\n```", "```py\nIn [39]: dates = [datetime(2011, 1, 2), datetime(2011, 1, 5),\n ....:          datetime(2011, 1, 7), datetime(2011, 1, 8),\n ....:          datetime(2011, 1, 10), datetime(2011, 1, 12)]\n\nIn [40]: ts = pd.Series(np.random.standard_normal(6), index=dates)\n\nIn [41]: ts\nOut[41]: \n2011-01-02   -0.204708\n2011-01-05    0.478943\n2011-01-07   -0.519439\n2011-01-08   -0.555730\n2011-01-10    1.965781\n2011-01-12    1.393406\ndtype: float64\n```", "```py\nIn [42]: ts.index\nOut[42]: \nDatetimeIndex(['2011-01-02', '2011-01-05', '2011-01-07', '2011-01-08',\n '2011-01-10', '2011-01-12'],\n dtype='datetime64[ns]', freq=None)\n```", "```py\nIn [43]: ts + ts[::2]\nOut[43]: \n2011-01-02   -0.409415\n2011-01-05         NaN\n2011-01-07   -1.038877\n2011-01-08         NaN\n2011-01-10    3.931561\n2011-01-12         NaN\ndtype: float64\n```", "```py\nIn [44]: ts.index.dtype\nOut[44]: dtype('<M8[ns]')\n```", "```py\nIn [45]: stamp = ts.index[0]\n\nIn [46]: stamp\nOut[46]: Timestamp('2011-01-02 00:00:00')\n```", "```py\nIn [47]: stamp = ts.index[2]\n\nIn [48]: ts[stamp]\nOut[48]: -0.5194387150567381\n```", "```py\nIn [49]: ts[\"2011-01-10\"]\nOut[49]: 1.9657805725027142\n```", "```py\nIn [50]: longer_ts = pd.Series(np.random.standard_normal(1000),\n ....:                       index=pd.date_range(\"2000-01-01\", periods=1000))\n\nIn [51]: longer_ts\nOut[51]: \n2000-01-01    0.092908\n2000-01-02    0.281746\n2000-01-03    0.769023\n2000-01-04    1.246435\n2000-01-05    1.007189\n ... \n2002-09-22    0.930944\n2002-09-23   -0.811676\n2002-09-24   -1.830156\n2002-09-25   -0.138730\n2002-09-26    0.334088\nFreq: D, Length: 1000, dtype: float64\n\nIn [52]: longer_ts[\"2001\"]\nOut[52]: \n2001-01-01    1.599534\n2001-01-02    0.474071\n2001-01-03    0.151326\n2001-01-04   -0.542173\n2001-01-05   -0.475496\n ... \n2001-12-27    0.057874\n2001-12-28   -0.433739\n2001-12-29    0.092698\n2001-12-30   -1.397820\n2001-12-31    1.457823\nFreq: D, Length: 365, dtype: float64\n```", "```py\nIn [53]: longer_ts[\"2001-05\"]\nOut[53]: \n2001-05-01   -0.622547\n2001-05-02    0.936289\n2001-05-03    0.750018\n2001-05-04   -0.056715\n2001-05-05    2.300675\n ... \n2001-05-27    0.235477\n2001-05-28    0.111835\n2001-05-29   -1.251504\n2001-05-30   -2.949343\n2001-05-31    0.634634\nFreq: D, Length: 31, dtype: float64\n```", "```py\nIn [54]: ts[datetime(2011, 1, 7):]\nOut[54]: \n2011-01-07   -0.519439\n2011-01-08   -0.555730\n2011-01-10    1.965781\n2011-01-12    1.393406\ndtype: float64\n\nIn [55]: ts[datetime(2011, 1, 7):datetime(2011, 1, 10)]\nOut[55]: \n2011-01-07   -0.519439\n2011-01-08   -0.555730\n2011-01-10    1.965781\ndtype: float64\n```", "```py\nIn [56]: ts\nOut[56]: \n2011-01-02   -0.204708\n2011-01-05    0.478943\n2011-01-07   -0.519439\n2011-01-08   -0.555730\n2011-01-10    1.965781\n2011-01-12    1.393406\ndtype: float64\n\nIn [57]: ts[\"2011-01-06\":\"2011-01-11\"]\nOut[57]: \n2011-01-07   -0.519439\n2011-01-08   -0.555730\n2011-01-10    1.965781\ndtype: float64\n```", "```py\nIn [58]: ts.truncate(after=\"2011-01-09\")\nOut[58]: \n2011-01-02   -0.204708\n2011-01-05    0.478943\n2011-01-07   -0.519439\n2011-01-08   -0.555730\ndtype: float64\n```", "```py\nIn [59]: dates = pd.date_range(\"2000-01-01\", periods=100, freq=\"W-WED\")\n\nIn [60]: long_df = pd.DataFrame(np.random.standard_normal((100, 4)),\n ....:                        index=dates,\n ....:                        columns=[\"Colorado\", \"Texas\",\n ....:                                 \"New York\", \"Ohio\"])\n\nIn [61]: long_df.loc[\"2001-05\"]\nOut[61]: \n Colorado     Texas  New York      Ohio\n2001-05-02 -0.006045  0.490094 -0.277186 -0.707213\n2001-05-09 -0.560107  2.735527  0.927335  1.513906\n2001-05-16  0.538600  1.273768  0.667876 -0.969206\n2001-05-23  1.676091 -0.817649  0.050188  1.951312\n2001-05-30  3.260383  0.963301  1.201206 -1.852001\n```", "```py\nIn [62]: dates = pd.DatetimeIndex([\"2000-01-01\", \"2000-01-02\", \"2000-01-02\",\n ....:                           \"2000-01-02\", \"2000-01-03\"])\n\nIn [63]: dup_ts = pd.Series(np.arange(5), index=dates)\n\nIn [64]: dup_ts\nOut[64]: \n2000-01-01    0\n2000-01-02    1\n2000-01-02    2\n2000-01-02    3\n2000-01-03    4\ndtype: int64\n```", "```py\nIn [65]: dup_ts.index.is_unique\nOut[65]: False\n```", "```py\nIn [66]: dup_ts[\"2000-01-03\"]  # not duplicated\nOut[66]: 4\n\nIn [67]: dup_ts[\"2000-01-02\"]  # duplicated\nOut[67]: \n2000-01-02    1\n2000-01-02    2\n2000-01-02    3\ndtype: int64\n```", "```py\nIn [68]: grouped = dup_ts.groupby(level=0)\n\nIn [69]: grouped.mean()\nOut[69]: \n2000-01-01    0.0\n2000-01-02    2.0\n2000-01-03    4.0\ndtype: float64\n\nIn [70]: grouped.count()\nOut[70]: \n2000-01-01    1\n2000-01-02    3\n2000-01-03    1\ndtype: int64\n```", "```py\nIn [71]: ts\nOut[71]: \n2011-01-02   -0.204708\n2011-01-05    0.478943\n2011-01-07   -0.519439\n2011-01-08   -0.555730\n2011-01-10    1.965781\n2011-01-12    1.393406\ndtype: float64\n\nIn [72]: resampler = ts.resample(\"D\")\n\nIn [73]: resampler\nOut[73]: <pandas.core.resample.DatetimeIndexResampler object at 0x17b0e7bb0>\n```", "```py\nIn [74]: index = pd.date_range(\"2012-04-01\", \"2012-06-01\")\n\nIn [75]: index\nOut[75]: \nDatetimeIndex(['2012-04-01', '2012-04-02', '2012-04-03', '2012-04-04',\n '2012-04-05', '2012-04-06', '2012-04-07', '2012-04-08',\n '2012-04-09', '2012-04-10', '2012-04-11', '2012-04-12',\n '2012-04-13', '2012-04-14', '2012-04-15', '2012-04-16',\n '2012-04-17', '2012-04-18', '2012-04-19', '2012-04-20',\n '2012-04-21', '2012-04-22', '2012-04-23', '2012-04-24',\n '2012-04-25', '2012-04-26', '2012-04-27', '2012-04-28',\n '2012-04-29', '2012-04-30', '2012-05-01', '2012-05-02',\n '2012-05-03', '2012-05-04', '2012-05-05', '2012-05-06',\n '2012-05-07', '2012-05-08', '2012-05-09', '2012-05-10',\n '2012-05-11', '2012-05-12', '2012-05-13', '2012-05-14',\n '2012-05-15', '2012-05-16', '2012-05-17', '2012-05-18',\n '2012-05-19', '2012-05-20', '2012-05-21', '2012-05-22',\n '2012-05-23', '2012-05-24', '2012-05-25', '2012-05-26',\n '2012-05-27', '2012-05-28', '2012-05-29', '2012-05-30',\n '2012-05-31', '2012-06-01'],\n dtype='datetime64[ns]', freq='D')\n```", "```py\nIn [76]: pd.date_range(start=\"2012-04-01\", periods=20)\nOut[76]: \nDatetimeIndex(['2012-04-01', '2012-04-02', '2012-04-03', '2012-04-04',\n '2012-04-05', '2012-04-06', '2012-04-07', '2012-04-08',\n '2012-04-09', '2012-04-10', '2012-04-11', '2012-04-12',\n '2012-04-13', '2012-04-14', '2012-04-15', '2012-04-16',\n '2012-04-17', '2012-04-18', '2012-04-19', '2012-04-20'],\n dtype='datetime64[ns]', freq='D')\n\nIn [77]: pd.date_range(end=\"2012-06-01\", periods=20)\nOut[77]: \nDatetimeIndex(['2012-05-13', '2012-05-14', '2012-05-15', '2012-05-16',\n '2012-05-17', '2012-05-18', '2012-05-19', '2012-05-20',\n '2012-05-21', '2012-05-22', '2012-05-23', '2012-05-24',\n '2012-05-25', '2012-05-26', '2012-05-27', '2012-05-28',\n '2012-05-29', '2012-05-30', '2012-05-31', '2012-06-01'],\n dtype='datetime64[ns]', freq='D')\n```", "```py\nIn [78]: pd.date_range(\"2000-01-01\", \"2000-12-01\", freq=\"BM\")\nOut[78]: \nDatetimeIndex(['2000-01-31', '2000-02-29', '2000-03-31', '2000-04-28',\n '2000-05-31', '2000-06-30', '2000-07-31', '2000-08-31',\n '2000-09-29', '2000-10-31', '2000-11-30'],\n dtype='datetime64[ns]', freq='BM')\n```", "```py\nIn [79]: pd.date_range(\"2012-05-02 12:56:31\", periods=5)\nOut[79]: \nDatetimeIndex(['2012-05-02 12:56:31', '2012-05-03 12:56:31',\n '2012-05-04 12:56:31', '2012-05-05 12:56:31',\n '2012-05-06 12:56:31'],\n dtype='datetime64[ns]', freq='D')\n```", "```py\nIn [80]: pd.date_range(\"2012-05-02 12:56:31\", periods=5, normalize=True)\nOut[80]: \nDatetimeIndex(['2012-05-02', '2012-05-03', '2012-05-04', '2012-05-05',\n '2012-05-06'],\n dtype='datetime64[ns]', freq='D')\n```", "```py\nIn [81]: from pandas.tseries.offsets import Hour, Minute\n\nIn [82]: hour = Hour()\n\nIn [83]: hour\nOut[83]: <Hour>\n```", "```py\nIn [84]: four_hours = Hour(4)\n\nIn [85]: four_hours\nOut[85]: <4 * Hours>\n```", "```py\nIn [86]: pd.date_range(\"2000-01-01\", \"2000-01-03 23:59\", freq=\"4H\")\nOut[86]: \nDatetimeIndex(['2000-01-01 00:00:00', '2000-01-01 04:00:00',\n '2000-01-01 08:00:00', '2000-01-01 12:00:00',\n '2000-01-01 16:00:00', '2000-01-01 20:00:00',\n '2000-01-02 00:00:00', '2000-01-02 04:00:00',\n '2000-01-02 08:00:00', '2000-01-02 12:00:00',\n '2000-01-02 16:00:00', '2000-01-02 20:00:00',\n '2000-01-03 00:00:00', '2000-01-03 04:00:00',\n '2000-01-03 08:00:00', '2000-01-03 12:00:00',\n '2000-01-03 16:00:00', '2000-01-03 20:00:00'],\n dtype='datetime64[ns]', freq='4H')\n```", "```py\nIn [87]: Hour(2) + Minute(30)\nOut[87]: <150 * Minutes>\n```", "```py\nIn [88]: pd.date_range(\"2000-01-01\", periods=10, freq=\"1h30min\")\nOut[88]: \nDatetimeIndex(['2000-01-01 00:00:00', '2000-01-01 01:30:00',\n '2000-01-01 03:00:00', '2000-01-01 04:30:00',\n '2000-01-01 06:00:00', '2000-01-01 07:30:00',\n '2000-01-01 09:00:00', '2000-01-01 10:30:00',\n '2000-01-01 12:00:00', '2000-01-01 13:30:00'],\n dtype='datetime64[ns]', freq='90T')\n```", "```py\nIn [89]: monthly_dates = pd.date_range(\"2012-01-01\", \"2012-09-01\", freq=\"WOM-3FRI\n\")\n\nIn [90]: list(monthly_dates)\nOut[90]: \n[Timestamp('2012-01-20 00:00:00'),\n Timestamp('2012-02-17 00:00:00'),\n Timestamp('2012-03-16 00:00:00'),\n Timestamp('2012-04-20 00:00:00'),\n Timestamp('2012-05-18 00:00:00'),\n Timestamp('2012-06-15 00:00:00'),\n Timestamp('2012-07-20 00:00:00'),\n Timestamp('2012-08-17 00:00:00')]\n```", "```py\nIn [91]: ts = pd.Series(np.random.standard_normal(4),\n ....:                index=pd.date_range(\"2000-01-01\", periods=4, freq=\"M\"))\n\nIn [92]: ts\nOut[92]: \n2000-01-31   -0.066748\n2000-02-29    0.838639\n2000-03-31   -0.117388\n2000-04-30   -0.517795\nFreq: M, dtype: float64\n\nIn [93]: ts.shift(2)\nOut[93]: \n2000-01-31         NaN\n2000-02-29         NaN\n2000-03-31   -0.066748\n2000-04-30    0.838639\nFreq: M, dtype: float64\n\nIn [94]: ts.shift(-2)\nOut[94]: \n2000-01-31   -0.117388\n2000-02-29   -0.517795\n2000-03-31         NaN\n2000-04-30         NaN\nFreq: M, dtype: float64\n```", "```py\nts / ts.shift(1) - 1\n```", "```py\nIn [95]: ts.shift(2, freq=\"M\")\nOut[95]: \n2000-03-31   -0.066748\n2000-04-30    0.838639\n2000-05-31   -0.117388\n2000-06-30   -0.517795\nFreq: M, dtype: float64\n```", "```py\nIn [96]: ts.shift(3, freq=\"D\")\nOut[96]: \n2000-02-03   -0.066748\n2000-03-03    0.838639\n2000-04-03   -0.117388\n2000-05-03   -0.517795\ndtype: float64\n\nIn [97]: ts.shift(1, freq=\"90T\")\nOut[97]: \n2000-01-31 01:30:00   -0.066748\n2000-02-29 01:30:00    0.838639\n2000-03-31 01:30:00   -0.117388\n2000-04-30 01:30:00   -0.517795\ndtype: float64\n```", "```py\nIn [98]: from pandas.tseries.offsets import Day, MonthEnd\n\nIn [99]: now = datetime(2011, 11, 17)\n\nIn [100]: now + 3 * Day()\nOut[100]: Timestamp('2011-11-20 00:00:00')\n```", "```py\nIn [101]: now + MonthEnd()\nOut[101]: Timestamp('2011-11-30 00:00:00')\n\nIn [102]: now + MonthEnd(2)\nOut[102]: Timestamp('2011-12-31 00:00:00')\n```", "```py\nIn [103]: offset = MonthEnd()\n\nIn [104]: offset.rollforward(now)\nOut[104]: Timestamp('2011-11-30 00:00:00')\n\nIn [105]: offset.rollback(now)\nOut[105]: Timestamp('2011-10-31 00:00:00')\n```", "```py\nIn [106]: ts = pd.Series(np.random.standard_normal(20),\n .....:                index=pd.date_range(\"2000-01-15\", periods=20, freq=\"4D\")\n)\n\nIn [107]: ts\nOut[107]: \n2000-01-15   -0.116696\n2000-01-19    2.389645\n2000-01-23   -0.932454\n2000-01-27   -0.229331\n2000-01-31   -1.140330\n2000-02-04    0.439920\n2000-02-08   -0.823758\n2000-02-12   -0.520930\n2000-02-16    0.350282\n2000-02-20    0.204395\n2000-02-24    0.133445\n2000-02-28    0.327905\n2000-03-03    0.072153\n2000-03-07    0.131678\n2000-03-11   -1.297459\n2000-03-15    0.997747\n2000-03-19    0.870955\n2000-03-23   -0.991253\n2000-03-27    0.151699\n2000-03-31    1.266151\nFreq: 4D, dtype: float64\n\nIn [108]: ts.groupby(MonthEnd().rollforward).mean()\nOut[108]: \n2000-01-31   -0.005833\n2000-02-29    0.015894\n2000-03-31    0.150209\ndtype: float64\n```", "```py\nIn [109]: ts.resample(\"M\").mean()\nOut[109]: \n2000-01-31   -0.005833\n2000-02-29    0.015894\n2000-03-31    0.150209\nFreq: M, dtype: float64\n```", "```py\nIn [110]: import pytz\n\nIn [111]: pytz.common_timezones[-5:]\nOut[111]: ['US/Eastern', 'US/Hawaii', 'US/Mountain', 'US/Pacific', 'UTC']\n```", "```py\nIn [112]: tz = pytz.timezone(\"America/New_York\")\n\nIn [113]: tz\nOut[113]: <DstTzInfo 'America/New_York' LMT-1 day, 19:04:00 STD>\n```", "```py\nIn [114]: dates = pd.date_range(\"2012-03-09 09:30\", periods=6)\n\nIn [115]: ts = pd.Series(np.random.standard_normal(len(dates)), index=dates)\n\nIn [116]: ts\nOut[116]: \n2012-03-09 09:30:00   -0.202469\n2012-03-10 09:30:00    0.050718\n2012-03-11 09:30:00    0.639869\n2012-03-12 09:30:00    0.597594\n2012-03-13 09:30:00   -0.797246\n2012-03-14 09:30:00    0.472879\nFreq: D, dtype: float64\n```", "```py\nIn [117]: print(ts.index.tz)\nNone\n```", "```py\nIn [118]: pd.date_range(\"2012-03-09 09:30\", periods=10, tz=\"UTC\")\nOut[118]: \nDatetimeIndex(['2012-03-09 09:30:00+00:00', '2012-03-10 09:30:00+00:00',\n '2012-03-11 09:30:00+00:00', '2012-03-12 09:30:00+00:00',\n '2012-03-13 09:30:00+00:00', '2012-03-14 09:30:00+00:00',\n '2012-03-15 09:30:00+00:00', '2012-03-16 09:30:00+00:00',\n '2012-03-17 09:30:00+00:00', '2012-03-18 09:30:00+00:00'],\n dtype='datetime64[ns, UTC]', freq='D')\n```", "```py\nIn [119]: ts\nOut[119]: \n2012-03-09 09:30:00   -0.202469\n2012-03-10 09:30:00    0.050718\n2012-03-11 09:30:00    0.639869\n2012-03-12 09:30:00    0.597594\n2012-03-13 09:30:00   -0.797246\n2012-03-14 09:30:00    0.472879\nFreq: D, dtype: float64\n\nIn [120]: ts_utc = ts.tz_localize(\"UTC\")\n\nIn [121]: ts_utc\nOut[121]: \n2012-03-09 09:30:00+00:00   -0.202469\n2012-03-10 09:30:00+00:00    0.050718\n2012-03-11 09:30:00+00:00    0.639869\n2012-03-12 09:30:00+00:00    0.597594\n2012-03-13 09:30:00+00:00   -0.797246\n2012-03-14 09:30:00+00:00    0.472879\nFreq: D, dtype: float64\n\nIn [122]: ts_utc.index\nOut[122]: \nDatetimeIndex(['2012-03-09 09:30:00+00:00', '2012-03-10 09:30:00+00:00',\n '2012-03-11 09:30:00+00:00', '2012-03-12 09:30:00+00:00',\n '2012-03-13 09:30:00+00:00', '2012-03-14 09:30:00+00:00'],\n dtype='datetime64[ns, UTC]', freq='D')\n```", "```py\nIn [123]: ts_utc.tz_convert(\"America/New_York\")\nOut[123]: \n2012-03-09 04:30:00-05:00   -0.202469\n2012-03-10 04:30:00-05:00    0.050718\n2012-03-11 05:30:00-04:00    0.639869\n2012-03-12 05:30:00-04:00    0.597594\n2012-03-13 05:30:00-04:00   -0.797246\n2012-03-14 05:30:00-04:00    0.472879\nFreq: D, dtype: float64\n```", "```py\nIn [124]: ts_eastern = ts.tz_localize(\"America/New_York\")\n\nIn [125]: ts_eastern.tz_convert(\"UTC\")\nOut[125]: \n2012-03-09 14:30:00+00:00   -0.202469\n2012-03-10 14:30:00+00:00    0.050718\n2012-03-11 13:30:00+00:00    0.639869\n2012-03-12 13:30:00+00:00    0.597594\n2012-03-13 13:30:00+00:00   -0.797246\n2012-03-14 13:30:00+00:00    0.472879\ndtype: float64\n\nIn [126]: ts_eastern.tz_convert(\"Europe/Berlin\")\nOut[126]: \n2012-03-09 15:30:00+01:00   -0.202469\n2012-03-10 15:30:00+01:00    0.050718\n2012-03-11 14:30:00+01:00    0.639869\n2012-03-12 14:30:00+01:00    0.597594\n2012-03-13 14:30:00+01:00   -0.797246\n2012-03-14 14:30:00+01:00    0.472879\ndtype: float64\n```", "```py\nIn [127]: ts.index.tz_localize(\"Asia/Shanghai\")\nOut[127]: \nDatetimeIndex(['2012-03-09 09:30:00+08:00', '2012-03-10 09:30:00+08:00',\n '2012-03-11 09:30:00+08:00', '2012-03-12 09:30:00+08:00',\n '2012-03-13 09:30:00+08:00', '2012-03-14 09:30:00+08:00'],\n dtype='datetime64[ns, Asia/Shanghai]', freq=None)\n```", "```py\nIn [128]: stamp = pd.Timestamp(\"2011-03-12 04:00\")\n\nIn [129]: stamp_utc = stamp.tz_localize(\"utc\")\n\nIn [130]: stamp_utc.tz_convert(\"America/New_York\")\nOut[130]: Timestamp('2011-03-11 23:00:00-0500', tz='America/New_York')\n```", "```py\nIn [131]: stamp_moscow = pd.Timestamp(\"2011-03-12 04:00\", tz=\"Europe/Moscow\")\n\nIn [132]: stamp_moscow\nOut[132]: Timestamp('2011-03-12 04:00:00+0300', tz='Europe/Moscow')\n```", "```py\nIn [133]: stamp_utc.value\nOut[133]: 1299902400000000000\n\nIn [134]: stamp_utc.tz_convert(\"America/New_York\").value\nOut[134]: 1299902400000000000\n```", "```py\nIn [135]: stamp = pd.Timestamp(\"2012-03-11 01:30\", tz=\"US/Eastern\")\n\nIn [136]: stamp\nOut[136]: Timestamp('2012-03-11 01:30:00-0500', tz='US/Eastern')\n\nIn [137]: stamp + Hour()\nOut[137]: Timestamp('2012-03-11 03:30:00-0400', tz='US/Eastern')\n```", "```py\nIn [138]: stamp = pd.Timestamp(\"2012-11-04 00:30\", tz=\"US/Eastern\")\n\nIn [139]: stamp\nOut[139]: Timestamp('2012-11-04 00:30:00-0400', tz='US/Eastern')\n\nIn [140]: stamp + 2 * Hour()\nOut[140]: Timestamp('2012-11-04 01:30:00-0500', tz='US/Eastern')\n```", "```py\nIn [141]: dates = pd.date_range(\"2012-03-07 09:30\", periods=10, freq=\"B\")\n\nIn [142]: ts = pd.Series(np.random.standard_normal(len(dates)), index=dates)\n\nIn [143]: ts\nOut[143]: \n2012-03-07 09:30:00    0.522356\n2012-03-08 09:30:00   -0.546348\n2012-03-09 09:30:00   -0.733537\n2012-03-12 09:30:00    1.302736\n2012-03-13 09:30:00    0.022199\n2012-03-14 09:30:00    0.364287\n2012-03-15 09:30:00   -0.922839\n2012-03-16 09:30:00    0.312656\n2012-03-19 09:30:00   -1.128497\n2012-03-20 09:30:00   -0.333488\nFreq: B, dtype: float64\n\nIn [144]: ts1 = ts[:7].tz_localize(\"Europe/London\")\n\nIn [145]: ts2 = ts1[2:].tz_convert(\"Europe/Moscow\")\n\nIn [146]: result = ts1 + ts2\n\nIn [147]: result.index\nOut[147]: \nDatetimeIndex(['2012-03-07 09:30:00+00:00', '2012-03-08 09:30:00+00:00',\n '2012-03-09 09:30:00+00:00', '2012-03-12 09:30:00+00:00',\n '2012-03-13 09:30:00+00:00', '2012-03-14 09:30:00+00:00',\n '2012-03-15 09:30:00+00:00'],\n dtype='datetime64[ns, UTC]', freq=None)\n```", "```py\nIn [148]: p = pd.Period(\"2011\", freq=\"A-DEC\")\n\nIn [149]: p\nOut[149]: Period('2011', 'A-DEC')\n```", "```py\nIn [150]: p + 5\nOut[150]: Period('2016', 'A-DEC')\n\nIn [151]: p - 2\nOut[151]: Period('2009', 'A-DEC')\n```", "```py\nIn [152]: pd.Period(\"2014\", freq=\"A-DEC\") - p\nOut[152]: <3 * YearEnds: month=12>\n```", "```py\nIn [153]: periods = pd.period_range(\"2000-01-01\", \"2000-06-30\", freq=\"M\")\n\nIn [154]: periods\nOut[154]: PeriodIndex(['2000-01', '2000-02', '2000-03', '2000-04', '2000-05', '20\n00-06'], dtype='period[M]')\n```", "```py\nIn [155]: pd.Series(np.random.standard_normal(6), index=periods)\nOut[155]: \n2000-01   -0.514551\n2000-02   -0.559782\n2000-03   -0.783408\n2000-04   -1.797685\n2000-05   -0.172670\n2000-06    0.680215\nFreq: M, dtype: float64\n```", "```py\nIn [156]: values = [\"2001Q3\", \"2002Q2\", \"2003Q1\"]\n\nIn [157]: index = pd.PeriodIndex(values, freq=\"Q-DEC\")\n\nIn [158]: index\nOut[158]: PeriodIndex(['2001Q3', '2002Q2', '2003Q1'], dtype='period[Q-DEC]')\n```", "```py\nIn [159]: p = pd.Period(\"2011\", freq=\"A-DEC\")\n\nIn [160]: p\nOut[160]: Period('2011', 'A-DEC')\n\nIn [161]: p.asfreq(\"M\", how=\"start\")\nOut[161]: Period('2011-01', 'M')\n\nIn [162]: p.asfreq(\"M\", how=\"end\")\nOut[162]: Period('2011-12', 'M')\n\nIn [163]: p.asfreq(\"M\")\nOut[163]: Period('2011-12', 'M')\n```", "```py\nIn [164]: p = pd.Period(\"2011\", freq=\"A-JUN\")\n\nIn [165]: p\nOut[165]: Period('2011', 'A-JUN')\n\nIn [166]: p.asfreq(\"M\", how=\"start\")\nOut[166]: Period('2010-07', 'M')\n\nIn [167]: p.asfreq(\"M\", how=\"end\")\nOut[167]: Period('2011-06', 'M')\n```", "```py\nIn [168]: p = pd.Period(\"Aug-2011\", \"M\")\n\nIn [169]: p.asfreq(\"A-JUN\")\nOut[169]: Period('2012', 'A-JUN')\n```", "```py\nIn [170]: periods = pd.period_range(\"2006\", \"2009\", freq=\"A-DEC\")\n\nIn [171]: ts = pd.Series(np.random.standard_normal(len(periods)), index=periods)\n\nIn [172]: ts\nOut[172]: \n2006    1.607578\n2007    0.200381\n2008   -0.834068\n2009   -0.302988\nFreq: A-DEC, dtype: float64\n\nIn [173]: ts.asfreq(\"M\", how=\"start\")\nOut[173]: \n2006-01    1.607578\n2007-01    0.200381\n2008-01   -0.834068\n2009-01   -0.302988\nFreq: M, dtype: float64\n```", "```py\nIn [174]: ts.asfreq(\"B\", how=\"end\")\nOut[174]: \n2006-12-29    1.607578\n2007-12-31    0.200381\n2008-12-31   -0.834068\n2009-12-31   -0.302988\nFreq: B, dtype: float64\n```", "```py\nIn [175]: p = pd.Period(\"2012Q4\", freq=\"Q-JAN\")\n\nIn [176]: p\nOut[176]: Period('2012Q4', 'Q-JAN')\n```", "```py\nIn [177]: p.asfreq(\"D\", how=\"start\")\nOut[177]: Period('2011-11-01', 'D')\n\nIn [178]: p.asfreq(\"D\", how=\"end\")\nOut[178]: Period('2012-01-31', 'D')\n```", "```py\nIn [179]: p4pm = (p.asfreq(\"B\", how=\"end\") - 1).asfreq(\"T\", how=\"start\") + 16 * 6\n0\n\nIn [180]: p4pm\nOut[180]: Period('2012-01-30 16:00', 'T')\n\nIn [181]: p4pm.to_timestamp()\nOut[181]: Timestamp('2012-01-30 16:00:00')\n```", "```py\nIn [182]: periods = pd.period_range(\"2011Q3\", \"2012Q4\", freq=\"Q-JAN\")\n\nIn [183]: ts = pd.Series(np.arange(len(periods)), index=periods)\n\nIn [184]: ts\nOut[184]: \n2011Q3    0\n2011Q4    1\n2012Q1    2\n2012Q2    3\n2012Q3    4\n2012Q4    5\nFreq: Q-JAN, dtype: int64\n\nIn [185]: new_periods = (periods.asfreq(\"B\", \"end\") - 1).asfreq(\"H\", \"start\") + 1\n6\n\nIn [186]: ts.index = new_periods.to_timestamp()\n\nIn [187]: ts\nOut[187]: \n2010-10-28 16:00:00    0\n2011-01-28 16:00:00    1\n2011-04-28 16:00:00    2\n2011-07-28 16:00:00    3\n2011-10-28 16:00:00    4\n2012-01-30 16:00:00    5\ndtype: int64\n```", "```py\nIn [188]: dates = pd.date_range(\"2000-01-01\", periods=3, freq=\"M\")\n\nIn [189]: ts = pd.Series(np.random.standard_normal(3), index=dates)\n\nIn [190]: ts\nOut[190]: \n2000-01-31    1.663261\n2000-02-29   -0.996206\n2000-03-31    1.521760\nFreq: M, dtype: float64\n\nIn [191]: pts = ts.to_period()\n\nIn [192]: pts\nOut[192]: \n2000-01    1.663261\n2000-02   -0.996206\n2000-03    1.521760\nFreq: M, dtype: float64\n```", "```py\nIn [193]: dates = pd.date_range(\"2000-01-29\", periods=6)\n\nIn [194]: ts2 = pd.Series(np.random.standard_normal(6), index=dates)\n\nIn [195]: ts2\nOut[195]: \n2000-01-29    0.244175\n2000-01-30    0.423331\n2000-01-31   -0.654040\n2000-02-01    2.089154\n2000-02-02   -0.060220\n2000-02-03   -0.167933\nFreq: D, dtype: float64\n\nIn [196]: ts2.to_period(\"M\")\nOut[196]: \n2000-01    0.244175\n2000-01    0.423331\n2000-01   -0.654040\n2000-02    2.089154\n2000-02   -0.060220\n2000-02   -0.167933\nFreq: M, dtype: float64\n```", "```py\nIn [197]: pts = ts2.to_period()\n\nIn [198]: pts\nOut[198]: \n2000-01-29    0.244175\n2000-01-30    0.423331\n2000-01-31   -0.654040\n2000-02-01    2.089154\n2000-02-02   -0.060220\n2000-02-03   -0.167933\nFreq: D, dtype: float64\n\nIn [199]: pts.to_timestamp(how=\"end\")\nOut[199]: \n2000-01-29 23:59:59.999999999    0.244175\n2000-01-30 23:59:59.999999999    0.423331\n2000-01-31 23:59:59.999999999   -0.654040\n2000-02-01 23:59:59.999999999    2.089154\n2000-02-02 23:59:59.999999999   -0.060220\n2000-02-03 23:59:59.999999999   -0.167933\nFreq: D, dtype: float64\n```", "```py\nIn [200]: data = pd.read_csv(\"examples/macrodata.csv\")\n\nIn [201]: data.head(5)\nOut[201]: \n year  quarter   realgdp  realcons  realinv  realgovt  realdpi    cpi \n0  1959        1  2710.349    1707.4  286.898   470.045   1886.9  28.98  \\\n1  1959        2  2778.801    1733.7  310.859   481.301   1919.7  29.15 \n2  1959        3  2775.488    1751.8  289.226   491.260   1916.4  29.35 \n3  1959        4  2785.204    1753.7  299.356   484.052   1931.3  29.37 \n4  1960        1  2847.699    1770.5  331.722   462.199   1955.5  29.54 \n m1  tbilrate  unemp      pop  infl  realint \n0  139.7      2.82    5.8  177.146  0.00     0.00 \n1  141.7      3.08    5.1  177.830  2.34     0.74 \n2  140.5      3.82    5.3  178.657  2.74     1.09 \n3  140.0      4.33    5.6  179.386  0.27     4.06 \n4  139.6      3.50    5.2  180.007  2.31     1.19 \n\nIn [202]: data[\"year\"]\nOut[202]: \n0      1959\n1      1959\n2      1959\n3      1959\n4      1960\n ... \n198    2008\n199    2008\n200    2009\n201    2009\n202    2009\nName: year, Length: 203, dtype: int64\n\nIn [203]: data[\"quarter\"]\nOut[203]: \n0      1\n1      2\n2      3\n3      4\n4      1\n ..\n198    3\n199    4\n200    1\n201    2\n202    3\nName: quarter, Length: 203, dtype: int64\n```", "```py\nIn [204]: index = pd.PeriodIndex(year=data[\"year\"], quarter=data[\"quarter\"],\n .....:                        freq=\"Q-DEC\")\n\nIn [205]: index\nOut[205]: \nPeriodIndex(['1959Q1', '1959Q2', '1959Q3', '1959Q4', '1960Q1', '1960Q2',\n '1960Q3', '1960Q4', '1961Q1', '1961Q2',\n ...\n '2007Q2', '2007Q3', '2007Q4', '2008Q1', '2008Q2', '2008Q3',\n '2008Q4', '2009Q1', '2009Q2', '2009Q3'],\n dtype='period[Q-DEC]', length=203)\n\nIn [206]: data.index = index\n\nIn [207]: data[\"infl\"]\nOut[207]: \n1959Q1    0.00\n1959Q2    2.34\n1959Q3    2.74\n1959Q4    0.27\n1960Q1    2.31\n ... \n2008Q3   -3.16\n2008Q4   -8.79\n2009Q1    0.94\n2009Q2    3.37\n2009Q3    3.56\nFreq: Q-DEC, Name: infl, Length: 203, dtype: float64\n```", "```py\nIn [208]: dates = pd.date_range(\"2000-01-01\", periods=100)\n\nIn [209]: ts = pd.Series(np.random.standard_normal(len(dates)), index=dates)\n\nIn [210]: ts\nOut[210]: \n2000-01-01    0.631634\n2000-01-02   -1.594313\n2000-01-03   -1.519937\n2000-01-04    1.108752\n2000-01-05    1.255853\n ... \n2000-04-05   -0.423776\n2000-04-06    0.789740\n2000-04-07    0.937568\n2000-04-08   -2.253294\n2000-04-09   -1.772919\nFreq: D, Length: 100, dtype: float64\n\nIn [211]: ts.resample(\"M\").mean()\nOut[211]: \n2000-01-31   -0.165893\n2000-02-29    0.078606\n2000-03-31    0.223811\n2000-04-30   -0.063643\nFreq: M, dtype: float64\n\nIn [212]: ts.resample(\"M\", kind=\"period\").mean()\nOut[212]: \n2000-01   -0.165893\n2000-02    0.078606\n2000-03    0.223811\n2000-04   -0.063643\nFreq: M, dtype: float64\n```", "```py\nIn [213]: dates = pd.date_range(\"2000-01-01\", periods=12, freq=\"T\")\n\nIn [214]: ts = pd.Series(np.arange(len(dates)), index=dates)\n\nIn [215]: ts\nOut[215]: \n2000-01-01 00:00:00     0\n2000-01-01 00:01:00     1\n2000-01-01 00:02:00     2\n2000-01-01 00:03:00     3\n2000-01-01 00:04:00     4\n2000-01-01 00:05:00     5\n2000-01-01 00:06:00     6\n2000-01-01 00:07:00     7\n2000-01-01 00:08:00     8\n2000-01-01 00:09:00     9\n2000-01-01 00:10:00    10\n2000-01-01 00:11:00    11\nFreq: T, dtype: int64\n```", "```py\nIn [216]: ts.resample(\"5min\").sum()\nOut[216]: \n2000-01-01 00:00:00    10\n2000-01-01 00:05:00    35\n2000-01-01 00:10:00    21\nFreq: 5T, dtype: int64\n```", "```py\nIn [217]: ts.resample(\"5min\", closed=\"right\").sum()\nOut[217]: \n1999-12-31 23:55:00     0\n2000-01-01 00:00:00    15\n2000-01-01 00:05:00    40\n2000-01-01 00:10:00    11\nFreq: 5T, dtype: int64\n```", "```py\nIn [218]: ts.resample(\"5min\", closed=\"right\", label=\"right\").sum()\nOut[218]: \n2000-01-01 00:00:00     0\n2000-01-01 00:05:00    15\n2000-01-01 00:10:00    40\n2000-01-01 00:15:00    11\nFreq: 5T, dtype: int64\n```", "```py\nIn [219]: from pandas.tseries.frequencies import to_offset\n\nIn [220]: result = ts.resample(\"5min\", closed=\"right\", label=\"right\").sum()\n\nIn [221]: result.index = result.index + to_offset(\"-1s\")\n\nIn [222]: result\nOut[222]: \n1999-12-31 23:59:59     0\n2000-01-01 00:04:59    15\n2000-01-01 00:09:59    40\n2000-01-01 00:14:59    11\nFreq: 5T, dtype: int64\n```", "```py\nIn [223]: ts = pd.Series(np.random.permutation(np.arange(len(dates))), index=date\ns)\n\nIn [224]: ts.resample(\"5min\").ohlc()\nOut[224]: \n open  high  low  close\n2000-01-01 00:00:00     8     8    1      5\n2000-01-01 00:05:00     6    11    2      2\n2000-01-01 00:10:00     0     7    0      7\n```", "```py\nIn [225]: frame = pd.DataFrame(np.random.standard_normal((2, 4)),\n .....:                      index=pd.date_range(\"2000-01-01\", periods=2,\n .....:                                          freq=\"W-WED\"),\n .....:                      columns=[\"Colorado\", \"Texas\", \"New York\", \"Ohio\"])\n\nIn [226]: frame\nOut[226]: \n Colorado     Texas  New York      Ohio\n2000-01-05 -0.896431  0.927238  0.482284 -0.867130\n2000-01-12  0.493841 -0.155434  1.397286  1.507055\n```", "```py\nIn [227]: df_daily = frame.resample(\"D\").asfreq()\n\nIn [228]: df_daily\nOut[228]: \n Colorado     Texas  New York      Ohio\n2000-01-05 -0.896431  0.927238  0.482284 -0.867130\n2000-01-06       NaN       NaN       NaN       NaN\n2000-01-07       NaN       NaN       NaN       NaN\n2000-01-08       NaN       NaN       NaN       NaN\n2000-01-09       NaN       NaN       NaN       NaN\n2000-01-10       NaN       NaN       NaN       NaN\n2000-01-11       NaN       NaN       NaN       NaN\n2000-01-12  0.493841 -0.155434  1.397286  1.507055\n```", "```py\nIn [229]: frame.resample(\"D\").ffill()\nOut[229]: \n Colorado     Texas  New York      Ohio\n2000-01-05 -0.896431  0.927238  0.482284 -0.867130\n2000-01-06 -0.896431  0.927238  0.482284 -0.867130\n2000-01-07 -0.896431  0.927238  0.482284 -0.867130\n2000-01-08 -0.896431  0.927238  0.482284 -0.867130\n2000-01-09 -0.896431  0.927238  0.482284 -0.867130\n2000-01-10 -0.896431  0.927238  0.482284 -0.867130\n2000-01-11 -0.896431  0.927238  0.482284 -0.867130\n2000-01-12  0.493841 -0.155434  1.397286  1.507055\n```", "```py\nIn [230]: frame.resample(\"D\").ffill(limit=2)\nOut[230]: \n Colorado     Texas  New York      Ohio\n2000-01-05 -0.896431  0.927238  0.482284 -0.867130\n2000-01-06 -0.896431  0.927238  0.482284 -0.867130\n2000-01-07 -0.896431  0.927238  0.482284 -0.867130\n2000-01-08       NaN       NaN       NaN       NaN\n2000-01-09       NaN       NaN       NaN       NaN\n2000-01-10       NaN       NaN       NaN       NaN\n2000-01-11       NaN       NaN       NaN       NaN\n2000-01-12  0.493841 -0.155434  1.397286  1.507055\n```", "```py\nIn [231]: frame.resample(\"W-THU\").ffill()\nOut[231]: \n Colorado     Texas  New York      Ohio\n2000-01-06 -0.896431  0.927238  0.482284 -0.867130\n2000-01-13  0.493841 -0.155434  1.397286  1.507055\n```", "```py\nIn [232]: frame = pd.DataFrame(np.random.standard_normal((24, 4)),\n .....:                      index=pd.period_range(\"1-2000\", \"12-2001\",\n .....:                                            freq=\"M\"),\n .....:                      columns=[\"Colorado\", \"Texas\", \"New York\", \"Ohio\"])\n\nIn [233]: frame.head()\nOut[233]: \n Colorado     Texas  New York      Ohio\n2000-01 -1.179442  0.443171  1.395676 -0.529658\n2000-02  0.787358  0.248845  0.743239  1.267746\n2000-03  1.302395 -0.272154 -0.051532 -0.467740\n2000-04 -1.040816  0.426419  0.312945 -1.115689\n2000-05  1.234297 -1.893094 -1.661605 -0.005477\n\nIn [234]: annual_frame = frame.resample(\"A-DEC\").mean()\n\nIn [235]: annual_frame\nOut[235]: \n Colorado     Texas  New York      Ohio\n2000  0.487329  0.104466  0.020495 -0.273945\n2001  0.203125  0.162429  0.056146 -0.103794\n```", "```py\n# Q-DEC: Quarterly, year ending in December\nIn [236]: annual_frame.resample(\"Q-DEC\").ffill()\nOut[236]: \n Colorado     Texas  New York      Ohio\n2000Q1  0.487329  0.104466  0.020495 -0.273945\n2000Q2  0.487329  0.104466  0.020495 -0.273945\n2000Q3  0.487329  0.104466  0.020495 -0.273945\n2000Q4  0.487329  0.104466  0.020495 -0.273945\n2001Q1  0.203125  0.162429  0.056146 -0.103794\n2001Q2  0.203125  0.162429  0.056146 -0.103794\n2001Q3  0.203125  0.162429  0.056146 -0.103794\n2001Q4  0.203125  0.162429  0.056146 -0.103794\n\nIn [237]: annual_frame.resample(\"Q-DEC\", convention=\"end\").asfreq()\nOut[237]: \n Colorado     Texas  New York      Ohio\n2000Q4  0.487329  0.104466  0.020495 -0.273945\n2001Q1       NaN       NaN       NaN       NaN\n2001Q2       NaN       NaN       NaN       NaN\n2001Q3       NaN       NaN       NaN       NaN\n2001Q4  0.203125  0.162429  0.056146 -0.103794\n```", "```py\nIn [238]: annual_frame.resample(\"Q-MAR\").ffill()\nOut[238]: \n Colorado     Texas  New York      Ohio\n2000Q4  0.487329  0.104466  0.020495 -0.273945\n2001Q1  0.487329  0.104466  0.020495 -0.273945\n2001Q2  0.487329  0.104466  0.020495 -0.273945\n2001Q3  0.487329  0.104466  0.020495 -0.273945\n2001Q4  0.203125  0.162429  0.056146 -0.103794\n2002Q1  0.203125  0.162429  0.056146 -0.103794\n2002Q2  0.203125  0.162429  0.056146 -0.103794\n2002Q3  0.203125  0.162429  0.056146 -0.103794\n```", "```py\nIn [239]: N = 15\n\nIn [240]: times = pd.date_range(\"2017-05-20 00:00\", freq=\"1min\", periods=N)\n\nIn [241]: df = pd.DataFrame({\"time\": times,\n .....:                    \"value\": np.arange(N)})\n\nIn [242]: df\nOut[242]: \n time  value\n0  2017-05-20 00:00:00      0\n1  2017-05-20 00:01:00      1\n2  2017-05-20 00:02:00      2\n3  2017-05-20 00:03:00      3\n4  2017-05-20 00:04:00      4\n5  2017-05-20 00:05:00      5\n6  2017-05-20 00:06:00      6\n7  2017-05-20 00:07:00      7\n8  2017-05-20 00:08:00      8\n9  2017-05-20 00:09:00      9\n10 2017-05-20 00:10:00     10\n11 2017-05-20 00:11:00     11\n12 2017-05-20 00:12:00     12\n13 2017-05-20 00:13:00     13\n14 2017-05-20 00:14:00     14\n```", "```py\nIn [243]: df.set_index(\"time\").resample(\"5min\").count()\nOut[243]: \n value\ntime \n2017-05-20 00:00:00      5\n2017-05-20 00:05:00      5\n2017-05-20 00:10:00      5\n```", "```py\nIn [244]: df2 = pd.DataFrame({\"time\": times.repeat(3),\n .....:                     \"key\": np.tile([\"a\", \"b\", \"c\"], N),\n .....:                     \"value\": np.arange(N * 3.)})\n\nIn [245]: df2.head(7)\nOut[245]: \n time key  value\n0 2017-05-20 00:00:00   a    0.0\n1 2017-05-20 00:00:00   b    1.0\n2 2017-05-20 00:00:00   c    2.0\n3 2017-05-20 00:01:00   a    3.0\n4 2017-05-20 00:01:00   b    4.0\n5 2017-05-20 00:01:00   c    5.0\n6 2017-05-20 00:02:00   a    6.0\n```", "```py\nIn [246]: time_key = pd.Grouper(freq=\"5min\")\n```", "```py\nIn [247]: resampled = (df2.set_index(\"time\")\n .....:              .groupby([\"key\", time_key])\n .....:              .sum())\n\nIn [248]: resampled\nOut[248]: \n value\nkey time \na   2017-05-20 00:00:00   30.0\n 2017-05-20 00:05:00  105.0\n 2017-05-20 00:10:00  180.0\nb   2017-05-20 00:00:00   35.0\n 2017-05-20 00:05:00  110.0\n 2017-05-20 00:10:00  185.0\nc   2017-05-20 00:00:00   40.0\n 2017-05-20 00:05:00  115.0\n 2017-05-20 00:10:00  190.0\n\nIn [249]: resampled.reset_index()\nOut[249]: \n key                time  value\n0   a 2017-05-20 00:00:00   30.0\n1   a 2017-05-20 00:05:00  105.0\n2   a 2017-05-20 00:10:00  180.0\n3   b 2017-05-20 00:00:00   35.0\n4   b 2017-05-20 00:05:00  110.0\n5   b 2017-05-20 00:10:00  185.0\n6   c 2017-05-20 00:00:00   40.0\n7   c 2017-05-20 00:05:00  115.0\n8   c 2017-05-20 00:10:00  190.0\n```", "```py\nIn [250]: close_px_all = pd.read_csv(\"examples/stock_px.csv\",\n .....:                            parse_dates=True, index_col=0)\n\nIn [251]: close_px = close_px_all[[\"AAPL\", \"MSFT\", \"XOM\"]]\n\nIn [252]: close_px = close_px.resample(\"B\").ffill()\n```", "```py\nIn [253]: close_px[\"AAPL\"].plot()\nOut[253]: <Axes: >\n\nIn [254]: close_px[\"AAPL\"].rolling(250).mean().plot()\n```", "```py\nIn [255]: plt.figure()\nOut[255]: <Figure size 1000x600 with 0 Axes>\n\nIn [256]: std250 = close_px[\"AAPL\"].pct_change().rolling(250, min_periods=10).std\n()\n\nIn [257]: std250[5:12]\nOut[257]: \n2003-01-09         NaN\n2003-01-10         NaN\n2003-01-13         NaN\n2003-01-14         NaN\n2003-01-15         NaN\n2003-01-16    0.009628\n2003-01-17    0.013818\nFreq: B, Name: AAPL, dtype: float64\n\nIn [258]: std250.plot()\n```", "```py\nIn [259]: expanding_mean = std250.expanding().mean()\n```", "```py\nIn [261]: plt.style.use('grayscale')\n\nIn [262]: close_px.rolling(60).mean().plot(logy=True)\n```", "```py\nIn [263]: close_px.rolling(\"20D\").mean()\nOut[263]: \n AAPL       MSFT        XOM\n2003-01-02    7.400000  21.110000  29.220000\n2003-01-03    7.425000  21.125000  29.230000\n2003-01-06    7.433333  21.256667  29.473333\n2003-01-07    7.432500  21.425000  29.342500\n2003-01-08    7.402000  21.402000  29.240000\n...                ...        ...        ...\n2011-10-10  389.351429  25.602143  72.527857\n2011-10-11  388.505000  25.674286  72.835000\n2011-10-12  388.531429  25.810000  73.400714\n2011-10-13  388.826429  25.961429  73.905000\n2011-10-14  391.038000  26.048667  74.185333\n[2292 rows x 3 columns]\n```", "```py\nIn [265]: aapl_px = close_px[\"AAPL\"][\"2006\":\"2007\"]\n\nIn [266]: ma30 = aapl_px.rolling(30, min_periods=20).mean()\n\nIn [267]: ewma30 = aapl_px.ewm(span=30).mean()\n\nIn [268]: aapl_px.plot(style=\"k-\", label=\"Price\")\nOut[268]: <Axes: >\n\nIn [269]: ma30.plot(style=\"k--\", label=\"Simple Moving Avg\")\nOut[269]: <Axes: >\n\nIn [270]: ewma30.plot(style=\"k-\", label=\"EW MA\")\nOut[270]: <Axes: >\n\nIn [271]: plt.legend()\n```", "```py\nIn [273]: spx_px = close_px_all[\"SPX\"]\n\nIn [274]: spx_rets = spx_px.pct_change()\n\nIn [275]: returns = close_px.pct_change()\n```", "```py\nIn [276]: corr = returns[\"AAPL\"].rolling(125, min_periods=100).corr(spx_rets)\n\nIn [277]: corr.plot()\n```", "```py\nIn [279]: corr = returns.rolling(125, min_periods=100).corr(spx_rets)\n\nIn [280]: corr.plot()\n```", "```py\nIn [282]: from scipy.stats import percentileofscore\n\nIn [283]: def score_at_2percent(x):\n .....:     return percentileofscore(x, 0.02)\n\nIn [284]: result = returns[\"AAPL\"].rolling(250).apply(score_at_2percent)\n\nIn [285]: result.plot()\n```", "```py\nconda install scipy\n```"]