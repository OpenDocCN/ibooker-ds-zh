["```py\nIn [5]: path = \"datasets/bitly_usagov/example.txt\"\n\nIn [6]: with open(path) as f:\n ...:     print(f.readline())\n ...:\n{ \"a\": \"Mozilla\\\\/5.0 (Windows NT 6.1; WOW64) AppleWebKit\\\\/535.11\n(KHTML, like Gecko) Chrome\\\\/17.0.963.78 Safari\\\\/535.11\", \"c\": \"US\", \"nk\": 1,\n\"tz\": \"America\\\\/New_York\", \"gr\": \"MA\", \"g\": \"A6qOVH\", \"h\": \"wfLQtf\", \"l\":\n\"orofrog\", \"al\": \"en-US,en;q=0.8\", \"hh\": \"1.usa.gov\", \"r\":\n\"http:\\\\/\\\\/www.facebook.com\\\\/l\\\\/7AQEFzjSi\\\\/1.usa.gov\\\\/wfLQtf\", \"u\":\n\"http:\\\\/\\\\/www.ncbi.nlm.nih.gov\\\\/pubmed\\\\/22415991\", \"t\": 1331923247, \"hc\":\n1331822918, \"cy\": \"Danvers\", \"ll\": [ 42.576698, -70.954903 ] }\n```", "```py\nimport json\nwith open(path) as f:\n records = [json.loads(line) for line in f]\n```", "```py\nIn [18]: records[0]\nOut[18]:\n{'a': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko)\nChrome/17.0.963.78 Safari/535.11',\n 'al': 'en-US,en;q=0.8',\n 'c': 'US',\n 'cy': 'Danvers',\n 'g': 'A6qOVH',\n 'gr': 'MA',\n 'h': 'wfLQtf',\n 'hc': 1331822918,\n 'hh': '1.usa.gov',\n 'l': 'orofrog',\n 'll': [42.576698, -70.954903],\n 'nk': 1,\n 'r': 'http://www.facebook.com/l/7AQEFzjSi/1.usa.gov/wfLQtf',\n 't': 1331923247,\n 'tz': 'America/New_York',\n 'u': 'http://www.ncbi.nlm.nih.gov/pubmed/22415991'}\n```", "```py\nIn [15]: time_zones = [rec[\"tz\"] for rec in records]\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\n<ipython-input-15-abdeba901c13> in <module>\n----> 1 time_zones = [rec[\"tz\"] for rec in records]\n<ipython-input-15-abdeba901c13> in <listcomp>(.0)\n----> 1 time_zones = [rec[\"tz\"] for rec in records]\nKeyError: 'tz'\n```", "```py\nIn [16]: time_zones = [rec[\"tz\"] for rec in records if \"tz\" in rec]\n\nIn [17]: time_zones[:10]\nOut[17]: \n['America/New_York',\n 'America/Denver',\n 'America/New_York',\n 'America/Sao_Paulo',\n 'America/New_York',\n 'America/New_York',\n 'Europe/Warsaw',\n '',\n '',\n '']\n```", "```py\ndef get_counts(sequence):\n counts = {}\n for x in sequence:\n if x in counts:\n counts[x] += 1\n else:\n counts[x] = 1\n return counts\n```", "```py\nfrom collections import defaultdict\n\ndef get_counts2(sequence):\n counts = defaultdict(int) # values will initialize to 0\n for x in sequence:\n counts[x] += 1\n return counts\n```", "```py\nIn [20]: counts = get_counts(time_zones)\n\nIn [21]: counts[\"America/New_York\"]\nOut[21]: 1251\n\nIn [22]: len(time_zones)\nOut[22]: 3440\n```", "```py\ndef top_counts(count_dict, n=10):\n value_key_pairs = [(count, tz) for tz, count in count_dict.items()]\n value_key_pairs.sort()\n return value_key_pairs[-n:]\n```", "```py\nIn [24]: top_counts(counts)\nOut[24]: \n[(33, 'America/Sao_Paulo'),\n (35, 'Europe/Madrid'),\n (36, 'Pacific/Honolulu'),\n (37, 'Asia/Tokyo'),\n (74, 'Europe/London'),\n (191, 'America/Denver'),\n (382, 'America/Los_Angeles'),\n (400, 'America/Chicago'),\n (521, ''),\n (1251, 'America/New_York')]\n```", "```py\nIn [25]: from collections import Counter\n\nIn [26]: counts = Counter(time_zones)\n\nIn [27]: counts.most_common(10)\nOut[27]: \n[('America/New_York', 1251),\n ('', 521),\n ('America/Chicago', 400),\n ('America/Los_Angeles', 382),\n ('America/Denver', 191),\n ('Europe/London', 74),\n ('Asia/Tokyo', 37),\n ('Pacific/Honolulu', 36),\n ('Europe/Madrid', 35),\n ('America/Sao_Paulo', 33)]\n```", "```py\nIn [28]: frame = pd.DataFrame(records)\n```", "```py\nIn [29]: frame.info()\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3560 entries, 0 to 3559\nData columns (total 18 columns):\n #   Column       Non-Null Count  Dtype \n---  ------       --------------  ----- \n 0   a            3440 non-null   object \n 1   c            2919 non-null   object \n 2   nk           3440 non-null   float64\n 3   tz           3440 non-null   object \n 4   gr           2919 non-null   object \n 5   g            3440 non-null   object \n 6   h            3440 non-null   object \n 7   l            3440 non-null   object \n 8   al           3094 non-null   object \n 9   hh           3440 non-null   object \n 10  r            3440 non-null   object \n 11  u            3440 non-null   object \n 12  t            3440 non-null   float64\n 13  hc           3440 non-null   float64\n 14  cy           2919 non-null   object \n 15  ll           2919 non-null   object \n 16  _heartbeat_  120 non-null    float64\n 17  kw           93 non-null     object \ndtypes: float64(4), object(14)\nmemory usage: 500.8+ KB\n\nIn [30]: frame[\"tz\"].head()\nOut[30]: \n0     America/New_York\n1       America/Denver\n2     America/New_York\n3    America/Sao_Paulo\n4     America/New_York\nName: tz, dtype: object\n```", "```py\nIn [31]: tz_counts = frame[\"tz\"].value_counts()\n\nIn [32]: tz_counts.head()\nOut[32]: \ntz\nAmerica/New_York       1251\n 521\nAmerica/Chicago         400\nAmerica/Los_Angeles     382\nAmerica/Denver          191\nName: count, dtype: int64\n```", "```py\nIn [33]: clean_tz = frame[\"tz\"].fillna(\"Missing\")\n\nIn [34]: clean_tz[clean_tz == \"\"] = \"Unknown\"\n\nIn [35]: tz_counts = clean_tz.value_counts()\n\nIn [36]: tz_counts.head()\nOut[36]: \ntz\nAmerica/New_York       1251\nUnknown                 521\nAmerica/Chicago         400\nAmerica/Los_Angeles     382\nAmerica/Denver          191\nName: count, dtype: int64\n```", "```py\nIn [38]: import seaborn as sns\n\nIn [39]: subset = tz_counts.head()\n\nIn [40]: sns.barplot(y=subset.index, x=subset.to_numpy())\n```", "```py\nIn [41]: frame[\"a\"][1]\nOut[41]: 'GoogleMaps/RochesterNY'\n\nIn [42]: frame[\"a\"][50]\nOut[42]: 'Mozilla/5.0 (Windows NT 5.1; rv:10.0.2) Gecko/20100101 Firefox/10.0.2'\n\nIn [43]: frame[\"a\"][51][:50]  # long line\nOut[43]: 'Mozilla/5.0 (Linux; U; Android 2.2.2; en-us; LG-P9'\n```", "```py\nIn [44]: results = pd.Series([x.split()[0] for x in frame[\"a\"].dropna()])\n\nIn [45]: results.head(5)\nOut[45]: \n0               Mozilla/5.0\n1    GoogleMaps/RochesterNY\n2               Mozilla/4.0\n3               Mozilla/5.0\n4               Mozilla/5.0\ndtype: object\n\nIn [46]: results.value_counts().head(8)\nOut[46]: \nMozilla/5.0                 2594\nMozilla/4.0                  601\nGoogleMaps/RochesterNY       121\nOpera/9.80                    34\nTEST_INTERNET_AGENT           24\nGoogleProducer                21\nMozilla/6.0                    5\nBlackBerry8520/5.0.0.681       4\nName: count, dtype: int64\n```", "```py\nIn [47]: cframe = frame[frame[\"a\"].notna()].copy()\n```", "```py\nIn [48]: cframe[\"os\"] = np.where(cframe[\"a\"].str.contains(\"Windows\"),\n ....:                         \"Windows\", \"Not Windows\")\n\nIn [49]: cframe[\"os\"].head(5)\nOut[49]: \n0        Windows\n1    Not Windows\n2        Windows\n3    Not Windows\n4        Windows\nName: os, dtype: object\n```", "```py\nIn [50]: by_tz_os = cframe.groupby([\"tz\", \"os\"])\n```", "```py\nIn [51]: agg_counts = by_tz_os.size().unstack().fillna(0)\n\nIn [52]: agg_counts.head()\nOut[52]: \nos                   Not Windows  Windows\ntz \n 245.0    276.0\nAfrica/Cairo                 0.0      3.0\nAfrica/Casablanca            0.0      1.0\nAfrica/Ceuta                 0.0      2.0\nAfrica/Johannesburg          0.0      1.0\n```", "```py\nIn [53]: indexer = agg_counts.sum(\"columns\").argsort()\n\nIn [54]: indexer.values[:10]\nOut[54]: array([24, 20, 21, 92, 87, 53, 54, 57, 26, 55])\n```", "```py\nIn [55]: count_subset = agg_counts.take(indexer[-10:])\n\nIn [56]: count_subset\nOut[56]: \nos                   Not Windows  Windows\ntz \nAmerica/Sao_Paulo           13.0     20.0\nEurope/Madrid               16.0     19.0\nPacific/Honolulu             0.0     36.0\nAsia/Tokyo                   2.0     35.0\nEurope/London               43.0     31.0\nAmerica/Denver             132.0     59.0\nAmerica/Los_Angeles        130.0    252.0\nAmerica/Chicago            115.0    285.0\n 245.0    276.0\nAmerica/New_York           339.0    912.0\n```", "```py\nIn [57]: agg_counts.sum(axis=\"columns\").nlargest(10)\nOut[57]: \ntz\nAmerica/New_York       1251.0\n 521.0\nAmerica/Chicago         400.0\nAmerica/Los_Angeles     382.0\nAmerica/Denver          191.0\nEurope/London            74.0\nAsia/Tokyo               37.0\nPacific/Honolulu         36.0\nEurope/Madrid            35.0\nAmerica/Sao_Paulo        33.0\ndtype: float64\n```", "```py\nIn [59]: count_subset = count_subset.stack()\n\nIn [60]: count_subset.name = \"total\"\n\nIn [61]: count_subset = count_subset.reset_index()\n\nIn [62]: count_subset.head(10)\nOut[62]: \n tz           os  total\n0  America/Sao_Paulo  Not Windows   13.0\n1  America/Sao_Paulo      Windows   20.0\n2      Europe/Madrid  Not Windows   16.0\n3      Europe/Madrid      Windows   19.0\n4   Pacific/Honolulu  Not Windows    0.0\n5   Pacific/Honolulu      Windows   36.0\n6         Asia/Tokyo  Not Windows    2.0\n7         Asia/Tokyo      Windows   35.0\n8      Europe/London  Not Windows   43.0\n9      Europe/London      Windows   31.0\n\nIn [63]: sns.barplot(x=\"total\", y=\"tz\", hue=\"os\",  data=count_subset)\n```", "```py\ndef norm_total(group):\n group[\"normed_total\"] = group[\"total\"] / group[\"total\"].sum()\n return group\n\nresults = count_subset.groupby(\"tz\").apply(norm_total)\n```", "```py\nIn [66]: sns.barplot(x=\"normed_total\", y=\"tz\", hue=\"os\",  data=results)\n```", "```py\nIn [67]: g = count_subset.groupby(\"tz\")\n\nIn [68]: results2 = count_subset[\"total\"] / g[\"total\"].transform(\"sum\")\n```", "```py\nunames = [\"user_id\", \"gender\", \"age\", \"occupation\", \"zip\"]\nusers = pd.read_table(\"datasets/movielens/users.dat\", sep=\"::\",\n header=None, names=unames, engine=\"python\")\n\nrnames = [\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]\nratings = pd.read_table(\"datasets/movielens/ratings.dat\", sep=\"::\",\n header=None, names=rnames, engine=\"python\")\n\nmnames = [\"movie_id\", \"title\", \"genres\"]\nmovies = pd.read_table(\"datasets/movielens/movies.dat\", sep=\"::\",\n header=None, names=mnames, engine=\"python\")\n```", "```py\nIn [70]: users.head(5)\nOut[70]: \n user_id gender  age  occupation    zip\n0        1      F    1          10  48067\n1        2      M   56          16  70072\n2        3      M   25          15  55117\n3        4      M   45           7  02460\n4        5      M   25          20  55455\n\nIn [71]: ratings.head(5)\nOut[71]: \n user_id  movie_id  rating  timestamp\n0        1      1193       5  978300760\n1        1       661       3  978302109\n2        1       914       3  978301968\n3        1      3408       4  978300275\n4        1      2355       5  978824291\n\nIn [72]: movies.head(5)\nOut[72]: \n movie_id                               title                        genres\n0         1                    Toy Story (1995)   Animation|Children's|Comedy\n1         2                      Jumanji (1995)  Adventure|Children's|Fantasy\n2         3             Grumpier Old Men (1995)                Comedy|Romance\n3         4            Waiting to Exhale (1995)                  Comedy|Drama\n4         5  Father of the Bride Part II (1995)                        Comedy\n\nIn [73]: ratings\nOut[73]: \n user_id  movie_id  rating  timestamp\n0              1      1193       5  978300760\n1              1       661       3  978302109\n2              1       914       3  978301968\n3              1      3408       4  978300275\n4              1      2355       5  978824291\n...          ...       ...     ...        ...\n1000204     6040      1091       1  956716541\n1000205     6040      1094       5  956704887\n1000206     6040       562       5  956704746\n1000207     6040      1096       4  956715648\n1000208     6040      1097       4  956715569\n[1000209 rows x 4 columns]\n```", "```py\nIn [74]: data = pd.merge(pd.merge(ratings, users), movies)\n\nIn [75]: data\nOut[75]: \n user_id  movie_id  rating  timestamp gender  age  occupation    zip \n0              1      1193       5  978300760      F    1          10  48067  \\\n1              2      1193       5  978298413      M   56          16  70072 \n2             12      1193       4  978220179      M   25          12  32793 \n3             15      1193       4  978199279      M   25           7  22903 \n4             17      1193       5  978158471      M   50           1  95350 \n...          ...       ...     ...        ...    ...  ...         ...    ... \n1000204     5949      2198       5  958846401      M   18          17  47901 \n1000205     5675      2703       3  976029116      M   35          14  30030 \n1000206     5780      2845       1  958153068      M   18          17  92886 \n1000207     5851      3607       5  957756608      F   18          20  55410 \n1000208     5938      2909       4  957273353      M   25           1  35401 \n title                genres \n0             One Flew Over the Cuckoo's Nest (1975)                 Drama \n1             One Flew Over the Cuckoo's Nest (1975)                 Drama \n2             One Flew Over the Cuckoo's Nest (1975)                 Drama \n3             One Flew Over the Cuckoo's Nest (1975)                 Drama \n4             One Flew Over the Cuckoo's Nest (1975)                 Drama \n...                                              ...                   ... \n1000204                           Modulations (1998)           Documentary \n1000205                        Broken Vessels (1998)                 Drama \n1000206                            White Boys (1999)                 Drama \n1000207                     One Little Indian (1973)  Comedy|Drama|Western \n1000208  Five Wives, Three Secretaries and Me (1998)           Documentary \n[1000209 rows x 10 columns]\n\nIn [76]: data.iloc[0]\nOut[76]: \nuser_id                                            1\nmovie_id                                        1193\nrating                                             5\ntimestamp                                  978300760\ngender                                             F\nage                                                1\noccupation                                        10\nzip                                            48067\ntitle         One Flew Over the Cuckoo's Nest (1975)\ngenres                                         Drama\nName: 0, dtype: object\n```", "```py\nIn [77]: mean_ratings = data.pivot_table(\"rating\", index=\"title\",\n ....:                                 columns=\"gender\", aggfunc=\"mean\")\n\nIn [78]: mean_ratings.head(5)\nOut[78]: \ngender                                F         M\ntitle \n$1,000,000 Duck (1971)         3.375000  2.761905\n'Night Mother (1986)           3.388889  3.352941\n'Til There Was You (1997)      2.675676  2.733333\n'burbs, The (1989)             2.793478  2.962085\n...And Justice for All (1979)  3.828571  3.689024\n```", "```py\nIn [79]: ratings_by_title = data.groupby(\"title\").size()\n\nIn [80]: ratings_by_title.head()\nOut[80]: \ntitle\n$1,000,000 Duck (1971)            37\n'Night Mother (1986)              70\n'Til There Was You (1997)         52\n'burbs, The (1989)               303\n...And Justice for All (1979)    199\ndtype: int64\n\nIn [81]: active_titles = ratings_by_title.index[ratings_by_title >= 250]\n\nIn [82]: active_titles\nOut[82]: \nIndex([''burbs, The (1989)', '10 Things I Hate About You (1999)',\n '101 Dalmatians (1961)', '101 Dalmatians (1996)', '12 Angry Men (1957)',\n '13th Warrior, The (1999)', '2 Days in the Valley (1996)',\n '20,000 Leagues Under the Sea (1954)', '2001: A Space Odyssey (1968)',\n '2010 (1984)',\n ...\n 'X-Men (2000)', 'Year of Living Dangerously (1982)',\n 'Yellow Submarine (1968)', 'You've Got Mail (1998)',\n 'Young Frankenstein (1974)', 'Young Guns (1988)',\n 'Young Guns II (1990)', 'Young Sherlock Holmes (1985)',\n 'Zero Effect (1998)', 'eXistenZ (1999)'],\n dtype='object', name='title', length=1216)\n```", "```py\nIn [83]: mean_ratings = mean_ratings.loc[active_titles]\n\nIn [84]: mean_ratings\nOut[84]: \ngender                                    F         M\ntitle \n'burbs, The (1989)                 2.793478  2.962085\n10 Things I Hate About You (1999)  3.646552  3.311966\n101 Dalmatians (1961)              3.791444  3.500000\n101 Dalmatians (1996)              3.240000  2.911215\n12 Angry Men (1957)                4.184397  4.328421\n...                                     ...       ...\nYoung Guns (1988)                  3.371795  3.425620\nYoung Guns II (1990)               2.934783  2.904025\nYoung Sherlock Holmes (1985)       3.514706  3.363344\nZero Effect (1998)                 3.864407  3.723140\neXistenZ (1999)                    3.098592  3.289086\n[1216 rows x 2 columns]\n```", "```py\nIn [86]: top_female_ratings = mean_ratings.sort_values(\"F\", ascending=False)\n\nIn [87]: top_female_ratings.head()\nOut[87]: \ngender                                                         F         M\ntitle \nClose Shave, A (1995)                                   4.644444  4.473795\nWrong Trousers, The (1993)                              4.588235  4.478261\nSunset Blvd. (a.k.a. Sunset Boulevard) (1950)           4.572650  4.464589\nWallace & Gromit: The Best of Aardman Animation (1996)  4.563107  4.385075\nSchindler's List (1993)                                 4.562602  4.491415\n```", "```py\nIn [88]: mean_ratings[\"diff\"] = mean_ratings[\"M\"] - mean_ratings[\"F\"]\n```", "```py\nIn [89]: sorted_by_diff = mean_ratings.sort_values(\"diff\")\n\nIn [90]: sorted_by_diff.head()\nOut[90]: \ngender                            F         M      diff\ntitle \nDirty Dancing (1987)       3.790378  2.959596 -0.830782\nJumpin' Jack Flash (1986)  3.254717  2.578358 -0.676359\nGrease (1978)              3.975265  3.367041 -0.608224\nLittle Women (1994)        3.870588  3.321739 -0.548849\nSteel Magnolias (1989)     3.901734  3.365957 -0.535777\n```", "```py\nIn [91]: sorted_by_diff[::-1].head()\nOut[91]: \ngender                                         F         M      diff\ntitle \nGood, The Bad and The Ugly, The (1966)  3.494949  4.221300  0.726351\nKentucky Fried Movie, The (1977)        2.878788  3.555147  0.676359\nDumb & Dumber (1994)                    2.697987  3.336595  0.638608\nLongest Day, The (1962)                 3.411765  4.031447  0.619682\nCable Guy, The (1996)                   2.250000  2.863787  0.613787\n```", "```py\nIn [92]: rating_std_by_title = data.groupby(\"title\")[\"rating\"].std()\n\nIn [93]: rating_std_by_title = rating_std_by_title.loc[active_titles]\n\nIn [94]: rating_std_by_title.head()\nOut[94]: \ntitle\n'burbs, The (1989)                   1.107760\n10 Things I Hate About You (1999)    0.989815\n101 Dalmatians (1961)                0.982103\n101 Dalmatians (1996)                1.098717\n12 Angry Men (1957)                  0.812731\nName: rating, dtype: float64\n```", "```py\nIn [95]: rating_std_by_title.sort_values(ascending=False)[:10]\nOut[95]: \ntitle\nDumb & Dumber (1994)                     1.321333\nBlair Witch Project, The (1999)          1.316368\nNatural Born Killers (1994)              1.307198\nTank Girl (1995)                         1.277695\nRocky Horror Picture Show, The (1975)    1.260177\nEyes Wide Shut (1999)                    1.259624\nEvita (1996)                             1.253631\nBilly Madison (1995)                     1.249970\nFear and Loathing in Las Vegas (1998)    1.246408\nBicentennial Man (1999)                  1.245533\nName: rating, dtype: float64\n```", "```py\nIn [96]: movies[\"genres\"].head()\nOut[96]: \n0     Animation|Children's|Comedy\n1    Adventure|Children's|Fantasy\n2                  Comedy|Romance\n3                    Comedy|Drama\n4                          Comedy\nName: genres, dtype: object\n\nIn [97]: movies[\"genres\"].head().str.split(\"|\")\nOut[97]: \n0     [Animation, Children's, Comedy]\n1 [Adventure, Children's, Fantasy]\n2 [Comedy, Romance]\n3                     [Comedy, Drama]\n4                            [Comedy]\nName: genres, dtype: object\n\nIn [98]: movies[\"genre\"] = movies.pop(\"genres\").str.split(\"|\")\n\nIn [99]: movies.head()\nOut[99]: \n movie_id                               title \n0         1                    Toy Story (1995)  \\\n1         2                      Jumanji (1995) \n2         3             Grumpier Old Men (1995) \n3         4            Waiting to Exhale (1995) \n4         5  Father of the Bride Part II (1995) \n genre \n0   [Animation, Children's, Comedy] \n1  [Adventure, Children's, Fantasy] \n2 [Comedy, Romance] \n3                   [Comedy, Drama] \n4                          [Comedy] \n```", "```py\nIn [100]: movies_exploded = movies.explode(\"genre\")\n\nIn [101]: movies_exploded[:10]\nOut[101]: \n movie_id                     title       genre\n0         1          Toy Story (1995)   Animation\n0         1          Toy Story (1995)  Children's\n0         1          Toy Story (1995)      Comedy\n1         2            Jumanji (1995)   Adventure\n1         2            Jumanji (1995)  Children's\n1         2            Jumanji (1995)     Fantasy\n2         3   Grumpier Old Men (1995)      Comedy\n2         3   Grumpier Old Men (1995)     Romance\n3         4  Waiting to Exhale (1995)      Comedy\n3         4  Waiting to Exhale (1995)       Drama\n```", "```py\nIn [102]: ratings_with_genre = pd.merge(pd.merge(movies_exploded, ratings), users\n)\n\nIn [103]: ratings_with_genre.iloc[0]\nOut[103]: \nmovie_id                     1\ntitle         Toy Story (1995)\ngenre                Animation\nuser_id                      1\nrating                       5\ntimestamp            978824268\ngender                       F\nage                          1\noccupation                  10\nzip                      48067\nName: 0, dtype: object\n\nIn [104]: genre_ratings = (ratings_with_genre.groupby([\"genre\", \"age\"])\n .....:                  [\"rating\"].mean()\n .....:                  .unstack(\"age\"))\n\nIn [105]: genre_ratings[:10]\nOut[105]: \nage                1         18        25        35        45        50 \ngenre \nAction       3.506385  3.447097  3.453358  3.538107  3.528543  3.611333  \\\nAdventure    3.449975  3.408525  3.443163  3.515291  3.528963  3.628163 \nAnimation    3.476113  3.624014  3.701228  3.740545  3.734856  3.780020 \nChildren's   3.241642  3.294257  3.426873  3.518423  3.527593  3.556555 \nComedy       3.497491  3.460417  3.490385  3.561984  3.591789  3.646868 \nCrime        3.710170  3.668054  3.680321  3.733736  3.750661  3.810688 \nDocumentary  3.730769  3.865865  3.946690  3.953747  3.966521  3.908108 \nDrama        3.794735  3.721930  3.726428  3.782512  3.784356  3.878415 \nFantasy      3.317647  3.353778  3.452484  3.482301  3.532468  3.581570 \nFilm-Noir    4.145455  3.997368  4.058725  4.064910  4.105376  4.175401 \nage                56 \ngenre \nAction       3.610709 \nAdventure    3.649064 \nAnimation    3.756233 \nChildren's   3.621822 \nComedy       3.650949 \nCrime        3.832549 \nDocumentary  3.961538 \nDrama        3.933465 \nFantasy      3.532700 \nFilm-Noir    4.125932 \n```", "```py\nIn [4]: names.head(10)\nOut[4]:\n name sex  births  year\n0       Mary   F    7065  1880\n1       Anna   F    2604  1880\n2       Emma   F    2003  1880\n3  Elizabeth   F    1939  1880\n4     Minnie   F    1746  1880\n5   Margaret   F    1578  1880\n6        Ida   F    1472  1880\n7      Alice   F    1414  1880\n8     Bertha   F    1320  1880\n9      Sarah   F    1288  1880\n```", "```py\nIn [106]: !head -n 10 datasets/babynames/yob1880.txt\nMary,F,7065\nAnna,F,2604\nEmma,F,2003\nElizabeth,F,1939\nMinnie,F,1746\nMargaret,F,1578\nIda,F,1472\nAlice,F,1414\nBertha,F,1320\nSarah,F,1288\n```", "```py\nIn [107]: names1880 = pd.read_csv(\"datasets/babynames/yob1880.txt\",\n .....:                         names=[\"name\", \"sex\", \"births\"])\n\nIn [108]: names1880\nOut[108]: \n name sex  births\n0          Mary   F    7065\n1          Anna   F    2604\n2          Emma   F    2003\n3     Elizabeth   F    1939\n4        Minnie   F    1746\n...         ...  ..     ...\n1995     Woodie   M       5\n1996     Worthy   M       5\n1997     Wright   M       5\n1998       York   M       5\n1999  Zachariah   M       5\n[2000 rows x 3 columns]\n```", "```py\nIn [109]: names1880.groupby(\"sex\")[\"births\"].sum()\nOut[109]: \nsex\nF     90993\nM    110493\nName: births, dtype: int64\n```", "```py\npieces = []\nfor year in range(1880, 2011):\n path = f\"datasets/babynames/yob{year}.txt\"\n frame = pd.read_csv(path, names=[\"name\", \"sex\", \"births\"])\n\n # Add a column for the year\n frame[\"year\"] = year\n pieces.append(frame)\n\n# Concatenate everything into a single DataFrame\nnames = pd.concat(pieces, ignore_index=True)\n```", "```py\nIn [111]: names\nOut[111]: \n name sex  births  year\n0             Mary   F    7065  1880\n1             Anna   F    2604  1880\n2             Emma   F    2003  1880\n3        Elizabeth   F    1939  1880\n4           Minnie   F    1746  1880\n...            ...  ..     ...   ...\n1690779    Zymaire   M       5  2010\n1690780     Zyonne   M       5  2010\n1690781  Zyquarius   M       5  2010\n1690782      Zyran   M       5  2010\n1690783      Zzyzx   M       5  2010\n[1690784 rows x 4 columns]\n```", "```py\nIn [112]: total_births = names.pivot_table(\"births\", index=\"year\",\n .....:                                  columns=\"sex\", aggfunc=sum)\n\nIn [113]: total_births.tail()\nOut[113]: \nsex         F        M\nyear \n2006  1896468  2050234\n2007  1916888  2069242\n2008  1883645  2032310\n2009  1827643  1973359\n2010  1759010  1898382\n\nIn [114]: total_births.plot(title=\"Total births by sex and year\")\n```", "```py\ndef add_prop(group):\n group[\"prop\"] = group[\"births\"] / group[\"births\"].sum()\n return group\nnames = names.groupby([\"year\", \"sex\"], group_keys=False).apply(add_prop)\n```", "```py\nIn [116]: names\nOut[116]: \n name sex  births  year      prop\n0             Mary   F    7065  1880  0.077643\n1             Anna   F    2604  1880  0.028618\n2             Emma   F    2003  1880  0.022013\n3        Elizabeth   F    1939  1880  0.021309\n4           Minnie   F    1746  1880  0.019188\n...            ...  ..     ...   ...       ...\n1690779    Zymaire   M       5  2010  0.000003\n1690780     Zyonne   M       5  2010  0.000003\n1690781  Zyquarius   M       5  2010  0.000003\n1690782      Zyran   M       5  2010  0.000003\n1690783      Zzyzx   M       5  2010  0.000003\n[1690784 rows x 5 columns]\n```", "```py\nIn [117]: names.groupby([\"year\", \"sex\"])[\"prop\"].sum()\nOut[117]: \nyear  sex\n1880  F      1.0\n M      1.0\n1881  F      1.0\n M      1.0\n1882  F      1.0\n ... \n2008  M      1.0\n2009  F      1.0\n M      1.0\n2010  F      1.0\n M      1.0\nName: prop, Length: 262, dtype: float64\n```", "```py\nIn [118]: def get_top1000(group):\n .....:     return group.sort_values(\"births\", ascending=False)[:1000]\n\nIn [119]: grouped = names.groupby([\"year\", \"sex\"])\n\nIn [120]: top1000 = grouped.apply(get_top1000)\n\nIn [121]: top1000.head()\nOut[121]: \n name sex  births  year      prop\nyear sex \n1880 F   0       Mary   F    7065  1880  0.077643\n 1       Anna   F    2604  1880  0.028618\n 2       Emma   F    2003  1880  0.022013\n 3  Elizabeth   F    1939  1880  0.021309\n 4     Minnie   F    1746  1880  0.019188\n```", "```py\nIn [122]: top1000 = top1000.reset_index(drop=True)\n```", "```py\nIn [123]: top1000.head()\nOut[123]: \n name sex  births  year      prop\n0       Mary   F    7065  1880  0.077643\n1       Anna   F    2604  1880  0.028618\n2       Emma   F    2003  1880  0.022013\n3  Elizabeth   F    1939  1880  0.021309\n4     Minnie   F    1746  1880  0.019188\n```", "```py\nIn [124]: boys = top1000[top1000[\"sex\"] == \"M\"]\n\nIn [125]: girls = top1000[top1000[\"sex\"] == \"F\"]\n```", "```py\nIn [126]: total_births = top1000.pivot_table(\"births\", index=\"year\",\n .....:                                    columns=\"name\",\n .....:                                    aggfunc=sum)\n```", "```py\nIn [127]: total_births.info()\n<class 'pandas.core.frame.DataFrame'>\nIndex: 131 entries, 1880 to 2010\nColumns: 6868 entries, Aaden to Zuri\ndtypes: float64(6868)\nmemory usage: 6.9 MB\n\nIn [128]: subset = total_births[[\"John\", \"Harry\", \"Mary\", \"Marilyn\"]]\n\nIn [129]: subset.plot(subplots=True, figsize=(12, 10),\n .....:             title=\"Number of births per year\")\n```", "```py\nIn [131]: table = top1000.pivot_table(\"prop\", index=\"year\",\n .....:                             columns=\"sex\", aggfunc=sum)\n\nIn [132]: table.plot(title=\"Sum of table1000.prop by year and sex\",\n .....:            yticks=np.linspace(0, 1.2, 13))\n```", "```py\nIn [133]: df = boys[boys[\"year\"] == 2010]\n\nIn [134]: df\nOut[134]: \n name sex  births  year      prop\n260877    Jacob   M   21875  2010  0.011523\n260878    Ethan   M   17866  2010  0.009411\n260879  Michael   M   17133  2010  0.009025\n260880   Jayden   M   17030  2010  0.008971\n260881  William   M   16870  2010  0.008887\n...         ...  ..     ...   ...       ...\n261872   Camilo   M     194  2010  0.000102\n261873   Destin   M     194  2010  0.000102\n261874   Jaquan   M     194  2010  0.000102\n261875   Jaydan   M     194  2010  0.000102\n261876   Maxton   M     193  2010  0.000102\n[1000 rows x 5 columns]\n```", "```py\nIn [135]: prop_cumsum = df[\"prop\"].sort_values(ascending=False).cumsum()\n\nIn [136]: prop_cumsum[:10]\nOut[136]: \n260877    0.011523\n260878    0.020934\n260879    0.029959\n260880    0.038930\n260881    0.047817\n260882    0.056579\n260883    0.065155\n260884    0.073414\n260885    0.081528\n260886    0.089621\nName: prop, dtype: float64\n\nIn [137]: prop_cumsum.searchsorted(0.5)\nOut[137]: 116\n```", "```py\nIn [138]: df = boys[boys.year == 1900]\n\nIn [139]: in1900 = df.sort_values(\"prop\", ascending=False).prop.cumsum()\n\nIn [140]: in1900.searchsorted(0.5) + 1\nOut[140]: 25\n```", "```py\ndef get_quantile_count(group, q=0.5):\n group = group.sort_values(\"prop\", ascending=False)\n return group.prop.cumsum().searchsorted(q) + 1\n\ndiversity = top1000.groupby([\"year\", \"sex\"]).apply(get_quantile_count)\ndiversity = diversity.unstack()\n```", "```py\nIn [143]: diversity.head()\nOut[143]: \nsex    F   M\nyear \n1880  38  14\n1881  38  14\n1882  38  15\n1883  39  15\n1884  39  16\n\nIn [144]: diversity.plot(title=\"Number of popular names in top 50%\")\n```", "```py\ndef get_last_letter(x):\n return x[-1]\n\nlast_letters = names[\"name\"].map(get_last_letter)\nlast_letters.name = \"last_letter\"\n\ntable = names.pivot_table(\"births\", index=last_letters,\n columns=[\"sex\", \"year\"], aggfunc=sum)\n```", "```py\nIn [146]: subtable = table.reindex(columns=[1910, 1960, 2010], level=\"year\")\n\nIn [147]: subtable.head()\nOut[147]: \nsex                 F                            M \nyear             1910      1960      2010     1910      1960      2010\nlast_letter \na            108376.0  691247.0  670605.0    977.0    5204.0   28438.0\nb                 NaN     694.0     450.0    411.0    3912.0   38859.0\nc                 5.0      49.0     946.0    482.0   15476.0   23125.0\nd              6750.0    3729.0    2607.0  22111.0  262112.0   44398.0\ne            133569.0  435013.0  313833.0  28655.0  178823.0  129012.0\n```", "```py\nIn [148]: subtable.sum()\nOut[148]: \nsex  year\nF    1910     396416.0\n 1960    2022062.0\n 2010    1759010.0\nM    1910     194198.0\n 1960    2132588.0\n 2010    1898382.0\ndtype: float64\n\nIn [149]: letter_prop = subtable / subtable.sum()\n\nIn [150]: letter_prop\nOut[150]: \nsex                 F                             M \nyear             1910      1960      2010      1910      1960      2010\nlast_letter \na            0.273390  0.341853  0.381240  0.005031  0.002440  0.014980\nb                 NaN  0.000343  0.000256  0.002116  0.001834  0.020470\nc            0.000013  0.000024  0.000538  0.002482  0.007257  0.012181\nd            0.017028  0.001844  0.001482  0.113858  0.122908  0.023387\ne            0.336941  0.215133  0.178415  0.147556  0.083853  0.067959\n...               ...       ...       ...       ...       ...       ...\nv                 NaN  0.000060  0.000117  0.000113  0.000037  0.001434\nw            0.000020  0.000031  0.001182  0.006329  0.007711  0.016148\nx            0.000015  0.000037  0.000727  0.003965  0.001851  0.008614\ny            0.110972  0.152569  0.116828  0.077349  0.160987  0.058168\nz            0.002439  0.000659  0.000704  0.000170  0.000184  0.001831\n[26 rows x 6 columns]\n```", "```py\nimport matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(2, 1, figsize=(10, 8))\nletter_prop[\"M\"].plot(kind=\"bar\", rot=0, ax=axes[0], title=\"Male\")\nletter_prop[\"F\"].plot(kind=\"bar\", rot=0, ax=axes[1], title=\"Female\",\n legend=False)\n```", "```py\nIn [153]: letter_prop = table / table.sum()\n\nIn [154]: dny_ts = letter_prop.loc[[\"d\", \"n\", \"y\"], \"M\"].T\n\nIn [155]: dny_ts.head()\nOut[155]: \nlast_letter         d         n         y\nyear \n1880         0.083055  0.153213  0.075760\n1881         0.083247  0.153214  0.077451\n1882         0.085340  0.149560  0.077537\n1883         0.084066  0.151646  0.079144\n1884         0.086120  0.149915  0.080405\n```", "```py\nIn [158]: dny_ts.plot()\n```", "```py\nIn [159]: all_names = pd.Series(top1000[\"name\"].unique())\n\nIn [160]: lesley_like = all_names[all_names.str.contains(\"Lesl\")]\n\nIn [161]: lesley_like\nOut[161]: \n632     Leslie\n2294    Lesley\n4262    Leslee\n4728     Lesli\n6103     Lesly\ndtype: object\n```", "```py\nIn [162]: filtered = top1000[top1000[\"name\"].isin(lesley_like)]\n\nIn [163]: filtered.groupby(\"name\")[\"births\"].sum()\nOut[163]: \nname\nLeslee      1082\nLesley     35022\nLesli        929\nLeslie    370429\nLesly      10067\nName: births, dtype: int64\n```", "```py\nIn [164]: table = filtered.pivot_table(\"births\", index=\"year\",\n .....:                              columns=\"sex\", aggfunc=\"sum\")\n\nIn [165]: table = table.div(table.sum(axis=\"columns\"), axis=\"index\")\n\nIn [166]: table.tail()\nOut[166]: \nsex     F   M\nyear \n2006  1.0 NaN\n2007  1.0 NaN\n2008  1.0 NaN\n2009  1.0 NaN\n2010  1.0 NaN\n```", "```py\nIn [168]: table.plot(style={\"M\": \"k-\", \"F\": \"k--\"})\n```", "```py\n{\n \"id\": 21441,\n \"description\": \"KENTUCKY FRIED CHICKEN, Fried Chicken, EXTRA CRISPY,\nWing, meat and skin with breading\",\n \"tags\": [\"KFC\"],\n \"manufacturer\": \"Kentucky Fried Chicken\",\n \"group\": \"Fast Foods\",\n \"portions\": [\n {\n \"amount\": 1,\n \"unit\": \"wing, with skin\",\n \"grams\": 68.0\n },\n\n ...\n ],\n \"nutrients\": [\n {\n \"value\": 20.8,\n \"units\": \"g\",\n \"description\": \"Protein\",\n \"group\": \"Composition\"\n },\n\n ...\n ]\n}\n```", "```py\nIn [169]: import json\n\nIn [170]: db = json.load(open(\"datasets/usda_food/database.json\"))\n\nIn [171]: len(db)\nOut[171]: 6636\n```", "```py\nIn [172]: db[0].keys()\nOut[172]: dict_keys(['id', 'description', 'tags', 'manufacturer', 'group', 'porti\nons', 'nutrients'])\n\nIn [173]: db[0][\"nutrients\"][0]\nOut[173]: \n{'value': 25.18,\n 'units': 'g',\n 'description': 'Protein',\n 'group': 'Composition'}\n\nIn [174]: nutrients = pd.DataFrame(db[0][\"nutrients\"])\n\nIn [175]: nutrients.head(7)\nOut[175]: \n value units                  description        group\n0    25.18     g                      Protein  Composition\n1    29.20     g            Total lipid (fat)  Composition\n2     3.06     g  Carbohydrate, by difference  Composition\n3     3.28     g                          Ash        Other\n4   376.00  kcal                       Energy       Energy\n5    39.28     g                        Water  Composition\n6  1573.00    kJ                       Energy       Energy\n```", "```py\nIn [176]: info_keys = [\"description\", \"group\", \"id\", \"manufacturer\"]\n\nIn [177]: info = pd.DataFrame(db, columns=info_keys)\n\nIn [178]: info.head()\nOut[178]: \n description                   group    id \n0                     Cheese, caraway  Dairy and Egg Products  1008  \\\n1                     Cheese, cheddar  Dairy and Egg Products  1009 \n2                        Cheese, edam  Dairy and Egg Products  1018 \n3                        Cheese, feta  Dairy and Egg Products  1019 \n4  Cheese, mozzarella, part skim milk  Dairy and Egg Products  1028 \n manufacturer \n0 \n1 \n2 \n3 \n4 \n\nIn [179]: info.info()\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 6636 entries, 0 to 6635\nData columns (total 4 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   description   6636 non-null   object\n 1   group         6636 non-null   object\n 2   id            6636 non-null   int64 \n 3   manufacturer  5195 non-null   object\ndtypes: int64(1), object(3)\nmemory usage: 207.5+ KB\n```", "```py\nIn [180]: pd.value_counts(info[\"group\"])[:10]\nOut[180]: \ngroup\nVegetables and Vegetable Products    812\nBeef Products                        618\nBaked Products                       496\nBreakfast Cereals                    403\nLegumes and Legume Products          365\nFast Foods                           365\nLamb, Veal, and Game Products        345\nSweets                               341\nFruits and Fruit Juices              328\nPork Products                        328\nName: count, dtype: int64\n```", "```py\nnutrients = []\n\nfor rec in db:\n fnuts = pd.DataFrame(rec[\"nutrients\"])\n fnuts[\"id\"] = rec[\"id\"]\n nutrients.append(fnuts)\n\nnutrients = pd.concat(nutrients, ignore_index=True)\n```", "```py\nIn [182]: nutrients\nOut[182]: \n value units                         description        group     id\n0        25.180     g                             Protein  Composition   1008\n1        29.200     g                   Total lipid (fat)  Composition   1008\n2         3.060     g         Carbohydrate, by difference  Composition   1008\n3         3.280     g                                 Ash        Other   1008\n4       376.000  kcal                              Energy       Energy   1008\n...         ...   ...                                 ...          ...    ...\n389350    0.000   mcg                 Vitamin B-12, added     Vitamins  43546\n389351    0.000    mg                         Cholesterol        Other  43546\n389352    0.072     g        Fatty acids, total saturated        Other  43546\n389353    0.028     g  Fatty acids, total monounsaturated        Other  43546\n389354    0.041     g  Fatty acids, total polyunsaturated        Other  43546\n[389355 rows x 5 columns]\n```", "```py\nIn [183]: nutrients.duplicated().sum()  # number of duplicates\nOut[183]: 14179\n\nIn [184]: nutrients = nutrients.drop_duplicates()\n```", "```py\nIn [185]: col_mapping = {\"description\" : \"food\",\n .....:                \"group\"       : \"fgroup\"}\n\nIn [186]: info = info.rename(columns=col_mapping, copy=False)\n\nIn [187]: info.info()\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 6636 entries, 0 to 6635\nData columns (total 4 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   food          6636 non-null   object\n 1   fgroup        6636 non-null   object\n 2   id            6636 non-null   int64 \n 3   manufacturer  5195 non-null   object\ndtypes: int64(1), object(3)\nmemory usage: 207.5+ KB\n\nIn [188]: col_mapping = {\"description\" : \"nutrient\",\n .....:                \"group\" : \"nutgroup\"}\n\nIn [189]: nutrients = nutrients.rename(columns=col_mapping, copy=False)\n\nIn [190]: nutrients\nOut[190]: \n value units                            nutrient     nutgroup     id\n0        25.180     g                             Protein  Composition   1008\n1        29.200     g                   Total lipid (fat)  Composition   1008\n2         3.060     g         Carbohydrate, by difference  Composition   1008\n3         3.280     g                                 Ash        Other   1008\n4       376.000  kcal                              Energy       Energy   1008\n...         ...   ...                                 ...          ...    ...\n389350    0.000   mcg                 Vitamin B-12, added     Vitamins  43546\n389351    0.000    mg                         Cholesterol        Other  43546\n389352    0.072     g        Fatty acids, total saturated        Other  43546\n389353    0.028     g  Fatty acids, total monounsaturated        Other  43546\n389354    0.041     g  Fatty acids, total polyunsaturated        Other  43546\n[375176 rows x 5 columns]\n```", "```py\nIn [191]: ndata = pd.merge(nutrients, info, on=\"id\")\n\nIn [192]: ndata.info()\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 375176 entries, 0 to 375175\nData columns (total 8 columns):\n #   Column        Non-Null Count   Dtype \n---  ------        --------------   ----- \n 0   value         375176 non-null  float64\n 1   units         375176 non-null  object \n 2   nutrient      375176 non-null  object \n 3   nutgroup      375176 non-null  object \n 4   id            375176 non-null  int64 \n 5   food          375176 non-null  object \n 6   fgroup        375176 non-null  object \n 7   manufacturer  293054 non-null  object \ndtypes: float64(1), int64(1), object(6)\nmemory usage: 22.9+ MB\n\nIn [193]: ndata.iloc[30000]\nOut[193]: \nvalue                                             0.04\nunits                                                g\nnutrient                                       Glycine\nnutgroup                                   Amino Acids\nid                                                6158\nfood            Soup, tomato bisque, canned, condensed\nfgroup                      Soups, Sauces, and Gravies\nmanufacturer \nName: 30000, dtype: object\n```", "```py\nIn [195]: result = ndata.groupby([\"nutrient\", \"fgroup\"])[\"value\"].quantile(0.5)\n\nIn [196]: result[\"Zinc, Zn\"].sort_values().plot(kind=\"barh\")\n```", "```py\nby_nutrient = ndata.groupby([\"nutgroup\", \"nutrient\"])\n\ndef get_maximum(x):\n return x.loc[x.value.idxmax()]\n\nmax_foods = by_nutrient.apply(get_maximum)[[\"value\", \"food\"]]\n\n# make the food a little smaller\nmax_foods[\"food\"] = max_foods[\"food\"].str[:50]\n```", "```py\nIn [198]: max_foods.loc[\"Amino Acids\"][\"food\"]\nOut[198]: \nnutrient\nAlanine                            Gelatins, dry powder, unsweetened\nArginine                                Seeds, sesame flour, low-fat\nAspartic acid                                    Soy protein isolate\nCystine                 Seeds, cottonseed flour, low fat (glandless)\nGlutamic acid                                    Soy protein isolate\nGlycine                            Gelatins, dry powder, unsweetened\nHistidine                 Whale, beluga, meat, dried (Alaska Native)\nHydroxyproline    KENTUCKY FRIED CHICKEN, Fried Chicken, ORIGINAL RE\nIsoleucine        Soy protein isolate, PROTEIN TECHNOLOGIES INTERNAT\nLeucine           Soy protein isolate, PROTEIN TECHNOLOGIES INTERNAT\nLysine            Seal, bearded (Oogruk), meat, dried (Alaska Native\nMethionine                     Fish, cod, Atlantic, dried and salted\nPhenylalanine     Soy protein isolate, PROTEIN TECHNOLOGIES INTERNAT\nProline                            Gelatins, dry powder, unsweetened\nSerine            Soy protein isolate, PROTEIN TECHNOLOGIES INTERNAT\nThreonine         Soy protein isolate, PROTEIN TECHNOLOGIES INTERNAT\nTryptophan          Sea lion, Steller, meat with fat (Alaska Native)\nTyrosine          Soy protein isolate, PROTEIN TECHNOLOGIES INTERNAT\nValine            Soy protein isolate, PROTEIN TECHNOLOGIES INTERNAT\nName: food, dtype: object\n```", "```py\nIn [199]: fec = pd.read_csv(\"datasets/fec/P00000001-ALL.csv\", low_memory=False)\n\nIn [200]: fec.info()\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1001731 entries, 0 to 1001730\nData columns (total 16 columns):\n #   Column             Non-Null Count    Dtype \n---  ------             --------------    ----- \n 0   cmte_id            1001731 non-null  object \n 1   cand_id            1001731 non-null  object \n 2   cand_nm            1001731 non-null  object \n 3   contbr_nm          1001731 non-null  object \n 4   contbr_city        1001712 non-null  object \n 5   contbr_st          1001727 non-null  object \n 6   contbr_zip         1001620 non-null  object \n 7   contbr_employer    988002 non-null   object \n 8   contbr_occupation  993301 non-null   object \n 9   contb_receipt_amt  1001731 non-null  float64\n 10  contb_receipt_dt   1001731 non-null  object \n 11  receipt_desc       14166 non-null    object \n 12  memo_cd            92482 non-null    object \n 13  memo_text          97770 non-null    object \n 14  form_tp            1001731 non-null  object \n 15  file_num           1001731 non-null  int64 \ndtypes: float64(1), int64(1), object(14)\nmemory usage: 122.3+ MB\n```", "```py\nIn [201]: fec.iloc[123456]\nOut[201]: \ncmte_id                             C00431445\ncand_id                             P80003338\ncand_nm                         Obama, Barack\ncontbr_nm                         ELLMAN, IRA\ncontbr_city                             TEMPE\ncontbr_st                                  AZ\ncontbr_zip                          852816719\ncontbr_employer      ARIZONA STATE UNIVERSITY\ncontbr_occupation                   PROFESSOR\ncontb_receipt_amt                        50.0\ncontb_receipt_dt                    01-DEC-11\nreceipt_desc                              NaN\nmemo_cd                                   NaN\nmemo_text                                 NaN\nform_tp                                 SA17A\nfile_num                               772372\nName: 123456, dtype: object\n```", "```py\nIn [202]: unique_cands = fec[\"cand_nm\"].unique()\n\nIn [203]: unique_cands\nOut[203]: \narray(['Bachmann, Michelle', 'Romney, Mitt', 'Obama, Barack',\n \"Roemer, Charles E. 'Buddy' III\", 'Pawlenty, Timothy',\n 'Johnson, Gary Earl', 'Paul, Ron', 'Santorum, Rick',\n 'Cain, Herman', 'Gingrich, Newt', 'McCotter, Thaddeus G',\n 'Huntsman, Jon', 'Perry, Rick'], dtype=object)\n\nIn [204]: unique_cands[2]\nOut[204]: 'Obama, Barack'\n```", "```py\nparties = {\"Bachmann, Michelle\": \"Republican\",\n \"Cain, Herman\": \"Republican\",\n \"Gingrich, Newt\": \"Republican\",\n \"Huntsman, Jon\": \"Republican\",\n \"Johnson, Gary Earl\": \"Republican\",\n \"McCotter, Thaddeus G\": \"Republican\",\n \"Obama, Barack\": \"Democrat\",\n \"Paul, Ron\": \"Republican\",\n \"Pawlenty, Timothy\": \"Republican\",\n \"Perry, Rick\": \"Republican\",\n \"Roemer, Charles E. 'Buddy' III\": \"Republican\",\n \"Romney, Mitt\": \"Republican\",\n \"Santorum, Rick\": \"Republican\"}\n```", "```py\nIn [206]: fec[\"cand_nm\"][123456:123461]\nOut[206]: \n123456    Obama, Barack\n123457    Obama, Barack\n123458    Obama, Barack\n123459    Obama, Barack\n123460    Obama, Barack\nName: cand_nm, dtype: object\n\nIn [207]: fec[\"cand_nm\"][123456:123461].map(parties)\nOut[207]: \n123456    Democrat\n123457    Democrat\n123458    Democrat\n123459    Democrat\n123460    Democrat\nName: cand_nm, dtype: object\n\n# Add it as a column\nIn [208]: fec[\"party\"] = fec[\"cand_nm\"].map(parties)\n\nIn [209]: fec[\"party\"].value_counts()\nOut[209]: \nparty\nDemocrat      593746\nRepublican    407985\nName: count, dtype: int64\n```", "```py\nIn [210]: (fec[\"contb_receipt_amt\"] > 0).value_counts()\nOut[210]: \ncontb_receipt_amt\nTrue     991475\nFalse     10256\nName: count, dtype: int64\n```", "```py\nIn [211]: fec = fec[fec[\"contb_receipt_amt\"] > 0]\n```", "```py\nIn [212]: fec_mrbo = fec[fec[\"cand_nm\"].isin([\"Obama, Barack\", \"Romney, Mitt\"])]\n```", "```py\nIn [213]: fec[\"contbr_occupation\"].value_counts()[:10]\nOut[213]: \ncontbr_occupation\nRETIRED                                   233990\nINFORMATION REQUESTED                      35107\nATTORNEY                                   34286\nHOMEMAKER                                  29931\nPHYSICIAN                                  23432\nINFORMATION REQUESTED PER BEST EFFORTS     21138\nENGINEER                                   14334\nTEACHER                                    13990\nCONSULTANT                                 13273\nPROFESSOR                                  12555\nName: count, dtype: int64\n```", "```py\nocc_mapping = {\n \"INFORMATION REQUESTED PER BEST EFFORTS\" : \"NOT PROVIDED\",\n \"INFORMATION REQUESTED\" : \"NOT PROVIDED\",\n \"INFORMATION REQUESTED (BEST EFFORTS)\" : \"NOT PROVIDED\",\n \"C.E.O.\": \"CEO\"\n}\n\ndef get_occ(x):\n # If no mapping provided, return x\n return occ_mapping.get(x, x)\n\nfec[\"contbr_occupation\"] = fec[\"contbr_occupation\"].map(get_occ)\n```", "```py\nemp_mapping = {\n \"INFORMATION REQUESTED PER BEST EFFORTS\" : \"NOT PROVIDED\",\n \"INFORMATION REQUESTED\" : \"NOT PROVIDED\",\n \"SELF\" : \"SELF-EMPLOYED\",\n \"SELF EMPLOYED\" : \"SELF-EMPLOYED\",\n}\n\ndef get_emp(x):\n # If no mapping provided, return x\n return emp_mapping.get(x, x)\n\nfec[\"contbr_employer\"] = fec[\"contbr_employer\"].map(get_emp)\n```", "```py\nIn [216]: by_occupation = fec.pivot_table(\"contb_receipt_amt\",\n .....:                                 index=\"contbr_occupation\",\n .....:                                 columns=\"party\", aggfunc=\"sum\")\n\nIn [217]: over_2mm = by_occupation[by_occupation.sum(axis=\"columns\") > 2000000]\n\nIn [218]: over_2mm\nOut[218]: \nparty                 Democrat   Republican\ncontbr_occupation \nATTORNEY           11141982.97   7477194.43\nCEO                 2074974.79   4211040.52\nCONSULTANT          2459912.71   2544725.45\nENGINEER             951525.55   1818373.70\nEXECUTIVE           1355161.05   4138850.09\nHOMEMAKER           4248875.80  13634275.78\nINVESTOR             884133.00   2431768.92\nLAWYER              3160478.87    391224.32\nMANAGER              762883.22   1444532.37\nNOT PROVIDED        4866973.96  20565473.01\nOWNER               1001567.36   2408286.92\nPHYSICIAN           3735124.94   3594320.24\nPRESIDENT           1878509.95   4720923.76\nPROFESSOR           2165071.08    296702.73\nREAL ESTATE          528902.09   1625902.25\nRETIRED            25305116.38  23561244.49\nSELF-EMPLOYED        672393.40   1640252.54\n```", "```py\nIn [220]: over_2mm.plot(kind=\"barh\")\n```", "```py\ndef get_top_amounts(group, key, n=5):\n totals = group.groupby(key)[\"contb_receipt_amt\"].sum()\n return totals.nlargest(n)\n```", "```py\nIn [222]: grouped = fec_mrbo.groupby(\"cand_nm\")\n\nIn [223]: grouped.apply(get_top_amounts, \"contbr_occupation\", n=7)\nOut[223]: \ncand_nm        contbr_occupation \nObama, Barack  RETIRED                                   25305116.38\n ATTORNEY                                  11141982.97\n INFORMATION REQUESTED                      4866973.96\n HOMEMAKER                                  4248875.80\n PHYSICIAN                                  3735124.94\n LAWYER                                     3160478.87\n CONSULTANT                                 2459912.71\nRomney, Mitt   RETIRED                                   11508473.59\n INFORMATION REQUESTED PER BEST EFFORTS    11396894.84\n HOMEMAKER                                  8147446.22\n ATTORNEY                                   5364718.82\n PRESIDENT                                  2491244.89\n EXECUTIVE                                  2300947.03\n C.E.O.                                     1968386.11\nName: contb_receipt_amt, dtype: float64\n\nIn [224]: grouped.apply(get_top_amounts, \"contbr_employer\", n=10)\nOut[224]: \ncand_nm        contbr_employer \nObama, Barack  RETIRED                                   22694358.85\n SELF-EMPLOYED                             17080985.96\n NOT EMPLOYED                               8586308.70\n INFORMATION REQUESTED                      5053480.37\n HOMEMAKER                                  2605408.54\n SELF                                       1076531.20\n SELF EMPLOYED                               469290.00\n STUDENT                                     318831.45\n VOLUNTEER                                   257104.00\n MICROSOFT                                   215585.36\nRomney, Mitt   INFORMATION REQUESTED PER BEST EFFORTS    12059527.24\n RETIRED                                   11506225.71\n HOMEMAKER                                  8147196.22\n SELF-EMPLOYED                              7409860.98\n STUDENT                                     496490.94\n CREDIT SUISSE                               281150.00\n MORGAN STANLEY                              267266.00\n GOLDMAN SACH & CO.                          238250.00\n BARCLAYS CAPITAL                            162750.00\n H.I.G. CAPITAL                              139500.00\nName: contb_receipt_amt, dtype: float64\n```", "```py\nIn [225]: bins = np.array([0, 1, 10, 100, 1000, 10000,\n .....:                  100_000, 1_000_000, 10_000_000])\n\nIn [226]: labels = pd.cut(fec_mrbo[\"contb_receipt_amt\"], bins)\n\nIn [227]: labels\nOut[227]: \n411         (10, 100]\n412       (100, 1000]\n413       (100, 1000]\n414         (10, 100]\n415         (10, 100]\n ... \n701381      (10, 100]\n701382    (100, 1000]\n701383        (1, 10]\n701384      (10, 100]\n701385    (100, 1000]\nName: contb_receipt_amt, Length: 694282, dtype: category\nCategories (8, interval[int64, right]): [(0, 1] < (1, 10] < (10, 100] < (100, 100\n0] <\n (1000, 10000] < (10000, 100000] < (10000\n0, 1000000] <\n (1000000, 10000000]]\n```", "```py\nIn [228]: grouped = fec_mrbo.groupby([\"cand_nm\", labels])\n\nIn [229]: grouped.size().unstack(level=0)\nOut[229]: \ncand_nm              Obama, Barack  Romney, Mitt\ncontb_receipt_amt \n(0, 1]                         493            77\n(1, 10]                      40070          3681\n(10, 100]                   372280         31853\n(100, 1000]                 153991         43357\n(1000, 10000]                22284         26186\n(10000, 100000]                  2             1\n(100000, 1000000]                3             0\n(1000000, 10000000]              4             0\n```", "```py\nIn [231]: bucket_sums = grouped[\"contb_receipt_amt\"].sum().unstack(level=0)\n\nIn [232]: normed_sums = bucket_sums.div(bucket_sums.sum(axis=\"columns\"),\n .....:                               axis=\"index\")\n\nIn [233]: normed_sums\nOut[233]: \ncand_nm              Obama, Barack  Romney, Mitt\ncontb_receipt_amt \n(0, 1]                    0.805182      0.194818\n(1, 10]                   0.918767      0.081233\n(10, 100]                 0.910769      0.089231\n(100, 1000]               0.710176      0.289824\n(1000, 10000]             0.447326      0.552674\n(10000, 100000]           0.823120      0.176880\n(100000, 1000000]         1.000000      0.000000\n(1000000, 10000000]       1.000000      0.000000\n\nIn [234]: normed_sums[:-2].plot(kind=\"barh\")\n```", "```py\nIn [235]: grouped = fec_mrbo.groupby([\"cand_nm\", \"contbr_st\"])\n\nIn [236]: totals = grouped[\"contb_receipt_amt\"].sum().unstack(level=0).fillna(0)\n\nIn [237]: totals = totals[totals.sum(axis=\"columns\") > 100000]\n\nIn [238]: totals.head(10)\nOut[238]: \ncand_nm    Obama, Barack  Romney, Mitt\ncontbr_st \nAK             281840.15      86204.24\nAL             543123.48     527303.51\nAR             359247.28     105556.00\nAZ            1506476.98    1888436.23\nCA           23824984.24   11237636.60\nCO            2132429.49    1506714.12\nCT            2068291.26    3499475.45\nDC            4373538.80    1025137.50\nDE             336669.14      82712.00\nFL            7318178.58    8338458.81\n```", "```py\nIn [239]: percent = totals.div(totals.sum(axis=\"columns\"), axis=\"index\")\n\nIn [240]: percent.head(10)\nOut[240]: \ncand_nm    Obama, Barack  Romney, Mitt\ncontbr_st \nAK              0.765778      0.234222\nAL              0.507390      0.492610\nAR              0.772902      0.227098\nAZ              0.443745      0.556255\nCA              0.679498      0.320502\nCO              0.585970      0.414030\nCT              0.371476      0.628524\nDC              0.810113      0.189887\nDE              0.802776      0.197224\nFL              0.467417      0.532583\n```"]